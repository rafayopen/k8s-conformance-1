May 13 18:23:16.012: INFO: Overriding default scale value of zero to 1
May 13 18:23:16.012: INFO: Overriding default milliseconds value of zero to 5000
I0513 18:23:16.443029      16 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-177230811
I0513 18:23:16.443139      16 e2e.go:304] Starting e2e run "2cddd349-75ac-11e9-a09a-7e4d6cfcc771" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1557771795 - Will randomize all specs
Will run 188 of 1814 specs

May 13 18:23:16.586: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
May 13 18:23:16.590: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
May 13 18:23:16.655: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May 13 18:23:16.727: INFO: 23 / 23 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 13 18:23:16.727: INFO: expected 11 pod replicas in namespace 'kube-system', 11 are Running and Ready.
May 13 18:23:16.727: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
May 13 18:23:16.742: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
May 13 18:23:16.742: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
May 13 18:23:16.742: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-kube-fluentd' (0 seconds elapsed)
May 13 18:23:16.742: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'ibm-master-proxy' (0 seconds elapsed)
May 13 18:23:16.742: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
May 13 18:23:16.742: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
May 13 18:23:16.742: INFO: e2e test version: v1.12.1
May 13 18:23:16.745: INFO: kube-apiserver version: v1.12.8+IKS
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:23:16.745: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename configmap
May 13 18:23:16.924: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
May 13 18:23:16.946: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-8chz2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-2d8f2460-75ac-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume configMaps
May 13 18:23:17.097: INFO: Waiting up to 5m0s for pod "pod-configmaps-2d90b076-75ac-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-configmap-8chz2" to be "success or failure"
May 13 18:23:17.105: INFO: Pod "pod-configmaps-2d90b076-75ac-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 8.161897ms
May 13 18:23:19.113: INFO: Pod "pod-configmaps-2d90b076-75ac-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016798199s
May 13 18:23:21.123: INFO: Pod "pod-configmaps-2d90b076-75ac-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026266073s
STEP: Saw pod success
May 13 18:23:21.123: INFO: Pod "pod-configmaps-2d90b076-75ac-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:23:21.132: INFO: Trying to get logs from node 10.170.219.140 pod pod-configmaps-2d90b076-75ac-11e9-a09a-7e4d6cfcc771 container configmap-volume-test: <nil>
STEP: delete the pod
May 13 18:23:21.182: INFO: Waiting for pod pod-configmaps-2d90b076-75ac-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:23:21.189: INFO: Pod pod-configmaps-2d90b076-75ac-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:23:21.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8chz2" for this suite.
May 13 18:23:27.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:23:27.467: INFO: namespace: e2e-tests-configmap-8chz2, resource: bindings, ignored listing per whitelist
May 13 18:23:27.540: INFO: namespace e2e-tests-configmap-8chz2 deletion completed in 6.338942429s

• [SLOW TEST:10.795 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:23:27.541: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-9cs7v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-33f8a2fe-75ac-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume secrets
May 13 18:23:27.853: INFO: Waiting up to 5m0s for pod "pod-secrets-33fa120e-75ac-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-secrets-9cs7v" to be "success or failure"
May 13 18:23:27.861: INFO: Pod "pod-secrets-33fa120e-75ac-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 7.861016ms
May 13 18:23:29.872: INFO: Pod "pod-secrets-33fa120e-75ac-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01937144s
STEP: Saw pod success
May 13 18:23:29.872: INFO: Pod "pod-secrets-33fa120e-75ac-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:23:29.883: INFO: Trying to get logs from node 10.170.219.140 pod pod-secrets-33fa120e-75ac-11e9-a09a-7e4d6cfcc771 container secret-volume-test: <nil>
STEP: delete the pod
May 13 18:23:29.930: INFO: Waiting for pod pod-secrets-33fa120e-75ac-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:23:29.941: INFO: Pod pod-secrets-33fa120e-75ac-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:23:29.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9cs7v" for this suite.
May 13 18:23:35.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:23:36.079: INFO: namespace: e2e-tests-secrets-9cs7v, resource: bindings, ignored listing per whitelist
May 13 18:23:36.305: INFO: namespace e2e-tests-secrets-9cs7v deletion completed in 6.351418224s

• [SLOW TEST:8.764 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:23:36.305: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-zlbxw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-3931a709-75ac-11e9-a09a-7e4d6cfcc771
May 13 18:23:36.608: INFO: Pod name my-hostname-basic-3931a709-75ac-11e9-a09a-7e4d6cfcc771: Found 0 pods out of 1
May 13 18:23:41.631: INFO: Pod name my-hostname-basic-3931a709-75ac-11e9-a09a-7e4d6cfcc771: Found 1 pods out of 1
May 13 18:23:41.631: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-3931a709-75ac-11e9-a09a-7e4d6cfcc771" are running
May 13 18:23:41.639: INFO: Pod "my-hostname-basic-3931a709-75ac-11e9-a09a-7e4d6cfcc771-k8lx7" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-13 18:23:36 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-13 18:23:38 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-13 18:23:38 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-13 18:23:36 +0000 UTC Reason: Message:}])
May 13 18:23:41.639: INFO: Trying to dial the pod
May 13 18:23:46.674: INFO: Controller my-hostname-basic-3931a709-75ac-11e9-a09a-7e4d6cfcc771: Got expected result from replica 1 [my-hostname-basic-3931a709-75ac-11e9-a09a-7e4d6cfcc771-k8lx7]: "my-hostname-basic-3931a709-75ac-11e9-a09a-7e4d6cfcc771-k8lx7", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:23:46.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-zlbxw" for this suite.
May 13 18:23:52.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:23:53.180: INFO: namespace: e2e-tests-replication-controller-zlbxw, resource: bindings, ignored listing per whitelist
May 13 18:23:53.197: INFO: namespace e2e-tests-replication-controller-zlbxw deletion completed in 6.512284229s

• [SLOW TEST:16.892 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:23:53.197: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-tjhhj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
May 13 18:23:55.598: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-43445ad5-75ac-11e9-a09a-7e4d6cfcc771", GenerateName:"", Namespace:"e2e-tests-pods-tjhhj", SelfLink:"/api/v1/namespaces/e2e-tests-pods-tjhhj/pods/pod-submit-remove-43445ad5-75ac-11e9-a09a-7e4d6cfcc771", UID:"434e3c33-75ac-11e9-906d-b2bf80cbe475", ResourceVersion:"28837", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63693368633, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"488872232"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-9tr4v", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc421aca300), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-9tr4v", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc4217d8d18), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.170.219.140", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc421235020), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4217d8e10)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4217d8e30)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc4217d8e38), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693368633, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693368635, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693368635, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693368633, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.170.219.140", PodIP:"172.30.208.8", StartTime:(*v1.Time)(0xc420f4eac0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc420f4eae0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"docker.io/library/nginx:1.14-alpine", ImageID:"docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7", ContainerID:"containerd://fb40514ee744cbf2c9ea2c7f10f0e8fbd6600452c5f9d844dc7c6213236be12d"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
May 13 18:24:00.760: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:24:00.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-tjhhj" for this suite.
May 13 18:24:06.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:24:07.185: INFO: namespace: e2e-tests-pods-tjhhj, resource: bindings, ignored listing per whitelist
May 13 18:24:07.202: INFO: namespace e2e-tests-pods-tjhhj deletion completed in 6.424475137s

• [SLOW TEST:14.005 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:24:07.202: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-pgwth
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 13 18:24:07.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-pgwth'
May 13 18:24:07.821: INFO: stderr: ""
May 13 18:24:07.821: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
May 13 18:24:12.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-pgwth -o json'
May 13 18:24:13.052: INFO: stderr: ""
May 13 18:24:13.052: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-05-13T18:24:07Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-pgwth\",\n        \"resourceVersion\": \"28902\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-pgwth/pods/e2e-test-nginx-pod\",\n        \"uid\": \"4bcc803d-75ac-11e9-85ce-bec991ad7e3d\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-s5kk5\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"10.170.219.140\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-s5kk5\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-s5kk5\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-13T18:24:07Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-13T18:24:09Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-13T18:24:09Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-13T18:24:07Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://9586b49c766581f3204ab44b5c4c7bbb03c7d1c4bc04f53659f68f4c0b1c13fc\",\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imageID\": \"docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-05-13T18:24:08Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.170.219.140\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.208.13\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-05-13T18:24:07Z\"\n    }\n}\n"
STEP: replace the image in the pod
May 13 18:24:13.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 replace -f - --namespace=e2e-tests-kubectl-pgwth'
May 13 18:24:13.339: INFO: stderr: ""
May 13 18:24:13.339: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
May 13 18:24:13.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-pgwth'
May 13 18:24:15.343: INFO: stderr: ""
May 13 18:24:15.343: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:24:15.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pgwth" for this suite.
May 13 18:24:21.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:24:21.899: INFO: namespace: e2e-tests-kubectl-pgwth, resource: bindings, ignored listing per whitelist
May 13 18:24:21.931: INFO: namespace e2e-tests-kubectl-pgwth deletion completed in 6.578539436s

• [SLOW TEST:14.729 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:24:21.932: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-dnx7l
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-54664d06-75ac-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume configMaps
May 13 18:24:22.259: INFO: Waiting up to 5m0s for pod "pod-configmaps-5467cc41-75ac-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-configmap-dnx7l" to be "success or failure"
May 13 18:24:22.271: INFO: Pod "pod-configmaps-5467cc41-75ac-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 10.641913ms
May 13 18:24:24.295: INFO: Pod "pod-configmaps-5467cc41-75ac-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035155293s
STEP: Saw pod success
May 13 18:24:24.295: INFO: Pod "pod-configmaps-5467cc41-75ac-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:24:24.305: INFO: Trying to get logs from node 10.170.219.140 pod pod-configmaps-5467cc41-75ac-11e9-a09a-7e4d6cfcc771 container configmap-volume-test: <nil>
STEP: delete the pod
May 13 18:24:24.361: INFO: Waiting for pod pod-configmaps-5467cc41-75ac-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:24:24.451: INFO: Pod pod-configmaps-5467cc41-75ac-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:24:24.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-dnx7l" for this suite.
May 13 18:24:30.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:24:30.658: INFO: namespace: e2e-tests-configmap-dnx7l, resource: bindings, ignored listing per whitelist
May 13 18:24:30.792: INFO: namespace e2e-tests-configmap-dnx7l deletion completed in 6.328614748s

• [SLOW TEST:8.860 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:24:30.792: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-258mr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 13 18:24:31.091: INFO: Waiting up to 5m0s for pod "downward-api-59ab7728-75ac-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-downward-api-258mr" to be "success or failure"
May 13 18:24:31.105: INFO: Pod "downward-api-59ab7728-75ac-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 13.268224ms
May 13 18:24:33.116: INFO: Pod "downward-api-59ab7728-75ac-11e9-a09a-7e4d6cfcc771": Phase="Running", Reason="", readiness=true. Elapsed: 2.024142182s
May 13 18:24:35.140: INFO: Pod "downward-api-59ab7728-75ac-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048706593s
STEP: Saw pod success
May 13 18:24:35.140: INFO: Pod "downward-api-59ab7728-75ac-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:24:35.150: INFO: Trying to get logs from node 10.170.219.140 pod downward-api-59ab7728-75ac-11e9-a09a-7e4d6cfcc771 container dapi-container: <nil>
STEP: delete the pod
May 13 18:24:35.197: INFO: Waiting for pod downward-api-59ab7728-75ac-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:24:35.206: INFO: Pod downward-api-59ab7728-75ac-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:24:35.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-258mr" for this suite.
May 13 18:24:41.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:24:41.301: INFO: namespace: e2e-tests-downward-api-258mr, resource: bindings, ignored listing per whitelist
May 13 18:24:41.649: INFO: namespace e2e-tests-downward-api-258mr deletion completed in 6.432477159s

• [SLOW TEST:10.857 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:24:41.649: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-9bqs4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-60252a35-75ac-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume configMaps
May 13 18:24:41.965: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6026bacc-75ac-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-projected-9bqs4" to be "success or failure"
May 13 18:24:41.973: INFO: Pod "pod-projected-configmaps-6026bacc-75ac-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 7.888214ms
May 13 18:24:43.982: INFO: Pod "pod-projected-configmaps-6026bacc-75ac-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017207419s
STEP: Saw pod success
May 13 18:24:43.983: INFO: Pod "pod-projected-configmaps-6026bacc-75ac-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:24:43.991: INFO: Trying to get logs from node 10.170.219.140 pod pod-projected-configmaps-6026bacc-75ac-11e9-a09a-7e4d6cfcc771 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 13 18:24:44.041: INFO: Waiting for pod pod-projected-configmaps-6026bacc-75ac-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:24:44.049: INFO: Pod pod-projected-configmaps-6026bacc-75ac-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:24:44.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9bqs4" for this suite.
May 13 18:24:50.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:24:50.218: INFO: namespace: e2e-tests-projected-9bqs4, resource: bindings, ignored listing per whitelist
May 13 18:24:50.418: INFO: namespace e2e-tests-projected-9bqs4 deletion completed in 6.35525249s

• [SLOW TEST:8.769 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:24:50.418: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-w6zvh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 18:24:50.726: INFO: Pod name cleanup-pod: Found 0 pods out of 1
May 13 18:24:55.735: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 13 18:24:55.735: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 13 18:24:57.899: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-w6zvh,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-w6zvh/deployments/test-cleanup-deployment,UID:68614d19-75ac-11e9-906d-b2bf80cbe475,ResourceVersion:29178,Generation:1,CreationTimestamp:2019-05-13 18:24:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-13 18:24:55 +0000 UTC 2019-05-13 18:24:55 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-13 18:24:57 +0000 UTC 2019-05-13 18:24:55 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-755f6b95cc" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 13 18:24:57.908: INFO: New ReplicaSet "test-cleanup-deployment-755f6b95cc" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-755f6b95cc,GenerateName:,Namespace:e2e-tests-deployment-w6zvh,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-w6zvh/replicasets/test-cleanup-deployment-755f6b95cc,UID:6866a497-75ac-11e9-a685-3eb3c297d0da,ResourceVersion:29169,Generation:1,CreationTimestamp:2019-05-13 18:24:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 68614d19-75ac-11e9-906d-b2bf80cbe475 0xc420be17f7 0xc420be17f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 13 18:24:57.917: INFO: Pod "test-cleanup-deployment-755f6b95cc-v6pdb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-755f6b95cc-v6pdb,GenerateName:test-cleanup-deployment-755f6b95cc-,Namespace:e2e-tests-deployment-w6zvh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w6zvh/pods/test-cleanup-deployment-755f6b95cc-v6pdb,UID:68685119-75ac-11e9-a685-3eb3c297d0da,ResourceVersion:29168,Generation:0,CreationTimestamp:2019-05-13 18:24:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-755f6b95cc 6866a497-75ac-11e9-a685-3eb3c297d0da 0xc42140a2c7 0xc42140a2c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kvqcc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kvqcc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-kvqcc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42140a340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42140a360}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 18:24:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 18:24:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 18:24:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 18:24:55 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.140,PodIP:172.30.208.20,StartTime:2019-05-13 18:24:55 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-13 18:24:56 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://34ea24d70530fccec940c4baea86f004f5028a3fe68425b926f5998018427a4a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:24:57.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-w6zvh" for this suite.
May 13 18:25:03.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:25:04.776: INFO: namespace: e2e-tests-deployment-w6zvh, resource: bindings, ignored listing per whitelist
May 13 18:25:04.821: INFO: namespace e2e-tests-deployment-w6zvh deletion completed in 6.892495278s

• [SLOW TEST:14.402 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:25:04.821: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-j5vrs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 13 18:25:05.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-j5vrs'
May 13 18:25:05.289: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
May 13 18:25:05.289: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
May 13 18:25:05.301: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
May 13 18:25:05.314: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
May 13 18:25:05.320: INFO: scanned /root for discovery docs: <nil>
May 13 18:25:05.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-j5vrs'
May 13 18:25:21.309: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 13 18:25:21.309: INFO: stdout: "Created e2e-test-nginx-rc-0b5464a96fbb51b50b950412f1068d17\nScaling up e2e-test-nginx-rc-0b5464a96fbb51b50b950412f1068d17 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-0b5464a96fbb51b50b950412f1068d17 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-0b5464a96fbb51b50b950412f1068d17 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
May 13 18:25:21.309: INFO: stdout: "Created e2e-test-nginx-rc-0b5464a96fbb51b50b950412f1068d17\nScaling up e2e-test-nginx-rc-0b5464a96fbb51b50b950412f1068d17 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-0b5464a96fbb51b50b950412f1068d17 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-0b5464a96fbb51b50b950412f1068d17 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
May 13 18:25:21.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-j5vrs'
May 13 18:25:21.418: INFO: stderr: ""
May 13 18:25:21.418: INFO: stdout: "e2e-test-nginx-rc-0b5464a96fbb51b50b950412f1068d17-qpn7d "
May 13 18:25:21.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods e2e-test-nginx-rc-0b5464a96fbb51b50b950412f1068d17-qpn7d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j5vrs'
May 13 18:25:21.575: INFO: stderr: ""
May 13 18:25:21.575: INFO: stdout: "true"
May 13 18:25:21.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods e2e-test-nginx-rc-0b5464a96fbb51b50b950412f1068d17-qpn7d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j5vrs'
May 13 18:25:21.688: INFO: stderr: ""
May 13 18:25:21.688: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
May 13 18:25:21.688: INFO: e2e-test-nginx-rc-0b5464a96fbb51b50b950412f1068d17-qpn7d is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
May 13 18:25:21.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-j5vrs'
May 13 18:25:21.838: INFO: stderr: ""
May 13 18:25:21.838: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:25:21.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-j5vrs" for this suite.
May 13 18:25:27.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:25:27.935: INFO: namespace: e2e-tests-kubectl-j5vrs, resource: bindings, ignored listing per whitelist
May 13 18:25:28.139: INFO: namespace e2e-tests-kubectl-j5vrs deletion completed in 6.290134562s

• [SLOW TEST:23.317 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:25:28.139: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-ltv4s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 18:25:28.456: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7bdc1a1e-75ac-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-projected-ltv4s" to be "success or failure"
May 13 18:25:28.463: INFO: Pod "downwardapi-volume-7bdc1a1e-75ac-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 7.762897ms
May 13 18:25:30.472: INFO: Pod "downwardapi-volume-7bdc1a1e-75ac-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016134467s
May 13 18:25:32.495: INFO: Pod "downwardapi-volume-7bdc1a1e-75ac-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039686818s
STEP: Saw pod success
May 13 18:25:32.495: INFO: Pod "downwardapi-volume-7bdc1a1e-75ac-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:25:32.504: INFO: Trying to get logs from node 10.170.219.140 pod downwardapi-volume-7bdc1a1e-75ac-11e9-a09a-7e4d6cfcc771 container client-container: <nil>
STEP: delete the pod
May 13 18:25:32.547: INFO: Waiting for pod downwardapi-volume-7bdc1a1e-75ac-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:25:32.555: INFO: Pod downwardapi-volume-7bdc1a1e-75ac-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:25:32.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ltv4s" for this suite.
May 13 18:25:38.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:25:38.673: INFO: namespace: e2e-tests-projected-ltv4s, resource: bindings, ignored listing per whitelist
May 13 18:25:38.869: INFO: namespace e2e-tests-projected-ltv4s deletion completed in 6.303887236s

• [SLOW TEST:10.731 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:25:38.871: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-j6c4b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
May 13 18:25:39.265: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:25:42.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-j6c4b" for this suite.
May 13 18:25:48.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:25:48.893: INFO: namespace: e2e-tests-init-container-j6c4b, resource: bindings, ignored listing per whitelist
May 13 18:25:49.157: INFO: namespace e2e-tests-init-container-j6c4b deletion completed in 6.5109714s

• [SLOW TEST:10.286 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:25:49.158: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-chhgg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-chhgg
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-chhgg
STEP: Deleting pre-stop pod
May 13 18:25:59.025: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:25:59.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-chhgg" for this suite.
May 13 18:26:39.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:26:39.338: INFO: namespace: e2e-tests-prestop-chhgg, resource: bindings, ignored listing per whitelist
May 13 18:26:39.472: INFO: namespace e2e-tests-prestop-chhgg deletion completed in 40.419631238s

• [SLOW TEST:50.314 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:26:39.472: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-qkrlj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 18:26:39.866: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a66c561d-75ac-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-downward-api-qkrlj" to be "success or failure"
May 13 18:26:39.875: INFO: Pod "downwardapi-volume-a66c561d-75ac-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 8.966266ms
May 13 18:26:41.884: INFO: Pod "downwardapi-volume-a66c561d-75ac-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018278328s
STEP: Saw pod success
May 13 18:26:41.884: INFO: Pod "downwardapi-volume-a66c561d-75ac-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:26:41.893: INFO: Trying to get logs from node 10.170.219.140 pod downwardapi-volume-a66c561d-75ac-11e9-a09a-7e4d6cfcc771 container client-container: <nil>
STEP: delete the pod
May 13 18:26:41.951: INFO: Waiting for pod downwardapi-volume-a66c561d-75ac-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:26:41.960: INFO: Pod downwardapi-volume-a66c561d-75ac-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:26:41.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qkrlj" for this suite.
May 13 18:26:48.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:26:48.232: INFO: namespace: e2e-tests-downward-api-qkrlj, resource: bindings, ignored listing per whitelist
May 13 18:26:48.419: INFO: namespace e2e-tests-downward-api-qkrlj deletion completed in 6.448849538s

• [SLOW TEST:8.947 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:26:48.421: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-fg5hb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-abba0162-75ac-11e9-a09a-7e4d6cfcc771
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-abba0162-75ac-11e9-a09a-7e4d6cfcc771
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:26:52.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fg5hb" for this suite.
May 13 18:27:14.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:27:15.204: INFO: namespace: e2e-tests-projected-fg5hb, resource: bindings, ignored listing per whitelist
May 13 18:27:15.421: INFO: namespace e2e-tests-projected-fg5hb deletion completed in 22.531290311s

• [SLOW TEST:27.000 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:27:15.422: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-v7kn6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 18:27:15.740: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bbceb5f2-75ac-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-downward-api-v7kn6" to be "success or failure"
May 13 18:27:15.749: INFO: Pod "downwardapi-volume-bbceb5f2-75ac-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 8.254775ms
May 13 18:27:17.757: INFO: Pod "downwardapi-volume-bbceb5f2-75ac-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01685656s
May 13 18:27:19.769: INFO: Pod "downwardapi-volume-bbceb5f2-75ac-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028137644s
STEP: Saw pod success
May 13 18:27:19.769: INFO: Pod "downwardapi-volume-bbceb5f2-75ac-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:27:19.777: INFO: Trying to get logs from node 10.170.219.140 pod downwardapi-volume-bbceb5f2-75ac-11e9-a09a-7e4d6cfcc771 container client-container: <nil>
STEP: delete the pod
May 13 18:27:19.865: INFO: Waiting for pod downwardapi-volume-bbceb5f2-75ac-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:27:19.873: INFO: Pod downwardapi-volume-bbceb5f2-75ac-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:27:19.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-v7kn6" for this suite.
May 13 18:27:25.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:27:26.182: INFO: namespace: e2e-tests-downward-api-v7kn6, resource: bindings, ignored listing per whitelist
May 13 18:27:26.182: INFO: namespace e2e-tests-downward-api-v7kn6 deletion completed in 6.298324184s

• [SLOW TEST:10.760 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:27:26.182: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-s9mfk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 18:27:26.563: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c2419e9a-75ac-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-projected-s9mfk" to be "success or failure"
May 13 18:27:26.571: INFO: Pod "downwardapi-volume-c2419e9a-75ac-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 8.013982ms
May 13 18:27:28.579: INFO: Pod "downwardapi-volume-c2419e9a-75ac-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016459421s
STEP: Saw pod success
May 13 18:27:28.579: INFO: Pod "downwardapi-volume-c2419e9a-75ac-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:27:28.590: INFO: Trying to get logs from node 10.170.219.140 pod downwardapi-volume-c2419e9a-75ac-11e9-a09a-7e4d6cfcc771 container client-container: <nil>
STEP: delete the pod
May 13 18:27:28.641: INFO: Waiting for pod downwardapi-volume-c2419e9a-75ac-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:27:28.649: INFO: Pod downwardapi-volume-c2419e9a-75ac-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:27:28.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-s9mfk" for this suite.
May 13 18:27:34.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:27:34.826: INFO: namespace: e2e-tests-projected-s9mfk, resource: bindings, ignored listing per whitelist
May 13 18:27:35.134: INFO: namespace e2e-tests-projected-s9mfk deletion completed in 6.473684163s

• [SLOW TEST:8.951 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:27:35.134: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-hbxvb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-hbxvb
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-hbxvb to expose endpoints map[]
May 13 18:27:35.475: INFO: Get endpoints failed (14.526461ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
May 13 18:27:36.483: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-hbxvb exposes endpoints map[] (1.022651053s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-hbxvb
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-hbxvb to expose endpoints map[pod1:[80]]
May 13 18:27:38.589: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-hbxvb exposes endpoints map[pod1:[80]] (2.063049256s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-hbxvb
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-hbxvb to expose endpoints map[pod1:[80] pod2:[80]]
May 13 18:27:40.729: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-hbxvb exposes endpoints map[pod1:[80] pod2:[80]] (2.076700618s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-hbxvb
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-hbxvb to expose endpoints map[pod2:[80]]
May 13 18:27:40.768: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-hbxvb exposes endpoints map[pod2:[80]] (15.151139ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-hbxvb
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-hbxvb to expose endpoints map[]
May 13 18:27:40.865: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-hbxvb exposes endpoints map[] (7.920448ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:27:40.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-hbxvb" for this suite.
May 13 18:28:04.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:28:04.984: INFO: namespace: e2e-tests-services-hbxvb, resource: bindings, ignored listing per whitelist
May 13 18:28:05.228: INFO: namespace e2e-tests-services-hbxvb deletion completed in 24.2968486s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:30.094 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:28:05.230: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-c84xk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 13 18:28:05.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-c84xk'
May 13 18:28:05.667: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
May 13 18:28:05.667: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
May 13 18:28:07.708: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-snq5k]
May 13 18:28:07.708: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-snq5k" in namespace "e2e-tests-kubectl-c84xk" to be "running and ready"
May 13 18:28:07.741: INFO: Pod "e2e-test-nginx-rc-snq5k": Phase="Running", Reason="", readiness=true. Elapsed: 33.242976ms
May 13 18:28:07.741: INFO: Pod "e2e-test-nginx-rc-snq5k" satisfied condition "running and ready"
May 13 18:28:07.741: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-snq5k]
May 13 18:28:07.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-c84xk'
May 13 18:28:07.909: INFO: stderr: ""
May 13 18:28:07.909: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
May 13 18:28:07.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-c84xk'
May 13 18:28:08.062: INFO: stderr: ""
May 13 18:28:08.062: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:28:08.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-c84xk" for this suite.
May 13 18:28:32.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:28:32.218: INFO: namespace: e2e-tests-kubectl-c84xk, resource: bindings, ignored listing per whitelist
May 13 18:28:32.369: INFO: namespace e2e-tests-kubectl-c84xk deletion completed in 24.29717244s

• [SLOW TEST:27.140 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:28:32.372: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-5xgff
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0513 18:28:42.763716      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 13 18:28:42.763: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:28:42.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-5xgff" for this suite.
May 13 18:28:48.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:28:49.062: INFO: namespace: e2e-tests-gc-5xgff, resource: bindings, ignored listing per whitelist
May 13 18:28:49.150: INFO: namespace e2e-tests-gc-5xgff deletion completed in 6.305706626s

• [SLOW TEST:16.778 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:28:49.151: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-fq5rp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-fq5rp
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-fq5rp to expose endpoints map[]
May 13 18:28:49.492: INFO: Get endpoints failed (7.569724ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
May 13 18:28:50.501: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-fq5rp exposes endpoints map[] (1.016967661s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-fq5rp
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-fq5rp to expose endpoints map[pod1:[100]]
May 13 18:28:52.572: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-fq5rp exposes endpoints map[pod1:[100]] (2.051863842s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-fq5rp
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-fq5rp to expose endpoints map[pod2:[101] pod1:[100]]
May 13 18:28:54.672: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-fq5rp exposes endpoints map[pod1:[100] pod2:[101]] (2.089303091s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-fq5rp
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-fq5rp to expose endpoints map[pod2:[101]]
May 13 18:28:54.749: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-fq5rp exposes endpoints map[pod2:[101]] (61.39539ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-fq5rp
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-fq5rp to expose endpoints map[]
May 13 18:28:54.771: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-fq5rp exposes endpoints map[] (7.198602ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:28:54.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-fq5rp" for this suite.
May 13 18:29:18.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:29:19.084: INFO: namespace: e2e-tests-services-fq5rp, resource: bindings, ignored listing per whitelist
May 13 18:29:19.135: INFO: namespace e2e-tests-services-fq5rp deletion completed in 24.297435902s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:29.985 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:29:19.136: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-bsmfg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-bsmfg.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-bsmfg.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-bsmfg.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-bsmfg.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-bsmfg.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-bsmfg.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 13 18:29:31.750: INFO: DNS probes using e2e-tests-dns-bsmfg/dns-test-058b0e4b-75ad-11e9-a09a-7e4d6cfcc771 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:29:31.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-bsmfg" for this suite.
May 13 18:29:37.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:29:38.057: INFO: namespace: e2e-tests-dns-bsmfg, resource: bindings, ignored listing per whitelist
May 13 18:29:38.129: INFO: namespace e2e-tests-dns-bsmfg deletion completed in 6.337761554s

• [SLOW TEST:18.993 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:29:38.129: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-lgk85
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
May 13 18:29:41.026: INFO: Successfully updated pod "annotationupdate10dd2a21-75ad-11e9-a09a-7e4d6cfcc771"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:29:43.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lgk85" for this suite.
May 13 18:30:07.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:30:07.476: INFO: namespace: e2e-tests-downward-api-lgk85, resource: bindings, ignored listing per whitelist
May 13 18:30:07.509: INFO: namespace e2e-tests-downward-api-lgk85 deletion completed in 24.423086193s

• [SLOW TEST:29.380 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:30:07.511: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-sbz6f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
May 13 18:30:10.716: INFO: Successfully updated pod "annotationupdate2262746a-75ad-11e9-a09a-7e4d6cfcc771"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:30:14.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sbz6f" for this suite.
May 13 18:30:38.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:30:38.871: INFO: namespace: e2e-tests-projected-sbz6f, resource: bindings, ignored listing per whitelist
May 13 18:30:39.113: INFO: namespace e2e-tests-projected-sbz6f deletion completed in 24.330975097s

• [SLOW TEST:31.602 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:30:39.113: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-hbcjj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
May 13 18:30:39.942: INFO: Waiting up to 5m0s for pod "pod-service-account-35855a5d-75ad-11e9-a09a-7e4d6cfcc771-kgvx2" in namespace "e2e-tests-svcaccounts-hbcjj" to be "success or failure"
May 13 18:30:39.950: INFO: Pod "pod-service-account-35855a5d-75ad-11e9-a09a-7e4d6cfcc771-kgvx2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.706304ms
May 13 18:30:41.959: INFO: Pod "pod-service-account-35855a5d-75ad-11e9-a09a-7e4d6cfcc771-kgvx2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016144898s
May 13 18:30:43.968: INFO: Pod "pod-service-account-35855a5d-75ad-11e9-a09a-7e4d6cfcc771-kgvx2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025402759s
STEP: Saw pod success
May 13 18:30:43.968: INFO: Pod "pod-service-account-35855a5d-75ad-11e9-a09a-7e4d6cfcc771-kgvx2" satisfied condition "success or failure"
May 13 18:30:43.976: INFO: Trying to get logs from node 10.170.219.140 pod pod-service-account-35855a5d-75ad-11e9-a09a-7e4d6cfcc771-kgvx2 container token-test: <nil>
STEP: delete the pod
May 13 18:30:44.022: INFO: Waiting for pod pod-service-account-35855a5d-75ad-11e9-a09a-7e4d6cfcc771-kgvx2 to disappear
May 13 18:30:44.030: INFO: Pod pod-service-account-35855a5d-75ad-11e9-a09a-7e4d6cfcc771-kgvx2 no longer exists
STEP: Creating a pod to test consume service account root CA
May 13 18:30:44.041: INFO: Waiting up to 5m0s for pod "pod-service-account-35855a5d-75ad-11e9-a09a-7e4d6cfcc771-2skxf" in namespace "e2e-tests-svcaccounts-hbcjj" to be "success or failure"
May 13 18:30:44.050: INFO: Pod "pod-service-account-35855a5d-75ad-11e9-a09a-7e4d6cfcc771-2skxf": Phase="Pending", Reason="", readiness=false. Elapsed: 9.085688ms
May 13 18:30:46.059: INFO: Pod "pod-service-account-35855a5d-75ad-11e9-a09a-7e4d6cfcc771-2skxf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018631966s
May 13 18:30:48.074: INFO: Pod "pod-service-account-35855a5d-75ad-11e9-a09a-7e4d6cfcc771-2skxf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032879948s
STEP: Saw pod success
May 13 18:30:48.074: INFO: Pod "pod-service-account-35855a5d-75ad-11e9-a09a-7e4d6cfcc771-2skxf" satisfied condition "success or failure"
May 13 18:30:48.084: INFO: Trying to get logs from node 10.170.219.140 pod pod-service-account-35855a5d-75ad-11e9-a09a-7e4d6cfcc771-2skxf container root-ca-test: <nil>
STEP: delete the pod
May 13 18:30:48.141: INFO: Waiting for pod pod-service-account-35855a5d-75ad-11e9-a09a-7e4d6cfcc771-2skxf to disappear
May 13 18:30:48.149: INFO: Pod pod-service-account-35855a5d-75ad-11e9-a09a-7e4d6cfcc771-2skxf no longer exists
STEP: Creating a pod to test consume service account namespace
May 13 18:30:48.161: INFO: Waiting up to 5m0s for pod "pod-service-account-35855a5d-75ad-11e9-a09a-7e4d6cfcc771-slpkn" in namespace "e2e-tests-svcaccounts-hbcjj" to be "success or failure"
May 13 18:30:48.170: INFO: Pod "pod-service-account-35855a5d-75ad-11e9-a09a-7e4d6cfcc771-slpkn": Phase="Pending", Reason="", readiness=false. Elapsed: 8.952299ms
May 13 18:30:50.193: INFO: Pod "pod-service-account-35855a5d-75ad-11e9-a09a-7e4d6cfcc771-slpkn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031676318s
May 13 18:30:52.202: INFO: Pod "pod-service-account-35855a5d-75ad-11e9-a09a-7e4d6cfcc771-slpkn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040456371s
STEP: Saw pod success
May 13 18:30:52.202: INFO: Pod "pod-service-account-35855a5d-75ad-11e9-a09a-7e4d6cfcc771-slpkn" satisfied condition "success or failure"
May 13 18:30:52.211: INFO: Trying to get logs from node 10.170.219.140 pod pod-service-account-35855a5d-75ad-11e9-a09a-7e4d6cfcc771-slpkn container namespace-test: <nil>
STEP: delete the pod
May 13 18:30:52.255: INFO: Waiting for pod pod-service-account-35855a5d-75ad-11e9-a09a-7e4d6cfcc771-slpkn to disappear
May 13 18:30:52.264: INFO: Pod pod-service-account-35855a5d-75ad-11e9-a09a-7e4d6cfcc771-slpkn no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:30:52.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-hbcjj" for this suite.
May 13 18:31:00.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:31:00.345: INFO: namespace: e2e-tests-svcaccounts-hbcjj, resource: bindings, ignored listing per whitelist
May 13 18:31:00.608: INFO: namespace e2e-tests-svcaccounts-hbcjj deletion completed in 8.328519012s

• [SLOW TEST:21.495 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:31:00.608: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-69d54
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 13 18:31:00.938: INFO: Waiting up to 5m0s for pod "downward-api-4208cddd-75ad-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-downward-api-69d54" to be "success or failure"
May 13 18:31:00.946: INFO: Pod "downward-api-4208cddd-75ad-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 8.126238ms
May 13 18:31:02.962: INFO: Pod "downward-api-4208cddd-75ad-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02392727s
STEP: Saw pod success
May 13 18:31:02.962: INFO: Pod "downward-api-4208cddd-75ad-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:31:02.970: INFO: Trying to get logs from node 10.170.219.140 pod downward-api-4208cddd-75ad-11e9-a09a-7e4d6cfcc771 container dapi-container: <nil>
STEP: delete the pod
May 13 18:31:03.014: INFO: Waiting for pod downward-api-4208cddd-75ad-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:31:03.022: INFO: Pod downward-api-4208cddd-75ad-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:31:03.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-69d54" for this suite.
May 13 18:31:09.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:31:09.138: INFO: namespace: e2e-tests-downward-api-69d54, resource: bindings, ignored listing per whitelist
May 13 18:31:09.342: INFO: namespace e2e-tests-downward-api-69d54 deletion completed in 6.309069559s

• [SLOW TEST:8.734 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:31:09.343: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-g5hcl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:31:09.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-g5hcl" for this suite.
May 13 18:31:31.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:31:32.013: INFO: namespace: e2e-tests-pods-g5hcl, resource: bindings, ignored listing per whitelist
May 13 18:31:32.066: INFO: namespace e2e-tests-pods-g5hcl deletion completed in 22.405122113s

• [SLOW TEST:22.724 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:31:32.066: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-nv8tn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
May 13 18:31:32.513: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-nv8tn,SelfLink:/api/v1/namespaces/e2e-tests-watch-nv8tn/configmaps/e2e-watch-test-resource-version,UID:54d424c4-75ad-11e9-906d-b2bf80cbe475,ResourceVersion:30918,Generation:0,CreationTimestamp:2019-05-13 18:31:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 13 18:31:32.513: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-nv8tn,SelfLink:/api/v1/namespaces/e2e-tests-watch-nv8tn/configmaps/e2e-watch-test-resource-version,UID:54d424c4-75ad-11e9-906d-b2bf80cbe475,ResourceVersion:30919,Generation:0,CreationTimestamp:2019-05-13 18:31:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:31:32.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-nv8tn" for this suite.
May 13 18:31:38.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:31:38.570: INFO: namespace: e2e-tests-watch-nv8tn, resource: bindings, ignored listing per whitelist
May 13 18:31:38.860: INFO: namespace e2e-tests-watch-nv8tn deletion completed in 6.336316198s

• [SLOW TEST:6.794 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:31:38.866: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-z78xz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 18:31:39.184: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
May 13 18:31:39.219: INFO: Number of nodes with available pods: 0
May 13 18:31:39.219: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:31:40.237: INFO: Number of nodes with available pods: 0
May 13 18:31:40.237: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:31:41.247: INFO: Number of nodes with available pods: 3
May 13 18:31:41.247: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
May 13 18:31:41.303: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:41.303: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:41.303: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:42.320: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:42.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:42.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:43.320: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:43.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:43.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:44.320: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:44.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:44.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:45.341: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:45.341: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:45.341: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:46.320: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:46.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:46.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:47.320: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:47.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:47.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:48.322: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:48.322: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:48.322: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:49.320: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:49.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:49.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:50.320: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:50.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:50.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:51.320: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:51.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:51.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:52.324: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:52.324: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:52.324: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:53.320: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:53.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:53.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:54.321: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:54.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:54.321: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:55.320: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:55.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:55.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:56.333: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:56.334: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:56.334: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:57.322: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:57.322: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:57.322: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:58.344: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:58.344: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:58.344: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:59.323: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:59.323: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:31:59.323: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:00.320: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:00.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:00.321: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:01.320: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:01.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:01.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:02.321: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:02.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:02.321: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:03.321: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:03.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:03.321: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:04.323: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:04.323: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:04.323: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:05.320: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:05.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:05.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:06.321: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:06.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:06.321: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:07.337: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:07.337: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:07.337: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:08.321: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:08.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:08.321: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:09.322: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:09.322: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:09.322: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:10.320: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:10.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:10.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:11.322: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:11.322: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:11.322: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:12.320: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:12.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:12.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:13.320: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:13.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:13.321: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:14.321: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:14.321: INFO: Pod daemon-set-ct5lq is not available
May 13 18:32:14.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:14.321: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:15.320: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:15.321: INFO: Pod daemon-set-ct5lq is not available
May 13 18:32:15.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:15.321: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:16.320: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:16.320: INFO: Pod daemon-set-ct5lq is not available
May 13 18:32:16.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:16.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:17.321: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:17.321: INFO: Pod daemon-set-ct5lq is not available
May 13 18:32:17.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:17.321: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:18.335: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:18.335: INFO: Pod daemon-set-ct5lq is not available
May 13 18:32:18.335: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:18.335: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:19.321: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:19.321: INFO: Pod daemon-set-ct5lq is not available
May 13 18:32:19.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:19.321: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:20.324: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:20.324: INFO: Pod daemon-set-ct5lq is not available
May 13 18:32:20.324: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:20.324: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:21.321: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:21.321: INFO: Pod daemon-set-ct5lq is not available
May 13 18:32:21.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:21.321: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:22.320: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:22.320: INFO: Pod daemon-set-ct5lq is not available
May 13 18:32:22.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:22.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:23.322: INFO: Wrong image for pod: daemon-set-ct5lq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:23.322: INFO: Pod daemon-set-ct5lq is not available
May 13 18:32:23.322: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:23.322: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:24.320: INFO: Pod daemon-set-bwbfx is not available
May 13 18:32:24.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:24.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:25.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:25.322: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:26.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:26.321: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:27.349: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:27.350: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:28.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:28.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:29.336: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:29.336: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:30.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:30.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:31.341: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:31.341: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:32.630: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:32.630: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:33.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:33.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:34.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:34.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:35.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:35.321: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:36.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:36.321: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:37.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:37.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:38.322: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:38.322: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:39.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:39.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:40.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:40.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:41.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:41.321: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:42.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:42.321: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:43.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:43.321: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:44.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:44.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:45.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:45.321: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:46.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:46.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:47.322: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:47.322: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:48.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:48.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:49.322: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:49.322: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:50.333: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:50.333: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:51.341: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:51.341: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:52.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:52.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:53.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:53.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:54.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:54.322: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:55.349: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:55.349: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:56.323: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:56.324: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:56.324: INFO: Pod daemon-set-jwtg9 is not available
May 13 18:32:57.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:57.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:57.320: INFO: Pod daemon-set-jwtg9 is not available
May 13 18:32:58.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:58.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:58.320: INFO: Pod daemon-set-jwtg9 is not available
May 13 18:32:59.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:59.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:32:59.320: INFO: Pod daemon-set-jwtg9 is not available
May 13 18:33:00.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:00.320: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:00.320: INFO: Pod daemon-set-jwtg9 is not available
May 13 18:33:01.334: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:01.334: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:01.334: INFO: Pod daemon-set-jwtg9 is not available
May 13 18:33:02.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:02.321: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:02.321: INFO: Pod daemon-set-jwtg9 is not available
May 13 18:33:03.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:03.321: INFO: Wrong image for pod: daemon-set-jwtg9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:03.321: INFO: Pod daemon-set-jwtg9 is not available
May 13 18:33:04.324: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:04.324: INFO: Pod daemon-set-v2mvp is not available
May 13 18:33:05.319: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:06.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:07.324: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:08.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:09.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:10.354: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:11.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:12.337: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:13.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:14.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:15.322: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:16.324: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:17.322: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:18.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:19.324: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:20.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:21.327: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:22.323: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:23.337: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:24.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:25.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:26.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:27.341: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:28.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:29.341: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:30.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:31.341: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:32.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:33.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:34.336: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:35.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:36.322: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:36.322: INFO: Pod daemon-set-grz8l is not available
May 13 18:33:37.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:37.320: INFO: Pod daemon-set-grz8l is not available
May 13 18:33:38.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:38.320: INFO: Pod daemon-set-grz8l is not available
May 13 18:33:39.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:39.321: INFO: Pod daemon-set-grz8l is not available
May 13 18:33:40.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:40.321: INFO: Pod daemon-set-grz8l is not available
May 13 18:33:41.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:41.320: INFO: Pod daemon-set-grz8l is not available
May 13 18:33:42.320: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:42.320: INFO: Pod daemon-set-grz8l is not available
May 13 18:33:43.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:43.321: INFO: Pod daemon-set-grz8l is not available
May 13 18:33:44.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:44.321: INFO: Pod daemon-set-grz8l is not available
May 13 18:33:45.337: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:45.337: INFO: Pod daemon-set-grz8l is not available
May 13 18:33:46.321: INFO: Wrong image for pod: daemon-set-grz8l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:33:46.321: INFO: Pod daemon-set-grz8l is not available
May 13 18:33:47.350: INFO: Pod daemon-set-6pm27 is not available
STEP: Check that daemon pods are still running on every node of the cluster.
May 13 18:33:47.379: INFO: Number of nodes with available pods: 2
May 13 18:33:47.379: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:33:48.400: INFO: Number of nodes with available pods: 2
May 13 18:33:48.400: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:33:49.399: INFO: Number of nodes with available pods: 3
May 13 18:33:49.399: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-z78xz, will wait for the garbage collector to delete the pods
May 13 18:33:49.522: INFO: Deleting {extensions DaemonSet} daemon-set took: 16.534471ms
May 13 18:33:49.622: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.275988ms
May 13 18:33:57.164: INFO: Number of nodes with available pods: 0
May 13 18:33:57.164: INFO: Number of running nodes: 0, number of available pods: 0
May 13 18:33:57.172: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-z78xz/daemonsets","resourceVersion":"31311"},"items":null}

May 13 18:33:57.180: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-z78xz/pods","resourceVersion":"31311"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:33:57.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-z78xz" for this suite.
May 13 18:34:05.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:34:05.507: INFO: namespace: e2e-tests-daemonsets-z78xz, resource: bindings, ignored listing per whitelist
May 13 18:34:05.625: INFO: namespace e2e-tests-daemonsets-z78xz deletion completed in 8.39877481s

• [SLOW TEST:146.760 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:34:05.626: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-xb2sm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 18:34:05.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 version --client'
May 13 18:34:06.018: INFO: stderr: ""
May 13 18:34:06.018: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
May 13 18:34:06.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 create -f - --namespace=e2e-tests-kubectl-xb2sm'
May 13 18:34:06.336: INFO: stderr: ""
May 13 18:34:06.336: INFO: stdout: "replicationcontroller/redis-master created\n"
May 13 18:34:06.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 create -f - --namespace=e2e-tests-kubectl-xb2sm'
May 13 18:34:06.636: INFO: stderr: ""
May 13 18:34:06.636: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
May 13 18:34:07.660: INFO: Selector matched 1 pods for map[app:redis]
May 13 18:34:07.660: INFO: Found 0 / 1
May 13 18:34:08.645: INFO: Selector matched 1 pods for map[app:redis]
May 13 18:34:08.645: INFO: Found 1 / 1
May 13 18:34:08.645: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 13 18:34:08.655: INFO: Selector matched 1 pods for map[app:redis]
May 13 18:34:08.655: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 13 18:34:08.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 describe pod redis-master-s662g --namespace=e2e-tests-kubectl-xb2sm'
May 13 18:34:08.930: INFO: stderr: ""
May 13 18:34:08.930: INFO: stdout: "Name:               redis-master-s662g\nNamespace:          e2e-tests-kubectl-xb2sm\nPriority:           0\nPriorityClassName:  <none>\nNode:               10.170.219.140/10.170.219.140\nStart Time:         Mon, 13 May 2019 18:34:06 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        kubernetes.io/psp: e2e-test-privileged-psp\nStatus:             Running\nIP:                 172.30.208.53\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://109d10b26ed1c443c80cdeb775cd5bdfbdf4f6a22773e63c59b13e096dd71391\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 13 May 2019 18:34:07 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-w9djq (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-w9djq:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-w9djq\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                     Message\n  ----    ------     ----  ----                     -------\n  Normal  Scheduled  2s    default-scheduler        Successfully assigned e2e-tests-kubectl-xb2sm/redis-master-s662g to 10.170.219.140\n  Normal  Pulled     1s    kubelet, 10.170.219.140  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, 10.170.219.140  Created container\n  Normal  Started    1s    kubelet, 10.170.219.140  Started container\n"
May 13 18:34:08.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 describe rc redis-master --namespace=e2e-tests-kubectl-xb2sm'
May 13 18:34:09.091: INFO: stderr: ""
May 13 18:34:09.091: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-xb2sm\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-s662g\n"
May 13 18:34:09.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 describe service redis-master --namespace=e2e-tests-kubectl-xb2sm'
May 13 18:34:09.236: INFO: stderr: ""
May 13 18:34:09.236: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-xb2sm\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.21.6.118\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.30.208.53:6379\nSession Affinity:  None\nEvents:            <none>\n"
May 13 18:34:09.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 describe node 10.170.219.140'
May 13 18:34:09.415: INFO: stderr: ""
May 13 18:34:09.415: INFO: stdout: "Name:               10.170.219.140\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-east\n                    failure-domain.beta.kubernetes.io/zone=wdc04\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/machine-type=b3c.4x16.encrypted\n                    ibm-cloud.kubernetes.io/os=UBUNTU_18_64\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-pool-id=e5e67d863b8a419ba7a75a47352a70a9-537e631\n                    ibm-cloud.kubernetes.io/worker-version=1.12.8_1552\n                    kubernetes.io/hostname=10.170.219.140\n                    privateVLAN=2615309\n                    publicVLAN=2615307\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 13 May 2019 16:26:20 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Mon, 13 May 2019 18:34:00 +0000   Mon, 13 May 2019 16:26:20 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Mon, 13 May 2019 18:34:00 +0000   Mon, 13 May 2019 16:26:20 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 13 May 2019 18:34:00 +0000   Mon, 13 May 2019 16:26:20 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 13 May 2019 18:34:00 +0000   Mon, 13 May 2019 16:26:20 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 13 May 2019 18:34:00 +0000   Mon, 13 May 2019 16:26:50 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.170.219.140\n  ExternalIP:  169.45.211.114\n  Hostname:    10.170.219.140\nCapacity:\n cpu:                4\n ephemeral-storage:  102685624Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16419936Ki\n pods:               110\nAllocatable:\n cpu:                3910m\n ephemeral-storage:  99892574949\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             13627488Ki\n pods:               110\nSystem Info:\n Machine ID:                 59d7838e0d83496682ef40885e2ece63\n System UUID:                4D684804-CD4E-98C1-8D61-D604AF323A23\n Boot ID:                    f0f56cf9-248d-4fea-9054-e83cf6f7579e\n Kernel Version:             4.15.0-47-generic\n OS Image:                   Ubuntu 18.04.2 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.1.7\n Kubelet Version:            v1.12.8+IKS\n Kube-Proxy Version:         v1.12.8+IKS\nProviderID:                  ibm://d18c889395112a40d2f4e3065f237a7d///e5e67d863b8a419ba7a75a47352a70a9/kube-wdc04-cre5e67d863b8a419ba7a75a47352a70a9-w2\nNon-terminated Pods:         (8 in total)\n  Namespace                  Name                                                              CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                              ------------  ----------  ---------------  -------------\n  e2e-tests-kubectl-xb2sm    redis-master-s662g                                                0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-5d6538ccab344242-8b4m8           0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  ibm-system                 ibm-cloud-provider-ip-169-45-233-124-7fbd585f77-sv6vv             5m (0%)       0 (0%)      10Mi (0%)        0 (0%)\n  kube-system                calico-node-nlxmm                                                 255m (6%)     0 (0%)      85Mi (0%)        0 (0%)\n  kube-system                ibm-keepalived-watcher-s9p9f                                      5m (0%)       0 (0%)      10Mi (0%)        0 (0%)\n  kube-system                ibm-kube-fluentd-kswb8                                            25m (0%)      300m (7%)   150Mi (1%)       1600M (11%)\n  kube-system                ibm-master-proxy-static-10.170.219.140                            25m (0%)      300m (7%)   32M (0%)         512M (3%)\n  kube-system                public-cre5e67d863b8a419ba7a75a47352a70a9-alb1-785767687-drrgh    0 (0%)        0 (0%)      0 (0%)           0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource  Requests       Limits\n  --------  --------       ------\n  cpu       315m (8%)      600m (15%)\n  memory    292370Ki (2%)  2112M (15%)\nEvents:     <none>\n"
May 13 18:34:09.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 describe namespace e2e-tests-kubectl-xb2sm'
May 13 18:34:09.580: INFO: stderr: ""
May 13 18:34:09.580: INFO: stdout: "Name:         e2e-tests-kubectl-xb2sm\nLabels:       e2e-framework=kubectl\n              e2e-run=2cddd349-75ac-11e9-a09a-7e4d6cfcc771\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:34:09.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xb2sm" for this suite.
May 13 18:34:33.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:34:33.789: INFO: namespace: e2e-tests-kubectl-xb2sm, resource: bindings, ignored listing per whitelist
May 13 18:34:33.898: INFO: namespace e2e-tests-kubectl-xb2sm deletion completed in 24.303897448s

• [SLOW TEST:28.272 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:34:33.898: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-lz82q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 18:34:34.210: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c127c737-75ad-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-downward-api-lz82q" to be "success or failure"
May 13 18:34:34.220: INFO: Pod "downwardapi-volume-c127c737-75ad-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 9.635609ms
May 13 18:34:36.228: INFO: Pod "downwardapi-volume-c127c737-75ad-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017695409s
STEP: Saw pod success
May 13 18:34:36.228: INFO: Pod "downwardapi-volume-c127c737-75ad-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:34:36.249: INFO: Trying to get logs from node 10.170.219.140 pod downwardapi-volume-c127c737-75ad-11e9-a09a-7e4d6cfcc771 container client-container: <nil>
STEP: delete the pod
May 13 18:34:36.292: INFO: Waiting for pod downwardapi-volume-c127c737-75ad-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:34:36.301: INFO: Pod downwardapi-volume-c127c737-75ad-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:34:36.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lz82q" for this suite.
May 13 18:34:42.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:34:42.453: INFO: namespace: e2e-tests-downward-api-lz82q, resource: bindings, ignored listing per whitelist
May 13 18:34:42.783: INFO: namespace e2e-tests-downward-api-lz82q deletion completed in 6.470722389s

• [SLOW TEST:8.885 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:34:42.784: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-zw5qk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-c6728567-75ad-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume secrets
May 13 18:34:43.096: INFO: Waiting up to 5m0s for pod "pod-secrets-c673f359-75ad-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-secrets-zw5qk" to be "success or failure"
May 13 18:34:43.104: INFO: Pod "pod-secrets-c673f359-75ad-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 8.354059ms
May 13 18:34:45.112: INFO: Pod "pod-secrets-c673f359-75ad-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016461971s
STEP: Saw pod success
May 13 18:34:45.112: INFO: Pod "pod-secrets-c673f359-75ad-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:34:45.120: INFO: Trying to get logs from node 10.170.219.140 pod pod-secrets-c673f359-75ad-11e9-a09a-7e4d6cfcc771 container secret-volume-test: <nil>
STEP: delete the pod
May 13 18:34:45.170: INFO: Waiting for pod pod-secrets-c673f359-75ad-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:34:45.178: INFO: Pod pod-secrets-c673f359-75ad-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:34:45.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-zw5qk" for this suite.
May 13 18:34:51.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:34:51.479: INFO: namespace: e2e-tests-secrets-zw5qk, resource: bindings, ignored listing per whitelist
May 13 18:34:51.512: INFO: namespace e2e-tests-secrets-zw5qk deletion completed in 6.324060064s

• [SLOW TEST:8.728 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:34:51.512: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-8kkzn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-8kkzn/configmap-test-cbac39da-75ad-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume configMaps
May 13 18:34:51.867: INFO: Waiting up to 5m0s for pod "pod-configmaps-cbade709-75ad-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-configmap-8kkzn" to be "success or failure"
May 13 18:34:51.879: INFO: Pod "pod-configmaps-cbade709-75ad-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 11.516991ms
May 13 18:34:53.903: INFO: Pod "pod-configmaps-cbade709-75ad-11e9-a09a-7e4d6cfcc771": Phase="Running", Reason="", readiness=true. Elapsed: 2.035226222s
May 13 18:34:55.912: INFO: Pod "pod-configmaps-cbade709-75ad-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044158756s
STEP: Saw pod success
May 13 18:34:55.912: INFO: Pod "pod-configmaps-cbade709-75ad-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:34:55.949: INFO: Trying to get logs from node 10.170.219.140 pod pod-configmaps-cbade709-75ad-11e9-a09a-7e4d6cfcc771 container env-test: <nil>
STEP: delete the pod
May 13 18:34:55.996: INFO: Waiting for pod pod-configmaps-cbade709-75ad-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:34:56.004: INFO: Pod pod-configmaps-cbade709-75ad-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:34:56.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8kkzn" for this suite.
May 13 18:35:02.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:35:02.367: INFO: namespace: e2e-tests-configmap-8kkzn, resource: bindings, ignored listing per whitelist
May 13 18:35:02.417: INFO: namespace e2e-tests-configmap-8kkzn deletion completed in 6.403257758s

• [SLOW TEST:10.905 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:35:02.418: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-bchck
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
May 13 18:35:08.805: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-bchck PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 18:35:08.805: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
May 13 18:35:09.128: INFO: Exec stderr: ""
May 13 18:35:09.128: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-bchck PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 18:35:09.128: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
May 13 18:35:09.320: INFO: Exec stderr: ""
May 13 18:35:09.320: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-bchck PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 18:35:09.320: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
May 13 18:35:09.939: INFO: Exec stderr: ""
May 13 18:35:09.939: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-bchck PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 18:35:09.939: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
May 13 18:35:10.129: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
May 13 18:35:10.129: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-bchck PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 18:35:10.129: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
May 13 18:35:10.322: INFO: Exec stderr: ""
May 13 18:35:10.322: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-bchck PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 18:35:10.322: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
May 13 18:35:10.517: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
May 13 18:35:10.518: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-bchck PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 18:35:10.518: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
May 13 18:35:10.701: INFO: Exec stderr: ""
May 13 18:35:10.701: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-bchck PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 18:35:10.701: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
May 13 18:35:10.902: INFO: Exec stderr: ""
May 13 18:35:10.902: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-bchck PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 18:35:10.902: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
May 13 18:35:11.066: INFO: Exec stderr: ""
May 13 18:35:11.066: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-bchck PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 18:35:11.066: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
May 13 18:35:11.268: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:35:11.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-bchck" for this suite.
May 13 18:36:01.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:36:01.883: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-bchck, resource: bindings, ignored listing per whitelist
May 13 18:36:02.107: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-bchck deletion completed in 50.828815277s

• [SLOW TEST:59.689 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:36:02.107: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-sfrmb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-f5bd0ffc-75ad-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume secrets
May 13 18:36:02.442: INFO: Waiting up to 5m0s for pod "pod-secrets-f5be9b91-75ad-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-secrets-sfrmb" to be "success or failure"
May 13 18:36:02.453: INFO: Pod "pod-secrets-f5be9b91-75ad-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 10.173569ms
May 13 18:36:04.463: INFO: Pod "pod-secrets-f5be9b91-75ad-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020246687s
STEP: Saw pod success
May 13 18:36:04.463: INFO: Pod "pod-secrets-f5be9b91-75ad-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:36:04.549: INFO: Trying to get logs from node 10.170.219.140 pod pod-secrets-f5be9b91-75ad-11e9-a09a-7e4d6cfcc771 container secret-volume-test: <nil>
STEP: delete the pod
May 13 18:36:04.606: INFO: Waiting for pod pod-secrets-f5be9b91-75ad-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:36:04.613: INFO: Pod pod-secrets-f5be9b91-75ad-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:36:04.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-sfrmb" for this suite.
May 13 18:36:10.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:36:10.881: INFO: namespace: e2e-tests-secrets-sfrmb, resource: bindings, ignored listing per whitelist
May 13 18:36:10.928: INFO: namespace e2e-tests-secrets-sfrmb deletion completed in 6.303347639s

• [SLOW TEST:8.821 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:36:10.929: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-pggf5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-fafbb204-75ad-11e9-a09a-7e4d6cfcc771
STEP: Creating secret with name secret-projected-all-test-volume-fafbb1e8-75ad-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test Check all projections for projected volume plugin
May 13 18:36:11.249: INFO: Waiting up to 5m0s for pod "projected-volume-fafbb1b0-75ad-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-projected-pggf5" to be "success or failure"
May 13 18:36:11.258: INFO: Pod "projected-volume-fafbb1b0-75ad-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 8.668604ms
May 13 18:36:13.311: INFO: Pod "projected-volume-fafbb1b0-75ad-11e9-a09a-7e4d6cfcc771": Phase="Running", Reason="", readiness=true. Elapsed: 2.062186614s
May 13 18:36:15.320: INFO: Pod "projected-volume-fafbb1b0-75ad-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.071140529s
STEP: Saw pod success
May 13 18:36:15.320: INFO: Pod "projected-volume-fafbb1b0-75ad-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:36:15.329: INFO: Trying to get logs from node 10.170.219.140 pod projected-volume-fafbb1b0-75ad-11e9-a09a-7e4d6cfcc771 container projected-all-volume-test: <nil>
STEP: delete the pod
May 13 18:36:15.373: INFO: Waiting for pod projected-volume-fafbb1b0-75ad-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:36:15.449: INFO: Pod projected-volume-fafbb1b0-75ad-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:36:15.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pggf5" for this suite.
May 13 18:36:21.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:36:21.599: INFO: namespace: e2e-tests-projected-pggf5, resource: bindings, ignored listing per whitelist
May 13 18:36:21.805: INFO: namespace e2e-tests-projected-pggf5 deletion completed in 6.344749877s

• [SLOW TEST:10.877 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:36:21.806: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-zdw9x
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-01859076-75ae-11e9-a09a-7e4d6cfcc771
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-01859076-75ae-11e9-a09a-7e4d6cfcc771
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:37:31.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-zdw9x" for this suite.
May 13 18:37:53.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:37:53.395: INFO: namespace: e2e-tests-configmap-zdw9x, resource: bindings, ignored listing per whitelist
May 13 18:37:53.485: INFO: namespace e2e-tests-configmap-zdw9x deletion completed in 22.389363154s

• [SLOW TEST:91.680 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:37:53.486: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-qq78j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-qq78j
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-qq78j
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-qq78j
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-qq78j
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-qq78j
May 13 18:37:57.941: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-qq78j, name: ss-0, uid: 3a510f7c-75ae-11e9-a685-3eb3c297d0da, status phase: Pending. Waiting for statefulset controller to delete.
May 13 18:37:58.044: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-qq78j, name: ss-0, uid: 3a510f7c-75ae-11e9-a685-3eb3c297d0da, status phase: Failed. Waiting for statefulset controller to delete.
May 13 18:37:58.054: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-qq78j, name: ss-0, uid: 3a510f7c-75ae-11e9-a685-3eb3c297d0da, status phase: Failed. Waiting for statefulset controller to delete.
May 13 18:37:58.062: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-qq78j
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-qq78j
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-qq78j and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 13 18:38:02.149: INFO: Deleting all statefulset in ns e2e-tests-statefulset-qq78j
May 13 18:38:02.158: INFO: Scaling statefulset ss to 0
May 13 18:38:12.215: INFO: Waiting for statefulset status.replicas updated to 0
May 13 18:38:12.403: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:38:12.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-qq78j" for this suite.
May 13 18:38:18.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:38:18.590: INFO: namespace: e2e-tests-statefulset-qq78j, resource: bindings, ignored listing per whitelist
May 13 18:38:18.809: INFO: namespace e2e-tests-statefulset-qq78j deletion completed in 6.35876945s

• [SLOW TEST:25.323 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:38:18.809: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-mw4gq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
May 13 18:38:19.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 create -f - --namespace=e2e-tests-kubectl-mw4gq'
May 13 18:38:19.414: INFO: stderr: ""
May 13 18:38:19.414: INFO: stdout: "pod/pause created\n"
May 13 18:38:19.414: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
May 13 18:38:19.414: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-mw4gq" to be "running and ready"
May 13 18:38:19.426: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 12.153098ms
May 13 18:38:21.435: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.021015171s
May 13 18:38:21.435: INFO: Pod "pause" satisfied condition "running and ready"
May 13 18:38:21.435: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
May 13 18:38:21.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-mw4gq'
May 13 18:38:21.584: INFO: stderr: ""
May 13 18:38:21.584: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
May 13 18:38:21.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pod pause -L testing-label --namespace=e2e-tests-kubectl-mw4gq'
May 13 18:38:21.717: INFO: stderr: ""
May 13 18:38:21.717: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
May 13 18:38:21.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 label pods pause testing-label- --namespace=e2e-tests-kubectl-mw4gq'
May 13 18:38:21.840: INFO: stderr: ""
May 13 18:38:21.840: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
May 13 18:38:21.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pod pause -L testing-label --namespace=e2e-tests-kubectl-mw4gq'
May 13 18:38:21.984: INFO: stderr: ""
May 13 18:38:21.984: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
May 13 18:38:21.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-mw4gq'
May 13 18:38:22.126: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 13 18:38:22.126: INFO: stdout: "pod \"pause\" force deleted\n"
May 13 18:38:22.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-mw4gq'
May 13 18:38:22.273: INFO: stderr: "No resources found.\n"
May 13 18:38:22.273: INFO: stdout: ""
May 13 18:38:22.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods -l name=pause --namespace=e2e-tests-kubectl-mw4gq -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 13 18:38:22.410: INFO: stderr: ""
May 13 18:38:22.410: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:38:22.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mw4gq" for this suite.
May 13 18:38:28.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:38:28.567: INFO: namespace: e2e-tests-kubectl-mw4gq, resource: bindings, ignored listing per whitelist
May 13 18:38:28.941: INFO: namespace e2e-tests-kubectl-mw4gq deletion completed in 6.520379828s

• [SLOW TEST:10.132 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:38:28.942: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-k62s7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0513 18:38:59.865105      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 13 18:38:59.865: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:38:59.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-k62s7" for this suite.
May 13 18:39:05.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:39:06.111: INFO: namespace: e2e-tests-gc-k62s7, resource: bindings, ignored listing per whitelist
May 13 18:39:06.296: INFO: namespace e2e-tests-gc-k62s7 deletion completed in 6.346715052s

• [SLOW TEST:37.354 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:39:06.296: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-p2fb7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-p2fb7/configmap-test-6385b700-75ae-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume configMaps
May 13 18:39:06.625: INFO: Waiting up to 5m0s for pod "pod-configmaps-63875b67-75ae-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-configmap-p2fb7" to be "success or failure"
May 13 18:39:06.633: INFO: Pod "pod-configmaps-63875b67-75ae-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 7.62781ms
May 13 18:39:08.642: INFO: Pod "pod-configmaps-63875b67-75ae-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016398338s
May 13 18:39:10.664: INFO: Pod "pod-configmaps-63875b67-75ae-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038156199s
STEP: Saw pod success
May 13 18:39:10.664: INFO: Pod "pod-configmaps-63875b67-75ae-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:39:10.672: INFO: Trying to get logs from node 10.170.219.140 pod pod-configmaps-63875b67-75ae-11e9-a09a-7e4d6cfcc771 container env-test: <nil>
STEP: delete the pod
May 13 18:39:10.722: INFO: Waiting for pod pod-configmaps-63875b67-75ae-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:39:10.729: INFO: Pod pod-configmaps-63875b67-75ae-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:39:10.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-p2fb7" for this suite.
May 13 18:39:16.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:39:17.132: INFO: namespace: e2e-tests-configmap-p2fb7, resource: bindings, ignored listing per whitelist
May 13 18:39:17.198: INFO: namespace e2e-tests-configmap-p2fb7 deletion completed in 6.457652577s

• [SLOW TEST:10.902 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:39:17.199: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-8c8n7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-6a0529cb-75ae-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume secrets
May 13 18:39:17.525: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6a0699c0-75ae-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-projected-8c8n7" to be "success or failure"
May 13 18:39:17.533: INFO: Pod "pod-projected-secrets-6a0699c0-75ae-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 7.258621ms
May 13 18:39:19.541: INFO: Pod "pod-projected-secrets-6a0699c0-75ae-11e9-a09a-7e4d6cfcc771": Phase="Running", Reason="", readiness=true. Elapsed: 2.015690766s
May 13 18:39:21.562: INFO: Pod "pod-projected-secrets-6a0699c0-75ae-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036950627s
STEP: Saw pod success
May 13 18:39:21.562: INFO: Pod "pod-projected-secrets-6a0699c0-75ae-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:39:21.571: INFO: Trying to get logs from node 10.170.219.140 pod pod-projected-secrets-6a0699c0-75ae-11e9-a09a-7e4d6cfcc771 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 13 18:39:21.666: INFO: Waiting for pod pod-projected-secrets-6a0699c0-75ae-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:39:21.674: INFO: Pod pod-projected-secrets-6a0699c0-75ae-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:39:21.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8c8n7" for this suite.
May 13 18:39:27.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:39:28.001: INFO: namespace: e2e-tests-projected-8c8n7, resource: bindings, ignored listing per whitelist
May 13 18:39:28.069: INFO: namespace e2e-tests-projected-8c8n7 deletion completed in 6.38426678s

• [SLOW TEST:10.870 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:39:28.069: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7k6lr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 18:39:28.764: INFO: Waiting up to 5m0s for pod "downwardapi-volume-70b901e1-75ae-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-projected-7k6lr" to be "success or failure"
May 13 18:39:28.772: INFO: Pod "downwardapi-volume-70b901e1-75ae-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 8.675594ms
May 13 18:39:30.782: INFO: Pod "downwardapi-volume-70b901e1-75ae-11e9-a09a-7e4d6cfcc771": Phase="Running", Reason="", readiness=true. Elapsed: 2.017735095s
May 13 18:39:32.814: INFO: Pod "downwardapi-volume-70b901e1-75ae-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050268052s
STEP: Saw pod success
May 13 18:39:32.814: INFO: Pod "downwardapi-volume-70b901e1-75ae-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:39:32.823: INFO: Trying to get logs from node 10.170.219.140 pod downwardapi-volume-70b901e1-75ae-11e9-a09a-7e4d6cfcc771 container client-container: <nil>
STEP: delete the pod
May 13 18:39:32.967: INFO: Waiting for pod downwardapi-volume-70b901e1-75ae-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:39:32.974: INFO: Pod downwardapi-volume-70b901e1-75ae-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:39:32.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7k6lr" for this suite.
May 13 18:39:39.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:39:39.058: INFO: namespace: e2e-tests-projected-7k6lr, resource: bindings, ignored listing per whitelist
May 13 18:39:39.794: INFO: namespace e2e-tests-projected-7k6lr deletion completed in 6.807799492s

• [SLOW TEST:11.725 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:39:39.794: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-tvlsx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-777d5c32-75ae-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume secrets
May 13 18:39:40.125: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-777ecbf0-75ae-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-projected-tvlsx" to be "success or failure"
May 13 18:39:40.134: INFO: Pod "pod-projected-secrets-777ecbf0-75ae-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 8.727073ms
May 13 18:39:42.142: INFO: Pod "pod-projected-secrets-777ecbf0-75ae-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017167435s
May 13 18:39:44.166: INFO: Pod "pod-projected-secrets-777ecbf0-75ae-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041069644s
STEP: Saw pod success
May 13 18:39:44.166: INFO: Pod "pod-projected-secrets-777ecbf0-75ae-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:39:44.174: INFO: Trying to get logs from node 10.170.219.140 pod pod-projected-secrets-777ecbf0-75ae-11e9-a09a-7e4d6cfcc771 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 13 18:39:44.223: INFO: Waiting for pod pod-projected-secrets-777ecbf0-75ae-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:39:44.230: INFO: Pod pod-projected-secrets-777ecbf0-75ae-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:39:44.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tvlsx" for this suite.
May 13 18:39:50.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:39:50.323: INFO: namespace: e2e-tests-projected-tvlsx, resource: bindings, ignored listing per whitelist
May 13 18:39:50.562: INFO: namespace e2e-tests-projected-tvlsx deletion completed in 6.320417677s

• [SLOW TEST:10.768 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:39:50.562: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-6rhzb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 13 18:39:50.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-6rhzb'
May 13 18:39:51.097: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
May 13 18:39:51.097: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
May 13 18:39:53.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-6rhzb'
May 13 18:39:53.251: INFO: stderr: ""
May 13 18:39:53.251: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:39:53.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6rhzb" for this suite.
May 13 18:40:17.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:40:17.581: INFO: namespace: e2e-tests-kubectl-6rhzb, resource: bindings, ignored listing per whitelist
May 13 18:40:17.619: INFO: namespace e2e-tests-kubectl-6rhzb deletion completed in 24.356119018s

• [SLOW TEST:27.057 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:40:17.620: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-fxbpb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-8e0f72f1-75ae-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume secrets
May 13 18:40:17.991: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8e10ee93-75ae-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-projected-fxbpb" to be "success or failure"
May 13 18:40:18.053: INFO: Pod "pod-projected-secrets-8e10ee93-75ae-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 62.247667ms
May 13 18:40:20.062: INFO: Pod "pod-projected-secrets-8e10ee93-75ae-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.071386289s
STEP: Saw pod success
May 13 18:40:20.062: INFO: Pod "pod-projected-secrets-8e10ee93-75ae-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:40:20.070: INFO: Trying to get logs from node 10.170.219.140 pod pod-projected-secrets-8e10ee93-75ae-11e9-a09a-7e4d6cfcc771 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 13 18:40:20.166: INFO: Waiting for pod pod-projected-secrets-8e10ee93-75ae-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:40:20.174: INFO: Pod pod-projected-secrets-8e10ee93-75ae-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:40:20.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fxbpb" for this suite.
May 13 18:40:26.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:40:26.458: INFO: namespace: e2e-tests-projected-fxbpb, resource: bindings, ignored listing per whitelist
May 13 18:40:26.509: INFO: namespace e2e-tests-projected-fxbpb deletion completed in 6.323907257s

• [SLOW TEST:8.889 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:40:26.509: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-9j6gs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-9j6gs
I0513 18:40:26.802863      16 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-9j6gs, replica count: 1
I0513 18:40:27.853363      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0513 18:40:28.853576      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 13 18:40:29.041: INFO: Created: latency-svc-bgh2j
May 13 18:40:29.041: INFO: Got endpoints: latency-svc-bgh2j [87.959807ms]
May 13 18:40:29.067: INFO: Created: latency-svc-7nfb2
May 13 18:40:29.072: INFO: Got endpoints: latency-svc-7nfb2 [30.430426ms]
May 13 18:40:29.078: INFO: Created: latency-svc-x66b5
May 13 18:40:29.084: INFO: Got endpoints: latency-svc-x66b5 [42.074882ms]
May 13 18:40:29.089: INFO: Created: latency-svc-9s9gq
May 13 18:40:29.095: INFO: Got endpoints: latency-svc-9s9gq [53.217086ms]
May 13 18:40:29.101: INFO: Created: latency-svc-62kbn
May 13 18:40:29.111: INFO: Got endpoints: latency-svc-62kbn [69.832184ms]
May 13 18:40:29.122: INFO: Created: latency-svc-jdnv6
May 13 18:40:29.129: INFO: Got endpoints: latency-svc-jdnv6 [86.902466ms]
May 13 18:40:29.134: INFO: Created: latency-svc-2rd8w
May 13 18:40:29.139: INFO: Got endpoints: latency-svc-2rd8w [97.954492ms]
May 13 18:40:29.146: INFO: Created: latency-svc-x9phx
May 13 18:40:29.156: INFO: Got endpoints: latency-svc-x9phx [113.867588ms]
May 13 18:40:29.159: INFO: Created: latency-svc-ndsxt
May 13 18:40:29.166: INFO: Got endpoints: latency-svc-ndsxt [124.781421ms]
May 13 18:40:29.173: INFO: Created: latency-svc-976k8
May 13 18:40:29.177: INFO: Got endpoints: latency-svc-976k8 [135.624891ms]
May 13 18:40:29.187: INFO: Created: latency-svc-jg2kg
May 13 18:40:29.193: INFO: Got endpoints: latency-svc-jg2kg [151.131174ms]
May 13 18:40:29.198: INFO: Created: latency-svc-9tmkh
May 13 18:40:29.206: INFO: Got endpoints: latency-svc-9tmkh [164.732105ms]
May 13 18:40:29.210: INFO: Created: latency-svc-wfh4z
May 13 18:40:29.216: INFO: Got endpoints: latency-svc-wfh4z [174.310111ms]
May 13 18:40:29.223: INFO: Created: latency-svc-9dpmt
May 13 18:40:29.229: INFO: Got endpoints: latency-svc-9dpmt [187.721197ms]
May 13 18:40:29.237: INFO: Created: latency-svc-hjvv7
May 13 18:40:29.241: INFO: Got endpoints: latency-svc-hjvv7 [199.29095ms]
May 13 18:40:29.248: INFO: Created: latency-svc-2bcvn
May 13 18:40:29.255: INFO: Got endpoints: latency-svc-2bcvn [213.339961ms]
May 13 18:40:29.261: INFO: Created: latency-svc-jpwzb
May 13 18:40:29.268: INFO: Got endpoints: latency-svc-jpwzb [196.140346ms]
May 13 18:40:29.275: INFO: Created: latency-svc-pp8gg
May 13 18:40:29.280: INFO: Got endpoints: latency-svc-pp8gg [195.896586ms]
May 13 18:40:29.286: INFO: Created: latency-svc-ccj49
May 13 18:40:29.293: INFO: Got endpoints: latency-svc-ccj49 [198.293132ms]
May 13 18:40:29.299: INFO: Created: latency-svc-j4mkn
May 13 18:40:29.307: INFO: Got endpoints: latency-svc-j4mkn [195.380221ms]
May 13 18:40:29.312: INFO: Created: latency-svc-c24pj
May 13 18:40:29.318: INFO: Got endpoints: latency-svc-c24pj [189.124838ms]
May 13 18:40:29.323: INFO: Created: latency-svc-xs86l
May 13 18:40:29.330: INFO: Got endpoints: latency-svc-xs86l [190.132434ms]
May 13 18:40:29.337: INFO: Created: latency-svc-llgjx
May 13 18:40:29.341: INFO: Got endpoints: latency-svc-llgjx [185.734324ms]
May 13 18:40:29.352: INFO: Created: latency-svc-5zp5r
May 13 18:40:29.361: INFO: Got endpoints: latency-svc-5zp5r [194.046282ms]
May 13 18:40:29.365: INFO: Created: latency-svc-8mwbk
May 13 18:40:29.373: INFO: Got endpoints: latency-svc-8mwbk [195.771603ms]
May 13 18:40:29.379: INFO: Created: latency-svc-5j542
May 13 18:40:29.385: INFO: Got endpoints: latency-svc-5j542 [192.044522ms]
May 13 18:40:29.391: INFO: Created: latency-svc-2pq4k
May 13 18:40:29.399: INFO: Got endpoints: latency-svc-2pq4k [192.626507ms]
May 13 18:40:29.405: INFO: Created: latency-svc-mwgzd
May 13 18:40:29.414: INFO: Got endpoints: latency-svc-mwgzd [197.793225ms]
May 13 18:40:29.421: INFO: Created: latency-svc-w82jp
May 13 18:40:29.427: INFO: Got endpoints: latency-svc-w82jp [197.681096ms]
May 13 18:40:29.435: INFO: Created: latency-svc-9rd6r
May 13 18:40:29.441: INFO: Got endpoints: latency-svc-9rd6r [199.476168ms]
May 13 18:40:29.447: INFO: Created: latency-svc-rqfln
May 13 18:40:29.452: INFO: Got endpoints: latency-svc-rqfln [197.209573ms]
May 13 18:40:29.460: INFO: Created: latency-svc-zv4dl
May 13 18:40:29.466: INFO: Got endpoints: latency-svc-zv4dl [198.235488ms]
May 13 18:40:29.473: INFO: Created: latency-svc-8qlgl
May 13 18:40:29.482: INFO: Got endpoints: latency-svc-8qlgl [201.847453ms]
May 13 18:40:29.486: INFO: Created: latency-svc-tvrfv
May 13 18:40:29.495: INFO: Got endpoints: latency-svc-tvrfv [201.337674ms]
May 13 18:40:29.497: INFO: Created: latency-svc-c4c26
May 13 18:40:29.507: INFO: Got endpoints: latency-svc-c4c26 [200.587595ms]
May 13 18:40:29.510: INFO: Created: latency-svc-gc8gq
May 13 18:40:29.516: INFO: Got endpoints: latency-svc-gc8gq [198.425448ms]
May 13 18:40:29.522: INFO: Created: latency-svc-jtl6b
May 13 18:40:29.529: INFO: Got endpoints: latency-svc-jtl6b [198.87298ms]
May 13 18:40:29.535: INFO: Created: latency-svc-w8cjz
May 13 18:40:29.547: INFO: Created: latency-svc-qml2l
May 13 18:40:29.551: INFO: Got endpoints: latency-svc-w8cjz [209.292852ms]
May 13 18:40:29.554: INFO: Got endpoints: latency-svc-qml2l [193.746301ms]
May 13 18:40:29.560: INFO: Created: latency-svc-p4d9j
May 13 18:40:29.566: INFO: Got endpoints: latency-svc-p4d9j [193.039732ms]
May 13 18:40:29.575: INFO: Created: latency-svc-f78ld
May 13 18:40:29.581: INFO: Got endpoints: latency-svc-f78ld [196.566033ms]
May 13 18:40:29.589: INFO: Created: latency-svc-f5snr
May 13 18:40:29.601: INFO: Created: latency-svc-5htmg
May 13 18:40:29.616: INFO: Created: latency-svc-r9vb4
May 13 18:40:29.622: INFO: Got endpoints: latency-svc-f5snr [222.863195ms]
May 13 18:40:29.629: INFO: Created: latency-svc-wgz9v
May 13 18:40:29.641: INFO: Created: latency-svc-cvstw
May 13 18:40:29.662: INFO: Created: latency-svc-rfgk5
May 13 18:40:29.672: INFO: Got endpoints: latency-svc-5htmg [258.343634ms]
May 13 18:40:29.680: INFO: Created: latency-svc-drr48
May 13 18:40:29.691: INFO: Created: latency-svc-dcbml
May 13 18:40:29.703: INFO: Created: latency-svc-fbrhs
May 13 18:40:29.714: INFO: Created: latency-svc-b4bmb
May 13 18:40:29.723: INFO: Got endpoints: latency-svc-r9vb4 [295.436751ms]
May 13 18:40:29.727: INFO: Created: latency-svc-5cbr2
May 13 18:40:29.740: INFO: Created: latency-svc-hrdgk
May 13 18:40:29.754: INFO: Created: latency-svc-qn9qz
May 13 18:40:29.766: INFO: Created: latency-svc-8ngmf
May 13 18:40:29.772: INFO: Got endpoints: latency-svc-wgz9v [331.411074ms]
May 13 18:40:29.778: INFO: Created: latency-svc-gc694
May 13 18:40:29.789: INFO: Created: latency-svc-b5w8c
May 13 18:40:29.801: INFO: Created: latency-svc-jgqtj
May 13 18:40:29.813: INFO: Created: latency-svc-rpvgp
May 13 18:40:29.822: INFO: Got endpoints: latency-svc-cvstw [369.299748ms]
May 13 18:40:29.826: INFO: Created: latency-svc-425tm
May 13 18:40:29.842: INFO: Created: latency-svc-tcc55
May 13 18:40:29.872: INFO: Got endpoints: latency-svc-rfgk5 [405.982689ms]
May 13 18:40:29.897: INFO: Created: latency-svc-vw9rz
May 13 18:40:29.922: INFO: Got endpoints: latency-svc-drr48 [440.638011ms]
May 13 18:40:29.946: INFO: Created: latency-svc-6sbfh
May 13 18:40:29.972: INFO: Got endpoints: latency-svc-dcbml [477.617573ms]
May 13 18:40:30.001: INFO: Created: latency-svc-kfnks
May 13 18:40:30.023: INFO: Got endpoints: latency-svc-fbrhs [516.018869ms]
May 13 18:40:30.053: INFO: Created: latency-svc-l6ftw
May 13 18:40:30.072: INFO: Got endpoints: latency-svc-b4bmb [556.027278ms]
May 13 18:40:30.096: INFO: Created: latency-svc-t5crs
May 13 18:40:30.123: INFO: Got endpoints: latency-svc-5cbr2 [593.977603ms]
May 13 18:40:30.145: INFO: Created: latency-svc-vqjn4
May 13 18:40:30.172: INFO: Got endpoints: latency-svc-hrdgk [621.299761ms]
May 13 18:40:30.194: INFO: Created: latency-svc-k2djr
May 13 18:40:30.223: INFO: Got endpoints: latency-svc-qn9qz [668.287603ms]
May 13 18:40:30.246: INFO: Created: latency-svc-vvjcj
May 13 18:40:30.273: INFO: Got endpoints: latency-svc-8ngmf [706.619721ms]
May 13 18:40:30.296: INFO: Created: latency-svc-cmj58
May 13 18:40:30.322: INFO: Got endpoints: latency-svc-gc694 [740.660752ms]
May 13 18:40:30.344: INFO: Created: latency-svc-gc6ct
May 13 18:40:30.374: INFO: Got endpoints: latency-svc-b5w8c [752.295719ms]
May 13 18:40:30.399: INFO: Created: latency-svc-n5dwd
May 13 18:40:30.422: INFO: Got endpoints: latency-svc-jgqtj [750.222848ms]
May 13 18:40:30.445: INFO: Created: latency-svc-kvz4m
May 13 18:40:30.472: INFO: Got endpoints: latency-svc-rpvgp [749.546126ms]
May 13 18:40:30.494: INFO: Created: latency-svc-27277
May 13 18:40:30.523: INFO: Got endpoints: latency-svc-425tm [751.081428ms]
May 13 18:40:30.549: INFO: Created: latency-svc-kgl4n
May 13 18:40:30.572: INFO: Got endpoints: latency-svc-tcc55 [750.551514ms]
May 13 18:40:30.593: INFO: Created: latency-svc-8s98x
May 13 18:40:30.622: INFO: Got endpoints: latency-svc-vw9rz [750.191179ms]
May 13 18:40:30.643: INFO: Created: latency-svc-b4qm4
May 13 18:40:30.673: INFO: Got endpoints: latency-svc-6sbfh [750.700662ms]
May 13 18:40:30.699: INFO: Created: latency-svc-flvsm
May 13 18:40:30.724: INFO: Got endpoints: latency-svc-kfnks [751.777745ms]
May 13 18:40:30.746: INFO: Created: latency-svc-7m8w2
May 13 18:40:30.772: INFO: Got endpoints: latency-svc-l6ftw [748.515952ms]
May 13 18:40:30.794: INFO: Created: latency-svc-2blsv
May 13 18:40:30.824: INFO: Got endpoints: latency-svc-t5crs [751.802141ms]
May 13 18:40:30.847: INFO: Created: latency-svc-s9wg5
May 13 18:40:30.872: INFO: Got endpoints: latency-svc-vqjn4 [749.608134ms]
May 13 18:40:30.895: INFO: Created: latency-svc-8t7pb
May 13 18:40:30.922: INFO: Got endpoints: latency-svc-k2djr [750.500348ms]
May 13 18:40:30.947: INFO: Created: latency-svc-bcfv7
May 13 18:40:30.972: INFO: Got endpoints: latency-svc-vvjcj [749.645634ms]
May 13 18:40:30.994: INFO: Created: latency-svc-w4h8q
May 13 18:40:31.023: INFO: Got endpoints: latency-svc-cmj58 [749.891985ms]
May 13 18:40:31.045: INFO: Created: latency-svc-vjgk8
May 13 18:40:31.073: INFO: Got endpoints: latency-svc-gc6ct [750.216377ms]
May 13 18:40:31.096: INFO: Created: latency-svc-tmz7z
May 13 18:40:31.123: INFO: Got endpoints: latency-svc-n5dwd [748.802144ms]
May 13 18:40:31.146: INFO: Created: latency-svc-vlzsm
May 13 18:40:31.173: INFO: Got endpoints: latency-svc-kvz4m [750.446436ms]
May 13 18:40:31.197: INFO: Created: latency-svc-kfncg
May 13 18:40:31.224: INFO: Got endpoints: latency-svc-27277 [751.592353ms]
May 13 18:40:31.246: INFO: Created: latency-svc-pdg44
May 13 18:40:31.272: INFO: Got endpoints: latency-svc-kgl4n [749.047612ms]
May 13 18:40:31.295: INFO: Created: latency-svc-2r2np
May 13 18:40:31.322: INFO: Got endpoints: latency-svc-8s98x [749.468767ms]
May 13 18:40:31.343: INFO: Created: latency-svc-jx47f
May 13 18:40:31.374: INFO: Got endpoints: latency-svc-b4qm4 [751.29365ms]
May 13 18:40:31.396: INFO: Created: latency-svc-t9jrg
May 13 18:40:31.423: INFO: Got endpoints: latency-svc-flvsm [749.532587ms]
May 13 18:40:31.447: INFO: Created: latency-svc-w2wgp
May 13 18:40:31.485: INFO: Got endpoints: latency-svc-7m8w2 [760.889458ms]
May 13 18:40:31.507: INFO: Created: latency-svc-jwgwq
May 13 18:40:31.524: INFO: Got endpoints: latency-svc-2blsv [751.928547ms]
May 13 18:40:31.546: INFO: Created: latency-svc-q4tns
May 13 18:40:31.574: INFO: Got endpoints: latency-svc-s9wg5 [749.423701ms]
May 13 18:40:31.596: INFO: Created: latency-svc-ph4fg
May 13 18:40:31.622: INFO: Got endpoints: latency-svc-8t7pb [750.108439ms]
May 13 18:40:31.644: INFO: Created: latency-svc-hs5hn
May 13 18:40:31.672: INFO: Got endpoints: latency-svc-bcfv7 [749.675108ms]
May 13 18:40:31.694: INFO: Created: latency-svc-rslcg
May 13 18:40:31.725: INFO: Got endpoints: latency-svc-w4h8q [752.729862ms]
May 13 18:40:31.748: INFO: Created: latency-svc-4vd6q
May 13 18:40:31.773: INFO: Got endpoints: latency-svc-vjgk8 [750.082355ms]
May 13 18:40:31.799: INFO: Created: latency-svc-rpjsp
May 13 18:40:31.823: INFO: Got endpoints: latency-svc-tmz7z [750.620506ms]
May 13 18:40:31.847: INFO: Created: latency-svc-tv2pg
May 13 18:40:31.873: INFO: Got endpoints: latency-svc-vlzsm [750.217875ms]
May 13 18:40:31.909: INFO: Created: latency-svc-277cp
May 13 18:40:31.923: INFO: Got endpoints: latency-svc-kfncg [749.631115ms]
May 13 18:40:31.949: INFO: Created: latency-svc-c5stw
May 13 18:40:31.975: INFO: Got endpoints: latency-svc-pdg44 [751.110746ms]
May 13 18:40:31.996: INFO: Created: latency-svc-7q9qq
May 13 18:40:32.023: INFO: Got endpoints: latency-svc-2r2np [750.701184ms]
May 13 18:40:32.045: INFO: Created: latency-svc-nqfjc
May 13 18:40:32.073: INFO: Got endpoints: latency-svc-jx47f [751.073028ms]
May 13 18:40:32.095: INFO: Created: latency-svc-7k8ml
May 13 18:40:32.122: INFO: Got endpoints: latency-svc-t9jrg [748.599599ms]
May 13 18:40:32.147: INFO: Created: latency-svc-wxpx7
May 13 18:40:32.173: INFO: Got endpoints: latency-svc-w2wgp [750.316587ms]
May 13 18:40:32.195: INFO: Created: latency-svc-t8r9g
May 13 18:40:32.222: INFO: Got endpoints: latency-svc-jwgwq [737.003136ms]
May 13 18:40:32.244: INFO: Created: latency-svc-vgnvz
May 13 18:40:32.272: INFO: Got endpoints: latency-svc-q4tns [748.197643ms]
May 13 18:40:32.297: INFO: Created: latency-svc-cxjkc
May 13 18:40:32.323: INFO: Got endpoints: latency-svc-ph4fg [749.710594ms]
May 13 18:40:32.348: INFO: Created: latency-svc-257gr
May 13 18:40:32.373: INFO: Got endpoints: latency-svc-hs5hn [750.687108ms]
May 13 18:40:32.397: INFO: Created: latency-svc-6r5ct
May 13 18:40:32.422: INFO: Got endpoints: latency-svc-rslcg [750.198681ms]
May 13 18:40:32.446: INFO: Created: latency-svc-744j8
May 13 18:40:32.473: INFO: Got endpoints: latency-svc-4vd6q [747.516047ms]
May 13 18:40:32.495: INFO: Created: latency-svc-bjfx7
May 13 18:40:32.522: INFO: Got endpoints: latency-svc-rpjsp [748.857671ms]
May 13 18:40:32.545: INFO: Created: latency-svc-96fqh
May 13 18:40:32.572: INFO: Got endpoints: latency-svc-tv2pg [748.620592ms]
May 13 18:40:32.595: INFO: Created: latency-svc-dhs5r
May 13 18:40:32.624: INFO: Got endpoints: latency-svc-277cp [750.190348ms]
May 13 18:40:32.647: INFO: Created: latency-svc-c4cql
May 13 18:40:32.676: INFO: Got endpoints: latency-svc-c5stw [752.898615ms]
May 13 18:40:32.697: INFO: Created: latency-svc-p6pt5
May 13 18:40:32.723: INFO: Got endpoints: latency-svc-7q9qq [747.613422ms]
May 13 18:40:32.746: INFO: Created: latency-svc-8rmmr
May 13 18:40:32.772: INFO: Got endpoints: latency-svc-nqfjc [749.494568ms]
May 13 18:40:32.794: INFO: Created: latency-svc-wthft
May 13 18:40:32.822: INFO: Got endpoints: latency-svc-7k8ml [749.587607ms]
May 13 18:40:32.844: INFO: Created: latency-svc-ctmhm
May 13 18:40:32.872: INFO: Got endpoints: latency-svc-wxpx7 [749.69682ms]
May 13 18:40:32.897: INFO: Created: latency-svc-p8mjg
May 13 18:40:32.923: INFO: Got endpoints: latency-svc-t8r9g [749.467633ms]
May 13 18:40:32.946: INFO: Created: latency-svc-5vggq
May 13 18:40:32.973: INFO: Got endpoints: latency-svc-vgnvz [750.762307ms]
May 13 18:40:32.996: INFO: Created: latency-svc-b7mfb
May 13 18:40:33.022: INFO: Got endpoints: latency-svc-cxjkc [749.789961ms]
May 13 18:40:33.044: INFO: Created: latency-svc-j7j86
May 13 18:40:33.073: INFO: Got endpoints: latency-svc-257gr [749.519389ms]
May 13 18:40:33.097: INFO: Created: latency-svc-dpfpz
May 13 18:40:33.123: INFO: Got endpoints: latency-svc-6r5ct [749.68107ms]
May 13 18:40:33.147: INFO: Created: latency-svc-wh2f2
May 13 18:40:33.174: INFO: Got endpoints: latency-svc-744j8 [751.154555ms]
May 13 18:40:33.197: INFO: Created: latency-svc-9q5vq
May 13 18:40:33.223: INFO: Got endpoints: latency-svc-bjfx7 [750.461954ms]
May 13 18:40:33.250: INFO: Created: latency-svc-xmpcm
May 13 18:40:33.273: INFO: Got endpoints: latency-svc-96fqh [750.726786ms]
May 13 18:40:33.297: INFO: Created: latency-svc-57dsd
May 13 18:40:33.323: INFO: Got endpoints: latency-svc-dhs5r [750.585966ms]
May 13 18:40:33.347: INFO: Created: latency-svc-zcc89
May 13 18:40:33.373: INFO: Got endpoints: latency-svc-c4cql [749.377579ms]
May 13 18:40:33.399: INFO: Created: latency-svc-h62gj
May 13 18:40:33.423: INFO: Got endpoints: latency-svc-p6pt5 [747.855626ms]
May 13 18:40:33.447: INFO: Created: latency-svc-lvg2w
May 13 18:40:33.473: INFO: Got endpoints: latency-svc-8rmmr [750.749017ms]
May 13 18:40:33.498: INFO: Created: latency-svc-p6lnq
May 13 18:40:33.522: INFO: Got endpoints: latency-svc-wthft [749.496967ms]
May 13 18:40:33.546: INFO: Created: latency-svc-jwlfj
May 13 18:40:33.573: INFO: Got endpoints: latency-svc-ctmhm [750.668253ms]
May 13 18:40:33.598: INFO: Created: latency-svc-q5shl
May 13 18:40:33.624: INFO: Got endpoints: latency-svc-p8mjg [751.562127ms]
May 13 18:40:33.646: INFO: Created: latency-svc-5fgmf
May 13 18:40:33.673: INFO: Got endpoints: latency-svc-5vggq [749.936804ms]
May 13 18:40:33.696: INFO: Created: latency-svc-jjqwg
May 13 18:40:33.723: INFO: Got endpoints: latency-svc-b7mfb [749.852576ms]
May 13 18:40:33.747: INFO: Created: latency-svc-2xqgm
May 13 18:40:33.772: INFO: Got endpoints: latency-svc-j7j86 [750.334724ms]
May 13 18:40:33.800: INFO: Created: latency-svc-gw5hc
May 13 18:40:33.823: INFO: Got endpoints: latency-svc-dpfpz [749.750459ms]
May 13 18:40:33.845: INFO: Created: latency-svc-j7ww2
May 13 18:40:33.874: INFO: Got endpoints: latency-svc-wh2f2 [751.162869ms]
May 13 18:40:33.896: INFO: Created: latency-svc-qsft5
May 13 18:40:33.923: INFO: Got endpoints: latency-svc-9q5vq [749.858081ms]
May 13 18:40:33.945: INFO: Created: latency-svc-ddpxv
May 13 18:40:33.972: INFO: Got endpoints: latency-svc-xmpcm [748.770839ms]
May 13 18:40:33.998: INFO: Created: latency-svc-nhn6j
May 13 18:40:34.024: INFO: Got endpoints: latency-svc-57dsd [751.317643ms]
May 13 18:40:34.057: INFO: Created: latency-svc-hmbzp
May 13 18:40:34.072: INFO: Got endpoints: latency-svc-zcc89 [749.584073ms]
May 13 18:40:34.096: INFO: Created: latency-svc-wz27w
May 13 18:40:34.123: INFO: Got endpoints: latency-svc-h62gj [749.728109ms]
May 13 18:40:34.145: INFO: Created: latency-svc-qbdp8
May 13 18:40:34.173: INFO: Got endpoints: latency-svc-lvg2w [749.124022ms]
May 13 18:40:34.195: INFO: Created: latency-svc-7ghxn
May 13 18:40:34.223: INFO: Got endpoints: latency-svc-p6lnq [749.034512ms]
May 13 18:40:34.245: INFO: Created: latency-svc-zrzq8
May 13 18:40:34.274: INFO: Got endpoints: latency-svc-jwlfj [751.674656ms]
May 13 18:40:34.296: INFO: Created: latency-svc-krt7p
May 13 18:40:34.323: INFO: Got endpoints: latency-svc-q5shl [749.49842ms]
May 13 18:40:34.346: INFO: Created: latency-svc-vbxb8
May 13 18:40:34.377: INFO: Got endpoints: latency-svc-5fgmf [752.860392ms]
May 13 18:40:34.400: INFO: Created: latency-svc-l5j9h
May 13 18:40:34.424: INFO: Got endpoints: latency-svc-jjqwg [750.919054ms]
May 13 18:40:34.445: INFO: Created: latency-svc-8cbwq
May 13 18:40:34.473: INFO: Got endpoints: latency-svc-2xqgm [750.044528ms]
May 13 18:40:34.494: INFO: Created: latency-svc-49l6r
May 13 18:40:34.524: INFO: Got endpoints: latency-svc-gw5hc [751.161014ms]
May 13 18:40:34.546: INFO: Created: latency-svc-swk9x
May 13 18:40:34.572: INFO: Got endpoints: latency-svc-j7ww2 [749.815487ms]
May 13 18:40:34.594: INFO: Created: latency-svc-9jgpm
May 13 18:40:34.622: INFO: Got endpoints: latency-svc-qsft5 [747.997225ms]
May 13 18:40:34.643: INFO: Created: latency-svc-8868t
May 13 18:40:34.673: INFO: Got endpoints: latency-svc-ddpxv [749.372591ms]
May 13 18:40:34.697: INFO: Created: latency-svc-mbzpx
May 13 18:40:34.723: INFO: Got endpoints: latency-svc-nhn6j [750.452568ms]
May 13 18:40:34.745: INFO: Created: latency-svc-ztnxk
May 13 18:40:34.772: INFO: Got endpoints: latency-svc-hmbzp [748.19425ms]
May 13 18:40:34.795: INFO: Created: latency-svc-lb9jm
May 13 18:40:34.825: INFO: Got endpoints: latency-svc-wz27w [752.234139ms]
May 13 18:40:34.846: INFO: Created: latency-svc-qsbck
May 13 18:40:34.872: INFO: Got endpoints: latency-svc-qbdp8 [749.596092ms]
May 13 18:40:34.894: INFO: Created: latency-svc-2mx4m
May 13 18:40:34.923: INFO: Got endpoints: latency-svc-7ghxn [750.133267ms]
May 13 18:40:34.947: INFO: Created: latency-svc-nvndp
May 13 18:40:34.973: INFO: Got endpoints: latency-svc-zrzq8 [749.830684ms]
May 13 18:40:34.994: INFO: Created: latency-svc-k58qb
May 13 18:40:35.024: INFO: Got endpoints: latency-svc-krt7p [750.065067ms]
May 13 18:40:35.046: INFO: Created: latency-svc-z4c4t
May 13 18:40:35.073: INFO: Got endpoints: latency-svc-vbxb8 [749.770598ms]
May 13 18:40:35.096: INFO: Created: latency-svc-twnss
May 13 18:40:35.123: INFO: Got endpoints: latency-svc-l5j9h [746.565317ms]
May 13 18:40:35.145: INFO: Created: latency-svc-pcgkd
May 13 18:40:35.175: INFO: Got endpoints: latency-svc-8cbwq [750.972243ms]
May 13 18:40:35.196: INFO: Created: latency-svc-7ltf9
May 13 18:40:35.223: INFO: Got endpoints: latency-svc-49l6r [749.824588ms]
May 13 18:40:35.245: INFO: Created: latency-svc-8ncn9
May 13 18:40:35.273: INFO: Got endpoints: latency-svc-swk9x [748.954166ms]
May 13 18:40:35.296: INFO: Created: latency-svc-wldpk
May 13 18:40:35.329: INFO: Got endpoints: latency-svc-9jgpm [756.152908ms]
May 13 18:40:35.350: INFO: Created: latency-svc-bxf7x
May 13 18:40:35.372: INFO: Got endpoints: latency-svc-8868t [750.12155ms]
May 13 18:40:35.393: INFO: Created: latency-svc-wxw9p
May 13 18:40:35.423: INFO: Got endpoints: latency-svc-mbzpx [750.210716ms]
May 13 18:40:35.445: INFO: Created: latency-svc-ldxv2
May 13 18:40:35.473: INFO: Got endpoints: latency-svc-ztnxk [750.096892ms]
May 13 18:40:35.497: INFO: Created: latency-svc-b2xk9
May 13 18:40:35.524: INFO: Got endpoints: latency-svc-lb9jm [751.330392ms]
May 13 18:40:35.549: INFO: Created: latency-svc-cnxvr
May 13 18:40:35.573: INFO: Got endpoints: latency-svc-qsbck [748.017978ms]
May 13 18:40:35.595: INFO: Created: latency-svc-ksmdp
May 13 18:40:35.622: INFO: Got endpoints: latency-svc-2mx4m [749.657144ms]
May 13 18:40:35.644: INFO: Created: latency-svc-jmzsq
May 13 18:40:35.673: INFO: Got endpoints: latency-svc-nvndp [749.975699ms]
May 13 18:40:35.696: INFO: Created: latency-svc-bq6xf
May 13 18:40:35.726: INFO: Got endpoints: latency-svc-k58qb [753.60228ms]
May 13 18:40:35.749: INFO: Created: latency-svc-lktnl
May 13 18:40:35.773: INFO: Got endpoints: latency-svc-z4c4t [748.659103ms]
May 13 18:40:35.796: INFO: Created: latency-svc-vkbt2
May 13 18:40:35.826: INFO: Got endpoints: latency-svc-twnss [753.019354ms]
May 13 18:40:35.849: INFO: Created: latency-svc-hqbl7
May 13 18:40:35.874: INFO: Got endpoints: latency-svc-pcgkd [750.662726ms]
May 13 18:40:35.897: INFO: Created: latency-svc-vlmz8
May 13 18:40:35.924: INFO: Got endpoints: latency-svc-7ltf9 [749.730523ms]
May 13 18:40:35.948: INFO: Created: latency-svc-kn2tm
May 13 18:40:35.973: INFO: Got endpoints: latency-svc-8ncn9 [750.128506ms]
May 13 18:40:35.994: INFO: Created: latency-svc-g726v
May 13 18:40:36.022: INFO: Got endpoints: latency-svc-wldpk [749.531952ms]
May 13 18:40:36.044: INFO: Created: latency-svc-k2qx2
May 13 18:40:36.073: INFO: Got endpoints: latency-svc-bxf7x [743.862996ms]
May 13 18:40:36.095: INFO: Created: latency-svc-wc9q2
May 13 18:40:36.123: INFO: Got endpoints: latency-svc-wxw9p [750.844943ms]
May 13 18:40:36.145: INFO: Created: latency-svc-5fh7s
May 13 18:40:36.172: INFO: Got endpoints: latency-svc-ldxv2 [748.719342ms]
May 13 18:40:36.193: INFO: Created: latency-svc-rwl9s
May 13 18:40:36.222: INFO: Got endpoints: latency-svc-b2xk9 [749.696221ms]
May 13 18:40:36.246: INFO: Created: latency-svc-czqvj
May 13 18:40:36.273: INFO: Got endpoints: latency-svc-cnxvr [748.982967ms]
May 13 18:40:36.298: INFO: Created: latency-svc-xq27t
May 13 18:40:36.325: INFO: Got endpoints: latency-svc-ksmdp [752.121467ms]
May 13 18:40:36.346: INFO: Created: latency-svc-bpdqm
May 13 18:40:36.441: INFO: Got endpoints: latency-svc-bq6xf [768.223878ms]
May 13 18:40:36.441: INFO: Got endpoints: latency-svc-jmzsq [819.037281ms]
May 13 18:40:36.464: INFO: Created: latency-svc-2zz5x
May 13 18:40:36.473: INFO: Got endpoints: latency-svc-lktnl [746.893991ms]
May 13 18:40:36.478: INFO: Created: latency-svc-4pdwt
May 13 18:40:36.494: INFO: Created: latency-svc-kpm8d
May 13 18:40:36.523: INFO: Got endpoints: latency-svc-vkbt2 [750.02347ms]
May 13 18:40:36.548: INFO: Created: latency-svc-rj87d
May 13 18:40:36.573: INFO: Got endpoints: latency-svc-hqbl7 [747.340726ms]
May 13 18:40:36.596: INFO: Created: latency-svc-2cmfj
May 13 18:40:36.623: INFO: Got endpoints: latency-svc-vlmz8 [748.565607ms]
May 13 18:40:36.645: INFO: Created: latency-svc-cp8fx
May 13 18:40:36.672: INFO: Got endpoints: latency-svc-kn2tm [748.13489ms]
May 13 18:40:36.695: INFO: Created: latency-svc-q49vd
May 13 18:40:36.723: INFO: Got endpoints: latency-svc-g726v [749.716757ms]
May 13 18:40:36.745: INFO: Created: latency-svc-c4m54
May 13 18:40:36.772: INFO: Got endpoints: latency-svc-k2qx2 [749.918174ms]
May 13 18:40:36.793: INFO: Created: latency-svc-64zbb
May 13 18:40:36.823: INFO: Got endpoints: latency-svc-wc9q2 [750.175299ms]
May 13 18:40:36.845: INFO: Created: latency-svc-mjlhk
May 13 18:40:36.873: INFO: Got endpoints: latency-svc-5fh7s [749.77647ms]
May 13 18:40:36.923: INFO: Got endpoints: latency-svc-rwl9s [750.685917ms]
May 13 18:40:36.976: INFO: Got endpoints: latency-svc-czqvj [753.126557ms]
May 13 18:40:37.023: INFO: Got endpoints: latency-svc-xq27t [749.913866ms]
May 13 18:40:37.078: INFO: Got endpoints: latency-svc-bpdqm [753.6947ms]
May 13 18:40:37.122: INFO: Got endpoints: latency-svc-2zz5x [680.875979ms]
May 13 18:40:37.181: INFO: Got endpoints: latency-svc-4pdwt [740.271578ms]
May 13 18:40:37.223: INFO: Got endpoints: latency-svc-kpm8d [750.110674ms]
May 13 18:40:37.272: INFO: Got endpoints: latency-svc-rj87d [749.390183ms]
May 13 18:40:37.324: INFO: Got endpoints: latency-svc-2cmfj [751.045811ms]
May 13 18:40:37.441: INFO: Got endpoints: latency-svc-q49vd [768.875471ms]
May 13 18:40:37.441: INFO: Got endpoints: latency-svc-cp8fx [818.803137ms]
May 13 18:40:37.473: INFO: Got endpoints: latency-svc-c4m54 [750.250157ms]
May 13 18:40:37.523: INFO: Got endpoints: latency-svc-64zbb [750.891418ms]
May 13 18:40:37.573: INFO: Got endpoints: latency-svc-mjlhk [750.157092ms]
May 13 18:40:37.573: INFO: Latencies: [30.430426ms 42.074882ms 53.217086ms 69.832184ms 86.902466ms 97.954492ms 113.867588ms 124.781421ms 135.624891ms 151.131174ms 164.732105ms 174.310111ms 185.734324ms 187.721197ms 189.124838ms 190.132434ms 192.044522ms 192.626507ms 193.039732ms 193.746301ms 194.046282ms 195.380221ms 195.771603ms 195.896586ms 196.140346ms 196.566033ms 197.209573ms 197.681096ms 197.793225ms 198.235488ms 198.293132ms 198.425448ms 198.87298ms 199.29095ms 199.476168ms 200.587595ms 201.337674ms 201.847453ms 209.292852ms 213.339961ms 222.863195ms 258.343634ms 295.436751ms 331.411074ms 369.299748ms 405.982689ms 440.638011ms 477.617573ms 516.018869ms 556.027278ms 593.977603ms 621.299761ms 668.287603ms 680.875979ms 706.619721ms 737.003136ms 740.271578ms 740.660752ms 743.862996ms 746.565317ms 746.893991ms 747.340726ms 747.516047ms 747.613422ms 747.855626ms 747.997225ms 748.017978ms 748.13489ms 748.19425ms 748.197643ms 748.515952ms 748.565607ms 748.599599ms 748.620592ms 748.659103ms 748.719342ms 748.770839ms 748.802144ms 748.857671ms 748.954166ms 748.982967ms 749.034512ms 749.047612ms 749.124022ms 749.372591ms 749.377579ms 749.390183ms 749.423701ms 749.467633ms 749.468767ms 749.494568ms 749.496967ms 749.49842ms 749.519389ms 749.531952ms 749.532587ms 749.546126ms 749.584073ms 749.587607ms 749.596092ms 749.608134ms 749.631115ms 749.645634ms 749.657144ms 749.675108ms 749.68107ms 749.696221ms 749.69682ms 749.710594ms 749.716757ms 749.728109ms 749.730523ms 749.750459ms 749.770598ms 749.77647ms 749.789961ms 749.815487ms 749.824588ms 749.830684ms 749.852576ms 749.858081ms 749.891985ms 749.913866ms 749.918174ms 749.936804ms 749.975699ms 750.02347ms 750.044528ms 750.065067ms 750.082355ms 750.096892ms 750.108439ms 750.110674ms 750.12155ms 750.128506ms 750.133267ms 750.157092ms 750.175299ms 750.190348ms 750.191179ms 750.198681ms 750.210716ms 750.216377ms 750.217875ms 750.222848ms 750.250157ms 750.316587ms 750.334724ms 750.446436ms 750.452568ms 750.461954ms 750.500348ms 750.551514ms 750.585966ms 750.620506ms 750.662726ms 750.668253ms 750.685917ms 750.687108ms 750.700662ms 750.701184ms 750.726786ms 750.749017ms 750.762307ms 750.844943ms 750.891418ms 750.919054ms 750.972243ms 751.045811ms 751.073028ms 751.081428ms 751.110746ms 751.154555ms 751.161014ms 751.162869ms 751.29365ms 751.317643ms 751.330392ms 751.562127ms 751.592353ms 751.674656ms 751.777745ms 751.802141ms 751.928547ms 752.121467ms 752.234139ms 752.295719ms 752.729862ms 752.860392ms 752.898615ms 753.019354ms 753.126557ms 753.60228ms 753.6947ms 756.152908ms 760.889458ms 768.223878ms 768.875471ms 818.803137ms 819.037281ms]
May 13 18:40:37.573: INFO: 50 %ile: 749.608134ms
May 13 18:40:37.573: INFO: 90 %ile: 751.674656ms
May 13 18:40:37.573: INFO: 99 %ile: 818.803137ms
May 13 18:40:37.573: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:40:37.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-9j6gs" for this suite.
May 13 18:40:51.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:40:51.760: INFO: namespace: e2e-tests-svc-latency-9j6gs, resource: bindings, ignored listing per whitelist
May 13 18:40:51.927: INFO: namespace e2e-tests-svc-latency-9j6gs deletion completed in 14.343802817s

• [SLOW TEST:25.418 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:40:51.927: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-7g7nv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
May 13 18:40:52.226: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-177230811 proxy --unix-socket=/tmp/kubectl-proxy-unix214425470/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:40:52.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7g7nv" for this suite.
May 13 18:40:58.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:40:58.652: INFO: namespace: e2e-tests-kubectl-7g7nv, resource: bindings, ignored listing per whitelist
May 13 18:40:58.723: INFO: namespace e2e-tests-kubectl-7g7nv deletion completed in 6.373369143s

• [SLOW TEST:6.796 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:40:58.724: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-dln98
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-gpd7
STEP: Creating a pod to test atomic-volume-subpath
May 13 18:40:59.080: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-gpd7" in namespace "e2e-tests-subpath-dln98" to be "success or failure"
May 13 18:40:59.088: INFO: Pod "pod-subpath-test-configmap-gpd7": Phase="Pending", Reason="", readiness=false. Elapsed: 7.749107ms
May 13 18:41:01.099: INFO: Pod "pod-subpath-test-configmap-gpd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018798072s
May 13 18:41:03.125: INFO: Pod "pod-subpath-test-configmap-gpd7": Phase="Running", Reason="", readiness=false. Elapsed: 4.044800164s
May 13 18:41:05.134: INFO: Pod "pod-subpath-test-configmap-gpd7": Phase="Running", Reason="", readiness=false. Elapsed: 6.05318723s
May 13 18:41:07.143: INFO: Pod "pod-subpath-test-configmap-gpd7": Phase="Running", Reason="", readiness=false. Elapsed: 8.062464246s
May 13 18:41:09.152: INFO: Pod "pod-subpath-test-configmap-gpd7": Phase="Running", Reason="", readiness=false. Elapsed: 10.071587943s
May 13 18:41:11.165: INFO: Pod "pod-subpath-test-configmap-gpd7": Phase="Running", Reason="", readiness=false. Elapsed: 12.084613855s
May 13 18:41:13.189: INFO: Pod "pod-subpath-test-configmap-gpd7": Phase="Running", Reason="", readiness=false. Elapsed: 14.109100339s
May 13 18:41:15.198: INFO: Pod "pod-subpath-test-configmap-gpd7": Phase="Running", Reason="", readiness=false. Elapsed: 16.117561926s
May 13 18:41:17.207: INFO: Pod "pod-subpath-test-configmap-gpd7": Phase="Running", Reason="", readiness=false. Elapsed: 18.126658639s
May 13 18:41:19.216: INFO: Pod "pod-subpath-test-configmap-gpd7": Phase="Running", Reason="", readiness=false. Elapsed: 20.136098637s
May 13 18:41:21.226: INFO: Pod "pod-subpath-test-configmap-gpd7": Phase="Running", Reason="", readiness=false. Elapsed: 22.145200729s
May 13 18:41:23.251: INFO: Pod "pod-subpath-test-configmap-gpd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.170132982s
STEP: Saw pod success
May 13 18:41:23.251: INFO: Pod "pod-subpath-test-configmap-gpd7" satisfied condition "success or failure"
May 13 18:41:23.258: INFO: Trying to get logs from node 10.170.219.140 pod pod-subpath-test-configmap-gpd7 container test-container-subpath-configmap-gpd7: <nil>
STEP: delete the pod
May 13 18:41:23.307: INFO: Waiting for pod pod-subpath-test-configmap-gpd7 to disappear
May 13 18:41:23.350: INFO: Pod pod-subpath-test-configmap-gpd7 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-gpd7
May 13 18:41:23.350: INFO: Deleting pod "pod-subpath-test-configmap-gpd7" in namespace "e2e-tests-subpath-dln98"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:41:23.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-dln98" for this suite.
May 13 18:41:29.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:41:29.541: INFO: namespace: e2e-tests-subpath-dln98, resource: bindings, ignored listing per whitelist
May 13 18:41:29.723: INFO: namespace e2e-tests-subpath-dln98 deletion completed in 6.353324856s

• [SLOW TEST:31.000 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:41:29.724: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-7qjqs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 18:41:30.039: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b901fabd-75ae-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-downward-api-7qjqs" to be "success or failure"
May 13 18:41:30.048: INFO: Pod "downwardapi-volume-b901fabd-75ae-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 9.051878ms
May 13 18:41:32.058: INFO: Pod "downwardapi-volume-b901fabd-75ae-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01884069s
STEP: Saw pod success
May 13 18:41:32.058: INFO: Pod "downwardapi-volume-b901fabd-75ae-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:41:32.066: INFO: Trying to get logs from node 10.170.219.140 pod downwardapi-volume-b901fabd-75ae-11e9-a09a-7e4d6cfcc771 container client-container: <nil>
STEP: delete the pod
May 13 18:41:32.141: INFO: Waiting for pod downwardapi-volume-b901fabd-75ae-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:41:32.149: INFO: Pod downwardapi-volume-b901fabd-75ae-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:41:32.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7qjqs" for this suite.
May 13 18:41:38.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:41:38.294: INFO: namespace: e2e-tests-downward-api-7qjqs, resource: bindings, ignored listing per whitelist
May 13 18:41:38.518: INFO: namespace e2e-tests-downward-api-7qjqs deletion completed in 6.358996121s

• [SLOW TEST:8.794 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:41:38.519: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-mff7f
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
May 13 18:41:38.813: INFO: Waiting up to 5m0s for pod "pod-be3d40c8-75ae-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-emptydir-mff7f" to be "success or failure"
May 13 18:41:38.821: INFO: Pod "pod-be3d40c8-75ae-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 7.547085ms
May 13 18:41:40.830: INFO: Pod "pod-be3d40c8-75ae-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016627713s
STEP: Saw pod success
May 13 18:41:40.830: INFO: Pod "pod-be3d40c8-75ae-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:41:40.838: INFO: Trying to get logs from node 10.170.219.140 pod pod-be3d40c8-75ae-11e9-a09a-7e4d6cfcc771 container test-container: <nil>
STEP: delete the pod
May 13 18:41:40.886: INFO: Waiting for pod pod-be3d40c8-75ae-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:41:40.895: INFO: Pod pod-be3d40c8-75ae-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:41:40.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mff7f" for this suite.
May 13 18:41:46.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:41:47.181: INFO: namespace: e2e-tests-emptydir-mff7f, resource: bindings, ignored listing per whitelist
May 13 18:41:47.239: INFO: namespace e2e-tests-emptydir-mff7f deletion completed in 6.332936349s

• [SLOW TEST:8.720 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:41:47.239: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7nf6t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-c37831e2-75ae-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume configMaps
May 13 18:41:47.597: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c379b8ca-75ae-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-projected-7nf6t" to be "success or failure"
May 13 18:41:47.605: INFO: Pod "pod-projected-configmaps-c379b8ca-75ae-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 8.677441ms
May 13 18:41:49.616: INFO: Pod "pod-projected-configmaps-c379b8ca-75ae-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019083828s
STEP: Saw pod success
May 13 18:41:49.616: INFO: Pod "pod-projected-configmaps-c379b8ca-75ae-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:41:49.623: INFO: Trying to get logs from node 10.170.219.140 pod pod-projected-configmaps-c379b8ca-75ae-11e9-a09a-7e4d6cfcc771 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 13 18:41:49.741: INFO: Waiting for pod pod-projected-configmaps-c379b8ca-75ae-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:41:49.751: INFO: Pod pod-projected-configmaps-c379b8ca-75ae-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:41:49.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7nf6t" for this suite.
May 13 18:41:55.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:41:56.236: INFO: namespace: e2e-tests-projected-7nf6t, resource: bindings, ignored listing per whitelist
May 13 18:41:56.495: INFO: namespace e2e-tests-projected-7nf6t deletion completed in 6.733481859s

• [SLOW TEST:9.255 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:41:56.495: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-kmg4n
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-c8f5d7df-75ae-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume secrets
May 13 18:41:56.812: INFO: Waiting up to 5m0s for pod "pod-secrets-c8f770e7-75ae-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-secrets-kmg4n" to be "success or failure"
May 13 18:41:56.820: INFO: Pod "pod-secrets-c8f770e7-75ae-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 7.917459ms
May 13 18:41:58.828: INFO: Pod "pod-secrets-c8f770e7-75ae-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016376621s
STEP: Saw pod success
May 13 18:41:58.828: INFO: Pod "pod-secrets-c8f770e7-75ae-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:41:58.837: INFO: Trying to get logs from node 10.170.219.140 pod pod-secrets-c8f770e7-75ae-11e9-a09a-7e4d6cfcc771 container secret-env-test: <nil>
STEP: delete the pod
May 13 18:41:58.884: INFO: Waiting for pod pod-secrets-c8f770e7-75ae-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:41:58.891: INFO: Pod pod-secrets-c8f770e7-75ae-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:41:58.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-kmg4n" for this suite.
May 13 18:42:04.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:42:05.265: INFO: namespace: e2e-tests-secrets-kmg4n, resource: bindings, ignored listing per whitelist
May 13 18:42:05.491: INFO: namespace e2e-tests-secrets-kmg4n deletion completed in 6.588331283s

• [SLOW TEST:8.996 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:42:05.492: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-8zlh4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 18:42:05.817: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ce55a90a-75ae-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-downward-api-8zlh4" to be "success or failure"
May 13 18:42:05.829: INFO: Pod "downwardapi-volume-ce55a90a-75ae-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 11.583461ms
May 13 18:42:07.853: INFO: Pod "downwardapi-volume-ce55a90a-75ae-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03585574s
STEP: Saw pod success
May 13 18:42:07.853: INFO: Pod "downwardapi-volume-ce55a90a-75ae-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:42:07.862: INFO: Trying to get logs from node 10.170.219.140 pod downwardapi-volume-ce55a90a-75ae-11e9-a09a-7e4d6cfcc771 container client-container: <nil>
STEP: delete the pod
May 13 18:42:07.941: INFO: Waiting for pod downwardapi-volume-ce55a90a-75ae-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:42:07.952: INFO: Pod downwardapi-volume-ce55a90a-75ae-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:42:07.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8zlh4" for this suite.
May 13 18:42:13.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:42:14.413: INFO: namespace: e2e-tests-downward-api-8zlh4, resource: bindings, ignored listing per whitelist
May 13 18:42:14.444: INFO: namespace e2e-tests-downward-api-8zlh4 deletion completed in 6.481579642s

• [SLOW TEST:8.952 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:42:14.444: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-thqst
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
May 13 18:42:14.838: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-177230811 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:42:14.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-thqst" for this suite.
May 13 18:42:20.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:42:21.191: INFO: namespace: e2e-tests-kubectl-thqst, resource: bindings, ignored listing per whitelist
May 13 18:42:21.468: INFO: namespace e2e-tests-kubectl-thqst deletion completed in 6.513034433s

• [SLOW TEST:7.024 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:42:21.470: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-xkwvg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-d7d97d42-75ae-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume secrets
May 13 18:42:21.790: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d7db0450-75ae-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-projected-xkwvg" to be "success or failure"
May 13 18:42:21.799: INFO: Pod "pod-projected-secrets-d7db0450-75ae-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 8.672743ms
May 13 18:42:23.849: INFO: Pod "pod-projected-secrets-d7db0450-75ae-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.059277966s
STEP: Saw pod success
May 13 18:42:23.849: INFO: Pod "pod-projected-secrets-d7db0450-75ae-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:42:23.858: INFO: Trying to get logs from node 10.170.219.140 pod pod-projected-secrets-d7db0450-75ae-11e9-a09a-7e4d6cfcc771 container secret-volume-test: <nil>
STEP: delete the pod
May 13 18:42:23.900: INFO: Waiting for pod pod-projected-secrets-d7db0450-75ae-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:42:23.907: INFO: Pod pod-projected-secrets-d7db0450-75ae-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:42:23.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xkwvg" for this suite.
May 13 18:42:29.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:42:30.074: INFO: namespace: e2e-tests-projected-xkwvg, resource: bindings, ignored listing per whitelist
May 13 18:42:30.233: INFO: namespace e2e-tests-projected-xkwvg deletion completed in 6.315374739s

• [SLOW TEST:8.764 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:42:30.233: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-wzdrc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 18:42:30.557: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dd144aaf-75ae-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-projected-wzdrc" to be "success or failure"
May 13 18:42:30.566: INFO: Pod "downwardapi-volume-dd144aaf-75ae-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 9.040605ms
May 13 18:42:32.575: INFO: Pod "downwardapi-volume-dd144aaf-75ae-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01792094s
STEP: Saw pod success
May 13 18:42:32.575: INFO: Pod "downwardapi-volume-dd144aaf-75ae-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:42:32.583: INFO: Trying to get logs from node 10.170.219.140 pod downwardapi-volume-dd144aaf-75ae-11e9-a09a-7e4d6cfcc771 container client-container: <nil>
STEP: delete the pod
May 13 18:42:32.641: INFO: Waiting for pod downwardapi-volume-dd144aaf-75ae-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:42:32.650: INFO: Pod downwardapi-volume-dd144aaf-75ae-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:42:32.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wzdrc" for this suite.
May 13 18:42:38.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:42:39.044: INFO: namespace: e2e-tests-projected-wzdrc, resource: bindings, ignored listing per whitelist
May 13 18:42:39.055: INFO: namespace e2e-tests-projected-wzdrc deletion completed in 6.392225783s

• [SLOW TEST:8.822 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:42:39.057: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-wf28x
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0513 18:42:40.536757      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 13 18:42:40.536: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:42:40.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-wf28x" for this suite.
May 13 18:42:46.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:42:46.688: INFO: namespace: e2e-tests-gc-wf28x, resource: bindings, ignored listing per whitelist
May 13 18:42:46.895: INFO: namespace e2e-tests-gc-wf28x deletion completed in 6.349990293s

• [SLOW TEST:7.838 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:42:46.895: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-kbf2z
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
May 13 18:42:47.265: INFO: Waiting up to 5m0s for pod "client-containers-e70a049f-75ae-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-containers-kbf2z" to be "success or failure"
May 13 18:42:47.277: INFO: Pod "client-containers-e70a049f-75ae-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 12.218566ms
May 13 18:42:49.286: INFO: Pod "client-containers-e70a049f-75ae-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021061484s
STEP: Saw pod success
May 13 18:42:49.286: INFO: Pod "client-containers-e70a049f-75ae-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:42:49.295: INFO: Trying to get logs from node 10.170.219.140 pod client-containers-e70a049f-75ae-11e9-a09a-7e4d6cfcc771 container test-container: <nil>
STEP: delete the pod
May 13 18:42:49.341: INFO: Waiting for pod client-containers-e70a049f-75ae-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:42:49.349: INFO: Pod client-containers-e70a049f-75ae-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:42:49.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-kbf2z" for this suite.
May 13 18:42:55.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:42:55.644: INFO: namespace: e2e-tests-containers-kbf2z, resource: bindings, ignored listing per whitelist
May 13 18:42:55.944: INFO: namespace e2e-tests-containers-kbf2z deletion completed in 6.502926s

• [SLOW TEST:9.049 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:42:55.946: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-lftb5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 18:42:56.269: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ec67d7c9-75ae-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-projected-lftb5" to be "success or failure"
May 13 18:42:56.278: INFO: Pod "downwardapi-volume-ec67d7c9-75ae-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 8.531921ms
May 13 18:42:58.287: INFO: Pod "downwardapi-volume-ec67d7c9-75ae-11e9-a09a-7e4d6cfcc771": Phase="Running", Reason="", readiness=true. Elapsed: 2.017504987s
May 13 18:43:00.494: INFO: Pod "downwardapi-volume-ec67d7c9-75ae-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.225248733s
STEP: Saw pod success
May 13 18:43:00.494: INFO: Pod "downwardapi-volume-ec67d7c9-75ae-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:43:00.505: INFO: Trying to get logs from node 10.170.219.140 pod downwardapi-volume-ec67d7c9-75ae-11e9-a09a-7e4d6cfcc771 container client-container: <nil>
STEP: delete the pod
May 13 18:43:00.553: INFO: Waiting for pod downwardapi-volume-ec67d7c9-75ae-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:43:00.561: INFO: Pod downwardapi-volume-ec67d7c9-75ae-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:43:00.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lftb5" for this suite.
May 13 18:43:06.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:43:06.958: INFO: namespace: e2e-tests-projected-lftb5, resource: bindings, ignored listing per whitelist
May 13 18:43:06.965: INFO: namespace e2e-tests-projected-lftb5 deletion completed in 6.393807372s

• [SLOW TEST:11.019 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:43:06.965: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-4l2cr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
May 13 18:43:07.284: INFO: Waiting up to 5m0s for pod "pod-f2f91ddb-75ae-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-emptydir-4l2cr" to be "success or failure"
May 13 18:43:07.292: INFO: Pod "pod-f2f91ddb-75ae-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 7.768313ms
May 13 18:43:09.302: INFO: Pod "pod-f2f91ddb-75ae-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017306316s
STEP: Saw pod success
May 13 18:43:09.302: INFO: Pod "pod-f2f91ddb-75ae-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:43:09.310: INFO: Trying to get logs from node 10.170.219.140 pod pod-f2f91ddb-75ae-11e9-a09a-7e4d6cfcc771 container test-container: <nil>
STEP: delete the pod
May 13 18:43:09.353: INFO: Waiting for pod pod-f2f91ddb-75ae-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:43:09.361: INFO: Pod pod-f2f91ddb-75ae-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:43:09.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4l2cr" for this suite.
May 13 18:43:15.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:43:15.497: INFO: namespace: e2e-tests-emptydir-4l2cr, resource: bindings, ignored listing per whitelist
May 13 18:43:15.659: INFO: namespace e2e-tests-emptydir-4l2cr deletion completed in 6.287583534s

• [SLOW TEST:8.694 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:43:15.659: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-nts6h
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 18:43:38.005: INFO: Container started at 2019-05-13 18:43:17 +0000 UTC, pod became ready at 2019-05-13 18:43:37 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:43:38.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-nts6h" for this suite.
May 13 18:44:00.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:44:00.405: INFO: namespace: e2e-tests-container-probe-nts6h, resource: bindings, ignored listing per whitelist
May 13 18:44:00.405: INFO: namespace e2e-tests-container-probe-nts6h deletion completed in 22.35402074s

• [SLOW TEST:44.746 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:44:00.406: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-lpkxw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0513 18:44:10.890434      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 13 18:44:10.890: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:44:10.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-lpkxw" for this suite.
May 13 18:44:18.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:44:18.978: INFO: namespace: e2e-tests-gc-lpkxw, resource: bindings, ignored listing per whitelist
May 13 18:44:19.253: INFO: namespace e2e-tests-gc-lpkxw deletion completed in 8.354635692s

• [SLOW TEST:18.847 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:44:19.255: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-qpmdb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
May 13 18:44:19.565: INFO: Waiting up to 5m0s for pod "pod-1e0dc0d5-75af-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-emptydir-qpmdb" to be "success or failure"
May 13 18:44:19.575: INFO: Pod "pod-1e0dc0d5-75af-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 9.994226ms
May 13 18:44:21.600: INFO: Pod "pod-1e0dc0d5-75af-11e9-a09a-7e4d6cfcc771": Phase="Running", Reason="", readiness=true. Elapsed: 2.035159261s
May 13 18:44:23.610: INFO: Pod "pod-1e0dc0d5-75af-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044927482s
STEP: Saw pod success
May 13 18:44:23.610: INFO: Pod "pod-1e0dc0d5-75af-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:44:23.618: INFO: Trying to get logs from node 10.170.219.140 pod pod-1e0dc0d5-75af-11e9-a09a-7e4d6cfcc771 container test-container: <nil>
STEP: delete the pod
May 13 18:44:23.664: INFO: Waiting for pod pod-1e0dc0d5-75af-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:44:23.671: INFO: Pod pod-1e0dc0d5-75af-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:44:23.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qpmdb" for this suite.
May 13 18:44:29.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:44:29.789: INFO: namespace: e2e-tests-emptydir-qpmdb, resource: bindings, ignored listing per whitelist
May 13 18:44:30.018: INFO: namespace e2e-tests-emptydir-qpmdb deletion completed in 6.336325085s

• [SLOW TEST:10.764 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:44:30.018: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-bm7k2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-247d9bd8-75af-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume secrets
May 13 18:44:30.372: INFO: Waiting up to 5m0s for pod "pod-secrets-247f1da1-75af-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-secrets-bm7k2" to be "success or failure"
May 13 18:44:30.380: INFO: Pod "pod-secrets-247f1da1-75af-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 7.698506ms
May 13 18:44:32.403: INFO: Pod "pod-secrets-247f1da1-75af-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030480162s
STEP: Saw pod success
May 13 18:44:32.403: INFO: Pod "pod-secrets-247f1da1-75af-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:44:32.412: INFO: Trying to get logs from node 10.170.219.140 pod pod-secrets-247f1da1-75af-11e9-a09a-7e4d6cfcc771 container secret-volume-test: <nil>
STEP: delete the pod
May 13 18:44:32.468: INFO: Waiting for pod pod-secrets-247f1da1-75af-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:44:32.476: INFO: Pod pod-secrets-247f1da1-75af-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:44:32.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-bm7k2" for this suite.
May 13 18:44:38.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:44:38.595: INFO: namespace: e2e-tests-secrets-bm7k2, resource: bindings, ignored listing per whitelist
May 13 18:44:38.801: INFO: namespace e2e-tests-secrets-bm7k2 deletion completed in 6.313934805s

• [SLOW TEST:8.782 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:44:38.801: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-4mntp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
May 13 18:44:39.115: INFO: Waiting up to 5m0s for pod "pod-29b4d6f1-75af-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-emptydir-4mntp" to be "success or failure"
May 13 18:44:39.125: INFO: Pod "pod-29b4d6f1-75af-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 10.825288ms
May 13 18:44:41.149: INFO: Pod "pod-29b4d6f1-75af-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034249296s
STEP: Saw pod success
May 13 18:44:41.149: INFO: Pod "pod-29b4d6f1-75af-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:44:41.157: INFO: Trying to get logs from node 10.170.219.140 pod pod-29b4d6f1-75af-11e9-a09a-7e4d6cfcc771 container test-container: <nil>
STEP: delete the pod
May 13 18:44:41.480: INFO: Waiting for pod pod-29b4d6f1-75af-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:44:41.550: INFO: Pod pod-29b4d6f1-75af-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:44:41.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4mntp" for this suite.
May 13 18:44:47.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:44:47.800: INFO: namespace: e2e-tests-emptydir-4mntp, resource: bindings, ignored listing per whitelist
May 13 18:44:48.043: INFO: namespace e2e-tests-emptydir-4mntp deletion completed in 6.482379584s

• [SLOW TEST:9.242 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:44:48.043: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-w27p4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
May 13 18:44:48.348: INFO: PodSpec: initContainers in spec.initContainers
May 13 18:45:30.918: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-2f38cb60-75af-11e9-a09a-7e4d6cfcc771", GenerateName:"", Namespace:"e2e-tests-init-container-w27p4", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-w27p4/pods/pod-init-2f38cb60-75af-11e9-a09a-7e4d6cfcc771", UID:"2f3a7d84-75af-11e9-906d-b2bf80cbe475", ResourceVersion:"35770", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63693369888, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"348865694"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-d65qb", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc421cc0ac0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-d65qb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-d65qb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-d65qb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc420be1408), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.170.219.140", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc421388240), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc420be17d0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc420be17f0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc420be17f8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693369888, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693369888, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693369888, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693369888, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.170.219.140", PodIP:"172.30.208.25", StartTime:(*v1.Time)(0xc42105e420), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc420fe6000)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc420fe60e0)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://9aed1b4c169c64befcf507c20710348dfd85aae475ba1fba1cc424039165c40d"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc42105e460), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc42105e440), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:45:30.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-w27p4" for this suite.
May 13 18:45:54.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:45:55.005: INFO: namespace: e2e-tests-init-container-w27p4, resource: bindings, ignored listing per whitelist
May 13 18:45:55.478: INFO: namespace e2e-tests-init-container-w27p4 deletion completed in 24.536036992s

• [SLOW TEST:67.435 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:45:55.479: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-jjw89
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
May 13 18:45:55.783: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 13 18:45:55.801: INFO: Waiting for terminating namespaces to be deleted...
May 13 18:45:55.809: INFO: 
Logging pods the kubelet thinks is on node 10.170.219.140 before test
May 13 18:45:55.904: INFO: ibm-keepalived-watcher-s9p9f from kube-system started at 2019-05-13 16:26:20 +0000 UTC (1 container statuses recorded)
May 13 18:45:55.904: INFO: 	Container keepalived-watcher ready: true, restart count 0
May 13 18:45:55.904: INFO: public-cre5e67d863b8a419ba7a75a47352a70a9-alb1-785767687-drrgh from kube-system started at 2019-05-13 16:32:34 +0000 UTC (4 container statuses recorded)
May 13 18:45:55.904: INFO: 	Container ingress-auth-1 ready: true, restart count 0
May 13 18:45:55.904: INFO: 	Container ingress-auth-2 ready: true, restart count 0
May 13 18:45:55.904: INFO: 	Container ingress-auth-3 ready: true, restart count 0
May 13 18:45:55.904: INFO: 	Container nginx-ingress ready: true, restart count 0
May 13 18:45:55.904: INFO: sonobuoy-systemd-logs-daemon-set-5d6538ccab344242-8b4m8 from heptio-sonobuoy started at 2019-05-13 18:23:14 +0000 UTC (2 container statuses recorded)
May 13 18:45:55.904: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 13 18:45:55.904: INFO: 	Container systemd-logs ready: true, restart count 0
May 13 18:45:55.904: INFO: ibm-kube-fluentd-kswb8 from kube-system started at 2019-05-13 16:27:54 +0000 UTC (1 container statuses recorded)
May 13 18:45:55.904: INFO: 	Container fluentd ready: true, restart count 0
May 13 18:45:55.904: INFO: ibm-master-proxy-static-10.170.219.140 from kube-system started at <nil> (0 container statuses recorded)
May 13 18:45:55.904: INFO: ibm-cloud-provider-ip-169-45-233-124-7fbd585f77-sv6vv from ibm-system started at 2019-05-13 16:27:29 +0000 UTC (1 container statuses recorded)
May 13 18:45:55.904: INFO: 	Container ibm-cloud-provider-ip-169-45-233-124 ready: true, restart count 0
May 13 18:45:55.904: INFO: calico-node-nlxmm from kube-system started at 2019-05-13 16:26:20 +0000 UTC (2 container statuses recorded)
May 13 18:45:55.904: INFO: 	Container calico-node ready: true, restart count 0
May 13 18:45:55.904: INFO: 	Container install-cni ready: true, restart count 0
May 13 18:45:55.904: INFO: 
Logging pods the kubelet thinks is on node 10.170.219.170 before test
May 13 18:45:55.930: INFO: ibm-keepalived-watcher-74r7v from kube-system started at 2019-05-13 16:26:56 +0000 UTC (1 container statuses recorded)
May 13 18:45:55.930: INFO: 	Container keepalived-watcher ready: true, restart count 0
May 13 18:45:55.930: INFO: sonobuoy-systemd-logs-daemon-set-5d6538ccab344242-2t9dg from heptio-sonobuoy started at 2019-05-13 18:23:14 +0000 UTC (2 container statuses recorded)
May 13 18:45:55.930: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 13 18:45:55.930: INFO: 	Container systemd-logs ready: true, restart count 0
May 13 18:45:55.930: INFO: ibm-master-proxy-static-10.170.219.170 from kube-system started at <nil> (0 container statuses recorded)
May 13 18:45:55.930: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-05-13 18:23:07 +0000 UTC (1 container statuses recorded)
May 13 18:45:55.930: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
May 13 18:45:55.930: INFO: calico-node-vsr6g from kube-system started at 2019-05-13 16:26:56 +0000 UTC (2 container statuses recorded)
May 13 18:45:55.930: INFO: 	Container calico-node ready: true, restart count 0
May 13 18:45:55.930: INFO: 	Container install-cni ready: true, restart count 0
May 13 18:45:55.930: INFO: metrics-server-77478c8fdd-zwg9d from kube-system started at 2019-05-13 16:27:41 +0000 UTC (2 container statuses recorded)
May 13 18:45:55.930: INFO: 	Container metrics-server ready: true, restart count 0
May 13 18:45:55.930: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 13 18:45:55.930: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-13 18:23:11 +0000 UTC (1 container statuses recorded)
May 13 18:45:55.930: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 13 18:45:55.930: INFO: kube-dns-amd64-fcdcf59c5-mbw97 from kube-system started at 2019-05-13 16:27:28 +0000 UTC (3 container statuses recorded)
May 13 18:45:55.930: INFO: 	Container dnsmasq ready: true, restart count 0
May 13 18:45:55.930: INFO: 	Container kubedns ready: true, restart count 0
May 13 18:45:55.930: INFO: 	Container sidecar ready: true, restart count 0
May 13 18:45:55.930: INFO: sonobuoy-e2e-job-d5dc9a0af3d340ba from heptio-sonobuoy started at 2019-05-13 18:23:14 +0000 UTC (2 container statuses recorded)
May 13 18:45:55.930: INFO: 	Container e2e ready: true, restart count 0
May 13 18:45:55.930: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 13 18:45:55.930: INFO: ibm-kube-fluentd-h589k from kube-system started at 2019-05-13 16:27:54 +0000 UTC (1 container statuses recorded)
May 13 18:45:55.930: INFO: 	Container fluentd ready: true, restart count 0
May 13 18:45:55.930: INFO: 
Logging pods the kubelet thinks is on node 10.170.219.189 before test
May 13 18:45:55.964: INFO: public-cre5e67d863b8a419ba7a75a47352a70a9-alb1-785767687-vsp6l from kube-system started at 2019-05-13 16:32:34 +0000 UTC (4 container statuses recorded)
May 13 18:45:55.964: INFO: 	Container ingress-auth-1 ready: true, restart count 0
May 13 18:45:55.964: INFO: 	Container ingress-auth-2 ready: true, restart count 0
May 13 18:45:55.964: INFO: 	Container ingress-auth-3 ready: true, restart count 0
May 13 18:45:55.964: INFO: 	Container nginx-ingress ready: true, restart count 0
May 13 18:45:55.964: INFO: ibm-file-plugin-75d4cc8576-b74ft from kube-system started at 2019-05-13 16:26:35 +0000 UTC (1 container statuses recorded)
May 13 18:45:55.964: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
May 13 18:45:55.964: INFO: sonobuoy-systemd-logs-daemon-set-5d6538ccab344242-ss8mg from heptio-sonobuoy started at 2019-05-13 18:23:14 +0000 UTC (2 container statuses recorded)
May 13 18:45:55.964: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 13 18:45:55.964: INFO: 	Container systemd-logs ready: true, restart count 0
May 13 18:45:55.964: INFO: calico-kube-controllers-69f46f96c4-k8td8 from kube-system started at 2019-05-13 16:25:45 +0000 UTC (1 container statuses recorded)
May 13 18:45:55.964: INFO: 	Container calico-kube-controllers ready: true, restart count 0
May 13 18:45:55.964: INFO: calico-node-j8pbf from kube-system started at 2019-05-13 16:25:45 +0000 UTC (2 container statuses recorded)
May 13 18:45:55.964: INFO: 	Container calico-node ready: true, restart count 0
May 13 18:45:55.964: INFO: 	Container install-cni ready: true, restart count 0
May 13 18:45:55.964: INFO: ibm-master-proxy-static-10.170.219.189 from kube-system started at <nil> (0 container statuses recorded)
May 13 18:45:55.964: INFO: kubernetes-dashboard-b4bc7db5d-dg6mx from kube-system started at 2019-05-13 16:26:35 +0000 UTC (1 container statuses recorded)
May 13 18:45:55.964: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 13 18:45:55.964: INFO: vpn-7d87f64d5b-z7z6p from kube-system started at 2019-05-13 16:26:35 +0000 UTC (1 container statuses recorded)
May 13 18:45:55.964: INFO: 	Container vpn ready: true, restart count 0
May 13 18:45:55.964: INFO: kube-dns-amd64-fcdcf59c5-vvwwq from kube-system started at 2019-05-13 16:26:35 +0000 UTC (3 container statuses recorded)
May 13 18:45:55.964: INFO: 	Container dnsmasq ready: true, restart count 0
May 13 18:45:55.964: INFO: 	Container kubedns ready: true, restart count 0
May 13 18:45:55.964: INFO: 	Container sidecar ready: true, restart count 0
May 13 18:45:55.964: INFO: ibm-storage-watcher-7765979c55-x5cgd from kube-system started at 2019-05-13 16:26:35 +0000 UTC (1 container statuses recorded)
May 13 18:45:55.964: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
May 13 18:45:55.964: INFO: ibm-cloud-provider-ip-169-45-233-124-7fbd585f77-wfw6v from ibm-system started at 2019-05-13 16:27:29 +0000 UTC (1 container statuses recorded)
May 13 18:45:55.964: INFO: 	Container ibm-cloud-provider-ip-169-45-233-124 ready: true, restart count 0
May 13 18:45:55.964: INFO: ibm-kube-fluentd-dsrqr from kube-system started at 2019-05-13 16:27:54 +0000 UTC (1 container statuses recorded)
May 13 18:45:55.964: INFO: 	Container fluentd ready: true, restart count 0
May 13 18:45:55.964: INFO: ibm-keepalived-watcher-l5ss8 from kube-system started at 2019-05-13 16:25:45 +0000 UTC (1 container statuses recorded)
May 13 18:45:55.964: INFO: 	Container keepalived-watcher ready: true, restart count 0
May 13 18:45:55.964: INFO: kube-dns-autoscaler-587cd5cd44-mrpn9 from kube-system started at 2019-05-13 16:26:35 +0000 UTC (1 container statuses recorded)
May 13 18:45:55.964: INFO: 	Container autoscaler ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-58c228ac-75af-11e9-a09a-7e4d6cfcc771 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-58c228ac-75af-11e9-a09a-7e4d6cfcc771 off the node 10.170.219.140
STEP: verifying the node doesn't have the label kubernetes.io/e2e-58c228ac-75af-11e9-a09a-7e4d6cfcc771
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:46:02.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-jjw89" for this suite.
May 13 18:46:18.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:46:18.496: INFO: namespace: e2e-tests-sched-pred-jjw89, resource: bindings, ignored listing per whitelist
May 13 18:46:18.603: INFO: namespace e2e-tests-sched-pred-jjw89 deletion completed in 16.448903576s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:23.125 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:46:18.605: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-b2x66
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-jw5ff in namespace e2e-tests-proxy-b2x66
I0513 18:46:18.981239      16 runners.go:180] Created replication controller with name: proxy-service-jw5ff, namespace: e2e-tests-proxy-b2x66, replica count: 1
I0513 18:46:20.031806      16 runners.go:180] proxy-service-jw5ff Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0513 18:46:21.032015      16 runners.go:180] proxy-service-jw5ff Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0513 18:46:22.032296      16 runners.go:180] proxy-service-jw5ff Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0513 18:46:23.032568      16 runners.go:180] proxy-service-jw5ff Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0513 18:46:24.032741      16 runners.go:180] proxy-service-jw5ff Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0513 18:46:25.032993      16 runners.go:180] proxy-service-jw5ff Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0513 18:46:26.033280      16 runners.go:180] proxy-service-jw5ff Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0513 18:46:27.033623      16 runners.go:180] proxy-service-jw5ff Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0513 18:46:28.033925      16 runners.go:180] proxy-service-jw5ff Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0513 18:46:29.034288      16 runners.go:180] proxy-service-jw5ff Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0513 18:46:30.034607      16 runners.go:180] proxy-service-jw5ff Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0513 18:46:31.035135      16 runners.go:180] proxy-service-jw5ff Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 13 18:46:31.120: INFO: setup took 12.175485552s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
May 13 18:46:31.145: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 24.918523ms)
May 13 18:46:31.145: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname2/proxy/: bar (200; 25.523569ms)
May 13 18:46:31.145: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/... (200; 25.385413ms)
May 13 18:46:31.146: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 25.724861ms)
May 13 18:46:31.152: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:462/proxy/: tls qux (200; 32.533651ms)
May 13 18:46:31.159: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/rewri... (200; 39.367224ms)
May 13 18:46:31.159: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname1/proxy/: tls baz (200; 39.588835ms)
May 13 18:46:31.161: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 41.103833ms)
May 13 18:46:31.162: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 42.194383ms)
May 13 18:46:31.162: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname2/proxy/: bar (200; 42.514434ms)
May 13 18:46:31.162: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/rewriteme"... (200; 42.449281ms)
May 13 18:46:31.168: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname2/proxy/: tls qux (200; 47.955135ms)
May 13 18:46:31.168: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:460/proxy/: tls baz (200; 47.997236ms)
May 13 18:46:31.168: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname1/proxy/: foo (200; 48.176561ms)
May 13 18:46:31.168: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname1/proxy/: foo (200; 48.172426ms)
May 13 18:46:31.172: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/... (200; 52.272241ms)
May 13 18:46:31.185: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 12.677668ms)
May 13 18:46:31.188: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 16.151986ms)
May 13 18:46:31.189: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:460/proxy/: tls baz (200; 16.572918ms)
May 13 18:46:31.189: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/rewriteme"... (200; 16.457042ms)
May 13 18:46:31.189: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/... (200; 16.469637ms)
May 13 18:46:31.189: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/rewri... (200; 16.525997ms)
May 13 18:46:31.189: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 16.339132ms)
May 13 18:46:31.189: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 16.458949ms)
May 13 18:46:31.189: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:462/proxy/: tls qux (200; 16.330076ms)
May 13 18:46:31.193: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname2/proxy/: bar (200; 20.604349ms)
May 13 18:46:31.193: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname1/proxy/: tls baz (200; 20.842034ms)
May 13 18:46:31.193: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/... (200; 20.608337ms)
May 13 18:46:31.197: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname2/proxy/: bar (200; 24.301885ms)
May 13 18:46:31.197: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname1/proxy/: foo (200; 24.14715ms)
May 13 18:46:31.197: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname1/proxy/: foo (200; 24.373398ms)
May 13 18:46:31.197: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname2/proxy/: tls qux (200; 24.637348ms)
May 13 18:46:31.209: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 11.874487ms)
May 13 18:46:31.214: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:462/proxy/: tls qux (200; 16.430229ms)
May 13 18:46:31.214: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/rewriteme"... (200; 16.877695ms)
May 13 18:46:31.215: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 16.895129ms)
May 13 18:46:31.215: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/rewri... (200; 17.031086ms)
May 13 18:46:31.215: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 16.722182ms)
May 13 18:46:31.215: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/... (200; 16.67446ms)
May 13 18:46:31.215: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 16.561186ms)
May 13 18:46:31.215: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:460/proxy/: tls baz (200; 16.847537ms)
May 13 18:46:31.215: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/... (200; 16.821181ms)
May 13 18:46:31.217: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname2/proxy/: bar (200; 19.745526ms)
May 13 18:46:31.221: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname1/proxy/: tls baz (200; 23.249346ms)
May 13 18:46:31.221: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname1/proxy/: foo (200; 23.374698ms)
May 13 18:46:31.221: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname1/proxy/: foo (200; 23.601997ms)
May 13 18:46:31.221: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname2/proxy/: tls qux (200; 23.499494ms)
May 13 18:46:31.221: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname2/proxy/: bar (200; 23.417508ms)
May 13 18:46:31.233: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/rewri... (200; 11.263801ms)
May 13 18:46:31.237: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 15.087329ms)
May 13 18:46:31.237: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 15.766971ms)
May 13 18:46:31.237: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/rewriteme"... (200; 15.562691ms)
May 13 18:46:31.237: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/... (200; 15.512979ms)
May 13 18:46:31.237: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:462/proxy/: tls qux (200; 15.664404ms)
May 13 18:46:31.238: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 15.732479ms)
May 13 18:46:31.238: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 15.891083ms)
May 13 18:46:31.238: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/... (200; 16.125546ms)
May 13 18:46:31.238: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:460/proxy/: tls baz (200; 15.898946ms)
May 13 18:46:31.242: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname2/proxy/: bar (200; 20.518264ms)
May 13 18:46:31.242: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname1/proxy/: foo (200; 20.572447ms)
May 13 18:46:31.247: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname1/proxy/: tls baz (200; 25.609697ms)
May 13 18:46:31.248: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname1/proxy/: foo (200; 26.035078ms)
May 13 18:46:31.248: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname2/proxy/: tls qux (200; 26.103077ms)
May 13 18:46:31.248: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname2/proxy/: bar (200; 25.986781ms)
May 13 18:46:31.262: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 13.510877ms)
May 13 18:46:31.264: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 15.339238ms)
May 13 18:46:31.264: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:462/proxy/: tls qux (200; 14.787774ms)
May 13 18:46:31.268: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:460/proxy/: tls baz (200; 17.855056ms)
May 13 18:46:31.268: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 17.167324ms)
May 13 18:46:31.268: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/rewri... (200; 17.403798ms)
May 13 18:46:31.268: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/rewriteme"... (200; 17.409173ms)
May 13 18:46:31.268: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/... (200; 17.347502ms)
May 13 18:46:31.268: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 19.565964ms)
May 13 18:46:31.268: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/... (200; 17.329036ms)
May 13 18:46:31.269: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname1/proxy/: foo (200; 20.098534ms)
May 13 18:46:31.274: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname1/proxy/: tls baz (200; 22.746531ms)
May 13 18:46:31.274: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname1/proxy/: foo (200; 25.971916ms)
May 13 18:46:31.274: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname2/proxy/: tls qux (200; 25.146867ms)
May 13 18:46:31.275: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname2/proxy/: bar (200; 23.884837ms)
May 13 18:46:31.276: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname2/proxy/: bar (200; 24.794124ms)
May 13 18:46:31.293: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 16.94872ms)
May 13 18:46:31.297: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/... (200; 20.688942ms)
May 13 18:46:31.298: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:462/proxy/: tls qux (200; 20.927741ms)
May 13 18:46:31.298: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 21.893969ms)
May 13 18:46:31.299: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:460/proxy/: tls baz (200; 23.145816ms)
May 13 18:46:31.300: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 23.297494ms)
May 13 18:46:31.300: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/rewriteme"... (200; 23.068201ms)
May 13 18:46:31.300: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/rewri... (200; 23.507495ms)
May 13 18:46:31.300: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 23.279167ms)
May 13 18:46:31.300: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/... (200; 23.049635ms)
May 13 18:46:31.303: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname2/proxy/: tls qux (200; 26.38734ms)
May 13 18:46:31.307: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname1/proxy/: foo (200; 30.659846ms)
May 13 18:46:31.307: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname2/proxy/: bar (200; 30.444789ms)
May 13 18:46:31.308: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname1/proxy/: tls baz (200; 32.097385ms)
May 13 18:46:31.308: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname1/proxy/: foo (200; 31.418189ms)
May 13 18:46:31.308: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname2/proxy/: bar (200; 32.251398ms)
May 13 18:46:31.325: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/... (200; 16.275571ms)
May 13 18:46:31.325: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/rewriteme"... (200; 16.888517ms)
May 13 18:46:31.326: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:460/proxy/: tls baz (200; 17.332884ms)
May 13 18:46:31.326: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/... (200; 17.066042ms)
May 13 18:46:31.326: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 16.761328ms)
May 13 18:46:31.326: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:462/proxy/: tls qux (200; 17.451858ms)
May 13 18:46:31.326: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/rewri... (200; 17.182106ms)
May 13 18:46:31.326: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 17.312202ms)
May 13 18:46:31.326: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 17.230104ms)
May 13 18:46:31.329: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 19.630205ms)
May 13 18:46:31.330: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname2/proxy/: bar (200; 21.361538ms)
May 13 18:46:31.333: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname2/proxy/: tls qux (200; 23.975158ms)
May 13 18:46:31.333: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname2/proxy/: bar (200; 23.888872ms)
May 13 18:46:31.333: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname1/proxy/: foo (200; 24.347105ms)
May 13 18:46:31.333: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname1/proxy/: tls baz (200; 24.002789ms)
May 13 18:46:31.333: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname1/proxy/: foo (200; 24.117535ms)
May 13 18:46:31.346: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 13.114026ms)
May 13 18:46:31.346: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 13.017052ms)
May 13 18:46:31.349: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:460/proxy/: tls baz (200; 15.347654ms)
May 13 18:46:31.349: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/... (200; 14.869844ms)
May 13 18:46:31.350: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 15.84025ms)
May 13 18:46:31.350: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/rewri... (200; 16.154089ms)
May 13 18:46:31.353: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/rewriteme"... (200; 18.752821ms)
May 13 18:46:31.353: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/... (200; 19.177141ms)
May 13 18:46:31.353: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:462/proxy/: tls qux (200; 19.141155ms)
May 13 18:46:31.353: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 19.426762ms)
May 13 18:46:31.357: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname1/proxy/: foo (200; 22.525087ms)
May 13 18:46:31.357: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname2/proxy/: bar (200; 23.420038ms)
May 13 18:46:31.357: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname1/proxy/: foo (200; 23.077713ms)
May 13 18:46:31.357: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname1/proxy/: tls baz (200; 23.357344ms)
May 13 18:46:31.357: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname2/proxy/: tls qux (200; 22.512637ms)
May 13 18:46:31.359: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname2/proxy/: bar (200; 24.277007ms)
May 13 18:46:31.377: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 17.822058ms)
May 13 18:46:31.377: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/... (200; 17.863418ms)
May 13 18:46:31.377: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/rewri... (200; 17.911707ms)
May 13 18:46:31.377: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/... (200; 18.147095ms)
May 13 18:46:31.377: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 18.063166ms)
May 13 18:46:31.377: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:462/proxy/: tls qux (200; 18.404329ms)
May 13 18:46:31.377: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 18.519894ms)
May 13 18:46:31.377: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:460/proxy/: tls baz (200; 18.647837ms)
May 13 18:46:31.379: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/rewriteme"... (200; 20.542847ms)
May 13 18:46:31.379: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 20.786215ms)
May 13 18:46:31.381: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname2/proxy/: bar (200; 21.816727ms)
May 13 18:46:31.382: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname1/proxy/: foo (200; 23.61361ms)
May 13 18:46:31.383: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname2/proxy/: tls qux (200; 23.965366ms)
May 13 18:46:31.383: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname2/proxy/: bar (200; 24.115803ms)
May 13 18:46:31.383: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname1/proxy/: tls baz (200; 24.122634ms)
May 13 18:46:31.383: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname1/proxy/: foo (200; 24.436777ms)
May 13 18:46:31.401: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 17.491295ms)
May 13 18:46:31.401: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 17.34324ms)
May 13 18:46:31.401: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 17.450971ms)
May 13 18:46:31.401: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/rewri... (200; 16.954712ms)
May 13 18:46:31.401: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/rewriteme"... (200; 16.942425ms)
May 13 18:46:31.401: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:462/proxy/: tls qux (200; 16.826417ms)
May 13 18:46:31.401: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:460/proxy/: tls baz (200; 17.349305ms)
May 13 18:46:31.401: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 17.140428ms)
May 13 18:46:31.401: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/... (200; 16.948494ms)
May 13 18:46:31.401: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/... (200; 17.0116ms)
May 13 18:46:31.404: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname1/proxy/: foo (200; 20.506515ms)
May 13 18:46:31.407: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname2/proxy/: bar (200; 22.767296ms)
May 13 18:46:31.407: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname2/proxy/: bar (200; 23.198126ms)
May 13 18:46:31.407: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname1/proxy/: tls baz (200; 23.379757ms)
May 13 18:46:31.408: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname1/proxy/: foo (200; 23.553249ms)
May 13 18:46:31.408: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname2/proxy/: tls qux (200; 23.549245ms)
May 13 18:46:31.423: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/... (200; 15.204653ms)
May 13 18:46:31.424: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 15.57912ms)
May 13 18:46:31.424: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 15.659835ms)
May 13 18:46:31.424: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/rewri... (200; 15.835834ms)
May 13 18:46:31.424: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/rewriteme"... (200; 16.226976ms)
May 13 18:46:31.424: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 16.376902ms)
May 13 18:46:31.425: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/... (200; 16.68177ms)
May 13 18:46:31.425: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:462/proxy/: tls qux (200; 17.078526ms)
May 13 18:46:31.425: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 16.959729ms)
May 13 18:46:31.425: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:460/proxy/: tls baz (200; 16.941238ms)
May 13 18:46:31.427: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname1/proxy/: foo (200; 19.477388ms)
May 13 18:46:31.430: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname2/proxy/: tls qux (200; 22.099744ms)
May 13 18:46:31.430: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname1/proxy/: foo (200; 22.07399ms)
May 13 18:46:31.430: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname1/proxy/: tls baz (200; 22.122664ms)
May 13 18:46:31.430: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname2/proxy/: bar (200; 22.079622ms)
May 13 18:46:31.430: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname2/proxy/: bar (200; 21.937095ms)
May 13 18:46:31.442: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 11.845541ms)
May 13 18:46:31.447: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/... (200; 16.332576ms)
May 13 18:46:31.447: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/rewriteme"... (200; 16.231635ms)
May 13 18:46:31.447: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 16.441693ms)
May 13 18:46:31.447: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/... (200; 16.252736ms)
May 13 18:46:31.447: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 16.477984ms)
May 13 18:46:31.447: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:460/proxy/: tls baz (200; 16.678107ms)
May 13 18:46:31.447: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:462/proxy/: tls qux (200; 16.451019ms)
May 13 18:46:31.447: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 16.580658ms)
May 13 18:46:31.447: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/rewri... (200; 16.667571ms)
May 13 18:46:31.450: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname1/proxy/: foo (200; 19.572122ms)
May 13 18:46:31.454: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname2/proxy/: bar (200; 23.145577ms)
May 13 18:46:31.454: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname1/proxy/: tls baz (200; 23.12859ms)
May 13 18:46:31.454: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname2/proxy/: tls qux (200; 23.136661ms)
May 13 18:46:31.454: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname2/proxy/: bar (200; 23.330884ms)
May 13 18:46:31.454: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname1/proxy/: foo (200; 23.393916ms)
May 13 18:46:31.471: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:460/proxy/: tls baz (200; 16.496525ms)
May 13 18:46:31.471: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:462/proxy/: tls qux (200; 15.105495ms)
May 13 18:46:31.471: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 15.932805ms)
May 13 18:46:31.471: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/... (200; 16.121502ms)
May 13 18:46:31.471: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 17.17493ms)
May 13 18:46:31.471: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/rewri... (200; 16.750245ms)
May 13 18:46:31.471: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/rewriteme"... (200; 15.994449ms)
May 13 18:46:31.471: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 16.622586ms)
May 13 18:46:31.472: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/... (200; 16.23414ms)
May 13 18:46:31.472: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 17.033045ms)
May 13 18:46:31.474: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname2/proxy/: bar (200; 19.575998ms)
May 13 18:46:31.478: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname1/proxy/: tls baz (200; 23.871763ms)
May 13 18:46:31.478: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname1/proxy/: foo (200; 23.611554ms)
May 13 18:46:31.478: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname1/proxy/: foo (200; 22.866602ms)
May 13 18:46:31.479: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname2/proxy/: bar (200; 23.423331ms)
May 13 18:46:31.479: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname2/proxy/: tls qux (200; 23.133778ms)
May 13 18:46:31.490: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/... (200; 11.292286ms)
May 13 18:46:31.495: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 15.930774ms)
May 13 18:46:31.495: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/rewri... (200; 15.792242ms)
May 13 18:46:31.495: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:462/proxy/: tls qux (200; 16.073772ms)
May 13 18:46:31.495: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/... (200; 16.186621ms)
May 13 18:46:31.496: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/rewriteme"... (200; 16.398105ms)
May 13 18:46:31.496: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 16.535978ms)
May 13 18:46:31.496: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 16.310235ms)
May 13 18:46:31.496: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 16.895533ms)
May 13 18:46:31.496: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:460/proxy/: tls baz (200; 17.034367ms)
May 13 18:46:31.498: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname2/proxy/: tls qux (200; 19.460388ms)
May 13 18:46:31.501: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname1/proxy/: foo (200; 21.725827ms)
May 13 18:46:31.501: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname1/proxy/: foo (200; 22.172069ms)
May 13 18:46:31.501: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname2/proxy/: bar (200; 22.398173ms)
May 13 18:46:31.501: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname1/proxy/: tls baz (200; 22.217103ms)
May 13 18:46:31.502: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname2/proxy/: bar (200; 22.939016ms)
May 13 18:46:31.513: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/rewriteme"... (200; 11.2545ms)
May 13 18:46:31.516: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 13.967636ms)
May 13 18:46:31.517: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 14.179082ms)
May 13 18:46:31.517: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/... (200; 14.129423ms)
May 13 18:46:31.517: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 14.156172ms)
May 13 18:46:31.517: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/rewri... (200; 14.569014ms)
May 13 18:46:31.517: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:462/proxy/: tls qux (200; 14.601627ms)
May 13 18:46:31.517: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/... (200; 14.798417ms)
May 13 18:46:31.517: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:460/proxy/: tls baz (200; 14.772143ms)
May 13 18:46:31.519: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 17.098665ms)
May 13 18:46:31.523: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname1/proxy/: tls baz (200; 20.638365ms)
May 13 18:46:31.523: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname1/proxy/: foo (200; 20.794047ms)
May 13 18:46:31.523: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname2/proxy/: bar (200; 20.682608ms)
May 13 18:46:31.527: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname2/proxy/: tls qux (200; 24.190363ms)
May 13 18:46:31.527: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname1/proxy/: foo (200; 24.256001ms)
May 13 18:46:31.527: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname2/proxy/: bar (200; 24.432853ms)
May 13 18:46:31.539: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 12.342598ms)
May 13 18:46:31.545: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:462/proxy/: tls qux (200; 18.259544ms)
May 13 18:46:31.545: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/rewri... (200; 18.099988ms)
May 13 18:46:31.545: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/rewriteme"... (200; 18.33523ms)
May 13 18:46:31.545: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/... (200; 18.419518ms)
May 13 18:46:31.545: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/... (200; 18.400996ms)
May 13 18:46:31.545: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 18.217878ms)
May 13 18:46:31.545: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:460/proxy/: tls baz (200; 18.1866ms)
May 13 18:46:31.545: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 18.294215ms)
May 13 18:46:31.545: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 18.289541ms)
May 13 18:46:31.547: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname1/proxy/: foo (200; 19.987554ms)
May 13 18:46:31.553: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname1/proxy/: tls baz (200; 25.846958ms)
May 13 18:46:31.557: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname1/proxy/: foo (200; 29.662221ms)
May 13 18:46:31.557: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname2/proxy/: tls qux (200; 29.594261ms)
May 13 18:46:31.557: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname2/proxy/: bar (200; 29.96176ms)
May 13 18:46:31.557: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname2/proxy/: bar (200; 30.114642ms)
May 13 18:46:31.571: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/... (200; 13.063519ms)
May 13 18:46:31.575: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/... (200; 17.808426ms)
May 13 18:46:31.575: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:460/proxy/: tls baz (200; 18.03996ms)
May 13 18:46:31.575: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 18.202412ms)
May 13 18:46:31.575: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 18.14329ms)
May 13 18:46:31.576: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:462/proxy/: tls qux (200; 18.264896ms)
May 13 18:46:31.576: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 18.268692ms)
May 13 18:46:31.576: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 18.141801ms)
May 13 18:46:31.576: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/rewriteme"... (200; 18.162615ms)
May 13 18:46:31.576: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/rewri... (200; 18.204108ms)
May 13 18:46:31.580: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname2/proxy/: bar (200; 23.016149ms)
May 13 18:46:31.584: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname1/proxy/: foo (200; 26.734851ms)
May 13 18:46:31.584: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname2/proxy/: bar (200; 26.675999ms)
May 13 18:46:31.584: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname1/proxy/: tls baz (200; 26.677572ms)
May 13 18:46:31.584: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname1/proxy/: foo (200; 26.907578ms)
May 13 18:46:31.584: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname2/proxy/: tls qux (200; 26.879406ms)
May 13 18:46:31.596: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 11.25026ms)
May 13 18:46:31.600: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/... (200; 15.392989ms)
May 13 18:46:31.601: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 16.190508ms)
May 13 18:46:31.602: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/... (200; 17.337987ms)
May 13 18:46:31.602: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/rewriteme"... (200; 17.204188ms)
May 13 18:46:31.602: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:462/proxy/: tls qux (200; 17.482864ms)
May 13 18:46:31.602: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 17.30989ms)
May 13 18:46:31.602: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 17.380451ms)
May 13 18:46:31.602: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/rewri... (200; 17.45696ms)
May 13 18:46:31.602: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:460/proxy/: tls baz (200; 17.706815ms)
May 13 18:46:31.607: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname2/proxy/: tls qux (200; 22.11083ms)
May 13 18:46:31.607: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname1/proxy/: foo (200; 22.037242ms)
May 13 18:46:31.608: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname1/proxy/: foo (200; 23.899593ms)
May 13 18:46:31.608: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname2/proxy/: bar (200; 24.003416ms)
May 13 18:46:31.608: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname1/proxy/: tls baz (200; 24.017037ms)
May 13 18:46:31.609: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname2/proxy/: bar (200; 24.002255ms)
May 13 18:46:31.621: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:460/proxy/: tls baz (200; 12.386817ms)
May 13 18:46:31.625: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 16.323561ms)
May 13 18:46:31.625: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/rewri... (200; 16.212904ms)
May 13 18:46:31.626: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 16.986462ms)
May 13 18:46:31.626: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:462/proxy/: tls qux (200; 16.928165ms)
May 13 18:46:31.626: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 16.740968ms)
May 13 18:46:31.626: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/... (200; 16.867479ms)
May 13 18:46:31.626: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/rewriteme"... (200; 16.998916ms)
May 13 18:46:31.626: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/... (200; 17.238113ms)
May 13 18:46:31.628: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 19.258569ms)
May 13 18:46:31.633: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname2/proxy/: bar (200; 23.710404ms)
May 13 18:46:31.633: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname1/proxy/: foo (200; 23.883616ms)
May 13 18:46:31.633: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname1/proxy/: foo (200; 23.827279ms)
May 13 18:46:31.633: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname2/proxy/: bar (200; 23.801954ms)
May 13 18:46:31.633: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname1/proxy/: tls baz (200; 23.786341ms)
May 13 18:46:31.633: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname2/proxy/: tls qux (200; 24.167714ms)
May 13 18:46:31.648: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:1080/proxy/rewri... (200; 15.14744ms)
May 13 18:46:31.648: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 15.014336ms)
May 13 18:46:31.649: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:160/proxy/: foo (200; 15.629598ms)
May 13 18:46:31.649: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t/proxy/rewriteme"... (200; 15.36808ms)
May 13 18:46:31.649: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:443/proxy/... (200; 15.401661ms)
May 13 18:46:31.649: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:460/proxy/: tls baz (200; 15.461577ms)
May 13 18:46:31.649: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 15.855079ms)
May 13 18:46:31.649: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:1080/proxy/... (200; 15.709691ms)
May 13 18:46:31.649: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/https:proxy-service-jw5ff-2jg5t:462/proxy/: tls qux (200; 15.983159ms)
May 13 18:46:31.649: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b2x66/pods/http:proxy-service-jw5ff-2jg5t:162/proxy/: bar (200; 16.049648ms)
May 13 18:46:31.653: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname2/proxy/: bar (200; 19.801538ms)
May 13 18:46:31.654: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname1/proxy/: foo (200; 20.52702ms)
May 13 18:46:31.654: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname1/proxy/: tls baz (200; 20.582401ms)
May 13 18:46:31.654: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/http:proxy-service-jw5ff:portname1/proxy/: foo (200; 21.090773ms)
May 13 18:46:31.655: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/https:proxy-service-jw5ff:tlsportname2/proxy/: tls qux (200; 21.33128ms)
May 13 18:46:31.655: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b2x66/services/proxy-service-jw5ff:portname2/proxy/: bar (200; 21.151096ms)
STEP: deleting { ReplicationController} proxy-service-jw5ff in namespace e2e-tests-proxy-b2x66, will wait for the garbage collector to delete the pods
May 13 18:46:31.733: INFO: Deleting { ReplicationController} proxy-service-jw5ff took: 20.485628ms
May 13 18:46:31.833: INFO: Terminating { ReplicationController} proxy-service-jw5ff pods took: 100.227012ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:46:37.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-b2x66" for this suite.
May 13 18:46:43.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:46:43.587: INFO: namespace: e2e-tests-proxy-b2x66, resource: bindings, ignored listing per whitelist
May 13 18:46:43.682: INFO: namespace e2e-tests-proxy-b2x66 deletion completed in 6.534927133s

• [SLOW TEST:25.077 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:46:43.682: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-gnw7r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
May 13 18:46:43.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 create -f - --namespace=e2e-tests-kubectl-gnw7r'
May 13 18:46:44.401: INFO: stderr: ""
May 13 18:46:44.401: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
May 13 18:46:45.412: INFO: Selector matched 1 pods for map[app:redis]
May 13 18:46:45.412: INFO: Found 0 / 1
May 13 18:46:46.412: INFO: Selector matched 1 pods for map[app:redis]
May 13 18:46:46.412: INFO: Found 1 / 1
May 13 18:46:46.412: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
May 13 18:46:46.420: INFO: Selector matched 1 pods for map[app:redis]
May 13 18:46:46.420: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 13 18:46:46.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 patch pod redis-master-f5xhj --namespace=e2e-tests-kubectl-gnw7r -p {"metadata":{"annotations":{"x":"y"}}}'
May 13 18:46:46.608: INFO: stderr: ""
May 13 18:46:46.608: INFO: stdout: "pod/redis-master-f5xhj patched\n"
STEP: checking annotations
May 13 18:46:46.619: INFO: Selector matched 1 pods for map[app:redis]
May 13 18:46:46.619: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:46:46.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gnw7r" for this suite.
May 13 18:47:02.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:47:02.998: INFO: namespace: e2e-tests-kubectl-gnw7r, resource: bindings, ignored listing per whitelist
May 13 18:47:03.104: INFO: namespace e2e-tests-kubectl-gnw7r deletion completed in 16.471811442s

• [SLOW TEST:19.422 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:47:03.105: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-8dsxp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
May 13 18:47:03.428: INFO: Waiting up to 5m0s for pod "var-expansion-7fb981e2-75af-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-var-expansion-8dsxp" to be "success or failure"
May 13 18:47:03.436: INFO: Pod "var-expansion-7fb981e2-75af-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 8.176939ms
May 13 18:47:05.446: INFO: Pod "var-expansion-7fb981e2-75af-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017477952s
STEP: Saw pod success
May 13 18:47:05.446: INFO: Pod "var-expansion-7fb981e2-75af-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:47:05.454: INFO: Trying to get logs from node 10.170.219.140 pod var-expansion-7fb981e2-75af-11e9-a09a-7e4d6cfcc771 container dapi-container: <nil>
STEP: delete the pod
May 13 18:47:05.515: INFO: Waiting for pod var-expansion-7fb981e2-75af-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:47:05.523: INFO: Pod var-expansion-7fb981e2-75af-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:47:05.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-8dsxp" for this suite.
May 13 18:47:11.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:47:11.683: INFO: namespace: e2e-tests-var-expansion-8dsxp, resource: bindings, ignored listing per whitelist
May 13 18:47:11.899: INFO: namespace e2e-tests-var-expansion-8dsxp deletion completed in 6.366140486s

• [SLOW TEST:8.794 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:47:11.900: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-4frgh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
May 13 18:47:12.239: INFO: namespace e2e-tests-kubectl-4frgh
May 13 18:47:12.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 create -f - --namespace=e2e-tests-kubectl-4frgh'
May 13 18:47:12.555: INFO: stderr: ""
May 13 18:47:12.555: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
May 13 18:47:13.579: INFO: Selector matched 1 pods for map[app:redis]
May 13 18:47:13.579: INFO: Found 0 / 1
May 13 18:47:14.565: INFO: Selector matched 1 pods for map[app:redis]
May 13 18:47:14.565: INFO: Found 1 / 1
May 13 18:47:14.565: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 13 18:47:14.574: INFO: Selector matched 1 pods for map[app:redis]
May 13 18:47:14.574: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 13 18:47:14.574: INFO: wait on redis-master startup in e2e-tests-kubectl-4frgh 
May 13 18:47:14.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 logs redis-master-9wtx5 redis-master --namespace=e2e-tests-kubectl-4frgh'
May 13 18:47:14.774: INFO: stderr: ""
May 13 18:47:14.774: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 13 May 18:47:13.728 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 13 May 18:47:13.728 # Server started, Redis version 3.2.12\n1:M 13 May 18:47:13.728 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 13 May 18:47:13.729 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
May 13 18:47:14.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-4frgh'
May 13 18:47:14.923: INFO: stderr: ""
May 13 18:47:14.923: INFO: stdout: "service/rm2 exposed\n"
May 13 18:47:14.934: INFO: Service rm2 in namespace e2e-tests-kubectl-4frgh found.
STEP: exposing service
May 13 18:47:16.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-4frgh'
May 13 18:47:17.143: INFO: stderr: ""
May 13 18:47:17.143: INFO: stdout: "service/rm3 exposed\n"
May 13 18:47:17.151: INFO: Service rm3 in namespace e2e-tests-kubectl-4frgh found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:47:19.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4frgh" for this suite.
May 13 18:47:43.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:47:43.506: INFO: namespace: e2e-tests-kubectl-4frgh, resource: bindings, ignored listing per whitelist
May 13 18:47:43.554: INFO: namespace e2e-tests-kubectl-4frgh deletion completed in 24.30260778s

• [SLOW TEST:31.655 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:47:43.555: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-dr42n
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-dr42n/secret-test-97d371b5-75af-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume secrets
May 13 18:47:43.874: INFO: Waiting up to 5m0s for pod "pod-configmaps-97d4f9ca-75af-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-secrets-dr42n" to be "success or failure"
May 13 18:47:43.883: INFO: Pod "pod-configmaps-97d4f9ca-75af-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 8.855537ms
May 13 18:47:46.084: INFO: Pod "pod-configmaps-97d4f9ca-75af-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 2.210412907s
May 13 18:47:48.110: INFO: Pod "pod-configmaps-97d4f9ca-75af-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.236482424s
STEP: Saw pod success
May 13 18:47:48.110: INFO: Pod "pod-configmaps-97d4f9ca-75af-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:47:48.119: INFO: Trying to get logs from node 10.170.219.140 pod pod-configmaps-97d4f9ca-75af-11e9-a09a-7e4d6cfcc771 container env-test: <nil>
STEP: delete the pod
May 13 18:47:48.165: INFO: Waiting for pod pod-configmaps-97d4f9ca-75af-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:47:48.173: INFO: Pod pod-configmaps-97d4f9ca-75af-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:47:48.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-dr42n" for this suite.
May 13 18:47:54.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:47:54.441: INFO: namespace: e2e-tests-secrets-dr42n, resource: bindings, ignored listing per whitelist
May 13 18:47:54.499: INFO: namespace e2e-tests-secrets-dr42n deletion completed in 6.315498908s

• [SLOW TEST:10.945 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:47:54.500: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-dtdqq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 13 18:47:54.905: INFO: Number of nodes with available pods: 0
May 13 18:47:54.905: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:47:55.925: INFO: Number of nodes with available pods: 0
May 13 18:47:55.925: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:47:56.963: INFO: Number of nodes with available pods: 3
May 13 18:47:56.963: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
May 13 18:47:57.015: INFO: Number of nodes with available pods: 2
May 13 18:47:57.015: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:47:58.039: INFO: Number of nodes with available pods: 2
May 13 18:47:58.040: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:47:59.053: INFO: Number of nodes with available pods: 2
May 13 18:47:59.053: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:00.035: INFO: Number of nodes with available pods: 2
May 13 18:48:00.035: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:01.035: INFO: Number of nodes with available pods: 2
May 13 18:48:01.035: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:02.038: INFO: Number of nodes with available pods: 2
May 13 18:48:02.038: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:03.050: INFO: Number of nodes with available pods: 2
May 13 18:48:03.051: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:04.035: INFO: Number of nodes with available pods: 2
May 13 18:48:04.035: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:05.050: INFO: Number of nodes with available pods: 2
May 13 18:48:05.050: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:06.046: INFO: Number of nodes with available pods: 2
May 13 18:48:06.046: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:07.035: INFO: Number of nodes with available pods: 2
May 13 18:48:07.035: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:08.035: INFO: Number of nodes with available pods: 2
May 13 18:48:08.035: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:09.064: INFO: Number of nodes with available pods: 2
May 13 18:48:09.064: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:10.035: INFO: Number of nodes with available pods: 2
May 13 18:48:10.035: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:11.038: INFO: Number of nodes with available pods: 2
May 13 18:48:11.038: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:12.045: INFO: Number of nodes with available pods: 2
May 13 18:48:12.045: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:13.050: INFO: Number of nodes with available pods: 2
May 13 18:48:13.050: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:14.035: INFO: Number of nodes with available pods: 2
May 13 18:48:14.035: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:15.038: INFO: Number of nodes with available pods: 2
May 13 18:48:15.038: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:16.050: INFO: Number of nodes with available pods: 2
May 13 18:48:16.050: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:17.037: INFO: Number of nodes with available pods: 2
May 13 18:48:17.037: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:18.035: INFO: Number of nodes with available pods: 2
May 13 18:48:18.035: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:19.041: INFO: Number of nodes with available pods: 2
May 13 18:48:19.041: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:20.049: INFO: Number of nodes with available pods: 2
May 13 18:48:20.049: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:21.035: INFO: Number of nodes with available pods: 2
May 13 18:48:21.035: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:22.035: INFO: Number of nodes with available pods: 2
May 13 18:48:22.035: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:23.039: INFO: Number of nodes with available pods: 2
May 13 18:48:23.039: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:24.042: INFO: Number of nodes with available pods: 2
May 13 18:48:24.042: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:25.037: INFO: Number of nodes with available pods: 2
May 13 18:48:25.037: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:26.058: INFO: Number of nodes with available pods: 2
May 13 18:48:26.058: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:27.038: INFO: Number of nodes with available pods: 2
May 13 18:48:27.038: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:28.035: INFO: Number of nodes with available pods: 2
May 13 18:48:28.035: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:29.035: INFO: Number of nodes with available pods: 2
May 13 18:48:29.036: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:30.150: INFO: Number of nodes with available pods: 2
May 13 18:48:30.150: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:31.036: INFO: Number of nodes with available pods: 2
May 13 18:48:31.036: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:32.035: INFO: Number of nodes with available pods: 2
May 13 18:48:32.035: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:33.035: INFO: Number of nodes with available pods: 2
May 13 18:48:33.035: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:34.034: INFO: Number of nodes with available pods: 2
May 13 18:48:34.034: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:35.040: INFO: Number of nodes with available pods: 2
May 13 18:48:35.040: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:36.036: INFO: Number of nodes with available pods: 2
May 13 18:48:36.036: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:37.063: INFO: Number of nodes with available pods: 2
May 13 18:48:37.063: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:38.048: INFO: Number of nodes with available pods: 2
May 13 18:48:38.048: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:48:39.034: INFO: Number of nodes with available pods: 3
May 13 18:48:39.034: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-dtdqq, will wait for the garbage collector to delete the pods
May 13 18:48:39.118: INFO: Deleting {extensions DaemonSet} daemon-set took: 17.689341ms
May 13 18:48:39.318: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 200.201131ms
May 13 18:49:17.140: INFO: Number of nodes with available pods: 0
May 13 18:49:17.140: INFO: Number of running nodes: 0, number of available pods: 0
May 13 18:49:17.149: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-dtdqq/daemonsets","resourceVersion":"36596"},"items":null}

May 13 18:49:17.156: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-dtdqq/pods","resourceVersion":"36596"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:49:17.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-dtdqq" for this suite.
May 13 18:49:23.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:49:23.405: INFO: namespace: e2e-tests-daemonsets-dtdqq, resource: bindings, ignored listing per whitelist
May 13 18:49:23.485: INFO: namespace e2e-tests-daemonsets-dtdqq deletion completed in 6.287136887s

• [SLOW TEST:88.985 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:49:23.485: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-5l7wr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 18:49:23.904: INFO: (0) /api/v1/nodes/10.170.219.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 112.729522ms)
May 13 18:49:23.916: INFO: (1) /api/v1/nodes/10.170.219.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 11.750844ms)
May 13 18:49:23.928: INFO: (2) /api/v1/nodes/10.170.219.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 11.352704ms)
May 13 18:49:23.939: INFO: (3) /api/v1/nodes/10.170.219.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 11.370749ms)
May 13 18:49:23.951: INFO: (4) /api/v1/nodes/10.170.219.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 11.76283ms)
May 13 18:49:23.964: INFO: (5) /api/v1/nodes/10.170.219.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 13.28089ms)
May 13 18:49:23.976: INFO: (6) /api/v1/nodes/10.170.219.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 11.696702ms)
May 13 18:49:23.987: INFO: (7) /api/v1/nodes/10.170.219.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 11.564772ms)
May 13 18:49:24.006: INFO: (8) /api/v1/nodes/10.170.219.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 18.149993ms)
May 13 18:49:24.018: INFO: (9) /api/v1/nodes/10.170.219.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 11.9887ms)
May 13 18:49:24.030: INFO: (10) /api/v1/nodes/10.170.219.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 12.011645ms)
May 13 18:49:24.046: INFO: (11) /api/v1/nodes/10.170.219.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.46546ms)
May 13 18:49:24.058: INFO: (12) /api/v1/nodes/10.170.219.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 12.286025ms)
May 13 18:49:24.070: INFO: (13) /api/v1/nodes/10.170.219.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 11.563286ms)
May 13 18:49:24.082: INFO: (14) /api/v1/nodes/10.170.219.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 11.791815ms)
May 13 18:49:24.095: INFO: (15) /api/v1/nodes/10.170.219.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 13.372466ms)
May 13 18:49:24.107: INFO: (16) /api/v1/nodes/10.170.219.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 11.817052ms)
May 13 18:49:24.120: INFO: (17) /api/v1/nodes/10.170.219.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 12.710966ms)
May 13 18:49:24.132: INFO: (18) /api/v1/nodes/10.170.219.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 11.935327ms)
May 13 18:49:24.143: INFO: (19) /api/v1/nodes/10.170.219.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 11.527988ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:49:24.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-5l7wr" for this suite.
May 13 18:49:30.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:49:30.457: INFO: namespace: e2e-tests-proxy-5l7wr, resource: bindings, ignored listing per whitelist
May 13 18:49:30.723: INFO: namespace e2e-tests-proxy-5l7wr deletion completed in 6.571120902s

• [SLOW TEST:7.237 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:49:30.723: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-5dg64
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-d7b2e5ea-75af-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume configMaps
May 13 18:49:31.034: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d7b44da5-75af-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-projected-5dg64" to be "success or failure"
May 13 18:49:31.042: INFO: Pod "pod-projected-configmaps-d7b44da5-75af-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 8.629823ms
May 13 18:49:33.051: INFO: Pod "pod-projected-configmaps-d7b44da5-75af-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017302664s
STEP: Saw pod success
May 13 18:49:33.051: INFO: Pod "pod-projected-configmaps-d7b44da5-75af-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:49:33.059: INFO: Trying to get logs from node 10.170.219.140 pod pod-projected-configmaps-d7b44da5-75af-11e9-a09a-7e4d6cfcc771 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 13 18:49:33.103: INFO: Waiting for pod pod-projected-configmaps-d7b44da5-75af-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:49:33.149: INFO: Pod pod-projected-configmaps-d7b44da5-75af-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:49:33.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5dg64" for this suite.
May 13 18:49:39.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:49:39.499: INFO: namespace: e2e-tests-projected-5dg64, resource: bindings, ignored listing per whitelist
May 13 18:49:39.596: INFO: namespace e2e-tests-projected-5dg64 deletion completed in 6.435239974s

• [SLOW TEST:8.873 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:49:39.596: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-8zfwx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 18:49:39.965: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dd06db14-75af-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-projected-8zfwx" to be "success or failure"
May 13 18:49:39.973: INFO: Pod "downwardapi-volume-dd06db14-75af-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 8.320438ms
May 13 18:49:41.982: INFO: Pod "downwardapi-volume-dd06db14-75af-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017059529s
STEP: Saw pod success
May 13 18:49:41.982: INFO: Pod "downwardapi-volume-dd06db14-75af-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:49:41.990: INFO: Trying to get logs from node 10.170.219.140 pod downwardapi-volume-dd06db14-75af-11e9-a09a-7e4d6cfcc771 container client-container: <nil>
STEP: delete the pod
May 13 18:49:42.047: INFO: Waiting for pod downwardapi-volume-dd06db14-75af-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:49:42.055: INFO: Pod downwardapi-volume-dd06db14-75af-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:49:42.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8zfwx" for this suite.
May 13 18:49:48.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:49:48.139: INFO: namespace: e2e-tests-projected-8zfwx, resource: bindings, ignored listing per whitelist
May 13 18:49:48.393: INFO: namespace e2e-tests-projected-8zfwx deletion completed in 6.327629068s

• [SLOW TEST:8.798 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:49:48.394: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-jfgb4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 13 18:49:51.283: INFO: Successfully updated pod "pod-update-activedeadlineseconds-e23cb316-75af-11e9-a09a-7e4d6cfcc771"
May 13 18:49:51.283: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-e23cb316-75af-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-pods-jfgb4" to be "terminated due to deadline exceeded"
May 13 18:49:51.291: INFO: Pod "pod-update-activedeadlineseconds-e23cb316-75af-11e9-a09a-7e4d6cfcc771": Phase="Running", Reason="", readiness=true. Elapsed: 8.052611ms
May 13 18:49:53.300: INFO: Pod "pod-update-activedeadlineseconds-e23cb316-75af-11e9-a09a-7e4d6cfcc771": Phase="Running", Reason="", readiness=true. Elapsed: 2.017036052s
May 13 18:49:55.310: INFO: Pod "pod-update-activedeadlineseconds-e23cb316-75af-11e9-a09a-7e4d6cfcc771": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.026426989s
May 13 18:49:55.310: INFO: Pod "pod-update-activedeadlineseconds-e23cb316-75af-11e9-a09a-7e4d6cfcc771" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:49:55.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-jfgb4" for this suite.
May 13 18:50:01.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:50:01.560: INFO: namespace: e2e-tests-pods-jfgb4, resource: bindings, ignored listing per whitelist
May 13 18:50:01.686: INFO: namespace e2e-tests-pods-jfgb4 deletion completed in 6.365106066s

• [SLOW TEST:13.293 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:50:01.688: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-gvxlj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 18:50:02.145: INFO: Creating ReplicaSet my-hostname-basic-ea425fcd-75af-11e9-a09a-7e4d6cfcc771
May 13 18:50:02.164: INFO: Pod name my-hostname-basic-ea425fcd-75af-11e9-a09a-7e4d6cfcc771: Found 0 pods out of 1
May 13 18:50:07.173: INFO: Pod name my-hostname-basic-ea425fcd-75af-11e9-a09a-7e4d6cfcc771: Found 1 pods out of 1
May 13 18:50:07.173: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-ea425fcd-75af-11e9-a09a-7e4d6cfcc771" is running
May 13 18:50:07.185: INFO: Pod "my-hostname-basic-ea425fcd-75af-11e9-a09a-7e4d6cfcc771-h9blv" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-13 18:50:02 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-13 18:50:04 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-13 18:50:04 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-13 18:50:02 +0000 UTC Reason: Message:}])
May 13 18:50:07.185: INFO: Trying to dial the pod
May 13 18:50:12.235: INFO: Controller my-hostname-basic-ea425fcd-75af-11e9-a09a-7e4d6cfcc771: Got expected result from replica 1 [my-hostname-basic-ea425fcd-75af-11e9-a09a-7e4d6cfcc771-h9blv]: "my-hostname-basic-ea425fcd-75af-11e9-a09a-7e4d6cfcc771-h9blv", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:50:12.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-gvxlj" for this suite.
May 13 18:50:18.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:50:18.373: INFO: namespace: e2e-tests-replicaset-gvxlj, resource: bindings, ignored listing per whitelist
May 13 18:50:18.567: INFO: namespace e2e-tests-replicaset-gvxlj deletion completed in 6.321122185s

• [SLOW TEST:16.879 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:50:18.568: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-8sk6l
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 13 18:50:18.884: INFO: Waiting up to 5m0s for pod "pod-f439b102-75af-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-emptydir-8sk6l" to be "success or failure"
May 13 18:50:18.894: INFO: Pod "pod-f439b102-75af-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 10.568823ms
May 13 18:50:20.904: INFO: Pod "pod-f439b102-75af-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020281614s
STEP: Saw pod success
May 13 18:50:20.904: INFO: Pod "pod-f439b102-75af-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:50:20.912: INFO: Trying to get logs from node 10.170.219.140 pod pod-f439b102-75af-11e9-a09a-7e4d6cfcc771 container test-container: <nil>
STEP: delete the pod
May 13 18:50:20.957: INFO: Waiting for pod pod-f439b102-75af-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:50:20.970: INFO: Pod pod-f439b102-75af-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:50:20.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8sk6l" for this suite.
May 13 18:50:29.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:50:29.235: INFO: namespace: e2e-tests-emptydir-8sk6l, resource: bindings, ignored listing per whitelist
May 13 18:50:29.309: INFO: namespace e2e-tests-emptydir-8sk6l deletion completed in 8.328080863s

• [SLOW TEST:10.742 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:50:29.310: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-f4w6f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-faa07789-75af-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume configMaps
May 13 18:50:29.635: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-faa22819-75af-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-projected-f4w6f" to be "success or failure"
May 13 18:50:29.644: INFO: Pod "pod-projected-configmaps-faa22819-75af-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 9.171918ms
May 13 18:50:31.652: INFO: Pod "pod-projected-configmaps-faa22819-75af-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017570402s
STEP: Saw pod success
May 13 18:50:31.652: INFO: Pod "pod-projected-configmaps-faa22819-75af-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:50:31.741: INFO: Trying to get logs from node 10.170.219.140 pod pod-projected-configmaps-faa22819-75af-11e9-a09a-7e4d6cfcc771 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 13 18:50:31.792: INFO: Waiting for pod pod-projected-configmaps-faa22819-75af-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:50:31.804: INFO: Pod pod-projected-configmaps-faa22819-75af-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:50:31.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-f4w6f" for this suite.
May 13 18:50:37.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:50:37.923: INFO: namespace: e2e-tests-projected-f4w6f, resource: bindings, ignored listing per whitelist
May 13 18:50:38.140: INFO: namespace e2e-tests-projected-f4w6f deletion completed in 6.325157604s

• [SLOW TEST:8.830 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:50:38.141: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-w6hh7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-w6hh7
May 13 18:50:42.465: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-w6hh7
STEP: checking the pod's current state and verifying that restartCount is present
May 13 18:50:42.473: INFO: Initial restart count of pod liveness-exec is 0
May 13 18:51:26.900: INFO: Restart count of pod e2e-tests-container-probe-w6hh7/liveness-exec is now 1 (44.427121501s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:51:26.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-w6hh7" for this suite.
May 13 18:51:32.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:51:33.127: INFO: namespace: e2e-tests-container-probe-w6hh7, resource: bindings, ignored listing per whitelist
May 13 18:51:33.296: INFO: namespace e2e-tests-container-probe-w6hh7 deletion completed in 6.344614128s

• [SLOW TEST:55.156 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:51:33.297: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-hjfdz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 13 18:51:33.613: INFO: Waiting up to 5m0s for pod "pod-20c49663-75b0-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-emptydir-hjfdz" to be "success or failure"
May 13 18:51:33.620: INFO: Pod "pod-20c49663-75b0-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 7.479161ms
May 13 18:51:35.643: INFO: Pod "pod-20c49663-75b0-11e9-a09a-7e4d6cfcc771": Phase="Running", Reason="", readiness=true. Elapsed: 2.030370999s
May 13 18:51:37.653: INFO: Pod "pod-20c49663-75b0-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040067134s
STEP: Saw pod success
May 13 18:51:37.653: INFO: Pod "pod-20c49663-75b0-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:51:37.665: INFO: Trying to get logs from node 10.170.219.140 pod pod-20c49663-75b0-11e9-a09a-7e4d6cfcc771 container test-container: <nil>
STEP: delete the pod
May 13 18:51:37.798: INFO: Waiting for pod pod-20c49663-75b0-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:51:37.806: INFO: Pod pod-20c49663-75b0-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:51:37.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hjfdz" for this suite.
May 13 18:51:43.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:51:44.145: INFO: namespace: e2e-tests-emptydir-hjfdz, resource: bindings, ignored listing per whitelist
May 13 18:51:44.276: INFO: namespace e2e-tests-emptydir-hjfdz deletion completed in 6.459231223s

• [SLOW TEST:10.979 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:51:44.276: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-swjss
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 18:51:44.658: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
May 13 18:51:44.676: INFO: Pod name sample-pod: Found 0 pods out of 1
May 13 18:51:49.699: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 13 18:51:49.700: INFO: Creating deployment "test-rolling-update-deployment"
May 13 18:51:49.711: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
May 13 18:51:49.726: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
May 13 18:51:51.744: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
May 13 18:51:51.751: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693370309, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693370309, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693370309, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693370309, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 13 18:51:53.761: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 13 18:51:53.790: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-swjss,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-swjss/deployments/test-rolling-update-deployment,UID:2a5e99b2-75b0-11e9-906d-b2bf80cbe475,ResourceVersion:37299,Generation:1,CreationTimestamp:2019-05-13 18:51:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-13 18:51:49 +0000 UTC 2019-05-13 18:51:49 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-13 18:51:51 +0000 UTC 2019-05-13 18:51:49 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 13 18:51:53.799: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-swjss,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-swjss/replicasets/test-rolling-update-deployment-65b7695dcf,UID:2a639569-75b0-11e9-a685-3eb3c297d0da,ResourceVersion:37290,Generation:1,CreationTimestamp:2019-05-13 18:51:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 2a5e99b2-75b0-11e9-906d-b2bf80cbe475 0xc420ca9457 0xc420ca9458}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 13 18:51:53.799: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
May 13 18:51:53.799: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-swjss,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-swjss/replicasets/test-rolling-update-controller,UID:275d4072-75b0-11e9-906d-b2bf80cbe475,ResourceVersion:37298,Generation:2,CreationTimestamp:2019-05-13 18:51:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 2a5e99b2-75b0-11e9-906d-b2bf80cbe475 0xc420ca930e 0xc420ca930f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 13 18:51:53.850: INFO: Pod "test-rolling-update-deployment-65b7695dcf-bzdtc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-bzdtc,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-swjss,SelfLink:/api/v1/namespaces/e2e-tests-deployment-swjss/pods/test-rolling-update-deployment-65b7695dcf-bzdtc,UID:2a64c40d-75b0-11e9-a685-3eb3c297d0da,ResourceVersion:37289,Generation:0,CreationTimestamp:2019-05-13 18:51:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf 2a639569-75b0-11e9-a685-3eb3c297d0da 0xc421015567 0xc421015568}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9j8vk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9j8vk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-9j8vk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4210155e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421015600}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 18:51:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 18:51:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 18:51:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 18:51:49 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.140,PodIP:172.30.208.53,StartTime:2019-05-13 18:51:49 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-13 18:51:50 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://56b29f7f0ac1b79f031a8c586a5634e369cf1ef458a507393eac718816874d78}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:51:53.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-swjss" for this suite.
May 13 18:51:59.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:52:00.061: INFO: namespace: e2e-tests-deployment-swjss, resource: bindings, ignored listing per whitelist
May 13 18:52:00.201: INFO: namespace e2e-tests-deployment-swjss deletion completed in 6.339785769s

• [SLOW TEST:15.926 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:52:00.202: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-mprss
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
May 13 18:52:02.555: INFO: Pod pod-hostip-30ce00b1-75b0-11e9-a09a-7e4d6cfcc771 has hostIP: 10.170.219.140
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:52:02.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-mprss" for this suite.
May 13 18:52:26.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:52:26.806: INFO: namespace: e2e-tests-pods-mprss, resource: bindings, ignored listing per whitelist
May 13 18:52:26.901: INFO: namespace e2e-tests-pods-mprss deletion completed in 24.335206753s

• [SLOW TEST:26.700 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:52:26.902: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-klvhk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-klvhk
May 13 18:52:29.230: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-klvhk
STEP: checking the pod's current state and verifying that restartCount is present
May 13 18:52:29.242: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:56:31.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-klvhk" for this suite.
May 13 18:56:37.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:56:37.457: INFO: namespace: e2e-tests-container-probe-klvhk, resource: bindings, ignored listing per whitelist
May 13 18:56:37.495: INFO: namespace e2e-tests-container-probe-klvhk deletion completed in 6.367968569s

• [SLOW TEST:250.593 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:56:37.495: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-phfz5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 13 18:56:38.044: INFO: Waiting up to 5m0s for pod "pod-d638ec2e-75b0-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-emptydir-phfz5" to be "success or failure"
May 13 18:56:38.051: INFO: Pod "pod-d638ec2e-75b0-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 7.679159ms
May 13 18:56:40.060: INFO: Pod "pod-d638ec2e-75b0-11e9-a09a-7e4d6cfcc771": Phase="Running", Reason="", readiness=true. Elapsed: 2.016923361s
May 13 18:56:42.069: INFO: Pod "pod-d638ec2e-75b0-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025503349s
STEP: Saw pod success
May 13 18:56:42.069: INFO: Pod "pod-d638ec2e-75b0-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:56:42.085: INFO: Trying to get logs from node 10.170.219.140 pod pod-d638ec2e-75b0-11e9-a09a-7e4d6cfcc771 container test-container: <nil>
STEP: delete the pod
May 13 18:56:42.241: INFO: Waiting for pod pod-d638ec2e-75b0-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:56:42.249: INFO: Pod pod-d638ec2e-75b0-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:56:42.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-phfz5" for this suite.
May 13 18:56:48.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:56:48.508: INFO: namespace: e2e-tests-emptydir-phfz5, resource: bindings, ignored listing per whitelist
May 13 18:56:48.608: INFO: namespace e2e-tests-emptydir-phfz5 deletion completed in 6.348559898s

• [SLOW TEST:11.113 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:56:48.610: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-klj68
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 18:56:49.333: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dcf387e7-75b0-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-projected-klj68" to be "success or failure"
May 13 18:56:49.342: INFO: Pod "downwardapi-volume-dcf387e7-75b0-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 8.679749ms
May 13 18:56:51.352: INFO: Pod "downwardapi-volume-dcf387e7-75b0-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018121972s
STEP: Saw pod success
May 13 18:56:51.352: INFO: Pod "downwardapi-volume-dcf387e7-75b0-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:56:51.360: INFO: Trying to get logs from node 10.170.219.140 pod downwardapi-volume-dcf387e7-75b0-11e9-a09a-7e4d6cfcc771 container client-container: <nil>
STEP: delete the pod
May 13 18:56:51.403: INFO: Waiting for pod downwardapi-volume-dcf387e7-75b0-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:56:51.412: INFO: Pod downwardapi-volume-dcf387e7-75b0-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:56:51.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-klj68" for this suite.
May 13 18:56:57.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:56:57.630: INFO: namespace: e2e-tests-projected-klj68, resource: bindings, ignored listing per whitelist
May 13 18:56:57.763: INFO: namespace e2e-tests-projected-klj68 deletion completed in 6.341019371s

• [SLOW TEST:9.153 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:56:57.764: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-qxh7n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-lfbt
STEP: Creating a pod to test atomic-volume-subpath
May 13 18:56:58.081: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-lfbt" in namespace "e2e-tests-subpath-qxh7n" to be "success or failure"
May 13 18:56:58.089: INFO: Pod "pod-subpath-test-configmap-lfbt": Phase="Pending", Reason="", readiness=false. Elapsed: 8.150879ms
May 13 18:57:00.107: INFO: Pod "pod-subpath-test-configmap-lfbt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026918448s
May 13 18:57:02.141: INFO: Pod "pod-subpath-test-configmap-lfbt": Phase="Running", Reason="", readiness=false. Elapsed: 4.060685857s
May 13 18:57:04.150: INFO: Pod "pod-subpath-test-configmap-lfbt": Phase="Running", Reason="", readiness=false. Elapsed: 6.06921951s
May 13 18:57:06.159: INFO: Pod "pod-subpath-test-configmap-lfbt": Phase="Running", Reason="", readiness=false. Elapsed: 8.078309584s
May 13 18:57:08.184: INFO: Pod "pod-subpath-test-configmap-lfbt": Phase="Running", Reason="", readiness=false. Elapsed: 10.103055231s
May 13 18:57:10.194: INFO: Pod "pod-subpath-test-configmap-lfbt": Phase="Running", Reason="", readiness=false. Elapsed: 12.112967131s
May 13 18:57:12.206: INFO: Pod "pod-subpath-test-configmap-lfbt": Phase="Running", Reason="", readiness=false. Elapsed: 14.125501281s
May 13 18:57:14.218: INFO: Pod "pod-subpath-test-configmap-lfbt": Phase="Running", Reason="", readiness=false. Elapsed: 16.137032609s
May 13 18:57:16.227: INFO: Pod "pod-subpath-test-configmap-lfbt": Phase="Running", Reason="", readiness=false. Elapsed: 18.146614148s
May 13 18:57:18.253: INFO: Pod "pod-subpath-test-configmap-lfbt": Phase="Running", Reason="", readiness=false. Elapsed: 20.172856085s
May 13 18:57:20.263: INFO: Pod "pod-subpath-test-configmap-lfbt": Phase="Running", Reason="", readiness=false. Elapsed: 22.182896452s
May 13 18:57:22.273: INFO: Pod "pod-subpath-test-configmap-lfbt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.192202189s
STEP: Saw pod success
May 13 18:57:22.273: INFO: Pod "pod-subpath-test-configmap-lfbt" satisfied condition "success or failure"
May 13 18:57:22.281: INFO: Trying to get logs from node 10.170.219.140 pod pod-subpath-test-configmap-lfbt container test-container-subpath-configmap-lfbt: <nil>
STEP: delete the pod
May 13 18:57:22.333: INFO: Waiting for pod pod-subpath-test-configmap-lfbt to disappear
May 13 18:57:22.343: INFO: Pod pod-subpath-test-configmap-lfbt no longer exists
STEP: Deleting pod pod-subpath-test-configmap-lfbt
May 13 18:57:22.343: INFO: Deleting pod "pod-subpath-test-configmap-lfbt" in namespace "e2e-tests-subpath-qxh7n"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:57:22.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-qxh7n" for this suite.
May 13 18:57:28.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:57:28.454: INFO: namespace: e2e-tests-subpath-qxh7n, resource: bindings, ignored listing per whitelist
May 13 18:57:28.697: INFO: namespace e2e-tests-subpath-qxh7n deletion completed in 6.334384165s

• [SLOW TEST:30.934 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:57:28.698: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-rkpk6
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-f4a38a30-75b0-11e9-a09a-7e4d6cfcc771
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:57:33.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-rkpk6" for this suite.
May 13 18:57:57.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:57:57.272: INFO: namespace: e2e-tests-configmap-rkpk6, resource: bindings, ignored listing per whitelist
May 13 18:57:57.483: INFO: namespace e2e-tests-configmap-rkpk6 deletion completed in 24.321175791s

• [SLOW TEST:28.785 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:57:57.483: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-t6j9c
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 18:57:57.898: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"05d17e21-75b1-11e9-906d-b2bf80cbe475", Controller:(*bool)(0xc42251f586), BlockOwnerDeletion:(*bool)(0xc42251f587)}}
May 13 18:57:57.910: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"05ce0fd5-75b1-11e9-906d-b2bf80cbe475", Controller:(*bool)(0xc4221ec496), BlockOwnerDeletion:(*bool)(0xc4221ec497)}}
May 13 18:57:57.923: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"05cfe5a9-75b1-11e9-906d-b2bf80cbe475", Controller:(*bool)(0xc421bce7b6), BlockOwnerDeletion:(*bool)(0xc421bce7b7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:58:02.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-t6j9c" for this suite.
May 13 18:58:08.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:58:09.175: INFO: namespace: e2e-tests-gc-t6j9c, resource: bindings, ignored listing per whitelist
May 13 18:58:09.353: INFO: namespace e2e-tests-gc-t6j9c deletion completed in 6.382554683s

• [SLOW TEST:11.870 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:58:09.354: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-spk4j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 13 18:58:09.725: INFO: Number of nodes with available pods: 0
May 13 18:58:09.725: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:58:10.744: INFO: Number of nodes with available pods: 0
May 13 18:58:10.744: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:58:11.746: INFO: Number of nodes with available pods: 3
May 13 18:58:11.746: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
May 13 18:58:11.789: INFO: Number of nodes with available pods: 2
May 13 18:58:11.789: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:58:12.851: INFO: Number of nodes with available pods: 2
May 13 18:58:12.851: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 18:58:13.830: INFO: Number of nodes with available pods: 3
May 13 18:58:13.830: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-spk4j, will wait for the garbage collector to delete the pods
May 13 18:58:13.923: INFO: Deleting {extensions DaemonSet} daemon-set took: 18.078405ms
May 13 18:58:14.023: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.280466ms
May 13 18:58:53.546: INFO: Number of nodes with available pods: 0
May 13 18:58:53.546: INFO: Number of running nodes: 0, number of available pods: 0
May 13 18:58:53.555: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-spk4j/daemonsets","resourceVersion":"38441"},"items":null}

May 13 18:58:53.563: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-spk4j/pods","resourceVersion":"38441"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:58:53.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-spk4j" for this suite.
May 13 18:58:59.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:58:59.734: INFO: namespace: e2e-tests-daemonsets-spk4j, resource: bindings, ignored listing per whitelist
May 13 18:58:59.921: INFO: namespace e2e-tests-daemonsets-spk4j deletion completed in 6.315647454s

• [SLOW TEST:50.567 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:58:59.922: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-b5fk8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
May 13 18:59:00.232: INFO: Waiting up to 5m0s for pod "pod-2af91ecd-75b1-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-emptydir-b5fk8" to be "success or failure"
May 13 18:59:00.252: INFO: Pod "pod-2af91ecd-75b1-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 19.496049ms
May 13 18:59:02.261: INFO: Pod "pod-2af91ecd-75b1-11e9-a09a-7e4d6cfcc771": Phase="Running", Reason="", readiness=true. Elapsed: 2.028293245s
May 13 18:59:04.285: INFO: Pod "pod-2af91ecd-75b1-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052324373s
STEP: Saw pod success
May 13 18:59:04.285: INFO: Pod "pod-2af91ecd-75b1-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 18:59:04.293: INFO: Trying to get logs from node 10.170.219.140 pod pod-2af91ecd-75b1-11e9-a09a-7e4d6cfcc771 container test-container: <nil>
STEP: delete the pod
May 13 18:59:04.342: INFO: Waiting for pod pod-2af91ecd-75b1-11e9-a09a-7e4d6cfcc771 to disappear
May 13 18:59:04.351: INFO: Pod pod-2af91ecd-75b1-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:59:04.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-b5fk8" for this suite.
May 13 18:59:10.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:59:10.444: INFO: namespace: e2e-tests-emptydir-b5fk8, resource: bindings, ignored listing per whitelist
May 13 18:59:10.695: INFO: namespace e2e-tests-emptydir-b5fk8 deletion completed in 6.33395286s

• [SLOW TEST:10.773 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 18:59:10.696: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-xxc9s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
May 13 18:59:10.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 create -f - --namespace=e2e-tests-kubectl-xxc9s'
May 13 18:59:11.379: INFO: stderr: ""
May 13 18:59:11.379: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 13 18:59:11.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-xxc9s'
May 13 18:59:11.513: INFO: stderr: ""
May 13 18:59:11.513: INFO: stdout: "update-demo-nautilus-4tbr5 update-demo-nautilus-7smdn "
May 13 18:59:11.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods update-demo-nautilus-4tbr5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xxc9s'
May 13 18:59:11.625: INFO: stderr: ""
May 13 18:59:11.625: INFO: stdout: ""
May 13 18:59:11.625: INFO: update-demo-nautilus-4tbr5 is created but not running
May 13 18:59:16.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-xxc9s'
May 13 18:59:16.805: INFO: stderr: ""
May 13 18:59:16.805: INFO: stdout: "update-demo-nautilus-4tbr5 update-demo-nautilus-7smdn "
May 13 18:59:16.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods update-demo-nautilus-4tbr5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xxc9s'
May 13 18:59:16.937: INFO: stderr: ""
May 13 18:59:16.937: INFO: stdout: "true"
May 13 18:59:16.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods update-demo-nautilus-4tbr5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xxc9s'
May 13 18:59:17.065: INFO: stderr: ""
May 13 18:59:17.065: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 13 18:59:17.065: INFO: validating pod update-demo-nautilus-4tbr5
May 13 18:59:17.082: INFO: got data: {
  "image": "nautilus.jpg"
}

May 13 18:59:17.082: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 13 18:59:17.082: INFO: update-demo-nautilus-4tbr5 is verified up and running
May 13 18:59:17.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods update-demo-nautilus-7smdn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xxc9s'
May 13 18:59:17.192: INFO: stderr: ""
May 13 18:59:17.192: INFO: stdout: "true"
May 13 18:59:17.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods update-demo-nautilus-7smdn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xxc9s'
May 13 18:59:17.317: INFO: stderr: ""
May 13 18:59:17.317: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 13 18:59:17.317: INFO: validating pod update-demo-nautilus-7smdn
May 13 18:59:17.335: INFO: got data: {
  "image": "nautilus.jpg"
}

May 13 18:59:17.335: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 13 18:59:17.335: INFO: update-demo-nautilus-7smdn is verified up and running
STEP: rolling-update to new replication controller
May 13 18:59:17.337: INFO: scanned /root for discovery docs: <nil>
May 13 18:59:17.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-xxc9s'
May 13 18:59:40.016: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 13 18:59:40.016: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 13 18:59:40.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-xxc9s'
May 13 18:59:40.163: INFO: stderr: ""
May 13 18:59:40.163: INFO: stdout: "update-demo-kitten-clvrd update-demo-kitten-s5qs9 "
May 13 18:59:40.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods update-demo-kitten-clvrd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xxc9s'
May 13 18:59:40.282: INFO: stderr: ""
May 13 18:59:40.282: INFO: stdout: "true"
May 13 18:59:40.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods update-demo-kitten-clvrd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xxc9s'
May 13 18:59:40.401: INFO: stderr: ""
May 13 18:59:40.401: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
May 13 18:59:40.401: INFO: validating pod update-demo-kitten-clvrd
May 13 18:59:40.422: INFO: got data: {
  "image": "kitten.jpg"
}

May 13 18:59:40.422: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 13 18:59:40.422: INFO: update-demo-kitten-clvrd is verified up and running
May 13 18:59:40.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods update-demo-kitten-s5qs9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xxc9s'
May 13 18:59:40.544: INFO: stderr: ""
May 13 18:59:40.544: INFO: stdout: "true"
May 13 18:59:40.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods update-demo-kitten-s5qs9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xxc9s'
May 13 18:59:40.660: INFO: stderr: ""
May 13 18:59:40.660: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
May 13 18:59:40.660: INFO: validating pod update-demo-kitten-s5qs9
May 13 18:59:40.677: INFO: got data: {
  "image": "kitten.jpg"
}

May 13 18:59:40.677: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 13 18:59:40.677: INFO: update-demo-kitten-s5qs9 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 18:59:40.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xxc9s" for this suite.
May 13 19:00:04.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:00:04.862: INFO: namespace: e2e-tests-kubectl-xxc9s, resource: bindings, ignored listing per whitelist
May 13 19:00:05.111: INFO: namespace e2e-tests-kubectl-xxc9s deletion completed in 24.422321298s

• [SLOW TEST:54.415 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:00:05.111: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-9j8nr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-qqxw
STEP: Creating a pod to test atomic-volume-subpath
May 13 19:00:05.545: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-qqxw" in namespace "e2e-tests-subpath-9j8nr" to be "success or failure"
May 13 19:00:05.552: INFO: Pod "pod-subpath-test-downwardapi-qqxw": Phase="Pending", Reason="", readiness=false. Elapsed: 7.665115ms
May 13 19:00:07.562: INFO: Pod "pod-subpath-test-downwardapi-qqxw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016893884s
May 13 19:00:09.570: INFO: Pod "pod-subpath-test-downwardapi-qqxw": Phase="Running", Reason="", readiness=false. Elapsed: 4.025511924s
May 13 19:00:11.579: INFO: Pod "pod-subpath-test-downwardapi-qqxw": Phase="Running", Reason="", readiness=false. Elapsed: 6.034295114s
May 13 19:00:13.604: INFO: Pod "pod-subpath-test-downwardapi-qqxw": Phase="Running", Reason="", readiness=false. Elapsed: 8.058953292s
May 13 19:00:15.641: INFO: Pod "pod-subpath-test-downwardapi-qqxw": Phase="Running", Reason="", readiness=false. Elapsed: 10.096328752s
May 13 19:00:17.651: INFO: Pod "pod-subpath-test-downwardapi-qqxw": Phase="Running", Reason="", readiness=false. Elapsed: 12.106293158s
May 13 19:00:19.660: INFO: Pod "pod-subpath-test-downwardapi-qqxw": Phase="Running", Reason="", readiness=false. Elapsed: 14.115277662s
May 13 19:00:21.669: INFO: Pod "pod-subpath-test-downwardapi-qqxw": Phase="Running", Reason="", readiness=false. Elapsed: 16.12395056s
May 13 19:00:23.692: INFO: Pod "pod-subpath-test-downwardapi-qqxw": Phase="Running", Reason="", readiness=false. Elapsed: 18.147654279s
May 13 19:00:25.703: INFO: Pod "pod-subpath-test-downwardapi-qqxw": Phase="Running", Reason="", readiness=false. Elapsed: 20.158450663s
May 13 19:00:27.712: INFO: Pod "pod-subpath-test-downwardapi-qqxw": Phase="Running", Reason="", readiness=false. Elapsed: 22.166967267s
May 13 19:00:29.721: INFO: Pod "pod-subpath-test-downwardapi-qqxw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.176339976s
STEP: Saw pod success
May 13 19:00:29.721: INFO: Pod "pod-subpath-test-downwardapi-qqxw" satisfied condition "success or failure"
May 13 19:00:29.730: INFO: Trying to get logs from node 10.170.219.140 pod pod-subpath-test-downwardapi-qqxw container test-container-subpath-downwardapi-qqxw: <nil>
STEP: delete the pod
May 13 19:00:29.775: INFO: Waiting for pod pod-subpath-test-downwardapi-qqxw to disappear
May 13 19:00:29.849: INFO: Pod pod-subpath-test-downwardapi-qqxw no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-qqxw
May 13 19:00:29.849: INFO: Deleting pod "pod-subpath-test-downwardapi-qqxw" in namespace "e2e-tests-subpath-9j8nr"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:00:29.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-9j8nr" for this suite.
May 13 19:00:35.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:00:36.184: INFO: namespace: e2e-tests-subpath-9j8nr, resource: bindings, ignored listing per whitelist
May 13 19:00:36.206: INFO: namespace e2e-tests-subpath-9j8nr deletion completed in 6.338352451s

• [SLOW TEST:31.095 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:00:36.206: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-74bjs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
May 13 19:00:36.509: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 13 19:00:36.527: INFO: Waiting for terminating namespaces to be deleted...
May 13 19:00:36.534: INFO: 
Logging pods the kubelet thinks is on node 10.170.219.140 before test
May 13 19:00:36.556: INFO: ibm-master-proxy-static-10.170.219.140 from kube-system started at <nil> (0 container statuses recorded)
May 13 19:00:36.556: INFO: ibm-cloud-provider-ip-169-45-233-124-7fbd585f77-sv6vv from ibm-system started at 2019-05-13 16:27:29 +0000 UTC (1 container statuses recorded)
May 13 19:00:36.556: INFO: 	Container ibm-cloud-provider-ip-169-45-233-124 ready: true, restart count 0
May 13 19:00:36.556: INFO: calico-node-nlxmm from kube-system started at 2019-05-13 16:26:20 +0000 UTC (2 container statuses recorded)
May 13 19:00:36.556: INFO: 	Container calico-node ready: true, restart count 0
May 13 19:00:36.556: INFO: 	Container install-cni ready: true, restart count 0
May 13 19:00:36.556: INFO: ibm-keepalived-watcher-s9p9f from kube-system started at 2019-05-13 16:26:20 +0000 UTC (1 container statuses recorded)
May 13 19:00:36.556: INFO: 	Container keepalived-watcher ready: true, restart count 0
May 13 19:00:36.556: INFO: public-cre5e67d863b8a419ba7a75a47352a70a9-alb1-785767687-drrgh from kube-system started at 2019-05-13 16:32:34 +0000 UTC (4 container statuses recorded)
May 13 19:00:36.556: INFO: 	Container ingress-auth-1 ready: true, restart count 0
May 13 19:00:36.556: INFO: 	Container ingress-auth-2 ready: true, restart count 0
May 13 19:00:36.556: INFO: 	Container ingress-auth-3 ready: true, restart count 0
May 13 19:00:36.556: INFO: 	Container nginx-ingress ready: true, restart count 0
May 13 19:00:36.556: INFO: sonobuoy-systemd-logs-daemon-set-5d6538ccab344242-8b4m8 from heptio-sonobuoy started at 2019-05-13 18:23:14 +0000 UTC (2 container statuses recorded)
May 13 19:00:36.556: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 13 19:00:36.556: INFO: 	Container systemd-logs ready: true, restart count 0
May 13 19:00:36.556: INFO: ibm-kube-fluentd-kswb8 from kube-system started at 2019-05-13 16:27:54 +0000 UTC (1 container statuses recorded)
May 13 19:00:36.556: INFO: 	Container fluentd ready: true, restart count 0
May 13 19:00:36.556: INFO: 
Logging pods the kubelet thinks is on node 10.170.219.170 before test
May 13 19:00:36.585: INFO: ibm-kube-fluentd-h589k from kube-system started at 2019-05-13 16:27:54 +0000 UTC (1 container statuses recorded)
May 13 19:00:36.585: INFO: 	Container fluentd ready: true, restart count 0
May 13 19:00:36.585: INFO: sonobuoy-e2e-job-d5dc9a0af3d340ba from heptio-sonobuoy started at 2019-05-13 18:23:14 +0000 UTC (2 container statuses recorded)
May 13 19:00:36.585: INFO: 	Container e2e ready: true, restart count 0
May 13 19:00:36.585: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 13 19:00:36.585: INFO: ibm-master-proxy-static-10.170.219.170 from kube-system started at <nil> (0 container statuses recorded)
May 13 19:00:36.585: INFO: ibm-keepalived-watcher-74r7v from kube-system started at 2019-05-13 16:26:56 +0000 UTC (1 container statuses recorded)
May 13 19:00:36.585: INFO: 	Container keepalived-watcher ready: true, restart count 0
May 13 19:00:36.585: INFO: sonobuoy-systemd-logs-daemon-set-5d6538ccab344242-2t9dg from heptio-sonobuoy started at 2019-05-13 18:23:14 +0000 UTC (2 container statuses recorded)
May 13 19:00:36.586: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 13 19:00:36.586: INFO: 	Container systemd-logs ready: true, restart count 0
May 13 19:00:36.586: INFO: calico-node-vsr6g from kube-system started at 2019-05-13 16:26:56 +0000 UTC (2 container statuses recorded)
May 13 19:00:36.586: INFO: 	Container calico-node ready: true, restart count 0
May 13 19:00:36.586: INFO: 	Container install-cni ready: true, restart count 0
May 13 19:00:36.586: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-05-13 18:23:07 +0000 UTC (1 container statuses recorded)
May 13 19:00:36.586: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
May 13 19:00:36.586: INFO: kube-dns-amd64-fcdcf59c5-mbw97 from kube-system started at 2019-05-13 16:27:28 +0000 UTC (3 container statuses recorded)
May 13 19:00:36.586: INFO: 	Container dnsmasq ready: true, restart count 0
May 13 19:00:36.586: INFO: 	Container kubedns ready: true, restart count 0
May 13 19:00:36.586: INFO: 	Container sidecar ready: true, restart count 0
May 13 19:00:36.586: INFO: metrics-server-77478c8fdd-zwg9d from kube-system started at 2019-05-13 16:27:41 +0000 UTC (2 container statuses recorded)
May 13 19:00:36.586: INFO: 	Container metrics-server ready: true, restart count 0
May 13 19:00:36.586: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 13 19:00:36.586: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-13 18:23:11 +0000 UTC (1 container statuses recorded)
May 13 19:00:36.586: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 13 19:00:36.586: INFO: 
Logging pods the kubelet thinks is on node 10.170.219.189 before test
May 13 19:00:36.647: INFO: kube-dns-autoscaler-587cd5cd44-mrpn9 from kube-system started at 2019-05-13 16:26:35 +0000 UTC (1 container statuses recorded)
May 13 19:00:36.647: INFO: 	Container autoscaler ready: true, restart count 0
May 13 19:00:36.647: INFO: calico-kube-controllers-69f46f96c4-k8td8 from kube-system started at 2019-05-13 16:25:45 +0000 UTC (1 container statuses recorded)
May 13 19:00:36.647: INFO: 	Container calico-kube-controllers ready: true, restart count 0
May 13 19:00:36.647: INFO: public-cre5e67d863b8a419ba7a75a47352a70a9-alb1-785767687-vsp6l from kube-system started at 2019-05-13 16:32:34 +0000 UTC (4 container statuses recorded)
May 13 19:00:36.647: INFO: 	Container ingress-auth-1 ready: true, restart count 0
May 13 19:00:36.647: INFO: 	Container ingress-auth-2 ready: true, restart count 0
May 13 19:00:36.648: INFO: 	Container ingress-auth-3 ready: true, restart count 0
May 13 19:00:36.648: INFO: 	Container nginx-ingress ready: true, restart count 0
May 13 19:00:36.648: INFO: ibm-file-plugin-75d4cc8576-b74ft from kube-system started at 2019-05-13 16:26:35 +0000 UTC (1 container statuses recorded)
May 13 19:00:36.648: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
May 13 19:00:36.648: INFO: sonobuoy-systemd-logs-daemon-set-5d6538ccab344242-ss8mg from heptio-sonobuoy started at 2019-05-13 18:23:14 +0000 UTC (2 container statuses recorded)
May 13 19:00:36.648: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 13 19:00:36.648: INFO: 	Container systemd-logs ready: true, restart count 0
May 13 19:00:36.648: INFO: ibm-master-proxy-static-10.170.219.189 from kube-system started at <nil> (0 container statuses recorded)
May 13 19:00:36.648: INFO: calico-node-j8pbf from kube-system started at 2019-05-13 16:25:45 +0000 UTC (2 container statuses recorded)
May 13 19:00:36.648: INFO: 	Container calico-node ready: true, restart count 0
May 13 19:00:36.648: INFO: 	Container install-cni ready: true, restart count 0
May 13 19:00:36.648: INFO: ibm-cloud-provider-ip-169-45-233-124-7fbd585f77-wfw6v from ibm-system started at 2019-05-13 16:27:29 +0000 UTC (1 container statuses recorded)
May 13 19:00:36.648: INFO: 	Container ibm-cloud-provider-ip-169-45-233-124 ready: true, restart count 0
May 13 19:00:36.648: INFO: ibm-kube-fluentd-dsrqr from kube-system started at 2019-05-13 16:27:54 +0000 UTC (1 container statuses recorded)
May 13 19:00:36.648: INFO: 	Container fluentd ready: true, restart count 0
May 13 19:00:36.648: INFO: ibm-keepalived-watcher-l5ss8 from kube-system started at 2019-05-13 16:25:45 +0000 UTC (1 container statuses recorded)
May 13 19:00:36.648: INFO: 	Container keepalived-watcher ready: true, restart count 0
May 13 19:00:36.648: INFO: kubernetes-dashboard-b4bc7db5d-dg6mx from kube-system started at 2019-05-13 16:26:35 +0000 UTC (1 container statuses recorded)
May 13 19:00:36.648: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 13 19:00:36.648: INFO: vpn-7d87f64d5b-z7z6p from kube-system started at 2019-05-13 16:26:35 +0000 UTC (1 container statuses recorded)
May 13 19:00:36.648: INFO: 	Container vpn ready: true, restart count 0
May 13 19:00:36.648: INFO: kube-dns-amd64-fcdcf59c5-vvwwq from kube-system started at 2019-05-13 16:26:35 +0000 UTC (3 container statuses recorded)
May 13 19:00:36.648: INFO: 	Container dnsmasq ready: true, restart count 0
May 13 19:00:36.648: INFO: 	Container kubedns ready: true, restart count 0
May 13 19:00:36.648: INFO: 	Container sidecar ready: true, restart count 0
May 13 19:00:36.648: INFO: ibm-storage-watcher-7765979c55-x5cgd from kube-system started at 2019-05-13 16:26:35 +0000 UTC (1 container statuses recorded)
May 13 19:00:36.648: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.159e533ba4efb64d], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:00:37.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-74bjs" for this suite.
May 13 19:00:43.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:00:44.060: INFO: namespace: e2e-tests-sched-pred-74bjs, resource: bindings, ignored listing per whitelist
May 13 19:00:44.126: INFO: namespace e2e-tests-sched-pred-74bjs deletion completed in 6.35383051s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:7.920 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:00:44.127: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-rxghk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-ttcbc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-s4th8
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:00:50.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-rxghk" for this suite.
May 13 19:00:56.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:00:57.275: INFO: namespace: e2e-tests-namespaces-rxghk, resource: bindings, ignored listing per whitelist
May 13 19:00:57.402: INFO: namespace e2e-tests-namespaces-rxghk deletion completed in 6.52225048s
STEP: Destroying namespace "e2e-tests-nsdeletetest-ttcbc" for this suite.
May 13 19:00:57.410: INFO: Namespace e2e-tests-nsdeletetest-ttcbc was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-s4th8" for this suite.
May 13 19:01:03.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:01:03.600: INFO: namespace: e2e-tests-nsdeletetest-s4th8, resource: bindings, ignored listing per whitelist
May 13 19:01:03.697: INFO: namespace e2e-tests-nsdeletetest-s4th8 deletion completed in 6.28649036s

• [SLOW TEST:19.570 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:01:03.698: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-79r5s
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0513 19:01:10.094247      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 13 19:01:10.094: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:01:10.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-79r5s" for this suite.
May 13 19:01:18.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:01:18.283: INFO: namespace: e2e-tests-gc-79r5s, resource: bindings, ignored listing per whitelist
May 13 19:01:18.431: INFO: namespace e2e-tests-gc-79r5s deletion completed in 8.327067648s

• [SLOW TEST:14.733 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:01:18.432: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-528v7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 19:01:19.032: INFO: (0) /api/v1/nodes/10.170.219.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.062102ms)
May 13 19:01:19.045: INFO: (1) /api/v1/nodes/10.170.219.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 12.854435ms)
May 13 19:01:19.073: INFO: (2) /api/v1/nodes/10.170.219.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 27.403502ms)
May 13 19:01:19.084: INFO: (3) /api/v1/nodes/10.170.219.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 11.703733ms)
May 13 19:01:19.096: INFO: (4) /api/v1/nodes/10.170.219.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 11.465641ms)
May 13 19:01:19.108: INFO: (5) /api/v1/nodes/10.170.219.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 11.948955ms)
May 13 19:01:19.120: INFO: (6) /api/v1/nodes/10.170.219.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 11.986053ms)
May 13 19:01:19.135: INFO: (7) /api/v1/nodes/10.170.219.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.654365ms)
May 13 19:01:19.146: INFO: (8) /api/v1/nodes/10.170.219.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 11.261058ms)
May 13 19:01:19.158: INFO: (9) /api/v1/nodes/10.170.219.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 12.384901ms)
May 13 19:01:19.170: INFO: (10) /api/v1/nodes/10.170.219.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 12.24027ms)
May 13 19:01:19.183: INFO: (11) /api/v1/nodes/10.170.219.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 12.23558ms)
May 13 19:01:19.195: INFO: (12) /api/v1/nodes/10.170.219.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 12.472685ms)
May 13 19:01:19.207: INFO: (13) /api/v1/nodes/10.170.219.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 11.882774ms)
May 13 19:01:19.219: INFO: (14) /api/v1/nodes/10.170.219.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 12.00324ms)
May 13 19:01:19.231: INFO: (15) /api/v1/nodes/10.170.219.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 11.677882ms)
May 13 19:01:19.242: INFO: (16) /api/v1/nodes/10.170.219.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 11.413073ms)
May 13 19:01:19.255: INFO: (17) /api/v1/nodes/10.170.219.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 12.272726ms)
May 13 19:01:19.266: INFO: (18) /api/v1/nodes/10.170.219.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 11.599254ms)
May 13 19:01:19.278: INFO: (19) /api/v1/nodes/10.170.219.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 12.155645ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:01:19.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-528v7" for this suite.
May 13 19:01:25.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:01:25.361: INFO: namespace: e2e-tests-proxy-528v7, resource: bindings, ignored listing per whitelist
May 13 19:01:25.613: INFO: namespace e2e-tests-proxy-528v7 deletion completed in 6.324425269s

• [SLOW TEST:7.180 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:01:25.613: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-bxpg6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-bxpg6
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-bxpg6
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-bxpg6
May 13 19:01:25.944: INFO: Found 0 stateful pods, waiting for 1
May 13 19:01:35.967: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
May 13 19:01:36.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 exec --namespace=e2e-tests-statefulset-bxpg6 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 13 19:01:36.670: INFO: stderr: ""
May 13 19:01:36.670: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 13 19:01:36.670: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 13 19:01:36.680: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 13 19:01:46.709: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 13 19:01:46.709: INFO: Waiting for statefulset status.replicas updated to 0
May 13 19:01:46.744: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May 13 19:01:46.744: INFO: ss-0  10.170.219.140  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:25 +0000 UTC  }]
May 13 19:01:46.744: INFO: ss-1                  Pending         []
May 13 19:01:46.744: INFO: 
May 13 19:01:46.745: INFO: StatefulSet ss has not reached scale 3, at 2
May 13 19:01:47.754: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.991593293s
May 13 19:01:48.763: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.982110923s
May 13 19:01:49.783: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.972649217s
May 13 19:01:50.793: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.953337153s
May 13 19:01:51.813: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.942916791s
May 13 19:01:52.821: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.923552368s
May 13 19:01:53.962: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.914662966s
May 13 19:01:54.972: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.773702849s
May 13 19:01:55.985: INFO: Verifying statefulset ss doesn't scale past 3 for another 763.763821ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-bxpg6
May 13 19:01:57.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 exec --namespace=e2e-tests-statefulset-bxpg6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 13 19:01:57.370: INFO: stderr: ""
May 13 19:01:57.370: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 13 19:01:57.370: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 13 19:01:57.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 exec --namespace=e2e-tests-statefulset-bxpg6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 13 19:01:57.843: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
May 13 19:01:57.843: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 13 19:01:57.843: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 13 19:01:57.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 exec --namespace=e2e-tests-statefulset-bxpg6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 13 19:01:58.157: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
May 13 19:01:58.157: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 13 19:01:58.157: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 13 19:01:58.166: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 13 19:01:58.166: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 13 19:01:58.166: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
May 13 19:01:58.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 exec --namespace=e2e-tests-statefulset-bxpg6 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 13 19:01:58.507: INFO: stderr: ""
May 13 19:01:58.507: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 13 19:01:58.507: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 13 19:01:58.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 exec --namespace=e2e-tests-statefulset-bxpg6 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 13 19:01:58.822: INFO: stderr: ""
May 13 19:01:58.822: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 13 19:01:58.822: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 13 19:01:58.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 exec --namespace=e2e-tests-statefulset-bxpg6 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 13 19:01:59.141: INFO: stderr: ""
May 13 19:01:59.141: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 13 19:01:59.141: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 13 19:01:59.141: INFO: Waiting for statefulset status.replicas updated to 0
May 13 19:01:59.248: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
May 13 19:02:09.283: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 13 19:02:09.283: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 13 19:02:09.283: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 13 19:02:09.360: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May 13 19:02:09.360: INFO: ss-0  10.170.219.140  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:25 +0000 UTC  }]
May 13 19:02:09.360: INFO: ss-1  10.170.219.189  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:46 +0000 UTC  }]
May 13 19:02:09.360: INFO: ss-2  10.170.219.170  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:46 +0000 UTC  }]
May 13 19:02:09.360: INFO: 
May 13 19:02:09.360: INFO: StatefulSet ss has not reached scale 0, at 3
May 13 19:02:10.370: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May 13 19:02:10.370: INFO: ss-0  10.170.219.140  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:25 +0000 UTC  }]
May 13 19:02:10.370: INFO: ss-1  10.170.219.189  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:46 +0000 UTC  }]
May 13 19:02:10.370: INFO: ss-2  10.170.219.170  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:46 +0000 UTC  }]
May 13 19:02:10.370: INFO: 
May 13 19:02:10.370: INFO: StatefulSet ss has not reached scale 0, at 3
May 13 19:02:11.379: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May 13 19:02:11.379: INFO: ss-1  10.170.219.189  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:46 +0000 UTC  }]
May 13 19:02:11.379: INFO: ss-2  10.170.219.170  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:01:46 +0000 UTC  }]
May 13 19:02:11.379: INFO: 
May 13 19:02:11.379: INFO: StatefulSet ss has not reached scale 0, at 2
May 13 19:02:12.392: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.972058171s
May 13 19:02:13.402: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.958797607s
May 13 19:02:14.411: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.94935391s
May 13 19:02:15.420: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.940358148s
May 13 19:02:16.431: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.931547425s
May 13 19:02:17.440: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.920076357s
May 13 19:02:18.449: INFO: Verifying statefulset ss doesn't scale past 0 for another 911.112551ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-bxpg6
May 13 19:02:19.471: INFO: Scaling statefulset ss to 0
May 13 19:02:19.499: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 13 19:02:19.511: INFO: Deleting all statefulset in ns e2e-tests-statefulset-bxpg6
May 13 19:02:19.519: INFO: Scaling statefulset ss to 0
May 13 19:02:19.543: INFO: Waiting for statefulset status.replicas updated to 0
May 13 19:02:19.552: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:02:19.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-bxpg6" for this suite.
May 13 19:02:27.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:02:27.714: INFO: namespace: e2e-tests-statefulset-bxpg6, resource: bindings, ignored listing per whitelist
May 13 19:02:27.927: INFO: namespace e2e-tests-statefulset-bxpg6 deletion completed in 8.322358415s

• [SLOW TEST:62.315 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:02:27.927: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-j48qj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 19:02:28.246: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a6f53583-75b1-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-projected-j48qj" to be "success or failure"
May 13 19:02:28.254: INFO: Pod "downwardapi-volume-a6f53583-75b1-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 8.061589ms
May 13 19:02:30.281: INFO: Pod "downwardapi-volume-a6f53583-75b1-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035139745s
STEP: Saw pod success
May 13 19:02:30.281: INFO: Pod "downwardapi-volume-a6f53583-75b1-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:02:30.341: INFO: Trying to get logs from node 10.170.219.140 pod downwardapi-volume-a6f53583-75b1-11e9-a09a-7e4d6cfcc771 container client-container: <nil>
STEP: delete the pod
May 13 19:02:30.401: INFO: Waiting for pod downwardapi-volume-a6f53583-75b1-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:02:30.412: INFO: Pod downwardapi-volume-a6f53583-75b1-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:02:30.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j48qj" for this suite.
May 13 19:02:36.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:02:36.656: INFO: namespace: e2e-tests-projected-j48qj, resource: bindings, ignored listing per whitelist
May 13 19:02:36.817: INFO: namespace e2e-tests-projected-j48qj deletion completed in 6.39447076s

• [SLOW TEST:8.890 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:02:36.817: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-lc2qm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:03:37.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-lc2qm" for this suite.
May 13 19:04:01.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:04:01.541: INFO: namespace: e2e-tests-container-probe-lc2qm, resource: bindings, ignored listing per whitelist
May 13 19:04:01.617: INFO: namespace e2e-tests-container-probe-lc2qm deletion completed in 24.461894375s

• [SLOW TEST:84.800 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:04:01.619: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-mw9p6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
May 13 19:04:01.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 create -f - --namespace=e2e-tests-kubectl-mw9p6'
May 13 19:04:02.228: INFO: stderr: ""
May 13 19:04:02.228: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 13 19:04:02.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-mw9p6'
May 13 19:04:02.353: INFO: stderr: ""
May 13 19:04:02.353: INFO: stdout: "update-demo-nautilus-87plw update-demo-nautilus-brznw "
May 13 19:04:02.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods update-demo-nautilus-87plw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mw9p6'
May 13 19:04:02.469: INFO: stderr: ""
May 13 19:04:02.469: INFO: stdout: ""
May 13 19:04:02.469: INFO: update-demo-nautilus-87plw is created but not running
May 13 19:04:07.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-mw9p6'
May 13 19:04:07.625: INFO: stderr: ""
May 13 19:04:07.625: INFO: stdout: "update-demo-nautilus-87plw update-demo-nautilus-brznw "
May 13 19:04:07.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods update-demo-nautilus-87plw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mw9p6'
May 13 19:04:07.746: INFO: stderr: ""
May 13 19:04:07.746: INFO: stdout: "true"
May 13 19:04:07.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods update-demo-nautilus-87plw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mw9p6'
May 13 19:04:07.951: INFO: stderr: ""
May 13 19:04:07.951: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 13 19:04:07.951: INFO: validating pod update-demo-nautilus-87plw
May 13 19:04:07.968: INFO: got data: {
  "image": "nautilus.jpg"
}

May 13 19:04:07.968: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 13 19:04:07.968: INFO: update-demo-nautilus-87plw is verified up and running
May 13 19:04:07.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods update-demo-nautilus-brznw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mw9p6'
May 13 19:04:08.091: INFO: stderr: ""
May 13 19:04:08.091: INFO: stdout: "true"
May 13 19:04:08.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods update-demo-nautilus-brznw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mw9p6'
May 13 19:04:08.212: INFO: stderr: ""
May 13 19:04:08.212: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 13 19:04:08.212: INFO: validating pod update-demo-nautilus-brznw
May 13 19:04:08.230: INFO: got data: {
  "image": "nautilus.jpg"
}

May 13 19:04:08.230: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 13 19:04:08.230: INFO: update-demo-nautilus-brznw is verified up and running
STEP: using delete to clean up resources
May 13 19:04:08.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-mw9p6'
May 13 19:04:08.390: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 13 19:04:08.390: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 13 19:04:08.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-mw9p6'
May 13 19:04:08.525: INFO: stderr: "No resources found.\n"
May 13 19:04:08.525: INFO: stdout: ""
May 13 19:04:08.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods -l name=update-demo --namespace=e2e-tests-kubectl-mw9p6 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 13 19:04:08.653: INFO: stderr: ""
May 13 19:04:08.653: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:04:08.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mw9p6" for this suite.
May 13 19:04:32.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:04:32.956: INFO: namespace: e2e-tests-kubectl-mw9p6, resource: bindings, ignored listing per whitelist
May 13 19:04:33.043: INFO: namespace e2e-tests-kubectl-mw9p6 deletion completed in 24.37909903s

• [SLOW TEST:31.424 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:04:33.044: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-cqm56
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 13 19:04:33.358: INFO: Waiting up to 5m0s for pod "downward-api-f187e53f-75b1-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-downward-api-cqm56" to be "success or failure"
May 13 19:04:33.365: INFO: Pod "downward-api-f187e53f-75b1-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 7.724499ms
May 13 19:04:35.376: INFO: Pod "downward-api-f187e53f-75b1-11e9-a09a-7e4d6cfcc771": Phase="Running", Reason="", readiness=true. Elapsed: 2.018644105s
May 13 19:04:37.509: INFO: Pod "downward-api-f187e53f-75b1-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.151455964s
STEP: Saw pod success
May 13 19:04:37.509: INFO: Pod "downward-api-f187e53f-75b1-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:04:37.520: INFO: Trying to get logs from node 10.170.219.140 pod downward-api-f187e53f-75b1-11e9-a09a-7e4d6cfcc771 container dapi-container: <nil>
STEP: delete the pod
May 13 19:04:37.566: INFO: Waiting for pod downward-api-f187e53f-75b1-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:04:37.573: INFO: Pod downward-api-f187e53f-75b1-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:04:37.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cqm56" for this suite.
May 13 19:04:43.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:04:43.678: INFO: namespace: e2e-tests-downward-api-cqm56, resource: bindings, ignored listing per whitelist
May 13 19:04:43.900: INFO: namespace e2e-tests-downward-api-cqm56 deletion completed in 6.317607955s

• [SLOW TEST:10.857 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:04:43.902: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-kbwch
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
May 13 19:04:48.305: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 13 19:04:48.314: INFO: Pod pod-with-prestop-http-hook still exists
May 13 19:04:50.314: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 13 19:04:50.324: INFO: Pod pod-with-prestop-http-hook still exists
May 13 19:04:52.314: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 13 19:04:52.338: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:04:52.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-kbwch" for this suite.
May 13 19:05:16.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:05:16.688: INFO: namespace: e2e-tests-container-lifecycle-hook-kbwch, resource: bindings, ignored listing per whitelist
May 13 19:05:16.716: INFO: namespace e2e-tests-container-lifecycle-hook-kbwch deletion completed in 24.347386839s

• [SLOW TEST:32.814 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:05:16.716: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-mh5kx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-mh5kx
May 13 19:05:19.050: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-mh5kx
STEP: checking the pod's current state and verifying that restartCount is present
May 13 19:05:19.057: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:09:20.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-mh5kx" for this suite.
May 13 19:09:27.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:09:27.130: INFO: namespace: e2e-tests-container-probe-mh5kx, resource: bindings, ignored listing per whitelist
May 13 19:09:27.304: INFO: namespace e2e-tests-container-probe-mh5kx deletion completed in 6.323541986s

• [SLOW TEST:250.588 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:09:27.304: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-bcbgj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-a0f5ee07-75b2-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume configMaps
May 13 19:09:27.687: INFO: Waiting up to 5m0s for pod "pod-configmaps-a0f76309-75b2-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-configmap-bcbgj" to be "success or failure"
May 13 19:09:27.695: INFO: Pod "pod-configmaps-a0f76309-75b2-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 8.016148ms
May 13 19:09:29.703: INFO: Pod "pod-configmaps-a0f76309-75b2-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016446104s
STEP: Saw pod success
May 13 19:09:29.703: INFO: Pod "pod-configmaps-a0f76309-75b2-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:09:29.711: INFO: Trying to get logs from node 10.170.219.140 pod pod-configmaps-a0f76309-75b2-11e9-a09a-7e4d6cfcc771 container configmap-volume-test: <nil>
STEP: delete the pod
May 13 19:09:29.841: INFO: Waiting for pod pod-configmaps-a0f76309-75b2-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:09:29.849: INFO: Pod pod-configmaps-a0f76309-75b2-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:09:29.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-bcbgj" for this suite.
May 13 19:09:37.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:09:37.998: INFO: namespace: e2e-tests-configmap-bcbgj, resource: bindings, ignored listing per whitelist
May 13 19:09:38.203: INFO: namespace e2e-tests-configmap-bcbgj deletion completed in 8.343174583s

• [SLOW TEST:10.899 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:09:38.203: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-n8rkb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secret-namespace-sxqkx
STEP: Creating secret with name secret-test-a7a3fa97-75b2-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume secrets
May 13 19:09:39.103: INFO: Waiting up to 5m0s for pod "pod-secrets-a7c48c64-75b2-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-secrets-n8rkb" to be "success or failure"
May 13 19:09:39.113: INFO: Pod "pod-secrets-a7c48c64-75b2-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 9.371367ms
May 13 19:09:41.123: INFO: Pod "pod-secrets-a7c48c64-75b2-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019812752s
STEP: Saw pod success
May 13 19:09:41.123: INFO: Pod "pod-secrets-a7c48c64-75b2-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:09:41.131: INFO: Trying to get logs from node 10.170.219.140 pod pod-secrets-a7c48c64-75b2-11e9-a09a-7e4d6cfcc771 container secret-volume-test: <nil>
STEP: delete the pod
May 13 19:09:41.177: INFO: Waiting for pod pod-secrets-a7c48c64-75b2-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:09:41.186: INFO: Pod pod-secrets-a7c48c64-75b2-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:09:41.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-n8rkb" for this suite.
May 13 19:09:47.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:09:47.507: INFO: namespace: e2e-tests-secrets-n8rkb, resource: bindings, ignored listing per whitelist
May 13 19:09:47.514: INFO: namespace e2e-tests-secrets-n8rkb deletion completed in 6.317060823s
STEP: Destroying namespace "e2e-tests-secret-namespace-sxqkx" for this suite.
May 13 19:09:55.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:09:55.557: INFO: namespace: e2e-tests-secret-namespace-sxqkx, resource: bindings, ignored listing per whitelist
May 13 19:09:55.815: INFO: namespace e2e-tests-secret-namespace-sxqkx deletion completed in 8.30174084s

• [SLOW TEST:17.612 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:09:55.816: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-vjrkg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
May 13 19:09:56.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 create -f - --namespace=e2e-tests-kubectl-vjrkg'
May 13 19:09:56.551: INFO: stderr: ""
May 13 19:09:56.551: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 13 19:09:56.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-vjrkg'
May 13 19:09:56.683: INFO: stderr: ""
May 13 19:09:56.683: INFO: stdout: "update-demo-nautilus-cqtdx update-demo-nautilus-hzxm8 "
May 13 19:09:56.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods update-demo-nautilus-cqtdx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vjrkg'
May 13 19:09:56.822: INFO: stderr: ""
May 13 19:09:56.822: INFO: stdout: ""
May 13 19:09:56.822: INFO: update-demo-nautilus-cqtdx is created but not running
May 13 19:10:01.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-vjrkg'
May 13 19:10:01.981: INFO: stderr: ""
May 13 19:10:01.981: INFO: stdout: "update-demo-nautilus-cqtdx update-demo-nautilus-hzxm8 "
May 13 19:10:01.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods update-demo-nautilus-cqtdx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vjrkg'
May 13 19:10:02.110: INFO: stderr: ""
May 13 19:10:02.110: INFO: stdout: "true"
May 13 19:10:02.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods update-demo-nautilus-cqtdx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vjrkg'
May 13 19:10:02.226: INFO: stderr: ""
May 13 19:10:02.226: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 13 19:10:02.226: INFO: validating pod update-demo-nautilus-cqtdx
May 13 19:10:02.242: INFO: got data: {
  "image": "nautilus.jpg"
}

May 13 19:10:02.242: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 13 19:10:02.242: INFO: update-demo-nautilus-cqtdx is verified up and running
May 13 19:10:02.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods update-demo-nautilus-hzxm8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vjrkg'
May 13 19:10:02.450: INFO: stderr: ""
May 13 19:10:02.451: INFO: stdout: "true"
May 13 19:10:02.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods update-demo-nautilus-hzxm8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vjrkg'
May 13 19:10:02.588: INFO: stderr: ""
May 13 19:10:02.588: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 13 19:10:02.588: INFO: validating pod update-demo-nautilus-hzxm8
May 13 19:10:02.606: INFO: got data: {
  "image": "nautilus.jpg"
}

May 13 19:10:02.606: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 13 19:10:02.606: INFO: update-demo-nautilus-hzxm8 is verified up and running
STEP: scaling down the replication controller
May 13 19:10:02.608: INFO: scanned /root for discovery docs: <nil>
May 13 19:10:02.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-vjrkg'
May 13 19:10:03.796: INFO: stderr: ""
May 13 19:10:03.796: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 13 19:10:03.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-vjrkg'
May 13 19:10:03.912: INFO: stderr: ""
May 13 19:10:03.912: INFO: stdout: "update-demo-nautilus-cqtdx update-demo-nautilus-hzxm8 "
STEP: Replicas for name=update-demo: expected=1 actual=2
May 13 19:10:08.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-vjrkg'
May 13 19:10:09.036: INFO: stderr: ""
May 13 19:10:09.036: INFO: stdout: "update-demo-nautilus-cqtdx "
May 13 19:10:09.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods update-demo-nautilus-cqtdx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vjrkg'
May 13 19:10:09.160: INFO: stderr: ""
May 13 19:10:09.160: INFO: stdout: "true"
May 13 19:10:09.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods update-demo-nautilus-cqtdx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vjrkg'
May 13 19:10:09.296: INFO: stderr: ""
May 13 19:10:09.296: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 13 19:10:09.296: INFO: validating pod update-demo-nautilus-cqtdx
May 13 19:10:09.309: INFO: got data: {
  "image": "nautilus.jpg"
}

May 13 19:10:09.309: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 13 19:10:09.309: INFO: update-demo-nautilus-cqtdx is verified up and running
STEP: scaling up the replication controller
May 13 19:10:09.310: INFO: scanned /root for discovery docs: <nil>
May 13 19:10:09.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-vjrkg'
May 13 19:10:10.503: INFO: stderr: ""
May 13 19:10:10.503: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 13 19:10:10.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-vjrkg'
May 13 19:10:10.625: INFO: stderr: ""
May 13 19:10:10.625: INFO: stdout: "update-demo-nautilus-cqtdx update-demo-nautilus-m88v6 "
May 13 19:10:10.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods update-demo-nautilus-cqtdx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vjrkg'
May 13 19:10:10.735: INFO: stderr: ""
May 13 19:10:10.735: INFO: stdout: "true"
May 13 19:10:10.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods update-demo-nautilus-cqtdx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vjrkg'
May 13 19:10:10.865: INFO: stderr: ""
May 13 19:10:10.865: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 13 19:10:10.865: INFO: validating pod update-demo-nautilus-cqtdx
May 13 19:10:10.880: INFO: got data: {
  "image": "nautilus.jpg"
}

May 13 19:10:10.880: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 13 19:10:10.880: INFO: update-demo-nautilus-cqtdx is verified up and running
May 13 19:10:10.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods update-demo-nautilus-m88v6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vjrkg'
May 13 19:10:10.999: INFO: stderr: ""
May 13 19:10:10.999: INFO: stdout: ""
May 13 19:10:10.999: INFO: update-demo-nautilus-m88v6 is created but not running
May 13 19:10:16.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-vjrkg'
May 13 19:10:16.152: INFO: stderr: ""
May 13 19:10:16.152: INFO: stdout: "update-demo-nautilus-cqtdx update-demo-nautilus-m88v6 "
May 13 19:10:16.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods update-demo-nautilus-cqtdx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vjrkg'
May 13 19:10:16.290: INFO: stderr: ""
May 13 19:10:16.290: INFO: stdout: "true"
May 13 19:10:16.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods update-demo-nautilus-cqtdx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vjrkg'
May 13 19:10:16.424: INFO: stderr: ""
May 13 19:10:16.424: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 13 19:10:16.424: INFO: validating pod update-demo-nautilus-cqtdx
May 13 19:10:16.511: INFO: got data: {
  "image": "nautilus.jpg"
}

May 13 19:10:16.511: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 13 19:10:16.511: INFO: update-demo-nautilus-cqtdx is verified up and running
May 13 19:10:16.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods update-demo-nautilus-m88v6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vjrkg'
May 13 19:10:16.645: INFO: stderr: ""
May 13 19:10:16.645: INFO: stdout: "true"
May 13 19:10:16.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods update-demo-nautilus-m88v6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vjrkg'
May 13 19:10:16.755: INFO: stderr: ""
May 13 19:10:16.755: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 13 19:10:16.755: INFO: validating pod update-demo-nautilus-m88v6
May 13 19:10:16.773: INFO: got data: {
  "image": "nautilus.jpg"
}

May 13 19:10:16.773: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 13 19:10:16.773: INFO: update-demo-nautilus-m88v6 is verified up and running
STEP: using delete to clean up resources
May 13 19:10:16.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-vjrkg'
May 13 19:10:16.913: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 13 19:10:16.913: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 13 19:10:16.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-vjrkg'
May 13 19:10:17.042: INFO: stderr: "No resources found.\n"
May 13 19:10:17.042: INFO: stdout: ""
May 13 19:10:17.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods -l name=update-demo --namespace=e2e-tests-kubectl-vjrkg -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 13 19:10:17.191: INFO: stderr: ""
May 13 19:10:17.191: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:10:17.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vjrkg" for this suite.
May 13 19:10:41.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:10:41.429: INFO: namespace: e2e-tests-kubectl-vjrkg, resource: bindings, ignored listing per whitelist
May 13 19:10:41.520: INFO: namespace e2e-tests-kubectl-vjrkg deletion completed in 24.314688405s

• [SLOW TEST:45.704 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:10:41.520: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-kp2qp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 13 19:10:41.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-kp2qp'
May 13 19:10:42.291: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
May 13 19:10:42.291: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
May 13 19:10:46.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-kp2qp'
May 13 19:10:46.457: INFO: stderr: ""
May 13 19:10:46.457: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:10:46.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kp2qp" for this suite.
May 13 19:11:08.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:11:08.783: INFO: namespace: e2e-tests-kubectl-kp2qp, resource: bindings, ignored listing per whitelist
May 13 19:11:08.899: INFO: namespace e2e-tests-kubectl-kp2qp deletion completed in 22.347433037s

• [SLOW TEST:27.379 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:11:08.899: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-847fm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 13 19:11:09.210: INFO: Waiting up to 5m0s for pod "downward-api-dd7a4a18-75b2-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-downward-api-847fm" to be "success or failure"
May 13 19:11:09.220: INFO: Pod "downward-api-dd7a4a18-75b2-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 10.230792ms
May 13 19:11:11.229: INFO: Pod "downward-api-dd7a4a18-75b2-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019414365s
May 13 19:11:13.253: INFO: Pod "downward-api-dd7a4a18-75b2-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043630011s
STEP: Saw pod success
May 13 19:11:13.253: INFO: Pod "downward-api-dd7a4a18-75b2-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:11:13.261: INFO: Trying to get logs from node 10.170.219.140 pod downward-api-dd7a4a18-75b2-11e9-a09a-7e4d6cfcc771 container dapi-container: <nil>
STEP: delete the pod
May 13 19:11:13.307: INFO: Waiting for pod downward-api-dd7a4a18-75b2-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:11:13.316: INFO: Pod downward-api-dd7a4a18-75b2-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:11:13.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-847fm" for this suite.
May 13 19:11:19.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:11:19.399: INFO: namespace: e2e-tests-downward-api-847fm, resource: bindings, ignored listing per whitelist
May 13 19:11:19.634: INFO: namespace e2e-tests-downward-api-847fm deletion completed in 6.30657118s

• [SLOW TEST:10.735 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:11:19.634: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-frss5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
May 13 19:11:19.952: INFO: Waiting up to 5m0s for pod "client-containers-e3e1a59a-75b2-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-containers-frss5" to be "success or failure"
May 13 19:11:19.961: INFO: Pod "client-containers-e3e1a59a-75b2-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 8.675653ms
May 13 19:11:21.971: INFO: Pod "client-containers-e3e1a59a-75b2-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019138835s
STEP: Saw pod success
May 13 19:11:21.971: INFO: Pod "client-containers-e3e1a59a-75b2-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:11:21.981: INFO: Trying to get logs from node 10.170.219.140 pod client-containers-e3e1a59a-75b2-11e9-a09a-7e4d6cfcc771 container test-container: <nil>
STEP: delete the pod
May 13 19:11:22.027: INFO: Waiting for pod client-containers-e3e1a59a-75b2-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:11:22.036: INFO: Pod client-containers-e3e1a59a-75b2-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:11:22.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-frss5" for this suite.
May 13 19:11:28.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:11:28.200: INFO: namespace: e2e-tests-containers-frss5, resource: bindings, ignored listing per whitelist
May 13 19:11:28.536: INFO: namespace e2e-tests-containers-frss5 deletion completed in 6.489735383s

• [SLOW TEST:8.902 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:11:28.537: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-q8dqj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-q8dqj
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
May 13 19:11:28.851: INFO: Found 0 stateful pods, waiting for 3
May 13 19:11:38.874: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 13 19:11:38.874: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 13 19:11:38.874: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
May 13 19:11:38.950: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
May 13 19:11:49.034: INFO: Updating stateful set ss2
May 13 19:11:49.054: INFO: Waiting for Pod e2e-tests-statefulset-q8dqj/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
May 13 19:11:59.176: INFO: Found 2 stateful pods, waiting for 3
May 13 19:12:09.241: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 13 19:12:09.241: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 13 19:12:09.241: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
May 13 19:12:09.290: INFO: Updating stateful set ss2
May 13 19:12:09.306: INFO: Waiting for Pod e2e-tests-statefulset-q8dqj/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
May 13 19:12:19.371: INFO: Updating stateful set ss2
May 13 19:12:19.388: INFO: Waiting for StatefulSet e2e-tests-statefulset-q8dqj/ss2 to complete update
May 13 19:12:19.388: INFO: Waiting for Pod e2e-tests-statefulset-q8dqj/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 13 19:12:29.426: INFO: Deleting all statefulset in ns e2e-tests-statefulset-q8dqj
May 13 19:12:29.435: INFO: Scaling statefulset ss2 to 0
May 13 19:12:49.475: INFO: Waiting for statefulset status.replicas updated to 0
May 13 19:12:49.483: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:12:49.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-q8dqj" for this suite.
May 13 19:12:57.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:12:57.808: INFO: namespace: e2e-tests-statefulset-q8dqj, resource: bindings, ignored listing per whitelist
May 13 19:12:58.031: INFO: namespace e2e-tests-statefulset-q8dqj deletion completed in 8.475468828s

• [SLOW TEST:89.495 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:12:58.032: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-z66bd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
May 13 19:12:58.491: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-z66bd,SelfLink:/api/v1/namespaces/e2e-tests-watch-z66bd/configmaps/e2e-watch-test-label-changed,UID:1e99f769-75b3-11e9-906d-b2bf80cbe475,ResourceVersion:41688,Generation:0,CreationTimestamp:2019-05-13 19:12:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 13 19:12:58.491: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-z66bd,SelfLink:/api/v1/namespaces/e2e-tests-watch-z66bd/configmaps/e2e-watch-test-label-changed,UID:1e99f769-75b3-11e9-906d-b2bf80cbe475,ResourceVersion:41689,Generation:0,CreationTimestamp:2019-05-13 19:12:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 13 19:12:58.491: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-z66bd,SelfLink:/api/v1/namespaces/e2e-tests-watch-z66bd/configmaps/e2e-watch-test-label-changed,UID:1e99f769-75b3-11e9-906d-b2bf80cbe475,ResourceVersion:41690,Generation:0,CreationTimestamp:2019-05-13 19:12:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
May 13 19:13:08.661: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-z66bd,SelfLink:/api/v1/namespaces/e2e-tests-watch-z66bd/configmaps/e2e-watch-test-label-changed,UID:1e99f769-75b3-11e9-906d-b2bf80cbe475,ResourceVersion:41708,Generation:0,CreationTimestamp:2019-05-13 19:12:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 13 19:13:08.662: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-z66bd,SelfLink:/api/v1/namespaces/e2e-tests-watch-z66bd/configmaps/e2e-watch-test-label-changed,UID:1e99f769-75b3-11e9-906d-b2bf80cbe475,ResourceVersion:41709,Generation:0,CreationTimestamp:2019-05-13 19:12:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
May 13 19:13:08.662: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-z66bd,SelfLink:/api/v1/namespaces/e2e-tests-watch-z66bd/configmaps/e2e-watch-test-label-changed,UID:1e99f769-75b3-11e9-906d-b2bf80cbe475,ResourceVersion:41710,Generation:0,CreationTimestamp:2019-05-13 19:12:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:13:08.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-z66bd" for this suite.
May 13 19:13:14.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:13:14.916: INFO: namespace: e2e-tests-watch-z66bd, resource: bindings, ignored listing per whitelist
May 13 19:13:14.970: INFO: namespace e2e-tests-watch-z66bd deletion completed in 6.298119769s

• [SLOW TEST:16.938 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:13:14.970: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-f5rxg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 13 19:13:15.369: INFO: Waiting up to 5m0s for pod "pod-28ace38b-75b3-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-emptydir-f5rxg" to be "success or failure"
May 13 19:13:15.379: INFO: Pod "pod-28ace38b-75b3-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 10.046908ms
May 13 19:13:17.388: INFO: Pod "pod-28ace38b-75b3-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0192003s
May 13 19:13:19.414: INFO: Pod "pod-28ace38b-75b3-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04485573s
STEP: Saw pod success
May 13 19:13:19.414: INFO: Pod "pod-28ace38b-75b3-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:13:19.422: INFO: Trying to get logs from node 10.170.219.140 pod pod-28ace38b-75b3-11e9-a09a-7e4d6cfcc771 container test-container: <nil>
STEP: delete the pod
May 13 19:13:19.466: INFO: Waiting for pod pod-28ace38b-75b3-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:13:19.541: INFO: Pod pod-28ace38b-75b3-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:13:19.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-f5rxg" for this suite.
May 13 19:13:25.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:13:25.784: INFO: namespace: e2e-tests-emptydir-f5rxg, resource: bindings, ignored listing per whitelist
May 13 19:13:25.945: INFO: namespace e2e-tests-emptydir-f5rxg deletion completed in 6.391595707s

• [SLOW TEST:10.974 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:13:25.945: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-mrqk2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
May 13 19:13:30.432: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 13 19:13:30.449: INFO: Pod pod-with-prestop-exec-hook still exists
May 13 19:13:32.449: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 13 19:13:32.459: INFO: Pod pod-with-prestop-exec-hook still exists
May 13 19:13:34.449: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 13 19:13:34.458: INFO: Pod pod-with-prestop-exec-hook still exists
May 13 19:13:36.450: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 13 19:13:36.459: INFO: Pod pod-with-prestop-exec-hook still exists
May 13 19:13:38.450: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 13 19:13:38.458: INFO: Pod pod-with-prestop-exec-hook still exists
May 13 19:13:40.450: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 13 19:13:40.473: INFO: Pod pod-with-prestop-exec-hook still exists
May 13 19:13:42.449: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 13 19:13:42.459: INFO: Pod pod-with-prestop-exec-hook still exists
May 13 19:13:44.449: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 13 19:13:44.461: INFO: Pod pod-with-prestop-exec-hook still exists
May 13 19:13:46.449: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 13 19:13:46.459: INFO: Pod pod-with-prestop-exec-hook still exists
May 13 19:13:48.449: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 13 19:13:48.458: INFO: Pod pod-with-prestop-exec-hook still exists
May 13 19:13:50.449: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 13 19:13:50.464: INFO: Pod pod-with-prestop-exec-hook still exists
May 13 19:13:52.449: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 13 19:13:52.474: INFO: Pod pod-with-prestop-exec-hook still exists
May 13 19:13:54.449: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 13 19:13:54.541: INFO: Pod pod-with-prestop-exec-hook still exists
May 13 19:13:56.449: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 13 19:13:56.461: INFO: Pod pod-with-prestop-exec-hook still exists
May 13 19:13:58.449: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 13 19:13:58.460: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:13:58.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-mrqk2" for this suite.
May 13 19:14:22.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:14:22.697: INFO: namespace: e2e-tests-container-lifecycle-hook-mrqk2, resource: bindings, ignored listing per whitelist
May 13 19:14:22.804: INFO: namespace e2e-tests-container-lifecycle-hook-mrqk2 deletion completed in 24.308612958s

• [SLOW TEST:56.859 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:14:22.804: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-fsvdh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-510f6afb-75b3-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume configMaps
May 13 19:14:23.136: INFO: Waiting up to 5m0s for pod "pod-configmaps-5110f77b-75b3-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-configmap-fsvdh" to be "success or failure"
May 13 19:14:23.149: INFO: Pod "pod-configmaps-5110f77b-75b3-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 13.518993ms
May 13 19:14:25.173: INFO: Pod "pod-configmaps-5110f77b-75b3-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.036953403s
STEP: Saw pod success
May 13 19:14:25.173: INFO: Pod "pod-configmaps-5110f77b-75b3-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:14:25.181: INFO: Trying to get logs from node 10.170.219.140 pod pod-configmaps-5110f77b-75b3-11e9-a09a-7e4d6cfcc771 container configmap-volume-test: <nil>
STEP: delete the pod
May 13 19:14:25.224: INFO: Waiting for pod pod-configmaps-5110f77b-75b3-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:14:25.232: INFO: Pod pod-configmaps-5110f77b-75b3-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:14:25.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-fsvdh" for this suite.
May 13 19:14:31.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:14:31.513: INFO: namespace: e2e-tests-configmap-fsvdh, resource: bindings, ignored listing per whitelist
May 13 19:14:31.607: INFO: namespace e2e-tests-configmap-fsvdh deletion completed in 6.304260135s

• [SLOW TEST:8.803 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:14:31.608: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-z5jxm
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-564d73b0-75b3-11e9-a09a-7e4d6cfcc771
STEP: Creating secret with name s-test-opt-upd-564d73f7-75b3-11e9-a09a-7e4d6cfcc771
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-564d73b0-75b3-11e9-a09a-7e4d6cfcc771
STEP: Updating secret s-test-opt-upd-564d73f7-75b3-11e9-a09a-7e4d6cfcc771
STEP: Creating secret with name s-test-opt-create-564d7417-75b3-11e9-a09a-7e4d6cfcc771
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:14:36.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-z5jxm" for this suite.
May 13 19:15:00.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:15:00.479: INFO: namespace: e2e-tests-secrets-z5jxm, resource: bindings, ignored listing per whitelist
May 13 19:15:00.613: INFO: namespace e2e-tests-secrets-z5jxm deletion completed in 24.437168548s

• [SLOW TEST:29.005 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:15:00.613: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-nsjrk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
May 13 19:15:01.079: INFO: Waiting up to 5m0s for pod "client-containers-67aed3f5-75b3-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-containers-nsjrk" to be "success or failure"
May 13 19:15:01.087: INFO: Pod "client-containers-67aed3f5-75b3-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 8.215354ms
May 13 19:15:03.097: INFO: Pod "client-containers-67aed3f5-75b3-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017598604s
STEP: Saw pod success
May 13 19:15:03.097: INFO: Pod "client-containers-67aed3f5-75b3-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:15:03.105: INFO: Trying to get logs from node 10.170.219.140 pod client-containers-67aed3f5-75b3-11e9-a09a-7e4d6cfcc771 container test-container: <nil>
STEP: delete the pod
May 13 19:15:03.151: INFO: Waiting for pod client-containers-67aed3f5-75b3-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:15:03.249: INFO: Pod client-containers-67aed3f5-75b3-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:15:03.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-nsjrk" for this suite.
May 13 19:15:09.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:15:09.745: INFO: namespace: e2e-tests-containers-nsjrk, resource: bindings, ignored listing per whitelist
May 13 19:15:09.825: INFO: namespace e2e-tests-containers-nsjrk deletion completed in 6.562522869s

• [SLOW TEST:9.212 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:15:09.825: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-4pb22
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 19:15:10.141: INFO: Pod name rollover-pod: Found 0 pods out of 1
May 13 19:15:15.151: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 13 19:15:15.151: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
May 13 19:15:17.161: INFO: Creating deployment "test-rollover-deployment"
May 13 19:15:17.251: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
May 13 19:15:17.262: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
May 13 19:15:17.281: INFO: Ensure that both replica sets have 1 created replica
May 13 19:15:17.304: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
May 13 19:15:17.324: INFO: Updating deployment test-rollover-deployment
May 13 19:15:17.324: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
May 13 19:15:19.354: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
May 13 19:15:19.371: INFO: Make sure deployment "test-rollover-deployment" is complete
May 13 19:15:19.441: INFO: all replica sets need to contain the pod-template-hash label
May 13 19:15:19.441: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693371717, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693371717, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693371718, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693371717, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 13 19:15:21.459: INFO: all replica sets need to contain the pod-template-hash label
May 13 19:15:21.459: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693371717, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693371717, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693371718, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693371717, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 13 19:15:23.468: INFO: all replica sets need to contain the pod-template-hash label
May 13 19:15:23.468: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693371717, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693371717, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693371718, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693371717, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 13 19:15:25.463: INFO: all replica sets need to contain the pod-template-hash label
May 13 19:15:25.463: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693371717, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693371717, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693371718, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693371717, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 13 19:15:27.462: INFO: all replica sets need to contain the pod-template-hash label
May 13 19:15:27.462: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693371717, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693371717, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693371718, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693371717, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 13 19:15:29.475: INFO: 
May 13 19:15:29.475: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 13 19:15:29.500: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-4pb22,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4pb22/deployments/test-rollover-deployment,UID:71482b6f-75b3-11e9-906d-b2bf80cbe475,ResourceVersion:42260,Generation:2,CreationTimestamp:2019-05-13 19:15:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-13 19:15:17 +0000 UTC 2019-05-13 19:15:17 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-13 19:15:28 +0000 UTC 2019-05-13 19:15:17 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 13 19:15:29.509: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-4pb22,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4pb22/replicasets/test-rollover-deployment-5b76ff8c4,UID:71609e4c-75b3-11e9-a685-3eb3c297d0da,ResourceVersion:42251,Generation:2,CreationTimestamp:2019-05-13 19:15:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 71482b6f-75b3-11e9-906d-b2bf80cbe475 0xc42221bb67 0xc42221bb68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 13 19:15:29.509: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
May 13 19:15:29.509: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-4pb22,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4pb22/replicasets/test-rollover-controller,UID:6d161bbc-75b3-11e9-906d-b2bf80cbe475,ResourceVersion:42259,Generation:2,CreationTimestamp:2019-05-13 19:15:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 71482b6f-75b3-11e9-906d-b2bf80cbe475 0xc42221ba8e 0xc42221ba8f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 13 19:15:29.509: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-4pb22,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4pb22/replicasets/test-rollover-deployment-6975f4fb87,UID:714ceaec-75b3-11e9-a685-3eb3c297d0da,ResourceVersion:42216,Generation:2,CreationTimestamp:2019-05-13 19:15:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 71482b6f-75b3-11e9-906d-b2bf80cbe475 0xc42221bf37 0xc42221bf38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 13 19:15:29.518: INFO: Pod "test-rollover-deployment-5b76ff8c4-ksh56" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-ksh56,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-4pb22,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4pb22/pods/test-rollover-deployment-5b76ff8c4-ksh56,UID:716608f4-75b3-11e9-a685-3eb3c297d0da,ResourceVersion:42232,Generation:0,CreationTimestamp:2019-05-13 19:15:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 71609e4c-75b3-11e9-a685-3eb3c297d0da 0xc420c14120 0xc420c14121}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fz7m2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fz7m2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-fz7m2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420c14190} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420c141b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:15:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:15:18 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:15:18 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:15:17 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.140,PodIP:172.30.208.32,StartTime:2019-05-13 19:15:17 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-13 19:15:18 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://bebc497780ca7b71b5d790b704ee506df239c1a24d815442fe7fee579cfbdc49}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:15:29.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-4pb22" for this suite.
May 13 19:15:37.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:15:37.706: INFO: namespace: e2e-tests-deployment-4pb22, resource: bindings, ignored listing per whitelist
May 13 19:15:37.917: INFO: namespace e2e-tests-deployment-4pb22 deletion completed in 8.387780653s

• [SLOW TEST:28.092 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:15:37.917: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-z2zm9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May 13 19:15:42.474: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 13 19:15:42.483: INFO: Pod pod-with-poststart-exec-hook still exists
May 13 19:15:44.483: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 13 19:15:44.493: INFO: Pod pod-with-poststart-exec-hook still exists
May 13 19:15:46.484: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 13 19:15:46.492: INFO: Pod pod-with-poststart-exec-hook still exists
May 13 19:15:48.484: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 13 19:15:48.492: INFO: Pod pod-with-poststart-exec-hook still exists
May 13 19:15:50.484: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 13 19:15:50.509: INFO: Pod pod-with-poststart-exec-hook still exists
May 13 19:15:52.484: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 13 19:15:52.492: INFO: Pod pod-with-poststart-exec-hook still exists
May 13 19:15:54.483: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 13 19:15:54.492: INFO: Pod pod-with-poststart-exec-hook still exists
May 13 19:15:56.484: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 13 19:15:56.492: INFO: Pod pod-with-poststart-exec-hook still exists
May 13 19:15:58.483: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 13 19:15:58.492: INFO: Pod pod-with-poststart-exec-hook still exists
May 13 19:16:00.483: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 13 19:16:00.588: INFO: Pod pod-with-poststart-exec-hook still exists
May 13 19:16:02.484: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 13 19:16:02.511: INFO: Pod pod-with-poststart-exec-hook still exists
May 13 19:16:04.483: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 13 19:16:04.493: INFO: Pod pod-with-poststart-exec-hook still exists
May 13 19:16:06.484: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 13 19:16:06.541: INFO: Pod pod-with-poststart-exec-hook still exists
May 13 19:16:08.484: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 13 19:16:08.541: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:16:08.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-z2zm9" for this suite.
May 13 19:16:32.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:16:32.821: INFO: namespace: e2e-tests-container-lifecycle-hook-z2zm9, resource: bindings, ignored listing per whitelist
May 13 19:16:32.855: INFO: namespace e2e-tests-container-lifecycle-hook-z2zm9 deletion completed in 24.302224044s

• [SLOW TEST:54.938 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:16:32.856: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-ml99z
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 19:16:33.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 version'
May 13 19:16:33.271: INFO: stderr: ""
May 13 19:16:33.271: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.8+IKS\", GitCommit:\"7a4f512a9a758154ccca50b13aaa8a76970b51df\", GitTreeState:\"clean\", BuildDate:\"2019-05-09T01:54:58Z\", GoVersion:\"go1.10.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:16:33.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ml99z" for this suite.
May 13 19:16:39.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:16:39.527: INFO: namespace: e2e-tests-kubectl-ml99z, resource: bindings, ignored listing per whitelist
May 13 19:16:39.603: INFO: namespace e2e-tests-kubectl-ml99z deletion completed in 6.322700198s

• [SLOW TEST:6.747 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:16:39.603: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-9gprs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
May 13 19:16:39.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 api-versions'
May 13 19:16:39.998: INFO: stderr: ""
May 13 19:16:39.998: INFO: stdout: "admissionregistration.k8s.io/v1alpha1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:16:39.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9gprs" for this suite.
May 13 19:16:46.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:16:46.367: INFO: namespace: e2e-tests-kubectl-9gprs, resource: bindings, ignored listing per whitelist
May 13 19:16:46.415: INFO: namespace e2e-tests-kubectl-9gprs deletion completed in 6.407154188s

• [SLOW TEST:6.812 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:16:46.415: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-vfspg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-a6a8a890-75b3-11e9-a09a-7e4d6cfcc771
STEP: Creating secret with name s-test-opt-upd-a6a8a8d4-75b3-11e9-a09a-7e4d6cfcc771
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-a6a8a890-75b3-11e9-a09a-7e4d6cfcc771
STEP: Updating secret s-test-opt-upd-a6a8a8d4-75b3-11e9-a09a-7e4d6cfcc771
STEP: Creating secret with name s-test-opt-create-a6a8a911-75b3-11e9-a09a-7e4d6cfcc771
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:18:00.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vfspg" for this suite.
May 13 19:18:24.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:18:25.046: INFO: namespace: e2e-tests-projected-vfspg, resource: bindings, ignored listing per whitelist
May 13 19:18:25.201: INFO: namespace e2e-tests-projected-vfspg deletion completed in 24.326554938s

• [SLOW TEST:98.786 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:18:25.202: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-n56dd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-e18a5fab-75b3-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume secrets
May 13 19:18:25.535: INFO: Waiting up to 5m0s for pod "pod-secrets-e18be96c-75b3-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-secrets-n56dd" to be "success or failure"
May 13 19:18:25.544: INFO: Pod "pod-secrets-e18be96c-75b3-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 8.726072ms
May 13 19:18:27.553: INFO: Pod "pod-secrets-e18be96c-75b3-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018597662s
STEP: Saw pod success
May 13 19:18:27.553: INFO: Pod "pod-secrets-e18be96c-75b3-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:18:27.564: INFO: Trying to get logs from node 10.170.219.140 pod pod-secrets-e18be96c-75b3-11e9-a09a-7e4d6cfcc771 container secret-volume-test: <nil>
STEP: delete the pod
May 13 19:18:27.667: INFO: Waiting for pod pod-secrets-e18be96c-75b3-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:18:27.675: INFO: Pod pod-secrets-e18be96c-75b3-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:18:27.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-n56dd" for this suite.
May 13 19:18:33.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:18:33.815: INFO: namespace: e2e-tests-secrets-n56dd, resource: bindings, ignored listing per whitelist
May 13 19:18:34.066: INFO: namespace e2e-tests-secrets-n56dd deletion completed in 6.379973557s

• [SLOW TEST:8.865 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:18:34.067: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-xlwhj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-8v8d
STEP: Creating a pod to test atomic-volume-subpath
May 13 19:18:34.447: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-8v8d" in namespace "e2e-tests-subpath-xlwhj" to be "success or failure"
May 13 19:18:34.456: INFO: Pod "pod-subpath-test-projected-8v8d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.314596ms
May 13 19:18:36.465: INFO: Pod "pod-subpath-test-projected-8v8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017315065s
May 13 19:18:38.476: INFO: Pod "pod-subpath-test-projected-8v8d": Phase="Running", Reason="", readiness=false. Elapsed: 4.028906826s
May 13 19:18:40.485: INFO: Pod "pod-subpath-test-projected-8v8d": Phase="Running", Reason="", readiness=false. Elapsed: 6.037857241s
May 13 19:18:42.511: INFO: Pod "pod-subpath-test-projected-8v8d": Phase="Running", Reason="", readiness=false. Elapsed: 8.063753526s
May 13 19:18:44.520: INFO: Pod "pod-subpath-test-projected-8v8d": Phase="Running", Reason="", readiness=false. Elapsed: 10.072616293s
May 13 19:18:46.530: INFO: Pod "pod-subpath-test-projected-8v8d": Phase="Running", Reason="", readiness=false. Elapsed: 12.082054136s
May 13 19:18:48.539: INFO: Pod "pod-subpath-test-projected-8v8d": Phase="Running", Reason="", readiness=false. Elapsed: 14.0913933s
May 13 19:18:50.548: INFO: Pod "pod-subpath-test-projected-8v8d": Phase="Running", Reason="", readiness=false. Elapsed: 16.100544225s
May 13 19:18:52.572: INFO: Pod "pod-subpath-test-projected-8v8d": Phase="Running", Reason="", readiness=false. Elapsed: 18.124955413s
May 13 19:18:54.581: INFO: Pod "pod-subpath-test-projected-8v8d": Phase="Running", Reason="", readiness=false. Elapsed: 20.133592398s
May 13 19:18:56.590: INFO: Pod "pod-subpath-test-projected-8v8d": Phase="Running", Reason="", readiness=false. Elapsed: 22.142127248s
May 13 19:18:58.598: INFO: Pod "pod-subpath-test-projected-8v8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.150859057s
STEP: Saw pod success
May 13 19:18:58.598: INFO: Pod "pod-subpath-test-projected-8v8d" satisfied condition "success or failure"
May 13 19:18:58.607: INFO: Trying to get logs from node 10.170.219.140 pod pod-subpath-test-projected-8v8d container test-container-subpath-projected-8v8d: <nil>
STEP: delete the pod
May 13 19:18:58.654: INFO: Waiting for pod pod-subpath-test-projected-8v8d to disappear
May 13 19:18:58.663: INFO: Pod pod-subpath-test-projected-8v8d no longer exists
STEP: Deleting pod pod-subpath-test-projected-8v8d
May 13 19:18:58.663: INFO: Deleting pod "pod-subpath-test-projected-8v8d" in namespace "e2e-tests-subpath-xlwhj"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:18:58.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-xlwhj" for this suite.
May 13 19:19:04.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:19:05.029: INFO: namespace: e2e-tests-subpath-xlwhj, resource: bindings, ignored listing per whitelist
May 13 19:19:05.037: INFO: namespace e2e-tests-subpath-xlwhj deletion completed in 6.34716368s

• [SLOW TEST:30.971 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:19:05.038: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-7vnrx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-f947d494-75b3-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume secrets
May 13 19:19:05.361: INFO: Waiting up to 5m0s for pod "pod-secrets-f94964ee-75b3-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-secrets-7vnrx" to be "success or failure"
May 13 19:19:05.370: INFO: Pod "pod-secrets-f94964ee-75b3-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 9.165333ms
May 13 19:19:07.380: INFO: Pod "pod-secrets-f94964ee-75b3-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019152265s
STEP: Saw pod success
May 13 19:19:07.380: INFO: Pod "pod-secrets-f94964ee-75b3-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:19:07.450: INFO: Trying to get logs from node 10.170.219.140 pod pod-secrets-f94964ee-75b3-11e9-a09a-7e4d6cfcc771 container secret-volume-test: <nil>
STEP: delete the pod
May 13 19:19:07.729: INFO: Waiting for pod pod-secrets-f94964ee-75b3-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:19:07.737: INFO: Pod pod-secrets-f94964ee-75b3-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:19:07.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-7vnrx" for this suite.
May 13 19:19:13.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:19:13.885: INFO: namespace: e2e-tests-secrets-7vnrx, resource: bindings, ignored listing per whitelist
May 13 19:19:14.082: INFO: namespace e2e-tests-secrets-7vnrx deletion completed in 6.334205413s

• [SLOW TEST:9.044 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:19:14.083: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-55l9f
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 13 19:19:14.450: INFO: Waiting up to 5m0s for pod "pod-feb45458-75b3-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-emptydir-55l9f" to be "success or failure"
May 13 19:19:14.459: INFO: Pod "pod-feb45458-75b3-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 8.616939ms
May 13 19:19:16.674: INFO: Pod "pod-feb45458-75b3-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.224286345s
STEP: Saw pod success
May 13 19:19:16.674: INFO: Pod "pod-feb45458-75b3-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:19:16.683: INFO: Trying to get logs from node 10.170.219.140 pod pod-feb45458-75b3-11e9-a09a-7e4d6cfcc771 container test-container: <nil>
STEP: delete the pod
May 13 19:19:16.727: INFO: Waiting for pod pod-feb45458-75b3-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:19:16.735: INFO: Pod pod-feb45458-75b3-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:19:16.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-55l9f" for this suite.
May 13 19:19:22.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:19:22.857: INFO: namespace: e2e-tests-emptydir-55l9f, resource: bindings, ignored listing per whitelist
May 13 19:19:23.167: INFO: namespace e2e-tests-emptydir-55l9f deletion completed in 6.421072257s

• [SLOW TEST:9.085 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:19:23.167: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-82hpn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 19:19:23.527: INFO: Waiting up to 5m0s for pod "downwardapi-volume-041c71af-75b4-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-downward-api-82hpn" to be "success or failure"
May 13 19:19:23.539: INFO: Pod "downwardapi-volume-041c71af-75b4-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 11.966879ms
May 13 19:19:25.568: INFO: Pod "downwardapi-volume-041c71af-75b4-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.040943212s
STEP: Saw pod success
May 13 19:19:25.568: INFO: Pod "downwardapi-volume-041c71af-75b4-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:19:25.641: INFO: Trying to get logs from node 10.170.219.140 pod downwardapi-volume-041c71af-75b4-11e9-a09a-7e4d6cfcc771 container client-container: <nil>
STEP: delete the pod
May 13 19:19:25.689: INFO: Waiting for pod downwardapi-volume-041c71af-75b4-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:19:25.698: INFO: Pod downwardapi-volume-041c71af-75b4-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:19:25.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-82hpn" for this suite.
May 13 19:19:33.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:19:33.894: INFO: namespace: e2e-tests-downward-api-82hpn, resource: bindings, ignored listing per whitelist
May 13 19:19:34.113: INFO: namespace e2e-tests-downward-api-82hpn deletion completed in 8.404740427s

• [SLOW TEST:10.946 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:19:34.113: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-dqwlp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 19:19:34.436: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0a9d8759-75b4-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-downward-api-dqwlp" to be "success or failure"
May 13 19:19:34.444: INFO: Pod "downwardapi-volume-0a9d8759-75b4-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 8.2571ms
May 13 19:19:36.468: INFO: Pod "downwardapi-volume-0a9d8759-75b4-11e9-a09a-7e4d6cfcc771": Phase="Running", Reason="", readiness=true. Elapsed: 2.031812128s
May 13 19:19:38.476: INFO: Pod "downwardapi-volume-0a9d8759-75b4-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040146452s
STEP: Saw pod success
May 13 19:19:38.476: INFO: Pod "downwardapi-volume-0a9d8759-75b4-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:19:38.486: INFO: Trying to get logs from node 10.170.219.140 pod downwardapi-volume-0a9d8759-75b4-11e9-a09a-7e4d6cfcc771 container client-container: <nil>
STEP: delete the pod
May 13 19:19:38.568: INFO: Waiting for pod downwardapi-volume-0a9d8759-75b4-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:19:38.578: INFO: Pod downwardapi-volume-0a9d8759-75b4-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:19:38.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dqwlp" for this suite.
May 13 19:19:46.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:19:46.765: INFO: namespace: e2e-tests-downward-api-dqwlp, resource: bindings, ignored listing per whitelist
May 13 19:19:46.900: INFO: namespace e2e-tests-downward-api-dqwlp deletion completed in 8.311473589s

• [SLOW TEST:12.787 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:19:46.900: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-t2wpn
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
May 13 19:19:47.223: INFO: Waiting up to 5m0s for pod "pod-123cbedf-75b4-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-emptydir-t2wpn" to be "success or failure"
May 13 19:19:47.230: INFO: Pod "pod-123cbedf-75b4-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 7.513251ms
May 13 19:19:49.240: INFO: Pod "pod-123cbedf-75b4-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016903319s
STEP: Saw pod success
May 13 19:19:49.240: INFO: Pod "pod-123cbedf-75b4-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:19:49.248: INFO: Trying to get logs from node 10.170.219.140 pod pod-123cbedf-75b4-11e9-a09a-7e4d6cfcc771 container test-container: <nil>
STEP: delete the pod
May 13 19:19:49.297: INFO: Waiting for pod pod-123cbedf-75b4-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:19:49.305: INFO: Pod pod-123cbedf-75b4-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:19:49.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-t2wpn" for this suite.
May 13 19:19:55.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:19:55.692: INFO: namespace: e2e-tests-emptydir-t2wpn, resource: bindings, ignored listing per whitelist
May 13 19:19:55.702: INFO: namespace e2e-tests-emptydir-t2wpn deletion completed in 6.385748238s

• [SLOW TEST:8.802 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:19:55.702: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-kn8m6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 13 19:19:58.713: INFO: Successfully updated pod "pod-update-177d49ed-75b4-11e9-a09a-7e4d6cfcc771"
STEP: verifying the updated pod is in kubernetes
May 13 19:19:58.729: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:19:58.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-kn8m6" for this suite.
May 13 19:20:20.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:20:20.911: INFO: namespace: e2e-tests-pods-kn8m6, resource: bindings, ignored listing per whitelist
May 13 19:20:21.119: INFO: namespace e2e-tests-pods-kn8m6 deletion completed in 22.379673348s

• [SLOW TEST:25.417 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:20:21.119: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-wbfcv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-26a068c0-75b4-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume configMaps
May 13 19:20:21.443: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-26a1e01a-75b4-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-projected-wbfcv" to be "success or failure"
May 13 19:20:21.454: INFO: Pod "pod-projected-configmaps-26a1e01a-75b4-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 11.325133ms
May 13 19:20:23.464: INFO: Pod "pod-projected-configmaps-26a1e01a-75b4-11e9-a09a-7e4d6cfcc771": Phase="Running", Reason="", readiness=true. Elapsed: 2.021192556s
May 13 19:20:25.473: INFO: Pod "pod-projected-configmaps-26a1e01a-75b4-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030305516s
STEP: Saw pod success
May 13 19:20:25.474: INFO: Pod "pod-projected-configmaps-26a1e01a-75b4-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:20:25.481: INFO: Trying to get logs from node 10.170.219.140 pod pod-projected-configmaps-26a1e01a-75b4-11e9-a09a-7e4d6cfcc771 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 13 19:20:25.535: INFO: Waiting for pod pod-projected-configmaps-26a1e01a-75b4-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:20:25.542: INFO: Pod pod-projected-configmaps-26a1e01a-75b4-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:20:25.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wbfcv" for this suite.
May 13 19:20:31.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:20:31.659: INFO: namespace: e2e-tests-projected-wbfcv, resource: bindings, ignored listing per whitelist
May 13 19:20:32.045: INFO: namespace e2e-tests-projected-wbfcv deletion completed in 6.492401298s

• [SLOW TEST:10.926 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:20:32.046: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-6tpwb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-6tpwb
May 13 19:20:34.514: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-6tpwb
STEP: checking the pod's current state and verifying that restartCount is present
May 13 19:20:34.523: INFO: Initial restart count of pod liveness-http is 0
May 13 19:20:50.620: INFO: Restart count of pod e2e-tests-container-probe-6tpwb/liveness-http is now 1 (16.096544443s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:20:50.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-6tpwb" for this suite.
May 13 19:20:56.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:20:56.828: INFO: namespace: e2e-tests-container-probe-6tpwb, resource: bindings, ignored listing per whitelist
May 13 19:20:57.006: INFO: namespace e2e-tests-container-probe-6tpwb deletion completed in 6.348429932s

• [SLOW TEST:24.960 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:20:57.006: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-9lscp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-9lscp
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 13 19:20:57.301: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 13 19:21:15.605: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.30.217.138 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-9lscp PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 19:21:15.605: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
May 13 19:21:16.854: INFO: Found all expected endpoints: [netserver-0]
May 13 19:21:17.171: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.30.208.40 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-9lscp PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 19:21:17.172: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
May 13 19:21:18.418: INFO: Found all expected endpoints: [netserver-1]
May 13 19:21:18.427: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.30.136.14 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-9lscp PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 19:21:18.427: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
May 13 19:21:19.615: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:21:19.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-9lscp" for this suite.
May 13 19:21:43.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:21:43.697: INFO: namespace: e2e-tests-pod-network-test-9lscp, resource: bindings, ignored listing per whitelist
May 13 19:21:43.966: INFO: namespace e2e-tests-pod-network-test-9lscp deletion completed in 24.340129988s

• [SLOW TEST:46.960 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:21:43.966: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-9tktt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 19:21:44.276: INFO: Creating deployment "test-recreate-deployment"
May 13 19:21:44.285: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
May 13 19:21:44.303: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
May 13 19:21:46.333: INFO: Waiting deployment "test-recreate-deployment" to complete
May 13 19:21:46.342: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
May 13 19:21:46.359: INFO: Updating deployment test-recreate-deployment
May 13 19:21:46.359: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 13 19:21:46.452: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-9tktt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9tktt/deployments/test-recreate-deployment,UID:58051fa1-75b4-11e9-906d-b2bf80cbe475,ResourceVersion:43693,Generation:2,CreationTimestamp:2019-05-13 19:21:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-05-13 19:21:46 +0000 UTC 2019-05-13 19:21:46 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-05-13 19:21:46 +0000 UTC 2019-05-13 19:21:44 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

May 13 19:21:46.461: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-9tktt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9tktt/replicasets/test-recreate-deployment-7cf749666b,UID:594a1f20-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:43692,Generation:1,CreationTimestamp:2019-05-13 19:21:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 58051fa1-75b4-11e9-906d-b2bf80cbe475 0xc421fe4207 0xc421fe4208}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 13 19:21:46.461: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
May 13 19:21:46.461: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-9tktt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9tktt/replicasets/test-recreate-deployment-79f694ff59,UID:5808889f-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:43683,Generation:2,CreationTimestamp:2019-05-13 19:21:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 58051fa1-75b4-11e9-906d-b2bf80cbe475 0xc421fe4137 0xc421fe4138}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 13 19:21:46.469: INFO: Pod "test-recreate-deployment-7cf749666b-mvxfz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-mvxfz,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-9tktt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9tktt/pods/test-recreate-deployment-7cf749666b-mvxfz,UID:594b8cc0-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:43695,Generation:0,CreationTimestamp:2019-05-13 19:21:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b 594a1f20-75b4-11e9-a685-3eb3c297d0da 0xc4224b2bd7 0xc4224b2bd8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t95wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t95wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t95wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4224b2c50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4224b2c70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:46 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.140,PodIP:,StartTime:2019-05-13 19:21:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:21:46.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-9tktt" for this suite.
May 13 19:21:52.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:21:52.720: INFO: namespace: e2e-tests-deployment-9tktt, resource: bindings, ignored listing per whitelist
May 13 19:21:52.787: INFO: namespace e2e-tests-deployment-9tktt deletion completed in 6.306888418s

• [SLOW TEST:8.820 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:21:52.788: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-srf2r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 19:21:53.146: INFO: Creating deployment "nginx-deployment"
May 13 19:21:53.156: INFO: Waiting for observed generation 1
May 13 19:21:55.176: INFO: Waiting for all required pods to come up
May 13 19:21:55.188: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
May 13 19:21:59.210: INFO: Waiting for deployment "nginx-deployment" to complete
May 13 19:21:59.241: INFO: Updating deployment "nginx-deployment" with a non-existent image
May 13 19:21:59.260: INFO: Updating deployment nginx-deployment
May 13 19:21:59.260: INFO: Waiting for observed generation 2
May 13 19:22:01.277: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
May 13 19:22:01.341: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
May 13 19:22:01.349: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
May 13 19:22:01.374: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
May 13 19:22:01.374: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
May 13 19:22:01.382: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
May 13 19:22:01.404: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
May 13 19:22:01.404: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
May 13 19:22:01.422: INFO: Updating deployment nginx-deployment
May 13 19:22:01.422: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
May 13 19:22:01.444: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
May 13 19:22:03.469: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 13 19:22:03.487: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-srf2r,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-srf2r/deployments/nginx-deployment,UID:5d4ebb87-75b4-11e9-906d-b2bf80cbe475,ResourceVersion:44082,Generation:3,CreationTimestamp:2019-05-13 19:21:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-05-13 19:22:01 +0000 UTC 2019-05-13 19:22:01 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-05-13 19:22:01 +0000 UTC 2019-05-13 19:21:53 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

May 13 19:22:03.495: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-srf2r,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-srf2r/replicasets/nginx-deployment-7dc8f79789,UID:60f355e0-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:44077,Generation:3,CreationTimestamp:2019-05-13 19:21:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 5d4ebb87-75b4-11e9-906d-b2bf80cbe475 0xc420d50507 0xc420d50508}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 13 19:22:03.495: INFO: All old ReplicaSets of Deployment "nginx-deployment":
May 13 19:22:03.496: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-srf2r,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-srf2r/replicasets/nginx-deployment-7f9675fb8b,UID:5d4fe566-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:44075,Generation:3,CreationTimestamp:2019-05-13 19:21:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 5d4ebb87-75b4-11e9-906d-b2bf80cbe475 0xc420d50657 0xc420d50658}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
May 13 19:22:03.510: INFO: Pod "nginx-deployment-7dc8f79789-4w7dt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-4w7dt,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7dc8f79789-4w7dt,UID:60fdf54a-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:44014,Generation:0,CreationTimestamp:2019-05-13 19:21:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 60f355e0-75b4-11e9-a685-3eb3c297d0da 0xc42166ab07 0xc42166ab08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42166ab90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42166abb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:59 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.140,PodIP:172.30.208.61,StartTime:2019-05-13 19:21:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.510: INFO: Pod "nginx-deployment-7dc8f79789-7k5xm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-7k5xm,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7dc8f79789-7k5xm,UID:60f61598-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:43999,Generation:0,CreationTimestamp:2019-05-13 19:21:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 60f355e0-75b4-11e9-a685-3eb3c297d0da 0xc42166ac90 0xc42166ac91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.189,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42166ad10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42166ad30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:59 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.189,PodIP:172.30.136.18,StartTime:2019-05-13 19:21:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.510: INFO: Pod "nginx-deployment-7dc8f79789-9ftfp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-9ftfp,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7dc8f79789-9ftfp,UID:623fe960-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:44078,Generation:0,CreationTimestamp:2019-05-13 19:22:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 60f355e0-75b4-11e9-a685-3eb3c297d0da 0xc42166ae10 0xc42166ae11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.170,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42166ae90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42166aeb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.170,PodIP:,StartTime:2019-05-13 19:22:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.510: INFO: Pod "nginx-deployment-7dc8f79789-c5p7d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-c5p7d,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7dc8f79789-c5p7d,UID:6241e468-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:44114,Generation:0,CreationTimestamp:2019-05-13 19:22:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 60f355e0-75b4-11e9-a685-3eb3c297d0da 0xc42166af70 0xc42166af71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42166b000} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42166b020}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.140,PodIP:,StartTime:2019-05-13 19:22:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.510: INFO: Pod "nginx-deployment-7dc8f79789-cb24m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-cb24m,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7dc8f79789-cb24m,UID:60f47d37-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:44011,Generation:0,CreationTimestamp:2019-05-13 19:21:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 60f355e0-75b4-11e9-a685-3eb3c297d0da 0xc42166b0e0 0xc42166b0e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42166b160} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42166b180}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:59 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.140,PodIP:172.30.208.59,StartTime:2019-05-13 19:21:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.510: INFO: Pod "nginx-deployment-7dc8f79789-ccrhq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-ccrhq,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7dc8f79789-ccrhq,UID:6241e29b-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:44085,Generation:0,CreationTimestamp:2019-05-13 19:22:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 60f355e0-75b4-11e9-a685-3eb3c297d0da 0xc42166b260 0xc42166b261}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.170,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42166b2e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42166b300}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.170,PodIP:,StartTime:2019-05-13 19:22:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.510: INFO: Pod "nginx-deployment-7dc8f79789-chf96" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-chf96,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7dc8f79789-chf96,UID:62439e2c-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:44095,Generation:0,CreationTimestamp:2019-05-13 19:22:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 60f355e0-75b4-11e9-a685-3eb3c297d0da 0xc42166b3c0 0xc42166b3c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.170,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42166b440} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42166b460}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.170,PodIP:,StartTime:2019-05-13 19:22:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.510: INFO: Pod "nginx-deployment-7dc8f79789-msc89" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-msc89,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7dc8f79789-msc89,UID:6248f7a5-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:44073,Generation:0,CreationTimestamp:2019-05-13 19:22:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 60f355e0-75b4-11e9-a685-3eb3c297d0da 0xc42166b520 0xc42166b521}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.189,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42166b5a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42166b5c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.510: INFO: Pod "nginx-deployment-7dc8f79789-n2gc8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-n2gc8,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7dc8f79789-n2gc8,UID:6243bfe5-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:44055,Generation:0,CreationTimestamp:2019-05-13 19:22:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 60f355e0-75b4-11e9-a685-3eb3c297d0da 0xc42166b630 0xc42166b631}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42166b6b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42166b6d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.511: INFO: Pod "nginx-deployment-7dc8f79789-prcjp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-prcjp,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7dc8f79789-prcjp,UID:6243d7f3-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:44054,Generation:0,CreationTimestamp:2019-05-13 19:22:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 60f355e0-75b4-11e9-a685-3eb3c297d0da 0xc42166b740 0xc42166b741}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42166b7c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42166b7e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.511: INFO: Pod "nginx-deployment-7dc8f79789-tfr6q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-tfr6q,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7dc8f79789-tfr6q,UID:62437d9a-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:44053,Generation:0,CreationTimestamp:2019-05-13 19:22:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 60f355e0-75b4-11e9-a685-3eb3c297d0da 0xc42166b850 0xc42166b851}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.189,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42166b8d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42166b8f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.511: INFO: Pod "nginx-deployment-7dc8f79789-tsxww" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-tsxww,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7dc8f79789-tsxww,UID:60f6022b-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:44005,Generation:0,CreationTimestamp:2019-05-13 19:21:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 60f355e0-75b4-11e9-a685-3eb3c297d0da 0xc42166b960 0xc42166b961}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.170,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42166b9e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42166ba00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:59 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.170,PodIP:172.30.217.141,StartTime:2019-05-13 19:21:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.511: INFO: Pod "nginx-deployment-7dc8f79789-w4rzp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-w4rzp,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7dc8f79789-w4rzp,UID:60ffb5f3-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:44009,Generation:0,CreationTimestamp:2019-05-13 19:21:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 60f355e0-75b4-11e9-a685-3eb3c297d0da 0xc42166bae0 0xc42166bae1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.189,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42166bb60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42166bb80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:59 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.189,PodIP:172.30.136.25,StartTime:2019-05-13 19:21:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.511: INFO: Pod "nginx-deployment-7f9675fb8b-4cm4x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-4cm4x,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7f9675fb8b-4cm4x,UID:6242668b-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:44124,Generation:0,CreationTimestamp:2019-05-13 19:22:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 5d4fe566-75b4-11e9-a685-3eb3c297d0da 0xc42166bc60 0xc42166bc61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.189,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42166bcd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42166bcf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.189,PodIP:,StartTime:2019-05-13 19:22:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.511: INFO: Pod "nginx-deployment-7f9675fb8b-595x7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-595x7,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7f9675fb8b-595x7,UID:5d563568-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:43887,Generation:0,CreationTimestamp:2019-05-13 19:21:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 5d4fe566-75b4-11e9-a685-3eb3c297d0da 0xc42166bda7 0xc42166bda8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42166be20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42166be50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:53 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:53 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.140,PodIP:172.30.208.52,StartTime:2019-05-13 19:21:53 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-13 19:21:54 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://0b1f968538a15bc3dd79341c50c935ade318637e5c9205a3d2d68ea06f706c11}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.511: INFO: Pod "nginx-deployment-7f9675fb8b-74n2k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-74n2k,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7f9675fb8b-74n2k,UID:6240aa0e-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:44064,Generation:0,CreationTimestamp:2019-05-13 19:22:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 5d4fe566-75b4-11e9-a685-3eb3c297d0da 0xc42166bf17 0xc42166bf18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42166bf90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42166bfb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.140,PodIP:,StartTime:2019-05-13 19:22:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.511: INFO: Pod "nginx-deployment-7f9675fb8b-7kkgl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-7kkgl,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7f9675fb8b-7kkgl,UID:62427630-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:44139,Generation:0,CreationTimestamp:2019-05-13 19:22:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 5d4fe566-75b4-11e9-a685-3eb3c297d0da 0xc421276067 0xc421276068}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4212760e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4212761c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.140,PodIP:,StartTime:2019-05-13 19:22:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.511: INFO: Pod "nginx-deployment-7f9675fb8b-8knwm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-8knwm,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7f9675fb8b-8knwm,UID:5d563983-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:43894,Generation:0,CreationTimestamp:2019-05-13 19:21:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 5d4fe566-75b4-11e9-a685-3eb3c297d0da 0xc4212762e7 0xc4212762e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421276360} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421276580}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:53 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:53 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.140,PodIP:172.30.208.56,StartTime:2019-05-13 19:21:53 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-13 19:21:54 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://f6772f8ae43613f7dfd43f13ca408f68f583b9efab984ff94a135824fd69ba57}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.511: INFO: Pod "nginx-deployment-7f9675fb8b-cwzv9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-cwzv9,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7f9675fb8b-cwzv9,UID:62425a30-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:44091,Generation:0,CreationTimestamp:2019-05-13 19:22:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 5d4fe566-75b4-11e9-a685-3eb3c297d0da 0xc421276647 0xc421276648}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.170,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4212766c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421276850}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.170,PodIP:,StartTime:2019-05-13 19:22:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.512: INFO: Pod "nginx-deployment-7f9675fb8b-dfq25" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-dfq25,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7f9675fb8b-dfq25,UID:62450b97-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:44146,Generation:0,CreationTimestamp:2019-05-13 19:22:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 5d4fe566-75b4-11e9-a685-3eb3c297d0da 0xc421276907 0xc421276908}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.170,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421276a90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421276ab0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.170,PodIP:,StartTime:2019-05-13 19:22:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.512: INFO: Pod "nginx-deployment-7f9675fb8b-gk85s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-gk85s,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7f9675fb8b-gk85s,UID:62454bf5-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:44067,Generation:0,CreationTimestamp:2019-05-13 19:22:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 5d4fe566-75b4-11e9-a685-3eb3c297d0da 0xc421276b67 0xc421276b68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421276cd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421276cf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.512: INFO: Pod "nginx-deployment-7f9675fb8b-grvnz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-grvnz,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7f9675fb8b-grvnz,UID:62408ad9-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:44107,Generation:0,CreationTimestamp:2019-05-13 19:22:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 5d4fe566-75b4-11e9-a685-3eb3c297d0da 0xc421276d60 0xc421276d61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.189,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421276dd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421276df0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.189,PodIP:,StartTime:2019-05-13 19:22:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.512: INFO: Pod "nginx-deployment-7f9675fb8b-h4vns" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-h4vns,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7f9675fb8b-h4vns,UID:6245437b-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:44116,Generation:0,CreationTimestamp:2019-05-13 19:22:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 5d4fe566-75b4-11e9-a685-3eb3c297d0da 0xc421276eb7 0xc421276eb8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.170,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421276f30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421276f50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.170,PodIP:,StartTime:2019-05-13 19:22:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.512: INFO: Pod "nginx-deployment-7f9675fb8b-hw5r6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-hw5r6,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7f9675fb8b-hw5r6,UID:5d54fc58-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:43881,Generation:0,CreationTimestamp:2019-05-13 19:21:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 5d4fe566-75b4-11e9-a685-3eb3c297d0da 0xc421277007 0xc421277008}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421277080} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4212770a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:53 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:53 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.140,PodIP:172.30.208.55,StartTime:2019-05-13 19:21:53 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-13 19:21:54 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://56e588b90854c049668123756902d8a64ff9baa1bd22957183c8fb60e45216f9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.512: INFO: Pod "nginx-deployment-7f9675fb8b-jvphv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-jvphv,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7f9675fb8b-jvphv,UID:5d54f8e3-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:43871,Generation:0,CreationTimestamp:2019-05-13 19:21:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 5d4fe566-75b4-11e9-a685-3eb3c297d0da 0xc421277167 0xc421277168}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.170,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4212771e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421277200}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:53 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:53 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.170,PodIP:172.30.217.140,StartTime:2019-05-13 19:21:53 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-13 19:21:54 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://a2cbbad1c64d9dc202d408093d66bccb6fc12fdfe95c3d8d7a8b9279e1f38978}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.512: INFO: Pod "nginx-deployment-7f9675fb8b-l9ktq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-l9ktq,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7f9675fb8b-l9ktq,UID:62457879-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:44074,Generation:0,CreationTimestamp:2019-05-13 19:22:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 5d4fe566-75b4-11e9-a685-3eb3c297d0da 0xc4212772c7 0xc4212772c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.189,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421277340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421277360}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.512: INFO: Pod "nginx-deployment-7f9675fb8b-md4w8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-md4w8,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7f9675fb8b-md4w8,UID:5d52e0c9-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:43857,Generation:0,CreationTimestamp:2019-05-13 19:21:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 5d4fe566-75b4-11e9-a685-3eb3c297d0da 0xc4212773d0 0xc4212773d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.189,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421277440} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421277460}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:53 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:53 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.189,PodIP:172.30.136.15,StartTime:2019-05-13 19:21:53 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-13 19:21:54 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://c7068e35fc4391718bba2a85828b8328b80825bdf2aa06f1e056b1e3f7754e32}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.512: INFO: Pod "nginx-deployment-7f9675fb8b-r7krj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-r7krj,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7f9675fb8b-r7krj,UID:6242a902-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:44168,Generation:0,CreationTimestamp:2019-05-13 19:22:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 5d4fe566-75b4-11e9-a685-3eb3c297d0da 0xc421277527 0xc421277528}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.189,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4212775a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4212775c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.189,PodIP:,StartTime:2019-05-13 19:22:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.513: INFO: Pod "nginx-deployment-7f9675fb8b-r8bf8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-r8bf8,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7f9675fb8b-r8bf8,UID:623e6c7a-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:44058,Generation:0,CreationTimestamp:2019-05-13 19:22:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 5d4fe566-75b4-11e9-a685-3eb3c297d0da 0xc421277677 0xc421277678}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.170,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4212776f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421277710}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.170,PodIP:,StartTime:2019-05-13 19:22:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.513: INFO: Pod "nginx-deployment-7f9675fb8b-rjzls" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-rjzls,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7f9675fb8b-rjzls,UID:5d52d877-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:43874,Generation:0,CreationTimestamp:2019-05-13 19:21:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 5d4fe566-75b4-11e9-a685-3eb3c297d0da 0xc4212777c7 0xc4212777c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.170,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421277840} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421277860}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:53 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:53 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.170,PodIP:172.30.217.139,StartTime:2019-05-13 19:21:53 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-13 19:21:54 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://e4f1ca94b2220a1be435b9d661fe8350d6a7a8ee2343dcdae95830c0f11f0c46}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.513: INFO: Pod "nginx-deployment-7f9675fb8b-sz4lx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-sz4lx,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7f9675fb8b-sz4lx,UID:5d54ef9d-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:43898,Generation:0,CreationTimestamp:2019-05-13 19:21:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 5d4fe566-75b4-11e9-a685-3eb3c297d0da 0xc421277927 0xc421277928}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4212779a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4212779c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:53 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:53 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.140,PodIP:172.30.208.57,StartTime:2019-05-13 19:21:53 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-13 19:21:54 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://7ea2ac8905766fa8e0cfe818c1df05c8c8383547e52cea5346b9d93f33fef7c2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.513: INFO: Pod "nginx-deployment-7f9675fb8b-xccqh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-xccqh,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7f9675fb8b-xccqh,UID:624593b3-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:44072,Generation:0,CreationTimestamp:2019-05-13 19:22:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 5d4fe566-75b4-11e9-a685-3eb3c297d0da 0xc421277a97 0xc421277a98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421277b10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421277b30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:22:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:22:03.513: INFO: Pod "nginx-deployment-7f9675fb8b-z98jd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-z98jd,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-srf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-srf2r/pods/nginx-deployment-7f9675fb8b-z98jd,UID:5d5501dc-75b4-11e9-a685-3eb3c297d0da,ResourceVersion:43855,Generation:0,CreationTimestamp:2019-05-13 19:21:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 5d4fe566-75b4-11e9-a685-3eb3c297d0da 0xc421277ba0 0xc421277ba1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bhdh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bhdh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bhdh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.189,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421277c10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421277c40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:53 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:21:53 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.189,PodIP:172.30.136.16,StartTime:2019-05-13 19:21:53 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-13 19:21:54 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://af01c2df96fef11259f57ce2c9b181958a726a5446e596dfa6689cd4350a63be}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:22:03.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-srf2r" for this suite.
May 13 19:22:13.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:22:13.639: INFO: namespace: e2e-tests-deployment-srf2r, resource: bindings, ignored listing per whitelist
May 13 19:22:13.887: INFO: namespace e2e-tests-deployment-srf2r deletion completed in 10.364250147s

• [SLOW TEST:21.099 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:22:13.887: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-wbqvq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 19:22:14.223: INFO: Waiting up to 5m0s for pod "downwardapi-volume-69dab6e2-75b4-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-downward-api-wbqvq" to be "success or failure"
May 13 19:22:14.232: INFO: Pod "downwardapi-volume-69dab6e2-75b4-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 9.546964ms
May 13 19:22:16.243: INFO: Pod "downwardapi-volume-69dab6e2-75b4-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02008271s
STEP: Saw pod success
May 13 19:22:16.243: INFO: Pod "downwardapi-volume-69dab6e2-75b4-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:22:16.251: INFO: Trying to get logs from node 10.170.219.140 pod downwardapi-volume-69dab6e2-75b4-11e9-a09a-7e4d6cfcc771 container client-container: <nil>
STEP: delete the pod
May 13 19:22:16.296: INFO: Waiting for pod downwardapi-volume-69dab6e2-75b4-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:22:16.304: INFO: Pod downwardapi-volume-69dab6e2-75b4-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:22:16.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wbqvq" for this suite.
May 13 19:22:22.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:22:22.514: INFO: namespace: e2e-tests-downward-api-wbqvq, resource: bindings, ignored listing per whitelist
May 13 19:22:22.686: INFO: namespace e2e-tests-downward-api-wbqvq deletion completed in 6.371380512s

• [SLOW TEST:8.799 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:22:22.688: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-tzxg7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-6f14a699-75b4-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume secrets
May 13 19:22:22.996: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6f160979-75b4-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-projected-tzxg7" to be "success or failure"
May 13 19:22:23.004: INFO: Pod "pod-projected-secrets-6f160979-75b4-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 7.411958ms
May 13 19:22:25.012: INFO: Pod "pod-projected-secrets-6f160979-75b4-11e9-a09a-7e4d6cfcc771": Phase="Running", Reason="", readiness=true. Elapsed: 2.015998654s
May 13 19:22:27.021: INFO: Pod "pod-projected-secrets-6f160979-75b4-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024541617s
STEP: Saw pod success
May 13 19:22:27.021: INFO: Pod "pod-projected-secrets-6f160979-75b4-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:22:27.029: INFO: Trying to get logs from node 10.170.219.140 pod pod-projected-secrets-6f160979-75b4-11e9-a09a-7e4d6cfcc771 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 13 19:22:27.076: INFO: Waiting for pod pod-projected-secrets-6f160979-75b4-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:22:27.084: INFO: Pod pod-projected-secrets-6f160979-75b4-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:22:27.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tzxg7" for this suite.
May 13 19:22:33.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:22:33.350: INFO: namespace: e2e-tests-projected-tzxg7, resource: bindings, ignored listing per whitelist
May 13 19:22:33.591: INFO: namespace e2e-tests-projected-tzxg7 deletion completed in 6.49456766s

• [SLOW TEST:10.903 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:22:33.591: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-rmp5g
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
May 13 19:22:33.922: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-rmp5g" to be "success or failure"
May 13 19:22:33.930: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 7.910411ms
May 13 19:22:35.939: INFO: Pod "pod-host-path-test": Phase="Running", Reason="", readiness=false. Elapsed: 2.01682147s
May 13 19:22:37.947: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025576449s
STEP: Saw pod success
May 13 19:22:37.947: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
May 13 19:22:37.958: INFO: Trying to get logs from node 10.170.219.140 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
May 13 19:22:38.022: INFO: Waiting for pod pod-host-path-test to disappear
May 13 19:22:38.030: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:22:38.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-rmp5g" for this suite.
May 13 19:22:46.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:22:46.247: INFO: namespace: e2e-tests-hostpath-rmp5g, resource: bindings, ignored listing per whitelist
May 13 19:22:46.426: INFO: namespace e2e-tests-hostpath-rmp5g deletion completed in 8.385882359s

• [SLOW TEST:12.835 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:22:46.426: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-jsnkn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 13 19:22:46.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-jsnkn'
May 13 19:22:47.171: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
May 13 19:22:47.171: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
May 13 19:22:47.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-jsnkn'
May 13 19:22:47.329: INFO: stderr: ""
May 13 19:22:47.329: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:22:47.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jsnkn" for this suite.
May 13 19:23:09.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:23:09.395: INFO: namespace: e2e-tests-kubectl-jsnkn, resource: bindings, ignored listing per whitelist
May 13 19:23:09.634: INFO: namespace e2e-tests-kubectl-jsnkn deletion completed in 22.294756899s

• [SLOW TEST:23.208 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:23:09.635: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-c2qf4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
May 13 19:23:12.581: INFO: Successfully updated pod "labelsupdate8b147ea5-75b4-11e9-a09a-7e4d6cfcc771"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:23:16.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-c2qf4" for this suite.
May 13 19:23:40.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:23:40.777: INFO: namespace: e2e-tests-downward-api-c2qf4, resource: bindings, ignored listing per whitelist
May 13 19:23:40.967: INFO: namespace e2e-tests-downward-api-c2qf4 deletion completed in 24.304163426s

• [SLOW TEST:31.332 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:23:40.967: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-4knk9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
May 13 19:23:41.273: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:23:45.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-4knk9" for this suite.
May 13 19:23:51.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:23:51.783: INFO: namespace: e2e-tests-init-container-4knk9, resource: bindings, ignored listing per whitelist
May 13 19:23:51.903: INFO: namespace e2e-tests-init-container-4knk9 deletion completed in 6.438448715s

• [SLOW TEST:10.936 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:23:51.903: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-tz6qd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 13 19:23:52.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-tz6qd'
May 13 19:23:52.328: INFO: stderr: ""
May 13 19:23:52.328: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
May 13 19:23:52.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-tz6qd'
May 13 19:23:57.039: INFO: stderr: ""
May 13 19:23:57.039: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:23:57.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tz6qd" for this suite.
May 13 19:24:03.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:24:03.258: INFO: namespace: e2e-tests-kubectl-tz6qd, resource: bindings, ignored listing per whitelist
May 13 19:24:03.514: INFO: namespace e2e-tests-kubectl-tz6qd deletion completed in 6.462419265s

• [SLOW TEST:11.610 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:24:03.514: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-g2tdq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-ab2f8c6c-75b4-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume configMaps
May 13 19:24:03.837: INFO: Waiting up to 5m0s for pod "pod-configmaps-ab313ad2-75b4-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-configmap-g2tdq" to be "success or failure"
May 13 19:24:03.845: INFO: Pod "pod-configmaps-ab313ad2-75b4-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 8.166946ms
May 13 19:24:05.854: INFO: Pod "pod-configmaps-ab313ad2-75b4-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016699618s
STEP: Saw pod success
May 13 19:24:05.854: INFO: Pod "pod-configmaps-ab313ad2-75b4-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:24:05.862: INFO: Trying to get logs from node 10.170.219.140 pod pod-configmaps-ab313ad2-75b4-11e9-a09a-7e4d6cfcc771 container configmap-volume-test: <nil>
STEP: delete the pod
May 13 19:24:05.906: INFO: Waiting for pod pod-configmaps-ab313ad2-75b4-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:24:05.915: INFO: Pod pod-configmaps-ab313ad2-75b4-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:24:05.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-g2tdq" for this suite.
May 13 19:24:11.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:24:12.602: INFO: namespace: e2e-tests-configmap-g2tdq, resource: bindings, ignored listing per whitelist
May 13 19:24:12.727: INFO: namespace e2e-tests-configmap-g2tdq deletion completed in 6.801384499s

• [SLOW TEST:9.213 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:24:12.727: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-c4jb6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-c4jb6
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 13 19:24:13.144: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 13 19:24:35.437: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.208.15:8080/dial?request=hostName&protocol=http&host=172.30.217.146&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-c4jb6 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 19:24:35.437: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
May 13 19:24:35.878: INFO: Waiting for endpoints: map[]
May 13 19:24:35.887: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.208.15:8080/dial?request=hostName&protocol=http&host=172.30.208.13&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-c4jb6 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 19:24:35.887: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
May 13 19:24:36.089: INFO: Waiting for endpoints: map[]
May 13 19:24:36.097: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.208.15:8080/dial?request=hostName&protocol=http&host=172.30.136.19&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-c4jb6 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 19:24:36.097: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
May 13 19:24:36.300: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:24:36.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-c4jb6" for this suite.
May 13 19:25:00.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:25:00.640: INFO: namespace: e2e-tests-pod-network-test-c4jb6, resource: bindings, ignored listing per whitelist
May 13 19:25:00.748: INFO: namespace e2e-tests-pod-network-test-c4jb6 deletion completed in 24.437228711s

• [SLOW TEST:48.021 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:25:00.748: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-2k7lx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-cd5e37cf-75b4-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume configMaps
May 13 19:25:01.226: INFO: Waiting up to 5m0s for pod "pod-configmaps-cd657d67-75b4-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-configmap-2k7lx" to be "success or failure"
May 13 19:25:01.237: INFO: Pod "pod-configmaps-cd657d67-75b4-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 10.781948ms
May 13 19:25:03.246: INFO: Pod "pod-configmaps-cd657d67-75b4-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019953837s
STEP: Saw pod success
May 13 19:25:03.246: INFO: Pod "pod-configmaps-cd657d67-75b4-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:25:03.255: INFO: Trying to get logs from node 10.170.219.140 pod pod-configmaps-cd657d67-75b4-11e9-a09a-7e4d6cfcc771 container configmap-volume-test: <nil>
STEP: delete the pod
May 13 19:25:03.307: INFO: Waiting for pod pod-configmaps-cd657d67-75b4-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:25:03.316: INFO: Pod pod-configmaps-cd657d67-75b4-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:25:03.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2k7lx" for this suite.
May 13 19:25:09.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:25:09.534: INFO: namespace: e2e-tests-configmap-2k7lx, resource: bindings, ignored listing per whitelist
May 13 19:25:09.703: INFO: namespace e2e-tests-configmap-2k7lx deletion completed in 6.377057231s

• [SLOW TEST:8.955 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:25:09.704: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-9bcv2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-9bcv2
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-9bcv2
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-9bcv2
May 13 19:25:10.027: INFO: Found 0 stateful pods, waiting for 1
May 13 19:25:20.052: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
May 13 19:25:20.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 exec --namespace=e2e-tests-statefulset-9bcv2 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 13 19:25:20.715: INFO: stderr: ""
May 13 19:25:20.715: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 13 19:25:20.715: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 13 19:25:20.725: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 13 19:25:30.755: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 13 19:25:30.755: INFO: Waiting for statefulset status.replicas updated to 0
May 13 19:25:30.793: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998943s
May 13 19:25:31.803: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.991567606s
May 13 19:25:32.812: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.981971381s
May 13 19:25:33.821: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.972373757s
May 13 19:25:34.831: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.963290912s
May 13 19:25:35.851: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.953311949s
May 13 19:25:36.860: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.933908862s
May 13 19:25:37.870: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.924713036s
May 13 19:25:38.882: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.91516447s
May 13 19:25:40.129: INFO: Verifying statefulset ss doesn't scale past 1 for another 902.862448ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-9bcv2
May 13 19:25:41.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 exec --namespace=e2e-tests-statefulset-9bcv2 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 13 19:25:41.820: INFO: stderr: ""
May 13 19:25:41.820: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 13 19:25:41.820: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 13 19:25:42.002: INFO: Found 1 stateful pods, waiting for 3
May 13 19:25:52.026: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 13 19:25:52.026: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 13 19:25:52.026: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
May 13 19:25:52.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 exec --namespace=e2e-tests-statefulset-9bcv2 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 13 19:25:52.359: INFO: stderr: ""
May 13 19:25:52.359: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 13 19:25:52.359: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 13 19:25:52.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 exec --namespace=e2e-tests-statefulset-9bcv2 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 13 19:25:52.703: INFO: stderr: ""
May 13 19:25:52.703: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 13 19:25:52.703: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 13 19:25:52.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 exec --namespace=e2e-tests-statefulset-9bcv2 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 13 19:25:53.016: INFO: stderr: ""
May 13 19:25:53.016: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 13 19:25:53.016: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 13 19:25:53.016: INFO: Waiting for statefulset status.replicas updated to 0
May 13 19:25:53.025: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
May 13 19:26:03.058: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 13 19:26:03.058: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 13 19:26:03.058: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 13 19:26:03.085: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998998s
May 13 19:26:04.094: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.990819477s
May 13 19:26:05.104: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.981468724s
May 13 19:26:06.115: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.972020402s
May 13 19:26:07.141: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.960561348s
May 13 19:26:08.150: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.934601132s
May 13 19:26:09.160: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.925513817s
May 13 19:26:10.170: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.915744147s
May 13 19:26:11.179: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.906214541s
May 13 19:26:12.191: INFO: Verifying statefulset ss doesn't scale past 3 for another 896.403954ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-9bcv2
May 13 19:26:13.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 exec --namespace=e2e-tests-statefulset-9bcv2 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 13 19:26:13.559: INFO: stderr: ""
May 13 19:26:13.559: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 13 19:26:13.559: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 13 19:26:13.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 exec --namespace=e2e-tests-statefulset-9bcv2 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 13 19:26:13.855: INFO: stderr: ""
May 13 19:26:13.855: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 13 19:26:13.855: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 13 19:26:13.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 exec --namespace=e2e-tests-statefulset-9bcv2 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 13 19:26:14.179: INFO: stderr: ""
May 13 19:26:14.179: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 13 19:26:14.179: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 13 19:26:14.179: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 13 19:26:44.230: INFO: Deleting all statefulset in ns e2e-tests-statefulset-9bcv2
May 13 19:26:44.238: INFO: Scaling statefulset ss to 0
May 13 19:26:44.264: INFO: Waiting for statefulset status.replicas updated to 0
May 13 19:26:44.272: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:26:44.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-9bcv2" for this suite.
May 13 19:26:52.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:26:52.669: INFO: namespace: e2e-tests-statefulset-9bcv2, resource: bindings, ignored listing per whitelist
May 13 19:26:52.834: INFO: namespace e2e-tests-statefulset-9bcv2 deletion completed in 8.511273452s

• [SLOW TEST:103.130 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:26:52.834: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-2zzqs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-101d2459-75b5-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume secrets
May 13 19:26:53.164: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-101e8b64-75b5-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-projected-2zzqs" to be "success or failure"
May 13 19:26:53.173: INFO: Pod "pod-projected-secrets-101e8b64-75b5-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 8.57498ms
May 13 19:26:55.196: INFO: Pod "pod-projected-secrets-101e8b64-75b5-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031550291s
STEP: Saw pod success
May 13 19:26:55.196: INFO: Pod "pod-projected-secrets-101e8b64-75b5-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:26:55.203: INFO: Trying to get logs from node 10.170.219.140 pod pod-projected-secrets-101e8b64-75b5-11e9-a09a-7e4d6cfcc771 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 13 19:26:55.247: INFO: Waiting for pod pod-projected-secrets-101e8b64-75b5-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:26:55.254: INFO: Pod pod-projected-secrets-101e8b64-75b5-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:26:55.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2zzqs" for this suite.
May 13 19:27:01.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:27:01.502: INFO: namespace: e2e-tests-projected-2zzqs, resource: bindings, ignored listing per whitelist
May 13 19:27:01.572: INFO: namespace e2e-tests-projected-2zzqs deletion completed in 6.306163118s

• [SLOW TEST:8.737 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:27:01.572: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-slgxt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-slgxt A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-slgxt;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-slgxt A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-slgxt;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-slgxt.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-slgxt.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-slgxt.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-slgxt.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-slgxt.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-slgxt.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-slgxt.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-slgxt.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-slgxt.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-slgxt.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-slgxt.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-slgxt.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-slgxt.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 10.28.21.172.in-addr.arpa. PTR)" && echo OK > /results/172.21.28.10_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 10.28.21.172.in-addr.arpa. PTR)" && echo OK > /results/172.21.28.10_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-slgxt A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-slgxt;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-slgxt A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-slgxt;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-slgxt.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-slgxt.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-slgxt.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-slgxt.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-slgxt.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-slgxt.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-slgxt.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-slgxt.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-slgxt.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-slgxt.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-slgxt.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-slgxt.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-slgxt.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 10.28.21.172.in-addr.arpa. PTR)" && echo OK > /results/172.21.28.10_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 10.28.21.172.in-addr.arpa. PTR)" && echo OK > /results/172.21.28.10_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 13 19:27:14.424: INFO: DNS probes using e2e-tests-dns-slgxt/dns-test-1554f767-75b5-11e9-a09a-7e4d6cfcc771 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:27:14.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-slgxt" for this suite.
May 13 19:27:20.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:27:20.978: INFO: namespace: e2e-tests-dns-slgxt, resource: bindings, ignored listing per whitelist
May 13 19:27:21.115: INFO: namespace e2e-tests-dns-slgxt deletion completed in 6.478111049s

• [SLOW TEST:19.542 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:27:21.115: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-ngwmw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
May 13 19:27:21.434: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ngwmw,SelfLink:/api/v1/namespaces/e2e-tests-watch-ngwmw/configmaps/e2e-watch-test-configmap-a,UID:20f9e86a-75b5-11e9-906d-b2bf80cbe475,ResourceVersion:45966,Generation:0,CreationTimestamp:2019-05-13 19:27:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 13 19:27:21.434: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ngwmw,SelfLink:/api/v1/namespaces/e2e-tests-watch-ngwmw/configmaps/e2e-watch-test-configmap-a,UID:20f9e86a-75b5-11e9-906d-b2bf80cbe475,ResourceVersion:45966,Generation:0,CreationTimestamp:2019-05-13 19:27:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
May 13 19:27:31.468: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ngwmw,SelfLink:/api/v1/namespaces/e2e-tests-watch-ngwmw/configmaps/e2e-watch-test-configmap-a,UID:20f9e86a-75b5-11e9-906d-b2bf80cbe475,ResourceVersion:45983,Generation:0,CreationTimestamp:2019-05-13 19:27:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 13 19:27:31.468: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ngwmw,SelfLink:/api/v1/namespaces/e2e-tests-watch-ngwmw/configmaps/e2e-watch-test-configmap-a,UID:20f9e86a-75b5-11e9-906d-b2bf80cbe475,ResourceVersion:45983,Generation:0,CreationTimestamp:2019-05-13 19:27:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
May 13 19:27:41.502: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ngwmw,SelfLink:/api/v1/namespaces/e2e-tests-watch-ngwmw/configmaps/e2e-watch-test-configmap-a,UID:20f9e86a-75b5-11e9-906d-b2bf80cbe475,ResourceVersion:46000,Generation:0,CreationTimestamp:2019-05-13 19:27:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 13 19:27:41.502: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ngwmw,SelfLink:/api/v1/namespaces/e2e-tests-watch-ngwmw/configmaps/e2e-watch-test-configmap-a,UID:20f9e86a-75b5-11e9-906d-b2bf80cbe475,ResourceVersion:46000,Generation:0,CreationTimestamp:2019-05-13 19:27:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
May 13 19:27:51.539: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ngwmw,SelfLink:/api/v1/namespaces/e2e-tests-watch-ngwmw/configmaps/e2e-watch-test-configmap-a,UID:20f9e86a-75b5-11e9-906d-b2bf80cbe475,ResourceVersion:46017,Generation:0,CreationTimestamp:2019-05-13 19:27:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 13 19:27:51.539: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ngwmw,SelfLink:/api/v1/namespaces/e2e-tests-watch-ngwmw/configmaps/e2e-watch-test-configmap-a,UID:20f9e86a-75b5-11e9-906d-b2bf80cbe475,ResourceVersion:46017,Generation:0,CreationTimestamp:2019-05-13 19:27:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
May 13 19:28:01.641: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-ngwmw,SelfLink:/api/v1/namespaces/e2e-tests-watch-ngwmw/configmaps/e2e-watch-test-configmap-b,UID:38e5a2ed-75b5-11e9-906d-b2bf80cbe475,ResourceVersion:46034,Generation:0,CreationTimestamp:2019-05-13 19:28:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 13 19:28:01.641: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-ngwmw,SelfLink:/api/v1/namespaces/e2e-tests-watch-ngwmw/configmaps/e2e-watch-test-configmap-b,UID:38e5a2ed-75b5-11e9-906d-b2bf80cbe475,ResourceVersion:46034,Generation:0,CreationTimestamp:2019-05-13 19:28:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
May 13 19:28:11.676: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-ngwmw,SelfLink:/api/v1/namespaces/e2e-tests-watch-ngwmw/configmaps/e2e-watch-test-configmap-b,UID:38e5a2ed-75b5-11e9-906d-b2bf80cbe475,ResourceVersion:46051,Generation:0,CreationTimestamp:2019-05-13 19:28:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 13 19:28:11.676: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-ngwmw,SelfLink:/api/v1/namespaces/e2e-tests-watch-ngwmw/configmaps/e2e-watch-test-configmap-b,UID:38e5a2ed-75b5-11e9-906d-b2bf80cbe475,ResourceVersion:46051,Generation:0,CreationTimestamp:2019-05-13 19:28:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:28:21.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-ngwmw" for this suite.
May 13 19:28:27.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:28:27.990: INFO: namespace: e2e-tests-watch-ngwmw, resource: bindings, ignored listing per whitelist
May 13 19:28:28.020: INFO: namespace e2e-tests-watch-ngwmw deletion completed in 6.315543192s

• [SLOW TEST:66.905 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:28:28.020: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-qwfhh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-48dd50db-75b5-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume configMaps
May 13 19:28:28.378: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-48ded757-75b5-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-projected-qwfhh" to be "success or failure"
May 13 19:28:28.388: INFO: Pod "pod-projected-configmaps-48ded757-75b5-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 10.351403ms
May 13 19:28:30.398: INFO: Pod "pod-projected-configmaps-48ded757-75b5-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019819008s
STEP: Saw pod success
May 13 19:28:30.398: INFO: Pod "pod-projected-configmaps-48ded757-75b5-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:28:30.408: INFO: Trying to get logs from node 10.170.219.140 pod pod-projected-configmaps-48ded757-75b5-11e9-a09a-7e4d6cfcc771 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 13 19:28:30.541: INFO: Waiting for pod pod-projected-configmaps-48ded757-75b5-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:28:30.550: INFO: Pod pod-projected-configmaps-48ded757-75b5-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:28:30.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qwfhh" for this suite.
May 13 19:28:36.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:28:36.772: INFO: namespace: e2e-tests-projected-qwfhh, resource: bindings, ignored listing per whitelist
May 13 19:28:36.877: INFO: namespace e2e-tests-projected-qwfhh deletion completed in 6.316165913s

• [SLOW TEST:8.856 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:28:36.877: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-p5f4v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-p5f4v
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 13 19:28:37.162: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 13 19:28:59.466: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.208.19:8080/dial?request=hostName&protocol=udp&host=172.30.217.152&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-p5f4v PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 19:28:59.466: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
May 13 19:28:59.683: INFO: Waiting for endpoints: map[]
May 13 19:28:59.692: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.208.19:8080/dial?request=hostName&protocol=udp&host=172.30.136.28&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-p5f4v PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 19:28:59.692: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
May 13 19:28:59.861: INFO: Waiting for endpoints: map[]
May 13 19:28:59.869: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.208.19:8080/dial?request=hostName&protocol=udp&host=172.30.208.22&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-p5f4v PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 19:28:59.869: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
May 13 19:29:00.054: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:29:00.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-p5f4v" for this suite.
May 13 19:29:24.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:29:24.621: INFO: namespace: e2e-tests-pod-network-test-p5f4v, resource: bindings, ignored listing per whitelist
May 13 19:29:24.687: INFO: namespace e2e-tests-pod-network-test-p5f4v deletion completed in 24.619400726s

• [SLOW TEST:47.810 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:29:24.687: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-29ddj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-rql5s
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
May 13 19:29:34.811: INFO: error from create uninitialized namespace: Internal error occurred: object deleted while waiting for creation
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-rbndv
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:29:52.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-29ddj" for this suite.
May 13 19:29:58.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:29:58.628: INFO: namespace: e2e-tests-namespaces-29ddj, resource: bindings, ignored listing per whitelist
May 13 19:29:58.876: INFO: namespace e2e-tests-namespaces-29ddj deletion completed in 6.355872236s
STEP: Destroying namespace "e2e-tests-nsdeletetest-rql5s" for this suite.
May 13 19:29:58.883: INFO: Namespace e2e-tests-nsdeletetest-rql5s was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-rbndv" for this suite.
May 13 19:30:04.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:30:05.066: INFO: namespace: e2e-tests-nsdeletetest-rbndv, resource: bindings, ignored listing per whitelist
May 13 19:30:05.189: INFO: namespace e2e-tests-nsdeletetest-rbndv deletion completed in 6.306209633s

• [SLOW TEST:40.502 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:30:05.190: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-js8bg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
May 13 19:30:05.476: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 13 19:30:05.497: INFO: Waiting for terminating namespaces to be deleted...
May 13 19:30:05.504: INFO: 
Logging pods the kubelet thinks is on node 10.170.219.140 before test
May 13 19:30:05.529: INFO: ibm-keepalived-watcher-s9p9f from kube-system started at 2019-05-13 16:26:20 +0000 UTC (1 container statuses recorded)
May 13 19:30:05.529: INFO: 	Container keepalived-watcher ready: true, restart count 0
May 13 19:30:05.529: INFO: public-cre5e67d863b8a419ba7a75a47352a70a9-alb1-785767687-drrgh from kube-system started at 2019-05-13 16:32:34 +0000 UTC (4 container statuses recorded)
May 13 19:30:05.529: INFO: 	Container ingress-auth-1 ready: true, restart count 0
May 13 19:30:05.529: INFO: 	Container ingress-auth-2 ready: true, restart count 0
May 13 19:30:05.529: INFO: 	Container ingress-auth-3 ready: true, restart count 0
May 13 19:30:05.529: INFO: 	Container nginx-ingress ready: true, restart count 0
May 13 19:30:05.529: INFO: sonobuoy-systemd-logs-daemon-set-5d6538ccab344242-8b4m8 from heptio-sonobuoy started at 2019-05-13 18:23:14 +0000 UTC (2 container statuses recorded)
May 13 19:30:05.529: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 13 19:30:05.529: INFO: 	Container systemd-logs ready: true, restart count 1
May 13 19:30:05.529: INFO: ibm-kube-fluentd-kswb8 from kube-system started at 2019-05-13 16:27:54 +0000 UTC (1 container statuses recorded)
May 13 19:30:05.529: INFO: 	Container fluentd ready: true, restart count 0
May 13 19:30:05.529: INFO: ibm-master-proxy-static-10.170.219.140 from kube-system started at <nil> (0 container statuses recorded)
May 13 19:30:05.529: INFO: ibm-cloud-provider-ip-169-45-233-124-7fbd585f77-sv6vv from ibm-system started at 2019-05-13 16:27:29 +0000 UTC (1 container statuses recorded)
May 13 19:30:05.529: INFO: 	Container ibm-cloud-provider-ip-169-45-233-124 ready: true, restart count 0
May 13 19:30:05.530: INFO: calico-node-nlxmm from kube-system started at 2019-05-13 16:26:20 +0000 UTC (2 container statuses recorded)
May 13 19:30:05.530: INFO: 	Container calico-node ready: true, restart count 0
May 13 19:30:05.530: INFO: 	Container install-cni ready: true, restart count 0
May 13 19:30:05.530: INFO: 
Logging pods the kubelet thinks is on node 10.170.219.170 before test
May 13 19:30:05.558: INFO: kube-dns-amd64-fcdcf59c5-mbw97 from kube-system started at 2019-05-13 16:27:28 +0000 UTC (3 container statuses recorded)
May 13 19:30:05.558: INFO: 	Container dnsmasq ready: true, restart count 0
May 13 19:30:05.558: INFO: 	Container kubedns ready: true, restart count 0
May 13 19:30:05.558: INFO: 	Container sidecar ready: true, restart count 0
May 13 19:30:05.559: INFO: metrics-server-77478c8fdd-zwg9d from kube-system started at 2019-05-13 16:27:41 +0000 UTC (2 container statuses recorded)
May 13 19:30:05.559: INFO: 	Container metrics-server ready: true, restart count 0
May 13 19:30:05.559: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 13 19:30:05.559: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-13 18:23:11 +0000 UTC (1 container statuses recorded)
May 13 19:30:05.559: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 13 19:30:05.559: INFO: ibm-kube-fluentd-h589k from kube-system started at 2019-05-13 16:27:54 +0000 UTC (1 container statuses recorded)
May 13 19:30:05.559: INFO: 	Container fluentd ready: true, restart count 0
May 13 19:30:05.559: INFO: sonobuoy-e2e-job-d5dc9a0af3d340ba from heptio-sonobuoy started at 2019-05-13 18:23:14 +0000 UTC (2 container statuses recorded)
May 13 19:30:05.559: INFO: 	Container e2e ready: true, restart count 0
May 13 19:30:05.559: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 13 19:30:05.559: INFO: ibm-master-proxy-static-10.170.219.170 from kube-system started at <nil> (0 container statuses recorded)
May 13 19:30:05.559: INFO: ibm-keepalived-watcher-74r7v from kube-system started at 2019-05-13 16:26:56 +0000 UTC (1 container statuses recorded)
May 13 19:30:05.559: INFO: 	Container keepalived-watcher ready: true, restart count 0
May 13 19:30:05.559: INFO: sonobuoy-systemd-logs-daemon-set-5d6538ccab344242-2t9dg from heptio-sonobuoy started at 2019-05-13 18:23:14 +0000 UTC (2 container statuses recorded)
May 13 19:30:05.559: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 13 19:30:05.559: INFO: 	Container systemd-logs ready: true, restart count 1
May 13 19:30:05.559: INFO: calico-node-vsr6g from kube-system started at 2019-05-13 16:26:56 +0000 UTC (2 container statuses recorded)
May 13 19:30:05.559: INFO: 	Container calico-node ready: true, restart count 0
May 13 19:30:05.559: INFO: 	Container install-cni ready: true, restart count 0
May 13 19:30:05.559: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-05-13 18:23:07 +0000 UTC (1 container statuses recorded)
May 13 19:30:05.559: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
May 13 19:30:05.559: INFO: 
Logging pods the kubelet thinks is on node 10.170.219.189 before test
May 13 19:30:05.643: INFO: kube-dns-autoscaler-587cd5cd44-mrpn9 from kube-system started at 2019-05-13 16:26:35 +0000 UTC (1 container statuses recorded)
May 13 19:30:05.643: INFO: 	Container autoscaler ready: true, restart count 0
May 13 19:30:05.643: INFO: sonobuoy-systemd-logs-daemon-set-5d6538ccab344242-ss8mg from heptio-sonobuoy started at 2019-05-13 18:23:14 +0000 UTC (2 container statuses recorded)
May 13 19:30:05.643: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 13 19:30:05.644: INFO: 	Container systemd-logs ready: true, restart count 1
May 13 19:30:05.644: INFO: calico-kube-controllers-69f46f96c4-k8td8 from kube-system started at 2019-05-13 16:25:45 +0000 UTC (1 container statuses recorded)
May 13 19:30:05.644: INFO: 	Container calico-kube-controllers ready: true, restart count 0
May 13 19:30:05.644: INFO: public-cre5e67d863b8a419ba7a75a47352a70a9-alb1-785767687-vsp6l from kube-system started at 2019-05-13 16:32:34 +0000 UTC (4 container statuses recorded)
May 13 19:30:05.644: INFO: 	Container ingress-auth-1 ready: true, restart count 0
May 13 19:30:05.644: INFO: 	Container ingress-auth-2 ready: true, restart count 0
May 13 19:30:05.644: INFO: 	Container ingress-auth-3 ready: true, restart count 0
May 13 19:30:05.644: INFO: 	Container nginx-ingress ready: true, restart count 0
May 13 19:30:05.644: INFO: ibm-file-plugin-75d4cc8576-b74ft from kube-system started at 2019-05-13 16:26:35 +0000 UTC (1 container statuses recorded)
May 13 19:30:05.644: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
May 13 19:30:05.644: INFO: ibm-master-proxy-static-10.170.219.189 from kube-system started at <nil> (0 container statuses recorded)
May 13 19:30:05.644: INFO: calico-node-j8pbf from kube-system started at 2019-05-13 16:25:45 +0000 UTC (2 container statuses recorded)
May 13 19:30:05.644: INFO: 	Container calico-node ready: true, restart count 0
May 13 19:30:05.644: INFO: 	Container install-cni ready: true, restart count 0
May 13 19:30:05.644: INFO: kube-dns-amd64-fcdcf59c5-vvwwq from kube-system started at 2019-05-13 16:26:35 +0000 UTC (3 container statuses recorded)
May 13 19:30:05.644: INFO: 	Container dnsmasq ready: true, restart count 0
May 13 19:30:05.644: INFO: 	Container kubedns ready: true, restart count 0
May 13 19:30:05.644: INFO: 	Container sidecar ready: true, restart count 0
May 13 19:30:05.644: INFO: ibm-storage-watcher-7765979c55-x5cgd from kube-system started at 2019-05-13 16:26:35 +0000 UTC (1 container statuses recorded)
May 13 19:30:05.644: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
May 13 19:30:05.644: INFO: ibm-cloud-provider-ip-169-45-233-124-7fbd585f77-wfw6v from ibm-system started at 2019-05-13 16:27:29 +0000 UTC (1 container statuses recorded)
May 13 19:30:05.644: INFO: 	Container ibm-cloud-provider-ip-169-45-233-124 ready: true, restart count 0
May 13 19:30:05.644: INFO: ibm-kube-fluentd-dsrqr from kube-system started at 2019-05-13 16:27:54 +0000 UTC (1 container statuses recorded)
May 13 19:30:05.644: INFO: 	Container fluentd ready: true, restart count 0
May 13 19:30:05.644: INFO: ibm-keepalived-watcher-l5ss8 from kube-system started at 2019-05-13 16:25:45 +0000 UTC (1 container statuses recorded)
May 13 19:30:05.644: INFO: 	Container keepalived-watcher ready: true, restart count 0
May 13 19:30:05.644: INFO: kubernetes-dashboard-b4bc7db5d-dg6mx from kube-system started at 2019-05-13 16:26:35 +0000 UTC (1 container statuses recorded)
May 13 19:30:05.644: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 13 19:30:05.644: INFO: vpn-7d87f64d5b-z7z6p from kube-system started at 2019-05-13 16:26:35 +0000 UTC (1 container statuses recorded)
May 13 19:30:05.644: INFO: 	Container vpn ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node 10.170.219.140
STEP: verifying the node has the label node 10.170.219.170
STEP: verifying the node has the label node 10.170.219.189
May 13 19:30:05.746: INFO: Pod test-k8s-e2e-pvg-master-verification requesting resource cpu=0m on Node 10.170.219.170
May 13 19:30:05.746: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.170.219.170
May 13 19:30:05.746: INFO: Pod sonobuoy-e2e-job-d5dc9a0af3d340ba requesting resource cpu=0m on Node 10.170.219.170
May 13 19:30:05.746: INFO: Pod sonobuoy-systemd-logs-daemon-set-5d6538ccab344242-2t9dg requesting resource cpu=0m on Node 10.170.219.170
May 13 19:30:05.746: INFO: Pod sonobuoy-systemd-logs-daemon-set-5d6538ccab344242-8b4m8 requesting resource cpu=0m on Node 10.170.219.140
May 13 19:30:05.746: INFO: Pod sonobuoy-systemd-logs-daemon-set-5d6538ccab344242-ss8mg requesting resource cpu=0m on Node 10.170.219.189
May 13 19:30:05.746: INFO: Pod ibm-cloud-provider-ip-169-45-233-124-7fbd585f77-sv6vv requesting resource cpu=5m on Node 10.170.219.140
May 13 19:30:05.746: INFO: Pod ibm-cloud-provider-ip-169-45-233-124-7fbd585f77-wfw6v requesting resource cpu=5m on Node 10.170.219.189
May 13 19:30:05.746: INFO: Pod calico-kube-controllers-69f46f96c4-k8td8 requesting resource cpu=10m on Node 10.170.219.189
May 13 19:30:05.746: INFO: Pod calico-node-j8pbf requesting resource cpu=255m on Node 10.170.219.189
May 13 19:30:05.746: INFO: Pod calico-node-nlxmm requesting resource cpu=255m on Node 10.170.219.140
May 13 19:30:05.746: INFO: Pod calico-node-vsr6g requesting resource cpu=255m on Node 10.170.219.170
May 13 19:30:05.746: INFO: Pod ibm-file-plugin-75d4cc8576-b74ft requesting resource cpu=50m on Node 10.170.219.189
May 13 19:30:05.746: INFO: Pod ibm-keepalived-watcher-74r7v requesting resource cpu=5m on Node 10.170.219.170
May 13 19:30:05.746: INFO: Pod ibm-keepalived-watcher-l5ss8 requesting resource cpu=5m on Node 10.170.219.189
May 13 19:30:05.746: INFO: Pod ibm-keepalived-watcher-s9p9f requesting resource cpu=5m on Node 10.170.219.140
May 13 19:30:05.746: INFO: Pod ibm-kube-fluentd-dsrqr requesting resource cpu=25m on Node 10.170.219.189
May 13 19:30:05.746: INFO: Pod ibm-kube-fluentd-h589k requesting resource cpu=25m on Node 10.170.219.170
May 13 19:30:05.746: INFO: Pod ibm-kube-fluentd-kswb8 requesting resource cpu=25m on Node 10.170.219.140
May 13 19:30:05.746: INFO: Pod ibm-master-proxy-static-10.170.219.140 requesting resource cpu=25m on Node 10.170.219.140
May 13 19:30:05.746: INFO: Pod ibm-master-proxy-static-10.170.219.170 requesting resource cpu=25m on Node 10.170.219.170
May 13 19:30:05.746: INFO: Pod ibm-master-proxy-static-10.170.219.189 requesting resource cpu=25m on Node 10.170.219.189
May 13 19:30:05.746: INFO: Pod ibm-storage-watcher-7765979c55-x5cgd requesting resource cpu=50m on Node 10.170.219.189
May 13 19:30:05.746: INFO: Pod kube-dns-amd64-fcdcf59c5-mbw97 requesting resource cpu=260m on Node 10.170.219.170
May 13 19:30:05.746: INFO: Pod kube-dns-amd64-fcdcf59c5-vvwwq requesting resource cpu=260m on Node 10.170.219.189
May 13 19:30:05.746: INFO: Pod kube-dns-autoscaler-587cd5cd44-mrpn9 requesting resource cpu=20m on Node 10.170.219.189
May 13 19:30:05.746: INFO: Pod kubernetes-dashboard-b4bc7db5d-dg6mx requesting resource cpu=50m on Node 10.170.219.189
May 13 19:30:05.746: INFO: Pod metrics-server-77478c8fdd-zwg9d requesting resource cpu=53m on Node 10.170.219.170
May 13 19:30:05.746: INFO: Pod public-cre5e67d863b8a419ba7a75a47352a70a9-alb1-785767687-drrgh requesting resource cpu=0m on Node 10.170.219.140
May 13 19:30:05.746: INFO: Pod public-cre5e67d863b8a419ba7a75a47352a70a9-alb1-785767687-vsp6l requesting resource cpu=0m on Node 10.170.219.189
May 13 19:30:05.746: INFO: Pod vpn-7d87f64d5b-z7z6p requesting resource cpu=5m on Node 10.170.219.189
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-82eac3c8-75b5-11e9-a09a-7e4d6cfcc771.159e54d78721de43], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-js8bg/filler-pod-82eac3c8-75b5-11e9-a09a-7e4d6cfcc771 to 10.170.219.140]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-82eac3c8-75b5-11e9-a09a-7e4d6cfcc771.159e54d7c3cea76f], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-82eac3c8-75b5-11e9-a09a-7e4d6cfcc771.159e54d7c6ea386a], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-82eac3c8-75b5-11e9-a09a-7e4d6cfcc771.159e54d7cefa28f7], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-82edd1af-75b5-11e9-a09a-7e4d6cfcc771.159e54d7881a719c], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-js8bg/filler-pod-82edd1af-75b5-11e9-a09a-7e4d6cfcc771 to 10.170.219.170]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-82edd1af-75b5-11e9-a09a-7e4d6cfcc771.159e54d7c76ca8ce], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-82edd1af-75b5-11e9-a09a-7e4d6cfcc771.159e54d7cabc8edc], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-82edd1af-75b5-11e9-a09a-7e4d6cfcc771.159e54d7d854847c], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-82f072fc-75b5-11e9-a09a-7e4d6cfcc771.159e54d789075065], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-js8bg/filler-pod-82f072fc-75b5-11e9-a09a-7e4d6cfcc771 to 10.170.219.189]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-82f072fc-75b5-11e9-a09a-7e4d6cfcc771.159e54d7c5c8eecd], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-82f072fc-75b5-11e9-a09a-7e4d6cfcc771.159e54d7c9e98941], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-82f072fc-75b5-11e9-a09a-7e4d6cfcc771.159e54d7d73d4dab], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.159e54d87c08aeea], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 10.170.219.140
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.170.219.170
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.170.219.189
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:30:10.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-js8bg" for this suite.
May 13 19:30:17.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:30:17.282: INFO: namespace: e2e-tests-sched-pred-js8bg, resource: bindings, ignored listing per whitelist
May 13 19:30:17.472: INFO: namespace e2e-tests-sched-pred-js8bg deletion completed in 6.489423631s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:12.283 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:30:17.473: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-tl75z
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 19:30:19.857: INFO: Waiting up to 5m0s for pod "client-envvars-8b521063-75b5-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-pods-tl75z" to be "success or failure"
May 13 19:30:19.880: INFO: Pod "client-envvars-8b521063-75b5-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 23.187612ms
May 13 19:30:21.889: INFO: Pod "client-envvars-8b521063-75b5-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031767684s
STEP: Saw pod success
May 13 19:30:21.889: INFO: Pod "client-envvars-8b521063-75b5-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:30:21.906: INFO: Trying to get logs from node 10.170.219.140 pod client-envvars-8b521063-75b5-11e9-a09a-7e4d6cfcc771 container env3cont: <nil>
STEP: delete the pod
May 13 19:30:21.952: INFO: Waiting for pod client-envvars-8b521063-75b5-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:30:21.963: INFO: Pod client-envvars-8b521063-75b5-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:30:21.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-tl75z" for this suite.
May 13 19:31:02.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:31:02.164: INFO: namespace: e2e-tests-pods-tl75z, resource: bindings, ignored listing per whitelist
May 13 19:31:02.334: INFO: namespace e2e-tests-pods-tl75z deletion completed in 40.359153613s

• [SLOW TEST:44.861 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:31:02.335: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-q8wqb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
May 13 19:31:04.750: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-a4d38294-75b5-11e9-a09a-7e4d6cfcc771,GenerateName:,Namespace:e2e-tests-events-q8wqb,SelfLink:/api/v1/namespaces/e2e-tests-events-q8wqb/pods/send-events-a4d38294-75b5-11e9-a09a-7e4d6cfcc771,UID:a4d54e28-75b5-11e9-906d-b2bf80cbe475,ResourceVersion:46731,Generation:0,CreationTimestamp:2019-05-13 19:31:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 636614930,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j8q5m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j8q5m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-j8q5m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f84130} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f84150}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:02 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:02 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.140,PodIP:172.30.208.28,StartTime:2019-05-13 19:31:02 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-05-13 19:31:03 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 containerd://ef5b793fcb9ccdf17d2ed0d1de1626a6bd7021f66801d973cd803bf44acfe9d9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
May 13 19:31:06.759: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
May 13 19:31:08.769: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:31:08.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-q8wqb" for this suite.
May 13 19:31:48.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:31:48.963: INFO: namespace: e2e-tests-events-q8wqb, resource: bindings, ignored listing per whitelist
May 13 19:31:49.199: INFO: namespace e2e-tests-events-q8wqb deletion completed in 40.400987112s

• [SLOW TEST:46.865 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:31:49.199: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-pjdf2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-pjdf2
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 13 19:31:49.495: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 13 19:32:11.792: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.30.136.30:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-pjdf2 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 19:32:11.792: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
May 13 19:32:12.041: INFO: Found all expected endpoints: [netserver-0]
May 13 19:32:12.050: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.30.208.25:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-pjdf2 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 19:32:12.051: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
May 13 19:32:12.251: INFO: Found all expected endpoints: [netserver-1]
May 13 19:32:12.260: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.30.217.150:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-pjdf2 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 19:32:12.260: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
May 13 19:32:12.467: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:32:12.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-pjdf2" for this suite.
May 13 19:32:36.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:32:36.740: INFO: namespace: e2e-tests-pod-network-test-pjdf2, resource: bindings, ignored listing per whitelist
May 13 19:32:36.810: INFO: namespace e2e-tests-pod-network-test-pjdf2 deletion completed in 24.331796564s

• [SLOW TEST:47.610 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:32:36.810: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-22b4x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 19:32:37.129: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dd22ee96-75b5-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-projected-22b4x" to be "success or failure"
May 13 19:32:37.140: INFO: Pod "downwardapi-volume-dd22ee96-75b5-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 11.362303ms
May 13 19:32:39.149: INFO: Pod "downwardapi-volume-dd22ee96-75b5-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020440314s
STEP: Saw pod success
May 13 19:32:39.149: INFO: Pod "downwardapi-volume-dd22ee96-75b5-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:32:39.158: INFO: Trying to get logs from node 10.170.219.140 pod downwardapi-volume-dd22ee96-75b5-11e9-a09a-7e4d6cfcc771 container client-container: <nil>
STEP: delete the pod
May 13 19:32:39.210: INFO: Waiting for pod downwardapi-volume-dd22ee96-75b5-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:32:39.218: INFO: Pod downwardapi-volume-dd22ee96-75b5-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:32:39.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-22b4x" for this suite.
May 13 19:32:45.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:32:45.390: INFO: namespace: e2e-tests-projected-22b4x, resource: bindings, ignored listing per whitelist
May 13 19:32:45.689: INFO: namespace e2e-tests-projected-22b4x deletion completed in 6.460621326s

• [SLOW TEST:8.879 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:32:45.689: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-mzzh7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-e275cbad-75b5-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume configMaps
May 13 19:32:46.187: INFO: Waiting up to 5m0s for pod "pod-configmaps-e28937dc-75b5-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-configmap-mzzh7" to be "success or failure"
May 13 19:32:46.241: INFO: Pod "pod-configmaps-e28937dc-75b5-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 53.847935ms
May 13 19:32:48.254: INFO: Pod "pod-configmaps-e28937dc-75b5-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.066971851s
STEP: Saw pod success
May 13 19:32:48.254: INFO: Pod "pod-configmaps-e28937dc-75b5-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:32:48.263: INFO: Trying to get logs from node 10.170.219.140 pod pod-configmaps-e28937dc-75b5-11e9-a09a-7e4d6cfcc771 container configmap-volume-test: <nil>
STEP: delete the pod
May 13 19:32:48.312: INFO: Waiting for pod pod-configmaps-e28937dc-75b5-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:32:48.319: INFO: Pod pod-configmaps-e28937dc-75b5-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:32:48.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-mzzh7" for this suite.
May 13 19:32:54.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:32:54.752: INFO: namespace: e2e-tests-configmap-mzzh7, resource: bindings, ignored listing per whitelist
May 13 19:32:54.779: INFO: namespace e2e-tests-configmap-mzzh7 deletion completed in 6.44932798s

• [SLOW TEST:9.090 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:32:54.780: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-77bqq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 19:32:55.129: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
May 13 19:32:55.145: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-77bqq/daemonsets","resourceVersion":"47156"},"items":null}

May 13 19:32:55.154: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-77bqq/pods","resourceVersion":"47156"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:32:55.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-77bqq" for this suite.
May 13 19:33:01.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:33:01.264: INFO: namespace: e2e-tests-daemonsets-77bqq, resource: bindings, ignored listing per whitelist
May 13 19:33:01.502: INFO: namespace e2e-tests-daemonsets-77bqq deletion completed in 6.309320264s

S [SKIPPING] [6.723 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  May 13 19:32:55.130: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:33:01.503: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-vmzgj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
May 13 19:33:01.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 create -f - --namespace=e2e-tests-kubectl-vmzgj'
May 13 19:33:02.265: INFO: stderr: ""
May 13 19:33:02.265: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
May 13 19:33:03.275: INFO: Selector matched 1 pods for map[app:redis]
May 13 19:33:03.275: INFO: Found 0 / 1
May 13 19:33:04.279: INFO: Selector matched 1 pods for map[app:redis]
May 13 19:33:04.279: INFO: Found 1 / 1
May 13 19:33:04.279: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 13 19:33:04.290: INFO: Selector matched 1 pods for map[app:redis]
May 13 19:33:04.290: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
May 13 19:33:04.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 logs redis-master-bcj6l redis-master --namespace=e2e-tests-kubectl-vmzgj'
May 13 19:33:04.486: INFO: stderr: ""
May 13 19:33:04.486: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 13 May 19:33:03.419 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 13 May 19:33:03.419 # Server started, Redis version 3.2.12\n1:M 13 May 19:33:03.419 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 13 May 19:33:03.419 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
May 13 19:33:04.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 log redis-master-bcj6l redis-master --namespace=e2e-tests-kubectl-vmzgj --tail=1'
May 13 19:33:04.616: INFO: stderr: ""
May 13 19:33:04.616: INFO: stdout: "1:M 13 May 19:33:03.419 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
May 13 19:33:04.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 log redis-master-bcj6l redis-master --namespace=e2e-tests-kubectl-vmzgj --limit-bytes=1'
May 13 19:33:04.796: INFO: stderr: ""
May 13 19:33:04.796: INFO: stdout: " "
STEP: exposing timestamps
May 13 19:33:04.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 log redis-master-bcj6l redis-master --namespace=e2e-tests-kubectl-vmzgj --tail=1 --timestamps'
May 13 19:33:04.943: INFO: stderr: ""
May 13 19:33:04.943: INFO: stdout: "2019-05-13T19:33:03.41948568Z 1:M 13 May 19:33:03.419 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
May 13 19:33:07.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 log redis-master-bcj6l redis-master --namespace=e2e-tests-kubectl-vmzgj --since=1s'
May 13 19:33:07.676: INFO: stderr: ""
May 13 19:33:07.676: INFO: stdout: ""
May 13 19:33:07.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 log redis-master-bcj6l redis-master --namespace=e2e-tests-kubectl-vmzgj --since=24h'
May 13 19:33:07.825: INFO: stderr: ""
May 13 19:33:07.825: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 13 May 19:33:03.419 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 13 May 19:33:03.419 # Server started, Redis version 3.2.12\n1:M 13 May 19:33:03.419 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 13 May 19:33:03.419 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
May 13 19:33:07.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-vmzgj'
May 13 19:33:07.961: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 13 19:33:07.961: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
May 13 19:33:07.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-vmzgj'
May 13 19:33:08.086: INFO: stderr: "No resources found.\n"
May 13 19:33:08.086: INFO: stdout: ""
May 13 19:33:08.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 get pods -l name=nginx --namespace=e2e-tests-kubectl-vmzgj -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 13 19:33:08.210: INFO: stderr: ""
May 13 19:33:08.210: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:33:08.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vmzgj" for this suite.
May 13 19:33:32.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:33:32.369: INFO: namespace: e2e-tests-kubectl-vmzgj, resource: bindings, ignored listing per whitelist
May 13 19:33:32.983: INFO: namespace e2e-tests-kubectl-vmzgj deletion completed in 24.759720658s

• [SLOW TEST:31.480 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:33:32.983: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-6q6qd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-kwrh
STEP: Creating a pod to test atomic-volume-subpath
May 13 19:33:33.386: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-kwrh" in namespace "e2e-tests-subpath-6q6qd" to be "success or failure"
May 13 19:33:33.396: INFO: Pod "pod-subpath-test-secret-kwrh": Phase="Pending", Reason="", readiness=false. Elapsed: 10.006007ms
May 13 19:33:35.405: INFO: Pod "pod-subpath-test-secret-kwrh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018840617s
May 13 19:33:37.418: INFO: Pod "pod-subpath-test-secret-kwrh": Phase="Running", Reason="", readiness=false. Elapsed: 4.03195556s
May 13 19:33:39.441: INFO: Pod "pod-subpath-test-secret-kwrh": Phase="Running", Reason="", readiness=false. Elapsed: 6.054865887s
May 13 19:33:41.450: INFO: Pod "pod-subpath-test-secret-kwrh": Phase="Running", Reason="", readiness=false. Elapsed: 8.063925736s
May 13 19:33:43.459: INFO: Pod "pod-subpath-test-secret-kwrh": Phase="Running", Reason="", readiness=false. Elapsed: 10.073092331s
May 13 19:33:45.469: INFO: Pod "pod-subpath-test-secret-kwrh": Phase="Running", Reason="", readiness=false. Elapsed: 12.08276728s
May 13 19:33:47.477: INFO: Pod "pod-subpath-test-secret-kwrh": Phase="Running", Reason="", readiness=false. Elapsed: 14.091718482s
May 13 19:33:49.541: INFO: Pod "pod-subpath-test-secret-kwrh": Phase="Running", Reason="", readiness=false. Elapsed: 16.155296059s
May 13 19:33:51.550: INFO: Pod "pod-subpath-test-secret-kwrh": Phase="Running", Reason="", readiness=false. Elapsed: 18.164679995s
May 13 19:33:53.559: INFO: Pod "pod-subpath-test-secret-kwrh": Phase="Running", Reason="", readiness=false. Elapsed: 20.173405021s
May 13 19:33:55.568: INFO: Pod "pod-subpath-test-secret-kwrh": Phase="Running", Reason="", readiness=false. Elapsed: 22.18250287s
May 13 19:33:57.578: INFO: Pod "pod-subpath-test-secret-kwrh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.19193104s
STEP: Saw pod success
May 13 19:33:57.578: INFO: Pod "pod-subpath-test-secret-kwrh" satisfied condition "success or failure"
May 13 19:33:57.586: INFO: Trying to get logs from node 10.170.219.140 pod pod-subpath-test-secret-kwrh container test-container-subpath-secret-kwrh: <nil>
STEP: delete the pod
May 13 19:33:57.636: INFO: Waiting for pod pod-subpath-test-secret-kwrh to disappear
May 13 19:33:57.647: INFO: Pod pod-subpath-test-secret-kwrh no longer exists
STEP: Deleting pod pod-subpath-test-secret-kwrh
May 13 19:33:57.647: INFO: Deleting pod "pod-subpath-test-secret-kwrh" in namespace "e2e-tests-subpath-6q6qd"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:33:57.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-6q6qd" for this suite.
May 13 19:34:03.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:34:03.949: INFO: namespace: e2e-tests-subpath-6q6qd, resource: bindings, ignored listing per whitelist
May 13 19:34:04.213: INFO: namespace e2e-tests-subpath-6q6qd deletion completed in 6.546509403s

• [SLOW TEST:31.231 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:34:04.214: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-t5xl5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0513 19:34:44.626202      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 13 19:34:44.626: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:34:44.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-t5xl5" for this suite.
May 13 19:34:52.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:34:52.734: INFO: namespace: e2e-tests-gc-t5xl5, resource: bindings, ignored listing per whitelist
May 13 19:34:52.950: INFO: namespace e2e-tests-gc-t5xl5 deletion completed in 8.315779759s

• [SLOW TEST:48.736 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:34:52.951: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-95dhm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-2e4984d0-75b6-11e9-a09a-7e4d6cfcc771
STEP: Creating configMap with name cm-test-opt-upd-2e498513-75b6-11e9-a09a-7e4d6cfcc771
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-2e4984d0-75b6-11e9-a09a-7e4d6cfcc771
STEP: Updating configmap cm-test-opt-upd-2e498513-75b6-11e9-a09a-7e4d6cfcc771
STEP: Creating configMap with name cm-test-opt-create-2e498530-75b6-11e9-a09a-7e4d6cfcc771
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:34:57.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-95dhm" for this suite.
May 13 19:35:21.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:35:22.213: INFO: namespace: e2e-tests-projected-95dhm, resource: bindings, ignored listing per whitelist
May 13 19:35:22.290: INFO: namespace e2e-tests-projected-95dhm deletion completed in 24.733157708s

• [SLOW TEST:29.339 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:35:22.291: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-hqvsc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
May 13 19:35:22.606: INFO: Waiting up to 5m0s for pod "client-containers-3fc4bbfe-75b6-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-containers-hqvsc" to be "success or failure"
May 13 19:35:22.617: INFO: Pod "client-containers-3fc4bbfe-75b6-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 10.673116ms
May 13 19:35:24.626: INFO: Pod "client-containers-3fc4bbfe-75b6-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020146574s
STEP: Saw pod success
May 13 19:35:24.626: INFO: Pod "client-containers-3fc4bbfe-75b6-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:35:24.635: INFO: Trying to get logs from node 10.170.219.140 pod client-containers-3fc4bbfe-75b6-11e9-a09a-7e4d6cfcc771 container test-container: <nil>
STEP: delete the pod
May 13 19:35:24.685: INFO: Waiting for pod client-containers-3fc4bbfe-75b6-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:35:24.693: INFO: Pod client-containers-3fc4bbfe-75b6-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:35:24.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-hqvsc" for this suite.
May 13 19:35:30.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:35:31.145: INFO: namespace: e2e-tests-containers-hqvsc, resource: bindings, ignored listing per whitelist
May 13 19:35:31.145: INFO: namespace e2e-tests-containers-hqvsc deletion completed in 6.441161293s

• [SLOW TEST:8.854 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:35:31.145: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-fwcq8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
May 13 19:35:31.437: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

May 13 19:35:31.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 create -f - --namespace=e2e-tests-kubectl-fwcq8'
May 13 19:35:31.724: INFO: stderr: ""
May 13 19:35:31.724: INFO: stdout: "service/redis-slave created\n"
May 13 19:35:31.724: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

May 13 19:35:31.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 create -f - --namespace=e2e-tests-kubectl-fwcq8'
May 13 19:35:31.980: INFO: stderr: ""
May 13 19:35:31.980: INFO: stdout: "service/redis-master created\n"
May 13 19:35:31.980: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

May 13 19:35:31.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 create -f - --namespace=e2e-tests-kubectl-fwcq8'
May 13 19:35:32.461: INFO: stderr: ""
May 13 19:35:32.461: INFO: stdout: "service/frontend created\n"
May 13 19:35:32.462: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

May 13 19:35:32.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 create -f - --namespace=e2e-tests-kubectl-fwcq8'
May 13 19:35:32.679: INFO: stderr: ""
May 13 19:35:32.679: INFO: stdout: "deployment.extensions/frontend created\n"
May 13 19:35:32.679: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

May 13 19:35:32.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 create -f - --namespace=e2e-tests-kubectl-fwcq8'
May 13 19:35:32.973: INFO: stderr: ""
May 13 19:35:32.973: INFO: stdout: "deployment.extensions/redis-master created\n"
May 13 19:35:32.973: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

May 13 19:35:32.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 create -f - --namespace=e2e-tests-kubectl-fwcq8'
May 13 19:35:33.271: INFO: stderr: ""
May 13 19:35:33.272: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
May 13 19:35:33.272: INFO: Waiting for all frontend pods to be Running.
May 13 19:35:38.322: INFO: Waiting for frontend to serve content.
May 13 19:35:38.352: INFO: Trying to add a new entry to the guestbook.
May 13 19:35:38.383: INFO: Verifying that added entry can be retrieved.
May 13 19:35:38.407: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
May 13 19:35:43.450: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
May 13 19:35:48.480: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
May 13 19:35:53.541: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
May 13 19:35:58.570: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
May 13 19:36:03.641: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
May 13 19:36:08.670: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
May 13 19:36:13.713: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
May 13 19:36:18.742: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
May 13 19:36:23.785: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
May 13 19:36:28.815: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
May 13 19:36:33.857: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
May 13 19:36:38.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-fwcq8'
May 13 19:36:39.062: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 13 19:36:39.062: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
May 13 19:36:39.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-fwcq8'
May 13 19:36:39.217: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 13 19:36:39.217: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
May 13 19:36:39.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-fwcq8'
May 13 19:36:39.452: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 13 19:36:39.452: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 13 19:36:39.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-fwcq8'
May 13 19:36:39.586: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 13 19:36:39.586: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 13 19:36:39.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-fwcq8'
May 13 19:36:39.735: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 13 19:36:39.735: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
May 13 19:36:39.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-fwcq8'
May 13 19:36:39.974: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 13 19:36:39.974: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:36:39.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fwcq8" for this suite.
May 13 19:37:26.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:37:26.271: INFO: namespace: e2e-tests-kubectl-fwcq8, resource: bindings, ignored listing per whitelist
May 13 19:37:26.438: INFO: namespace e2e-tests-kubectl-fwcq8 deletion completed in 46.452855992s

• [SLOW TEST:115.293 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:37:26.438: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-thdtq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 13 19:37:26.754: INFO: Waiting up to 5m0s for pod "pod-89c447a6-75b6-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-emptydir-thdtq" to be "success or failure"
May 13 19:37:26.763: INFO: Pod "pod-89c447a6-75b6-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 9.311791ms
May 13 19:37:28.772: INFO: Pod "pod-89c447a6-75b6-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018583227s
STEP: Saw pod success
May 13 19:37:28.772: INFO: Pod "pod-89c447a6-75b6-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:37:28.781: INFO: Trying to get logs from node 10.170.219.140 pod pod-89c447a6-75b6-11e9-a09a-7e4d6cfcc771 container test-container: <nil>
STEP: delete the pod
May 13 19:37:28.832: INFO: Waiting for pod pod-89c447a6-75b6-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:37:28.841: INFO: Pod pod-89c447a6-75b6-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:37:28.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-thdtq" for this suite.
May 13 19:37:34.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:37:35.052: INFO: namespace: e2e-tests-emptydir-thdtq, resource: bindings, ignored listing per whitelist
May 13 19:37:35.209: INFO: namespace e2e-tests-emptydir-thdtq deletion completed in 6.357197207s

• [SLOW TEST:8.771 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:37:35.209: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-mdbqt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
May 13 19:37:35.563: INFO: Waiting up to 5m0s for pod "var-expansion-8f0495f6-75b6-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-var-expansion-mdbqt" to be "success or failure"
May 13 19:37:35.571: INFO: Pod "var-expansion-8f0495f6-75b6-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 7.78826ms
May 13 19:37:37.581: INFO: Pod "var-expansion-8f0495f6-75b6-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018092763s
May 13 19:37:39.589: INFO: Pod "var-expansion-8f0495f6-75b6-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026680052s
STEP: Saw pod success
May 13 19:37:39.590: INFO: Pod "var-expansion-8f0495f6-75b6-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:37:39.597: INFO: Trying to get logs from node 10.170.219.140 pod var-expansion-8f0495f6-75b6-11e9-a09a-7e4d6cfcc771 container dapi-container: <nil>
STEP: delete the pod
May 13 19:37:39.679: INFO: Waiting for pod var-expansion-8f0495f6-75b6-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:37:39.687: INFO: Pod var-expansion-8f0495f6-75b6-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:37:39.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-mdbqt" for this suite.
May 13 19:37:45.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:37:45.984: INFO: namespace: e2e-tests-var-expansion-mdbqt, resource: bindings, ignored listing per whitelist
May 13 19:37:46.030: INFO: namespace e2e-tests-var-expansion-mdbqt deletion completed in 6.330919712s

• [SLOW TEST:10.820 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:37:46.031: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-59nv5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
May 13 19:37:46.339: INFO: Waiting up to 5m0s for pod "var-expansion-9570f570-75b6-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-var-expansion-59nv5" to be "success or failure"
May 13 19:37:46.350: INFO: Pod "var-expansion-9570f570-75b6-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 10.647897ms
May 13 19:37:48.361: INFO: Pod "var-expansion-9570f570-75b6-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022165255s
STEP: Saw pod success
May 13 19:37:48.361: INFO: Pod "var-expansion-9570f570-75b6-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:37:48.370: INFO: Trying to get logs from node 10.170.219.140 pod var-expansion-9570f570-75b6-11e9-a09a-7e4d6cfcc771 container dapi-container: <nil>
STEP: delete the pod
May 13 19:37:48.467: INFO: Waiting for pod var-expansion-9570f570-75b6-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:37:48.475: INFO: Pod var-expansion-9570f570-75b6-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:37:48.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-59nv5" for this suite.
May 13 19:37:54.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:37:54.579: INFO: namespace: e2e-tests-var-expansion-59nv5, resource: bindings, ignored listing per whitelist
May 13 19:37:54.905: INFO: namespace e2e-tests-var-expansion-59nv5 deletion completed in 6.419530839s

• [SLOW TEST:8.875 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:37:54.905: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-swdmt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-swdmt
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
May 13 19:37:55.222: INFO: Found 0 stateful pods, waiting for 3
May 13 19:38:05.245: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 13 19:38:05.245: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 13 19:38:05.245: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
May 13 19:38:05.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 exec --namespace=e2e-tests-statefulset-swdmt ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 13 19:38:05.615: INFO: stderr: ""
May 13 19:38:05.615: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 13 19:38:05.615: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
May 13 19:38:15.752: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
May 13 19:38:25.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 exec --namespace=e2e-tests-statefulset-swdmt ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 13 19:38:27.116: INFO: stderr: ""
May 13 19:38:27.116: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 13 19:38:27.116: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 13 19:38:27.172: INFO: Waiting for StatefulSet e2e-tests-statefulset-swdmt/ss2 to complete update
May 13 19:38:27.172: INFO: Waiting for Pod e2e-tests-statefulset-swdmt/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
May 13 19:38:27.172: INFO: Waiting for Pod e2e-tests-statefulset-swdmt/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
May 13 19:38:27.172: INFO: Waiting for Pod e2e-tests-statefulset-swdmt/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
May 13 19:38:37.250: INFO: Waiting for StatefulSet e2e-tests-statefulset-swdmt/ss2 to complete update
May 13 19:38:37.250: INFO: Waiting for Pod e2e-tests-statefulset-swdmt/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
May 13 19:38:47.191: INFO: Waiting for StatefulSet e2e-tests-statefulset-swdmt/ss2 to complete update
STEP: Rolling back to a previous revision
May 13 19:38:57.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 exec --namespace=e2e-tests-statefulset-swdmt ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 13 19:38:57.530: INFO: stderr: ""
May 13 19:38:57.530: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 13 19:38:57.530: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 13 19:39:07.652: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
May 13 19:39:17.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 exec --namespace=e2e-tests-statefulset-swdmt ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 13 19:39:18.089: INFO: stderr: ""
May 13 19:39:18.089: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 13 19:39:18.089: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 13 19:39:38.161: INFO: Waiting for StatefulSet e2e-tests-statefulset-swdmt/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 13 19:39:48.197: INFO: Deleting all statefulset in ns e2e-tests-statefulset-swdmt
May 13 19:39:48.210: INFO: Scaling statefulset ss2 to 0
May 13 19:40:08.269: INFO: Waiting for statefulset status.replicas updated to 0
May 13 19:40:08.278: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:40:08.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-swdmt" for this suite.
May 13 19:40:16.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:40:16.496: INFO: namespace: e2e-tests-statefulset-swdmt, resource: bindings, ignored listing per whitelist
May 13 19:40:16.715: INFO: namespace e2e-tests-statefulset-swdmt deletion completed in 8.374841656s

• [SLOW TEST:141.810 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:40:16.716: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-4zvhs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
May 13 19:40:17.031: INFO: Waiting up to 5m0s for pod "pod-ef427769-75b6-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-emptydir-4zvhs" to be "success or failure"
May 13 19:40:17.039: INFO: Pod "pod-ef427769-75b6-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 8.059318ms
May 13 19:40:19.062: INFO: Pod "pod-ef427769-75b6-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031060645s
STEP: Saw pod success
May 13 19:40:19.062: INFO: Pod "pod-ef427769-75b6-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:40:19.072: INFO: Trying to get logs from node 10.170.219.140 pod pod-ef427769-75b6-11e9-a09a-7e4d6cfcc771 container test-container: <nil>
STEP: delete the pod
May 13 19:40:19.141: INFO: Waiting for pod pod-ef427769-75b6-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:40:19.156: INFO: Pod pod-ef427769-75b6-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:40:19.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4zvhs" for this suite.
May 13 19:40:25.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:40:25.245: INFO: namespace: e2e-tests-emptydir-4zvhs, resource: bindings, ignored listing per whitelist
May 13 19:40:25.505: INFO: namespace e2e-tests-emptydir-4zvhs deletion completed in 6.336498966s

• [SLOW TEST:8.789 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:40:25.505: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-gsjms
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
May 13 19:40:28.386: INFO: Successfully updated pod "labelsupdatef47da7ce-75b6-11e9-a09a-7e4d6cfcc771"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:40:32.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gsjms" for this suite.
May 13 19:40:56.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:40:56.841: INFO: namespace: e2e-tests-projected-gsjms, resource: bindings, ignored listing per whitelist
May 13 19:40:56.889: INFO: namespace e2e-tests-projected-gsjms deletion completed in 24.418210164s

• [SLOW TEST:31.384 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:40:56.889: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-j9s8k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-0737aa6e-75b7-11e9-a09a-7e4d6cfcc771
STEP: Creating a pod to test consume configMaps
May 13 19:40:57.236: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-073963b3-75b7-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-projected-j9s8k" to be "success or failure"
May 13 19:40:57.244: INFO: Pod "pod-projected-configmaps-073963b3-75b7-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 7.987995ms
May 13 19:40:59.253: INFO: Pod "pod-projected-configmaps-073963b3-75b7-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017023802s
STEP: Saw pod success
May 13 19:40:59.253: INFO: Pod "pod-projected-configmaps-073963b3-75b7-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:40:59.261: INFO: Trying to get logs from node 10.170.219.140 pod pod-projected-configmaps-073963b3-75b7-11e9-a09a-7e4d6cfcc771 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 13 19:40:59.307: INFO: Waiting for pod pod-projected-configmaps-073963b3-75b7-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:40:59.315: INFO: Pod pod-projected-configmaps-073963b3-75b7-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:40:59.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j9s8k" for this suite.
May 13 19:41:05.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:41:05.414: INFO: namespace: e2e-tests-projected-j9s8k, resource: bindings, ignored listing per whitelist
May 13 19:41:05.635: INFO: namespace e2e-tests-projected-j9s8k deletion completed in 6.309227801s

• [SLOW TEST:8.746 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:41:05.636: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-rnng2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
May 13 19:41:05.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 cluster-info'
May 13 19:41:06.051: INFO: stderr: ""
May 13 19:41:06.051: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:41:06.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rnng2" for this suite.
May 13 19:41:12.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:41:12.545: INFO: namespace: e2e-tests-kubectl-rnng2, resource: bindings, ignored listing per whitelist
May 13 19:41:12.619: INFO: namespace e2e-tests-kubectl-rnng2 deletion completed in 6.556765324s

• [SLOW TEST:6.984 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:41:12.620: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-vp4td
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:41:13.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-vp4td" for this suite.
May 13 19:41:19.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:41:19.215: INFO: namespace: e2e-tests-services-vp4td, resource: bindings, ignored listing per whitelist
May 13 19:41:19.411: INFO: namespace e2e-tests-services-vp4td deletion completed in 6.335551406s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.792 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:41:19.412: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-mvj9n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May 13 19:41:23.857: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 13 19:41:23.866: INFO: Pod pod-with-poststart-http-hook still exists
May 13 19:41:25.867: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 13 19:41:25.889: INFO: Pod pod-with-poststart-http-hook still exists
May 13 19:41:27.867: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 13 19:41:27.941: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:41:27.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-mvj9n" for this suite.
May 13 19:41:51.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:41:52.266: INFO: namespace: e2e-tests-container-lifecycle-hook-mvj9n, resource: bindings, ignored listing per whitelist
May 13 19:41:52.403: INFO: namespace e2e-tests-container-lifecycle-hook-mvj9n deletion completed in 24.449931316s

• [SLOW TEST:32.991 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:41:52.404: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-6gtz4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 19:41:52.744: INFO: Waiting up to 5m0s for pod "downwardapi-volume-284e629c-75b7-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-downward-api-6gtz4" to be "success or failure"
May 13 19:41:52.755: INFO: Pod "downwardapi-volume-284e629c-75b7-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 10.783981ms
May 13 19:41:54.764: INFO: Pod "downwardapi-volume-284e629c-75b7-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01967024s
STEP: Saw pod success
May 13 19:41:54.764: INFO: Pod "downwardapi-volume-284e629c-75b7-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:41:54.772: INFO: Trying to get logs from node 10.170.219.140 pod downwardapi-volume-284e629c-75b7-11e9-a09a-7e4d6cfcc771 container client-container: <nil>
STEP: delete the pod
May 13 19:41:54.870: INFO: Waiting for pod downwardapi-volume-284e629c-75b7-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:41:54.881: INFO: Pod downwardapi-volume-284e629c-75b7-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:41:54.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6gtz4" for this suite.
May 13 19:42:00.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:42:01.070: INFO: namespace: e2e-tests-downward-api-6gtz4, resource: bindings, ignored listing per whitelist
May 13 19:42:01.191: INFO: namespace e2e-tests-downward-api-6gtz4 deletion completed in 6.300058127s

• [SLOW TEST:8.788 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:42:01.192: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-s7t2s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
May 13 19:42:01.476: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:42:05.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-s7t2s" for this suite.
May 13 19:42:29.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:42:29.785: INFO: namespace: e2e-tests-init-container-s7t2s, resource: bindings, ignored listing per whitelist
May 13 19:42:30.045: INFO: namespace e2e-tests-init-container-s7t2s deletion completed in 24.766492345s

• [SLOW TEST:28.853 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:42:30.046: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-654x8
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-3ebf19f2-75b7-11e9-a09a-7e4d6cfcc771
STEP: Creating configMap with name cm-test-opt-upd-3ebf1a3a-75b7-11e9-a09a-7e4d6cfcc771
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-3ebf19f2-75b7-11e9-a09a-7e4d6cfcc771
STEP: Updating configmap cm-test-opt-upd-3ebf1a3a-75b7-11e9-a09a-7e4d6cfcc771
STEP: Creating configMap with name cm-test-opt-create-3ebf1a58-75b7-11e9-a09a-7e4d6cfcc771
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:42:34.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-654x8" for this suite.
May 13 19:42:58.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:42:58.789: INFO: namespace: e2e-tests-configmap-654x8, resource: bindings, ignored listing per whitelist
May 13 19:42:59.025: INFO: namespace e2e-tests-configmap-654x8 deletion completed in 24.375004272s

• [SLOW TEST:28.980 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:42:59.025: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-6k7b7
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 19:42:59.332: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:43:00.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-6k7b7" for this suite.
May 13 19:43:06.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:43:06.748: INFO: namespace: e2e-tests-custom-resource-definition-6k7b7, resource: bindings, ignored listing per whitelist
May 13 19:43:06.766: INFO: namespace e2e-tests-custom-resource-definition-6k7b7 deletion completed in 6.325050952s

• [SLOW TEST:7.740 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:43:06.766: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-jkg44
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
May 13 19:43:07.075: INFO: Waiting up to 5m0s for pod "pod-549d694e-75b7-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-emptydir-jkg44" to be "success or failure"
May 13 19:43:07.084: INFO: Pod "pod-549d694e-75b7-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 8.630993ms
May 13 19:43:09.093: INFO: Pod "pod-549d694e-75b7-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018316642s
STEP: Saw pod success
May 13 19:43:09.093: INFO: Pod "pod-549d694e-75b7-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:43:09.104: INFO: Trying to get logs from node 10.170.219.140 pod pod-549d694e-75b7-11e9-a09a-7e4d6cfcc771 container test-container: <nil>
STEP: delete the pod
May 13 19:43:09.155: INFO: Waiting for pod pod-549d694e-75b7-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:43:09.241: INFO: Pod pod-549d694e-75b7-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:43:09.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jkg44" for this suite.
May 13 19:43:15.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:43:15.446: INFO: namespace: e2e-tests-emptydir-jkg44, resource: bindings, ignored listing per whitelist
May 13 19:43:15.567: INFO: namespace e2e-tests-emptydir-jkg44 deletion completed in 6.313862725s

• [SLOW TEST:8.801 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:43:15.567: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-pfzrv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 13 19:43:15.884: INFO: Waiting up to 5m0s for pod "downward-api-59dd817e-75b7-11e9-a09a-7e4d6cfcc771" in namespace "e2e-tests-downward-api-pfzrv" to be "success or failure"
May 13 19:43:15.894: INFO: Pod "downward-api-59dd817e-75b7-11e9-a09a-7e4d6cfcc771": Phase="Pending", Reason="", readiness=false. Elapsed: 9.87527ms
May 13 19:43:17.916: INFO: Pod "downward-api-59dd817e-75b7-11e9-a09a-7e4d6cfcc771": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031748245s
STEP: Saw pod success
May 13 19:43:17.916: INFO: Pod "downward-api-59dd817e-75b7-11e9-a09a-7e4d6cfcc771" satisfied condition "success or failure"
May 13 19:43:17.924: INFO: Trying to get logs from node 10.170.219.140 pod downward-api-59dd817e-75b7-11e9-a09a-7e4d6cfcc771 container dapi-container: <nil>
STEP: delete the pod
May 13 19:43:18.041: INFO: Waiting for pod downward-api-59dd817e-75b7-11e9-a09a-7e4d6cfcc771 to disappear
May 13 19:43:18.060: INFO: Pod downward-api-59dd817e-75b7-11e9-a09a-7e4d6cfcc771 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:43:18.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pfzrv" for this suite.
May 13 19:43:24.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:43:24.149: INFO: namespace: e2e-tests-downward-api-pfzrv, resource: bindings, ignored listing per whitelist
May 13 19:43:24.416: INFO: namespace e2e-tests-downward-api-pfzrv deletion completed in 6.344652605s

• [SLOW TEST:8.849 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:43:24.416: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-8bzjg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 19:43:24.775: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
May 13 19:43:24.795: INFO: Number of nodes with available pods: 0
May 13 19:43:24.795: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
May 13 19:43:24.834: INFO: Number of nodes with available pods: 0
May 13 19:43:24.834: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:25.843: INFO: Number of nodes with available pods: 0
May 13 19:43:25.843: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:26.844: INFO: Number of nodes with available pods: 1
May 13 19:43:26.844: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
May 13 19:43:26.950: INFO: Number of nodes with available pods: 0
May 13 19:43:26.950: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
May 13 19:43:26.973: INFO: Number of nodes with available pods: 0
May 13 19:43:26.973: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:27.998: INFO: Number of nodes with available pods: 0
May 13 19:43:27.998: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:28.981: INFO: Number of nodes with available pods: 0
May 13 19:43:28.981: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:29.981: INFO: Number of nodes with available pods: 0
May 13 19:43:29.982: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:30.981: INFO: Number of nodes with available pods: 0
May 13 19:43:30.981: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:31.983: INFO: Number of nodes with available pods: 0
May 13 19:43:31.983: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:32.981: INFO: Number of nodes with available pods: 0
May 13 19:43:32.981: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:34.041: INFO: Number of nodes with available pods: 0
May 13 19:43:34.041: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:34.981: INFO: Number of nodes with available pods: 0
May 13 19:43:34.981: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:35.982: INFO: Number of nodes with available pods: 0
May 13 19:43:35.982: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:36.982: INFO: Number of nodes with available pods: 0
May 13 19:43:36.982: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:37.982: INFO: Number of nodes with available pods: 0
May 13 19:43:37.982: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:38.996: INFO: Number of nodes with available pods: 0
May 13 19:43:38.996: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:39.982: INFO: Number of nodes with available pods: 0
May 13 19:43:39.982: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:40.982: INFO: Number of nodes with available pods: 0
May 13 19:43:40.982: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:41.982: INFO: Number of nodes with available pods: 0
May 13 19:43:41.982: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:42.982: INFO: Number of nodes with available pods: 0
May 13 19:43:42.982: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:43.984: INFO: Number of nodes with available pods: 0
May 13 19:43:43.984: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:44.982: INFO: Number of nodes with available pods: 0
May 13 19:43:44.982: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:45.984: INFO: Number of nodes with available pods: 0
May 13 19:43:45.984: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:46.982: INFO: Number of nodes with available pods: 0
May 13 19:43:46.982: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:47.983: INFO: Number of nodes with available pods: 0
May 13 19:43:47.983: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:48.983: INFO: Number of nodes with available pods: 0
May 13 19:43:48.984: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:49.996: INFO: Number of nodes with available pods: 0
May 13 19:43:49.996: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:50.982: INFO: Number of nodes with available pods: 0
May 13 19:43:50.982: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:51.982: INFO: Number of nodes with available pods: 0
May 13 19:43:51.982: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:52.982: INFO: Number of nodes with available pods: 0
May 13 19:43:52.982: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:53.981: INFO: Number of nodes with available pods: 0
May 13 19:43:53.981: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:54.982: INFO: Number of nodes with available pods: 0
May 13 19:43:54.982: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:55.982: INFO: Number of nodes with available pods: 0
May 13 19:43:55.982: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:56.983: INFO: Number of nodes with available pods: 0
May 13 19:43:56.983: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:57.982: INFO: Number of nodes with available pods: 0
May 13 19:43:57.982: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:58.982: INFO: Number of nodes with available pods: 0
May 13 19:43:58.982: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:43:59.984: INFO: Number of nodes with available pods: 0
May 13 19:43:59.984: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:44:00.997: INFO: Number of nodes with available pods: 0
May 13 19:44:00.997: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:44:01.981: INFO: Number of nodes with available pods: 0
May 13 19:44:01.982: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:44:02.982: INFO: Number of nodes with available pods: 0
May 13 19:44:02.982: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:44:03.982: INFO: Number of nodes with available pods: 0
May 13 19:44:03.982: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:44:05.049: INFO: Number of nodes with available pods: 0
May 13 19:44:05.049: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:44:05.982: INFO: Number of nodes with available pods: 0
May 13 19:44:05.983: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:44:06.981: INFO: Number of nodes with available pods: 0
May 13 19:44:06.981: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:44:07.981: INFO: Number of nodes with available pods: 0
May 13 19:44:07.982: INFO: Node 10.170.219.140 is running more than one daemon pod
May 13 19:44:08.981: INFO: Number of nodes with available pods: 1
May 13 19:44:08.981: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-8bzjg, will wait for the garbage collector to delete the pods
May 13 19:44:09.073: INFO: Deleting {extensions DaemonSet} daemon-set took: 18.585654ms
May 13 19:44:09.173: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.237115ms
May 13 19:44:47.100: INFO: Number of nodes with available pods: 0
May 13 19:44:47.100: INFO: Number of running nodes: 0, number of available pods: 0
May 13 19:44:47.108: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-8bzjg/daemonsets","resourceVersion":"50091"},"items":null}

May 13 19:44:47.117: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-8bzjg/pods","resourceVersion":"50091"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:44:47.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-8bzjg" for this suite.
May 13 19:44:53.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:44:53.445: INFO: namespace: e2e-tests-daemonsets-8bzjg, resource: bindings, ignored listing per whitelist
May 13 19:44:53.668: INFO: namespace e2e-tests-daemonsets-8bzjg deletion completed in 6.494624328s

• [SLOW TEST:89.252 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:44:53.669: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-2xb2g
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-2xb2g
May 13 19:44:56.159: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-2xb2g
STEP: checking the pod's current state and verifying that restartCount is present
May 13 19:44:56.168: INFO: Initial restart count of pod liveness-http is 0
May 13 19:45:12.376: INFO: Restart count of pod e2e-tests-container-probe-2xb2g/liveness-http is now 1 (16.20853708s elapsed)
May 13 19:45:30.899: INFO: Restart count of pod e2e-tests-container-probe-2xb2g/liveness-http is now 2 (34.731145458s elapsed)
May 13 19:45:51.062: INFO: Restart count of pod e2e-tests-container-probe-2xb2g/liveness-http is now 3 (54.894500921s elapsed)
May 13 19:46:11.183: INFO: Restart count of pod e2e-tests-container-probe-2xb2g/liveness-http is now 4 (1m15.015562997s elapsed)
May 13 19:47:23.859: INFO: Restart count of pod e2e-tests-container-probe-2xb2g/liveness-http is now 5 (2m27.691127662s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:47:23.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-2xb2g" for this suite.
May 13 19:47:29.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:47:30.175: INFO: namespace: e2e-tests-container-probe-2xb2g, resource: bindings, ignored listing per whitelist
May 13 19:47:30.331: INFO: namespace e2e-tests-container-probe-2xb2g deletion completed in 6.37792799s

• [SLOW TEST:156.662 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:47:30.331: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-9s757
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
May 13 19:47:31.205: INFO: created pod pod-service-account-defaultsa
May 13 19:47:31.205: INFO: pod pod-service-account-defaultsa service account token volume mount: true
May 13 19:47:31.217: INFO: created pod pod-service-account-mountsa
May 13 19:47:31.217: INFO: pod pod-service-account-mountsa service account token volume mount: true
May 13 19:47:31.229: INFO: created pod pod-service-account-nomountsa
May 13 19:47:31.229: INFO: pod pod-service-account-nomountsa service account token volume mount: false
May 13 19:47:31.242: INFO: created pod pod-service-account-defaultsa-mountspec
May 13 19:47:31.242: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
May 13 19:47:31.259: INFO: created pod pod-service-account-mountsa-mountspec
May 13 19:47:31.259: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
May 13 19:47:31.271: INFO: created pod pod-service-account-nomountsa-mountspec
May 13 19:47:31.271: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
May 13 19:47:31.283: INFO: created pod pod-service-account-defaultsa-nomountspec
May 13 19:47:31.283: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
May 13 19:47:31.296: INFO: created pod pod-service-account-mountsa-nomountspec
May 13 19:47:31.296: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
May 13 19:47:31.311: INFO: created pod pod-service-account-nomountsa-nomountspec
May 13 19:47:31.311: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:47:31.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-9s757" for this suite.
May 13 19:47:39.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:47:39.373: INFO: namespace: e2e-tests-svcaccounts-9s757, resource: bindings, ignored listing per whitelist
May 13 19:47:39.639: INFO: namespace e2e-tests-svcaccounts-9s757 deletion completed in 8.314547435s

• [SLOW TEST:9.308 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:47:39.640: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-s67ml
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
May 13 19:47:39.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-177230811 --namespace=e2e-tests-kubectl-s67ml run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
May 13 19:47:42.273: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
May 13 19:47:42.273: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:47:44.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-s67ml" for this suite.
May 13 19:47:50.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:47:50.455: INFO: namespace: e2e-tests-kubectl-s67ml, resource: bindings, ignored listing per whitelist
May 13 19:47:50.658: INFO: namespace e2e-tests-kubectl-s67ml deletion completed in 6.343245922s

• [SLOW TEST:11.019 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 13 19:47:50.659: INFO: >>> kubeConfig: /tmp/kubeconfig-177230811
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-zn5hl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
May 13 19:47:51.076: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-zn5hl,SelfLink:/api/v1/namespaces/e2e-tests-watch-zn5hl/configmaps/e2e-watch-test-watch-closed,UID:fde31b2b-75b7-11e9-906d-b2bf80cbe475,ResourceVersion:50726,Generation:0,CreationTimestamp:2019-05-13 19:47:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 13 19:47:51.076: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-zn5hl,SelfLink:/api/v1/namespaces/e2e-tests-watch-zn5hl/configmaps/e2e-watch-test-watch-closed,UID:fde31b2b-75b7-11e9-906d-b2bf80cbe475,ResourceVersion:50727,Generation:0,CreationTimestamp:2019-05-13 19:47:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
May 13 19:47:51.118: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-zn5hl,SelfLink:/api/v1/namespaces/e2e-tests-watch-zn5hl/configmaps/e2e-watch-test-watch-closed,UID:fde31b2b-75b7-11e9-906d-b2bf80cbe475,ResourceVersion:50728,Generation:0,CreationTimestamp:2019-05-13 19:47:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 13 19:47:51.118: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-zn5hl,SelfLink:/api/v1/namespaces/e2e-tests-watch-zn5hl/configmaps/e2e-watch-test-watch-closed,UID:fde31b2b-75b7-11e9-906d-b2bf80cbe475,ResourceVersion:50729,Generation:0,CreationTimestamp:2019-05-13 19:47:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 13 19:47:51.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-zn5hl" for this suite.
May 13 19:47:57.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:47:57.341: INFO: namespace: e2e-tests-watch-zn5hl, resource: bindings, ignored listing per whitelist
May 13 19:47:57.433: INFO: namespace e2e-tests-watch-zn5hl deletion completed in 6.30274076s

• [SLOW TEST:6.774 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSMay 13 19:47:57.433: INFO: Running AfterSuite actions on all node
May 13 19:47:57.433: INFO: Running AfterSuite actions on node 1
May 13 19:47:57.433: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 5080.848 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 1h24m41.648263222s
Test Suite Passed
