Dec  5 20:51:41.317: INFO: Overriding default scale value of zero to 1
Dec  5 20:51:41.317: INFO: Overriding default milliseconds value of zero to 5000
I1205 20:51:41.875821      16 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-794602807
I1205 20:51:41.877899      16 e2e.go:304] Starting e2e run "912be3c6-f8cf-11e8-b962-c6dde3e93636" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1544043101 - Will randomize all specs
Will run 188 of 1814 specs

Dec  5 20:51:42.134: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
Dec  5 20:51:42.137: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec  5 20:51:42.204: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec  5 20:51:42.309: INFO: 23 / 23 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec  5 20:51:42.309: INFO: expected 11 pod replicas in namespace 'kube-system', 11 are Running and Ready.
Dec  5 20:51:42.309: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec  5 20:51:42.333: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Dec  5 20:51:42.333: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
Dec  5 20:51:42.333: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-kube-fluentd' (0 seconds elapsed)
Dec  5 20:51:42.333: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'ibm-master-proxy' (0 seconds elapsed)
Dec  5 20:51:42.333: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
Dec  5 20:51:42.333: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Dec  5 20:51:42.333: INFO: e2e test version: v1.12.1
Dec  5 20:51:42.336: INFO: kube-apiserver version: v1.12.3+IKS
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 20:51:42.337: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename gc
Dec  5 20:51:42.586: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Dec  5 20:51:42.626: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-hbkft
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1205 20:51:43.933076      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  5 20:51:43.933: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 20:51:43.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-hbkft" for this suite.
Dec  5 20:51:49.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:51:50.164: INFO: namespace: e2e-tests-gc-hbkft, resource: bindings, ignored listing per whitelist
Dec  5 20:51:50.435: INFO: namespace e2e-tests-gc-hbkft deletion completed in 6.491615726s

• [SLOW TEST:8.098 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 20:51:50.435: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-dxpnh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-96d8af90-f8cf-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume secrets
Dec  5 20:51:50.862: INFO: Waiting up to 5m0s for pod "pod-secrets-96e73a46-f8cf-11e8-b962-c6dde3e93636" in namespace "e2e-tests-secrets-dxpnh" to be "success or failure"
Dec  5 20:51:50.870: INFO: Pod "pod-secrets-96e73a46-f8cf-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 8.404748ms
Dec  5 20:51:52.894: INFO: Pod "pod-secrets-96e73a46-f8cf-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03221787s
Dec  5 20:51:54.910: INFO: Pod "pod-secrets-96e73a46-f8cf-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047729228s
STEP: Saw pod success
Dec  5 20:51:54.910: INFO: Pod "pod-secrets-96e73a46-f8cf-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 20:51:54.924: INFO: Trying to get logs from node 10.191.0.150 pod pod-secrets-96e73a46-f8cf-11e8-b962-c6dde3e93636 container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 20:51:55.045: INFO: Waiting for pod pod-secrets-96e73a46-f8cf-11e8-b962-c6dde3e93636 to disappear
Dec  5 20:51:55.054: INFO: Pod pod-secrets-96e73a46-f8cf-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 20:51:55.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-dxpnh" for this suite.
Dec  5 20:52:01.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:52:01.257: INFO: namespace: e2e-tests-secrets-dxpnh, resource: bindings, ignored listing per whitelist
Dec  5 20:52:01.467: INFO: namespace e2e-tests-secrets-dxpnh deletion completed in 6.398314393s

• [SLOW TEST:11.032 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 20:52:01.468: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-hmqdj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 20:52:01.836: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9d716bda-f8cf-11e8-b962-c6dde3e93636" in namespace "e2e-tests-downward-api-hmqdj" to be "success or failure"
Dec  5 20:52:01.857: INFO: Pod "downwardapi-volume-9d716bda-f8cf-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 20.508609ms
Dec  5 20:52:03.885: INFO: Pod "downwardapi-volume-9d716bda-f8cf-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.04915282s
STEP: Saw pod success
Dec  5 20:52:03.886: INFO: Pod "downwardapi-volume-9d716bda-f8cf-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 20:52:03.896: INFO: Trying to get logs from node 10.191.0.150 pod downwardapi-volume-9d716bda-f8cf-11e8-b962-c6dde3e93636 container client-container: <nil>
STEP: delete the pod
Dec  5 20:52:03.957: INFO: Waiting for pod downwardapi-volume-9d716bda-f8cf-11e8-b962-c6dde3e93636 to disappear
Dec  5 20:52:03.976: INFO: Pod downwardapi-volume-9d716bda-f8cf-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 20:52:03.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hmqdj" for this suite.
Dec  5 20:52:10.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:52:10.155: INFO: namespace: e2e-tests-downward-api-hmqdj, resource: bindings, ignored listing per whitelist
Dec  5 20:52:10.476: INFO: namespace e2e-tests-downward-api-hmqdj deletion completed in 6.440739793s

• [SLOW TEST:9.009 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 20:52:10.477: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-fjpnw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1205 20:52:20.964678      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  5 20:52:20.964: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 20:52:20.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-fjpnw" for this suite.
Dec  5 20:52:27.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:52:27.398: INFO: namespace: e2e-tests-gc-fjpnw, resource: bindings, ignored listing per whitelist
Dec  5 20:52:27.465: INFO: namespace e2e-tests-gc-fjpnw deletion completed in 6.486498695s

• [SLOW TEST:16.988 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 20:52:27.466: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-z2bzt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  5 20:52:27.808: INFO: Waiting up to 5m0s for pod "pod-acecab56-f8cf-11e8-b962-c6dde3e93636" in namespace "e2e-tests-emptydir-z2bzt" to be "success or failure"
Dec  5 20:52:27.820: INFO: Pod "pod-acecab56-f8cf-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 11.590968ms
Dec  5 20:52:29.831: INFO: Pod "pod-acecab56-f8cf-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023395581s
Dec  5 20:52:31.839: INFO: Pod "pod-acecab56-f8cf-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031268309s
STEP: Saw pod success
Dec  5 20:52:31.839: INFO: Pod "pod-acecab56-f8cf-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 20:52:31.847: INFO: Trying to get logs from node 10.191.0.150 pod pod-acecab56-f8cf-11e8-b962-c6dde3e93636 container test-container: <nil>
STEP: delete the pod
Dec  5 20:52:31.900: INFO: Waiting for pod pod-acecab56-f8cf-11e8-b962-c6dde3e93636 to disappear
Dec  5 20:52:31.909: INFO: Pod pod-acecab56-f8cf-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 20:52:31.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-z2bzt" for this suite.
Dec  5 20:52:37.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:52:38.260: INFO: namespace: e2e-tests-emptydir-z2bzt, resource: bindings, ignored listing per whitelist
Dec  5 20:52:38.415: INFO: namespace e2e-tests-emptydir-z2bzt deletion completed in 6.491221896s

• [SLOW TEST:10.949 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 20:52:38.415: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-wggwz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-b374a3ae-f8cf-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume configMaps
Dec  5 20:52:38.784: INFO: Waiting up to 5m0s for pod "pod-configmaps-b3766dc2-f8cf-11e8-b962-c6dde3e93636" in namespace "e2e-tests-configmap-wggwz" to be "success or failure"
Dec  5 20:52:38.797: INFO: Pod "pod-configmaps-b3766dc2-f8cf-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 12.306633ms
Dec  5 20:52:40.805: INFO: Pod "pod-configmaps-b3766dc2-f8cf-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020770035s
STEP: Saw pod success
Dec  5 20:52:40.805: INFO: Pod "pod-configmaps-b3766dc2-f8cf-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 20:52:40.819: INFO: Trying to get logs from node 10.191.0.150 pod pod-configmaps-b3766dc2-f8cf-11e8-b962-c6dde3e93636 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 20:52:40.879: INFO: Waiting for pod pod-configmaps-b3766dc2-f8cf-11e8-b962-c6dde3e93636 to disappear
Dec  5 20:52:40.936: INFO: Pod pod-configmaps-b3766dc2-f8cf-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 20:52:40.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wggwz" for this suite.
Dec  5 20:52:47.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:52:47.253: INFO: namespace: e2e-tests-configmap-wggwz, resource: bindings, ignored listing per whitelist
Dec  5 20:52:47.494: INFO: namespace e2e-tests-configmap-wggwz deletion completed in 6.536070716s

• [SLOW TEST:9.079 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 20:52:47.494: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-k9xnb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 20:52:47.847: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b8de6e96-f8cf-11e8-b962-c6dde3e93636" in namespace "e2e-tests-projected-k9xnb" to be "success or failure"
Dec  5 20:52:47.861: INFO: Pod "downwardapi-volume-b8de6e96-f8cf-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 14.455919ms
Dec  5 20:52:49.883: INFO: Pod "downwardapi-volume-b8de6e96-f8cf-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035936073s
STEP: Saw pod success
Dec  5 20:52:49.883: INFO: Pod "downwardapi-volume-b8de6e96-f8cf-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 20:52:49.898: INFO: Trying to get logs from node 10.191.0.150 pod downwardapi-volume-b8de6e96-f8cf-11e8-b962-c6dde3e93636 container client-container: <nil>
STEP: delete the pod
Dec  5 20:52:49.986: INFO: Waiting for pod downwardapi-volume-b8de6e96-f8cf-11e8-b962-c6dde3e93636 to disappear
Dec  5 20:52:49.997: INFO: Pod downwardapi-volume-b8de6e96-f8cf-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 20:52:49.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k9xnb" for this suite.
Dec  5 20:52:56.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:52:56.176: INFO: namespace: e2e-tests-projected-k9xnb, resource: bindings, ignored listing per whitelist
Dec  5 20:52:56.417: INFO: namespace e2e-tests-projected-k9xnb deletion completed in 6.404097921s

• [SLOW TEST:8.923 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 20:52:56.418: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-8v8l7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-be2eb915-f8cf-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume secrets
Dec  5 20:52:56.775: INFO: Waiting up to 5m0s for pod "pod-secrets-be304e8d-f8cf-11e8-b962-c6dde3e93636" in namespace "e2e-tests-secrets-8v8l7" to be "success or failure"
Dec  5 20:52:56.836: INFO: Pod "pod-secrets-be304e8d-f8cf-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 60.431946ms
Dec  5 20:52:58.849: INFO: Pod "pod-secrets-be304e8d-f8cf-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.074176441s
STEP: Saw pod success
Dec  5 20:52:58.849: INFO: Pod "pod-secrets-be304e8d-f8cf-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 20:52:58.859: INFO: Trying to get logs from node 10.191.0.150 pod pod-secrets-be304e8d-f8cf-11e8-b962-c6dde3e93636 container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 20:52:58.964: INFO: Waiting for pod pod-secrets-be304e8d-f8cf-11e8-b962-c6dde3e93636 to disappear
Dec  5 20:52:58.972: INFO: Pod pod-secrets-be304e8d-f8cf-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 20:52:58.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-8v8l7" for this suite.
Dec  5 20:53:05.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:53:05.281: INFO: namespace: e2e-tests-secrets-8v8l7, resource: bindings, ignored listing per whitelist
Dec  5 20:53:05.436: INFO: namespace e2e-tests-secrets-8v8l7 deletion completed in 6.44970189s

• [SLOW TEST:9.018 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 20:53:05.437: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-fvttb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-c38c02d9-f8cf-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume configMaps
Dec  5 20:53:05.864: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c39b60cb-f8cf-11e8-b962-c6dde3e93636" in namespace "e2e-tests-projected-fvttb" to be "success or failure"
Dec  5 20:53:05.873: INFO: Pod "pod-projected-configmaps-c39b60cb-f8cf-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 9.218646ms
Dec  5 20:53:07.886: INFO: Pod "pod-projected-configmaps-c39b60cb-f8cf-11e8-b962-c6dde3e93636": Phase="Running", Reason="", readiness=true. Elapsed: 2.02183809s
Dec  5 20:53:09.895: INFO: Pod "pod-projected-configmaps-c39b60cb-f8cf-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030989293s
STEP: Saw pod success
Dec  5 20:53:09.895: INFO: Pod "pod-projected-configmaps-c39b60cb-f8cf-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 20:53:09.904: INFO: Trying to get logs from node 10.191.0.150 pod pod-projected-configmaps-c39b60cb-f8cf-11e8-b962-c6dde3e93636 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 20:53:09.955: INFO: Waiting for pod pod-projected-configmaps-c39b60cb-f8cf-11e8-b962-c6dde3e93636 to disappear
Dec  5 20:53:09.963: INFO: Pod pod-projected-configmaps-c39b60cb-f8cf-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 20:53:09.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fvttb" for this suite.
Dec  5 20:53:16.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:53:16.443: INFO: namespace: e2e-tests-projected-fvttb, resource: bindings, ignored listing per whitelist
Dec  5 20:53:16.737: INFO: namespace e2e-tests-projected-fvttb deletion completed in 6.763633755s

• [SLOW TEST:11.301 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 20:53:16.738: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-d4jf8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 20:53:17.254: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ca656d53-f8cf-11e8-b962-c6dde3e93636" in namespace "e2e-tests-downward-api-d4jf8" to be "success or failure"
Dec  5 20:53:17.262: INFO: Pod "downwardapi-volume-ca656d53-f8cf-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 8.010623ms
Dec  5 20:53:19.270: INFO: Pod "downwardapi-volume-ca656d53-f8cf-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016811436s
STEP: Saw pod success
Dec  5 20:53:19.271: INFO: Pod "downwardapi-volume-ca656d53-f8cf-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 20:53:19.283: INFO: Trying to get logs from node 10.191.0.150 pod downwardapi-volume-ca656d53-f8cf-11e8-b962-c6dde3e93636 container client-container: <nil>
STEP: delete the pod
Dec  5 20:53:19.342: INFO: Waiting for pod downwardapi-volume-ca656d53-f8cf-11e8-b962-c6dde3e93636 to disappear
Dec  5 20:53:19.350: INFO: Pod downwardapi-volume-ca656d53-f8cf-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 20:53:19.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-d4jf8" for this suite.
Dec  5 20:53:27.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:53:27.722: INFO: namespace: e2e-tests-downward-api-d4jf8, resource: bindings, ignored listing per whitelist
Dec  5 20:53:27.901: INFO: namespace e2e-tests-downward-api-d4jf8 deletion completed in 8.534592254s

• [SLOW TEST:11.163 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 20:53:27.902: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-jr4rr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  5 20:53:31.063: INFO: Successfully updated pod "labelsupdated10d8e54-f8cf-11e8-b962-c6dde3e93636"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 20:53:35.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jr4rr" for this suite.
Dec  5 20:53:59.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:53:59.375: INFO: namespace: e2e-tests-downward-api-jr4rr, resource: bindings, ignored listing per whitelist
Dec  5 20:53:59.666: INFO: namespace e2e-tests-downward-api-jr4rr deletion completed in 24.500426366s

• [SLOW TEST:31.764 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 20:53:59.668: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-wctbt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 20:54:00.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 version'
Dec  5 20:54:00.170: INFO: stderr: ""
Dec  5 20:54:00.170: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.3+IKS\", GitCommit:\"16085f81010963073bdba425efe1d277c44a224f\", GitTreeState:\"clean\", BuildDate:\"2018-12-04T10:07:31Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 20:54:00.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wctbt" for this suite.
Dec  5 20:54:06.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:54:06.363: INFO: namespace: e2e-tests-kubectl-wctbt, resource: bindings, ignored listing per whitelist
Dec  5 20:54:06.727: INFO: namespace e2e-tests-kubectl-wctbt deletion completed in 6.544042169s

• [SLOW TEST:7.060 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 20:54:06.727: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-79z8v
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-e816b942-f8cf-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume secrets
Dec  5 20:54:07.082: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e8186dce-f8cf-11e8-b962-c6dde3e93636" in namespace "e2e-tests-projected-79z8v" to be "success or failure"
Dec  5 20:54:07.090: INFO: Pod "pod-projected-secrets-e8186dce-f8cf-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 7.730936ms
Dec  5 20:54:09.112: INFO: Pod "pod-projected-secrets-e8186dce-f8cf-11e8-b962-c6dde3e93636": Phase="Running", Reason="", readiness=true. Elapsed: 2.029859679s
Dec  5 20:54:11.122: INFO: Pod "pod-projected-secrets-e8186dce-f8cf-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040682571s
STEP: Saw pod success
Dec  5 20:54:11.123: INFO: Pod "pod-projected-secrets-e8186dce-f8cf-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 20:54:11.133: INFO: Trying to get logs from node 10.191.0.150 pod pod-projected-secrets-e8186dce-f8cf-11e8-b962-c6dde3e93636 container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 20:54:11.183: INFO: Waiting for pod pod-projected-secrets-e8186dce-f8cf-11e8-b962-c6dde3e93636 to disappear
Dec  5 20:54:11.195: INFO: Pod pod-projected-secrets-e8186dce-f8cf-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 20:54:11.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-79z8v" for this suite.
Dec  5 20:54:17.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:54:17.567: INFO: namespace: e2e-tests-projected-79z8v, resource: bindings, ignored listing per whitelist
Dec  5 20:54:17.636: INFO: namespace e2e-tests-projected-79z8v deletion completed in 6.426031042s

• [SLOW TEST:10.909 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 20:54:17.638: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-njtnf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec  5 20:54:28.068: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-njtnf PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 20:54:28.068: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
Dec  5 20:54:28.278: INFO: Exec stderr: ""
Dec  5 20:54:28.278: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-njtnf PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 20:54:28.278: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
Dec  5 20:54:28.472: INFO: Exec stderr: ""
Dec  5 20:54:28.472: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-njtnf PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 20:54:28.472: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
Dec  5 20:54:28.774: INFO: Exec stderr: ""
Dec  5 20:54:28.774: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-njtnf PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 20:54:28.774: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
Dec  5 20:54:29.075: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec  5 20:54:29.076: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-njtnf PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 20:54:29.076: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
Dec  5 20:54:29.384: INFO: Exec stderr: ""
Dec  5 20:54:29.384: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-njtnf PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 20:54:29.384: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
Dec  5 20:54:29.645: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec  5 20:54:29.645: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-njtnf PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 20:54:29.645: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
Dec  5 20:54:29.934: INFO: Exec stderr: ""
Dec  5 20:54:29.934: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-njtnf PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 20:54:29.934: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
Dec  5 20:54:30.160: INFO: Exec stderr: ""
Dec  5 20:54:30.160: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-njtnf PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 20:54:30.160: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
Dec  5 20:54:30.424: INFO: Exec stderr: ""
Dec  5 20:54:30.424: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-njtnf PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 20:54:30.424: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
Dec  5 20:54:30.711: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 20:54:30.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-njtnf" for this suite.
Dec  5 20:55:26.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:55:26.900: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-njtnf, resource: bindings, ignored listing per whitelist
Dec  5 20:55:27.187: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-njtnf deletion completed in 56.463929648s

• [SLOW TEST:69.549 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 20:55:27.188: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-cvnjp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-cvnjp
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  5 20:55:27.610: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  5 20:55:49.982: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.30.248.82:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-cvnjp PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 20:55:49.982: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
Dec  5 20:55:50.222: INFO: Found all expected endpoints: [netserver-0]
Dec  5 20:55:50.245: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.30.110.9:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-cvnjp PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 20:55:50.245: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
Dec  5 20:55:50.446: INFO: Found all expected endpoints: [netserver-1]
Dec  5 20:55:50.536: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.30.46.134:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-cvnjp PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 20:55:50.536: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
Dec  5 20:55:50.747: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 20:55:50.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-cvnjp" for this suite.
Dec  5 20:56:14.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:56:14.974: INFO: namespace: e2e-tests-pod-network-test-cvnjp, resource: bindings, ignored listing per whitelist
Dec  5 20:56:15.171: INFO: namespace e2e-tests-pod-network-test-cvnjp deletion completed in 24.413326298s

• [SLOW TEST:47.984 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 20:56:15.173: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-p774r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1205 20:56:21.591621      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  5 20:56:21.591: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 20:56:21.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-p774r" for this suite.
Dec  5 20:56:29.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:56:30.083: INFO: namespace: e2e-tests-gc-p774r, resource: bindings, ignored listing per whitelist
Dec  5 20:56:30.193: INFO: namespace e2e-tests-gc-p774r deletion completed in 8.59117315s

• [SLOW TEST:15.020 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 20:56:30.193: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-k4j42
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  5 20:56:30.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-k4j42'
Dec  5 20:56:30.895: INFO: stderr: ""
Dec  5 20:56:30.895: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Dec  5 20:56:30.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-k4j42'
Dec  5 20:56:39.408: INFO: stderr: ""
Dec  5 20:56:39.408: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 20:56:39.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-k4j42" for this suite.
Dec  5 20:56:45.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:56:45.744: INFO: namespace: e2e-tests-kubectl-k4j42, resource: bindings, ignored listing per whitelist
Dec  5 20:56:45.933: INFO: namespace e2e-tests-kubectl-k4j42 deletion completed in 6.462698072s

• [SLOW TEST:15.739 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 20:56:45.933: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-l5b5t
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  5 20:56:46.335: INFO: Waiting up to 5m0s for pod "pod-46fcc315-f8d0-11e8-b962-c6dde3e93636" in namespace "e2e-tests-emptydir-l5b5t" to be "success or failure"
Dec  5 20:56:46.347: INFO: Pod "pod-46fcc315-f8d0-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 11.042285ms
Dec  5 20:56:48.357: INFO: Pod "pod-46fcc315-f8d0-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021386314s
STEP: Saw pod success
Dec  5 20:56:48.357: INFO: Pod "pod-46fcc315-f8d0-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 20:56:48.366: INFO: Trying to get logs from node 10.191.0.150 pod pod-46fcc315-f8d0-11e8-b962-c6dde3e93636 container test-container: <nil>
STEP: delete the pod
Dec  5 20:56:48.424: INFO: Waiting for pod pod-46fcc315-f8d0-11e8-b962-c6dde3e93636 to disappear
Dec  5 20:56:48.440: INFO: Pod pod-46fcc315-f8d0-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 20:56:48.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-l5b5t" for this suite.
Dec  5 20:56:54.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:56:54.712: INFO: namespace: e2e-tests-emptydir-l5b5t, resource: bindings, ignored listing per whitelist
Dec  5 20:56:54.822: INFO: namespace e2e-tests-emptydir-l5b5t deletion completed in 6.368954291s

• [SLOW TEST:8.889 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 20:56:54.822: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-85cf5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  5 20:56:55.168: INFO: Waiting up to 5m0s for pod "pod-4c478d83-f8d0-11e8-b962-c6dde3e93636" in namespace "e2e-tests-emptydir-85cf5" to be "success or failure"
Dec  5 20:56:55.187: INFO: Pod "pod-4c478d83-f8d0-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 18.760325ms
Dec  5 20:56:57.197: INFO: Pod "pod-4c478d83-f8d0-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029182984s
STEP: Saw pod success
Dec  5 20:56:57.197: INFO: Pod "pod-4c478d83-f8d0-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 20:56:57.207: INFO: Trying to get logs from node 10.191.0.150 pod pod-4c478d83-f8d0-11e8-b962-c6dde3e93636 container test-container: <nil>
STEP: delete the pod
Dec  5 20:56:57.257: INFO: Waiting for pod pod-4c478d83-f8d0-11e8-b962-c6dde3e93636 to disappear
Dec  5 20:56:57.335: INFO: Pod pod-4c478d83-f8d0-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 20:56:57.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-85cf5" for this suite.
Dec  5 20:57:03.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:57:03.780: INFO: namespace: e2e-tests-emptydir-85cf5, resource: bindings, ignored listing per whitelist
Dec  5 20:57:03.829: INFO: namespace e2e-tests-emptydir-85cf5 deletion completed in 6.478951788s

• [SLOW TEST:9.007 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 20:57:03.829: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-vrnrs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-51bec5d1-f8d0-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume secrets
Dec  5 20:57:04.345: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-51c0b430-f8d0-11e8-b962-c6dde3e93636" in namespace "e2e-tests-projected-vrnrs" to be "success or failure"
Dec  5 20:57:04.361: INFO: Pod "pod-projected-secrets-51c0b430-f8d0-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 16.122945ms
Dec  5 20:57:06.370: INFO: Pod "pod-projected-secrets-51c0b430-f8d0-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025158988s
STEP: Saw pod success
Dec  5 20:57:06.370: INFO: Pod "pod-projected-secrets-51c0b430-f8d0-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 20:57:06.378: INFO: Trying to get logs from node 10.191.0.150 pod pod-projected-secrets-51c0b430-f8d0-11e8-b962-c6dde3e93636 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  5 20:57:06.469: INFO: Waiting for pod pod-projected-secrets-51c0b430-f8d0-11e8-b962-c6dde3e93636 to disappear
Dec  5 20:57:06.480: INFO: Pod pod-projected-secrets-51c0b430-f8d0-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 20:57:06.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vrnrs" for this suite.
Dec  5 20:57:12.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:57:12.946: INFO: namespace: e2e-tests-projected-vrnrs, resource: bindings, ignored listing per whitelist
Dec  5 20:57:12.991: INFO: namespace e2e-tests-projected-vrnrs deletion completed in 6.498561742s

• [SLOW TEST:9.162 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 20:57:12.991: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-sp426
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-57274b30-f8d0-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume configMaps
Dec  5 20:57:13.416: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5728da13-f8d0-11e8-b962-c6dde3e93636" in namespace "e2e-tests-projected-sp426" to be "success or failure"
Dec  5 20:57:13.433: INFO: Pod "pod-projected-configmaps-5728da13-f8d0-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 17.328692ms
Dec  5 20:57:15.446: INFO: Pod "pod-projected-configmaps-5728da13-f8d0-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029856043s
STEP: Saw pod success
Dec  5 20:57:15.446: INFO: Pod "pod-projected-configmaps-5728da13-f8d0-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 20:57:15.458: INFO: Trying to get logs from node 10.191.0.150 pod pod-projected-configmaps-5728da13-f8d0-11e8-b962-c6dde3e93636 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 20:57:15.519: INFO: Waiting for pod pod-projected-configmaps-5728da13-f8d0-11e8-b962-c6dde3e93636 to disappear
Dec  5 20:57:15.535: INFO: Pod pod-projected-configmaps-5728da13-f8d0-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 20:57:15.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sp426" for this suite.
Dec  5 20:57:21.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:57:21.820: INFO: namespace: e2e-tests-projected-sp426, resource: bindings, ignored listing per whitelist
Dec  5 20:57:22.027: INFO: namespace e2e-tests-projected-sp426 deletion completed in 6.478688416s

• [SLOW TEST:9.036 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 20:57:22.028: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-dm4q2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-dm4q2
Dec  5 20:57:26.470: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-dm4q2
STEP: checking the pod's current state and verifying that restartCount is present
Dec  5 20:57:26.478: INFO: Initial restart count of pod liveness-http is 0
Dec  5 20:57:50.626: INFO: Restart count of pod e2e-tests-container-probe-dm4q2/liveness-http is now 1 (24.147779319s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 20:57:50.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-dm4q2" for this suite.
Dec  5 20:57:56.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:57:56.860: INFO: namespace: e2e-tests-container-probe-dm4q2, resource: bindings, ignored listing per whitelist
Dec  5 20:57:57.042: INFO: namespace e2e-tests-container-probe-dm4q2 deletion completed in 6.375646765s

• [SLOW TEST:35.014 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 20:57:57.049: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-vpsj8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-vpsj8
Dec  5 20:57:59.446: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-vpsj8
STEP: checking the pod's current state and verifying that restartCount is present
Dec  5 20:57:59.454: INFO: Initial restart count of pod liveness-exec is 0
Dec  5 20:58:45.837: INFO: Restart count of pod e2e-tests-container-probe-vpsj8/liveness-exec is now 1 (46.382680147s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 20:58:45.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-vpsj8" for this suite.
Dec  5 20:58:51.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:58:52.235: INFO: namespace: e2e-tests-container-probe-vpsj8, resource: bindings, ignored listing per whitelist
Dec  5 20:58:52.432: INFO: namespace e2e-tests-container-probe-vpsj8 deletion completed in 6.493226338s

• [SLOW TEST:55.383 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 20:58:52.434: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-5fxjx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec  5 20:58:52.800: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-5fxjx,SelfLink:/api/v1/namespaces/e2e-tests-watch-5fxjx/configmaps/e2e-watch-test-watch-closed,UID:9264a470-f8d0-11e8-9151-427614c96c42,ResourceVersion:8410,Generation:0,CreationTimestamp:2018-12-05 20:58:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  5 20:58:52.801: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-5fxjx,SelfLink:/api/v1/namespaces/e2e-tests-watch-5fxjx/configmaps/e2e-watch-test-watch-closed,UID:9264a470-f8d0-11e8-9151-427614c96c42,ResourceVersion:8411,Generation:0,CreationTimestamp:2018-12-05 20:58:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec  5 20:58:52.843: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-5fxjx,SelfLink:/api/v1/namespaces/e2e-tests-watch-5fxjx/configmaps/e2e-watch-test-watch-closed,UID:9264a470-f8d0-11e8-9151-427614c96c42,ResourceVersion:8412,Generation:0,CreationTimestamp:2018-12-05 20:58:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  5 20:58:52.843: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-5fxjx,SelfLink:/api/v1/namespaces/e2e-tests-watch-5fxjx/configmaps/e2e-watch-test-watch-closed,UID:9264a470-f8d0-11e8-9151-427614c96c42,ResourceVersion:8413,Generation:0,CreationTimestamp:2018-12-05 20:58:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 20:58:52.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-5fxjx" for this suite.
Dec  5 20:58:58.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:58:59.132: INFO: namespace: e2e-tests-watch-5fxjx, resource: bindings, ignored listing per whitelist
Dec  5 20:58:59.293: INFO: namespace e2e-tests-watch-5fxjx deletion completed in 6.436489088s

• [SLOW TEST:6.859 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 20:58:59.294: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-w8fxk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec  5 20:58:59.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 create -f - --namespace=e2e-tests-kubectl-w8fxk'
Dec  5 20:58:59.969: INFO: stderr: ""
Dec  5 20:58:59.969: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  5 20:59:00.979: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 20:59:00.979: INFO: Found 0 / 1
Dec  5 20:59:01.979: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 20:59:01.979: INFO: Found 0 / 1
Dec  5 20:59:02.981: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 20:59:02.981: INFO: Found 0 / 1
Dec  5 20:59:03.979: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 20:59:03.979: INFO: Found 1 / 1
Dec  5 20:59:03.979: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec  5 20:59:04.044: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 20:59:04.044: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  5 20:59:04.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 patch pod redis-master-xdc6k --namespace=e2e-tests-kubectl-w8fxk -p {"metadata":{"annotations":{"x":"y"}}}'
Dec  5 20:59:04.235: INFO: stderr: ""
Dec  5 20:59:04.235: INFO: stdout: "pod/redis-master-xdc6k patched\n"
STEP: checking annotations
Dec  5 20:59:04.247: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 20:59:04.247: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 20:59:04.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-w8fxk" for this suite.
Dec  5 20:59:28.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:59:28.337: INFO: namespace: e2e-tests-kubectl-w8fxk, resource: bindings, ignored listing per whitelist
Dec  5 20:59:28.677: INFO: namespace e2e-tests-kubectl-w8fxk deletion completed in 24.416381096s

• [SLOW TEST:29.384 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 20:59:28.679: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-tt9qh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Dec  5 20:59:29.018: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-794602807 proxy --unix-socket=/tmp/kubectl-proxy-unix446456618/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 20:59:29.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tt9qh" for this suite.
Dec  5 20:59:35.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:59:35.375: INFO: namespace: e2e-tests-kubectl-tt9qh, resource: bindings, ignored listing per whitelist
Dec  5 20:59:35.516: INFO: namespace e2e-tests-kubectl-tt9qh deletion completed in 6.407465875s

• [SLOW TEST:6.837 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 20:59:35.517: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-4ztxl
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-ac1992ba-f8d0-11e8-b962-c6dde3e93636
STEP: Creating configMap with name cm-test-opt-upd-ac199314-f8d0-11e8-b962-c6dde3e93636
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-ac1992ba-f8d0-11e8-b962-c6dde3e93636
STEP: Updating configmap cm-test-opt-upd-ac199314-f8d0-11e8-b962-c6dde3e93636
STEP: Creating configMap with name cm-test-opt-create-ac19933b-f8d0-11e8-b962-c6dde3e93636
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:00:45.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4ztxl" for this suite.
Dec  5 21:01:09.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:01:09.366: INFO: namespace: e2e-tests-configmap-4ztxl, resource: bindings, ignored listing per whitelist
Dec  5 21:01:09.499: INFO: namespace e2e-tests-configmap-4ztxl deletion completed in 24.450787096s

• [SLOW TEST:93.983 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:01:09.500: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-b5q4h
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  5 21:01:09.853: INFO: Waiting up to 5m0s for pod "downward-api-e4168a4c-f8d0-11e8-b962-c6dde3e93636" in namespace "e2e-tests-downward-api-b5q4h" to be "success or failure"
Dec  5 21:01:09.863: INFO: Pod "downward-api-e4168a4c-f8d0-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 10.192178ms
Dec  5 21:01:11.873: INFO: Pod "downward-api-e4168a4c-f8d0-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020158045s
STEP: Saw pod success
Dec  5 21:01:11.873: INFO: Pod "downward-api-e4168a4c-f8d0-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:01:11.882: INFO: Trying to get logs from node 10.191.0.150 pod downward-api-e4168a4c-f8d0-11e8-b962-c6dde3e93636 container dapi-container: <nil>
STEP: delete the pod
Dec  5 21:01:11.936: INFO: Waiting for pod downward-api-e4168a4c-f8d0-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:01:11.947: INFO: Pod downward-api-e4168a4c-f8d0-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:01:11.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-b5q4h" for this suite.
Dec  5 21:01:17.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:01:18.313: INFO: namespace: e2e-tests-downward-api-b5q4h, resource: bindings, ignored listing per whitelist
Dec  5 21:01:18.359: INFO: namespace e2e-tests-downward-api-b5q4h deletion completed in 6.397587456s

• [SLOW TEST:8.859 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:01:18.362: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-h7djb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 21:01:18.714: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e95eb243-f8d0-11e8-b962-c6dde3e93636" in namespace "e2e-tests-downward-api-h7djb" to be "success or failure"
Dec  5 21:01:18.723: INFO: Pod "downwardapi-volume-e95eb243-f8d0-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 8.885749ms
Dec  5 21:01:20.733: INFO: Pod "downwardapi-volume-e95eb243-f8d0-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018510322s
Dec  5 21:01:22.746: INFO: Pod "downwardapi-volume-e95eb243-f8d0-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03178222s
STEP: Saw pod success
Dec  5 21:01:22.746: INFO: Pod "downwardapi-volume-e95eb243-f8d0-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:01:22.755: INFO: Trying to get logs from node 10.191.0.150 pod downwardapi-volume-e95eb243-f8d0-11e8-b962-c6dde3e93636 container client-container: <nil>
STEP: delete the pod
Dec  5 21:01:22.860: INFO: Waiting for pod downwardapi-volume-e95eb243-f8d0-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:01:22.870: INFO: Pod downwardapi-volume-e95eb243-f8d0-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:01:22.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-h7djb" for this suite.
Dec  5 21:01:28.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:01:29.119: INFO: namespace: e2e-tests-downward-api-h7djb, resource: bindings, ignored listing per whitelist
Dec  5 21:01:29.383: INFO: namespace e2e-tests-downward-api-h7djb deletion completed in 6.499391406s

• [SLOW TEST:11.022 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:01:29.384: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-nd5pl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1205 21:02:00.371058      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  5 21:02:00.371: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:02:00.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-nd5pl" for this suite.
Dec  5 21:02:06.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:02:06.771: INFO: namespace: e2e-tests-gc-nd5pl, resource: bindings, ignored listing per whitelist
Dec  5 21:02:06.853: INFO: namespace e2e-tests-gc-nd5pl deletion completed in 6.465957709s

• [SLOW TEST:37.470 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:02:06.854: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-wkzd7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Dec  5 21:02:07.757: INFO: Waiting up to 5m0s for pod "pod-service-account-0697c66b-f8d1-11e8-b962-c6dde3e93636-jvvtl" in namespace "e2e-tests-svcaccounts-wkzd7" to be "success or failure"
Dec  5 21:02:07.765: INFO: Pod "pod-service-account-0697c66b-f8d1-11e8-b962-c6dde3e93636-jvvtl": Phase="Pending", Reason="", readiness=false. Elapsed: 8.396327ms
Dec  5 21:02:09.778: INFO: Pod "pod-service-account-0697c66b-f8d1-11e8-b962-c6dde3e93636-jvvtl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021145246s
Dec  5 21:02:11.802: INFO: Pod "pod-service-account-0697c66b-f8d1-11e8-b962-c6dde3e93636-jvvtl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045102375s
STEP: Saw pod success
Dec  5 21:02:11.802: INFO: Pod "pod-service-account-0697c66b-f8d1-11e8-b962-c6dde3e93636-jvvtl" satisfied condition "success or failure"
Dec  5 21:02:11.814: INFO: Trying to get logs from node 10.191.0.150 pod pod-service-account-0697c66b-f8d1-11e8-b962-c6dde3e93636-jvvtl container token-test: <nil>
STEP: delete the pod
Dec  5 21:02:11.936: INFO: Waiting for pod pod-service-account-0697c66b-f8d1-11e8-b962-c6dde3e93636-jvvtl to disappear
Dec  5 21:02:11.943: INFO: Pod pod-service-account-0697c66b-f8d1-11e8-b962-c6dde3e93636-jvvtl no longer exists
STEP: Creating a pod to test consume service account root CA
Dec  5 21:02:11.954: INFO: Waiting up to 5m0s for pod "pod-service-account-0697c66b-f8d1-11e8-b962-c6dde3e93636-drbhs" in namespace "e2e-tests-svcaccounts-wkzd7" to be "success or failure"
Dec  5 21:02:11.963: INFO: Pod "pod-service-account-0697c66b-f8d1-11e8-b962-c6dde3e93636-drbhs": Phase="Pending", Reason="", readiness=false. Elapsed: 8.082572ms
Dec  5 21:02:13.975: INFO: Pod "pod-service-account-0697c66b-f8d1-11e8-b962-c6dde3e93636-drbhs": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020343211s
Dec  5 21:02:15.984: INFO: Pod "pod-service-account-0697c66b-f8d1-11e8-b962-c6dde3e93636-drbhs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029777837s
STEP: Saw pod success
Dec  5 21:02:15.984: INFO: Pod "pod-service-account-0697c66b-f8d1-11e8-b962-c6dde3e93636-drbhs" satisfied condition "success or failure"
Dec  5 21:02:15.992: INFO: Trying to get logs from node 10.191.0.150 pod pod-service-account-0697c66b-f8d1-11e8-b962-c6dde3e93636-drbhs container root-ca-test: <nil>
STEP: delete the pod
Dec  5 21:02:16.043: INFO: Waiting for pod pod-service-account-0697c66b-f8d1-11e8-b962-c6dde3e93636-drbhs to disappear
Dec  5 21:02:16.053: INFO: Pod pod-service-account-0697c66b-f8d1-11e8-b962-c6dde3e93636-drbhs no longer exists
STEP: Creating a pod to test consume service account namespace
Dec  5 21:02:16.063: INFO: Waiting up to 5m0s for pod "pod-service-account-0697c66b-f8d1-11e8-b962-c6dde3e93636-tdj5x" in namespace "e2e-tests-svcaccounts-wkzd7" to be "success or failure"
Dec  5 21:02:16.074: INFO: Pod "pod-service-account-0697c66b-f8d1-11e8-b962-c6dde3e93636-tdj5x": Phase="Pending", Reason="", readiness=false. Elapsed: 10.640223ms
Dec  5 21:02:18.084: INFO: Pod "pod-service-account-0697c66b-f8d1-11e8-b962-c6dde3e93636-tdj5x": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020659231s
Dec  5 21:02:20.093: INFO: Pod "pod-service-account-0697c66b-f8d1-11e8-b962-c6dde3e93636-tdj5x": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029116971s
STEP: Saw pod success
Dec  5 21:02:20.093: INFO: Pod "pod-service-account-0697c66b-f8d1-11e8-b962-c6dde3e93636-tdj5x" satisfied condition "success or failure"
Dec  5 21:02:20.100: INFO: Trying to get logs from node 10.191.0.150 pod pod-service-account-0697c66b-f8d1-11e8-b962-c6dde3e93636-tdj5x container namespace-test: <nil>
STEP: delete the pod
Dec  5 21:02:20.154: INFO: Waiting for pod pod-service-account-0697c66b-f8d1-11e8-b962-c6dde3e93636-tdj5x to disappear
Dec  5 21:02:20.164: INFO: Pod pod-service-account-0697c66b-f8d1-11e8-b962-c6dde3e93636-tdj5x no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:02:20.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-wkzd7" for this suite.
Dec  5 21:02:28.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:02:28.491: INFO: namespace: e2e-tests-svcaccounts-wkzd7, resource: bindings, ignored listing per whitelist
Dec  5 21:02:28.722: INFO: namespace e2e-tests-svcaccounts-wkzd7 deletion completed in 8.485890782s

• [SLOW TEST:21.868 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:02:28.723: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-dk2gm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  5 21:02:29.074: INFO: PodSpec: initContainers in spec.initContainers
Dec  5 21:03:16.425: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-1351437d-f8d1-11e8-b962-c6dde3e93636", GenerateName:"", Namespace:"e2e-tests-init-container-dk2gm", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-dk2gm/pods/pod-init-1351437d-f8d1-11e8-b962-c6dde3e93636", UID:"13527518-f8d1-11e8-9151-427614c96c42", ResourceVersion:"9282", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63679640549, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"74629854"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-mql4g", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc42127e700), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-mql4g", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-mql4g", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-mql4g", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc422033328), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.191.0.150", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc421c8a060), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4220333b0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4220333d0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc4220333d8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679640549, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679640549, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679640549, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679640549, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.191.0.150", PodIP:"172.30.248.104", StartTime:(*v1.Time)(0xc421074a80), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc421c697a0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc421c69810)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:2a03a6059f21e150ae84b0973863609494aad70f0a80eaeb64bddd8d92465812", ContainerID:"containerd://e15fa4261e476357e43f9bfda82b12bd8af02b9a353b1ef2725507e34a055015"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc421074b20), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc421074ae0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:03:16.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-dk2gm" for this suite.
Dec  5 21:03:40.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:03:40.806: INFO: namespace: e2e-tests-init-container-dk2gm, resource: bindings, ignored listing per whitelist
Dec  5 21:03:40.948: INFO: namespace e2e-tests-init-container-dk2gm deletion completed in 24.489168653s

• [SLOW TEST:72.225 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:03:40.948: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-k96xb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 21:03:41.408: INFO: (0) /api/v1/nodes/10.191.0.134/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 93.00941ms)
Dec  5 21:03:41.423: INFO: (1) /api/v1/nodes/10.191.0.134/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.105936ms)
Dec  5 21:03:41.440: INFO: (2) /api/v1/nodes/10.191.0.134/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 16.592494ms)
Dec  5 21:03:41.460: INFO: (3) /api/v1/nodes/10.191.0.134/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 20.218338ms)
Dec  5 21:03:41.475: INFO: (4) /api/v1/nodes/10.191.0.134/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.987538ms)
Dec  5 21:03:41.535: INFO: (5) /api/v1/nodes/10.191.0.134/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 60.343868ms)
Dec  5 21:03:41.550: INFO: (6) /api/v1/nodes/10.191.0.134/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.80631ms)
Dec  5 21:03:41.564: INFO: (7) /api/v1/nodes/10.191.0.134/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.383473ms)
Dec  5 21:03:41.583: INFO: (8) /api/v1/nodes/10.191.0.134/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 19.171973ms)
Dec  5 21:03:41.599: INFO: (9) /api/v1/nodes/10.191.0.134/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 16.083224ms)
Dec  5 21:03:41.613: INFO: (10) /api/v1/nodes/10.191.0.134/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.674533ms)
Dec  5 21:03:41.628: INFO: (11) /api/v1/nodes/10.191.0.134/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.430699ms)
Dec  5 21:03:41.644: INFO: (12) /api/v1/nodes/10.191.0.134/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.211744ms)
Dec  5 21:03:41.662: INFO: (13) /api/v1/nodes/10.191.0.134/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 18.291614ms)
Dec  5 21:03:41.684: INFO: (14) /api/v1/nodes/10.191.0.134/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 22.19632ms)
Dec  5 21:03:41.698: INFO: (15) /api/v1/nodes/10.191.0.134/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.163363ms)
Dec  5 21:03:41.717: INFO: (16) /api/v1/nodes/10.191.0.134/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 18.433092ms)
Dec  5 21:03:41.735: INFO: (17) /api/v1/nodes/10.191.0.134/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 17.767466ms)
Dec  5 21:03:41.751: INFO: (18) /api/v1/nodes/10.191.0.134/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.778523ms)
Dec  5 21:03:41.767: INFO: (19) /api/v1/nodes/10.191.0.134/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 16.520671ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:03:41.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-k96xb" for this suite.
Dec  5 21:03:47.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:03:47.894: INFO: namespace: e2e-tests-proxy-k96xb, resource: bindings, ignored listing per whitelist
Dec  5 21:03:48.254: INFO: namespace e2e-tests-proxy-k96xb deletion completed in 6.473452263s

• [SLOW TEST:7.306 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:03:48.255: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-nwj8r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Dec  5 21:03:48.594: INFO: Waiting up to 5m0s for pod "client-containers-42b43d84-f8d1-11e8-b962-c6dde3e93636" in namespace "e2e-tests-containers-nwj8r" to be "success or failure"
Dec  5 21:03:48.621: INFO: Pod "client-containers-42b43d84-f8d1-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 26.74799ms
Dec  5 21:03:50.629: INFO: Pod "client-containers-42b43d84-f8d1-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035267004s
Dec  5 21:03:52.639: INFO: Pod "client-containers-42b43d84-f8d1-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044693423s
STEP: Saw pod success
Dec  5 21:03:52.639: INFO: Pod "client-containers-42b43d84-f8d1-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:03:52.649: INFO: Trying to get logs from node 10.191.0.150 pod client-containers-42b43d84-f8d1-11e8-b962-c6dde3e93636 container test-container: <nil>
STEP: delete the pod
Dec  5 21:03:52.711: INFO: Waiting for pod client-containers-42b43d84-f8d1-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:03:52.720: INFO: Pod client-containers-42b43d84-f8d1-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:03:52.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-nwj8r" for this suite.
Dec  5 21:03:58.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:03:59.051: INFO: namespace: e2e-tests-containers-nwj8r, resource: bindings, ignored listing per whitelist
Dec  5 21:03:59.239: INFO: namespace e2e-tests-containers-nwj8r deletion completed in 6.49453888s

• [SLOW TEST:10.984 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:03:59.239: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-xq829
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  5 21:03:59.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-xq829'
Dec  5 21:03:59.695: INFO: stderr: ""
Dec  5 21:03:59.695: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Dec  5 21:04:04.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-xq829 -o json'
Dec  5 21:04:04.907: INFO: stderr: ""
Dec  5 21:04:04.907: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2018-12-05T21:03:59Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-xq829\",\n        \"resourceVersion\": \"9481\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-xq829/pods/e2e-test-nginx-pod\",\n        \"uid\": \"49525b8a-f8d1-11e8-bcf8-b20187c1163a\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-9vfb9\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"10.191.0.150\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-9vfb9\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-9vfb9\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-05T21:03:59Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-05T21:04:01Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-05T21:04:01Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-05T21:03:59Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://c01abd68641bcf7f05a02b37d6b4fd287dc743b9d5f711e9d2a1a5700a6b29c7\",\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imageID\": \"docker.io/library/nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2018-12-05T21:04:00Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.191.0.150\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.248.106\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2018-12-05T21:03:59Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec  5 21:04:04.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 replace -f - --namespace=e2e-tests-kubectl-xq829'
Dec  5 21:04:05.151: INFO: stderr: ""
Dec  5 21:04:05.151: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Dec  5 21:04:05.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-xq829'
Dec  5 21:04:07.624: INFO: stderr: ""
Dec  5 21:04:07.624: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:04:07.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xq829" for this suite.
Dec  5 21:04:13.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:04:14.012: INFO: namespace: e2e-tests-kubectl-xq829, resource: bindings, ignored listing per whitelist
Dec  5 21:04:14.117: INFO: namespace e2e-tests-kubectl-xq829 deletion completed in 6.480029553s

• [SLOW TEST:14.878 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:04:14.117: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-l4s6l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Dec  5 21:04:14.443: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-794602807 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:04:14.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-l4s6l" for this suite.
Dec  5 21:04:20.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:04:20.758: INFO: namespace: e2e-tests-kubectl-l4s6l, resource: bindings, ignored listing per whitelist
Dec  5 21:04:20.922: INFO: namespace e2e-tests-kubectl-l4s6l deletion completed in 6.341862772s

• [SLOW TEST:6.805 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:04:20.922: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-2svfw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-2svfw
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  5 21:04:21.233: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  5 21:04:41.527: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.30.46.141 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-2svfw PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 21:04:41.527: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
Dec  5 21:04:42.721: INFO: Found all expected endpoints: [netserver-0]
Dec  5 21:04:42.733: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.30.110.12 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-2svfw PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 21:04:42.733: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
Dec  5 21:04:43.916: INFO: Found all expected endpoints: [netserver-1]
Dec  5 21:04:43.926: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.30.248.107 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-2svfw PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 21:04:43.926: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
Dec  5 21:04:45.166: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:04:45.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-2svfw" for this suite.
Dec  5 21:05:09.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:05:09.421: INFO: namespace: e2e-tests-pod-network-test-2svfw, resource: bindings, ignored listing per whitelist
Dec  5 21:05:09.656: INFO: namespace e2e-tests-pod-network-test-2svfw deletion completed in 24.420287701s

• [SLOW TEST:48.734 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:05:09.656: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-bm6v9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  5 21:05:09.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-bm6v9'
Dec  5 21:05:10.150: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec  5 21:05:10.150: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Dec  5 21:05:12.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-bm6v9'
Dec  5 21:05:12.413: INFO: stderr: ""
Dec  5 21:05:12.413: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:05:12.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bm6v9" for this suite.
Dec  5 21:05:18.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:05:18.989: INFO: namespace: e2e-tests-kubectl-bm6v9, resource: bindings, ignored listing per whitelist
Dec  5 21:05:19.009: INFO: namespace e2e-tests-kubectl-bm6v9 deletion completed in 6.573250773s

• [SLOW TEST:9.353 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:05:19.009: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-5hqjx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  5 21:05:19.456: INFO: Waiting up to 5m0s for pod "downward-api-78dc60fc-f8d1-11e8-b962-c6dde3e93636" in namespace "e2e-tests-downward-api-5hqjx" to be "success or failure"
Dec  5 21:05:19.464: INFO: Pod "downward-api-78dc60fc-f8d1-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 7.930698ms
Dec  5 21:05:21.474: INFO: Pod "downward-api-78dc60fc-f8d1-11e8-b962-c6dde3e93636": Phase="Running", Reason="", readiness=true. Elapsed: 2.017605238s
Dec  5 21:05:23.488: INFO: Pod "downward-api-78dc60fc-f8d1-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031557976s
STEP: Saw pod success
Dec  5 21:05:23.488: INFO: Pod "downward-api-78dc60fc-f8d1-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:05:23.495: INFO: Trying to get logs from node 10.191.0.150 pod downward-api-78dc60fc-f8d1-11e8-b962-c6dde3e93636 container dapi-container: <nil>
STEP: delete the pod
Dec  5 21:05:23.551: INFO: Waiting for pod downward-api-78dc60fc-f8d1-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:05:23.561: INFO: Pod downward-api-78dc60fc-f8d1-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:05:23.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5hqjx" for this suite.
Dec  5 21:05:29.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:05:29.741: INFO: namespace: e2e-tests-downward-api-5hqjx, resource: bindings, ignored listing per whitelist
Dec  5 21:05:30.089: INFO: namespace e2e-tests-downward-api-5hqjx deletion completed in 6.515503959s

• [SLOW TEST:11.080 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:05:30.090: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-8xl2d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  5 21:05:30.511: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:05:32.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-8xl2d" for this suite.
Dec  5 21:05:38.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:05:39.185: INFO: namespace: e2e-tests-init-container-8xl2d, resource: bindings, ignored listing per whitelist
Dec  5 21:05:39.318: INFO: namespace e2e-tests-init-container-8xl2d deletion completed in 6.574890372s

• [SLOW TEST:9.229 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:05:39.321: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-8vxvb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  5 21:05:39.629: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:05:43.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-8vxvb" for this suite.
Dec  5 21:05:49.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:05:49.969: INFO: namespace: e2e-tests-init-container-8vxvb, resource: bindings, ignored listing per whitelist
Dec  5 21:05:50.256: INFO: namespace e2e-tests-init-container-8vxvb deletion completed in 6.484161573s

• [SLOW TEST:10.935 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:05:50.256: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-52wtt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 21:05:50.607: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec  5 21:05:55.616: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  5 21:05:55.616: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  5 21:05:55.695: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-52wtt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-52wtt/deployments/test-cleanup-deployment,UID:8e705e3f-f8d1-11e8-9151-427614c96c42,ResourceVersion:10035,Generation:1,CreationTimestamp:2018-12-05 21:05:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Dec  5 21:05:55.706: INFO: New ReplicaSet "test-cleanup-deployment-755f6b95cc" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-755f6b95cc,GenerateName:,Namespace:e2e-tests-deployment-52wtt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-52wtt/replicasets/test-cleanup-deployment-755f6b95cc,UID:8e774e53-f8d1-11e8-bcf8-b20187c1163a,ResourceVersion:10037,Generation:1,CreationTimestamp:2018-12-05 21:05:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 8e705e3f-f8d1-11e8-9151-427614c96c42 0xc420be1027 0xc420be1028}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  5 21:05:55.706: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Dec  5 21:05:55.706: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-52wtt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-52wtt/replicasets/test-cleanup-controller,UID:8b6d852b-f8d1-11e8-9151-427614c96c42,ResourceVersion:10036,Generation:1,CreationTimestamp:2018-12-05 21:05:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 8e705e3f-f8d1-11e8-9151-427614c96c42 0xc420be0f67 0xc420be0f68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  5 21:05:55.737: INFO: Pod "test-cleanup-controller-rf7rm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-rf7rm,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-52wtt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52wtt/pods/test-cleanup-controller-rf7rm,UID:8bb1ec38-f8d1-11e8-bcf8-b20187c1163a,ResourceVersion:10030,Generation:0,CreationTimestamp:2018-12-05 21:05:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 8b6d852b-f8d1-11e8-9151-427614c96c42 0xc421b20757 0xc421b20758}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-d6v4n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d6v4n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d6v4n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.0.150,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421b207d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421b207f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 21:05:51 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 21:05:52 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 21:05:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 21:05:51 +0000 UTC  }],Message:,Reason:,HostIP:10.191.0.150,PodIP:172.30.248.115,StartTime:2018-12-05 21:05:51 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-05 21:05:52 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd containerd://217b202d8fdfcdf0c32ba2559e231526f7bf64ea3cada05eb5d00d2da85e9e9d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 21:05:55.737: INFO: Pod "test-cleanup-deployment-755f6b95cc-ffnc2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-755f6b95cc-ffnc2,GenerateName:test-cleanup-deployment-755f6b95cc-,Namespace:e2e-tests-deployment-52wtt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52wtt/pods/test-cleanup-deployment-755f6b95cc-ffnc2,UID:8e78baa1-f8d1-11e8-bcf8-b20187c1163a,ResourceVersion:10039,Generation:0,CreationTimestamp:2018-12-05 21:05:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-755f6b95cc 8e774e53-f8d1-11e8-bcf8-b20187c1163a 0xc421b208d7 0xc421b208d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-d6v4n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d6v4n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-d6v4n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421b20940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421b20960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:05:55.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-52wtt" for this suite.
Dec  5 21:06:01.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:06:02.160: INFO: namespace: e2e-tests-deployment-52wtt, resource: bindings, ignored listing per whitelist
Dec  5 21:06:02.409: INFO: namespace e2e-tests-deployment-52wtt deletion completed in 6.592248837s

• [SLOW TEST:12.153 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:06:02.411: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-cf4dr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 21:06:02.836: INFO: Waiting up to 5m0s for pod "downwardapi-volume-92b6d181-f8d1-11e8-b962-c6dde3e93636" in namespace "e2e-tests-downward-api-cf4dr" to be "success or failure"
Dec  5 21:06:02.856: INFO: Pod "downwardapi-volume-92b6d181-f8d1-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 19.756093ms
Dec  5 21:06:04.865: INFO: Pod "downwardapi-volume-92b6d181-f8d1-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027981282s
Dec  5 21:06:06.875: INFO: Pod "downwardapi-volume-92b6d181-f8d1-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03874412s
STEP: Saw pod success
Dec  5 21:06:06.876: INFO: Pod "downwardapi-volume-92b6d181-f8d1-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:06:06.885: INFO: Trying to get logs from node 10.191.0.150 pod downwardapi-volume-92b6d181-f8d1-11e8-b962-c6dde3e93636 container client-container: <nil>
STEP: delete the pod
Dec  5 21:06:06.941: INFO: Waiting for pod downwardapi-volume-92b6d181-f8d1-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:06:06.953: INFO: Pod downwardapi-volume-92b6d181-f8d1-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:06:06.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cf4dr" for this suite.
Dec  5 21:06:13.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:06:13.316: INFO: namespace: e2e-tests-downward-api-cf4dr, resource: bindings, ignored listing per whitelist
Dec  5 21:06:13.497: INFO: namespace e2e-tests-downward-api-cf4dr deletion completed in 6.527355235s

• [SLOW TEST:11.086 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:06:13.497: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-d2z77
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-9948586e-f8d1-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume configMaps
Dec  5 21:06:13.857: INFO: Waiting up to 5m0s for pod "pod-configmaps-9949c769-f8d1-11e8-b962-c6dde3e93636" in namespace "e2e-tests-configmap-d2z77" to be "success or failure"
Dec  5 21:06:13.936: INFO: Pod "pod-configmaps-9949c769-f8d1-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 78.621779ms
Dec  5 21:06:15.949: INFO: Pod "pod-configmaps-9949c769-f8d1-11e8-b962-c6dde3e93636": Phase="Running", Reason="", readiness=true. Elapsed: 2.091677668s
Dec  5 21:06:17.959: INFO: Pod "pod-configmaps-9949c769-f8d1-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.102497183s
STEP: Saw pod success
Dec  5 21:06:17.959: INFO: Pod "pod-configmaps-9949c769-f8d1-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:06:17.968: INFO: Trying to get logs from node 10.191.0.150 pod pod-configmaps-9949c769-f8d1-11e8-b962-c6dde3e93636 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 21:06:18.036: INFO: Waiting for pod pod-configmaps-9949c769-f8d1-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:06:18.047: INFO: Pod pod-configmaps-9949c769-f8d1-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:06:18.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-d2z77" for this suite.
Dec  5 21:06:24.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:06:24.437: INFO: namespace: e2e-tests-configmap-d2z77, resource: bindings, ignored listing per whitelist
Dec  5 21:06:24.596: INFO: namespace e2e-tests-configmap-d2z77 deletion completed in 6.447309965s

• [SLOW TEST:11.099 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:06:24.597: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-qt57r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  5 21:06:24.941: INFO: Waiting up to 5m0s for pod "pod-9fe51b1b-f8d1-11e8-b962-c6dde3e93636" in namespace "e2e-tests-emptydir-qt57r" to be "success or failure"
Dec  5 21:06:24.952: INFO: Pod "pod-9fe51b1b-f8d1-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 10.829706ms
Dec  5 21:06:26.962: INFO: Pod "pod-9fe51b1b-f8d1-11e8-b962-c6dde3e93636": Phase="Running", Reason="", readiness=true. Elapsed: 2.020828147s
Dec  5 21:06:28.970: INFO: Pod "pod-9fe51b1b-f8d1-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029037313s
STEP: Saw pod success
Dec  5 21:06:28.970: INFO: Pod "pod-9fe51b1b-f8d1-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:06:28.979: INFO: Trying to get logs from node 10.191.0.150 pod pod-9fe51b1b-f8d1-11e8-b962-c6dde3e93636 container test-container: <nil>
STEP: delete the pod
Dec  5 21:06:29.030: INFO: Waiting for pod pod-9fe51b1b-f8d1-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:06:29.039: INFO: Pod pod-9fe51b1b-f8d1-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:06:29.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qt57r" for this suite.
Dec  5 21:06:35.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:06:35.453: INFO: namespace: e2e-tests-emptydir-qt57r, resource: bindings, ignored listing per whitelist
Dec  5 21:06:35.484: INFO: namespace e2e-tests-emptydir-qt57r deletion completed in 6.430219803s

• [SLOW TEST:10.887 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:06:35.484: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-78c2h
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-a6638433-f8d1-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume secrets
Dec  5 21:06:35.867: INFO: Waiting up to 5m0s for pod "pod-secrets-a667aee7-f8d1-11e8-b962-c6dde3e93636" in namespace "e2e-tests-secrets-78c2h" to be "success or failure"
Dec  5 21:06:35.875: INFO: Pod "pod-secrets-a667aee7-f8d1-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 7.591334ms
Dec  5 21:06:37.887: INFO: Pod "pod-secrets-a667aee7-f8d1-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020393723s
STEP: Saw pod success
Dec  5 21:06:37.887: INFO: Pod "pod-secrets-a667aee7-f8d1-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:06:37.900: INFO: Trying to get logs from node 10.191.0.150 pod pod-secrets-a667aee7-f8d1-11e8-b962-c6dde3e93636 container secret-env-test: <nil>
STEP: delete the pod
Dec  5 21:06:37.960: INFO: Waiting for pod pod-secrets-a667aee7-f8d1-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:06:37.973: INFO: Pod pod-secrets-a667aee7-f8d1-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:06:37.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-78c2h" for this suite.
Dec  5 21:06:44.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:06:44.197: INFO: namespace: e2e-tests-secrets-78c2h, resource: bindings, ignored listing per whitelist
Dec  5 21:06:44.503: INFO: namespace e2e-tests-secrets-78c2h deletion completed in 6.51620202s

• [SLOW TEST:9.019 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:06:44.504: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-lx5bx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 21:06:44.822: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec  5 21:06:44.840: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec  5 21:06:49.863: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  5 21:06:49.863: INFO: Creating deployment "test-rolling-update-deployment"
Dec  5 21:06:49.873: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec  5 21:06:49.891: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec  5 21:06:51.908: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec  5 21:06:51.914: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  5 21:06:51.946: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-lx5bx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lx5bx/deployments/test-rolling-update-deployment,UID:aec2cbad-f8d1-11e8-9151-427614c96c42,ResourceVersion:10386,Generation:1,CreationTimestamp:2018-12-05 21:06:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-05 21:06:49 +0000 UTC 2018-12-05 21:06:49 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-05 21:06:51 +0000 UTC 2018-12-05 21:06:49 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec  5 21:06:51.957: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-lx5bx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lx5bx/replicasets/test-rolling-update-deployment-65b7695dcf,UID:aeca3458-f8d1-11e8-bcf8-b20187c1163a,ResourceVersion:10377,Generation:1,CreationTimestamp:2018-12-05 21:06:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment aec2cbad-f8d1-11e8-9151-427614c96c42 0xc4213f2267 0xc4213f2268}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  5 21:06:51.957: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec  5 21:06:51.957: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-lx5bx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lx5bx/replicasets/test-rolling-update-controller,UID:abc19812-f8d1-11e8-9151-427614c96c42,ResourceVersion:10385,Generation:2,CreationTimestamp:2018-12-05 21:06:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment aec2cbad-f8d1-11e8-9151-427614c96c42 0xc4213f219e 0xc4213f219f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  5 21:06:52.047: INFO: Pod "test-rolling-update-deployment-65b7695dcf-xxzpt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-xxzpt,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-lx5bx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lx5bx/pods/test-rolling-update-deployment-65b7695dcf-xxzpt,UID:aecbdf52-f8d1-11e8-bcf8-b20187c1163a,ResourceVersion:10376,Generation:0,CreationTimestamp:2018-12-05 21:06:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf aeca3458-f8d1-11e8-bcf8-b20187c1163a 0xc4213f2f77 0xc4213f2f78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-774vt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-774vt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-774vt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.0.150,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4213f2ff0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4213f3010}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 21:06:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 21:06:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 21:06:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 21:06:49 +0000 UTC  }],Message:,Reason:,HostIP:10.191.0.150,PodIP:172.30.248.122,StartTime:2018-12-05 21:06:49 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-05 21:06:51 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://09ca495e65e7d446a59ca3cfd7c66dab48010e0998edbefb86b84f5edd790856}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:06:52.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-lx5bx" for this suite.
Dec  5 21:06:58.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:06:58.333: INFO: namespace: e2e-tests-deployment-lx5bx, resource: bindings, ignored listing per whitelist
Dec  5 21:06:58.453: INFO: namespace e2e-tests-deployment-lx5bx deletion completed in 6.392870633s

• [SLOW TEST:13.949 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:06:58.454: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-9wlxc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-9wlxc.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-9wlxc.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-9wlxc.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-9wlxc.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-9wlxc.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-9wlxc.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  5 21:07:27.209: INFO: DNS probes using e2e-tests-dns-9wlxc/dns-test-b41373fd-f8d1-11e8-b962-c6dde3e93636 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:07:27.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-9wlxc" for this suite.
Dec  5 21:07:33.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:07:33.539: INFO: namespace: e2e-tests-dns-9wlxc, resource: bindings, ignored listing per whitelist
Dec  5 21:07:33.739: INFO: namespace e2e-tests-dns-9wlxc deletion completed in 6.480787076s

• [SLOW TEST:35.285 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:07:33.740: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-45xgw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  5 21:07:34.196: INFO: Number of nodes with available pods: 0
Dec  5 21:07:34.196: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:07:35.234: INFO: Number of nodes with available pods: 0
Dec  5 21:07:35.234: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:07:36.245: INFO: Number of nodes with available pods: 0
Dec  5 21:07:36.245: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:07:37.247: INFO: Number of nodes with available pods: 1
Dec  5 21:07:37.247: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:07:38.220: INFO: Number of nodes with available pods: 2
Dec  5 21:07:38.220: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:07:39.219: INFO: Number of nodes with available pods: 3
Dec  5 21:07:39.219: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec  5 21:07:39.277: INFO: Number of nodes with available pods: 2
Dec  5 21:07:39.277: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 21:07:40.344: INFO: Number of nodes with available pods: 3
Dec  5 21:07:40.344: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-45xgw, will wait for the garbage collector to delete the pods
Dec  5 21:07:40.446: INFO: Deleting {extensions DaemonSet} daemon-set took: 25.496716ms
Dec  5 21:07:40.546: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.269782ms
Dec  5 21:08:19.780: INFO: Number of nodes with available pods: 0
Dec  5 21:08:19.780: INFO: Number of running nodes: 0, number of available pods: 0
Dec  5 21:08:19.791: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-45xgw/daemonsets","resourceVersion":"10723"},"items":null}

Dec  5 21:08:19.799: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-45xgw/pods","resourceVersion":"10723"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:08:19.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-45xgw" for this suite.
Dec  5 21:08:27.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:08:28.400: INFO: namespace: e2e-tests-daemonsets-45xgw, resource: bindings, ignored listing per whitelist
Dec  5 21:08:28.456: INFO: namespace e2e-tests-daemonsets-45xgw deletion completed in 8.557454838s

• [SLOW TEST:54.716 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:08:28.457: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-zgrhg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Dec  5 21:08:28.835: INFO: Waiting up to 5m0s for pod "var-expansion-e9bbb94f-f8d1-11e8-b962-c6dde3e93636" in namespace "e2e-tests-var-expansion-zgrhg" to be "success or failure"
Dec  5 21:08:28.844: INFO: Pod "var-expansion-e9bbb94f-f8d1-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 9.029244ms
Dec  5 21:08:30.870: INFO: Pod "var-expansion-e9bbb94f-f8d1-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034730055s
STEP: Saw pod success
Dec  5 21:08:30.870: INFO: Pod "var-expansion-e9bbb94f-f8d1-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:08:30.878: INFO: Trying to get logs from node 10.191.0.150 pod var-expansion-e9bbb94f-f8d1-11e8-b962-c6dde3e93636 container dapi-container: <nil>
STEP: delete the pod
Dec  5 21:08:30.937: INFO: Waiting for pod var-expansion-e9bbb94f-f8d1-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:08:30.948: INFO: Pod var-expansion-e9bbb94f-f8d1-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:08:30.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-zgrhg" for this suite.
Dec  5 21:08:37.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:08:37.221: INFO: namespace: e2e-tests-var-expansion-zgrhg, resource: bindings, ignored listing per whitelist
Dec  5 21:08:37.403: INFO: namespace e2e-tests-var-expansion-zgrhg deletion completed in 6.437210261s

• [SLOW TEST:8.946 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:08:37.404: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-vsxj5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  5 21:08:43.953: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  5 21:08:43.965: INFO: Pod pod-with-poststart-http-hook still exists
Dec  5 21:08:45.965: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  5 21:08:45.976: INFO: Pod pod-with-poststart-http-hook still exists
Dec  5 21:08:47.965: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  5 21:08:47.976: INFO: Pod pod-with-poststart-http-hook still exists
Dec  5 21:08:49.965: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  5 21:08:49.976: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:08:49.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-vsxj5" for this suite.
Dec  5 21:09:14.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:09:14.398: INFO: namespace: e2e-tests-container-lifecycle-hook-vsxj5, resource: bindings, ignored listing per whitelist
Dec  5 21:09:14.470: INFO: namespace e2e-tests-container-lifecycle-hook-vsxj5 deletion completed in 24.480794455s

• [SLOW TEST:37.067 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:09:14.470: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-dvspj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-w4qw
STEP: Creating a pod to test atomic-volume-subpath
Dec  5 21:09:14.879: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-w4qw" in namespace "e2e-tests-subpath-dvspj" to be "success or failure"
Dec  5 21:09:14.886: INFO: Pod "pod-subpath-test-configmap-w4qw": Phase="Pending", Reason="", readiness=false. Elapsed: 7.334328ms
Dec  5 21:09:16.895: INFO: Pod "pod-subpath-test-configmap-w4qw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015940584s
Dec  5 21:09:18.910: INFO: Pod "pod-subpath-test-configmap-w4qw": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031751874s
Dec  5 21:09:20.919: INFO: Pod "pod-subpath-test-configmap-w4qw": Phase="Pending", Reason="", readiness=false. Elapsed: 6.040249266s
Dec  5 21:09:22.930: INFO: Pod "pod-subpath-test-configmap-w4qw": Phase="Running", Reason="", readiness=false. Elapsed: 8.051021362s
Dec  5 21:09:24.957: INFO: Pod "pod-subpath-test-configmap-w4qw": Phase="Running", Reason="", readiness=false. Elapsed: 10.077885221s
Dec  5 21:09:26.967: INFO: Pod "pod-subpath-test-configmap-w4qw": Phase="Running", Reason="", readiness=false. Elapsed: 12.08868435s
Dec  5 21:09:28.976: INFO: Pod "pod-subpath-test-configmap-w4qw": Phase="Running", Reason="", readiness=false. Elapsed: 14.097747121s
Dec  5 21:09:30.988: INFO: Pod "pod-subpath-test-configmap-w4qw": Phase="Running", Reason="", readiness=false. Elapsed: 16.109014754s
Dec  5 21:09:33.000: INFO: Pod "pod-subpath-test-configmap-w4qw": Phase="Running", Reason="", readiness=false. Elapsed: 18.121764869s
Dec  5 21:09:35.022: INFO: Pod "pod-subpath-test-configmap-w4qw": Phase="Running", Reason="", readiness=false. Elapsed: 20.142903058s
Dec  5 21:09:37.043: INFO: Pod "pod-subpath-test-configmap-w4qw": Phase="Running", Reason="", readiness=false. Elapsed: 22.164139565s
Dec  5 21:09:39.052: INFO: Pod "pod-subpath-test-configmap-w4qw": Phase="Running", Reason="", readiness=false. Elapsed: 24.173323875s
Dec  5 21:09:41.062: INFO: Pod "pod-subpath-test-configmap-w4qw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.183509409s
STEP: Saw pod success
Dec  5 21:09:41.062: INFO: Pod "pod-subpath-test-configmap-w4qw" satisfied condition "success or failure"
Dec  5 21:09:41.071: INFO: Trying to get logs from node 10.191.0.147 pod pod-subpath-test-configmap-w4qw container test-container-subpath-configmap-w4qw: <nil>
STEP: delete the pod
Dec  5 21:09:41.204: INFO: Waiting for pod pod-subpath-test-configmap-w4qw to disappear
Dec  5 21:09:41.216: INFO: Pod pod-subpath-test-configmap-w4qw no longer exists
STEP: Deleting pod pod-subpath-test-configmap-w4qw
Dec  5 21:09:41.216: INFO: Deleting pod "pod-subpath-test-configmap-w4qw" in namespace "e2e-tests-subpath-dvspj"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:09:41.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-dvspj" for this suite.
Dec  5 21:09:47.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:09:47.687: INFO: namespace: e2e-tests-subpath-dvspj, resource: bindings, ignored listing per whitelist
Dec  5 21:09:47.720: INFO: namespace e2e-tests-subpath-dvspj deletion completed in 6.471855412s

• [SLOW TEST:33.249 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:09:47.720: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-kdpx8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec  5 21:09:48.133: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-kdpx8,SelfLink:/api/v1/namespaces/e2e-tests-watch-kdpx8/configmaps/e2e-watch-test-configmap-a,UID:19032bb8-f8d2-11e8-9151-427614c96c42,ResourceVersion:11102,Generation:0,CreationTimestamp:2018-12-05 21:09:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  5 21:09:48.133: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-kdpx8,SelfLink:/api/v1/namespaces/e2e-tests-watch-kdpx8/configmaps/e2e-watch-test-configmap-a,UID:19032bb8-f8d2-11e8-9151-427614c96c42,ResourceVersion:11102,Generation:0,CreationTimestamp:2018-12-05 21:09:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec  5 21:09:58.166: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-kdpx8,SelfLink:/api/v1/namespaces/e2e-tests-watch-kdpx8/configmaps/e2e-watch-test-configmap-a,UID:19032bb8-f8d2-11e8-9151-427614c96c42,ResourceVersion:11118,Generation:0,CreationTimestamp:2018-12-05 21:09:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  5 21:09:58.166: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-kdpx8,SelfLink:/api/v1/namespaces/e2e-tests-watch-kdpx8/configmaps/e2e-watch-test-configmap-a,UID:19032bb8-f8d2-11e8-9151-427614c96c42,ResourceVersion:11118,Generation:0,CreationTimestamp:2018-12-05 21:09:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec  5 21:10:08.208: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-kdpx8,SelfLink:/api/v1/namespaces/e2e-tests-watch-kdpx8/configmaps/e2e-watch-test-configmap-a,UID:19032bb8-f8d2-11e8-9151-427614c96c42,ResourceVersion:11135,Generation:0,CreationTimestamp:2018-12-05 21:09:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  5 21:10:08.208: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-kdpx8,SelfLink:/api/v1/namespaces/e2e-tests-watch-kdpx8/configmaps/e2e-watch-test-configmap-a,UID:19032bb8-f8d2-11e8-9151-427614c96c42,ResourceVersion:11135,Generation:0,CreationTimestamp:2018-12-05 21:09:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec  5 21:10:18.245: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-kdpx8,SelfLink:/api/v1/namespaces/e2e-tests-watch-kdpx8/configmaps/e2e-watch-test-configmap-a,UID:19032bb8-f8d2-11e8-9151-427614c96c42,ResourceVersion:11152,Generation:0,CreationTimestamp:2018-12-05 21:09:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  5 21:10:18.245: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-kdpx8,SelfLink:/api/v1/namespaces/e2e-tests-watch-kdpx8/configmaps/e2e-watch-test-configmap-a,UID:19032bb8-f8d2-11e8-9151-427614c96c42,ResourceVersion:11152,Generation:0,CreationTimestamp:2018-12-05 21:09:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec  5 21:10:28.276: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-kdpx8,SelfLink:/api/v1/namespaces/e2e-tests-watch-kdpx8/configmaps/e2e-watch-test-configmap-b,UID:30ef6a13-f8d2-11e8-9151-427614c96c42,ResourceVersion:11169,Generation:0,CreationTimestamp:2018-12-05 21:10:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  5 21:10:28.276: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-kdpx8,SelfLink:/api/v1/namespaces/e2e-tests-watch-kdpx8/configmaps/e2e-watch-test-configmap-b,UID:30ef6a13-f8d2-11e8-9151-427614c96c42,ResourceVersion:11169,Generation:0,CreationTimestamp:2018-12-05 21:10:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec  5 21:10:38.324: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-kdpx8,SelfLink:/api/v1/namespaces/e2e-tests-watch-kdpx8/configmaps/e2e-watch-test-configmap-b,UID:30ef6a13-f8d2-11e8-9151-427614c96c42,ResourceVersion:11186,Generation:0,CreationTimestamp:2018-12-05 21:10:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  5 21:10:38.324: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-kdpx8,SelfLink:/api/v1/namespaces/e2e-tests-watch-kdpx8/configmaps/e2e-watch-test-configmap-b,UID:30ef6a13-f8d2-11e8-9151-427614c96c42,ResourceVersion:11186,Generation:0,CreationTimestamp:2018-12-05 21:10:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:10:48.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-kdpx8" for this suite.
Dec  5 21:10:54.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:10:54.685: INFO: namespace: e2e-tests-watch-kdpx8, resource: bindings, ignored listing per whitelist
Dec  5 21:10:54.901: INFO: namespace e2e-tests-watch-kdpx8 deletion completed in 6.550844005s

• [SLOW TEST:67.181 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:10:54.902: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-cj828
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-pdk8
STEP: Creating a pod to test atomic-volume-subpath
Dec  5 21:10:55.261: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-pdk8" in namespace "e2e-tests-subpath-cj828" to be "success or failure"
Dec  5 21:10:55.270: INFO: Pod "pod-subpath-test-configmap-pdk8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.075753ms
Dec  5 21:10:57.282: INFO: Pod "pod-subpath-test-configmap-pdk8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021489508s
Dec  5 21:10:59.306: INFO: Pod "pod-subpath-test-configmap-pdk8": Phase="Running", Reason="", readiness=false. Elapsed: 4.04478186s
Dec  5 21:11:01.316: INFO: Pod "pod-subpath-test-configmap-pdk8": Phase="Running", Reason="", readiness=false. Elapsed: 6.054767673s
Dec  5 21:11:03.326: INFO: Pod "pod-subpath-test-configmap-pdk8": Phase="Running", Reason="", readiness=false. Elapsed: 8.065039883s
Dec  5 21:11:05.338: INFO: Pod "pod-subpath-test-configmap-pdk8": Phase="Running", Reason="", readiness=false. Elapsed: 10.077423606s
Dec  5 21:11:07.349: INFO: Pod "pod-subpath-test-configmap-pdk8": Phase="Running", Reason="", readiness=false. Elapsed: 12.088301367s
Dec  5 21:11:09.371: INFO: Pod "pod-subpath-test-configmap-pdk8": Phase="Running", Reason="", readiness=false. Elapsed: 14.110468383s
Dec  5 21:11:11.380: INFO: Pod "pod-subpath-test-configmap-pdk8": Phase="Running", Reason="", readiness=false. Elapsed: 16.119035768s
Dec  5 21:11:13.390: INFO: Pod "pod-subpath-test-configmap-pdk8": Phase="Running", Reason="", readiness=false. Elapsed: 18.129253336s
Dec  5 21:11:15.403: INFO: Pod "pod-subpath-test-configmap-pdk8": Phase="Running", Reason="", readiness=false. Elapsed: 20.141801318s
Dec  5 21:11:17.411: INFO: Pod "pod-subpath-test-configmap-pdk8": Phase="Running", Reason="", readiness=false. Elapsed: 22.149827409s
Dec  5 21:11:19.434: INFO: Pod "pod-subpath-test-configmap-pdk8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.173003254s
STEP: Saw pod success
Dec  5 21:11:19.434: INFO: Pod "pod-subpath-test-configmap-pdk8" satisfied condition "success or failure"
Dec  5 21:11:19.444: INFO: Trying to get logs from node 10.191.0.150 pod pod-subpath-test-configmap-pdk8 container test-container-subpath-configmap-pdk8: <nil>
STEP: delete the pod
Dec  5 21:11:19.502: INFO: Waiting for pod pod-subpath-test-configmap-pdk8 to disappear
Dec  5 21:11:19.535: INFO: Pod pod-subpath-test-configmap-pdk8 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-pdk8
Dec  5 21:11:19.535: INFO: Deleting pod "pod-subpath-test-configmap-pdk8" in namespace "e2e-tests-subpath-cj828"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:11:19.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-cj828" for this suite.
Dec  5 21:11:25.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:11:25.892: INFO: namespace: e2e-tests-subpath-cj828, resource: bindings, ignored listing per whitelist
Dec  5 21:11:26.007: INFO: namespace e2e-tests-subpath-cj828 deletion completed in 6.451754541s

• [SLOW TEST:31.105 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:11:26.008: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-bw6lx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-bw6lx/configmap-test-538eb60d-f8d2-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume configMaps
Dec  5 21:11:26.376: INFO: Waiting up to 5m0s for pod "pod-configmaps-53905a10-f8d2-11e8-b962-c6dde3e93636" in namespace "e2e-tests-configmap-bw6lx" to be "success or failure"
Dec  5 21:11:26.387: INFO: Pod "pod-configmaps-53905a10-f8d2-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 10.737843ms
Dec  5 21:11:28.396: INFO: Pod "pod-configmaps-53905a10-f8d2-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019784975s
STEP: Saw pod success
Dec  5 21:11:28.396: INFO: Pod "pod-configmaps-53905a10-f8d2-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:11:28.404: INFO: Trying to get logs from node 10.191.0.150 pod pod-configmaps-53905a10-f8d2-11e8-b962-c6dde3e93636 container env-test: <nil>
STEP: delete the pod
Dec  5 21:11:28.466: INFO: Waiting for pod pod-configmaps-53905a10-f8d2-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:11:28.475: INFO: Pod pod-configmaps-53905a10-f8d2-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:11:28.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-bw6lx" for this suite.
Dec  5 21:11:34.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:11:35.000: INFO: namespace: e2e-tests-configmap-bw6lx, resource: bindings, ignored listing per whitelist
Dec  5 21:11:35.035: INFO: namespace e2e-tests-configmap-bw6lx deletion completed in 6.548782944s

• [SLOW TEST:9.028 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:11:35.035: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-gwrjd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:11:35.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-gwrjd" for this suite.
Dec  5 21:11:59.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:11:59.536: INFO: namespace: e2e-tests-pods-gwrjd, resource: bindings, ignored listing per whitelist
Dec  5 21:11:59.776: INFO: namespace e2e-tests-pods-gwrjd deletion completed in 24.384999754s

• [SLOW TEST:24.741 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:11:59.777: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-mvn94
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec  5 21:12:00.128: INFO: Waiting up to 5m0s for pod "pod-67ae164c-f8d2-11e8-b962-c6dde3e93636" in namespace "e2e-tests-emptydir-mvn94" to be "success or failure"
Dec  5 21:12:00.138: INFO: Pod "pod-67ae164c-f8d2-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 9.335348ms
Dec  5 21:12:02.150: INFO: Pod "pod-67ae164c-f8d2-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021900092s
STEP: Saw pod success
Dec  5 21:12:02.150: INFO: Pod "pod-67ae164c-f8d2-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:12:02.161: INFO: Trying to get logs from node 10.191.0.150 pod pod-67ae164c-f8d2-11e8-b962-c6dde3e93636 container test-container: <nil>
STEP: delete the pod
Dec  5 21:12:02.236: INFO: Waiting for pod pod-67ae164c-f8d2-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:12:02.244: INFO: Pod pod-67ae164c-f8d2-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:12:02.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mvn94" for this suite.
Dec  5 21:12:08.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:12:08.352: INFO: namespace: e2e-tests-emptydir-mvn94, resource: bindings, ignored listing per whitelist
Dec  5 21:12:08.754: INFO: namespace e2e-tests-emptydir-mvn94 deletion completed in 6.495843475s

• [SLOW TEST:8.977 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:12:08.758: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-q6wkq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-6d0647d5-f8d2-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume configMaps
Dec  5 21:12:09.171: INFO: Waiting up to 5m0s for pod "pod-configmaps-6d116380-f8d2-11e8-b962-c6dde3e93636" in namespace "e2e-tests-configmap-q6wkq" to be "success or failure"
Dec  5 21:12:09.193: INFO: Pod "pod-configmaps-6d116380-f8d2-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 22.732976ms
Dec  5 21:12:11.211: INFO: Pod "pod-configmaps-6d116380-f8d2-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.039912416s
STEP: Saw pod success
Dec  5 21:12:11.211: INFO: Pod "pod-configmaps-6d116380-f8d2-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:12:11.220: INFO: Trying to get logs from node 10.191.0.150 pod pod-configmaps-6d116380-f8d2-11e8-b962-c6dde3e93636 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 21:12:11.287: INFO: Waiting for pod pod-configmaps-6d116380-f8d2-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:12:11.297: INFO: Pod pod-configmaps-6d116380-f8d2-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:12:11.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-q6wkq" for this suite.
Dec  5 21:12:17.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:12:17.852: INFO: namespace: e2e-tests-configmap-q6wkq, resource: bindings, ignored listing per whitelist
Dec  5 21:12:17.888: INFO: namespace e2e-tests-configmap-q6wkq deletion completed in 6.576455286s

• [SLOW TEST:9.130 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:12:17.889: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-4dvpn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-4dvpn/configmap-test-727b05ce-f8d2-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume configMaps
Dec  5 21:12:18.263: INFO: Waiting up to 5m0s for pod "pod-configmaps-727dc496-f8d2-11e8-b962-c6dde3e93636" in namespace "e2e-tests-configmap-4dvpn" to be "success or failure"
Dec  5 21:12:18.274: INFO: Pod "pod-configmaps-727dc496-f8d2-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 11.081183ms
Dec  5 21:12:20.284: INFO: Pod "pod-configmaps-727dc496-f8d2-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020733034s
STEP: Saw pod success
Dec  5 21:12:20.284: INFO: Pod "pod-configmaps-727dc496-f8d2-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:12:20.291: INFO: Trying to get logs from node 10.191.0.150 pod pod-configmaps-727dc496-f8d2-11e8-b962-c6dde3e93636 container env-test: <nil>
STEP: delete the pod
Dec  5 21:12:20.367: INFO: Waiting for pod pod-configmaps-727dc496-f8d2-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:12:20.378: INFO: Pod pod-configmaps-727dc496-f8d2-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:12:20.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4dvpn" for this suite.
Dec  5 21:12:26.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:12:26.672: INFO: namespace: e2e-tests-configmap-4dvpn, resource: bindings, ignored listing per whitelist
Dec  5 21:12:26.827: INFO: namespace e2e-tests-configmap-4dvpn deletion completed in 6.43408683s

• [SLOW TEST:8.938 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:12:26.828: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-w4bqm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-77cab869-f8d2-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume configMaps
Dec  5 21:12:27.171: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-77cc9076-f8d2-11e8-b962-c6dde3e93636" in namespace "e2e-tests-projected-w4bqm" to be "success or failure"
Dec  5 21:12:27.182: INFO: Pod "pod-projected-configmaps-77cc9076-f8d2-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 11.438514ms
Dec  5 21:12:29.193: INFO: Pod "pod-projected-configmaps-77cc9076-f8d2-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022163016s
STEP: Saw pod success
Dec  5 21:12:29.193: INFO: Pod "pod-projected-configmaps-77cc9076-f8d2-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:12:29.202: INFO: Trying to get logs from node 10.191.0.150 pod pod-projected-configmaps-77cc9076-f8d2-11e8-b962-c6dde3e93636 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 21:12:29.267: INFO: Waiting for pod pod-projected-configmaps-77cc9076-f8d2-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:12:29.344: INFO: Pod pod-projected-configmaps-77cc9076-f8d2-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:12:29.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-w4bqm" for this suite.
Dec  5 21:12:35.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:12:35.587: INFO: namespace: e2e-tests-projected-w4bqm, resource: bindings, ignored listing per whitelist
Dec  5 21:12:35.804: INFO: namespace e2e-tests-projected-w4bqm deletion completed in 6.448901024s

• [SLOW TEST:8.976 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:12:35.806: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-4lbpl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Dec  5 21:12:36.698: INFO: created pod pod-service-account-defaultsa
Dec  5 21:12:36.698: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec  5 21:12:36.708: INFO: created pod pod-service-account-mountsa
Dec  5 21:12:36.708: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec  5 21:12:36.722: INFO: created pod pod-service-account-nomountsa
Dec  5 21:12:36.723: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec  5 21:12:36.738: INFO: created pod pod-service-account-defaultsa-mountspec
Dec  5 21:12:36.738: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec  5 21:12:36.760: INFO: created pod pod-service-account-mountsa-mountspec
Dec  5 21:12:36.760: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec  5 21:12:36.774: INFO: created pod pod-service-account-nomountsa-mountspec
Dec  5 21:12:36.774: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec  5 21:12:36.786: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec  5 21:12:36.786: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec  5 21:12:36.802: INFO: created pod pod-service-account-mountsa-nomountspec
Dec  5 21:12:36.802: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec  5 21:12:36.816: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec  5 21:12:36.816: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:12:36.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-4lbpl" for this suite.
Dec  5 21:12:42.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:12:43.092: INFO: namespace: e2e-tests-svcaccounts-4lbpl, resource: bindings, ignored listing per whitelist
Dec  5 21:12:43.238: INFO: namespace e2e-tests-svcaccounts-4lbpl deletion completed in 6.409635785s

• [SLOW TEST:7.432 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:12:43.240: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-jkj8l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  5 21:12:49.697: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 21:12:49.706: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 21:12:51.706: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 21:12:51.715: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 21:12:53.707: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 21:12:53.718: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 21:12:55.706: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 21:12:55.715: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 21:12:57.706: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 21:12:57.730: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 21:12:59.706: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 21:12:59.716: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 21:13:01.706: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 21:13:01.718: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 21:13:03.706: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 21:13:03.715: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 21:13:05.706: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 21:13:05.720: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 21:13:07.706: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 21:13:07.716: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 21:13:09.706: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 21:13:09.733: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 21:13:11.706: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 21:13:11.735: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 21:13:13.706: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 21:13:13.716: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 21:13:15.706: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 21:13:15.716: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 21:13:17.706: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 21:13:17.716: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 21:13:19.706: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 21:13:19.715: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 21:13:21.706: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 21:13:21.730: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:13:21.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-jkj8l" for this suite.
Dec  5 21:13:45.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:13:45.997: INFO: namespace: e2e-tests-container-lifecycle-hook-jkj8l, resource: bindings, ignored listing per whitelist
Dec  5 21:13:46.172: INFO: namespace e2e-tests-container-lifecycle-hook-jkj8l deletion completed in 24.427489821s

• [SLOW TEST:62.932 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:13:46.174: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-s79mw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  5 21:13:46.522: INFO: Waiting up to 5m0s for pod "downward-api-a7190628-f8d2-11e8-b962-c6dde3e93636" in namespace "e2e-tests-downward-api-s79mw" to be "success or failure"
Dec  5 21:13:46.532: INFO: Pod "downward-api-a7190628-f8d2-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 10.150651ms
Dec  5 21:13:48.543: INFO: Pod "downward-api-a7190628-f8d2-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021192979s
STEP: Saw pod success
Dec  5 21:13:48.543: INFO: Pod "downward-api-a7190628-f8d2-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:13:48.552: INFO: Trying to get logs from node 10.191.0.150 pod downward-api-a7190628-f8d2-11e8-b962-c6dde3e93636 container dapi-container: <nil>
STEP: delete the pod
Dec  5 21:13:48.620: INFO: Waiting for pod downward-api-a7190628-f8d2-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:13:48.630: INFO: Pod downward-api-a7190628-f8d2-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:13:48.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-s79mw" for this suite.
Dec  5 21:13:54.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:13:55.011: INFO: namespace: e2e-tests-downward-api-s79mw, resource: bindings, ignored listing per whitelist
Dec  5 21:13:55.126: INFO: namespace e2e-tests-downward-api-s79mw deletion completed in 6.482176582s

• [SLOW TEST:8.952 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:13:55.126: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-9nxfv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-ac74fb4c-f8d2-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume secrets
Dec  5 21:13:55.576: INFO: Waiting up to 5m0s for pod "pod-secrets-ac7e9314-f8d2-11e8-b962-c6dde3e93636" in namespace "e2e-tests-secrets-9nxfv" to be "success or failure"
Dec  5 21:13:55.587: INFO: Pod "pod-secrets-ac7e9314-f8d2-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 11.548822ms
Dec  5 21:13:57.595: INFO: Pod "pod-secrets-ac7e9314-f8d2-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019713467s
STEP: Saw pod success
Dec  5 21:13:57.595: INFO: Pod "pod-secrets-ac7e9314-f8d2-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:13:57.603: INFO: Trying to get logs from node 10.191.0.150 pod pod-secrets-ac7e9314-f8d2-11e8-b962-c6dde3e93636 container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 21:13:57.658: INFO: Waiting for pod pod-secrets-ac7e9314-f8d2-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:13:57.666: INFO: Pod pod-secrets-ac7e9314-f8d2-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:13:57.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9nxfv" for this suite.
Dec  5 21:14:03.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:14:03.889: INFO: namespace: e2e-tests-secrets-9nxfv, resource: bindings, ignored listing per whitelist
Dec  5 21:14:04.250: INFO: namespace e2e-tests-secrets-9nxfv deletion completed in 6.560780394s

• [SLOW TEST:9.124 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:14:04.252: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-jhchm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-b1e0d351-f8d2-11e8-b962-c6dde3e93636
STEP: Creating secret with name s-test-opt-upd-b1e0d48d-f8d2-11e8-b962-c6dde3e93636
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-b1e0d351-f8d2-11e8-b962-c6dde3e93636
STEP: Updating secret s-test-opt-upd-b1e0d48d-f8d2-11e8-b962-c6dde3e93636
STEP: Creating secret with name s-test-opt-create-b1e0d4af-f8d2-11e8-b962-c6dde3e93636
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:14:10.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jhchm" for this suite.
Dec  5 21:14:34.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:14:35.021: INFO: namespace: e2e-tests-projected-jhchm, resource: bindings, ignored listing per whitelist
Dec  5 21:14:35.282: INFO: namespace e2e-tests-projected-jhchm deletion completed in 24.325655286s

• [SLOW TEST:31.031 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:14:35.284: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-w647n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  5 21:14:39.823: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  5 21:14:39.835: INFO: Pod pod-with-prestop-http-hook still exists
Dec  5 21:14:41.836: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  5 21:14:41.846: INFO: Pod pod-with-prestop-http-hook still exists
Dec  5 21:14:43.836: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  5 21:14:43.849: INFO: Pod pod-with-prestop-http-hook still exists
Dec  5 21:14:45.836: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  5 21:14:45.844: INFO: Pod pod-with-prestop-http-hook still exists
Dec  5 21:14:47.836: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  5 21:14:47.844: INFO: Pod pod-with-prestop-http-hook still exists
Dec  5 21:14:49.836: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  5 21:14:49.860: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:14:49.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-w647n" for this suite.
Dec  5 21:15:13.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:15:14.346: INFO: namespace: e2e-tests-container-lifecycle-hook-w647n, resource: bindings, ignored listing per whitelist
Dec  5 21:15:14.488: INFO: namespace e2e-tests-container-lifecycle-hook-w647n deletion completed in 24.597653687s

• [SLOW TEST:39.205 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:15:14.490: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-zs84r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  5 21:15:14.979: INFO: Waiting up to 5m0s for pod "pod-dbd2992b-f8d2-11e8-b962-c6dde3e93636" in namespace "e2e-tests-emptydir-zs84r" to be "success or failure"
Dec  5 21:15:14.992: INFO: Pod "pod-dbd2992b-f8d2-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 12.231978ms
Dec  5 21:15:17.043: INFO: Pod "pod-dbd2992b-f8d2-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.06388813s
STEP: Saw pod success
Dec  5 21:15:17.043: INFO: Pod "pod-dbd2992b-f8d2-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:15:17.053: INFO: Trying to get logs from node 10.191.0.150 pod pod-dbd2992b-f8d2-11e8-b962-c6dde3e93636 container test-container: <nil>
STEP: delete the pod
Dec  5 21:15:17.109: INFO: Waiting for pod pod-dbd2992b-f8d2-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:15:17.118: INFO: Pod pod-dbd2992b-f8d2-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:15:17.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-zs84r" for this suite.
Dec  5 21:15:23.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:15:23.360: INFO: namespace: e2e-tests-emptydir-zs84r, resource: bindings, ignored listing per whitelist
Dec  5 21:15:23.596: INFO: namespace e2e-tests-emptydir-zs84r deletion completed in 6.462356915s

• [SLOW TEST:9.106 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:15:23.599: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-6k5kc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:16:23.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-6k5kc" for this suite.
Dec  5 21:16:48.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:16:48.165: INFO: namespace: e2e-tests-container-probe-6k5kc, resource: bindings, ignored listing per whitelist
Dec  5 21:16:48.421: INFO: namespace e2e-tests-container-probe-6k5kc deletion completed in 24.455292919s

• [SLOW TEST:84.823 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:16:48.422: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-98fdh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:16:48.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-98fdh" for this suite.
Dec  5 21:16:54.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:16:54.989: INFO: namespace: e2e-tests-services-98fdh, resource: bindings, ignored listing per whitelist
Dec  5 21:16:55.173: INFO: namespace e2e-tests-services-98fdh deletion completed in 6.388240668s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.751 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:16:55.175: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-8m7hg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-17c15138-f8d3-11e8-b962-c6dde3e93636
STEP: Creating secret with name secret-projected-all-test-volume-17c15115-f8d3-11e8-b962-c6dde3e93636
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec  5 21:16:55.554: INFO: Waiting up to 5m0s for pod "projected-volume-17c150d4-f8d3-11e8-b962-c6dde3e93636" in namespace "e2e-tests-projected-8m7hg" to be "success or failure"
Dec  5 21:16:55.564: INFO: Pod "projected-volume-17c150d4-f8d3-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 10.084724ms
Dec  5 21:16:57.575: INFO: Pod "projected-volume-17c150d4-f8d3-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020733893s
STEP: Saw pod success
Dec  5 21:16:57.575: INFO: Pod "projected-volume-17c150d4-f8d3-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:16:57.584: INFO: Trying to get logs from node 10.191.0.150 pod projected-volume-17c150d4-f8d3-11e8-b962-c6dde3e93636 container projected-all-volume-test: <nil>
STEP: delete the pod
Dec  5 21:16:57.632: INFO: Waiting for pod projected-volume-17c150d4-f8d3-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:16:57.644: INFO: Pod projected-volume-17c150d4-f8d3-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:16:57.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8m7hg" for this suite.
Dec  5 21:17:03.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:17:03.964: INFO: namespace: e2e-tests-projected-8m7hg, resource: bindings, ignored listing per whitelist
Dec  5 21:17:04.077: INFO: namespace e2e-tests-projected-8m7hg deletion completed in 6.418528087s

• [SLOW TEST:8.902 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:17:04.079: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-ghcb9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 21:17:04.453: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec  5 21:17:04.475: INFO: Number of nodes with available pods: 0
Dec  5 21:17:04.476: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec  5 21:17:04.524: INFO: Number of nodes with available pods: 0
Dec  5 21:17:04.524: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:05.532: INFO: Number of nodes with available pods: 0
Dec  5 21:17:05.532: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:06.535: INFO: Number of nodes with available pods: 1
Dec  5 21:17:06.535: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec  5 21:17:06.597: INFO: Number of nodes with available pods: 1
Dec  5 21:17:06.597: INFO: Number of running nodes: 0, number of available pods: 1
Dec  5 21:17:07.608: INFO: Number of nodes with available pods: 0
Dec  5 21:17:07.608: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec  5 21:17:07.635: INFO: Number of nodes with available pods: 0
Dec  5 21:17:07.636: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:08.645: INFO: Number of nodes with available pods: 0
Dec  5 21:17:08.645: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:09.648: INFO: Number of nodes with available pods: 0
Dec  5 21:17:09.648: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:10.660: INFO: Number of nodes with available pods: 0
Dec  5 21:17:10.660: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:11.661: INFO: Number of nodes with available pods: 0
Dec  5 21:17:11.661: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:12.648: INFO: Number of nodes with available pods: 0
Dec  5 21:17:12.648: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:13.645: INFO: Number of nodes with available pods: 0
Dec  5 21:17:13.645: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:14.645: INFO: Number of nodes with available pods: 0
Dec  5 21:17:14.645: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:15.644: INFO: Number of nodes with available pods: 0
Dec  5 21:17:15.644: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:16.645: INFO: Number of nodes with available pods: 0
Dec  5 21:17:16.645: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:17.648: INFO: Number of nodes with available pods: 0
Dec  5 21:17:17.648: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:18.654: INFO: Number of nodes with available pods: 0
Dec  5 21:17:18.654: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:19.645: INFO: Number of nodes with available pods: 0
Dec  5 21:17:19.645: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:20.645: INFO: Number of nodes with available pods: 0
Dec  5 21:17:20.645: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:21.660: INFO: Number of nodes with available pods: 0
Dec  5 21:17:21.660: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:22.644: INFO: Number of nodes with available pods: 0
Dec  5 21:17:22.644: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:23.644: INFO: Number of nodes with available pods: 0
Dec  5 21:17:23.645: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:24.647: INFO: Number of nodes with available pods: 0
Dec  5 21:17:24.647: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:25.647: INFO: Number of nodes with available pods: 0
Dec  5 21:17:25.647: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:26.646: INFO: Number of nodes with available pods: 0
Dec  5 21:17:26.646: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:27.645: INFO: Number of nodes with available pods: 0
Dec  5 21:17:27.645: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:28.646: INFO: Number of nodes with available pods: 0
Dec  5 21:17:28.646: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:29.647: INFO: Number of nodes with available pods: 0
Dec  5 21:17:29.647: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:30.645: INFO: Number of nodes with available pods: 0
Dec  5 21:17:30.645: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:31.647: INFO: Number of nodes with available pods: 0
Dec  5 21:17:31.647: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:32.657: INFO: Number of nodes with available pods: 0
Dec  5 21:17:32.657: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:33.644: INFO: Number of nodes with available pods: 0
Dec  5 21:17:33.644: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:34.648: INFO: Number of nodes with available pods: 0
Dec  5 21:17:34.648: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:35.644: INFO: Number of nodes with available pods: 0
Dec  5 21:17:35.644: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:36.643: INFO: Number of nodes with available pods: 0
Dec  5 21:17:36.643: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:37.645: INFO: Number of nodes with available pods: 0
Dec  5 21:17:37.645: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:38.646: INFO: Number of nodes with available pods: 0
Dec  5 21:17:38.646: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:39.645: INFO: Number of nodes with available pods: 0
Dec  5 21:17:39.645: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:40.646: INFO: Number of nodes with available pods: 0
Dec  5 21:17:40.646: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:41.646: INFO: Number of nodes with available pods: 0
Dec  5 21:17:41.646: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:42.645: INFO: Number of nodes with available pods: 0
Dec  5 21:17:42.645: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:43.659: INFO: Number of nodes with available pods: 0
Dec  5 21:17:43.659: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:44.645: INFO: Number of nodes with available pods: 0
Dec  5 21:17:44.645: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:45.646: INFO: Number of nodes with available pods: 0
Dec  5 21:17:45.646: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:17:46.647: INFO: Number of nodes with available pods: 1
Dec  5 21:17:46.647: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-ghcb9, will wait for the garbage collector to delete the pods
Dec  5 21:17:46.810: INFO: Deleting {extensions DaemonSet} daemon-set took: 24.116323ms
Dec  5 21:17:46.910: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.207395ms
Dec  5 21:18:25.036: INFO: Number of nodes with available pods: 0
Dec  5 21:18:25.036: INFO: Number of running nodes: 0, number of available pods: 0
Dec  5 21:18:25.051: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-ghcb9/daemonsets","resourceVersion":"12892"},"items":null}

Dec  5 21:18:25.060: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-ghcb9/pods","resourceVersion":"12892"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:18:25.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-ghcb9" for this suite.
Dec  5 21:18:31.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:18:31.345: INFO: namespace: e2e-tests-daemonsets-ghcb9, resource: bindings, ignored listing per whitelist
Dec  5 21:18:31.580: INFO: namespace e2e-tests-daemonsets-ghcb9 deletion completed in 6.446696627s

• [SLOW TEST:87.501 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:18:31.580: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-z7mwr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  5 21:18:31.916: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:18:35.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-z7mwr" for this suite.
Dec  5 21:18:59.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:18:59.997: INFO: namespace: e2e-tests-init-container-z7mwr, resource: bindings, ignored listing per whitelist
Dec  5 21:19:00.027: INFO: namespace e2e-tests-init-container-z7mwr deletion completed in 24.591537152s

• [SLOW TEST:28.448 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:19:00.028: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-9f9sl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  5 21:19:00.460: INFO: Waiting up to 5m0s for pod "downward-api-62380736-f8d3-11e8-b962-c6dde3e93636" in namespace "e2e-tests-downward-api-9f9sl" to be "success or failure"
Dec  5 21:19:00.469: INFO: Pod "downward-api-62380736-f8d3-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 8.948546ms
Dec  5 21:19:02.479: INFO: Pod "downward-api-62380736-f8d3-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018542549s
Dec  5 21:19:04.488: INFO: Pod "downward-api-62380736-f8d3-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028199694s
STEP: Saw pod success
Dec  5 21:19:04.488: INFO: Pod "downward-api-62380736-f8d3-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:19:04.498: INFO: Trying to get logs from node 10.191.0.150 pod downward-api-62380736-f8d3-11e8-b962-c6dde3e93636 container dapi-container: <nil>
STEP: delete the pod
Dec  5 21:19:04.553: INFO: Waiting for pod downward-api-62380736-f8d3-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:19:04.561: INFO: Pod downward-api-62380736-f8d3-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:19:04.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9f9sl" for this suite.
Dec  5 21:19:10.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:19:10.831: INFO: namespace: e2e-tests-downward-api-9f9sl, resource: bindings, ignored listing per whitelist
Dec  5 21:19:11.146: INFO: namespace e2e-tests-downward-api-9f9sl deletion completed in 6.572528457s

• [SLOW TEST:11.118 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:19:11.148: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-st2ml
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 21:19:11.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 version --client'
Dec  5 21:19:11.692: INFO: stderr: ""
Dec  5 21:19:11.692: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Dec  5 21:19:11.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 create -f - --namespace=e2e-tests-kubectl-st2ml'
Dec  5 21:19:12.216: INFO: stderr: ""
Dec  5 21:19:12.216: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec  5 21:19:12.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 create -f - --namespace=e2e-tests-kubectl-st2ml'
Dec  5 21:19:12.524: INFO: stderr: ""
Dec  5 21:19:12.524: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  5 21:19:13.533: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 21:19:13.533: INFO: Found 1 / 1
Dec  5 21:19:13.533: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  5 21:19:13.544: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 21:19:13.544: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  5 21:19:13.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 describe pod redis-master-vjsc4 --namespace=e2e-tests-kubectl-st2ml'
Dec  5 21:19:13.742: INFO: stderr: ""
Dec  5 21:19:13.742: INFO: stdout: "Name:               redis-master-vjsc4\nNamespace:          e2e-tests-kubectl-st2ml\nPriority:           0\nPriorityClassName:  <none>\nNode:               10.191.0.150/10.191.0.150\nStart Time:         Wed, 05 Dec 2018 21:19:12 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        kubernetes.io/psp: e2e-test-privileged-psp\nStatus:             Running\nIP:                 172.30.248.94\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://1bb9371619f168dcc65d4baa5ba335135d36a7861c4684ed65e6dc888d41c9ef\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 05 Dec 2018 21:19:13 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-g5g6b (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-g5g6b:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-g5g6b\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                   Message\n  ----    ------     ----  ----                   -------\n  Normal  Scheduled  1s    default-scheduler      Successfully assigned e2e-tests-kubectl-st2ml/redis-master-vjsc4 to 10.191.0.150\n  Normal  Pulled     0s    kubelet, 10.191.0.150  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    0s    kubelet, 10.191.0.150  Created container\n  Normal  Started    0s    kubelet, 10.191.0.150  Started container\n"
Dec  5 21:19:13.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 describe rc redis-master --namespace=e2e-tests-kubectl-st2ml'
Dec  5 21:19:13.937: INFO: stderr: ""
Dec  5 21:19:13.937: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-st2ml\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  1s    replication-controller  Created pod: redis-master-vjsc4\n"
Dec  5 21:19:13.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 describe service redis-master --namespace=e2e-tests-kubectl-st2ml'
Dec  5 21:19:14.121: INFO: stderr: ""
Dec  5 21:19:14.121: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-st2ml\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.21.150.67\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.30.248.94:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec  5 21:19:14.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 describe node 10.191.0.134'
Dec  5 21:19:14.385: INFO: stderr: ""
Dec  5 21:19:14.386: INFO: stdout: "Name:               10.191.0.134\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=u2c.2x4.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-east\n                    failure-domain.beta.kubernetes.io/zone=wdc07\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/machine-type=u2c.2x4.encrypted\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-pool-id=13c0509290e4443aab67bdb06ca2f6df-7d0b149\n                    ibm-cloud.kubernetes.io/worker-version=1.12.3_1531\n                    kubernetes.io/hostname=10.191.0.134\n                    privateVLAN=2501449\n                    publicVLAN=2501447\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 05 Dec 2018 20:13:25 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Wed, 05 Dec 2018 21:19:09 +0000   Wed, 05 Dec 2018 20:13:25 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Wed, 05 Dec 2018 21:19:09 +0000   Wed, 05 Dec 2018 20:13:25 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 05 Dec 2018 21:19:09 +0000   Wed, 05 Dec 2018 20:13:25 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 05 Dec 2018 21:19:09 +0000   Wed, 05 Dec 2018 20:13:25 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 05 Dec 2018 21:19:09 +0000   Wed, 05 Dec 2018 20:13:55 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.191.0.134\n  ExternalIP:  169.61.96.51\n  Hostname:    10.191.0.134\nCapacity:\n cpu:                2\n ephemeral-storage:  103079200Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             4041608Ki\n pods:               110\nAllocatable:\n cpu:                1920m\n ephemeral-storage:  100275445682\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             3535752Ki\n pods:               110\nSystem Info:\n Machine ID:                 266c2075dace453da02500b328c9e325\n System UUID:                36404141-E2F9-E17A-4437-29499AAE229E\n Boot ID:                    31d13d7a-9bb4-44e1-8a45-53b2e023af51\n Kernel Version:             4.4.0-139-generic\n OS Image:                   Ubuntu 16.04.5 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.1.5\n Kubelet Version:            v1.12.3+IKS\n Kube-Proxy Version:         v1.12.3+IKS\nProviderID:                  ibm://d18c889395112a40d2f4e3065f237a7d///13c0509290e4443aab67bdb06ca2f6df/kube-wdc07-cr13c0509290e4443aab67bdb06ca2f6df-w3\nNon-terminated Pods:         (13 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-9347e99d64a449f0-2fct4    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                calico-kube-controllers-5c699798bc-szf68                   10m (0%)      0 (0%)      25Mi (0%)        0 (0%)\n  kube-system                calico-node-hjfvw                                          255m (13%)    0 (0%)      85Mi (2%)        0 (0%)\n  kube-system                ibm-file-plugin-66d9565b46-pmd5k                           50m (2%)      200m (10%)  100Mi (2%)       0 (0%)\n  kube-system                ibm-keepalived-watcher-c8gfz                               5m (0%)       0 (0%)      10Mi (0%)        0 (0%)\n  kube-system                ibm-kube-fluentd-kszbp                                     25m (1%)      300m (15%)  50Mi (1%)        800M (22%)\n  kube-system                ibm-master-proxy-static-10.191.0.134                       25m (1%)      300m (15%)  32M (0%)         512M (14%)\n  kube-system                ibm-storage-watcher-d7fb6f996-sw7ft                        50m (2%)      200m (10%)  100Mi (2%)       0 (0%)\n  kube-system                kube-dns-amd64-fddfcc69-drvmh                              260m (13%)    0 (0%)      110Mi (3%)       170Mi (4%)\n  kube-system                kube-dns-amd64-fddfcc69-ph96f                              260m (13%)    0 (0%)      110Mi (3%)       170Mi (4%)\n  kube-system                kube-dns-autoscaler-587cd5cd44-wtn48                       20m (1%)      0 (0%)      10Mi (0%)        0 (0%)\n  kube-system                kubernetes-dashboard-b6b5cbdb4-n88tm                       50m (2%)      0 (0%)      100Mi (2%)       0 (0%)\n  kube-system                vpn-65599665d9-g4r5v                                       5m (0%)       0 (0%)      5Mi (0%)         0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource  Requests        Limits\n  --------  --------        ------\n  cpu       1015m (52%)     1 (52%)\n  memory    753170Ki (21%)  1668515840 (46%)\nEvents:     <none>\n"
Dec  5 21:19:14.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 describe namespace e2e-tests-kubectl-st2ml'
Dec  5 21:19:14.654: INFO: stderr: ""
Dec  5 21:19:14.654: INFO: stdout: "Name:         e2e-tests-kubectl-st2ml\nLabels:       e2e-framework=kubectl\n              e2e-run=912be3c6-f8cf-11e8-b962-c6dde3e93636\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:19:14.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-st2ml" for this suite.
Dec  5 21:19:38.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:19:38.866: INFO: namespace: e2e-tests-kubectl-st2ml, resource: bindings, ignored listing per whitelist
Dec  5 21:19:39.168: INFO: namespace e2e-tests-kubectl-st2ml deletion completed in 24.502088694s

• [SLOW TEST:28.021 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:19:39.170: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-g5gv9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1205 21:19:49.751165      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  5 21:19:49.751: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:19:49.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-g5gv9" for this suite.
Dec  5 21:19:57.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:19:57.896: INFO: namespace: e2e-tests-gc-g5gv9, resource: bindings, ignored listing per whitelist
Dec  5 21:19:58.136: INFO: namespace e2e-tests-gc-g5gv9 deletion completed in 8.374731478s

• [SLOW TEST:18.966 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:19:58.136: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-nbgbv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 21:19:58.521: INFO: Waiting up to 5m0s for pod "downwardapi-volume-84d37c25-f8d3-11e8-b962-c6dde3e93636" in namespace "e2e-tests-projected-nbgbv" to be "success or failure"
Dec  5 21:19:58.532: INFO: Pod "downwardapi-volume-84d37c25-f8d3-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 11.57702ms
Dec  5 21:20:00.542: INFO: Pod "downwardapi-volume-84d37c25-f8d3-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020839716s
STEP: Saw pod success
Dec  5 21:20:00.542: INFO: Pod "downwardapi-volume-84d37c25-f8d3-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:20:00.551: INFO: Trying to get logs from node 10.191.0.150 pod downwardapi-volume-84d37c25-f8d3-11e8-b962-c6dde3e93636 container client-container: <nil>
STEP: delete the pod
Dec  5 21:20:00.635: INFO: Waiting for pod downwardapi-volume-84d37c25-f8d3-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:20:00.648: INFO: Pod downwardapi-volume-84d37c25-f8d3-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:20:00.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nbgbv" for this suite.
Dec  5 21:20:06.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:20:06.985: INFO: namespace: e2e-tests-projected-nbgbv, resource: bindings, ignored listing per whitelist
Dec  5 21:20:07.077: INFO: namespace e2e-tests-projected-nbgbv deletion completed in 6.415341924s

• [SLOW TEST:8.941 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:20:07.079: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-bw7j8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-8a210be5-f8d3-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume secrets
Dec  5 21:20:07.435: INFO: Waiting up to 5m0s for pod "pod-secrets-8a22e66c-f8d3-11e8-b962-c6dde3e93636" in namespace "e2e-tests-secrets-bw7j8" to be "success or failure"
Dec  5 21:20:07.444: INFO: Pod "pod-secrets-8a22e66c-f8d3-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 8.925402ms
Dec  5 21:20:09.454: INFO: Pod "pod-secrets-8a22e66c-f8d3-11e8-b962-c6dde3e93636": Phase="Running", Reason="", readiness=true. Elapsed: 2.018088968s
Dec  5 21:20:11.463: INFO: Pod "pod-secrets-8a22e66c-f8d3-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027221763s
STEP: Saw pod success
Dec  5 21:20:11.463: INFO: Pod "pod-secrets-8a22e66c-f8d3-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:20:11.476: INFO: Trying to get logs from node 10.191.0.150 pod pod-secrets-8a22e66c-f8d3-11e8-b962-c6dde3e93636 container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 21:20:11.571: INFO: Waiting for pod pod-secrets-8a22e66c-f8d3-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:20:11.580: INFO: Pod pod-secrets-8a22e66c-f8d3-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:20:11.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-bw7j8" for this suite.
Dec  5 21:20:17.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:20:17.819: INFO: namespace: e2e-tests-secrets-bw7j8, resource: bindings, ignored listing per whitelist
Dec  5 21:20:18.027: INFO: namespace e2e-tests-secrets-bw7j8 deletion completed in 6.429536854s

• [SLOW TEST:10.948 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:20:18.028: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-9t2fb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  5 21:20:18.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-9t2fb'
Dec  5 21:20:18.494: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec  5 21:20:18.494: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Dec  5 21:20:20.518: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-rxwvn]
Dec  5 21:20:20.518: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-rxwvn" in namespace "e2e-tests-kubectl-9t2fb" to be "running and ready"
Dec  5 21:20:20.526: INFO: Pod "e2e-test-nginx-rc-rxwvn": Phase="Pending", Reason="", readiness=false. Elapsed: 8.108654ms
Dec  5 21:20:22.535: INFO: Pod "e2e-test-nginx-rc-rxwvn": Phase="Running", Reason="", readiness=true. Elapsed: 2.017293348s
Dec  5 21:20:22.535: INFO: Pod "e2e-test-nginx-rc-rxwvn" satisfied condition "running and ready"
Dec  5 21:20:22.535: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-rxwvn]
Dec  5 21:20:22.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-9t2fb'
Dec  5 21:20:22.763: INFO: stderr: ""
Dec  5 21:20:22.763: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Dec  5 21:20:22.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-9t2fb'
Dec  5 21:20:22.950: INFO: stderr: ""
Dec  5 21:20:22.950: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:20:22.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9t2fb" for this suite.
Dec  5 21:20:47.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:20:47.508: INFO: namespace: e2e-tests-kubectl-9t2fb, resource: bindings, ignored listing per whitelist
Dec  5 21:20:47.584: INFO: namespace e2e-tests-kubectl-9t2fb deletion completed in 24.610111503s

• [SLOW TEST:29.556 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:20:47.584: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-5grw9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-a24a16d0-f8d3-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume secrets
Dec  5 21:20:47.967: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a24bc30e-f8d3-11e8-b962-c6dde3e93636" in namespace "e2e-tests-projected-5grw9" to be "success or failure"
Dec  5 21:20:47.975: INFO: Pod "pod-projected-secrets-a24bc30e-f8d3-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 8.021989ms
Dec  5 21:20:49.985: INFO: Pod "pod-projected-secrets-a24bc30e-f8d3-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017636991s
STEP: Saw pod success
Dec  5 21:20:49.985: INFO: Pod "pod-projected-secrets-a24bc30e-f8d3-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:20:49.994: INFO: Trying to get logs from node 10.191.0.150 pod pod-projected-secrets-a24bc30e-f8d3-11e8-b962-c6dde3e93636 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  5 21:20:50.051: INFO: Waiting for pod pod-projected-secrets-a24bc30e-f8d3-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:20:50.067: INFO: Pod pod-projected-secrets-a24bc30e-f8d3-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:20:50.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5grw9" for this suite.
Dec  5 21:20:56.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:20:56.407: INFO: namespace: e2e-tests-projected-5grw9, resource: bindings, ignored listing per whitelist
Dec  5 21:20:56.600: INFO: namespace e2e-tests-projected-5grw9 deletion completed in 6.516844093s

• [SLOW TEST:9.016 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:20:56.602: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-qdfgw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  5 21:20:57.017: INFO: Waiting up to 5m0s for pod "pod-a7b17cbe-f8d3-11e8-b962-c6dde3e93636" in namespace "e2e-tests-emptydir-qdfgw" to be "success or failure"
Dec  5 21:20:57.046: INFO: Pod "pod-a7b17cbe-f8d3-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 28.960317ms
Dec  5 21:20:59.056: INFO: Pod "pod-a7b17cbe-f8d3-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.038273329s
STEP: Saw pod success
Dec  5 21:20:59.056: INFO: Pod "pod-a7b17cbe-f8d3-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:20:59.066: INFO: Trying to get logs from node 10.191.0.150 pod pod-a7b17cbe-f8d3-11e8-b962-c6dde3e93636 container test-container: <nil>
STEP: delete the pod
Dec  5 21:20:59.163: INFO: Waiting for pod pod-a7b17cbe-f8d3-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:20:59.171: INFO: Pod pod-a7b17cbe-f8d3-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:20:59.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qdfgw" for this suite.
Dec  5 21:21:05.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:21:05.424: INFO: namespace: e2e-tests-emptydir-qdfgw, resource: bindings, ignored listing per whitelist
Dec  5 21:21:05.586: INFO: namespace e2e-tests-emptydir-qdfgw deletion completed in 6.399535705s

• [SLOW TEST:8.984 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:21:05.588: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-w65mk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Dec  5 21:21:05.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 create -f - --namespace=e2e-tests-kubectl-w65mk'
Dec  5 21:21:06.193: INFO: stderr: ""
Dec  5 21:21:06.193: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  5 21:21:06.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-w65mk'
Dec  5 21:21:06.358: INFO: stderr: ""
Dec  5 21:21:06.358: INFO: stdout: "update-demo-nautilus-hrwpv update-demo-nautilus-ndpct "
Dec  5 21:21:06.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods update-demo-nautilus-hrwpv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-w65mk'
Dec  5 21:21:06.534: INFO: stderr: ""
Dec  5 21:21:06.534: INFO: stdout: ""
Dec  5 21:21:06.534: INFO: update-demo-nautilus-hrwpv is created but not running
Dec  5 21:21:11.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-w65mk'
Dec  5 21:21:11.702: INFO: stderr: ""
Dec  5 21:21:11.702: INFO: stdout: "update-demo-nautilus-hrwpv update-demo-nautilus-ndpct "
Dec  5 21:21:11.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods update-demo-nautilus-hrwpv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-w65mk'
Dec  5 21:21:11.860: INFO: stderr: ""
Dec  5 21:21:11.860: INFO: stdout: "true"
Dec  5 21:21:11.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods update-demo-nautilus-hrwpv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-w65mk'
Dec  5 21:21:12.045: INFO: stderr: ""
Dec  5 21:21:12.045: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 21:21:12.045: INFO: validating pod update-demo-nautilus-hrwpv
Dec  5 21:21:12.066: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 21:21:12.067: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 21:21:12.067: INFO: update-demo-nautilus-hrwpv is verified up and running
Dec  5 21:21:12.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods update-demo-nautilus-ndpct -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-w65mk'
Dec  5 21:21:12.201: INFO: stderr: ""
Dec  5 21:21:12.201: INFO: stdout: "true"
Dec  5 21:21:12.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods update-demo-nautilus-ndpct -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-w65mk'
Dec  5 21:21:12.327: INFO: stderr: ""
Dec  5 21:21:12.327: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 21:21:12.327: INFO: validating pod update-demo-nautilus-ndpct
Dec  5 21:21:12.345: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 21:21:12.345: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 21:21:12.345: INFO: update-demo-nautilus-ndpct is verified up and running
STEP: rolling-update to new replication controller
Dec  5 21:21:12.347: INFO: scanned /root for discovery docs: <nil>
Dec  5 21:21:12.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-w65mk'
Dec  5 21:21:35.091: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  5 21:21:35.091: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  5 21:21:35.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-w65mk'
Dec  5 21:21:35.252: INFO: stderr: ""
Dec  5 21:21:35.252: INFO: stdout: "update-demo-kitten-p5jgm update-demo-kitten-zzdlg "
Dec  5 21:21:35.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods update-demo-kitten-p5jgm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-w65mk'
Dec  5 21:21:35.402: INFO: stderr: ""
Dec  5 21:21:35.402: INFO: stdout: "true"
Dec  5 21:21:35.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods update-demo-kitten-p5jgm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-w65mk'
Dec  5 21:21:35.556: INFO: stderr: ""
Dec  5 21:21:35.556: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  5 21:21:35.556: INFO: validating pod update-demo-kitten-p5jgm
Dec  5 21:21:35.635: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  5 21:21:35.636: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  5 21:21:35.636: INFO: update-demo-kitten-p5jgm is verified up and running
Dec  5 21:21:35.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods update-demo-kitten-zzdlg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-w65mk'
Dec  5 21:21:35.792: INFO: stderr: ""
Dec  5 21:21:35.792: INFO: stdout: "true"
Dec  5 21:21:35.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods update-demo-kitten-zzdlg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-w65mk'
Dec  5 21:21:35.921: INFO: stderr: ""
Dec  5 21:21:35.921: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  5 21:21:35.921: INFO: validating pod update-demo-kitten-zzdlg
Dec  5 21:21:35.938: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  5 21:21:35.938: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  5 21:21:35.938: INFO: update-demo-kitten-zzdlg is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:21:35.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-w65mk" for this suite.
Dec  5 21:21:59.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:22:00.236: INFO: namespace: e2e-tests-kubectl-w65mk, resource: bindings, ignored listing per whitelist
Dec  5 21:22:00.319: INFO: namespace e2e-tests-kubectl-w65mk deletion completed in 24.366811328s

• [SLOW TEST:54.731 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:22:00.319: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-gklfv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-cdb7daac-f8d3-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume configMaps
Dec  5 21:22:00.835: INFO: Waiting up to 5m0s for pod "pod-configmaps-cdb9841a-f8d3-11e8-b962-c6dde3e93636" in namespace "e2e-tests-configmap-gklfv" to be "success or failure"
Dec  5 21:22:00.846: INFO: Pod "pod-configmaps-cdb9841a-f8d3-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 10.233427ms
Dec  5 21:22:02.854: INFO: Pod "pod-configmaps-cdb9841a-f8d3-11e8-b962-c6dde3e93636": Phase="Running", Reason="", readiness=true. Elapsed: 2.018736359s
Dec  5 21:22:04.864: INFO: Pod "pod-configmaps-cdb9841a-f8d3-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028634281s
STEP: Saw pod success
Dec  5 21:22:04.864: INFO: Pod "pod-configmaps-cdb9841a-f8d3-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:22:04.873: INFO: Trying to get logs from node 10.191.0.150 pod pod-configmaps-cdb9841a-f8d3-11e8-b962-c6dde3e93636 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 21:22:04.929: INFO: Waiting for pod pod-configmaps-cdb9841a-f8d3-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:22:04.939: INFO: Pod pod-configmaps-cdb9841a-f8d3-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:22:04.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-gklfv" for this suite.
Dec  5 21:22:10.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:22:11.294: INFO: namespace: e2e-tests-configmap-gklfv, resource: bindings, ignored listing per whitelist
Dec  5 21:22:11.326: INFO: namespace e2e-tests-configmap-gklfv deletion completed in 6.374037518s

• [SLOW TEST:11.007 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:22:11.326: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-q5n9d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 21:22:11.770: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec  5 21:22:11.804: INFO: Number of nodes with available pods: 0
Dec  5 21:22:11.804: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:22:12.830: INFO: Number of nodes with available pods: 0
Dec  5 21:22:12.830: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:22:13.826: INFO: Number of nodes with available pods: 3
Dec  5 21:22:13.826: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec  5 21:22:13.888: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:13.888: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:13.888: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:14.910: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:14.910: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:14.910: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:15.913: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:15.913: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:15.913: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:16.909: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:16.909: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:16.909: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:17.911: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:17.911: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:17.911: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:18.909: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:18.909: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:18.909: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:19.923: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:19.923: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:19.923: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:20.909: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:20.910: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:20.910: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:21.911: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:21.911: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:21.911: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:22.935: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:22.936: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:22.936: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:23.909: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:23.909: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:23.909: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:24.910: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:24.910: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:24.910: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:25.909: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:25.909: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:25.909: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:26.912: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:26.912: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:26.912: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:27.914: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:27.914: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:27.915: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:28.909: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:28.909: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:28.909: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:29.913: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:29.913: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:29.913: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:30.924: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:30.924: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:30.924: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:31.912: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:31.912: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:31.912: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:32.911: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:32.911: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:32.911: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:33.910: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:33.910: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:33.910: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:34.909: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:34.909: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:34.909: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:35.908: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:35.908: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:35.908: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:36.908: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:36.908: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:36.908: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:37.913: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:37.913: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:37.913: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:38.910: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:38.910: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:38.910: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:39.917: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:39.917: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:39.917: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:40.909: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:40.909: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:40.910: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:41.926: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:41.926: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:41.926: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:42.909: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:42.909: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:42.909: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:43.909: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:43.909: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:43.909: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:44.908: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:44.908: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:44.908: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:45.910: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:45.910: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:45.910: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:46.913: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:46.913: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:46.913: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:46.913: INFO: Pod daemon-set-rchwc is not available
Dec  5 21:22:47.910: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:47.910: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:47.910: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:47.910: INFO: Pod daemon-set-rchwc is not available
Dec  5 21:22:48.909: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:48.909: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:48.909: INFO: Wrong image for pod: daemon-set-rchwc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:48.909: INFO: Pod daemon-set-rchwc is not available
Dec  5 21:22:49.912: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:49.912: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:49.912: INFO: Pod daemon-set-kwn45 is not available
Dec  5 21:22:50.914: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:50.915: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:50.915: INFO: Pod daemon-set-kwn45 is not available
Dec  5 21:22:51.910: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:51.910: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:51.910: INFO: Pod daemon-set-kwn45 is not available
Dec  5 21:22:52.925: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:52.925: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:53.911: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:53.911: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:54.908: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:54.909: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:55.914: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:55.914: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:56.909: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:56.909: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:57.910: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:57.910: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:58.908: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:58.908: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:59.915: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:22:59.915: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:00.909: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:00.910: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:01.909: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:01.909: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:02.911: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:02.911: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:03.922: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:03.922: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:04.909: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:04.909: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:05.909: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:05.909: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:06.913: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:06.914: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:07.910: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:07.910: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:08.909: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:08.909: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:09.913: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:09.913: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:10.909: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:10.909: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:11.909: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:11.909: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:12.912: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:12.912: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:13.916: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:13.916: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:14.909: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:14.909: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:15.911: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:15.911: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:16.908: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:16.908: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:17.909: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:17.910: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:18.908: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:18.908: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:19.913: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:19.913: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:20.917: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:20.917: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:21.912: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:21.912: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:22.910: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:22.910: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:23.908: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:23.908: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:24.926: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:24.926: INFO: Pod daemon-set-csgl7 is not available
Dec  5 21:23:24.926: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:25.910: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:25.910: INFO: Pod daemon-set-csgl7 is not available
Dec  5 21:23:25.910: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:26.911: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:26.911: INFO: Pod daemon-set-csgl7 is not available
Dec  5 21:23:26.911: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:27.910: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:27.910: INFO: Pod daemon-set-csgl7 is not available
Dec  5 21:23:27.910: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:28.911: INFO: Wrong image for pod: daemon-set-csgl7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:28.911: INFO: Pod daemon-set-csgl7 is not available
Dec  5 21:23:28.911: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:29.908: INFO: Pod daemon-set-984nd is not available
Dec  5 21:23:29.908: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:30.910: INFO: Pod daemon-set-984nd is not available
Dec  5 21:23:30.910: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:31.911: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:32.909: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:33.908: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:34.910: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:35.920: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:36.911: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:37.911: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:38.910: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:39.910: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:40.909: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:41.909: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:42.909: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:43.911: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:44.918: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:45.911: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:46.928: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:47.909: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:48.920: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:49.914: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:50.909: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:51.912: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:52.910: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:53.910: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:54.914: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:55.909: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:56.910: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:57.929: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:58.910: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:23:59.911: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:24:00.909: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:24:01.910: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:24:02.912: INFO: Wrong image for pod: daemon-set-g55wt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 21:24:02.912: INFO: Pod daemon-set-g55wt is not available
Dec  5 21:24:03.916: INFO: Pod daemon-set-rgv2p is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Dec  5 21:24:03.953: INFO: Number of nodes with available pods: 2
Dec  5 21:24:03.953: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:24:05.045: INFO: Number of nodes with available pods: 2
Dec  5 21:24:05.045: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:24:05.979: INFO: Number of nodes with available pods: 2
Dec  5 21:24:05.979: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:24:06.977: INFO: Number of nodes with available pods: 2
Dec  5 21:24:06.977: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 21:24:07.991: INFO: Number of nodes with available pods: 3
Dec  5 21:24:07.991: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-q5n9d, will wait for the garbage collector to delete the pods
Dec  5 21:24:08.115: INFO: Deleting {extensions DaemonSet} daemon-set took: 22.551707ms
Dec  5 21:24:08.215: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.212904ms
Dec  5 21:24:19.836: INFO: Number of nodes with available pods: 0
Dec  5 21:24:19.836: INFO: Number of running nodes: 0, number of available pods: 0
Dec  5 21:24:19.849: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-q5n9d/daemonsets","resourceVersion":"14553"},"items":null}

Dec  5 21:24:19.857: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-q5n9d/pods","resourceVersion":"14553"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:24:19.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-q5n9d" for this suite.
Dec  5 21:24:27.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:24:28.205: INFO: namespace: e2e-tests-daemonsets-q5n9d, resource: bindings, ignored listing per whitelist
Dec  5 21:24:28.367: INFO: namespace e2e-tests-daemonsets-q5n9d deletion completed in 8.451424009s

• [SLOW TEST:137.041 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:24:28.370: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-fb6tq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-fb6tq
Dec  5 21:24:30.771: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-fb6tq
STEP: checking the pod's current state and verifying that restartCount is present
Dec  5 21:24:30.779: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:28:32.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-fb6tq" for this suite.
Dec  5 21:28:38.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:28:38.679: INFO: namespace: e2e-tests-container-probe-fb6tq, resource: bindings, ignored listing per whitelist
Dec  5 21:28:38.903: INFO: namespace e2e-tests-container-probe-fb6tq deletion completed in 6.466958789s

• [SLOW TEST:250.533 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:28:38.903: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-9mmdn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Dec  5 21:28:39.252: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-9mmdn" to be "success or failure"
Dec  5 21:28:39.336: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 83.745777ms
Dec  5 21:28:41.345: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.092336608s
STEP: Saw pod success
Dec  5 21:28:41.345: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec  5 21:28:41.435: INFO: Trying to get logs from node 10.191.0.150 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec  5 21:28:41.500: INFO: Waiting for pod pod-host-path-test to disappear
Dec  5 21:28:41.509: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:28:41.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-9mmdn" for this suite.
Dec  5 21:28:47.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:28:47.824: INFO: namespace: e2e-tests-hostpath-9mmdn, resource: bindings, ignored listing per whitelist
Dec  5 21:28:47.985: INFO: namespace e2e-tests-hostpath-9mmdn deletion completed in 6.46355527s

• [SLOW TEST:9.082 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:28:47.986: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-nwr5b
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-c09a7736-f8d4-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume secrets
Dec  5 21:28:48.319: INFO: Waiting up to 5m0s for pod "pod-secrets-c09c5278-f8d4-11e8-b962-c6dde3e93636" in namespace "e2e-tests-secrets-nwr5b" to be "success or failure"
Dec  5 21:28:48.333: INFO: Pod "pod-secrets-c09c5278-f8d4-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 13.333285ms
Dec  5 21:28:50.341: INFO: Pod "pod-secrets-c09c5278-f8d4-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022171719s
STEP: Saw pod success
Dec  5 21:28:50.342: INFO: Pod "pod-secrets-c09c5278-f8d4-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:28:50.356: INFO: Trying to get logs from node 10.191.0.150 pod pod-secrets-c09c5278-f8d4-11e8-b962-c6dde3e93636 container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 21:28:50.435: INFO: Waiting for pod pod-secrets-c09c5278-f8d4-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:28:50.449: INFO: Pod pod-secrets-c09c5278-f8d4-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:28:50.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-nwr5b" for this suite.
Dec  5 21:28:56.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:28:56.729: INFO: namespace: e2e-tests-secrets-nwr5b, resource: bindings, ignored listing per whitelist
Dec  5 21:28:56.833: INFO: namespace e2e-tests-secrets-nwr5b deletion completed in 6.370997734s

• [SLOW TEST:8.847 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:28:56.834: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-7jnzc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 21:28:57.236: INFO: (0) /api/v1/nodes/10.191.0.134:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 66.043286ms)
Dec  5 21:28:57.252: INFO: (1) /api/v1/nodes/10.191.0.134:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.426306ms)
Dec  5 21:28:57.266: INFO: (2) /api/v1/nodes/10.191.0.134:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.362629ms)
Dec  5 21:28:57.284: INFO: (3) /api/v1/nodes/10.191.0.134:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 17.378097ms)
Dec  5 21:28:57.301: INFO: (4) /api/v1/nodes/10.191.0.134:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 17.250194ms)
Dec  5 21:28:57.317: INFO: (5) /api/v1/nodes/10.191.0.134:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.679488ms)
Dec  5 21:28:57.337: INFO: (6) /api/v1/nodes/10.191.0.134:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 20.517659ms)
Dec  5 21:28:57.358: INFO: (7) /api/v1/nodes/10.191.0.134:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 20.084734ms)
Dec  5 21:28:57.376: INFO: (8) /api/v1/nodes/10.191.0.134:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 18.09573ms)
Dec  5 21:28:57.394: INFO: (9) /api/v1/nodes/10.191.0.134:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 17.838687ms)
Dec  5 21:28:57.407: INFO: (10) /api/v1/nodes/10.191.0.134:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.720459ms)
Dec  5 21:28:57.421: INFO: (11) /api/v1/nodes/10.191.0.134:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.035752ms)
Dec  5 21:28:57.437: INFO: (12) /api/v1/nodes/10.191.0.134:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 16.269152ms)
Dec  5 21:28:57.451: INFO: (13) /api/v1/nodes/10.191.0.134:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.939834ms)
Dec  5 21:28:57.469: INFO: (14) /api/v1/nodes/10.191.0.134:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 18.256117ms)
Dec  5 21:28:57.490: INFO: (15) /api/v1/nodes/10.191.0.134:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 20.332944ms)
Dec  5 21:28:57.509: INFO: (16) /api/v1/nodes/10.191.0.134:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 19.420717ms)
Dec  5 21:28:57.525: INFO: (17) /api/v1/nodes/10.191.0.134:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 16.09805ms)
Dec  5 21:28:57.538: INFO: (18) /api/v1/nodes/10.191.0.134:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.153281ms)
Dec  5 21:28:57.554: INFO: (19) /api/v1/nodes/10.191.0.134:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.1092ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:28:57.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-7jnzc" for this suite.
Dec  5 21:29:03.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:29:03.700: INFO: namespace: e2e-tests-proxy-7jnzc, resource: bindings, ignored listing per whitelist
Dec  5 21:29:04.013: INFO: namespace e2e-tests-proxy-7jnzc deletion completed in 6.448950203s

• [SLOW TEST:7.179 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:29:04.015: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wstrb
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Dec  5 21:29:04.376: INFO: Waiting up to 5m0s for pod "pod-ca2d8e9d-f8d4-11e8-b962-c6dde3e93636" in namespace "e2e-tests-emptydir-wstrb" to be "success or failure"
Dec  5 21:29:04.387: INFO: Pod "pod-ca2d8e9d-f8d4-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 10.69275ms
Dec  5 21:29:06.408: INFO: Pod "pod-ca2d8e9d-f8d4-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03226366s
STEP: Saw pod success
Dec  5 21:29:06.408: INFO: Pod "pod-ca2d8e9d-f8d4-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:29:06.416: INFO: Trying to get logs from node 10.191.0.150 pod pod-ca2d8e9d-f8d4-11e8-b962-c6dde3e93636 container test-container: <nil>
STEP: delete the pod
Dec  5 21:29:06.469: INFO: Waiting for pod pod-ca2d8e9d-f8d4-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:29:06.477: INFO: Pod pod-ca2d8e9d-f8d4-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:29:06.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wstrb" for this suite.
Dec  5 21:29:12.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:29:12.645: INFO: namespace: e2e-tests-emptydir-wstrb, resource: bindings, ignored listing per whitelist
Dec  5 21:29:12.928: INFO: namespace e2e-tests-emptydir-wstrb deletion completed in 6.438827838s

• [SLOW TEST:8.913 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:29:12.928: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-5fjff
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  5 21:29:13.352: INFO: Waiting up to 5m0s for pod "pod-cf7cff43-f8d4-11e8-b962-c6dde3e93636" in namespace "e2e-tests-emptydir-5fjff" to be "success or failure"
Dec  5 21:29:13.363: INFO: Pod "pod-cf7cff43-f8d4-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 10.858542ms
Dec  5 21:29:15.372: INFO: Pod "pod-cf7cff43-f8d4-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019610485s
STEP: Saw pod success
Dec  5 21:29:15.372: INFO: Pod "pod-cf7cff43-f8d4-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:29:15.380: INFO: Trying to get logs from node 10.191.0.150 pod pod-cf7cff43-f8d4-11e8-b962-c6dde3e93636 container test-container: <nil>
STEP: delete the pod
Dec  5 21:29:15.426: INFO: Waiting for pod pod-cf7cff43-f8d4-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:29:15.435: INFO: Pod pod-cf7cff43-f8d4-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:29:15.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5fjff" for this suite.
Dec  5 21:29:21.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:29:21.804: INFO: namespace: e2e-tests-emptydir-5fjff, resource: bindings, ignored listing per whitelist
Dec  5 21:29:21.844: INFO: namespace e2e-tests-emptydir-5fjff deletion completed in 6.395762621s

• [SLOW TEST:8.916 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:29:21.844: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-vb84l
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-vb84l
I1205 21:29:22.182007      16 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-vb84l, replica count: 1
I1205 21:29:23.232410      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1205 21:29:24.232685      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  5 21:29:24.359: INFO: Created: latency-svc-nd4g2
Dec  5 21:29:24.376: INFO: Got endpoints: latency-svc-nd4g2 [43.274657ms]
Dec  5 21:29:24.458: INFO: Created: latency-svc-s29b7
Dec  5 21:29:24.466: INFO: Got endpoints: latency-svc-s29b7 [89.657743ms]
Dec  5 21:29:24.475: INFO: Created: latency-svc-nzcc6
Dec  5 21:29:24.480: INFO: Got endpoints: latency-svc-nzcc6 [102.962197ms]
Dec  5 21:29:24.487: INFO: Created: latency-svc-njx9x
Dec  5 21:29:24.493: INFO: Got endpoints: latency-svc-njx9x [117.247817ms]
Dec  5 21:29:24.502: INFO: Created: latency-svc-8wc9v
Dec  5 21:29:24.509: INFO: Got endpoints: latency-svc-8wc9v [132.547349ms]
Dec  5 21:29:24.521: INFO: Created: latency-svc-n8r7n
Dec  5 21:29:24.528: INFO: Got endpoints: latency-svc-n8r7n [150.913266ms]
Dec  5 21:29:24.536: INFO: Created: latency-svc-4tsvs
Dec  5 21:29:24.548: INFO: Got endpoints: latency-svc-4tsvs [170.64791ms]
Dec  5 21:29:24.555: INFO: Created: latency-svc-wtdkn
Dec  5 21:29:24.564: INFO: Got endpoints: latency-svc-wtdkn [186.399222ms]
Dec  5 21:29:24.570: INFO: Created: latency-svc-6hdnc
Dec  5 21:29:24.592: INFO: Got endpoints: latency-svc-6hdnc [214.625826ms]
Dec  5 21:29:24.603: INFO: Created: latency-svc-sz9sl
Dec  5 21:29:24.607: INFO: Got endpoints: latency-svc-sz9sl [229.652507ms]
Dec  5 21:29:24.611: INFO: Created: latency-svc-qx9fz
Dec  5 21:29:24.618: INFO: Got endpoints: latency-svc-qx9fz [241.029632ms]
Dec  5 21:29:24.627: INFO: Created: latency-svc-4q6qb
Dec  5 21:29:24.634: INFO: Got endpoints: latency-svc-4q6qb [256.511647ms]
Dec  5 21:29:24.648: INFO: Created: latency-svc-wjfn4
Dec  5 21:29:24.648: INFO: Got endpoints: latency-svc-wjfn4 [270.967971ms]
Dec  5 21:29:24.660: INFO: Created: latency-svc-chqgf
Dec  5 21:29:24.666: INFO: Got endpoints: latency-svc-chqgf [289.265874ms]
Dec  5 21:29:24.674: INFO: Created: latency-svc-w2hxv
Dec  5 21:29:24.687: INFO: Created: latency-svc-2lvq9
Dec  5 21:29:24.690: INFO: Got endpoints: latency-svc-w2hxv [41.859548ms]
Dec  5 21:29:24.695: INFO: Got endpoints: latency-svc-2lvq9 [317.540691ms]
Dec  5 21:29:24.705: INFO: Created: latency-svc-k7pdq
Dec  5 21:29:24.712: INFO: Got endpoints: latency-svc-k7pdq [334.462434ms]
Dec  5 21:29:24.722: INFO: Created: latency-svc-vp7hm
Dec  5 21:29:24.728: INFO: Got endpoints: latency-svc-vp7hm [261.999935ms]
Dec  5 21:29:24.741: INFO: Created: latency-svc-7hj9c
Dec  5 21:29:24.741: INFO: Got endpoints: latency-svc-7hj9c [261.747993ms]
Dec  5 21:29:24.755: INFO: Created: latency-svc-rl85v
Dec  5 21:29:24.764: INFO: Got endpoints: latency-svc-rl85v [270.171941ms]
Dec  5 21:29:24.767: INFO: Created: latency-svc-smxxd
Dec  5 21:29:24.773: INFO: Got endpoints: latency-svc-smxxd [263.905077ms]
Dec  5 21:29:24.785: INFO: Created: latency-svc-6rkr8
Dec  5 21:29:24.792: INFO: Got endpoints: latency-svc-6rkr8 [263.933845ms]
Dec  5 21:29:24.799: INFO: Created: latency-svc-9t4sn
Dec  5 21:29:24.805: INFO: Got endpoints: latency-svc-9t4sn [256.964606ms]
Dec  5 21:29:24.812: INFO: Created: latency-svc-pmcnn
Dec  5 21:29:24.818: INFO: Got endpoints: latency-svc-pmcnn [254.549554ms]
Dec  5 21:29:24.828: INFO: Created: latency-svc-9jqk4
Dec  5 21:29:24.832: INFO: Got endpoints: latency-svc-9jqk4 [239.937984ms]
Dec  5 21:29:24.839: INFO: Created: latency-svc-xx428
Dec  5 21:29:24.849: INFO: Got endpoints: latency-svc-xx428 [242.345891ms]
Dec  5 21:29:24.855: INFO: Created: latency-svc-bnw2w
Dec  5 21:29:24.860: INFO: Got endpoints: latency-svc-bnw2w [241.303396ms]
Dec  5 21:29:24.870: INFO: Created: latency-svc-mrbvm
Dec  5 21:29:24.877: INFO: Got endpoints: latency-svc-mrbvm [243.315203ms]
Dec  5 21:29:24.885: INFO: Created: latency-svc-tccq2
Dec  5 21:29:24.892: INFO: Got endpoints: latency-svc-tccq2 [225.217398ms]
Dec  5 21:29:24.897: INFO: Created: latency-svc-v5wfn
Dec  5 21:29:24.905: INFO: Got endpoints: latency-svc-v5wfn [214.008838ms]
Dec  5 21:29:24.911: INFO: Created: latency-svc-hfngk
Dec  5 21:29:24.918: INFO: Got endpoints: latency-svc-hfngk [223.309692ms]
Dec  5 21:29:24.926: INFO: Created: latency-svc-57hmx
Dec  5 21:29:24.929: INFO: Got endpoints: latency-svc-57hmx [217.663268ms]
Dec  5 21:29:24.940: INFO: Created: latency-svc-9wknw
Dec  5 21:29:24.947: INFO: Got endpoints: latency-svc-9wknw [218.426864ms]
Dec  5 21:29:24.956: INFO: Created: latency-svc-gtccq
Dec  5 21:29:24.963: INFO: Got endpoints: latency-svc-gtccq [220.89957ms]
Dec  5 21:29:24.972: INFO: Created: latency-svc-z5mdm
Dec  5 21:29:24.978: INFO: Got endpoints: latency-svc-z5mdm [213.731345ms]
Dec  5 21:29:24.986: INFO: Created: latency-svc-vtjpm
Dec  5 21:29:24.990: INFO: Got endpoints: latency-svc-vtjpm [217.028591ms]
Dec  5 21:29:24.997: INFO: Created: latency-svc-hdjkr
Dec  5 21:29:25.004: INFO: Got endpoints: latency-svc-hdjkr [212.096618ms]
Dec  5 21:29:25.014: INFO: Created: latency-svc-7sqvt
Dec  5 21:29:25.018: INFO: Got endpoints: latency-svc-7sqvt [213.282039ms]
Dec  5 21:29:25.027: INFO: Created: latency-svc-rlnpb
Dec  5 21:29:25.033: INFO: Got endpoints: latency-svc-rlnpb [214.637399ms]
Dec  5 21:29:25.040: INFO: Created: latency-svc-gqgfs
Dec  5 21:29:25.047: INFO: Got endpoints: latency-svc-gqgfs [214.701926ms]
Dec  5 21:29:25.056: INFO: Created: latency-svc-rhqq2
Dec  5 21:29:25.064: INFO: Got endpoints: latency-svc-rhqq2 [214.636694ms]
Dec  5 21:29:25.067: INFO: Created: latency-svc-z6kcr
Dec  5 21:29:25.073: INFO: Got endpoints: latency-svc-z6kcr [213.384058ms]
Dec  5 21:29:25.079: INFO: Created: latency-svc-fsjc4
Dec  5 21:29:25.086: INFO: Got endpoints: latency-svc-fsjc4 [208.900594ms]
Dec  5 21:29:25.093: INFO: Created: latency-svc-v6dxl
Dec  5 21:29:25.107: INFO: Created: latency-svc-2p94x
Dec  5 21:29:25.117: INFO: Got endpoints: latency-svc-v6dxl [225.071124ms]
Dec  5 21:29:25.122: INFO: Created: latency-svc-sd4d2
Dec  5 21:29:25.136: INFO: Created: latency-svc-94dt8
Dec  5 21:29:25.151: INFO: Created: latency-svc-kw46m
Dec  5 21:29:25.167: INFO: Created: latency-svc-bm5vt
Dec  5 21:29:25.169: INFO: Got endpoints: latency-svc-2p94x [264.097267ms]
Dec  5 21:29:25.181: INFO: Created: latency-svc-7wn9x
Dec  5 21:29:25.195: INFO: Created: latency-svc-bbb89
Dec  5 21:29:25.211: INFO: Created: latency-svc-c7g7d
Dec  5 21:29:25.215: INFO: Got endpoints: latency-svc-sd4d2 [296.749872ms]
Dec  5 21:29:25.231: INFO: Created: latency-svc-w7qnr
Dec  5 21:29:25.244: INFO: Created: latency-svc-xtrpq
Dec  5 21:29:25.263: INFO: Created: latency-svc-sdwbt
Dec  5 21:29:25.266: INFO: Got endpoints: latency-svc-94dt8 [336.415392ms]
Dec  5 21:29:25.281: INFO: Created: latency-svc-4jdht
Dec  5 21:29:25.296: INFO: Created: latency-svc-zk9dl
Dec  5 21:29:25.308: INFO: Created: latency-svc-8jmhj
Dec  5 21:29:25.315: INFO: Got endpoints: latency-svc-kw46m [368.109703ms]
Dec  5 21:29:25.322: INFO: Created: latency-svc-c872d
Dec  5 21:29:25.339: INFO: Created: latency-svc-vjdwm
Dec  5 21:29:25.359: INFO: Created: latency-svc-5gbqh
Dec  5 21:29:25.368: INFO: Got endpoints: latency-svc-bm5vt [405.060905ms]
Dec  5 21:29:25.369: INFO: Created: latency-svc-87n6r
Dec  5 21:29:25.384: INFO: Created: latency-svc-98j9s
Dec  5 21:29:25.402: INFO: Created: latency-svc-fc85r
Dec  5 21:29:25.419: INFO: Got endpoints: latency-svc-7wn9x [441.746302ms]
Dec  5 21:29:25.444: INFO: Created: latency-svc-2h2mg
Dec  5 21:29:25.465: INFO: Got endpoints: latency-svc-bbb89 [475.065691ms]
Dec  5 21:29:25.490: INFO: Created: latency-svc-8sg98
Dec  5 21:29:25.516: INFO: Got endpoints: latency-svc-c7g7d [511.84769ms]
Dec  5 21:29:25.543: INFO: Created: latency-svc-tnq8p
Dec  5 21:29:25.565: INFO: Got endpoints: latency-svc-w7qnr [546.958528ms]
Dec  5 21:29:25.596: INFO: Created: latency-svc-v7xq5
Dec  5 21:29:25.615: INFO: Got endpoints: latency-svc-xtrpq [582.326851ms]
Dec  5 21:29:25.643: INFO: Created: latency-svc-6tb4j
Dec  5 21:29:25.667: INFO: Got endpoints: latency-svc-sdwbt [620.080634ms]
Dec  5 21:29:25.715: INFO: Got endpoints: latency-svc-4jdht [651.39419ms]
Dec  5 21:29:25.718: INFO: Created: latency-svc-k6ljv
Dec  5 21:29:25.742: INFO: Created: latency-svc-7kf25
Dec  5 21:29:25.767: INFO: Got endpoints: latency-svc-zk9dl [693.522402ms]
Dec  5 21:29:25.791: INFO: Created: latency-svc-9mtkq
Dec  5 21:29:25.822: INFO: Got endpoints: latency-svc-8jmhj [736.084481ms]
Dec  5 21:29:25.844: INFO: Created: latency-svc-fd98h
Dec  5 21:29:25.865: INFO: Got endpoints: latency-svc-c872d [748.531639ms]
Dec  5 21:29:25.887: INFO: Created: latency-svc-8hwdx
Dec  5 21:29:25.915: INFO: Got endpoints: latency-svc-vjdwm [746.131385ms]
Dec  5 21:29:25.937: INFO: Created: latency-svc-7lnsz
Dec  5 21:29:25.972: INFO: Got endpoints: latency-svc-5gbqh [757.226353ms]
Dec  5 21:29:26.004: INFO: Created: latency-svc-h82cz
Dec  5 21:29:26.015: INFO: Got endpoints: latency-svc-87n6r [749.365929ms]
Dec  5 21:29:26.039: INFO: Created: latency-svc-qcqlq
Dec  5 21:29:26.065: INFO: Got endpoints: latency-svc-98j9s [749.673879ms]
Dec  5 21:29:26.092: INFO: Created: latency-svc-vrkkf
Dec  5 21:29:26.116: INFO: Got endpoints: latency-svc-fc85r [748.175511ms]
Dec  5 21:29:26.140: INFO: Created: latency-svc-4vwl8
Dec  5 21:29:26.169: INFO: Got endpoints: latency-svc-2h2mg [749.900916ms]
Dec  5 21:29:26.197: INFO: Created: latency-svc-zst4d
Dec  5 21:29:26.216: INFO: Got endpoints: latency-svc-8sg98 [750.397771ms]
Dec  5 21:29:26.242: INFO: Created: latency-svc-tgz4g
Dec  5 21:29:26.265: INFO: Got endpoints: latency-svc-tnq8p [748.977595ms]
Dec  5 21:29:26.290: INFO: Created: latency-svc-6zhtl
Dec  5 21:29:26.316: INFO: Got endpoints: latency-svc-v7xq5 [750.556784ms]
Dec  5 21:29:26.344: INFO: Created: latency-svc-4jc2s
Dec  5 21:29:26.366: INFO: Got endpoints: latency-svc-6tb4j [750.554886ms]
Dec  5 21:29:26.391: INFO: Created: latency-svc-2dczz
Dec  5 21:29:26.415: INFO: Got endpoints: latency-svc-k6ljv [748.202169ms]
Dec  5 21:29:26.448: INFO: Created: latency-svc-772mk
Dec  5 21:29:26.465: INFO: Got endpoints: latency-svc-7kf25 [749.432784ms]
Dec  5 21:29:26.490: INFO: Created: latency-svc-gnr42
Dec  5 21:29:26.535: INFO: Got endpoints: latency-svc-9mtkq [768.01829ms]
Dec  5 21:29:26.561: INFO: Created: latency-svc-22kfx
Dec  5 21:29:26.564: INFO: Got endpoints: latency-svc-fd98h [741.559269ms]
Dec  5 21:29:26.636: INFO: Created: latency-svc-bt8pt
Dec  5 21:29:26.636: INFO: Got endpoints: latency-svc-8hwdx [770.917613ms]
Dec  5 21:29:26.661: INFO: Created: latency-svc-vx4gg
Dec  5 21:29:26.664: INFO: Got endpoints: latency-svc-7lnsz [748.887239ms]
Dec  5 21:29:26.699: INFO: Created: latency-svc-499vn
Dec  5 21:29:26.715: INFO: Got endpoints: latency-svc-h82cz [742.231023ms]
Dec  5 21:29:26.744: INFO: Created: latency-svc-gwtjr
Dec  5 21:29:26.765: INFO: Got endpoints: latency-svc-qcqlq [748.969113ms]
Dec  5 21:29:26.790: INFO: Created: latency-svc-sh4xx
Dec  5 21:29:26.815: INFO: Got endpoints: latency-svc-vrkkf [750.748316ms]
Dec  5 21:29:26.844: INFO: Created: latency-svc-2lq2b
Dec  5 21:29:26.868: INFO: Got endpoints: latency-svc-4vwl8 [752.07037ms]
Dec  5 21:29:26.894: INFO: Created: latency-svc-l7mq9
Dec  5 21:29:26.914: INFO: Got endpoints: latency-svc-zst4d [744.615795ms]
Dec  5 21:29:26.940: INFO: Created: latency-svc-pf4m4
Dec  5 21:29:26.966: INFO: Got endpoints: latency-svc-tgz4g [749.793801ms]
Dec  5 21:29:26.991: INFO: Created: latency-svc-4pr67
Dec  5 21:29:27.015: INFO: Got endpoints: latency-svc-6zhtl [749.98401ms]
Dec  5 21:29:27.038: INFO: Created: latency-svc-mrqnx
Dec  5 21:29:27.065: INFO: Got endpoints: latency-svc-4jc2s [748.552173ms]
Dec  5 21:29:27.090: INFO: Created: latency-svc-wlkzc
Dec  5 21:29:27.120: INFO: Got endpoints: latency-svc-2dczz [754.169723ms]
Dec  5 21:29:27.146: INFO: Created: latency-svc-9dcx2
Dec  5 21:29:27.164: INFO: Got endpoints: latency-svc-772mk [748.821905ms]
Dec  5 21:29:27.188: INFO: Created: latency-svc-jn58f
Dec  5 21:29:27.218: INFO: Got endpoints: latency-svc-gnr42 [753.415582ms]
Dec  5 21:29:27.243: INFO: Created: latency-svc-bwwzw
Dec  5 21:29:27.265: INFO: Got endpoints: latency-svc-22kfx [730.146325ms]
Dec  5 21:29:27.289: INFO: Created: latency-svc-z2mzm
Dec  5 21:29:27.317: INFO: Got endpoints: latency-svc-bt8pt [752.347447ms]
Dec  5 21:29:27.342: INFO: Created: latency-svc-gtpc5
Dec  5 21:29:27.364: INFO: Got endpoints: latency-svc-vx4gg [727.885751ms]
Dec  5 21:29:27.387: INFO: Created: latency-svc-72262
Dec  5 21:29:27.415: INFO: Got endpoints: latency-svc-499vn [750.773426ms]
Dec  5 21:29:27.435: INFO: Created: latency-svc-2rzcd
Dec  5 21:29:27.464: INFO: Got endpoints: latency-svc-gwtjr [749.23386ms]
Dec  5 21:29:27.488: INFO: Created: latency-svc-5s8xr
Dec  5 21:29:27.513: INFO: Got endpoints: latency-svc-sh4xx [748.89822ms]
Dec  5 21:29:27.558: INFO: Created: latency-svc-ftrs9
Dec  5 21:29:27.567: INFO: Got endpoints: latency-svc-2lq2b [750.849484ms]
Dec  5 21:29:27.595: INFO: Created: latency-svc-6kdfb
Dec  5 21:29:27.615: INFO: Got endpoints: latency-svc-l7mq9 [746.731424ms]
Dec  5 21:29:27.637: INFO: Created: latency-svc-w8nrx
Dec  5 21:29:27.674: INFO: Got endpoints: latency-svc-pf4m4 [758.947862ms]
Dec  5 21:29:27.696: INFO: Created: latency-svc-55j2s
Dec  5 21:29:27.714: INFO: Got endpoints: latency-svc-4pr67 [748.470278ms]
Dec  5 21:29:27.739: INFO: Created: latency-svc-k4mw7
Dec  5 21:29:27.766: INFO: Got endpoints: latency-svc-mrqnx [750.403606ms]
Dec  5 21:29:27.792: INFO: Created: latency-svc-4t9jg
Dec  5 21:29:27.815: INFO: Got endpoints: latency-svc-wlkzc [750.423843ms]
Dec  5 21:29:27.838: INFO: Created: latency-svc-bzdxx
Dec  5 21:29:27.865: INFO: Got endpoints: latency-svc-9dcx2 [745.049881ms]
Dec  5 21:29:27.892: INFO: Created: latency-svc-5h47v
Dec  5 21:29:27.914: INFO: Got endpoints: latency-svc-jn58f [750.370539ms]
Dec  5 21:29:27.942: INFO: Created: latency-svc-ltnsp
Dec  5 21:29:27.965: INFO: Got endpoints: latency-svc-bwwzw [746.125473ms]
Dec  5 21:29:27.989: INFO: Created: latency-svc-s8gct
Dec  5 21:29:28.015: INFO: Got endpoints: latency-svc-z2mzm [749.588313ms]
Dec  5 21:29:28.039: INFO: Created: latency-svc-dn2sx
Dec  5 21:29:28.065: INFO: Got endpoints: latency-svc-gtpc5 [748.14408ms]
Dec  5 21:29:28.086: INFO: Created: latency-svc-xvc5p
Dec  5 21:29:28.114: INFO: Got endpoints: latency-svc-72262 [749.413606ms]
Dec  5 21:29:28.140: INFO: Created: latency-svc-xxlz5
Dec  5 21:29:28.169: INFO: Got endpoints: latency-svc-2rzcd [753.972823ms]
Dec  5 21:29:28.191: INFO: Created: latency-svc-9nsld
Dec  5 21:29:28.214: INFO: Got endpoints: latency-svc-5s8xr [749.679201ms]
Dec  5 21:29:28.237: INFO: Created: latency-svc-qkx5w
Dec  5 21:29:28.265: INFO: Got endpoints: latency-svc-ftrs9 [751.052721ms]
Dec  5 21:29:28.287: INFO: Created: latency-svc-v6mp7
Dec  5 21:29:28.316: INFO: Got endpoints: latency-svc-6kdfb [748.708167ms]
Dec  5 21:29:28.339: INFO: Created: latency-svc-8ql4k
Dec  5 21:29:28.365: INFO: Got endpoints: latency-svc-w8nrx [750.22387ms]
Dec  5 21:29:28.392: INFO: Created: latency-svc-t8lmk
Dec  5 21:29:28.414: INFO: Got endpoints: latency-svc-55j2s [739.460152ms]
Dec  5 21:29:28.436: INFO: Created: latency-svc-52pfq
Dec  5 21:29:28.464: INFO: Got endpoints: latency-svc-k4mw7 [750.033736ms]
Dec  5 21:29:28.487: INFO: Created: latency-svc-rg9nc
Dec  5 21:29:28.515: INFO: Got endpoints: latency-svc-4t9jg [749.314831ms]
Dec  5 21:29:28.552: INFO: Created: latency-svc-gmrk8
Dec  5 21:29:28.565: INFO: Got endpoints: latency-svc-bzdxx [750.133115ms]
Dec  5 21:29:28.591: INFO: Created: latency-svc-c6bgn
Dec  5 21:29:28.615: INFO: Got endpoints: latency-svc-5h47v [749.502609ms]
Dec  5 21:29:28.641: INFO: Created: latency-svc-v22pq
Dec  5 21:29:28.665: INFO: Got endpoints: latency-svc-ltnsp [750.097046ms]
Dec  5 21:29:28.690: INFO: Created: latency-svc-8sqkx
Dec  5 21:29:28.717: INFO: Got endpoints: latency-svc-s8gct [752.253493ms]
Dec  5 21:29:28.746: INFO: Created: latency-svc-lws56
Dec  5 21:29:28.764: INFO: Got endpoints: latency-svc-dn2sx [749.244154ms]
Dec  5 21:29:28.789: INFO: Created: latency-svc-nhcwt
Dec  5 21:29:28.815: INFO: Got endpoints: latency-svc-xvc5p [750.375251ms]
Dec  5 21:29:28.854: INFO: Created: latency-svc-ts7rb
Dec  5 21:29:28.866: INFO: Got endpoints: latency-svc-xxlz5 [752.212921ms]
Dec  5 21:29:28.908: INFO: Created: latency-svc-b8xqt
Dec  5 21:29:28.915: INFO: Got endpoints: latency-svc-9nsld [746.518146ms]
Dec  5 21:29:28.939: INFO: Created: latency-svc-4x4vr
Dec  5 21:29:28.965: INFO: Got endpoints: latency-svc-qkx5w [751.107708ms]
Dec  5 21:29:28.986: INFO: Created: latency-svc-wtqlb
Dec  5 21:29:29.015: INFO: Got endpoints: latency-svc-v6mp7 [749.99015ms]
Dec  5 21:29:29.041: INFO: Created: latency-svc-jzwdf
Dec  5 21:29:29.066: INFO: Got endpoints: latency-svc-8ql4k [750.223005ms]
Dec  5 21:29:29.088: INFO: Created: latency-svc-4d4cc
Dec  5 21:29:29.114: INFO: Got endpoints: latency-svc-t8lmk [748.854774ms]
Dec  5 21:29:29.143: INFO: Created: latency-svc-srlct
Dec  5 21:29:29.165: INFO: Got endpoints: latency-svc-52pfq [750.57562ms]
Dec  5 21:29:29.187: INFO: Created: latency-svc-ljk4b
Dec  5 21:29:29.216: INFO: Got endpoints: latency-svc-rg9nc [751.142661ms]
Dec  5 21:29:29.242: INFO: Created: latency-svc-jnwdb
Dec  5 21:29:29.265: INFO: Got endpoints: latency-svc-gmrk8 [749.742987ms]
Dec  5 21:29:29.336: INFO: Got endpoints: latency-svc-c6bgn [770.23626ms]
Dec  5 21:29:29.357: INFO: Created: latency-svc-mwk2v
Dec  5 21:29:29.365: INFO: Got endpoints: latency-svc-v22pq [750.304412ms]
Dec  5 21:29:29.369: INFO: Created: latency-svc-vzzf7
Dec  5 21:29:29.388: INFO: Created: latency-svc-xrkz5
Dec  5 21:29:29.415: INFO: Got endpoints: latency-svc-8sqkx [750.496504ms]
Dec  5 21:29:29.439: INFO: Created: latency-svc-gf9r7
Dec  5 21:29:29.465: INFO: Got endpoints: latency-svc-lws56 [747.715175ms]
Dec  5 21:29:29.486: INFO: Created: latency-svc-chnjp
Dec  5 21:29:29.514: INFO: Got endpoints: latency-svc-nhcwt [749.825771ms]
Dec  5 21:29:29.537: INFO: Created: latency-svc-wt2zf
Dec  5 21:29:29.566: INFO: Got endpoints: latency-svc-ts7rb [750.951851ms]
Dec  5 21:29:29.595: INFO: Created: latency-svc-dgg87
Dec  5 21:29:29.614: INFO: Got endpoints: latency-svc-b8xqt [747.857713ms]
Dec  5 21:29:29.639: INFO: Created: latency-svc-45fdr
Dec  5 21:29:29.666: INFO: Got endpoints: latency-svc-4x4vr [750.361104ms]
Dec  5 21:29:29.689: INFO: Created: latency-svc-8dz5d
Dec  5 21:29:29.715: INFO: Got endpoints: latency-svc-wtqlb [749.330468ms]
Dec  5 21:29:29.741: INFO: Created: latency-svc-6mg4w
Dec  5 21:29:29.768: INFO: Got endpoints: latency-svc-jzwdf [753.270448ms]
Dec  5 21:29:29.799: INFO: Created: latency-svc-kbhhl
Dec  5 21:29:29.815: INFO: Got endpoints: latency-svc-4d4cc [749.264875ms]
Dec  5 21:29:29.866: INFO: Got endpoints: latency-svc-srlct [751.500013ms]
Dec  5 21:29:29.867: INFO: Created: latency-svc-6c9gc
Dec  5 21:29:29.894: INFO: Created: latency-svc-mn7dn
Dec  5 21:29:29.916: INFO: Got endpoints: latency-svc-ljk4b [750.508955ms]
Dec  5 21:29:29.939: INFO: Created: latency-svc-86jvd
Dec  5 21:29:29.964: INFO: Got endpoints: latency-svc-jnwdb [748.234469ms]
Dec  5 21:29:29.989: INFO: Created: latency-svc-62gd2
Dec  5 21:29:30.015: INFO: Got endpoints: latency-svc-mwk2v [750.19577ms]
Dec  5 21:29:30.037: INFO: Created: latency-svc-mf254
Dec  5 21:29:30.073: INFO: Got endpoints: latency-svc-vzzf7 [737.791011ms]
Dec  5 21:29:30.101: INFO: Created: latency-svc-8vlqm
Dec  5 21:29:30.115: INFO: Got endpoints: latency-svc-xrkz5 [750.087772ms]
Dec  5 21:29:30.145: INFO: Created: latency-svc-2xdfk
Dec  5 21:29:30.165: INFO: Got endpoints: latency-svc-gf9r7 [749.217226ms]
Dec  5 21:29:30.236: INFO: Got endpoints: latency-svc-chnjp [770.888491ms]
Dec  5 21:29:30.265: INFO: Got endpoints: latency-svc-wt2zf [751.065802ms]
Dec  5 21:29:30.287: INFO: Created: latency-svc-g75qk
Dec  5 21:29:30.304: INFO: Created: latency-svc-mttvg
Dec  5 21:29:30.316: INFO: Got endpoints: latency-svc-dgg87 [749.422435ms]
Dec  5 21:29:30.322: INFO: Created: latency-svc-7r799
Dec  5 21:29:30.342: INFO: Created: latency-svc-pd2nr
Dec  5 21:29:30.365: INFO: Got endpoints: latency-svc-45fdr [750.439205ms]
Dec  5 21:29:30.390: INFO: Created: latency-svc-fjn7s
Dec  5 21:29:30.415: INFO: Got endpoints: latency-svc-8dz5d [749.10533ms]
Dec  5 21:29:30.437: INFO: Created: latency-svc-2g9rd
Dec  5 21:29:30.465: INFO: Got endpoints: latency-svc-6mg4w [750.240245ms]
Dec  5 21:29:30.486: INFO: Created: latency-svc-xk2dv
Dec  5 21:29:30.517: INFO: Got endpoints: latency-svc-kbhhl [749.278891ms]
Dec  5 21:29:30.545: INFO: Created: latency-svc-mxqjd
Dec  5 21:29:30.570: INFO: Got endpoints: latency-svc-6c9gc [754.493383ms]
Dec  5 21:29:30.592: INFO: Created: latency-svc-8lf6w
Dec  5 21:29:30.616: INFO: Got endpoints: latency-svc-mn7dn [750.789497ms]
Dec  5 21:29:30.639: INFO: Created: latency-svc-zpj8b
Dec  5 21:29:30.664: INFO: Got endpoints: latency-svc-86jvd [748.603976ms]
Dec  5 21:29:30.696: INFO: Created: latency-svc-rjw9r
Dec  5 21:29:30.714: INFO: Got endpoints: latency-svc-62gd2 [750.369301ms]
Dec  5 21:29:30.743: INFO: Created: latency-svc-bn47f
Dec  5 21:29:30.764: INFO: Got endpoints: latency-svc-mf254 [749.02097ms]
Dec  5 21:29:30.863: INFO: Got endpoints: latency-svc-8vlqm [789.76157ms]
Dec  5 21:29:30.873: INFO: Got endpoints: latency-svc-2xdfk [757.045383ms]
Dec  5 21:29:30.876: INFO: Created: latency-svc-f9r8s
Dec  5 21:29:30.903: INFO: Created: latency-svc-t9jgv
Dec  5 21:29:30.915: INFO: Got endpoints: latency-svc-g75qk [749.772728ms]
Dec  5 21:29:30.917: INFO: Created: latency-svc-nn2kc
Dec  5 21:29:30.944: INFO: Created: latency-svc-kjc4d
Dec  5 21:29:30.965: INFO: Got endpoints: latency-svc-mttvg [729.009821ms]
Dec  5 21:29:30.987: INFO: Created: latency-svc-z7dcj
Dec  5 21:29:31.019: INFO: Got endpoints: latency-svc-7r799 [753.573497ms]
Dec  5 21:29:31.048: INFO: Created: latency-svc-dckbv
Dec  5 21:29:31.067: INFO: Got endpoints: latency-svc-pd2nr [751.34602ms]
Dec  5 21:29:31.097: INFO: Created: latency-svc-lxjlm
Dec  5 21:29:31.114: INFO: Got endpoints: latency-svc-fjn7s [749.367863ms]
Dec  5 21:29:31.138: INFO: Created: latency-svc-88q5j
Dec  5 21:29:31.165: INFO: Got endpoints: latency-svc-2g9rd [749.973326ms]
Dec  5 21:29:31.190: INFO: Created: latency-svc-wfmpz
Dec  5 21:29:31.215: INFO: Got endpoints: latency-svc-xk2dv [749.884119ms]
Dec  5 21:29:31.241: INFO: Created: latency-svc-427bs
Dec  5 21:29:31.267: INFO: Got endpoints: latency-svc-mxqjd [750.050696ms]
Dec  5 21:29:31.290: INFO: Created: latency-svc-5c9t7
Dec  5 21:29:31.314: INFO: Got endpoints: latency-svc-8lf6w [744.529655ms]
Dec  5 21:29:31.347: INFO: Created: latency-svc-qj76f
Dec  5 21:29:31.366: INFO: Got endpoints: latency-svc-zpj8b [749.172694ms]
Dec  5 21:29:31.395: INFO: Created: latency-svc-2rxgr
Dec  5 21:29:31.415: INFO: Got endpoints: latency-svc-rjw9r [750.483596ms]
Dec  5 21:29:31.436: INFO: Created: latency-svc-mncb8
Dec  5 21:29:31.466: INFO: Got endpoints: latency-svc-bn47f [751.509062ms]
Dec  5 21:29:31.495: INFO: Created: latency-svc-csw7l
Dec  5 21:29:31.515: INFO: Got endpoints: latency-svc-f9r8s [750.379886ms]
Dec  5 21:29:31.542: INFO: Created: latency-svc-w7jhr
Dec  5 21:29:31.567: INFO: Got endpoints: latency-svc-t9jgv [703.824471ms]
Dec  5 21:29:31.591: INFO: Created: latency-svc-kgrtg
Dec  5 21:29:31.615: INFO: Got endpoints: latency-svc-nn2kc [741.771539ms]
Dec  5 21:29:31.635: INFO: Created: latency-svc-whvvd
Dec  5 21:29:31.665: INFO: Got endpoints: latency-svc-kjc4d [749.794074ms]
Dec  5 21:29:31.688: INFO: Created: latency-svc-4vjv9
Dec  5 21:29:31.718: INFO: Got endpoints: latency-svc-z7dcj [752.839079ms]
Dec  5 21:29:31.746: INFO: Created: latency-svc-9b9tn
Dec  5 21:29:31.764: INFO: Got endpoints: latency-svc-dckbv [745.284188ms]
Dec  5 21:29:31.792: INFO: Created: latency-svc-qks8c
Dec  5 21:29:31.815: INFO: Got endpoints: latency-svc-lxjlm [748.019638ms]
Dec  5 21:29:31.843: INFO: Created: latency-svc-8lzpm
Dec  5 21:29:31.865: INFO: Got endpoints: latency-svc-88q5j [750.636765ms]
Dec  5 21:29:31.893: INFO: Created: latency-svc-q69rb
Dec  5 21:29:31.916: INFO: Got endpoints: latency-svc-wfmpz [750.448454ms]
Dec  5 21:29:31.940: INFO: Created: latency-svc-5lgjc
Dec  5 21:29:31.969: INFO: Got endpoints: latency-svc-427bs [753.299337ms]
Dec  5 21:29:31.994: INFO: Created: latency-svc-r72f8
Dec  5 21:29:32.016: INFO: Got endpoints: latency-svc-5c9t7 [748.410344ms]
Dec  5 21:29:32.045: INFO: Created: latency-svc-v5wn4
Dec  5 21:29:32.067: INFO: Got endpoints: latency-svc-qj76f [752.620346ms]
Dec  5 21:29:32.099: INFO: Created: latency-svc-d4jvx
Dec  5 21:29:32.115: INFO: Got endpoints: latency-svc-2rxgr [749.571997ms]
Dec  5 21:29:32.138: INFO: Created: latency-svc-lxstt
Dec  5 21:29:32.169: INFO: Got endpoints: latency-svc-mncb8 [753.430744ms]
Dec  5 21:29:32.195: INFO: Created: latency-svc-8w8ml
Dec  5 21:29:32.214: INFO: Got endpoints: latency-svc-csw7l [748.289636ms]
Dec  5 21:29:32.253: INFO: Created: latency-svc-m6p7l
Dec  5 21:29:32.266: INFO: Got endpoints: latency-svc-w7jhr [750.908098ms]
Dec  5 21:29:32.316: INFO: Got endpoints: latency-svc-kgrtg [748.780743ms]
Dec  5 21:29:32.366: INFO: Got endpoints: latency-svc-whvvd [751.258784ms]
Dec  5 21:29:32.415: INFO: Got endpoints: latency-svc-4vjv9 [750.49853ms]
Dec  5 21:29:32.466: INFO: Got endpoints: latency-svc-9b9tn [747.981659ms]
Dec  5 21:29:32.515: INFO: Got endpoints: latency-svc-qks8c [750.126556ms]
Dec  5 21:29:32.565: INFO: Got endpoints: latency-svc-8lzpm [750.106931ms]
Dec  5 21:29:32.615: INFO: Got endpoints: latency-svc-q69rb [749.572584ms]
Dec  5 21:29:32.665: INFO: Got endpoints: latency-svc-5lgjc [749.162964ms]
Dec  5 21:29:32.716: INFO: Got endpoints: latency-svc-r72f8 [746.700676ms]
Dec  5 21:29:32.766: INFO: Got endpoints: latency-svc-v5wn4 [749.634533ms]
Dec  5 21:29:32.818: INFO: Got endpoints: latency-svc-d4jvx [750.786023ms]
Dec  5 21:29:32.866: INFO: Got endpoints: latency-svc-lxstt [750.896642ms]
Dec  5 21:29:32.918: INFO: Got endpoints: latency-svc-8w8ml [749.145187ms]
Dec  5 21:29:32.965: INFO: Got endpoints: latency-svc-m6p7l [750.47418ms]
Dec  5 21:29:32.965: INFO: Latencies: [41.859548ms 89.657743ms 102.962197ms 117.247817ms 132.547349ms 150.913266ms 170.64791ms 186.399222ms 208.900594ms 212.096618ms 213.282039ms 213.384058ms 213.731345ms 214.008838ms 214.625826ms 214.636694ms 214.637399ms 214.701926ms 217.028591ms 217.663268ms 218.426864ms 220.89957ms 223.309692ms 225.071124ms 225.217398ms 229.652507ms 239.937984ms 241.029632ms 241.303396ms 242.345891ms 243.315203ms 254.549554ms 256.511647ms 256.964606ms 261.747993ms 261.999935ms 263.905077ms 263.933845ms 264.097267ms 270.171941ms 270.967971ms 289.265874ms 296.749872ms 317.540691ms 334.462434ms 336.415392ms 368.109703ms 405.060905ms 441.746302ms 475.065691ms 511.84769ms 546.958528ms 582.326851ms 620.080634ms 651.39419ms 693.522402ms 703.824471ms 727.885751ms 729.009821ms 730.146325ms 736.084481ms 737.791011ms 739.460152ms 741.559269ms 741.771539ms 742.231023ms 744.529655ms 744.615795ms 745.049881ms 745.284188ms 746.125473ms 746.131385ms 746.518146ms 746.700676ms 746.731424ms 747.715175ms 747.857713ms 747.981659ms 748.019638ms 748.14408ms 748.175511ms 748.202169ms 748.234469ms 748.289636ms 748.410344ms 748.470278ms 748.531639ms 748.552173ms 748.603976ms 748.708167ms 748.780743ms 748.821905ms 748.854774ms 748.887239ms 748.89822ms 748.969113ms 748.977595ms 749.02097ms 749.10533ms 749.145187ms 749.162964ms 749.172694ms 749.217226ms 749.23386ms 749.244154ms 749.264875ms 749.278891ms 749.314831ms 749.330468ms 749.365929ms 749.367863ms 749.413606ms 749.422435ms 749.432784ms 749.502609ms 749.571997ms 749.572584ms 749.588313ms 749.634533ms 749.673879ms 749.679201ms 749.742987ms 749.772728ms 749.793801ms 749.794074ms 749.825771ms 749.884119ms 749.900916ms 749.973326ms 749.98401ms 749.99015ms 750.033736ms 750.050696ms 750.087772ms 750.097046ms 750.106931ms 750.126556ms 750.133115ms 750.19577ms 750.223005ms 750.22387ms 750.240245ms 750.304412ms 750.361104ms 750.369301ms 750.370539ms 750.375251ms 750.379886ms 750.397771ms 750.403606ms 750.423843ms 750.439205ms 750.448454ms 750.47418ms 750.483596ms 750.496504ms 750.49853ms 750.508955ms 750.554886ms 750.556784ms 750.57562ms 750.636765ms 750.748316ms 750.773426ms 750.786023ms 750.789497ms 750.849484ms 750.896642ms 750.908098ms 750.951851ms 751.052721ms 751.065802ms 751.107708ms 751.142661ms 751.258784ms 751.34602ms 751.500013ms 751.509062ms 752.07037ms 752.212921ms 752.253493ms 752.347447ms 752.620346ms 752.839079ms 753.270448ms 753.299337ms 753.415582ms 753.430744ms 753.573497ms 753.972823ms 754.169723ms 754.493383ms 757.045383ms 757.226353ms 758.947862ms 768.01829ms 770.23626ms 770.888491ms 770.917613ms 789.76157ms]
Dec  5 21:29:32.965: INFO: 50 %ile: 749.162964ms
Dec  5 21:29:32.965: INFO: 90 %ile: 752.253493ms
Dec  5 21:29:32.965: INFO: 99 %ile: 770.917613ms
Dec  5 21:29:32.966: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:29:32.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-vb84l" for this suite.
Dec  5 21:29:51.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:29:51.315: INFO: namespace: e2e-tests-svc-latency-vb84l, resource: bindings, ignored listing per whitelist
Dec  5 21:29:51.561: INFO: namespace e2e-tests-svc-latency-vb84l deletion completed in 18.578774327s

• [SLOW TEST:29.717 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:29:51.561: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-7sth6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Dec  5 21:29:51.874: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  5 21:29:51.896: INFO: Waiting for terminating namespaces to be deleted...
Dec  5 21:29:51.906: INFO: 
Logging pods the kubelet thinks is on node 10.191.0.134 before test
Dec  5 21:29:51.949: INFO: ibm-master-proxy-static-10.191.0.134 from kube-system started at <nil> (0 container statuses recorded)
Dec  5 21:29:51.949: INFO: kube-dns-autoscaler-587cd5cd44-wtn48 from kube-system started at 2018-12-05 20:13:25 +0000 UTC (1 container statuses recorded)
Dec  5 21:29:51.950: INFO: 	Container autoscaler ready: true, restart count 0
Dec  5 21:29:51.950: INFO: ibm-storage-watcher-d7fb6f996-sw7ft from kube-system started at 2018-12-05 20:13:25 +0000 UTC (1 container statuses recorded)
Dec  5 21:29:51.950: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Dec  5 21:29:51.950: INFO: ibm-file-plugin-66d9565b46-pmd5k from kube-system started at 2018-12-05 20:13:25 +0000 UTC (1 container statuses recorded)
Dec  5 21:29:51.950: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Dec  5 21:29:51.950: INFO: calico-node-hjfvw from kube-system started at 2018-12-05 20:13:25 +0000 UTC (2 container statuses recorded)
Dec  5 21:29:51.950: INFO: 	Container calico-node ready: true, restart count 0
Dec  5 21:29:51.950: INFO: 	Container install-cni ready: true, restart count 0
Dec  5 21:29:51.950: INFO: sonobuoy-systemd-logs-daemon-set-9347e99d64a449f0-2fct4 from heptio-sonobuoy started at 2018-12-05 20:51:14 +0000 UTC (2 container statuses recorded)
Dec  5 21:29:51.951: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec  5 21:29:51.951: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  5 21:29:51.951: INFO: ibm-kube-fluentd-kszbp from kube-system started at 2018-12-05 20:19:21 +0000 UTC (1 container statuses recorded)
Dec  5 21:29:51.951: INFO: 	Container fluentd ready: true, restart count 0
Dec  5 21:29:51.951: INFO: calico-kube-controllers-5c699798bc-szf68 from kube-system started at 2018-12-05 20:13:25 +0000 UTC (1 container statuses recorded)
Dec  5 21:29:51.951: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec  5 21:29:51.951: INFO: kube-dns-amd64-fddfcc69-drvmh from kube-system started at 2018-12-05 20:13:25 +0000 UTC (3 container statuses recorded)
Dec  5 21:29:51.951: INFO: 	Container dnsmasq ready: true, restart count 0
Dec  5 21:29:51.952: INFO: 	Container kubedns ready: true, restart count 0
Dec  5 21:29:51.952: INFO: 	Container sidecar ready: true, restart count 0
Dec  5 21:29:51.952: INFO: kubernetes-dashboard-b6b5cbdb4-n88tm from kube-system started at 2018-12-05 20:13:25 +0000 UTC (1 container statuses recorded)
Dec  5 21:29:51.952: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec  5 21:29:51.952: INFO: vpn-65599665d9-g4r5v from kube-system started at 2018-12-05 20:13:25 +0000 UTC (1 container statuses recorded)
Dec  5 21:29:51.952: INFO: 	Container vpn ready: true, restart count 0
Dec  5 21:29:51.952: INFO: kube-dns-amd64-fddfcc69-ph96f from kube-system started at 2018-12-05 20:13:55 +0000 UTC (3 container statuses recorded)
Dec  5 21:29:51.952: INFO: 	Container dnsmasq ready: true, restart count 0
Dec  5 21:29:51.952: INFO: 	Container kubedns ready: true, restart count 0
Dec  5 21:29:51.952: INFO: 	Container sidecar ready: true, restart count 0
Dec  5 21:29:51.952: INFO: ibm-keepalived-watcher-c8gfz from kube-system started at 2018-12-05 20:13:25 +0000 UTC (1 container statuses recorded)
Dec  5 21:29:51.953: INFO: 	Container keepalived-watcher ready: true, restart count 0
Dec  5 21:29:51.953: INFO: 
Logging pods the kubelet thinks is on node 10.191.0.147 before test
Dec  5 21:29:51.994: INFO: ibm-master-proxy-static-10.191.0.147 from kube-system started at <nil> (0 container statuses recorded)
Dec  5 21:29:51.995: INFO: ibm-keepalived-watcher-8sx6s from kube-system started at 2018-12-05 20:13:32 +0000 UTC (1 container statuses recorded)
Dec  5 21:29:51.995: INFO: 	Container keepalived-watcher ready: true, restart count 0
Dec  5 21:29:51.995: INFO: ibm-cloud-provider-ip-169-61-124-166-74499dcdfd-4qnpc from ibm-system started at 2018-12-05 20:17:26 +0000 UTC (1 container statuses recorded)
Dec  5 21:29:51.995: INFO: 	Container ibm-cloud-provider-ip-169-61-124-166 ready: true, restart count 0
Dec  5 21:29:51.995: INFO: public-cr13c0509290e4443aab67bdb06ca2f6df-alb1-8576b8658-28rzk from kube-system started at 2018-12-05 20:18:36 +0000 UTC (4 container statuses recorded)
Dec  5 21:29:51.995: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Dec  5 21:29:51.995: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Dec  5 21:29:51.996: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Dec  5 21:29:51.996: INFO: 	Container nginx-ingress ready: true, restart count 0
Dec  5 21:29:51.996: INFO: ibm-kube-fluentd-zkwzj from kube-system started at 2018-12-05 20:19:21 +0000 UTC (1 container statuses recorded)
Dec  5 21:29:51.996: INFO: 	Container fluentd ready: true, restart count 0
Dec  5 21:29:51.996: INFO: test-k8s-e2e-pvg-master-verification from default started at 2018-12-05 20:50:44 +0000 UTC (1 container statuses recorded)
Dec  5 21:29:51.996: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Dec  5 21:29:51.996: INFO: calico-node-xgzvj from kube-system started at 2018-12-05 20:13:32 +0000 UTC (2 container statuses recorded)
Dec  5 21:29:51.996: INFO: 	Container calico-node ready: true, restart count 0
Dec  5 21:29:51.996: INFO: 	Container install-cni ready: true, restart count 0
Dec  5 21:29:51.996: INFO: sonobuoy-e2e-job-bf9289e3f16942e1 from heptio-sonobuoy started at 2018-12-05 20:51:14 +0000 UTC (2 container statuses recorded)
Dec  5 21:29:51.997: INFO: 	Container e2e ready: true, restart count 0
Dec  5 21:29:51.997: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  5 21:29:51.997: INFO: sonobuoy-systemd-logs-daemon-set-9347e99d64a449f0-dnc6s from heptio-sonobuoy started at 2018-12-05 20:51:14 +0000 UTC (2 container statuses recorded)
Dec  5 21:29:51.997: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec  5 21:29:51.997: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  5 21:29:51.997: INFO: 
Logging pods the kubelet thinks is on node 10.191.0.150 before test
Dec  5 21:29:52.033: INFO: ibm-master-proxy-static-10.191.0.150 from kube-system started at <nil> (0 container statuses recorded)
Dec  5 21:29:52.033: INFO: calico-node-x9v6g from kube-system started at 2018-12-05 20:13:31 +0000 UTC (2 container statuses recorded)
Dec  5 21:29:52.033: INFO: 	Container calico-node ready: true, restart count 0
Dec  5 21:29:52.033: INFO: 	Container install-cni ready: true, restart count 0
Dec  5 21:29:52.033: INFO: ibm-kube-fluentd-qswkt from kube-system started at 2018-12-05 20:19:21 +0000 UTC (1 container statuses recorded)
Dec  5 21:29:52.033: INFO: 	Container fluentd ready: true, restart count 0
Dec  5 21:29:52.033: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-05 20:51:09 +0000 UTC (1 container statuses recorded)
Dec  5 21:29:52.033: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  5 21:29:52.033: INFO: ibm-keepalived-watcher-fpp78 from kube-system started at 2018-12-05 20:13:31 +0000 UTC (1 container statuses recorded)
Dec  5 21:29:52.033: INFO: 	Container keepalived-watcher ready: true, restart count 0
Dec  5 21:29:52.033: INFO: metrics-server-5b95c9cc4c-hjph5 from kube-system started at 2018-12-05 20:14:11 +0000 UTC (2 container statuses recorded)
Dec  5 21:29:52.033: INFO: 	Container metrics-server ready: true, restart count 0
Dec  5 21:29:52.033: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Dec  5 21:29:52.033: INFO: ibm-cloud-provider-ip-169-61-124-166-74499dcdfd-rcg2p from ibm-system started at 2018-12-05 20:17:26 +0000 UTC (1 container statuses recorded)
Dec  5 21:29:52.033: INFO: 	Container ibm-cloud-provider-ip-169-61-124-166 ready: true, restart count 0
Dec  5 21:29:52.033: INFO: public-cr13c0509290e4443aab67bdb06ca2f6df-alb1-8576b8658-lhtpj from kube-system started at 2018-12-05 20:18:36 +0000 UTC (4 container statuses recorded)
Dec  5 21:29:52.033: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Dec  5 21:29:52.033: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Dec  5 21:29:52.033: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Dec  5 21:29:52.033: INFO: 	Container nginx-ingress ready: true, restart count 0
Dec  5 21:29:52.033: INFO: sonobuoy-systemd-logs-daemon-set-9347e99d64a449f0-bpd58 from heptio-sonobuoy started at 2018-12-05 20:51:14 +0000 UTC (2 container statuses recorded)
Dec  5 21:29:52.033: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec  5 21:29:52.033: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node 10.191.0.134
STEP: verifying the node has the label node 10.191.0.147
STEP: verifying the node has the label node 10.191.0.150
Dec  5 21:29:52.190: INFO: Pod test-k8s-e2e-pvg-master-verification requesting resource cpu=0m on Node 10.191.0.147
Dec  5 21:29:52.190: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.191.0.150
Dec  5 21:29:52.190: INFO: Pod sonobuoy-e2e-job-bf9289e3f16942e1 requesting resource cpu=0m on Node 10.191.0.147
Dec  5 21:29:52.190: INFO: Pod sonobuoy-systemd-logs-daemon-set-9347e99d64a449f0-2fct4 requesting resource cpu=0m on Node 10.191.0.134
Dec  5 21:29:52.190: INFO: Pod sonobuoy-systemd-logs-daemon-set-9347e99d64a449f0-bpd58 requesting resource cpu=0m on Node 10.191.0.150
Dec  5 21:29:52.190: INFO: Pod sonobuoy-systemd-logs-daemon-set-9347e99d64a449f0-dnc6s requesting resource cpu=0m on Node 10.191.0.147
Dec  5 21:29:52.190: INFO: Pod ibm-cloud-provider-ip-169-61-124-166-74499dcdfd-4qnpc requesting resource cpu=5m on Node 10.191.0.147
Dec  5 21:29:52.190: INFO: Pod ibm-cloud-provider-ip-169-61-124-166-74499dcdfd-rcg2p requesting resource cpu=5m on Node 10.191.0.150
Dec  5 21:29:52.190: INFO: Pod calico-kube-controllers-5c699798bc-szf68 requesting resource cpu=10m on Node 10.191.0.134
Dec  5 21:29:52.190: INFO: Pod calico-node-hjfvw requesting resource cpu=255m on Node 10.191.0.134
Dec  5 21:29:52.190: INFO: Pod calico-node-x9v6g requesting resource cpu=255m on Node 10.191.0.150
Dec  5 21:29:52.190: INFO: Pod calico-node-xgzvj requesting resource cpu=255m on Node 10.191.0.147
Dec  5 21:29:52.190: INFO: Pod ibm-file-plugin-66d9565b46-pmd5k requesting resource cpu=50m on Node 10.191.0.134
Dec  5 21:29:52.190: INFO: Pod ibm-keepalived-watcher-8sx6s requesting resource cpu=5m on Node 10.191.0.147
Dec  5 21:29:52.190: INFO: Pod ibm-keepalived-watcher-c8gfz requesting resource cpu=5m on Node 10.191.0.134
Dec  5 21:29:52.190: INFO: Pod ibm-keepalived-watcher-fpp78 requesting resource cpu=5m on Node 10.191.0.150
Dec  5 21:29:52.190: INFO: Pod ibm-kube-fluentd-kszbp requesting resource cpu=25m on Node 10.191.0.134
Dec  5 21:29:52.190: INFO: Pod ibm-kube-fluentd-qswkt requesting resource cpu=25m on Node 10.191.0.150
Dec  5 21:29:52.190: INFO: Pod ibm-kube-fluentd-zkwzj requesting resource cpu=25m on Node 10.191.0.147
Dec  5 21:29:52.190: INFO: Pod ibm-master-proxy-static-10.191.0.134 requesting resource cpu=25m on Node 10.191.0.134
Dec  5 21:29:52.190: INFO: Pod ibm-master-proxy-static-10.191.0.147 requesting resource cpu=25m on Node 10.191.0.147
Dec  5 21:29:52.190: INFO: Pod ibm-master-proxy-static-10.191.0.150 requesting resource cpu=25m on Node 10.191.0.150
Dec  5 21:29:52.190: INFO: Pod ibm-storage-watcher-d7fb6f996-sw7ft requesting resource cpu=50m on Node 10.191.0.134
Dec  5 21:29:52.190: INFO: Pod kube-dns-amd64-fddfcc69-drvmh requesting resource cpu=260m on Node 10.191.0.134
Dec  5 21:29:52.190: INFO: Pod kube-dns-amd64-fddfcc69-ph96f requesting resource cpu=260m on Node 10.191.0.134
Dec  5 21:29:52.190: INFO: Pod kube-dns-autoscaler-587cd5cd44-wtn48 requesting resource cpu=20m on Node 10.191.0.134
Dec  5 21:29:52.190: INFO: Pod kubernetes-dashboard-b6b5cbdb4-n88tm requesting resource cpu=50m on Node 10.191.0.134
Dec  5 21:29:52.190: INFO: Pod metrics-server-5b95c9cc4c-hjph5 requesting resource cpu=53m on Node 10.191.0.150
Dec  5 21:29:52.190: INFO: Pod public-cr13c0509290e4443aab67bdb06ca2f6df-alb1-8576b8658-28rzk requesting resource cpu=0m on Node 10.191.0.147
Dec  5 21:29:52.190: INFO: Pod public-cr13c0509290e4443aab67bdb06ca2f6df-alb1-8576b8658-lhtpj requesting resource cpu=0m on Node 10.191.0.150
Dec  5 21:29:52.191: INFO: Pod vpn-65599665d9-g4r5v requesting resource cpu=5m on Node 10.191.0.134
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6b0f1bd-f8d4-11e8-b962-c6dde3e93636.156d8d1a80c3da83], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-7sth6/filler-pod-e6b0f1bd-f8d4-11e8-b962-c6dde3e93636 to 10.191.0.134]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6b0f1bd-f8d4-11e8-b962-c6dde3e93636.156d8d1ab1a2bcbc], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6b0f1bd-f8d4-11e8-b962-c6dde3e93636.156d8d1b1baaf232], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6b0f1bd-f8d4-11e8-b962-c6dde3e93636.156d8d1b1e9d0416], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6b0f1bd-f8d4-11e8-b962-c6dde3e93636.156d8d1b282d3b81], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6b42cd2-f8d4-11e8-b962-c6dde3e93636.156d8d1a81d78502], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-7sth6/filler-pod-e6b42cd2-f8d4-11e8-b962-c6dde3e93636 to 10.191.0.147]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6b42cd2-f8d4-11e8-b962-c6dde3e93636.156d8d1ab06210e8], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6b42cd2-f8d4-11e8-b962-c6dde3e93636.156d8d1b1b3b35fc], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6b42cd2-f8d4-11e8-b962-c6dde3e93636.156d8d1b1de9583e], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6b42cd2-f8d4-11e8-b962-c6dde3e93636.156d8d1b288eaa0f], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6b691f4-f8d4-11e8-b962-c6dde3e93636.156d8d1a82ca3dfd], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-7sth6/filler-pod-e6b691f4-f8d4-11e8-b962-c6dde3e93636 to 10.191.0.150]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6b691f4-f8d4-11e8-b962-c6dde3e93636.156d8d1ab94c1e1d], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6b691f4-f8d4-11e8-b962-c6dde3e93636.156d8d1abc799a60], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6b691f4-f8d4-11e8-b962-c6dde3e93636.156d8d1ac4115eaa], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.156d8d1b744371d9], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 10.191.0.147
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.191.0.150
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.191.0.134
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:29:57.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-7sth6" for this suite.
Dec  5 21:30:05.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:30:05.849: INFO: namespace: e2e-tests-sched-pred-7sth6, resource: bindings, ignored listing per whitelist
Dec  5 21:30:05.944: INFO: namespace e2e-tests-sched-pred-7sth6 deletion completed in 8.479165262s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:14.383 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:30:05.946: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-68jf2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-ef1ca436-f8d4-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume configMaps
Dec  5 21:30:06.349: INFO: Waiting up to 5m0s for pod "pod-configmaps-ef1e3c68-f8d4-11e8-b962-c6dde3e93636" in namespace "e2e-tests-configmap-68jf2" to be "success or failure"
Dec  5 21:30:06.362: INFO: Pod "pod-configmaps-ef1e3c68-f8d4-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 12.790075ms
Dec  5 21:30:08.372: INFO: Pod "pod-configmaps-ef1e3c68-f8d4-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022590509s
STEP: Saw pod success
Dec  5 21:30:08.372: INFO: Pod "pod-configmaps-ef1e3c68-f8d4-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:30:08.380: INFO: Trying to get logs from node 10.191.0.150 pod pod-configmaps-ef1e3c68-f8d4-11e8-b962-c6dde3e93636 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 21:30:08.434: INFO: Waiting for pod pod-configmaps-ef1e3c68-f8d4-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:30:08.443: INFO: Pod pod-configmaps-ef1e3c68-f8d4-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:30:08.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-68jf2" for this suite.
Dec  5 21:30:14.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:30:14.685: INFO: namespace: e2e-tests-configmap-68jf2, resource: bindings, ignored listing per whitelist
Dec  5 21:30:14.988: INFO: namespace e2e-tests-configmap-68jf2 deletion completed in 6.451684185s

• [SLOW TEST:9.042 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:30:14.988: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-5c4gv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-f49b1eb6-f8d4-11e8-b962-c6dde3e93636
STEP: Creating configMap with name cm-test-opt-upd-f49b1efb-f8d4-11e8-b962-c6dde3e93636
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-f49b1eb6-f8d4-11e8-b962-c6dde3e93636
STEP: Updating configmap cm-test-opt-upd-f49b1efb-f8d4-11e8-b962-c6dde3e93636
STEP: Creating configMap with name cm-test-opt-create-f49b1f1a-f8d4-11e8-b962-c6dde3e93636
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:30:19.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5c4gv" for this suite.
Dec  5 21:30:43.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:30:44.209: INFO: namespace: e2e-tests-projected-5c4gv, resource: bindings, ignored listing per whitelist
Dec  5 21:30:44.330: INFO: namespace e2e-tests-projected-5c4gv deletion completed in 24.483458684s

• [SLOW TEST:29.342 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:30:44.330: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-q4wf6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-q4wf6
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  5 21:30:44.678: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  5 21:31:06.980: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.46.159:8080/dial?request=hostName&protocol=udp&host=172.30.110.22&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-q4wf6 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 21:31:06.980: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
Dec  5 21:31:07.213: INFO: Waiting for endpoints: map[]
Dec  5 21:31:07.223: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.46.159:8080/dial?request=hostName&protocol=udp&host=172.30.46.158&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-q4wf6 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 21:31:07.223: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
Dec  5 21:31:07.536: INFO: Waiting for endpoints: map[]
Dec  5 21:31:07.548: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.46.159:8080/dial?request=hostName&protocol=udp&host=172.30.248.118&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-q4wf6 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 21:31:07.548: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
Dec  5 21:31:07.775: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:31:07.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-q4wf6" for this suite.
Dec  5 21:31:31.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:31:31.900: INFO: namespace: e2e-tests-pod-network-test-q4wf6, resource: bindings, ignored listing per whitelist
Dec  5 21:31:32.351: INFO: namespace e2e-tests-pod-network-test-q4wf6 deletion completed in 24.561963902s

• [SLOW TEST:48.021 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:31:32.355: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-dccxf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1205 21:32:12.859153      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  5 21:32:12.859: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:32:12.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-dccxf" for this suite.
Dec  5 21:32:20.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:32:21.253: INFO: namespace: e2e-tests-gc-dccxf, resource: bindings, ignored listing per whitelist
Dec  5 21:32:21.599: INFO: namespace e2e-tests-gc-dccxf deletion completed in 8.663469234s

• [SLOW TEST:49.244 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:32:21.600: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-bvghc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Dec  5 21:32:21.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 create -f - --namespace=e2e-tests-kubectl-bvghc'
Dec  5 21:32:22.521: INFO: stderr: ""
Dec  5 21:32:22.521: INFO: stdout: "pod/pause created\n"
Dec  5 21:32:22.521: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec  5 21:32:22.521: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-bvghc" to be "running and ready"
Dec  5 21:32:22.532: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 10.519679ms
Dec  5 21:32:24.558: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.036896759s
Dec  5 21:32:24.558: INFO: Pod "pause" satisfied condition "running and ready"
Dec  5 21:32:24.558: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Dec  5 21:32:24.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-bvghc'
Dec  5 21:32:24.737: INFO: stderr: ""
Dec  5 21:32:24.737: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec  5 21:32:24.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pod pause -L testing-label --namespace=e2e-tests-kubectl-bvghc'
Dec  5 21:32:24.920: INFO: stderr: ""
Dec  5 21:32:24.920: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec  5 21:32:24.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 label pods pause testing-label- --namespace=e2e-tests-kubectl-bvghc'
Dec  5 21:32:25.070: INFO: stderr: ""
Dec  5 21:32:25.070: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec  5 21:32:25.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pod pause -L testing-label --namespace=e2e-tests-kubectl-bvghc'
Dec  5 21:32:25.240: INFO: stderr: ""
Dec  5 21:32:25.240: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Dec  5 21:32:25.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bvghc'
Dec  5 21:32:25.427: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 21:32:25.427: INFO: stdout: "pod \"pause\" force deleted\n"
Dec  5 21:32:25.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-bvghc'
Dec  5 21:32:25.664: INFO: stderr: "No resources found.\n"
Dec  5 21:32:25.664: INFO: stdout: ""
Dec  5 21:32:25.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods -l name=pause --namespace=e2e-tests-kubectl-bvghc -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  5 21:32:25.837: INFO: stderr: ""
Dec  5 21:32:25.837: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:32:25.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bvghc" for this suite.
Dec  5 21:32:31.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:32:32.319: INFO: namespace: e2e-tests-kubectl-bvghc, resource: bindings, ignored listing per whitelist
Dec  5 21:32:32.499: INFO: namespace e2e-tests-kubectl-bvghc deletion completed in 6.645321182s

• [SLOW TEST:10.900 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:32:32.502: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-x7h65
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-467fd2b9-f8d5-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume secrets
Dec  5 21:32:32.970: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-46827b07-f8d5-11e8-b962-c6dde3e93636" in namespace "e2e-tests-projected-x7h65" to be "success or failure"
Dec  5 21:32:33.035: INFO: Pod "pod-projected-secrets-46827b07-f8d5-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 65.813428ms
Dec  5 21:32:35.068: INFO: Pod "pod-projected-secrets-46827b07-f8d5-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.098156758s
STEP: Saw pod success
Dec  5 21:32:35.068: INFO: Pod "pod-projected-secrets-46827b07-f8d5-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:32:35.081: INFO: Trying to get logs from node 10.191.0.150 pod pod-projected-secrets-46827b07-f8d5-11e8-b962-c6dde3e93636 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  5 21:32:35.141: INFO: Waiting for pod pod-projected-secrets-46827b07-f8d5-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:32:35.151: INFO: Pod pod-projected-secrets-46827b07-f8d5-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:32:35.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-x7h65" for this suite.
Dec  5 21:32:41.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:32:41.634: INFO: namespace: e2e-tests-projected-x7h65, resource: bindings, ignored listing per whitelist
Dec  5 21:32:41.698: INFO: namespace e2e-tests-projected-x7h65 deletion completed in 6.534913769s

• [SLOW TEST:9.196 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:32:41.699: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-5g2c6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-5g2c6
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-5g2c6 to expose endpoints map[]
Dec  5 21:32:42.147: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-5g2c6 exposes endpoints map[] (11.174322ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-5g2c6
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-5g2c6 to expose endpoints map[pod1:[100]]
Dec  5 21:32:44.218: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-5g2c6 exposes endpoints map[pod1:[100]] (2.049595084s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-5g2c6
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-5g2c6 to expose endpoints map[pod1:[100] pod2:[101]]
Dec  5 21:32:46.433: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-5g2c6 exposes endpoints map[pod1:[100] pod2:[101]] (2.203264658s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-5g2c6
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-5g2c6 to expose endpoints map[pod2:[101]]
Dec  5 21:32:46.499: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-5g2c6 exposes endpoints map[pod2:[101]] (38.027718ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-5g2c6
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-5g2c6 to expose endpoints map[]
Dec  5 21:32:46.531: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-5g2c6 exposes endpoints map[] (7.936457ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:32:46.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-5g2c6" for this suite.
Dec  5 21:33:10.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:33:11.091: INFO: namespace: e2e-tests-services-5g2c6, resource: bindings, ignored listing per whitelist
Dec  5 21:33:11.191: INFO: namespace e2e-tests-services-5g2c6 deletion completed in 24.581153165s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:29.493 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:33:11.191: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-dsfrg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Dec  5 21:33:11.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 api-versions'
Dec  5 21:33:11.783: INFO: stderr: ""
Dec  5 21:33:11.783: INFO: stdout: "admissionregistration.k8s.io/v1alpha1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:33:11.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dsfrg" for this suite.
Dec  5 21:33:17.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:33:17.991: INFO: namespace: e2e-tests-kubectl-dsfrg, resource: bindings, ignored listing per whitelist
Dec  5 21:33:18.288: INFO: namespace e2e-tests-kubectl-dsfrg deletion completed in 6.492627455s

• [SLOW TEST:7.097 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:33:18.289: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-jdb22
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-61d1ea5d-f8d5-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume configMaps
Dec  5 21:33:18.796: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-61d37001-f8d5-11e8-b962-c6dde3e93636" in namespace "e2e-tests-projected-jdb22" to be "success or failure"
Dec  5 21:33:18.807: INFO: Pod "pod-projected-configmaps-61d37001-f8d5-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 11.021381ms
Dec  5 21:33:20.822: INFO: Pod "pod-projected-configmaps-61d37001-f8d5-11e8-b962-c6dde3e93636": Phase="Running", Reason="", readiness=true. Elapsed: 2.026081203s
Dec  5 21:33:22.831: INFO: Pod "pod-projected-configmaps-61d37001-f8d5-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035044024s
STEP: Saw pod success
Dec  5 21:33:22.831: INFO: Pod "pod-projected-configmaps-61d37001-f8d5-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:33:22.848: INFO: Trying to get logs from node 10.191.0.150 pod pod-projected-configmaps-61d37001-f8d5-11e8-b962-c6dde3e93636 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 21:33:22.936: INFO: Waiting for pod pod-projected-configmaps-61d37001-f8d5-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:33:22.948: INFO: Pod pod-projected-configmaps-61d37001-f8d5-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:33:22.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jdb22" for this suite.
Dec  5 21:33:29.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:33:29.254: INFO: namespace: e2e-tests-projected-jdb22, resource: bindings, ignored listing per whitelist
Dec  5 21:33:29.495: INFO: namespace e2e-tests-projected-jdb22 deletion completed in 6.525686495s

• [SLOW TEST:11.206 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:33:29.498: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-r46r5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-6870462e-f8d5-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume configMaps
Dec  5 21:33:29.902: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-687236bf-f8d5-11e8-b962-c6dde3e93636" in namespace "e2e-tests-projected-r46r5" to be "success or failure"
Dec  5 21:33:29.911: INFO: Pod "pod-projected-configmaps-687236bf-f8d5-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 9.151864ms
Dec  5 21:33:31.935: INFO: Pod "pod-projected-configmaps-687236bf-f8d5-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033631521s
STEP: Saw pod success
Dec  5 21:33:31.936: INFO: Pod "pod-projected-configmaps-687236bf-f8d5-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:33:31.945: INFO: Trying to get logs from node 10.191.0.150 pod pod-projected-configmaps-687236bf-f8d5-11e8-b962-c6dde3e93636 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 21:33:32.008: INFO: Waiting for pod pod-projected-configmaps-687236bf-f8d5-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:33:32.018: INFO: Pod pod-projected-configmaps-687236bf-f8d5-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:33:32.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-r46r5" for this suite.
Dec  5 21:33:38.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:33:38.324: INFO: namespace: e2e-tests-projected-r46r5, resource: bindings, ignored listing per whitelist
Dec  5 21:33:38.524: INFO: namespace e2e-tests-projected-r46r5 deletion completed in 6.48470601s

• [SLOW TEST:9.026 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:33:38.525: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-njf24
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-njf24
Dec  5 21:33:42.967: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-njf24
STEP: checking the pod's current state and verifying that restartCount is present
Dec  5 21:33:42.978: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:37:44.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-njf24" for this suite.
Dec  5 21:37:50.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:37:51.144: INFO: namespace: e2e-tests-container-probe-njf24, resource: bindings, ignored listing per whitelist
Dec  5 21:37:51.454: INFO: namespace e2e-tests-container-probe-njf24 deletion completed in 6.503599829s

• [SLOW TEST:252.929 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:37:51.454: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-p7q6s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec  5 21:37:51.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 create -f - --namespace=e2e-tests-kubectl-p7q6s'
Dec  5 21:37:52.058: INFO: stderr: ""
Dec  5 21:37:52.058: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  5 21:37:52.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-p7q6s'
Dec  5 21:37:52.216: INFO: stderr: ""
Dec  5 21:37:52.216: INFO: stdout: "update-demo-nautilus-bwv4g update-demo-nautilus-jg9xh "
Dec  5 21:37:52.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods update-demo-nautilus-bwv4g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p7q6s'
Dec  5 21:37:52.377: INFO: stderr: ""
Dec  5 21:37:52.377: INFO: stdout: ""
Dec  5 21:37:52.377: INFO: update-demo-nautilus-bwv4g is created but not running
Dec  5 21:37:57.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-p7q6s'
Dec  5 21:37:57.568: INFO: stderr: ""
Dec  5 21:37:57.568: INFO: stdout: "update-demo-nautilus-bwv4g update-demo-nautilus-jg9xh "
Dec  5 21:37:57.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods update-demo-nautilus-bwv4g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p7q6s'
Dec  5 21:37:57.721: INFO: stderr: ""
Dec  5 21:37:57.721: INFO: stdout: "true"
Dec  5 21:37:57.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods update-demo-nautilus-bwv4g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p7q6s'
Dec  5 21:37:57.882: INFO: stderr: ""
Dec  5 21:37:57.883: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 21:37:57.883: INFO: validating pod update-demo-nautilus-bwv4g
Dec  5 21:37:57.936: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 21:37:57.936: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 21:37:57.936: INFO: update-demo-nautilus-bwv4g is verified up and running
Dec  5 21:37:57.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods update-demo-nautilus-jg9xh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p7q6s'
Dec  5 21:37:58.079: INFO: stderr: ""
Dec  5 21:37:58.079: INFO: stdout: "true"
Dec  5 21:37:58.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods update-demo-nautilus-jg9xh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p7q6s'
Dec  5 21:37:58.217: INFO: stderr: ""
Dec  5 21:37:58.217: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 21:37:58.217: INFO: validating pod update-demo-nautilus-jg9xh
Dec  5 21:37:58.240: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 21:37:58.240: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 21:37:58.240: INFO: update-demo-nautilus-jg9xh is verified up and running
STEP: scaling down the replication controller
Dec  5 21:37:58.241: INFO: scanned /root for discovery docs: <nil>
Dec  5 21:37:58.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-p7q6s'
Dec  5 21:37:59.438: INFO: stderr: ""
Dec  5 21:37:59.438: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  5 21:37:59.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-p7q6s'
Dec  5 21:37:59.577: INFO: stderr: ""
Dec  5 21:37:59.577: INFO: stdout: "update-demo-nautilus-bwv4g update-demo-nautilus-jg9xh "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec  5 21:38:04.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-p7q6s'
Dec  5 21:38:04.740: INFO: stderr: ""
Dec  5 21:38:04.740: INFO: stdout: "update-demo-nautilus-bwv4g "
Dec  5 21:38:04.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods update-demo-nautilus-bwv4g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p7q6s'
Dec  5 21:38:04.886: INFO: stderr: ""
Dec  5 21:38:04.886: INFO: stdout: "true"
Dec  5 21:38:04.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods update-demo-nautilus-bwv4g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p7q6s'
Dec  5 21:38:05.048: INFO: stderr: ""
Dec  5 21:38:05.048: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 21:38:05.048: INFO: validating pod update-demo-nautilus-bwv4g
Dec  5 21:38:05.063: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 21:38:05.063: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 21:38:05.063: INFO: update-demo-nautilus-bwv4g is verified up and running
STEP: scaling up the replication controller
Dec  5 21:38:05.065: INFO: scanned /root for discovery docs: <nil>
Dec  5 21:38:05.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-p7q6s'
Dec  5 21:38:06.284: INFO: stderr: ""
Dec  5 21:38:06.284: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  5 21:38:06.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-p7q6s'
Dec  5 21:38:06.541: INFO: stderr: ""
Dec  5 21:38:06.541: INFO: stdout: "update-demo-nautilus-bwv4g update-demo-nautilus-sm7l4 "
Dec  5 21:38:06.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods update-demo-nautilus-bwv4g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p7q6s'
Dec  5 21:38:06.695: INFO: stderr: ""
Dec  5 21:38:06.695: INFO: stdout: "true"
Dec  5 21:38:06.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods update-demo-nautilus-bwv4g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p7q6s'
Dec  5 21:38:06.829: INFO: stderr: ""
Dec  5 21:38:06.830: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 21:38:06.830: INFO: validating pod update-demo-nautilus-bwv4g
Dec  5 21:38:06.844: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 21:38:06.844: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 21:38:06.844: INFO: update-demo-nautilus-bwv4g is verified up and running
Dec  5 21:38:06.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods update-demo-nautilus-sm7l4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p7q6s'
Dec  5 21:38:06.979: INFO: stderr: ""
Dec  5 21:38:06.979: INFO: stdout: "true"
Dec  5 21:38:06.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods update-demo-nautilus-sm7l4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p7q6s'
Dec  5 21:38:07.133: INFO: stderr: ""
Dec  5 21:38:07.133: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 21:38:07.133: INFO: validating pod update-demo-nautilus-sm7l4
Dec  5 21:38:07.152: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 21:38:07.152: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 21:38:07.152: INFO: update-demo-nautilus-sm7l4 is verified up and running
STEP: using delete to clean up resources
Dec  5 21:38:07.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-p7q6s'
Dec  5 21:38:07.347: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 21:38:07.348: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  5 21:38:07.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-p7q6s'
Dec  5 21:38:07.509: INFO: stderr: "No resources found.\n"
Dec  5 21:38:07.509: INFO: stdout: ""
Dec  5 21:38:07.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods -l name=update-demo --namespace=e2e-tests-kubectl-p7q6s -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  5 21:38:07.652: INFO: stderr: ""
Dec  5 21:38:07.652: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:38:07.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-p7q6s" for this suite.
Dec  5 21:38:13.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:38:13.972: INFO: namespace: e2e-tests-kubectl-p7q6s, resource: bindings, ignored listing per whitelist
Dec  5 21:38:14.081: INFO: namespace e2e-tests-kubectl-p7q6s deletion completed in 6.396546935s

• [SLOW TEST:22.627 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:38:14.082: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-sz9jn
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-1219bfc4-f8d6-11e8-b962-c6dde3e93636
STEP: Creating secret with name s-test-opt-upd-1219c024-f8d6-11e8-b962-c6dde3e93636
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-1219bfc4-f8d6-11e8-b962-c6dde3e93636
STEP: Updating secret s-test-opt-upd-1219c024-f8d6-11e8-b962-c6dde3e93636
STEP: Creating secret with name s-test-opt-create-1219c047-f8d6-11e8-b962-c6dde3e93636
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:39:41.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-sz9jn" for this suite.
Dec  5 21:40:06.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:40:06.284: INFO: namespace: e2e-tests-secrets-sz9jn, resource: bindings, ignored listing per whitelist
Dec  5 21:40:06.663: INFO: namespace e2e-tests-secrets-sz9jn deletion completed in 24.623768023s

• [SLOW TEST:112.582 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:40:06.666: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-b4b2f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  5 21:40:07.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-b4b2f'
Dec  5 21:40:07.258: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec  5 21:40:07.258: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
Dec  5 21:40:07.349: INFO: scanned /root for discovery docs: <nil>
Dec  5 21:40:07.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-b4b2f'
Dec  5 21:40:23.275: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  5 21:40:23.275: INFO: stdout: "Created e2e-test-nginx-rc-d49525de2f237733b023cbafbf3794d9\nScaling up e2e-test-nginx-rc-d49525de2f237733b023cbafbf3794d9 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-d49525de2f237733b023cbafbf3794d9 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-d49525de2f237733b023cbafbf3794d9 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Dec  5 21:40:23.275: INFO: stdout: "Created e2e-test-nginx-rc-d49525de2f237733b023cbafbf3794d9\nScaling up e2e-test-nginx-rc-d49525de2f237733b023cbafbf3794d9 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-d49525de2f237733b023cbafbf3794d9 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-d49525de2f237733b023cbafbf3794d9 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Dec  5 21:40:23.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-b4b2f'
Dec  5 21:40:23.411: INFO: stderr: ""
Dec  5 21:40:23.411: INFO: stdout: "e2e-test-nginx-rc-d49525de2f237733b023cbafbf3794d9-xpwq8 "
Dec  5 21:40:23.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods e2e-test-nginx-rc-d49525de2f237733b023cbafbf3794d9-xpwq8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b4b2f'
Dec  5 21:40:23.543: INFO: stderr: ""
Dec  5 21:40:23.543: INFO: stdout: "true"
Dec  5 21:40:23.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods e2e-test-nginx-rc-d49525de2f237733b023cbafbf3794d9-xpwq8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b4b2f'
Dec  5 21:40:23.692: INFO: stderr: ""
Dec  5 21:40:23.692: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Dec  5 21:40:23.692: INFO: e2e-test-nginx-rc-d49525de2f237733b023cbafbf3794d9-xpwq8 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Dec  5 21:40:23.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-b4b2f'
Dec  5 21:40:23.856: INFO: stderr: ""
Dec  5 21:40:23.856: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:40:23.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b4b2f" for this suite.
Dec  5 21:40:47.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:40:48.036: INFO: namespace: e2e-tests-kubectl-b4b2f, resource: bindings, ignored listing per whitelist
Dec  5 21:40:48.352: INFO: namespace e2e-tests-kubectl-b4b2f deletion completed in 24.416601966s

• [SLOW TEST:41.687 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:40:48.353: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-dk78l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 21:40:48.735: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6e01fc6a-f8d6-11e8-b962-c6dde3e93636" in namespace "e2e-tests-downward-api-dk78l" to be "success or failure"
Dec  5 21:40:48.746: INFO: Pod "downwardapi-volume-6e01fc6a-f8d6-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 10.366256ms
Dec  5 21:40:50.757: INFO: Pod "downwardapi-volume-6e01fc6a-f8d6-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02123439s
STEP: Saw pod success
Dec  5 21:40:50.757: INFO: Pod "downwardapi-volume-6e01fc6a-f8d6-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:40:50.769: INFO: Trying to get logs from node 10.191.0.150 pod downwardapi-volume-6e01fc6a-f8d6-11e8-b962-c6dde3e93636 container client-container: <nil>
STEP: delete the pod
Dec  5 21:40:50.834: INFO: Waiting for pod downwardapi-volume-6e01fc6a-f8d6-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:40:50.842: INFO: Pod downwardapi-volume-6e01fc6a-f8d6-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:40:50.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dk78l" for this suite.
Dec  5 21:40:56.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:40:57.197: INFO: namespace: e2e-tests-downward-api-dk78l, resource: bindings, ignored listing per whitelist
Dec  5 21:40:57.267: INFO: namespace e2e-tests-downward-api-dk78l deletion completed in 6.410739402s

• [SLOW TEST:8.915 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:40:57.268: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-frp5n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-2bqr
STEP: Creating a pod to test atomic-volume-subpath
Dec  5 21:40:57.650: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-2bqr" in namespace "e2e-tests-subpath-frp5n" to be "success or failure"
Dec  5 21:40:57.660: INFO: Pod "pod-subpath-test-downwardapi-2bqr": Phase="Pending", Reason="", readiness=false. Elapsed: 10.267549ms
Dec  5 21:40:59.736: INFO: Pod "pod-subpath-test-downwardapi-2bqr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.085486608s
Dec  5 21:41:01.744: INFO: Pod "pod-subpath-test-downwardapi-2bqr": Phase="Running", Reason="", readiness=false. Elapsed: 4.094304202s
Dec  5 21:41:03.755: INFO: Pod "pod-subpath-test-downwardapi-2bqr": Phase="Running", Reason="", readiness=false. Elapsed: 6.105302187s
Dec  5 21:41:05.766: INFO: Pod "pod-subpath-test-downwardapi-2bqr": Phase="Running", Reason="", readiness=false. Elapsed: 8.116043336s
Dec  5 21:41:07.795: INFO: Pod "pod-subpath-test-downwardapi-2bqr": Phase="Running", Reason="", readiness=false. Elapsed: 10.14512498s
Dec  5 21:41:09.804: INFO: Pod "pod-subpath-test-downwardapi-2bqr": Phase="Running", Reason="", readiness=false. Elapsed: 12.15360225s
Dec  5 21:41:11.815: INFO: Pod "pod-subpath-test-downwardapi-2bqr": Phase="Running", Reason="", readiness=false. Elapsed: 14.165151038s
Dec  5 21:41:13.825: INFO: Pod "pod-subpath-test-downwardapi-2bqr": Phase="Running", Reason="", readiness=false. Elapsed: 16.174901566s
Dec  5 21:41:15.834: INFO: Pod "pod-subpath-test-downwardapi-2bqr": Phase="Running", Reason="", readiness=false. Elapsed: 18.184182774s
Dec  5 21:41:17.860: INFO: Pod "pod-subpath-test-downwardapi-2bqr": Phase="Running", Reason="", readiness=false. Elapsed: 20.209527919s
Dec  5 21:41:19.868: INFO: Pod "pod-subpath-test-downwardapi-2bqr": Phase="Running", Reason="", readiness=false. Elapsed: 22.218374768s
Dec  5 21:41:21.879: INFO: Pod "pod-subpath-test-downwardapi-2bqr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.228913773s
STEP: Saw pod success
Dec  5 21:41:21.879: INFO: Pod "pod-subpath-test-downwardapi-2bqr" satisfied condition "success or failure"
Dec  5 21:41:21.887: INFO: Trying to get logs from node 10.191.0.147 pod pod-subpath-test-downwardapi-2bqr container test-container-subpath-downwardapi-2bqr: <nil>
STEP: delete the pod
Dec  5 21:41:21.960: INFO: Waiting for pod pod-subpath-test-downwardapi-2bqr to disappear
Dec  5 21:41:21.979: INFO: Pod pod-subpath-test-downwardapi-2bqr no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-2bqr
Dec  5 21:41:21.979: INFO: Deleting pod "pod-subpath-test-downwardapi-2bqr" in namespace "e2e-tests-subpath-frp5n"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:41:21.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-frp5n" for this suite.
Dec  5 21:41:28.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:41:28.406: INFO: namespace: e2e-tests-subpath-frp5n, resource: bindings, ignored listing per whitelist
Dec  5 21:41:28.431: INFO: namespace e2e-tests-subpath-frp5n deletion completed in 6.429662487s

• [SLOW TEST:31.163 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:41:28.433: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-kwkkl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  5 21:41:28.850: INFO: Waiting up to 5m0s for pod "pod-85ec81b7-f8d6-11e8-b962-c6dde3e93636" in namespace "e2e-tests-emptydir-kwkkl" to be "success or failure"
Dec  5 21:41:28.859: INFO: Pod "pod-85ec81b7-f8d6-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 8.576475ms
Dec  5 21:41:30.868: INFO: Pod "pod-85ec81b7-f8d6-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017993008s
STEP: Saw pod success
Dec  5 21:41:30.869: INFO: Pod "pod-85ec81b7-f8d6-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:41:30.880: INFO: Trying to get logs from node 10.191.0.150 pod pod-85ec81b7-f8d6-11e8-b962-c6dde3e93636 container test-container: <nil>
STEP: delete the pod
Dec  5 21:41:30.935: INFO: Waiting for pod pod-85ec81b7-f8d6-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:41:30.944: INFO: Pod pod-85ec81b7-f8d6-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:41:30.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kwkkl" for this suite.
Dec  5 21:41:36.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:41:37.096: INFO: namespace: e2e-tests-emptydir-kwkkl, resource: bindings, ignored listing per whitelist
Dec  5 21:41:37.409: INFO: namespace e2e-tests-emptydir-kwkkl deletion completed in 6.453134172s

• [SLOW TEST:8.976 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:41:37.409: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-p4xg4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Dec  5 21:41:37.741: INFO: Waiting up to 5m0s for pod "var-expansion-8b382845-f8d6-11e8-b962-c6dde3e93636" in namespace "e2e-tests-var-expansion-p4xg4" to be "success or failure"
Dec  5 21:41:37.762: INFO: Pod "var-expansion-8b382845-f8d6-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 21.448408ms
Dec  5 21:41:39.783: INFO: Pod "var-expansion-8b382845-f8d6-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.042240352s
STEP: Saw pod success
Dec  5 21:41:39.783: INFO: Pod "var-expansion-8b382845-f8d6-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:41:39.791: INFO: Trying to get logs from node 10.191.0.150 pod var-expansion-8b382845-f8d6-11e8-b962-c6dde3e93636 container dapi-container: <nil>
STEP: delete the pod
Dec  5 21:41:39.845: INFO: Waiting for pod var-expansion-8b382845-f8d6-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:41:39.860: INFO: Pod var-expansion-8b382845-f8d6-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:41:39.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-p4xg4" for this suite.
Dec  5 21:41:45.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:41:46.241: INFO: namespace: e2e-tests-var-expansion-p4xg4, resource: bindings, ignored listing per whitelist
Dec  5 21:41:46.275: INFO: namespace e2e-tests-var-expansion-p4xg4 deletion completed in 6.401350689s

• [SLOW TEST:8.866 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:41:46.276: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-k9j5p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-nlcjf
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-6gtdg
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:41:53.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-k9j5p" for this suite.
Dec  5 21:41:59.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:41:59.309: INFO: namespace: e2e-tests-namespaces-k9j5p, resource: bindings, ignored listing per whitelist
Dec  5 21:41:59.520: INFO: namespace e2e-tests-namespaces-k9j5p deletion completed in 6.3455792s
STEP: Destroying namespace "e2e-tests-nsdeletetest-nlcjf" for this suite.
Dec  5 21:41:59.530: INFO: Namespace e2e-tests-nsdeletetest-nlcjf was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-6gtdg" for this suite.
Dec  5 21:42:05.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:42:06.133: INFO: namespace: e2e-tests-nsdeletetest-6gtdg, resource: bindings, ignored listing per whitelist
Dec  5 21:42:06.331: INFO: namespace e2e-tests-nsdeletetest-6gtdg deletion completed in 6.800654307s

• [SLOW TEST:20.055 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:42:06.332: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-dqmq4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-9c7e535f-f8d6-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume configMaps
Dec  5 21:42:06.763: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9c8525c8-f8d6-11e8-b962-c6dde3e93636" in namespace "e2e-tests-projected-dqmq4" to be "success or failure"
Dec  5 21:42:06.776: INFO: Pod "pod-projected-configmaps-9c8525c8-f8d6-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 12.461928ms
Dec  5 21:42:08.786: INFO: Pod "pod-projected-configmaps-9c8525c8-f8d6-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022376525s
STEP: Saw pod success
Dec  5 21:42:08.786: INFO: Pod "pod-projected-configmaps-9c8525c8-f8d6-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:42:08.797: INFO: Trying to get logs from node 10.191.0.150 pod pod-projected-configmaps-9c8525c8-f8d6-11e8-b962-c6dde3e93636 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 21:42:08.847: INFO: Waiting for pod pod-projected-configmaps-9c8525c8-f8d6-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:42:08.935: INFO: Pod pod-projected-configmaps-9c8525c8-f8d6-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:42:08.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dqmq4" for this suite.
Dec  5 21:42:14.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:42:15.360: INFO: namespace: e2e-tests-projected-dqmq4, resource: bindings, ignored listing per whitelist
Dec  5 21:42:15.360: INFO: namespace e2e-tests-projected-dqmq4 deletion completed in 6.411575498s

• [SLOW TEST:9.028 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:42:15.360: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-2s9hq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-2s9hq
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Dec  5 21:42:15.710: INFO: Found 0 stateful pods, waiting for 3
Dec  5 21:42:25.734: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 21:42:25.734: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 21:42:25.734: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 21:42:25.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-2s9hq ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  5 21:42:26.172: INFO: stderr: ""
Dec  5 21:42:26.172: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  5 21:42:26.172: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec  5 21:42:36.263: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec  5 21:42:46.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-2s9hq ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 21:42:46.743: INFO: stderr: ""
Dec  5 21:42:46.743: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  5 21:42:46.743: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  5 21:43:06.918: INFO: Waiting for StatefulSet e2e-tests-statefulset-2s9hq/ss2 to complete update
Dec  5 21:43:06.918: INFO: Waiting for Pod e2e-tests-statefulset-2s9hq/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Dec  5 21:43:16.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-2s9hq ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  5 21:43:17.369: INFO: stderr: ""
Dec  5 21:43:17.369: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  5 21:43:17.369: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  5 21:43:27.457: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec  5 21:43:37.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-2s9hq ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 21:43:37.911: INFO: stderr: ""
Dec  5 21:43:37.911: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  5 21:43:37.911: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  5 21:43:48.016: INFO: Waiting for StatefulSet e2e-tests-statefulset-2s9hq/ss2 to complete update
Dec  5 21:43:48.016: INFO: Waiting for Pod e2e-tests-statefulset-2s9hq/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Dec  5 21:43:48.016: INFO: Waiting for Pod e2e-tests-statefulset-2s9hq/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Dec  5 21:43:58.047: INFO: Waiting for StatefulSet e2e-tests-statefulset-2s9hq/ss2 to complete update
Dec  5 21:43:58.047: INFO: Waiting for Pod e2e-tests-statefulset-2s9hq/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  5 21:44:08.036: INFO: Deleting all statefulset in ns e2e-tests-statefulset-2s9hq
Dec  5 21:44:08.060: INFO: Scaling statefulset ss2 to 0
Dec  5 21:44:28.144: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 21:44:28.153: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:44:28.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-2s9hq" for this suite.
Dec  5 21:44:36.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:44:36.386: INFO: namespace: e2e-tests-statefulset-2s9hq, resource: bindings, ignored listing per whitelist
Dec  5 21:44:36.663: INFO: namespace e2e-tests-statefulset-2s9hq deletion completed in 8.438934702s

• [SLOW TEST:141.302 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:44:36.665: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-glvkq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 21:44:37.007: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f611bdd2-f8d6-11e8-b962-c6dde3e93636" in namespace "e2e-tests-projected-glvkq" to be "success or failure"
Dec  5 21:44:37.021: INFO: Pod "downwardapi-volume-f611bdd2-f8d6-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 13.739487ms
Dec  5 21:44:39.044: INFO: Pod "downwardapi-volume-f611bdd2-f8d6-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.037476565s
STEP: Saw pod success
Dec  5 21:44:39.044: INFO: Pod "downwardapi-volume-f611bdd2-f8d6-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:44:39.054: INFO: Trying to get logs from node 10.191.0.150 pod downwardapi-volume-f611bdd2-f8d6-11e8-b962-c6dde3e93636 container client-container: <nil>
STEP: delete the pod
Dec  5 21:44:39.107: INFO: Waiting for pod downwardapi-volume-f611bdd2-f8d6-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:44:39.117: INFO: Pod downwardapi-volume-f611bdd2-f8d6-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:44:39.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-glvkq" for this suite.
Dec  5 21:44:45.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:44:45.424: INFO: namespace: e2e-tests-projected-glvkq, resource: bindings, ignored listing per whitelist
Dec  5 21:44:45.619: INFO: namespace e2e-tests-projected-glvkq deletion completed in 6.489227746s

• [SLOW TEST:8.954 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:44:45.621: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-ccg54
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec  5 21:44:46.047: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-ccg54,SelfLink:/api/v1/namespaces/e2e-tests-watch-ccg54/configmaps/e2e-watch-test-label-changed,UID:fb702922-f8d6-11e8-9151-427614c96c42,ResourceVersion:20098,Generation:0,CreationTimestamp:2018-12-05 21:44:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  5 21:44:46.048: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-ccg54,SelfLink:/api/v1/namespaces/e2e-tests-watch-ccg54/configmaps/e2e-watch-test-label-changed,UID:fb702922-f8d6-11e8-9151-427614c96c42,ResourceVersion:20099,Generation:0,CreationTimestamp:2018-12-05 21:44:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  5 21:44:46.048: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-ccg54,SelfLink:/api/v1/namespaces/e2e-tests-watch-ccg54/configmaps/e2e-watch-test-label-changed,UID:fb702922-f8d6-11e8-9151-427614c96c42,ResourceVersion:20100,Generation:0,CreationTimestamp:2018-12-05 21:44:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec  5 21:44:56.182: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-ccg54,SelfLink:/api/v1/namespaces/e2e-tests-watch-ccg54/configmaps/e2e-watch-test-label-changed,UID:fb702922-f8d6-11e8-9151-427614c96c42,ResourceVersion:20118,Generation:0,CreationTimestamp:2018-12-05 21:44:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  5 21:44:56.182: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-ccg54,SelfLink:/api/v1/namespaces/e2e-tests-watch-ccg54/configmaps/e2e-watch-test-label-changed,UID:fb702922-f8d6-11e8-9151-427614c96c42,ResourceVersion:20119,Generation:0,CreationTimestamp:2018-12-05 21:44:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec  5 21:44:56.182: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-ccg54,SelfLink:/api/v1/namespaces/e2e-tests-watch-ccg54/configmaps/e2e-watch-test-label-changed,UID:fb702922-f8d6-11e8-9151-427614c96c42,ResourceVersion:20120,Generation:0,CreationTimestamp:2018-12-05 21:44:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:44:56.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-ccg54" for this suite.
Dec  5 21:45:02.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:45:02.658: INFO: namespace: e2e-tests-watch-ccg54, resource: bindings, ignored listing per whitelist
Dec  5 21:45:02.732: INFO: namespace e2e-tests-watch-ccg54 deletion completed in 6.535634465s

• [SLOW TEST:17.112 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:45:02.733: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-sqkgg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 21:45:03.150: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Dec  5 21:45:03.171: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-sqkgg/daemonsets","resourceVersion":"20146"},"items":null}

Dec  5 21:45:03.179: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-sqkgg/pods","resourceVersion":"20146"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:45:03.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-sqkgg" for this suite.
Dec  5 21:45:09.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:45:09.569: INFO: namespace: e2e-tests-daemonsets-sqkgg, resource: bindings, ignored listing per whitelist
Dec  5 21:45:09.788: INFO: namespace e2e-tests-daemonsets-sqkgg deletion completed in 6.551380634s

S [SKIPPING] [7.055 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Dec  5 21:45:03.150: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:45:09.788: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-xxj2g
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec  5 21:45:10.226: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-xxj2g,SelfLink:/api/v1/namespaces/e2e-tests-watch-xxj2g/configmaps/e2e-watch-test-resource-version,UID:09d73404-f8d7-11e8-9151-427614c96c42,ResourceVersion:20177,Generation:0,CreationTimestamp:2018-12-05 21:45:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  5 21:45:10.226: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-xxj2g,SelfLink:/api/v1/namespaces/e2e-tests-watch-xxj2g/configmaps/e2e-watch-test-resource-version,UID:09d73404-f8d7-11e8-9151-427614c96c42,ResourceVersion:20178,Generation:0,CreationTimestamp:2018-12-05 21:45:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:45:10.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-xxj2g" for this suite.
Dec  5 21:45:16.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:45:16.465: INFO: namespace: e2e-tests-watch-xxj2g, resource: bindings, ignored listing per whitelist
Dec  5 21:45:16.635: INFO: namespace e2e-tests-watch-xxj2g deletion completed in 6.395301894s

• [SLOW TEST:6.846 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:45:16.636: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-nc267
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-ld9xz in namespace e2e-tests-proxy-nc267
I1205 21:45:17.037078      16 runners.go:180] Created replication controller with name: proxy-service-ld9xz, namespace: e2e-tests-proxy-nc267, replica count: 1
I1205 21:45:18.087436      16 runners.go:180] proxy-service-ld9xz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1205 21:45:19.087627      16 runners.go:180] proxy-service-ld9xz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1205 21:45:20.087838      16 runners.go:180] proxy-service-ld9xz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1205 21:45:21.088068      16 runners.go:180] proxy-service-ld9xz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1205 21:45:22.088292      16 runners.go:180] proxy-service-ld9xz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1205 21:45:23.088577      16 runners.go:180] proxy-service-ld9xz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1205 21:45:24.088771      16 runners.go:180] proxy-service-ld9xz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1205 21:45:25.088974      16 runners.go:180] proxy-service-ld9xz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1205 21:45:26.089195      16 runners.go:180] proxy-service-ld9xz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1205 21:45:27.089381      16 runners.go:180] proxy-service-ld9xz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1205 21:45:28.089661      16 runners.go:180] proxy-service-ld9xz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1205 21:45:29.089936      16 runners.go:180] proxy-service-ld9xz Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  5 21:45:29.109: INFO: setup took 12.105781917s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec  5 21:45:29.140: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/rewri... (200; 30.950003ms)
Dec  5 21:45:29.141: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 30.796999ms)
Dec  5 21:45:29.140: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 30.646601ms)
Dec  5 21:45:29.141: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 30.781861ms)
Dec  5 21:45:29.141: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/... (200; 31.429801ms)
Dec  5 21:45:29.141: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/rewriteme"... (200; 31.302085ms)
Dec  5 21:45:29.145: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 35.26689ms)
Dec  5 21:45:29.145: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname1/proxy/: foo (200; 35.347315ms)
Dec  5 21:45:29.151: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname2/proxy/: bar (200; 41.808301ms)
Dec  5 21:45:29.152: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname2/proxy/: bar (200; 42.239527ms)
Dec  5 21:45:29.152: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname1/proxy/: foo (200; 42.055258ms)
Dec  5 21:45:29.156: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:460/proxy/: tls baz (200; 46.613935ms)
Dec  5 21:45:29.156: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname2/proxy/: tls qux (200; 46.777746ms)
Dec  5 21:45:29.156: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/... (200; 46.950727ms)
Dec  5 21:45:29.158: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname1/proxy/: tls baz (200; 48.475066ms)
Dec  5 21:45:29.160: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:462/proxy/: tls qux (200; 50.894079ms)
Dec  5 21:45:29.173: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 13.17902ms)
Dec  5 21:45:29.178: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 16.835094ms)
Dec  5 21:45:29.178: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 16.90733ms)
Dec  5 21:45:29.178: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/rewriteme"... (200; 17.357558ms)
Dec  5 21:45:29.178: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 17.697142ms)
Dec  5 21:45:29.178: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/rewri... (200; 17.434982ms)
Dec  5 21:45:29.180: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/... (200; 19.290639ms)
Dec  5 21:45:29.180: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/... (200; 19.623344ms)
Dec  5 21:45:29.181: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:462/proxy/: tls qux (200; 20.37971ms)
Dec  5 21:45:29.181: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:460/proxy/: tls baz (200; 20.45299ms)
Dec  5 21:45:29.181: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname2/proxy/: tls qux (200; 20.975205ms)
Dec  5 21:45:29.183: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname1/proxy/: tls baz (200; 22.30564ms)
Dec  5 21:45:29.183: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname2/proxy/: bar (200; 22.758102ms)
Dec  5 21:45:29.183: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname1/proxy/: foo (200; 22.585377ms)
Dec  5 21:45:29.183: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname2/proxy/: bar (200; 22.849936ms)
Dec  5 21:45:29.187: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname1/proxy/: foo (200; 26.088662ms)
Dec  5 21:45:29.213: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 26.164549ms)
Dec  5 21:45:29.215: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 28.357015ms)
Dec  5 21:45:29.215: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 27.855107ms)
Dec  5 21:45:29.216: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/rewri... (200; 28.936459ms)
Dec  5 21:45:29.216: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 28.888466ms)
Dec  5 21:45:29.217: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/rewriteme"... (200; 29.735327ms)
Dec  5 21:45:29.218: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/... (200; 30.021818ms)
Dec  5 21:45:29.221: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:462/proxy/: tls qux (200; 33.521889ms)
Dec  5 21:45:29.223: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/... (200; 35.180445ms)
Dec  5 21:45:29.224: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:460/proxy/: tls baz (200; 36.332933ms)
Dec  5 21:45:29.227: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname2/proxy/: tls qux (200; 39.950078ms)
Dec  5 21:45:29.227: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname2/proxy/: bar (200; 39.816185ms)
Dec  5 21:45:29.227: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname1/proxy/: foo (200; 39.723221ms)
Dec  5 21:45:29.228: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname2/proxy/: bar (200; 40.138963ms)
Dec  5 21:45:29.228: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname1/proxy/: tls baz (200; 40.583207ms)
Dec  5 21:45:29.228: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname1/proxy/: foo (200; 40.756934ms)
Dec  5 21:45:29.244: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:462/proxy/: tls qux (200; 15.876843ms)
Dec  5 21:45:29.246: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:460/proxy/: tls baz (200; 17.881621ms)
Dec  5 21:45:29.247: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/... (200; 17.880341ms)
Dec  5 21:45:29.247: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/rewri... (200; 18.549584ms)
Dec  5 21:45:29.248: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/... (200; 19.792299ms)
Dec  5 21:45:29.249: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/rewriteme"... (200; 19.880225ms)
Dec  5 21:45:29.249: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 20.503356ms)
Dec  5 21:45:29.249: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 20.093646ms)
Dec  5 21:45:29.249: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 20.087355ms)
Dec  5 21:45:29.249: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 20.360229ms)
Dec  5 21:45:29.250: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname1/proxy/: tls baz (200; 21.595165ms)
Dec  5 21:45:29.250: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname2/proxy/: tls qux (200; 20.971964ms)
Dec  5 21:45:29.255: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname2/proxy/: bar (200; 26.237234ms)
Dec  5 21:45:29.255: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname1/proxy/: foo (200; 26.430365ms)
Dec  5 21:45:29.255: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname1/proxy/: foo (200; 26.864614ms)
Dec  5 21:45:29.255: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname2/proxy/: bar (200; 27.353972ms)
Dec  5 21:45:29.275: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/... (200; 19.33289ms)
Dec  5 21:45:29.277: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:460/proxy/: tls baz (200; 21.610143ms)
Dec  5 21:45:29.278: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 22.15061ms)
Dec  5 21:45:29.278: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/... (200; 21.847132ms)
Dec  5 21:45:29.280: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/rewri... (200; 24.759005ms)
Dec  5 21:45:29.281: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:462/proxy/: tls qux (200; 25.366386ms)
Dec  5 21:45:29.281: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 24.791748ms)
Dec  5 21:45:29.282: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 26.147332ms)
Dec  5 21:45:29.284: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/rewriteme"... (200; 27.874401ms)
Dec  5 21:45:29.287: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 30.250202ms)
Dec  5 21:45:29.288: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname1/proxy/: foo (200; 32.888235ms)
Dec  5 21:45:29.289: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname2/proxy/: bar (200; 31.998079ms)
Dec  5 21:45:29.289: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname1/proxy/: tls baz (200; 32.278087ms)
Dec  5 21:45:29.289: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname2/proxy/: bar (200; 32.380996ms)
Dec  5 21:45:29.290: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname2/proxy/: tls qux (200; 32.914635ms)
Dec  5 21:45:29.291: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname1/proxy/: foo (200; 35.164239ms)
Dec  5 21:45:29.304: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:462/proxy/: tls qux (200; 12.866439ms)
Dec  5 21:45:29.307: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/... (200; 15.993737ms)
Dec  5 21:45:29.307: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/rewriteme"... (200; 16.123026ms)
Dec  5 21:45:29.307: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 15.763486ms)
Dec  5 21:45:29.307: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 15.970582ms)
Dec  5 21:45:29.307: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/rewri... (200; 16.105667ms)
Dec  5 21:45:29.310: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname2/proxy/: bar (200; 18.688548ms)
Dec  5 21:45:29.313: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 21.455843ms)
Dec  5 21:45:29.313: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 22.006329ms)
Dec  5 21:45:29.313: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname1/proxy/: tls baz (200; 21.691524ms)
Dec  5 21:45:29.313: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:460/proxy/: tls baz (200; 21.987797ms)
Dec  5 21:45:29.313: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/... (200; 21.838373ms)
Dec  5 21:45:29.314: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname2/proxy/: tls qux (200; 23.220802ms)
Dec  5 21:45:29.315: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname2/proxy/: bar (200; 23.631359ms)
Dec  5 21:45:29.316: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname1/proxy/: foo (200; 24.292981ms)
Dec  5 21:45:29.316: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname1/proxy/: foo (200; 24.769385ms)
Dec  5 21:45:29.335: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/... (200; 19.072481ms)
Dec  5 21:45:29.336: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:462/proxy/: tls qux (200; 18.806099ms)
Dec  5 21:45:29.336: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:460/proxy/: tls baz (200; 19.187817ms)
Dec  5 21:45:29.336: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/rewriteme"... (200; 19.633876ms)
Dec  5 21:45:29.336: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/... (200; 19.519415ms)
Dec  5 21:45:29.336: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/rewri... (200; 19.458262ms)
Dec  5 21:45:29.337: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 20.757939ms)
Dec  5 21:45:29.338: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 20.579068ms)
Dec  5 21:45:29.338: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 21.106061ms)
Dec  5 21:45:29.338: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 21.700428ms)
Dec  5 21:45:29.339: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname2/proxy/: tls qux (200; 23.042282ms)
Dec  5 21:45:29.341: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname1/proxy/: tls baz (200; 24.580561ms)
Dec  5 21:45:29.342: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname2/proxy/: bar (200; 25.625694ms)
Dec  5 21:45:29.343: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname2/proxy/: bar (200; 26.214153ms)
Dec  5 21:45:29.343: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname1/proxy/: foo (200; 26.958375ms)
Dec  5 21:45:29.343: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname1/proxy/: foo (200; 26.615987ms)
Dec  5 21:45:29.357: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/rewriteme"... (200; 13.319103ms)
Dec  5 21:45:29.360: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 15.687074ms)
Dec  5 21:45:29.360: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/... (200; 15.805889ms)
Dec  5 21:45:29.361: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/... (200; 17.010571ms)
Dec  5 21:45:29.361: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 17.01125ms)
Dec  5 21:45:29.361: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 17.119416ms)
Dec  5 21:45:29.370: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:462/proxy/: tls qux (200; 25.908023ms)
Dec  5 21:45:29.371: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/rewri... (200; 26.229847ms)
Dec  5 21:45:29.371: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 26.417151ms)
Dec  5 21:45:29.371: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:460/proxy/: tls baz (200; 27.013134ms)
Dec  5 21:45:29.379: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname1/proxy/: foo (200; 34.441352ms)
Dec  5 21:45:29.382: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname2/proxy/: bar (200; 37.80728ms)
Dec  5 21:45:29.382: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname1/proxy/: tls baz (200; 38.306634ms)
Dec  5 21:45:29.382: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname2/proxy/: tls qux (200; 38.194095ms)
Dec  5 21:45:29.383: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname2/proxy/: bar (200; 38.556442ms)
Dec  5 21:45:29.383: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname1/proxy/: foo (200; 38.848532ms)
Dec  5 21:45:29.396: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/... (200; 12.930239ms)
Dec  5 21:45:29.402: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 18.644526ms)
Dec  5 21:45:29.402: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 19.032275ms)
Dec  5 21:45:29.402: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/... (200; 18.540116ms)
Dec  5 21:45:29.402: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 18.361414ms)
Dec  5 21:45:29.402: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 18.544349ms)
Dec  5 21:45:29.402: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/rewri... (200; 18.749903ms)
Dec  5 21:45:29.402: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:462/proxy/: tls qux (200; 18.771227ms)
Dec  5 21:45:29.402: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:460/proxy/: tls baz (200; 18.847418ms)
Dec  5 21:45:29.402: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/rewriteme"... (200; 19.420838ms)
Dec  5 21:45:29.408: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname1/proxy/: foo (200; 24.47975ms)
Dec  5 21:45:29.408: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname2/proxy/: tls qux (200; 24.511292ms)
Dec  5 21:45:29.408: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname2/proxy/: bar (200; 24.749735ms)
Dec  5 21:45:29.408: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname1/proxy/: tls baz (200; 25.097634ms)
Dec  5 21:45:29.408: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname2/proxy/: bar (200; 24.905034ms)
Dec  5 21:45:29.408: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname1/proxy/: foo (200; 24.427331ms)
Dec  5 21:45:29.424: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 15.336402ms)
Dec  5 21:45:29.428: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:462/proxy/: tls qux (200; 19.323973ms)
Dec  5 21:45:29.429: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/... (200; 19.881544ms)
Dec  5 21:45:29.429: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/rewriteme"... (200; 20.557047ms)
Dec  5 21:45:29.429: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 20.312067ms)
Dec  5 21:45:29.429: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname2/proxy/: bar (200; 20.244685ms)
Dec  5 21:45:29.429: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/rewri... (200; 20.755507ms)
Dec  5 21:45:29.429: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 20.581441ms)
Dec  5 21:45:29.432: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:460/proxy/: tls baz (200; 23.393069ms)
Dec  5 21:45:29.432: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname1/proxy/: foo (200; 23.645182ms)
Dec  5 21:45:29.432: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname1/proxy/: tls baz (200; 23.540086ms)
Dec  5 21:45:29.432: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname1/proxy/: foo (200; 23.626222ms)
Dec  5 21:45:29.433: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/... (200; 24.161166ms)
Dec  5 21:45:29.433: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname2/proxy/: tls qux (200; 24.264382ms)
Dec  5 21:45:29.433: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname2/proxy/: bar (200; 24.694197ms)
Dec  5 21:45:29.433: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 24.572741ms)
Dec  5 21:45:29.447: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/... (200; 13.141572ms)
Dec  5 21:45:29.450: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 14.423076ms)
Dec  5 21:45:29.450: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/rewriteme"... (200; 15.40221ms)
Dec  5 21:45:29.453: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 14.772329ms)
Dec  5 21:45:29.457: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname1/proxy/: tls baz (200; 22.406222ms)
Dec  5 21:45:29.463: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 22.451941ms)
Dec  5 21:45:29.463: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 22.371211ms)
Dec  5 21:45:29.463: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/rewri... (200; 29.269749ms)
Dec  5 21:45:29.463: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/... (200; 24.491819ms)
Dec  5 21:45:29.463: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:460/proxy/: tls baz (200; 23.397189ms)
Dec  5 21:45:29.463: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:462/proxy/: tls qux (200; 23.605251ms)
Dec  5 21:45:29.468: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname1/proxy/: foo (200; 29.509956ms)
Dec  5 21:45:29.472: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname2/proxy/: bar (200; 33.397131ms)
Dec  5 21:45:29.474: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname2/proxy/: tls qux (200; 35.359117ms)
Dec  5 21:45:29.474: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname1/proxy/: foo (200; 34.879951ms)
Dec  5 21:45:29.474: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname2/proxy/: bar (200; 35.611216ms)
Dec  5 21:45:29.487: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 12.79401ms)
Dec  5 21:45:29.491: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/rewri... (200; 15.751838ms)
Dec  5 21:45:29.491: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/rewriteme"... (200; 15.862591ms)
Dec  5 21:45:29.491: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/... (200; 16.215374ms)
Dec  5 21:45:29.491: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/... (200; 15.707604ms)
Dec  5 21:45:29.492: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:460/proxy/: tls baz (200; 16.931725ms)
Dec  5 21:45:29.492: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 17.380685ms)
Dec  5 21:45:29.492: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 17.147244ms)
Dec  5 21:45:29.493: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 17.503035ms)
Dec  5 21:45:29.494: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:462/proxy/: tls qux (200; 18.923997ms)
Dec  5 21:45:29.495: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname2/proxy/: tls qux (200; 20.020022ms)
Dec  5 21:45:29.495: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname2/proxy/: bar (200; 20.49534ms)
Dec  5 21:45:29.496: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname1/proxy/: foo (200; 21.032358ms)
Dec  5 21:45:29.496: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname1/proxy/: tls baz (200; 21.29802ms)
Dec  5 21:45:29.497: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname1/proxy/: foo (200; 21.751321ms)
Dec  5 21:45:29.497: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname2/proxy/: bar (200; 22.1215ms)
Dec  5 21:45:29.514: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:462/proxy/: tls qux (200; 16.720884ms)
Dec  5 21:45:29.518: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 20.211051ms)
Dec  5 21:45:29.518: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 20.861714ms)
Dec  5 21:45:29.519: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/rewriteme"... (200; 21.600763ms)
Dec  5 21:45:29.519: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 21.948751ms)
Dec  5 21:45:29.520: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/rewri... (200; 22.360859ms)
Dec  5 21:45:29.520: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/... (200; 22.325473ms)
Dec  5 21:45:29.520: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:460/proxy/: tls baz (200; 22.827881ms)
Dec  5 21:45:29.520: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/... (200; 22.387847ms)
Dec  5 21:45:29.520: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 22.81331ms)
Dec  5 21:45:29.522: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname1/proxy/: tls baz (200; 24.611339ms)
Dec  5 21:45:29.522: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname1/proxy/: foo (200; 24.755427ms)
Dec  5 21:45:29.522: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname2/proxy/: tls qux (200; 24.732547ms)
Dec  5 21:45:29.524: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname2/proxy/: bar (200; 26.762007ms)
Dec  5 21:45:29.524: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname2/proxy/: bar (200; 26.083059ms)
Dec  5 21:45:29.526: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname1/proxy/: foo (200; 28.504165ms)
Dec  5 21:45:29.539: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/rewri... (200; 12.776407ms)
Dec  5 21:45:29.542: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 15.396837ms)
Dec  5 21:45:29.542: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/rewriteme"... (200; 15.48385ms)
Dec  5 21:45:29.542: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 15.685194ms)
Dec  5 21:45:29.543: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 16.734341ms)
Dec  5 21:45:29.543: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/... (200; 17.086398ms)
Dec  5 21:45:29.544: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/... (200; 18.488788ms)
Dec  5 21:45:29.544: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:460/proxy/: tls baz (200; 18.17122ms)
Dec  5 21:45:29.544: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:462/proxy/: tls qux (200; 18.551146ms)
Dec  5 21:45:29.545: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 18.545658ms)
Dec  5 21:45:29.546: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname2/proxy/: bar (200; 20.211024ms)
Dec  5 21:45:29.551: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname1/proxy/: foo (200; 24.662696ms)
Dec  5 21:45:29.551: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname1/proxy/: tls baz (200; 25.004196ms)
Dec  5 21:45:29.551: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname2/proxy/: tls qux (200; 25.16101ms)
Dec  5 21:45:29.551: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname1/proxy/: foo (200; 25.20189ms)
Dec  5 21:45:29.552: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname2/proxy/: bar (200; 25.657789ms)
Dec  5 21:45:29.566: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/rewriteme"... (200; 14.330303ms)
Dec  5 21:45:29.572: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/rewri... (200; 19.870715ms)
Dec  5 21:45:29.572: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 19.740562ms)
Dec  5 21:45:29.572: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/... (200; 19.421531ms)
Dec  5 21:45:29.572: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 20.048271ms)
Dec  5 21:45:29.572: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 19.827917ms)
Dec  5 21:45:29.572: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/... (200; 19.81188ms)
Dec  5 21:45:29.573: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:462/proxy/: tls qux (200; 20.454429ms)
Dec  5 21:45:29.573: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:460/proxy/: tls baz (200; 20.271256ms)
Dec  5 21:45:29.573: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 20.917053ms)
Dec  5 21:45:29.578: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname2/proxy/: bar (200; 25.222025ms)
Dec  5 21:45:29.578: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname1/proxy/: foo (200; 25.307308ms)
Dec  5 21:45:29.578: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname1/proxy/: foo (200; 25.796372ms)
Dec  5 21:45:29.578: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname2/proxy/: tls qux (200; 25.779812ms)
Dec  5 21:45:29.578: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname1/proxy/: tls baz (200; 26.074439ms)
Dec  5 21:45:29.579: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname2/proxy/: bar (200; 26.329833ms)
Dec  5 21:45:29.590: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/... (200; 11.254633ms)
Dec  5 21:45:29.593: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 13.458965ms)
Dec  5 21:45:29.593: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 13.305479ms)
Dec  5 21:45:29.594: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:460/proxy/: tls baz (200; 14.141983ms)
Dec  5 21:45:29.594: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/rewriteme"... (200; 15.286106ms)
Dec  5 21:45:29.595: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/... (200; 15.520361ms)
Dec  5 21:45:29.600: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 19.395547ms)
Dec  5 21:45:29.600: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname1/proxy/: tls baz (200; 20.585864ms)
Dec  5 21:45:29.600: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname2/proxy/: bar (200; 20.390374ms)
Dec  5 21:45:29.600: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname1/proxy/: foo (200; 19.91176ms)
Dec  5 21:45:29.600: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:462/proxy/: tls qux (200; 20.517029ms)
Dec  5 21:45:29.600: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname2/proxy/: tls qux (200; 20.672057ms)
Dec  5 21:45:29.600: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname2/proxy/: bar (200; 20.415868ms)
Dec  5 21:45:29.600: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/rewri... (200; 21.274545ms)
Dec  5 21:45:29.601: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 21.437843ms)
Dec  5 21:45:29.601: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname1/proxy/: foo (200; 21.332974ms)
Dec  5 21:45:29.616: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/rewri... (200; 14.932134ms)
Dec  5 21:45:29.616: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 15.20389ms)
Dec  5 21:45:29.617: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 15.645808ms)
Dec  5 21:45:29.617: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:462/proxy/: tls qux (200; 16.52163ms)
Dec  5 21:45:29.619: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/... (200; 17.70785ms)
Dec  5 21:45:29.619: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 17.39508ms)
Dec  5 21:45:29.621: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 19.463029ms)
Dec  5 21:45:29.622: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/... (200; 19.684074ms)
Dec  5 21:45:29.623: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:460/proxy/: tls baz (200; 20.570686ms)
Dec  5 21:45:29.623: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/rewriteme"... (200; 21.164673ms)
Dec  5 21:45:29.623: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname2/proxy/: bar (200; 21.701032ms)
Dec  5 21:45:29.628: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname1/proxy/: tls baz (200; 26.645251ms)
Dec  5 21:45:29.629: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname1/proxy/: foo (200; 27.159953ms)
Dec  5 21:45:29.629: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname1/proxy/: foo (200; 27.342864ms)
Dec  5 21:45:29.629: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname2/proxy/: tls qux (200; 27.492405ms)
Dec  5 21:45:29.632: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname2/proxy/: bar (200; 30.221207ms)
Dec  5 21:45:29.645: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:462/proxy/: tls qux (200; 13.156454ms)
Dec  5 21:45:29.650: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 17.777563ms)
Dec  5 21:45:29.650: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/... (200; 18.059349ms)
Dec  5 21:45:29.650: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 18.10914ms)
Dec  5 21:45:29.650: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 18.396729ms)
Dec  5 21:45:29.651: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:460/proxy/: tls baz (200; 18.361873ms)
Dec  5 21:45:29.655: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/rewri... (200; 23.354829ms)
Dec  5 21:45:29.655: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/rewriteme"... (200; 23.136456ms)
Dec  5 21:45:29.655: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname2/proxy/: bar (200; 23.440835ms)
Dec  5 21:45:29.657: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/... (200; 25.229196ms)
Dec  5 21:45:29.658: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 25.529919ms)
Dec  5 21:45:29.660: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname1/proxy/: foo (200; 27.441873ms)
Dec  5 21:45:29.660: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname1/proxy/: foo (200; 27.447307ms)
Dec  5 21:45:29.660: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname2/proxy/: tls qux (200; 27.736684ms)
Dec  5 21:45:29.660: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname1/proxy/: tls baz (200; 27.525707ms)
Dec  5 21:45:29.660: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname2/proxy/: bar (200; 28.332808ms)
Dec  5 21:45:29.673: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 12.579593ms)
Dec  5 21:45:29.678: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 17.353609ms)
Dec  5 21:45:29.680: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname1/proxy/: tls baz (200; 19.326887ms)
Dec  5 21:45:29.680: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/... (200; 18.244843ms)
Dec  5 21:45:29.680: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/rewri... (200; 18.878643ms)
Dec  5 21:45:29.681: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname2/proxy/: tls qux (200; 19.489644ms)
Dec  5 21:45:29.681: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:460/proxy/: tls baz (200; 20.383146ms)
Dec  5 21:45:29.682: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:462/proxy/: tls qux (200; 20.436674ms)
Dec  5 21:45:29.682: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 20.412285ms)
Dec  5 21:45:29.682: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/rewriteme"... (200; 20.899328ms)
Dec  5 21:45:29.687: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname2/proxy/: bar (200; 25.363765ms)
Dec  5 21:45:29.687: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname1/proxy/: foo (200; 26.661309ms)
Dec  5 21:45:29.687: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/... (200; 26.28077ms)
Dec  5 21:45:29.688: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname1/proxy/: foo (200; 26.251839ms)
Dec  5 21:45:29.688: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 26.347544ms)
Dec  5 21:45:29.688: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname2/proxy/: bar (200; 26.488483ms)
Dec  5 21:45:29.708: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 19.2467ms)
Dec  5 21:45:29.708: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:1080/proxy/rewri... (200; 18.865996ms)
Dec  5 21:45:29.708: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:443/proxy/... (200; 19.976179ms)
Dec  5 21:45:29.708: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:160/proxy/: foo (200; 18.866262ms)
Dec  5 21:45:29.708: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:460/proxy/: tls baz (200; 19.530463ms)
Dec  5 21:45:29.707: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9/proxy/rewriteme"... (200; 18.294202ms)
Dec  5 21:45:29.709: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:1080/proxy/... (200; 20.15361ms)
Dec  5 21:45:29.710: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/https:proxy-service-ld9xz-8csk9:462/proxy/: tls qux (200; 21.537221ms)
Dec  5 21:45:29.710: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 20.921974ms)
Dec  5 21:45:29.710: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc267/pods/http:proxy-service-ld9xz-8csk9:162/proxy/: bar (200; 20.872861ms)
Dec  5 21:45:29.713: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname1/proxy/: foo (200; 24.762348ms)
Dec  5 21:45:29.714: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname1/proxy/: foo (200; 24.975849ms)
Dec  5 21:45:29.714: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname1/proxy/: tls baz (200; 25.450972ms)
Dec  5 21:45:29.716: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc267/services/https:proxy-service-ld9xz:tlsportname2/proxy/: tls qux (200; 27.579123ms)
Dec  5 21:45:29.716: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc267/services/http:proxy-service-ld9xz:portname2/proxy/: bar (200; 27.857385ms)
Dec  5 21:45:29.716: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc267/services/proxy-service-ld9xz:portname2/proxy/: bar (200; 28.071466ms)
STEP: deleting { ReplicationController} proxy-service-ld9xz in namespace e2e-tests-proxy-nc267, will wait for the garbage collector to delete the pods
Dec  5 21:45:29.790: INFO: Deleting { ReplicationController} proxy-service-ld9xz took: 14.968804ms
Dec  5 21:45:29.890: INFO: Terminating { ReplicationController} proxy-service-ld9xz pods took: 100.203102ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:45:31.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-nc267" for this suite.
Dec  5 21:45:37.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:45:38.295: INFO: namespace: e2e-tests-proxy-nc267, resource: bindings, ignored listing per whitelist
Dec  5 21:45:38.315: INFO: namespace e2e-tests-proxy-nc267 deletion completed in 6.408686269s

• [SLOW TEST:21.680 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:45:38.316: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-2cd9l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 21:45:38.735: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1ad26380-f8d7-11e8-b962-c6dde3e93636" in namespace "e2e-tests-downward-api-2cd9l" to be "success or failure"
Dec  5 21:45:38.744: INFO: Pod "downwardapi-volume-1ad26380-f8d7-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 8.973077ms
Dec  5 21:45:40.765: INFO: Pod "downwardapi-volume-1ad26380-f8d7-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029877366s
STEP: Saw pod success
Dec  5 21:45:40.765: INFO: Pod "downwardapi-volume-1ad26380-f8d7-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:45:40.773: INFO: Trying to get logs from node 10.191.0.150 pod downwardapi-volume-1ad26380-f8d7-11e8-b962-c6dde3e93636 container client-container: <nil>
STEP: delete the pod
Dec  5 21:45:40.887: INFO: Waiting for pod downwardapi-volume-1ad26380-f8d7-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:45:40.895: INFO: Pod downwardapi-volume-1ad26380-f8d7-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:45:40.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2cd9l" for this suite.
Dec  5 21:45:46.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:45:47.284: INFO: namespace: e2e-tests-downward-api-2cd9l, resource: bindings, ignored listing per whitelist
Dec  5 21:45:47.319: INFO: namespace e2e-tests-downward-api-2cd9l deletion completed in 6.410960645s

• [SLOW TEST:9.003 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:45:47.321: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-vdxk8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 21:45:47.735: INFO: Waiting up to 5m0s for pod "downwardapi-volume-203a3c0b-f8d7-11e8-b962-c6dde3e93636" in namespace "e2e-tests-projected-vdxk8" to be "success or failure"
Dec  5 21:45:47.747: INFO: Pod "downwardapi-volume-203a3c0b-f8d7-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 12.128667ms
Dec  5 21:45:49.757: INFO: Pod "downwardapi-volume-203a3c0b-f8d7-11e8-b962-c6dde3e93636": Phase="Running", Reason="", readiness=true. Elapsed: 2.022374114s
Dec  5 21:45:51.783: INFO: Pod "downwardapi-volume-203a3c0b-f8d7-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048702834s
STEP: Saw pod success
Dec  5 21:45:51.784: INFO: Pod "downwardapi-volume-203a3c0b-f8d7-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:45:51.792: INFO: Trying to get logs from node 10.191.0.150 pod downwardapi-volume-203a3c0b-f8d7-11e8-b962-c6dde3e93636 container client-container: <nil>
STEP: delete the pod
Dec  5 21:45:51.844: INFO: Waiting for pod downwardapi-volume-203a3c0b-f8d7-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:45:51.854: INFO: Pod downwardapi-volume-203a3c0b-f8d7-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:45:51.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vdxk8" for this suite.
Dec  5 21:45:57.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:45:58.120: INFO: namespace: e2e-tests-projected-vdxk8, resource: bindings, ignored listing per whitelist
Dec  5 21:45:58.328: INFO: namespace e2e-tests-projected-vdxk8 deletion completed in 6.460636706s

• [SLOW TEST:11.008 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:45:58.329: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-lw8qk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  5 21:45:58.775: INFO: Waiting up to 5m0s for pod "pod-26cfb116-f8d7-11e8-b962-c6dde3e93636" in namespace "e2e-tests-emptydir-lw8qk" to be "success or failure"
Dec  5 21:45:58.785: INFO: Pod "pod-26cfb116-f8d7-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 10.059958ms
Dec  5 21:46:00.795: INFO: Pod "pod-26cfb116-f8d7-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020435452s
Dec  5 21:46:02.828: INFO: Pod "pod-26cfb116-f8d7-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052624297s
STEP: Saw pod success
Dec  5 21:46:02.828: INFO: Pod "pod-26cfb116-f8d7-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:46:02.838: INFO: Trying to get logs from node 10.191.0.150 pod pod-26cfb116-f8d7-11e8-b962-c6dde3e93636 container test-container: <nil>
STEP: delete the pod
Dec  5 21:46:02.888: INFO: Waiting for pod pod-26cfb116-f8d7-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:46:02.944: INFO: Pod pod-26cfb116-f8d7-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:46:02.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lw8qk" for this suite.
Dec  5 21:46:08.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:46:09.191: INFO: namespace: e2e-tests-emptydir-lw8qk, resource: bindings, ignored listing per whitelist
Dec  5 21:46:09.429: INFO: namespace e2e-tests-emptydir-lw8qk deletion completed in 6.471353417s

• [SLOW TEST:11.100 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:46:09.431: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-cqw95
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  5 21:46:09.771: INFO: Waiting up to 5m0s for pod "pod-2d5d4681-f8d7-11e8-b962-c6dde3e93636" in namespace "e2e-tests-emptydir-cqw95" to be "success or failure"
Dec  5 21:46:09.835: INFO: Pod "pod-2d5d4681-f8d7-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 64.520845ms
Dec  5 21:46:11.844: INFO: Pod "pod-2d5d4681-f8d7-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.073134879s
STEP: Saw pod success
Dec  5 21:46:11.844: INFO: Pod "pod-2d5d4681-f8d7-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:46:11.855: INFO: Trying to get logs from node 10.191.0.150 pod pod-2d5d4681-f8d7-11e8-b962-c6dde3e93636 container test-container: <nil>
STEP: delete the pod
Dec  5 21:46:11.917: INFO: Waiting for pod pod-2d5d4681-f8d7-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:46:11.928: INFO: Pod pod-2d5d4681-f8d7-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:46:11.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cqw95" for this suite.
Dec  5 21:46:17.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:46:18.131: INFO: namespace: e2e-tests-emptydir-cqw95, resource: bindings, ignored listing per whitelist
Dec  5 21:46:18.365: INFO: namespace e2e-tests-emptydir-cqw95 deletion completed in 6.42059419s

• [SLOW TEST:8.934 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:46:18.366: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-mjlxf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  5 21:46:18.718: INFO: Waiting up to 5m0s for pod "pod-32b17015-f8d7-11e8-b962-c6dde3e93636" in namespace "e2e-tests-emptydir-mjlxf" to be "success or failure"
Dec  5 21:46:18.731: INFO: Pod "pod-32b17015-f8d7-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 12.67969ms
Dec  5 21:46:20.741: INFO: Pod "pod-32b17015-f8d7-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022889862s
STEP: Saw pod success
Dec  5 21:46:20.741: INFO: Pod "pod-32b17015-f8d7-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:46:20.749: INFO: Trying to get logs from node 10.191.0.150 pod pod-32b17015-f8d7-11e8-b962-c6dde3e93636 container test-container: <nil>
STEP: delete the pod
Dec  5 21:46:20.802: INFO: Waiting for pod pod-32b17015-f8d7-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:46:20.812: INFO: Pod pod-32b17015-f8d7-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:46:20.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mjlxf" for this suite.
Dec  5 21:46:27.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:46:27.432: INFO: namespace: e2e-tests-emptydir-mjlxf, resource: bindings, ignored listing per whitelist
Dec  5 21:46:27.514: INFO: namespace e2e-tests-emptydir-mjlxf deletion completed in 6.687893147s

• [SLOW TEST:9.148 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:46:27.514: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-q6ts8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-3826c7b8-f8d7-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume secrets
Dec  5 21:46:27.953: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-38338aee-f8d7-11e8-b962-c6dde3e93636" in namespace "e2e-tests-projected-q6ts8" to be "success or failure"
Dec  5 21:46:27.961: INFO: Pod "pod-projected-secrets-38338aee-f8d7-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 8.006766ms
Dec  5 21:46:29.970: INFO: Pod "pod-projected-secrets-38338aee-f8d7-11e8-b962-c6dde3e93636": Phase="Running", Reason="", readiness=true. Elapsed: 2.016714402s
Dec  5 21:46:31.981: INFO: Pod "pod-projected-secrets-38338aee-f8d7-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02796462s
STEP: Saw pod success
Dec  5 21:46:31.981: INFO: Pod "pod-projected-secrets-38338aee-f8d7-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:46:31.990: INFO: Trying to get logs from node 10.191.0.150 pod pod-projected-secrets-38338aee-f8d7-11e8-b962-c6dde3e93636 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  5 21:46:32.045: INFO: Waiting for pod pod-projected-secrets-38338aee-f8d7-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:46:32.053: INFO: Pod pod-projected-secrets-38338aee-f8d7-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:46:32.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-q6ts8" for this suite.
Dec  5 21:46:38.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:46:38.227: INFO: namespace: e2e-tests-projected-q6ts8, resource: bindings, ignored listing per whitelist
Dec  5 21:46:38.527: INFO: namespace e2e-tests-projected-q6ts8 deletion completed in 6.462299503s

• [SLOW TEST:11.013 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:46:38.529: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-ttfd8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec  5 21:46:38.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 create -f - --namespace=e2e-tests-kubectl-ttfd8'
Dec  5 21:46:39.507: INFO: stderr: ""
Dec  5 21:46:39.507: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  5 21:46:39.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ttfd8'
Dec  5 21:46:39.706: INFO: stderr: ""
Dec  5 21:46:39.706: INFO: stdout: "update-demo-nautilus-7h9qf update-demo-nautilus-tr2gw "
Dec  5 21:46:39.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods update-demo-nautilus-7h9qf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ttfd8'
Dec  5 21:46:39.865: INFO: stderr: ""
Dec  5 21:46:39.865: INFO: stdout: ""
Dec  5 21:46:39.865: INFO: update-demo-nautilus-7h9qf is created but not running
Dec  5 21:46:44.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ttfd8'
Dec  5 21:46:45.007: INFO: stderr: ""
Dec  5 21:46:45.007: INFO: stdout: "update-demo-nautilus-7h9qf update-demo-nautilus-tr2gw "
Dec  5 21:46:45.007: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods update-demo-nautilus-7h9qf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ttfd8'
Dec  5 21:46:45.146: INFO: stderr: ""
Dec  5 21:46:45.147: INFO: stdout: "true"
Dec  5 21:46:45.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods update-demo-nautilus-7h9qf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ttfd8'
Dec  5 21:46:45.359: INFO: stderr: ""
Dec  5 21:46:45.359: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 21:46:45.359: INFO: validating pod update-demo-nautilus-7h9qf
Dec  5 21:46:45.384: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 21:46:45.384: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 21:46:45.384: INFO: update-demo-nautilus-7h9qf is verified up and running
Dec  5 21:46:45.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods update-demo-nautilus-tr2gw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ttfd8'
Dec  5 21:46:45.553: INFO: stderr: ""
Dec  5 21:46:45.553: INFO: stdout: "true"
Dec  5 21:46:45.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods update-demo-nautilus-tr2gw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ttfd8'
Dec  5 21:46:45.738: INFO: stderr: ""
Dec  5 21:46:45.738: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 21:46:45.738: INFO: validating pod update-demo-nautilus-tr2gw
Dec  5 21:46:45.763: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 21:46:45.763: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 21:46:45.763: INFO: update-demo-nautilus-tr2gw is verified up and running
STEP: using delete to clean up resources
Dec  5 21:46:45.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-ttfd8'
Dec  5 21:46:45.929: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 21:46:45.930: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  5 21:46:45.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-ttfd8'
Dec  5 21:46:46.083: INFO: stderr: "No resources found.\n"
Dec  5 21:46:46.083: INFO: stdout: ""
Dec  5 21:46:46.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods -l name=update-demo --namespace=e2e-tests-kubectl-ttfd8 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  5 21:46:46.362: INFO: stderr: ""
Dec  5 21:46:46.362: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:46:46.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ttfd8" for this suite.
Dec  5 21:46:52.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:46:52.654: INFO: namespace: e2e-tests-kubectl-ttfd8, resource: bindings, ignored listing per whitelist
Dec  5 21:46:52.965: INFO: namespace e2e-tests-kubectl-ttfd8 deletion completed in 6.567356731s

• [SLOW TEST:14.436 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:46:52.965: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-wcq55
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-tt6nx
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
Dec  5 21:47:02.830: INFO: error from create uninitialized namespace: Internal error occurred: object deleted while waiting for creation
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-xsw5m
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:47:20.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-wcq55" for this suite.
Dec  5 21:47:26.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:47:27.094: INFO: namespace: e2e-tests-namespaces-wcq55, resource: bindings, ignored listing per whitelist
Dec  5 21:47:27.355: INFO: namespace e2e-tests-namespaces-wcq55 deletion completed in 6.418862842s
STEP: Destroying namespace "e2e-tests-nsdeletetest-tt6nx" for this suite.
Dec  5 21:47:27.365: INFO: Namespace e2e-tests-nsdeletetest-tt6nx was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-xsw5m" for this suite.
Dec  5 21:47:33.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:47:33.602: INFO: namespace: e2e-tests-nsdeletetest-xsw5m, resource: bindings, ignored listing per whitelist
Dec  5 21:47:33.850: INFO: namespace e2e-tests-nsdeletetest-xsw5m deletion completed in 6.48487264s

• [SLOW TEST:40.885 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:47:33.854: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-hwsbf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 21:47:34.327: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5fc2bcc1-f8d7-11e8-b962-c6dde3e93636" in namespace "e2e-tests-projected-hwsbf" to be "success or failure"
Dec  5 21:47:34.336: INFO: Pod "downwardapi-volume-5fc2bcc1-f8d7-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 9.008982ms
Dec  5 21:47:36.345: INFO: Pod "downwardapi-volume-5fc2bcc1-f8d7-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017195924s
STEP: Saw pod success
Dec  5 21:47:36.345: INFO: Pod "downwardapi-volume-5fc2bcc1-f8d7-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:47:36.353: INFO: Trying to get logs from node 10.191.0.150 pod downwardapi-volume-5fc2bcc1-f8d7-11e8-b962-c6dde3e93636 container client-container: <nil>
STEP: delete the pod
Dec  5 21:47:36.401: INFO: Waiting for pod downwardapi-volume-5fc2bcc1-f8d7-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:47:36.410: INFO: Pod downwardapi-volume-5fc2bcc1-f8d7-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:47:36.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hwsbf" for this suite.
Dec  5 21:47:42.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:47:42.569: INFO: namespace: e2e-tests-projected-hwsbf, resource: bindings, ignored listing per whitelist
Dec  5 21:47:42.901: INFO: namespace e2e-tests-projected-hwsbf deletion completed in 6.478322921s

• [SLOW TEST:9.047 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:47:42.901: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-5cnh6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec  5 21:47:45.451: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-652e0cb9-f8d7-11e8-b962-c6dde3e93636,GenerateName:,Namespace:e2e-tests-events-5cnh6,SelfLink:/api/v1/namespaces/e2e-tests-events-5cnh6/pods/send-events-652e0cb9-f8d7-11e8-b962-c6dde3e93636,UID:652f6c30-f8d7-11e8-9151-427614c96c42,ResourceVersion:20912,Generation:0,CreationTimestamp:2018-12-05 21:47:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 397401516,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jk6bg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jk6bg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-jk6bg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.0.150,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4214878e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421487900}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 21:47:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 21:47:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 21:47:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 21:47:43 +0000 UTC  }],Message:,Reason:,HostIP:10.191.0.150,PodIP:172.30.248.91,StartTime:2018-12-05 21:47:43 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2018-12-05 21:47:44 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 containerd://b7c48909c80be56b99c508514c83663bcf24974c423ae6b201cdff9eb5321cb4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Dec  5 21:47:47.463: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec  5 21:47:49.474: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:47:49.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-5cnh6" for this suite.
Dec  5 21:48:31.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:48:31.948: INFO: namespace: e2e-tests-events-5cnh6, resource: bindings, ignored listing per whitelist
Dec  5 21:48:31.967: INFO: namespace e2e-tests-events-5cnh6 deletion completed in 42.464798174s

• [SLOW TEST:49.066 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:48:31.968: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-khn2g
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-82598843-f8d7-11e8-b962-c6dde3e93636
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-82598843-f8d7-11e8-b962-c6dde3e93636
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:50:01.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-khn2g" for this suite.
Dec  5 21:50:26.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:50:26.508: INFO: namespace: e2e-tests-configmap-khn2g, resource: bindings, ignored listing per whitelist
Dec  5 21:50:26.508: INFO: namespace e2e-tests-configmap-khn2g deletion completed in 24.56496891s

• [SLOW TEST:114.539 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:50:26.508: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-2p757
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 21:50:26.836: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c6956fad-f8d7-11e8-b962-c6dde3e93636" in namespace "e2e-tests-projected-2p757" to be "success or failure"
Dec  5 21:50:26.844: INFO: Pod "downwardapi-volume-c6956fad-f8d7-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 7.488188ms
Dec  5 21:50:28.860: INFO: Pod "downwardapi-volume-c6956fad-f8d7-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023838383s
STEP: Saw pod success
Dec  5 21:50:28.860: INFO: Pod "downwardapi-volume-c6956fad-f8d7-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:50:28.870: INFO: Trying to get logs from node 10.191.0.150 pod downwardapi-volume-c6956fad-f8d7-11e8-b962-c6dde3e93636 container client-container: <nil>
STEP: delete the pod
Dec  5 21:50:28.930: INFO: Waiting for pod downwardapi-volume-c6956fad-f8d7-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:50:28.939: INFO: Pod downwardapi-volume-c6956fad-f8d7-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:50:28.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2p757" for this suite.
Dec  5 21:50:34.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:50:35.217: INFO: namespace: e2e-tests-projected-2p757, resource: bindings, ignored listing per whitelist
Dec  5 21:50:35.473: INFO: namespace e2e-tests-projected-2p757 deletion completed in 6.519128708s

• [SLOW TEST:8.965 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:50:35.473: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-fq957
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secret-namespace-bhjgh
STEP: Creating secret with name secret-test-cbef47da-f8d7-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume secrets
Dec  5 21:50:36.069: INFO: Waiting up to 5m0s for pod "pod-secrets-cc170cc6-f8d7-11e8-b962-c6dde3e93636" in namespace "e2e-tests-secrets-fq957" to be "success or failure"
Dec  5 21:50:36.077: INFO: Pod "pod-secrets-cc170cc6-f8d7-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 8.057477ms
Dec  5 21:50:38.085: INFO: Pod "pod-secrets-cc170cc6-f8d7-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016382059s
STEP: Saw pod success
Dec  5 21:50:38.085: INFO: Pod "pod-secrets-cc170cc6-f8d7-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:50:38.099: INFO: Trying to get logs from node 10.191.0.150 pod pod-secrets-cc170cc6-f8d7-11e8-b962-c6dde3e93636 container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 21:50:38.150: INFO: Waiting for pod pod-secrets-cc170cc6-f8d7-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:50:38.157: INFO: Pod pod-secrets-cc170cc6-f8d7-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:50:38.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-fq957" for this suite.
Dec  5 21:50:44.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:50:44.540: INFO: namespace: e2e-tests-secrets-fq957, resource: bindings, ignored listing per whitelist
Dec  5 21:50:44.630: INFO: namespace e2e-tests-secrets-fq957 deletion completed in 6.461325866s
STEP: Destroying namespace "e2e-tests-secret-namespace-bhjgh" for this suite.
Dec  5 21:50:50.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:50:50.776: INFO: namespace: e2e-tests-secret-namespace-bhjgh, resource: bindings, ignored listing per whitelist
Dec  5 21:50:51.139: INFO: namespace e2e-tests-secret-namespace-bhjgh deletion completed in 6.508739756s

• [SLOW TEST:15.666 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:50:51.140: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-d9ds6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 21:50:51.503: INFO: Creating ReplicaSet my-hostname-basic-d54cd16a-f8d7-11e8-b962-c6dde3e93636
Dec  5 21:50:51.529: INFO: Pod name my-hostname-basic-d54cd16a-f8d7-11e8-b962-c6dde3e93636: Found 0 pods out of 1
Dec  5 21:50:56.555: INFO: Pod name my-hostname-basic-d54cd16a-f8d7-11e8-b962-c6dde3e93636: Found 1 pods out of 1
Dec  5 21:50:56.555: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-d54cd16a-f8d7-11e8-b962-c6dde3e93636" is running
Dec  5 21:50:56.564: INFO: Pod "my-hostname-basic-d54cd16a-f8d7-11e8-b962-c6dde3e93636-hjxc5" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-05 21:50:51 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-05 21:50:52 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-05 21:50:52 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-05 21:50:51 +0000 UTC Reason: Message:}])
Dec  5 21:50:56.564: INFO: Trying to dial the pod
Dec  5 21:51:01.599: INFO: Controller my-hostname-basic-d54cd16a-f8d7-11e8-b962-c6dde3e93636: Got expected result from replica 1 [my-hostname-basic-d54cd16a-f8d7-11e8-b962-c6dde3e93636-hjxc5]: "my-hostname-basic-d54cd16a-f8d7-11e8-b962-c6dde3e93636-hjxc5", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:51:01.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-d9ds6" for this suite.
Dec  5 21:51:07.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:51:07.858: INFO: namespace: e2e-tests-replicaset-d9ds6, resource: bindings, ignored listing per whitelist
Dec  5 21:51:07.975: INFO: namespace e2e-tests-replicaset-d9ds6 deletion completed in 6.36097188s

• [SLOW TEST:16.836 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:51:07.976: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-xhntg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Dec  5 21:51:08.282: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  5 21:51:08.303: INFO: Waiting for terminating namespaces to be deleted...
Dec  5 21:51:08.312: INFO: 
Logging pods the kubelet thinks is on node 10.191.0.134 before test
Dec  5 21:51:08.349: INFO: ibm-master-proxy-static-10.191.0.134 from kube-system started at <nil> (0 container statuses recorded)
Dec  5 21:51:08.349: INFO: kube-dns-autoscaler-587cd5cd44-wtn48 from kube-system started at 2018-12-05 20:13:25 +0000 UTC (1 container statuses recorded)
Dec  5 21:51:08.349: INFO: 	Container autoscaler ready: true, restart count 0
Dec  5 21:51:08.349: INFO: ibm-storage-watcher-d7fb6f996-sw7ft from kube-system started at 2018-12-05 20:13:25 +0000 UTC (1 container statuses recorded)
Dec  5 21:51:08.349: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Dec  5 21:51:08.349: INFO: ibm-file-plugin-66d9565b46-pmd5k from kube-system started at 2018-12-05 20:13:25 +0000 UTC (1 container statuses recorded)
Dec  5 21:51:08.349: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Dec  5 21:51:08.349: INFO: calico-node-hjfvw from kube-system started at 2018-12-05 20:13:25 +0000 UTC (2 container statuses recorded)
Dec  5 21:51:08.349: INFO: 	Container calico-node ready: true, restart count 0
Dec  5 21:51:08.349: INFO: 	Container install-cni ready: true, restart count 0
Dec  5 21:51:08.349: INFO: sonobuoy-systemd-logs-daemon-set-9347e99d64a449f0-2fct4 from heptio-sonobuoy started at 2018-12-05 20:51:14 +0000 UTC (2 container statuses recorded)
Dec  5 21:51:08.350: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec  5 21:51:08.350: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  5 21:51:08.350: INFO: calico-kube-controllers-5c699798bc-szf68 from kube-system started at 2018-12-05 20:13:25 +0000 UTC (1 container statuses recorded)
Dec  5 21:51:08.350: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec  5 21:51:08.350: INFO: kube-dns-amd64-fddfcc69-drvmh from kube-system started at 2018-12-05 20:13:25 +0000 UTC (3 container statuses recorded)
Dec  5 21:51:08.350: INFO: 	Container dnsmasq ready: true, restart count 0
Dec  5 21:51:08.350: INFO: 	Container kubedns ready: true, restart count 0
Dec  5 21:51:08.350: INFO: 	Container sidecar ready: true, restart count 0
Dec  5 21:51:08.350: INFO: kubernetes-dashboard-b6b5cbdb4-n88tm from kube-system started at 2018-12-05 20:13:25 +0000 UTC (1 container statuses recorded)
Dec  5 21:51:08.350: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec  5 21:51:08.350: INFO: vpn-65599665d9-g4r5v from kube-system started at 2018-12-05 20:13:25 +0000 UTC (1 container statuses recorded)
Dec  5 21:51:08.350: INFO: 	Container vpn ready: true, restart count 0
Dec  5 21:51:08.350: INFO: kube-dns-amd64-fddfcc69-ph96f from kube-system started at 2018-12-05 20:13:55 +0000 UTC (3 container statuses recorded)
Dec  5 21:51:08.350: INFO: 	Container dnsmasq ready: true, restart count 0
Dec  5 21:51:08.350: INFO: 	Container kubedns ready: true, restart count 0
Dec  5 21:51:08.350: INFO: 	Container sidecar ready: true, restart count 0
Dec  5 21:51:08.350: INFO: ibm-kube-fluentd-kszbp from kube-system started at 2018-12-05 20:19:21 +0000 UTC (1 container statuses recorded)
Dec  5 21:51:08.350: INFO: 	Container fluentd ready: true, restart count 0
Dec  5 21:51:08.350: INFO: ibm-keepalived-watcher-c8gfz from kube-system started at 2018-12-05 20:13:25 +0000 UTC (1 container statuses recorded)
Dec  5 21:51:08.350: INFO: 	Container keepalived-watcher ready: true, restart count 0
Dec  5 21:51:08.350: INFO: 
Logging pods the kubelet thinks is on node 10.191.0.147 before test
Dec  5 21:51:08.389: INFO: calico-node-xgzvj from kube-system started at 2018-12-05 20:13:32 +0000 UTC (2 container statuses recorded)
Dec  5 21:51:08.389: INFO: 	Container calico-node ready: true, restart count 0
Dec  5 21:51:08.389: INFO: 	Container install-cni ready: true, restart count 0
Dec  5 21:51:08.389: INFO: sonobuoy-e2e-job-bf9289e3f16942e1 from heptio-sonobuoy started at 2018-12-05 20:51:14 +0000 UTC (2 container statuses recorded)
Dec  5 21:51:08.389: INFO: 	Container e2e ready: true, restart count 0
Dec  5 21:51:08.389: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  5 21:51:08.389: INFO: sonobuoy-systemd-logs-daemon-set-9347e99d64a449f0-dnc6s from heptio-sonobuoy started at 2018-12-05 20:51:14 +0000 UTC (2 container statuses recorded)
Dec  5 21:51:08.389: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec  5 21:51:08.389: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  5 21:51:08.389: INFO: ibm-master-proxy-static-10.191.0.147 from kube-system started at <nil> (0 container statuses recorded)
Dec  5 21:51:08.389: INFO: ibm-keepalived-watcher-8sx6s from kube-system started at 2018-12-05 20:13:32 +0000 UTC (1 container statuses recorded)
Dec  5 21:51:08.389: INFO: 	Container keepalived-watcher ready: true, restart count 0
Dec  5 21:51:08.389: INFO: ibm-cloud-provider-ip-169-61-124-166-74499dcdfd-4qnpc from ibm-system started at 2018-12-05 20:17:26 +0000 UTC (1 container statuses recorded)
Dec  5 21:51:08.389: INFO: 	Container ibm-cloud-provider-ip-169-61-124-166 ready: true, restart count 0
Dec  5 21:51:08.390: INFO: public-cr13c0509290e4443aab67bdb06ca2f6df-alb1-8576b8658-28rzk from kube-system started at 2018-12-05 20:18:36 +0000 UTC (4 container statuses recorded)
Dec  5 21:51:08.390: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Dec  5 21:51:08.390: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Dec  5 21:51:08.390: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Dec  5 21:51:08.390: INFO: 	Container nginx-ingress ready: true, restart count 0
Dec  5 21:51:08.390: INFO: ibm-kube-fluentd-zkwzj from kube-system started at 2018-12-05 20:19:21 +0000 UTC (1 container statuses recorded)
Dec  5 21:51:08.390: INFO: 	Container fluentd ready: true, restart count 0
Dec  5 21:51:08.390: INFO: test-k8s-e2e-pvg-master-verification from default started at 2018-12-05 20:50:44 +0000 UTC (1 container statuses recorded)
Dec  5 21:51:08.390: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Dec  5 21:51:08.390: INFO: 
Logging pods the kubelet thinks is on node 10.191.0.150 before test
Dec  5 21:51:08.415: INFO: ibm-keepalived-watcher-fpp78 from kube-system started at 2018-12-05 20:13:31 +0000 UTC (1 container statuses recorded)
Dec  5 21:51:08.415: INFO: 	Container keepalived-watcher ready: true, restart count 0
Dec  5 21:51:08.415: INFO: metrics-server-5b95c9cc4c-hjph5 from kube-system started at 2018-12-05 20:14:11 +0000 UTC (2 container statuses recorded)
Dec  5 21:51:08.415: INFO: 	Container metrics-server ready: true, restart count 0
Dec  5 21:51:08.415: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Dec  5 21:51:08.415: INFO: ibm-cloud-provider-ip-169-61-124-166-74499dcdfd-rcg2p from ibm-system started at 2018-12-05 20:17:26 +0000 UTC (1 container statuses recorded)
Dec  5 21:51:08.415: INFO: 	Container ibm-cloud-provider-ip-169-61-124-166 ready: true, restart count 0
Dec  5 21:51:08.415: INFO: public-cr13c0509290e4443aab67bdb06ca2f6df-alb1-8576b8658-lhtpj from kube-system started at 2018-12-05 20:18:36 +0000 UTC (4 container statuses recorded)
Dec  5 21:51:08.415: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Dec  5 21:51:08.415: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Dec  5 21:51:08.415: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Dec  5 21:51:08.415: INFO: 	Container nginx-ingress ready: true, restart count 0
Dec  5 21:51:08.416: INFO: sonobuoy-systemd-logs-daemon-set-9347e99d64a449f0-bpd58 from heptio-sonobuoy started at 2018-12-05 20:51:14 +0000 UTC (2 container statuses recorded)
Dec  5 21:51:08.416: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec  5 21:51:08.416: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  5 21:51:08.416: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-05 20:51:09 +0000 UTC (1 container statuses recorded)
Dec  5 21:51:08.416: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  5 21:51:08.416: INFO: ibm-master-proxy-static-10.191.0.150 from kube-system started at <nil> (0 container statuses recorded)
Dec  5 21:51:08.416: INFO: calico-node-x9v6g from kube-system started at 2018-12-05 20:13:31 +0000 UTC (2 container statuses recorded)
Dec  5 21:51:08.416: INFO: 	Container calico-node ready: true, restart count 0
Dec  5 21:51:08.416: INFO: 	Container install-cni ready: true, restart count 0
Dec  5 21:51:08.416: INFO: ibm-kube-fluentd-qswkt from kube-system started at 2018-12-05 20:19:21 +0000 UTC (1 container statuses recorded)
Dec  5 21:51:08.416: INFO: 	Container fluentd ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-e0a1b7a4-f8d7-11e8-b962-c6dde3e93636 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-e0a1b7a4-f8d7-11e8-b962-c6dde3e93636 off the node 10.191.0.150
STEP: verifying the node doesn't have the label kubernetes.io/e2e-e0a1b7a4-f8d7-11e8-b962-c6dde3e93636
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:51:12.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-xhntg" for this suite.
Dec  5 21:51:34.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:51:35.099: INFO: namespace: e2e-tests-sched-pred-xhntg, resource: bindings, ignored listing per whitelist
Dec  5 21:51:35.187: INFO: namespace e2e-tests-sched-pred-xhntg deletion completed in 22.540072966s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:27.212 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:51:35.188: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-hgw8h
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-hgw8h
Dec  5 21:51:37.555: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-hgw8h
STEP: checking the pod's current state and verifying that restartCount is present
Dec  5 21:51:37.568: INFO: Initial restart count of pod liveness-http is 0
Dec  5 21:51:55.711: INFO: Restart count of pod e2e-tests-container-probe-hgw8h/liveness-http is now 1 (18.143223874s elapsed)
Dec  5 21:52:15.831: INFO: Restart count of pod e2e-tests-container-probe-hgw8h/liveness-http is now 2 (38.262562258s elapsed)
Dec  5 21:52:35.990: INFO: Restart count of pod e2e-tests-container-probe-hgw8h/liveness-http is now 3 (58.421880102s elapsed)
Dec  5 21:52:56.227: INFO: Restart count of pod e2e-tests-container-probe-hgw8h/liveness-http is now 4 (1m18.659467117s elapsed)
Dec  5 21:53:56.826: INFO: Restart count of pod e2e-tests-container-probe-hgw8h/liveness-http is now 5 (2m19.25783141s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:53:56.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-hgw8h" for this suite.
Dec  5 21:54:02.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:54:03.153: INFO: namespace: e2e-tests-container-probe-hgw8h, resource: bindings, ignored listing per whitelist
Dec  5 21:54:03.477: INFO: namespace e2e-tests-container-probe-hgw8h deletion completed in 6.613812646s

• [SLOW TEST:148.289 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:54:03.477: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-qkfs4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 21:54:21.858: INFO: Container started at 2018-12-05 21:54:04 +0000 UTC, pod became ready at 2018-12-05 21:54:21 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:54:21.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-qkfs4" for this suite.
Dec  5 21:54:45.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:54:46.238: INFO: namespace: e2e-tests-container-probe-qkfs4, resource: bindings, ignored listing per whitelist
Dec  5 21:54:46.398: INFO: namespace e2e-tests-container-probe-qkfs4 deletion completed in 24.46273545s

• [SLOW TEST:42.921 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:54:46.399: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-2lw5g
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Dec  5 21:54:46.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 cluster-info'
Dec  5 21:54:46.870: INFO: stderr: ""
Dec  5 21:54:46.870: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:54:46.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2lw5g" for this suite.
Dec  5 21:54:52.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:54:53.257: INFO: namespace: e2e-tests-kubectl-2lw5g, resource: bindings, ignored listing per whitelist
Dec  5 21:54:53.320: INFO: namespace e2e-tests-kubectl-2lw5g deletion completed in 6.383920737s

• [SLOW TEST:6.921 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:54:53.321: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-sj57g
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 21:54:53.632: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:54:54.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-sj57g" for this suite.
Dec  5 21:55:00.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:55:01.010: INFO: namespace: e2e-tests-custom-resource-definition-sj57g, resource: bindings, ignored listing per whitelist
Dec  5 21:55:01.223: INFO: namespace e2e-tests-custom-resource-definition-sj57g deletion completed in 6.462041932s

• [SLOW TEST:7.902 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:55:01.223: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-wlt5s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 21:55:01.573: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6a571031-f8d8-11e8-b962-c6dde3e93636" in namespace "e2e-tests-projected-wlt5s" to be "success or failure"
Dec  5 21:55:01.581: INFO: Pod "downwardapi-volume-6a571031-f8d8-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 8.143436ms
Dec  5 21:55:03.591: INFO: Pod "downwardapi-volume-6a571031-f8d8-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017998784s
STEP: Saw pod success
Dec  5 21:55:03.591: INFO: Pod "downwardapi-volume-6a571031-f8d8-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:55:03.635: INFO: Trying to get logs from node 10.191.0.150 pod downwardapi-volume-6a571031-f8d8-11e8-b962-c6dde3e93636 container client-container: <nil>
STEP: delete the pod
Dec  5 21:55:03.690: INFO: Waiting for pod downwardapi-volume-6a571031-f8d8-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:55:03.698: INFO: Pod downwardapi-volume-6a571031-f8d8-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:55:03.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wlt5s" for this suite.
Dec  5 21:55:09.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:55:10.089: INFO: namespace: e2e-tests-projected-wlt5s, resource: bindings, ignored listing per whitelist
Dec  5 21:55:10.204: INFO: namespace e2e-tests-projected-wlt5s deletion completed in 6.489615377s

• [SLOW TEST:8.981 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:55:10.205: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-mwt8d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Dec  5 21:55:10.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 --namespace=e2e-tests-kubectl-mwt8d run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec  5 21:55:12.573: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec  5 21:55:12.573: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:55:14.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mwt8d" for this suite.
Dec  5 21:55:20.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:55:20.874: INFO: namespace: e2e-tests-kubectl-mwt8d, resource: bindings, ignored listing per whitelist
Dec  5 21:55:21.097: INFO: namespace e2e-tests-kubectl-mwt8d deletion completed in 6.43215872s

• [SLOW TEST:10.893 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:55:21.097: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-hbzl2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-hbzl2
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-hbzl2
STEP: Deleting pre-stop pod
Dec  5 21:55:34.754: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:55:34.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-hbzl2" for this suite.
Dec  5 21:56:14.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:56:15.252: INFO: namespace: e2e-tests-prestop-hbzl2, resource: bindings, ignored listing per whitelist
Dec  5 21:56:15.286: INFO: namespace e2e-tests-prestop-hbzl2 deletion completed in 40.504466142s

• [SLOW TEST:54.189 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:56:15.287: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-478c4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Dec  5 21:56:15.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 create -f - --namespace=e2e-tests-kubectl-478c4'
Dec  5 21:56:15.853: INFO: stderr: ""
Dec  5 21:56:15.853: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Dec  5 21:56:16.862: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 21:56:16.862: INFO: Found 0 / 1
Dec  5 21:56:17.864: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 21:56:17.864: INFO: Found 1 / 1
Dec  5 21:56:17.864: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  5 21:56:17.873: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 21:56:17.873: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Dec  5 21:56:17.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 logs redis-master-m7fxv redis-master --namespace=e2e-tests-kubectl-478c4'
Dec  5 21:56:18.023: INFO: stderr: ""
Dec  5 21:56:18.023: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 05 Dec 21:56:16.933 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 05 Dec 21:56:16.933 # Server started, Redis version 3.2.12\n1:M 05 Dec 21:56:16.933 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 05 Dec 21:56:16.933 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Dec  5 21:56:18.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 log redis-master-m7fxv redis-master --namespace=e2e-tests-kubectl-478c4 --tail=1'
Dec  5 21:56:18.180: INFO: stderr: ""
Dec  5 21:56:18.180: INFO: stdout: "1:M 05 Dec 21:56:16.933 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Dec  5 21:56:18.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 log redis-master-m7fxv redis-master --namespace=e2e-tests-kubectl-478c4 --limit-bytes=1'
Dec  5 21:56:18.339: INFO: stderr: ""
Dec  5 21:56:18.339: INFO: stdout: " "
STEP: exposing timestamps
Dec  5 21:56:18.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 log redis-master-m7fxv redis-master --namespace=e2e-tests-kubectl-478c4 --tail=1 --timestamps'
Dec  5 21:56:18.499: INFO: stderr: ""
Dec  5 21:56:18.499: INFO: stdout: "2018-12-05T21:56:16.934846693Z 1:M 05 Dec 21:56:16.933 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Dec  5 21:56:21.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 log redis-master-m7fxv redis-master --namespace=e2e-tests-kubectl-478c4 --since=1s'
Dec  5 21:56:21.145: INFO: stderr: ""
Dec  5 21:56:21.145: INFO: stdout: ""
Dec  5 21:56:21.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 log redis-master-m7fxv redis-master --namespace=e2e-tests-kubectl-478c4 --since=24h'
Dec  5 21:56:21.400: INFO: stderr: ""
Dec  5 21:56:21.400: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 05 Dec 21:56:16.933 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 05 Dec 21:56:16.933 # Server started, Redis version 3.2.12\n1:M 05 Dec 21:56:16.933 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 05 Dec 21:56:16.933 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Dec  5 21:56:21.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-478c4'
Dec  5 21:56:21.568: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 21:56:21.568: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Dec  5 21:56:21.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-478c4'
Dec  5 21:56:21.726: INFO: stderr: "No resources found.\n"
Dec  5 21:56:21.726: INFO: stdout: ""
Dec  5 21:56:21.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 get pods -l name=nginx --namespace=e2e-tests-kubectl-478c4 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  5 21:56:21.885: INFO: stderr: ""
Dec  5 21:56:21.885: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:56:21.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-478c4" for this suite.
Dec  5 21:56:27.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:56:28.173: INFO: namespace: e2e-tests-kubectl-478c4, resource: bindings, ignored listing per whitelist
Dec  5 21:56:28.353: INFO: namespace e2e-tests-kubectl-478c4 deletion completed in 6.403984415s

• [SLOW TEST:13.066 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:56:28.354: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-pczh6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-9e47f6b6-f8d8-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume secrets
Dec  5 21:56:28.723: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9e49b377-f8d8-11e8-b962-c6dde3e93636" in namespace "e2e-tests-projected-pczh6" to be "success or failure"
Dec  5 21:56:28.739: INFO: Pod "pod-projected-secrets-9e49b377-f8d8-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 16.217429ms
Dec  5 21:56:30.747: INFO: Pod "pod-projected-secrets-9e49b377-f8d8-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024720407s
STEP: Saw pod success
Dec  5 21:56:30.748: INFO: Pod "pod-projected-secrets-9e49b377-f8d8-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:56:30.764: INFO: Trying to get logs from node 10.191.0.150 pod pod-projected-secrets-9e49b377-f8d8-11e8-b962-c6dde3e93636 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  5 21:56:30.835: INFO: Waiting for pod pod-projected-secrets-9e49b377-f8d8-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:56:30.846: INFO: Pod pod-projected-secrets-9e49b377-f8d8-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:56:30.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pczh6" for this suite.
Dec  5 21:56:36.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:56:37.266: INFO: namespace: e2e-tests-projected-pczh6, resource: bindings, ignored listing per whitelist
Dec  5 21:56:37.307: INFO: namespace e2e-tests-projected-pczh6 deletion completed in 6.448179849s

• [SLOW TEST:8.954 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:56:37.309: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-jtp2k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Dec  5 21:56:39.687: INFO: Pod pod-hostip-a39b7b66-f8d8-11e8-b962-c6dde3e93636 has hostIP: 10.191.0.150
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:56:39.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-jtp2k" for this suite.
Dec  5 21:57:03.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:57:03.984: INFO: namespace: e2e-tests-pods-jtp2k, resource: bindings, ignored listing per whitelist
Dec  5 21:57:04.129: INFO: namespace e2e-tests-pods-jtp2k deletion completed in 24.427887794s

• [SLOW TEST:26.821 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:57:04.132: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-5crw7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-5crw7
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-5crw7
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-5crw7
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-5crw7
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-5crw7
Dec  5 21:57:08.627: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-5crw7, name: ss-0, uid: b5db3aab-f8d8-11e8-bcf8-b20187c1163a, status phase: Pending. Waiting for statefulset controller to delete.
Dec  5 21:57:08.809: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-5crw7, name: ss-0, uid: b5db3aab-f8d8-11e8-bcf8-b20187c1163a, status phase: Failed. Waiting for statefulset controller to delete.
Dec  5 21:57:08.821: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-5crw7, name: ss-0, uid: b5db3aab-f8d8-11e8-bcf8-b20187c1163a, status phase: Failed. Waiting for statefulset controller to delete.
Dec  5 21:57:08.836: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-5crw7
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-5crw7
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-5crw7 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  5 21:57:13.259: INFO: Deleting all statefulset in ns e2e-tests-statefulset-5crw7
Dec  5 21:57:13.270: INFO: Scaling statefulset ss to 0
Dec  5 21:57:23.372: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 21:57:23.384: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:57:23.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-5crw7" for this suite.
Dec  5 21:57:29.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:57:29.661: INFO: namespace: e2e-tests-statefulset-5crw7, resource: bindings, ignored listing per whitelist
Dec  5 21:57:29.899: INFO: namespace e2e-tests-statefulset-5crw7 deletion completed in 6.461914679s

• [SLOW TEST:25.767 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:57:29.900: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-dnbd4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 21:57:30.253: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c2f67e0c-f8d8-11e8-b962-c6dde3e93636" in namespace "e2e-tests-downward-api-dnbd4" to be "success or failure"
Dec  5 21:57:30.261: INFO: Pod "downwardapi-volume-c2f67e0c-f8d8-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 7.397657ms
Dec  5 21:57:32.269: INFO: Pod "downwardapi-volume-c2f67e0c-f8d8-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016177166s
STEP: Saw pod success
Dec  5 21:57:32.269: INFO: Pod "downwardapi-volume-c2f67e0c-f8d8-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:57:32.277: INFO: Trying to get logs from node 10.191.0.150 pod downwardapi-volume-c2f67e0c-f8d8-11e8-b962-c6dde3e93636 container client-container: <nil>
STEP: delete the pod
Dec  5 21:57:32.333: INFO: Waiting for pod downwardapi-volume-c2f67e0c-f8d8-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:57:32.346: INFO: Pod downwardapi-volume-c2f67e0c-f8d8-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:57:32.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dnbd4" for this suite.
Dec  5 21:57:38.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:57:38.494: INFO: namespace: e2e-tests-downward-api-dnbd4, resource: bindings, ignored listing per whitelist
Dec  5 21:57:38.768: INFO: namespace e2e-tests-downward-api-dnbd4 deletion completed in 6.407768487s

• [SLOW TEST:8.868 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:57:38.768: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-fnrj2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-c8415e3e-f8d8-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume configMaps
Dec  5 21:57:39.164: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c84618cf-f8d8-11e8-b962-c6dde3e93636" in namespace "e2e-tests-projected-fnrj2" to be "success or failure"
Dec  5 21:57:39.176: INFO: Pod "pod-projected-configmaps-c84618cf-f8d8-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 11.693381ms
Dec  5 21:57:41.186: INFO: Pod "pod-projected-configmaps-c84618cf-f8d8-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02118488s
STEP: Saw pod success
Dec  5 21:57:41.186: INFO: Pod "pod-projected-configmaps-c84618cf-f8d8-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:57:41.196: INFO: Trying to get logs from node 10.191.0.150 pod pod-projected-configmaps-c84618cf-f8d8-11e8-b962-c6dde3e93636 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 21:57:41.246: INFO: Waiting for pod pod-projected-configmaps-c84618cf-f8d8-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:57:41.255: INFO: Pod pod-projected-configmaps-c84618cf-f8d8-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:57:41.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fnrj2" for this suite.
Dec  5 21:57:47.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:57:47.672: INFO: namespace: e2e-tests-projected-fnrj2, resource: bindings, ignored listing per whitelist
Dec  5 21:57:47.680: INFO: namespace e2e-tests-projected-fnrj2 deletion completed in 6.408983865s

• [SLOW TEST:8.912 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:57:47.681: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-dwb5p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  5 21:57:50.636: INFO: Successfully updated pod "pod-update-cd8c668c-f8d8-11e8-b962-c6dde3e93636"
STEP: verifying the updated pod is in kubernetes
Dec  5 21:57:50.656: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:57:50.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-dwb5p" for this suite.
Dec  5 21:58:14.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:58:14.890: INFO: namespace: e2e-tests-pods-dwb5p, resource: bindings, ignored listing per whitelist
Dec  5 21:58:15.002: INFO: namespace e2e-tests-pods-dwb5p deletion completed in 24.327443696s

• [SLOW TEST:27.322 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:58:15.005: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-xdt6g
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 21:58:15.444: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  5 21:58:17.464: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec  5 21:58:19.487: INFO: Creating deployment "test-rollover-deployment"
Dec  5 21:58:19.503: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec  5 21:58:21.516: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec  5 21:58:21.537: INFO: Ensure that both replica sets have 1 created replica
Dec  5 21:58:21.557: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec  5 21:58:21.576: INFO: Updating deployment test-rollover-deployment
Dec  5 21:58:21.576: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec  5 21:58:23.590: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec  5 21:58:23.608: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec  5 21:58:23.648: INFO: all replica sets need to contain the pod-template-hash label
Dec  5 21:58:23.648: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679643899, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679643899, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679643902, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679643899, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  5 21:58:25.668: INFO: all replica sets need to contain the pod-template-hash label
Dec  5 21:58:25.668: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679643899, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679643899, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679643902, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679643899, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  5 21:58:27.677: INFO: all replica sets need to contain the pod-template-hash label
Dec  5 21:58:27.677: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679643899, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679643899, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679643902, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679643899, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  5 21:58:29.696: INFO: all replica sets need to contain the pod-template-hash label
Dec  5 21:58:29.696: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679643899, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679643899, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679643902, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679643899, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  5 21:58:31.667: INFO: all replica sets need to contain the pod-template-hash label
Dec  5 21:58:31.667: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679643899, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679643899, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679643902, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679643899, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  5 21:58:33.667: INFO: 
Dec  5 21:58:33.667: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  5 21:58:33.695: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-xdt6g,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xdt6g/deployments/test-rollover-deployment,UID:e0526669-f8d8-11e8-9151-427614c96c42,ResourceVersion:23135,Generation:2,CreationTimestamp:2018-12-05 21:58:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-05 21:58:19 +0000 UTC 2018-12-05 21:58:19 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-05 21:58:32 +0000 UTC 2018-12-05 21:58:19 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec  5 21:58:33.706: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-xdt6g,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xdt6g/replicasets/test-rollover-deployment-5b76ff8c4,UID:e19268b2-f8d8-11e8-bcf8-b20187c1163a,ResourceVersion:23126,Generation:2,CreationTimestamp:2018-12-05 21:58:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment e0526669-f8d8-11e8-9151-427614c96c42 0xc4227e4dc7 0xc4227e4dc8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  5 21:58:33.706: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec  5 21:58:33.706: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-xdt6g,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xdt6g/replicasets/test-rollover-controller,UID:dde1a8da-f8d8-11e8-9151-427614c96c42,ResourceVersion:23134,Generation:2,CreationTimestamp:2018-12-05 21:58:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment e0526669-f8d8-11e8-9151-427614c96c42 0xc4227e4cfe 0xc4227e4cff}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  5 21:58:33.707: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-xdt6g,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xdt6g/replicasets/test-rollover-deployment-6975f4fb87,UID:e0580ee7-f8d8-11e8-bcf8-b20187c1163a,ResourceVersion:23056,Generation:2,CreationTimestamp:2018-12-05 21:58:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment e0526669-f8d8-11e8-9151-427614c96c42 0xc4227e4e87 0xc4227e4e88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  5 21:58:33.715: INFO: Pod "test-rollover-deployment-5b76ff8c4-js269" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-js269,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-xdt6g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdt6g/pods/test-rollover-deployment-5b76ff8c4-js269,UID:e19b59d8-f8d8-11e8-bcf8-b20187c1163a,ResourceVersion:23071,Generation:0,CreationTimestamp:2018-12-05 21:58:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 e19268b2-f8d8-11e8-bcf8-b20187c1163a 0xc4227e5980 0xc4227e5981}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5xdvj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5xdvj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-5xdvj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.0.150,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4227e59f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4227e5a10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 21:58:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 21:58:22 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 21:58:22 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 21:58:21 +0000 UTC  }],Message:,Reason:,HostIP:10.191.0.150,PodIP:172.30.248.110,StartTime:2018-12-05 21:58:21 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-05 21:58:22 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://124325f0becd2e6795a2208d3a70f606400917710da0917859343487577f5585}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:58:33.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-xdt6g" for this suite.
Dec  5 21:58:41.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:58:41.915: INFO: namespace: e2e-tests-deployment-xdt6g, resource: bindings, ignored listing per whitelist
Dec  5 21:58:42.261: INFO: namespace e2e-tests-deployment-xdt6g deletion completed in 8.523211681s

• [SLOW TEST:27.256 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:58:42.262: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-4tzwz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-4tzwz A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-4tzwz;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-4tzwz A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-4tzwz;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-4tzwz.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-4tzwz.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-4tzwz.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-4tzwz.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-4tzwz.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-4tzwz.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-4tzwz.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-4tzwz.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-4tzwz.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-4tzwz.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-4tzwz.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-4tzwz.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-4tzwz.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 136.55.21.172.in-addr.arpa. PTR)" && echo OK > /results/172.21.55.136_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 136.55.21.172.in-addr.arpa. PTR)" && echo OK > /results/172.21.55.136_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-4tzwz A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-4tzwz;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-4tzwz A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-4tzwz;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-4tzwz.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-4tzwz.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-4tzwz.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-4tzwz.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-4tzwz.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-4tzwz.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-4tzwz.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-4tzwz.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-4tzwz.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-4tzwz.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-4tzwz.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-4tzwz.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-4tzwz.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 136.55.21.172.in-addr.arpa. PTR)" && echo OK > /results/172.21.55.136_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 136.55.21.172.in-addr.arpa. PTR)" && echo OK > /results/172.21.55.136_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  5 21:58:57.238: INFO: DNS probes using e2e-tests-dns-4tzwz/dns-test-ee2bb734-f8d8-11e8-b962-c6dde3e93636 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:58:57.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-4tzwz" for this suite.
Dec  5 21:59:03.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:59:03.635: INFO: namespace: e2e-tests-dns-4tzwz, resource: bindings, ignored listing per whitelist
Dec  5 21:59:03.839: INFO: namespace e2e-tests-dns-4tzwz deletion completed in 6.469432794s

• [SLOW TEST:21.577 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:59:03.841: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-7t7jd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  5 21:59:04.281: INFO: Waiting up to 5m0s for pod "pod-fb01b08c-f8d8-11e8-b962-c6dde3e93636" in namespace "e2e-tests-emptydir-7t7jd" to be "success or failure"
Dec  5 21:59:04.292: INFO: Pod "pod-fb01b08c-f8d8-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 11.328426ms
Dec  5 21:59:06.301: INFO: Pod "pod-fb01b08c-f8d8-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019942974s
STEP: Saw pod success
Dec  5 21:59:06.301: INFO: Pod "pod-fb01b08c-f8d8-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:59:06.310: INFO: Trying to get logs from node 10.191.0.150 pod pod-fb01b08c-f8d8-11e8-b962-c6dde3e93636 container test-container: <nil>
STEP: delete the pod
Dec  5 21:59:06.357: INFO: Waiting for pod pod-fb01b08c-f8d8-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:59:06.367: INFO: Pod pod-fb01b08c-f8d8-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:59:06.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7t7jd" for this suite.
Dec  5 21:59:12.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:59:12.474: INFO: namespace: e2e-tests-emptydir-7t7jd, resource: bindings, ignored listing per whitelist
Dec  5 21:59:12.742: INFO: namespace e2e-tests-emptydir-7t7jd deletion completed in 6.357293733s

• [SLOW TEST:8.901 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:59:12.743: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-xpq84
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  5 21:59:13.100: INFO: Waiting up to 5m0s for pod "downward-api-0043446f-f8d9-11e8-b962-c6dde3e93636" in namespace "e2e-tests-downward-api-xpq84" to be "success or failure"
Dec  5 21:59:13.109: INFO: Pod "downward-api-0043446f-f8d9-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 8.724308ms
Dec  5 21:59:15.117: INFO: Pod "downward-api-0043446f-f8d9-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017156298s
STEP: Saw pod success
Dec  5 21:59:15.117: INFO: Pod "downward-api-0043446f-f8d9-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 21:59:15.126: INFO: Trying to get logs from node 10.191.0.150 pod downward-api-0043446f-f8d9-11e8-b962-c6dde3e93636 container dapi-container: <nil>
STEP: delete the pod
Dec  5 21:59:15.190: INFO: Waiting for pod downward-api-0043446f-f8d9-11e8-b962-c6dde3e93636 to disappear
Dec  5 21:59:15.198: INFO: Pod downward-api-0043446f-f8d9-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:59:15.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xpq84" for this suite.
Dec  5 21:59:21.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:59:21.336: INFO: namespace: e2e-tests-downward-api-xpq84, resource: bindings, ignored listing per whitelist
Dec  5 21:59:21.663: INFO: namespace e2e-tests-downward-api-xpq84 deletion completed in 6.447707974s

• [SLOW TEST:8.920 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 21:59:21.664: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-ztzs4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-ztzs4
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  5 21:59:22.105: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  5 21:59:46.398: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.248.111:8080/dial?request=hostName&protocol=http&host=172.30.248.114&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-ztzs4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 21:59:46.398: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
Dec  5 21:59:46.663: INFO: Waiting for endpoints: map[]
Dec  5 21:59:46.672: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.248.111:8080/dial?request=hostName&protocol=http&host=172.30.46.173&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-ztzs4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 21:59:46.672: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
Dec  5 21:59:46.901: INFO: Waiting for endpoints: map[]
Dec  5 21:59:46.911: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.248.111:8080/dial?request=hostName&protocol=http&host=172.30.110.31&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-ztzs4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 21:59:46.911: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
Dec  5 21:59:47.105: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 21:59:47.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-ztzs4" for this suite.
Dec  5 22:00:11.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:00:11.344: INFO: namespace: e2e-tests-pod-network-test-ztzs4, resource: bindings, ignored listing per whitelist
Dec  5 22:00:11.480: INFO: namespace e2e-tests-pod-network-test-ztzs4 deletion completed in 24.360631342s

• [SLOW TEST:49.816 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:00:11.481: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-sgz7h
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-2344f46c-f8d9-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume secrets
Dec  5 22:00:11.842: INFO: Waiting up to 5m0s for pod "pod-secrets-2346b6ad-f8d9-11e8-b962-c6dde3e93636" in namespace "e2e-tests-secrets-sgz7h" to be "success or failure"
Dec  5 22:00:11.857: INFO: Pod "pod-secrets-2346b6ad-f8d9-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 14.844968ms
Dec  5 22:00:13.895: INFO: Pod "pod-secrets-2346b6ad-f8d9-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.05267943s
STEP: Saw pod success
Dec  5 22:00:13.895: INFO: Pod "pod-secrets-2346b6ad-f8d9-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 22:00:13.906: INFO: Trying to get logs from node 10.191.0.150 pod pod-secrets-2346b6ad-f8d9-11e8-b962-c6dde3e93636 container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 22:00:13.967: INFO: Waiting for pod pod-secrets-2346b6ad-f8d9-11e8-b962-c6dde3e93636 to disappear
Dec  5 22:00:13.975: INFO: Pod pod-secrets-2346b6ad-f8d9-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:00:13.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-sgz7h" for this suite.
Dec  5 22:00:20.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:00:20.230: INFO: namespace: e2e-tests-secrets-sgz7h, resource: bindings, ignored listing per whitelist
Dec  5 22:00:20.443: INFO: namespace e2e-tests-secrets-sgz7h deletion completed in 6.456449348s

• [SLOW TEST:8.962 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:00:20.446: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-qqqbj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Dec  5 22:00:20.787: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  5 22:00:20.808: INFO: Waiting for terminating namespaces to be deleted...
Dec  5 22:00:20.818: INFO: 
Logging pods the kubelet thinks is on node 10.191.0.134 before test
Dec  5 22:00:20.853: INFO: ibm-keepalived-watcher-c8gfz from kube-system started at 2018-12-05 20:13:25 +0000 UTC (1 container statuses recorded)
Dec  5 22:00:20.853: INFO: 	Container keepalived-watcher ready: true, restart count 0
Dec  5 22:00:20.853: INFO: ibm-master-proxy-static-10.191.0.134 from kube-system started at <nil> (0 container statuses recorded)
Dec  5 22:00:20.853: INFO: kube-dns-autoscaler-587cd5cd44-wtn48 from kube-system started at 2018-12-05 20:13:25 +0000 UTC (1 container statuses recorded)
Dec  5 22:00:20.853: INFO: 	Container autoscaler ready: true, restart count 0
Dec  5 22:00:20.853: INFO: ibm-storage-watcher-d7fb6f996-sw7ft from kube-system started at 2018-12-05 20:13:25 +0000 UTC (1 container statuses recorded)
Dec  5 22:00:20.853: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Dec  5 22:00:20.853: INFO: ibm-file-plugin-66d9565b46-pmd5k from kube-system started at 2018-12-05 20:13:25 +0000 UTC (1 container statuses recorded)
Dec  5 22:00:20.853: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Dec  5 22:00:20.853: INFO: calico-node-hjfvw from kube-system started at 2018-12-05 20:13:25 +0000 UTC (2 container statuses recorded)
Dec  5 22:00:20.854: INFO: 	Container calico-node ready: true, restart count 0
Dec  5 22:00:20.854: INFO: 	Container install-cni ready: true, restart count 0
Dec  5 22:00:20.854: INFO: sonobuoy-systemd-logs-daemon-set-9347e99d64a449f0-2fct4 from heptio-sonobuoy started at 2018-12-05 20:51:14 +0000 UTC (2 container statuses recorded)
Dec  5 22:00:20.854: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec  5 22:00:20.854: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  5 22:00:20.854: INFO: calico-kube-controllers-5c699798bc-szf68 from kube-system started at 2018-12-05 20:13:25 +0000 UTC (1 container statuses recorded)
Dec  5 22:00:20.854: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec  5 22:00:20.854: INFO: kube-dns-amd64-fddfcc69-drvmh from kube-system started at 2018-12-05 20:13:25 +0000 UTC (3 container statuses recorded)
Dec  5 22:00:20.854: INFO: 	Container dnsmasq ready: true, restart count 0
Dec  5 22:00:20.854: INFO: 	Container kubedns ready: true, restart count 0
Dec  5 22:00:20.854: INFO: 	Container sidecar ready: true, restart count 0
Dec  5 22:00:20.854: INFO: kubernetes-dashboard-b6b5cbdb4-n88tm from kube-system started at 2018-12-05 20:13:25 +0000 UTC (1 container statuses recorded)
Dec  5 22:00:20.854: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec  5 22:00:20.854: INFO: vpn-65599665d9-g4r5v from kube-system started at 2018-12-05 20:13:25 +0000 UTC (1 container statuses recorded)
Dec  5 22:00:20.854: INFO: 	Container vpn ready: true, restart count 0
Dec  5 22:00:20.854: INFO: kube-dns-amd64-fddfcc69-ph96f from kube-system started at 2018-12-05 20:13:55 +0000 UTC (3 container statuses recorded)
Dec  5 22:00:20.854: INFO: 	Container dnsmasq ready: true, restart count 0
Dec  5 22:00:20.854: INFO: 	Container kubedns ready: true, restart count 0
Dec  5 22:00:20.855: INFO: 	Container sidecar ready: true, restart count 0
Dec  5 22:00:20.855: INFO: ibm-kube-fluentd-kszbp from kube-system started at 2018-12-05 20:19:21 +0000 UTC (1 container statuses recorded)
Dec  5 22:00:20.855: INFO: 	Container fluentd ready: true, restart count 0
Dec  5 22:00:20.855: INFO: 
Logging pods the kubelet thinks is on node 10.191.0.147 before test
Dec  5 22:00:20.888: INFO: public-cr13c0509290e4443aab67bdb06ca2f6df-alb1-8576b8658-28rzk from kube-system started at 2018-12-05 20:18:36 +0000 UTC (4 container statuses recorded)
Dec  5 22:00:20.889: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Dec  5 22:00:20.889: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Dec  5 22:00:20.889: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Dec  5 22:00:20.889: INFO: 	Container nginx-ingress ready: true, restart count 0
Dec  5 22:00:20.889: INFO: ibm-kube-fluentd-zkwzj from kube-system started at 2018-12-05 20:19:21 +0000 UTC (1 container statuses recorded)
Dec  5 22:00:20.889: INFO: 	Container fluentd ready: true, restart count 0
Dec  5 22:00:20.889: INFO: test-k8s-e2e-pvg-master-verification from default started at 2018-12-05 20:50:44 +0000 UTC (1 container statuses recorded)
Dec  5 22:00:20.889: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Dec  5 22:00:20.889: INFO: ibm-master-proxy-static-10.191.0.147 from kube-system started at <nil> (0 container statuses recorded)
Dec  5 22:00:20.889: INFO: ibm-keepalived-watcher-8sx6s from kube-system started at 2018-12-05 20:13:32 +0000 UTC (1 container statuses recorded)
Dec  5 22:00:20.889: INFO: 	Container keepalived-watcher ready: true, restart count 0
Dec  5 22:00:20.889: INFO: ibm-cloud-provider-ip-169-61-124-166-74499dcdfd-4qnpc from ibm-system started at 2018-12-05 20:17:26 +0000 UTC (1 container statuses recorded)
Dec  5 22:00:20.889: INFO: 	Container ibm-cloud-provider-ip-169-61-124-166 ready: true, restart count 0
Dec  5 22:00:20.889: INFO: calico-node-xgzvj from kube-system started at 2018-12-05 20:13:32 +0000 UTC (2 container statuses recorded)
Dec  5 22:00:20.889: INFO: 	Container calico-node ready: true, restart count 0
Dec  5 22:00:20.889: INFO: 	Container install-cni ready: true, restart count 0
Dec  5 22:00:20.889: INFO: sonobuoy-e2e-job-bf9289e3f16942e1 from heptio-sonobuoy started at 2018-12-05 20:51:14 +0000 UTC (2 container statuses recorded)
Dec  5 22:00:20.889: INFO: 	Container e2e ready: true, restart count 0
Dec  5 22:00:20.889: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  5 22:00:20.889: INFO: sonobuoy-systemd-logs-daemon-set-9347e99d64a449f0-dnc6s from heptio-sonobuoy started at 2018-12-05 20:51:14 +0000 UTC (2 container statuses recorded)
Dec  5 22:00:20.889: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec  5 22:00:20.889: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  5 22:00:20.889: INFO: 
Logging pods the kubelet thinks is on node 10.191.0.150 before test
Dec  5 22:00:20.915: INFO: public-cr13c0509290e4443aab67bdb06ca2f6df-alb1-8576b8658-lhtpj from kube-system started at 2018-12-05 20:18:36 +0000 UTC (4 container statuses recorded)
Dec  5 22:00:20.915: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Dec  5 22:00:20.915: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Dec  5 22:00:20.915: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Dec  5 22:00:20.915: INFO: 	Container nginx-ingress ready: true, restart count 0
Dec  5 22:00:20.915: INFO: sonobuoy-systemd-logs-daemon-set-9347e99d64a449f0-bpd58 from heptio-sonobuoy started at 2018-12-05 20:51:14 +0000 UTC (2 container statuses recorded)
Dec  5 22:00:20.915: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec  5 22:00:20.915: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  5 22:00:20.915: INFO: ibm-master-proxy-static-10.191.0.150 from kube-system started at <nil> (0 container statuses recorded)
Dec  5 22:00:20.915: INFO: calico-node-x9v6g from kube-system started at 2018-12-05 20:13:31 +0000 UTC (2 container statuses recorded)
Dec  5 22:00:20.915: INFO: 	Container calico-node ready: true, restart count 0
Dec  5 22:00:20.915: INFO: 	Container install-cni ready: true, restart count 0
Dec  5 22:00:20.915: INFO: ibm-kube-fluentd-qswkt from kube-system started at 2018-12-05 20:19:21 +0000 UTC (1 container statuses recorded)
Dec  5 22:00:20.916: INFO: 	Container fluentd ready: true, restart count 0
Dec  5 22:00:20.916: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-05 20:51:09 +0000 UTC (1 container statuses recorded)
Dec  5 22:00:20.916: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  5 22:00:20.916: INFO: ibm-keepalived-watcher-fpp78 from kube-system started at 2018-12-05 20:13:31 +0000 UTC (1 container statuses recorded)
Dec  5 22:00:20.916: INFO: 	Container keepalived-watcher ready: true, restart count 0
Dec  5 22:00:20.916: INFO: metrics-server-5b95c9cc4c-hjph5 from kube-system started at 2018-12-05 20:14:11 +0000 UTC (2 container statuses recorded)
Dec  5 22:00:20.916: INFO: 	Container metrics-server ready: true, restart count 0
Dec  5 22:00:20.916: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Dec  5 22:00:20.916: INFO: ibm-cloud-provider-ip-169-61-124-166-74499dcdfd-rcg2p from ibm-system started at 2018-12-05 20:17:26 +0000 UTC (1 container statuses recorded)
Dec  5 22:00:20.916: INFO: 	Container ibm-cloud-provider-ip-169-61-124-166 ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.156d8ec44a558f0a], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:00:21.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-qqqbj" for this suite.
Dec  5 22:00:28.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:00:28.409: INFO: namespace: e2e-tests-sched-pred-qqqbj, resource: bindings, ignored listing per whitelist
Dec  5 22:00:28.591: INFO: namespace e2e-tests-sched-pred-qqqbj deletion completed in 6.603491418s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:8.145 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:00:28.593: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mcf7k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  5 22:00:31.566: INFO: Successfully updated pod "annotationupdate2d7b4306-f8d9-11e8-b962-c6dde3e93636"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:00:35.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mcf7k" for this suite.
Dec  5 22:00:59.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:00:59.787: INFO: namespace: e2e-tests-projected-mcf7k, resource: bindings, ignored listing per whitelist
Dec  5 22:01:00.070: INFO: namespace e2e-tests-projected-mcf7k deletion completed in 24.389704254s

• [SLOW TEST:31.478 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:01:00.072: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-g624r
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-403a6bbd-f8d9-11e8-b962-c6dde3e93636
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:01:02.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-g624r" for this suite.
Dec  5 22:01:26.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:01:26.902: INFO: namespace: e2e-tests-configmap-g624r, resource: bindings, ignored listing per whitelist
Dec  5 22:01:26.921: INFO: namespace e2e-tests-configmap-g624r deletion completed in 24.416122564s

• [SLOW TEST:26.849 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:01:26.924: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-52t4q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 22:01:27.335: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5045f8cc-f8d9-11e8-b962-c6dde3e93636" in namespace "e2e-tests-downward-api-52t4q" to be "success or failure"
Dec  5 22:01:27.354: INFO: Pod "downwardapi-volume-5045f8cc-f8d9-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 19.379617ms
Dec  5 22:01:29.378: INFO: Pod "downwardapi-volume-5045f8cc-f8d9-11e8-b962-c6dde3e93636": Phase="Running", Reason="", readiness=true. Elapsed: 2.043071946s
Dec  5 22:01:31.388: INFO: Pod "downwardapi-volume-5045f8cc-f8d9-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052737162s
STEP: Saw pod success
Dec  5 22:01:31.388: INFO: Pod "downwardapi-volume-5045f8cc-f8d9-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 22:01:31.397: INFO: Trying to get logs from node 10.191.0.150 pod downwardapi-volume-5045f8cc-f8d9-11e8-b962-c6dde3e93636 container client-container: <nil>
STEP: delete the pod
Dec  5 22:01:31.449: INFO: Waiting for pod downwardapi-volume-5045f8cc-f8d9-11e8-b962-c6dde3e93636 to disappear
Dec  5 22:01:31.462: INFO: Pod downwardapi-volume-5045f8cc-f8d9-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:01:31.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-52t4q" for this suite.
Dec  5 22:01:37.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:01:37.624: INFO: namespace: e2e-tests-downward-api-52t4q, resource: bindings, ignored listing per whitelist
Dec  5 22:01:37.868: INFO: namespace e2e-tests-downward-api-52t4q deletion completed in 6.392109873s

• [SLOW TEST:10.944 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:01:37.868: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-5tw6b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 22:01:38.210: INFO: Waiting up to 5m0s for pod "downwardapi-volume-56c1f692-f8d9-11e8-b962-c6dde3e93636" in namespace "e2e-tests-projected-5tw6b" to be "success or failure"
Dec  5 22:01:38.217: INFO: Pod "downwardapi-volume-56c1f692-f8d9-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 7.619616ms
Dec  5 22:01:40.244: INFO: Pod "downwardapi-volume-56c1f692-f8d9-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033922819s
STEP: Saw pod success
Dec  5 22:01:40.244: INFO: Pod "downwardapi-volume-56c1f692-f8d9-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 22:01:40.262: INFO: Trying to get logs from node 10.191.0.150 pod downwardapi-volume-56c1f692-f8d9-11e8-b962-c6dde3e93636 container client-container: <nil>
STEP: delete the pod
Dec  5 22:01:40.320: INFO: Waiting for pod downwardapi-volume-56c1f692-f8d9-11e8-b962-c6dde3e93636 to disappear
Dec  5 22:01:40.335: INFO: Pod downwardapi-volume-56c1f692-f8d9-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:01:40.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5tw6b" for this suite.
Dec  5 22:01:46.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:01:46.580: INFO: namespace: e2e-tests-projected-5tw6b, resource: bindings, ignored listing per whitelist
Dec  5 22:01:46.832: INFO: namespace e2e-tests-projected-5tw6b deletion completed in 6.483793508s

• [SLOW TEST:8.964 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:01:46.834: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-wv9p7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  5 22:01:49.791: INFO: Successfully updated pod "annotationupdate5c196662-f8d9-11e8-b962-c6dde3e93636"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:01:53.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wv9p7" for this suite.
Dec  5 22:02:17.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:02:18.293: INFO: namespace: e2e-tests-downward-api-wv9p7, resource: bindings, ignored listing per whitelist
Dec  5 22:02:18.335: INFO: namespace e2e-tests-downward-api-wv9p7 deletion completed in 24.44247144s

• [SLOW TEST:31.502 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:02:18.337: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-t4nrz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  5 22:02:22.815: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 22:02:22.829: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 22:02:24.829: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 22:02:24.851: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 22:02:26.831: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 22:02:26.840: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 22:02:28.829: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 22:02:28.839: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 22:02:30.829: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 22:02:30.839: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 22:02:32.829: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 22:02:32.838: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 22:02:34.829: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 22:02:34.841: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 22:02:36.829: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 22:02:36.853: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 22:02:38.829: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 22:02:38.838: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 22:02:40.830: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 22:02:40.842: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 22:02:42.829: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 22:02:42.838: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 22:02:44.829: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 22:02:44.838: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 22:02:46.829: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 22:02:46.847: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 22:02:48.829: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 22:02:48.854: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 22:02:50.829: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 22:02:50.838: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:02:50.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-t4nrz" for this suite.
Dec  5 22:03:14.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:03:15.386: INFO: namespace: e2e-tests-container-lifecycle-hook-t4nrz, resource: bindings, ignored listing per whitelist
Dec  5 22:03:15.450: INFO: namespace e2e-tests-container-lifecycle-hook-t4nrz deletion completed in 24.569895039s

• [SLOW TEST:57.113 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:03:15.451: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-djtmr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-djtmr
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-djtmr to expose endpoints map[]
Dec  5 22:03:15.841: INFO: Get endpoints failed (7.086784ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Dec  5 22:03:16.848: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-djtmr exposes endpoints map[] (1.014478949s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-djtmr
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-djtmr to expose endpoints map[pod1:[80]]
Dec  5 22:03:18.970: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-djtmr exposes endpoints map[pod1:[80]] (2.103018818s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-djtmr
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-djtmr to expose endpoints map[pod1:[80] pod2:[80]]
Dec  5 22:03:21.135: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-djtmr exposes endpoints map[pod1:[80] pod2:[80]] (2.083372665s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-djtmr
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-djtmr to expose endpoints map[pod2:[80]]
Dec  5 22:03:22.192: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-djtmr exposes endpoints map[pod2:[80]] (1.039908272s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-djtmr
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-djtmr to expose endpoints map[]
Dec  5 22:03:22.215: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-djtmr exposes endpoints map[] (9.62026ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:03:22.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-djtmr" for this suite.
Dec  5 22:03:46.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:03:46.441: INFO: namespace: e2e-tests-services-djtmr, resource: bindings, ignored listing per whitelist
Dec  5 22:03:46.725: INFO: namespace e2e-tests-services-djtmr deletion completed in 24.444117032s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:31.274 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:03:46.726: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-jxjkt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Dec  5 22:03:47.059: INFO: Waiting up to 5m0s for pod "client-containers-a38ebd79-f8d9-11e8-b962-c6dde3e93636" in namespace "e2e-tests-containers-jxjkt" to be "success or failure"
Dec  5 22:03:47.067: INFO: Pod "client-containers-a38ebd79-f8d9-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 8.032014ms
Dec  5 22:03:49.077: INFO: Pod "client-containers-a38ebd79-f8d9-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018189771s
STEP: Saw pod success
Dec  5 22:03:49.078: INFO: Pod "client-containers-a38ebd79-f8d9-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 22:03:49.086: INFO: Trying to get logs from node 10.191.0.150 pod client-containers-a38ebd79-f8d9-11e8-b962-c6dde3e93636 container test-container: <nil>
STEP: delete the pod
Dec  5 22:03:49.168: INFO: Waiting for pod client-containers-a38ebd79-f8d9-11e8-b962-c6dde3e93636 to disappear
Dec  5 22:03:49.177: INFO: Pod client-containers-a38ebd79-f8d9-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:03:49.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-jxjkt" for this suite.
Dec  5 22:03:55.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:03:55.342: INFO: namespace: e2e-tests-containers-jxjkt, resource: bindings, ignored listing per whitelist
Dec  5 22:03:55.694: INFO: namespace e2e-tests-containers-jxjkt deletion completed in 6.500903122s

• [SLOW TEST:8.969 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:03:55.695: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-5fp7c
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-a8f3e9b1-f8d9-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume configMaps
Dec  5 22:03:56.127: INFO: Waiting up to 5m0s for pod "pod-configmaps-a8f5f856-f8d9-11e8-b962-c6dde3e93636" in namespace "e2e-tests-configmap-5fp7c" to be "success or failure"
Dec  5 22:03:56.136: INFO: Pod "pod-configmaps-a8f5f856-f8d9-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 9.058916ms
Dec  5 22:03:58.146: INFO: Pod "pod-configmaps-a8f5f856-f8d9-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018985026s
STEP: Saw pod success
Dec  5 22:03:58.146: INFO: Pod "pod-configmaps-a8f5f856-f8d9-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 22:03:58.160: INFO: Trying to get logs from node 10.191.0.150 pod pod-configmaps-a8f5f856-f8d9-11e8-b962-c6dde3e93636 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 22:03:58.226: INFO: Waiting for pod pod-configmaps-a8f5f856-f8d9-11e8-b962-c6dde3e93636 to disappear
Dec  5 22:03:58.237: INFO: Pod pod-configmaps-a8f5f856-f8d9-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:03:58.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-5fp7c" for this suite.
Dec  5 22:04:04.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:04:04.623: INFO: namespace: e2e-tests-configmap-5fp7c, resource: bindings, ignored listing per whitelist
Dec  5 22:04:04.804: INFO: namespace e2e-tests-configmap-5fp7c deletion completed in 6.554854963s

• [SLOW TEST:9.109 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:04:04.804: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-b2gsr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-b2gsr/secret-test-ae553053-f8d9-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume secrets
Dec  5 22:04:05.150: INFO: Waiting up to 5m0s for pod "pod-configmaps-ae56f6fd-f8d9-11e8-b962-c6dde3e93636" in namespace "e2e-tests-secrets-b2gsr" to be "success or failure"
Dec  5 22:04:05.162: INFO: Pod "pod-configmaps-ae56f6fd-f8d9-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 12.174239ms
Dec  5 22:04:07.185: INFO: Pod "pod-configmaps-ae56f6fd-f8d9-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035245866s
STEP: Saw pod success
Dec  5 22:04:07.186: INFO: Pod "pod-configmaps-ae56f6fd-f8d9-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 22:04:07.198: INFO: Trying to get logs from node 10.191.0.150 pod pod-configmaps-ae56f6fd-f8d9-11e8-b962-c6dde3e93636 container env-test: <nil>
STEP: delete the pod
Dec  5 22:04:07.261: INFO: Waiting for pod pod-configmaps-ae56f6fd-f8d9-11e8-b962-c6dde3e93636 to disappear
Dec  5 22:04:07.269: INFO: Pod pod-configmaps-ae56f6fd-f8d9-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:04:07.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-b2gsr" for this suite.
Dec  5 22:04:13.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:04:13.504: INFO: namespace: e2e-tests-secrets-b2gsr, resource: bindings, ignored listing per whitelist
Dec  5 22:04:13.752: INFO: namespace e2e-tests-secrets-b2gsr deletion completed in 6.468533454s

• [SLOW TEST:8.948 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:04:13.752: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-76xzb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec  5 22:04:14.052: INFO: namespace e2e-tests-kubectl-76xzb
Dec  5 22:04:14.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 create -f - --namespace=e2e-tests-kubectl-76xzb'
Dec  5 22:04:14.706: INFO: stderr: ""
Dec  5 22:04:14.706: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  5 22:04:15.717: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 22:04:15.717: INFO: Found 0 / 1
Dec  5 22:04:16.716: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 22:04:16.716: INFO: Found 1 / 1
Dec  5 22:04:16.716: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  5 22:04:16.726: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 22:04:16.726: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  5 22:04:16.726: INFO: wait on redis-master startup in e2e-tests-kubectl-76xzb 
Dec  5 22:04:16.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 logs redis-master-7n85z redis-master --namespace=e2e-tests-kubectl-76xzb'
Dec  5 22:04:16.885: INFO: stderr: ""
Dec  5 22:04:16.886: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 05 Dec 22:04:15.767 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 05 Dec 22:04:15.767 # Server started, Redis version 3.2.12\n1:M 05 Dec 22:04:15.767 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 05 Dec 22:04:15.767 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Dec  5 22:04:16.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-76xzb'
Dec  5 22:04:17.061: INFO: stderr: ""
Dec  5 22:04:17.061: INFO: stdout: "service/rm2 exposed\n"
Dec  5 22:04:17.071: INFO: Service rm2 in namespace e2e-tests-kubectl-76xzb found.
STEP: exposing service
Dec  5 22:04:19.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-76xzb'
Dec  5 22:04:19.250: INFO: stderr: ""
Dec  5 22:04:19.250: INFO: stdout: "service/rm3 exposed\n"
Dec  5 22:04:19.259: INFO: Service rm3 in namespace e2e-tests-kubectl-76xzb found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:04:21.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-76xzb" for this suite.
Dec  5 22:04:45.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:04:45.506: INFO: namespace: e2e-tests-kubectl-76xzb, resource: bindings, ignored listing per whitelist
Dec  5 22:04:45.886: INFO: namespace e2e-tests-kubectl-76xzb deletion completed in 24.535303887s

• [SLOW TEST:32.134 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:04:45.889: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-xq9zq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 22:04:46.255: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c6d345b8-f8d9-11e8-b962-c6dde3e93636" in namespace "e2e-tests-downward-api-xq9zq" to be "success or failure"
Dec  5 22:04:46.265: INFO: Pod "downwardapi-volume-c6d345b8-f8d9-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 10.517529ms
Dec  5 22:04:48.281: INFO: Pod "downwardapi-volume-c6d345b8-f8d9-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025623853s
STEP: Saw pod success
Dec  5 22:04:48.281: INFO: Pod "downwardapi-volume-c6d345b8-f8d9-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 22:04:48.292: INFO: Trying to get logs from node 10.191.0.150 pod downwardapi-volume-c6d345b8-f8d9-11e8-b962-c6dde3e93636 container client-container: <nil>
STEP: delete the pod
Dec  5 22:04:48.345: INFO: Waiting for pod downwardapi-volume-c6d345b8-f8d9-11e8-b962-c6dde3e93636 to disappear
Dec  5 22:04:48.358: INFO: Pod downwardapi-volume-c6d345b8-f8d9-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:04:48.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xq9zq" for this suite.
Dec  5 22:04:54.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:04:54.682: INFO: namespace: e2e-tests-downward-api-xq9zq, resource: bindings, ignored listing per whitelist
Dec  5 22:04:54.737: INFO: namespace e2e-tests-downward-api-xq9zq deletion completed in 6.366107871s

• [SLOW TEST:8.849 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:04:54.737: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-dfvhc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 22:04:55.094: INFO: Creating deployment "test-recreate-deployment"
Dec  5 22:04:55.104: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec  5 22:04:55.123: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Dec  5 22:04:57.139: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec  5 22:04:57.154: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec  5 22:04:57.171: INFO: Updating deployment test-recreate-deployment
Dec  5 22:04:57.171: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  5 22:04:57.286: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-dfvhc,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-dfvhc/deployments/test-recreate-deployment,UID:cc1f4bc3-f8d9-11e8-9151-427614c96c42,ResourceVersion:24722,Generation:2,CreationTimestamp:2018-12-05 22:04:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2018-12-05 22:04:57 +0000 UTC 2018-12-05 22:04:57 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-12-05 22:04:57 +0000 UTC 2018-12-05 22:04:55 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Dec  5 22:04:57.296: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-dfvhc,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-dfvhc/replicasets/test-recreate-deployment-7cf749666b,UID:cd643149-f8d9-11e8-bcf8-b20187c1163a,ResourceVersion:24720,Generation:1,CreationTimestamp:2018-12-05 22:04:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment cc1f4bc3-f8d9-11e8-9151-427614c96c42 0xc421813447 0xc421813448}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  5 22:04:57.296: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec  5 22:04:57.296: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-dfvhc,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-dfvhc/replicasets/test-recreate-deployment-79f694ff59,UID:cc22db98-f8d9-11e8-bcf8-b20187c1163a,ResourceVersion:24711,Generation:2,CreationTimestamp:2018-12-05 22:04:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment cc1f4bc3-f8d9-11e8-9151-427614c96c42 0xc421813387 0xc421813388}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  5 22:04:57.308: INFO: Pod "test-recreate-deployment-7cf749666b-fcxpp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-fcxpp,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-dfvhc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-dfvhc/pods/test-recreate-deployment-7cf749666b-fcxpp,UID:cd659f13-f8d9-11e8-bcf8-b20187c1163a,ResourceVersion:24717,Generation:0,CreationTimestamp:2018-12-05 22:04:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b cd643149-f8d9-11e8-bcf8-b20187c1163a 0xc423398947 0xc423398948}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn5bn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn5bn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dn5bn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.0.150,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4233989c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4233989e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:04:57 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:04:57.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-dfvhc" for this suite.
Dec  5 22:05:03.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:05:03.608: INFO: namespace: e2e-tests-deployment-dfvhc, resource: bindings, ignored listing per whitelist
Dec  5 22:05:03.850: INFO: namespace e2e-tests-deployment-dfvhc deletion completed in 6.515787685s

• [SLOW TEST:9.113 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:05:03.851: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-l7s56
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 22:05:04.236: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d18b749a-f8d9-11e8-b962-c6dde3e93636" in namespace "e2e-tests-projected-l7s56" to be "success or failure"
Dec  5 22:05:04.245: INFO: Pod "downwardapi-volume-d18b749a-f8d9-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 8.865083ms
Dec  5 22:05:06.257: INFO: Pod "downwardapi-volume-d18b749a-f8d9-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020974139s
Dec  5 22:05:08.266: INFO: Pod "downwardapi-volume-d18b749a-f8d9-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030835403s
STEP: Saw pod success
Dec  5 22:05:08.267: INFO: Pod "downwardapi-volume-d18b749a-f8d9-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 22:05:08.275: INFO: Trying to get logs from node 10.191.0.150 pod downwardapi-volume-d18b749a-f8d9-11e8-b962-c6dde3e93636 container client-container: <nil>
STEP: delete the pod
Dec  5 22:05:08.362: INFO: Waiting for pod downwardapi-volume-d18b749a-f8d9-11e8-b962-c6dde3e93636 to disappear
Dec  5 22:05:08.370: INFO: Pod downwardapi-volume-d18b749a-f8d9-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:05:08.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-l7s56" for this suite.
Dec  5 22:05:14.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:05:14.744: INFO: namespace: e2e-tests-projected-l7s56, resource: bindings, ignored listing per whitelist
Dec  5 22:05:14.850: INFO: namespace e2e-tests-projected-l7s56 deletion completed in 6.467111664s

• [SLOW TEST:10.999 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:05:14.851: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-j8q65
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 22:05:17.347: INFO: Waiting up to 5m0s for pod "client-envvars-d96066da-f8d9-11e8-b962-c6dde3e93636" in namespace "e2e-tests-pods-j8q65" to be "success or failure"
Dec  5 22:05:17.357: INFO: Pod "client-envvars-d96066da-f8d9-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 10.060686ms
Dec  5 22:05:19.367: INFO: Pod "client-envvars-d96066da-f8d9-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01985949s
STEP: Saw pod success
Dec  5 22:05:19.367: INFO: Pod "client-envvars-d96066da-f8d9-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 22:05:19.377: INFO: Trying to get logs from node 10.191.0.147 pod client-envvars-d96066da-f8d9-11e8-b962-c6dde3e93636 container env3cont: <nil>
STEP: delete the pod
Dec  5 22:05:19.434: INFO: Waiting for pod client-envvars-d96066da-f8d9-11e8-b962-c6dde3e93636 to disappear
Dec  5 22:05:19.442: INFO: Pod client-envvars-d96066da-f8d9-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:05:19.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-j8q65" for this suite.
Dec  5 22:05:59.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:05:59.603: INFO: namespace: e2e-tests-pods-j8q65, resource: bindings, ignored listing per whitelist
Dec  5 22:05:59.873: INFO: namespace e2e-tests-pods-j8q65 deletion completed in 40.415734535s

• [SLOW TEST:45.022 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:05:59.873: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-shsxl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  5 22:06:03.013: INFO: Successfully updated pod "labelsupdatef30bd1f2-f8d9-11e8-b962-c6dde3e93636"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:06:07.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-shsxl" for this suite.
Dec  5 22:06:31.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:06:31.287: INFO: namespace: e2e-tests-projected-shsxl, resource: bindings, ignored listing per whitelist
Dec  5 22:06:31.599: INFO: namespace e2e-tests-projected-shsxl deletion completed in 24.491774349s

• [SLOW TEST:31.726 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:06:31.599: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-4x2px
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 22:06:32.094: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"05ebe912-f8da-11e8-9151-427614c96c42", Controller:(*bool)(0xc421b1a24e), BlockOwnerDeletion:(*bool)(0xc421b1a24f)}}
Dec  5 22:06:32.112: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"05e81170-f8da-11e8-9151-427614c96c42", Controller:(*bool)(0xc421737e8e), BlockOwnerDeletion:(*bool)(0xc421737e8f)}}
Dec  5 22:06:32.128: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"05ea45db-f8da-11e8-9151-427614c96c42", Controller:(*bool)(0xc421b1a426), BlockOwnerDeletion:(*bool)(0xc421b1a427)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:06:37.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-4x2px" for this suite.
Dec  5 22:06:43.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:06:43.409: INFO: namespace: e2e-tests-gc-4x2px, resource: bindings, ignored listing per whitelist
Dec  5 22:06:44.035: INFO: namespace e2e-tests-gc-4x2px deletion completed in 6.848919554s

• [SLOW TEST:12.436 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:06:44.036: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-k7mjf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Dec  5 22:06:44.529: INFO: Waiting up to 5m0s for pod "client-containers-0d56559e-f8da-11e8-b962-c6dde3e93636" in namespace "e2e-tests-containers-k7mjf" to be "success or failure"
Dec  5 22:06:44.538: INFO: Pod "client-containers-0d56559e-f8da-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 9.303267ms
Dec  5 22:06:46.546: INFO: Pod "client-containers-0d56559e-f8da-11e8-b962-c6dde3e93636": Phase="Running", Reason="", readiness=true. Elapsed: 2.01754918s
Dec  5 22:06:48.574: INFO: Pod "client-containers-0d56559e-f8da-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045012464s
STEP: Saw pod success
Dec  5 22:06:48.574: INFO: Pod "client-containers-0d56559e-f8da-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 22:06:48.581: INFO: Trying to get logs from node 10.191.0.150 pod client-containers-0d56559e-f8da-11e8-b962-c6dde3e93636 container test-container: <nil>
STEP: delete the pod
Dec  5 22:06:48.628: INFO: Waiting for pod client-containers-0d56559e-f8da-11e8-b962-c6dde3e93636 to disappear
Dec  5 22:06:48.635: INFO: Pod client-containers-0d56559e-f8da-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:06:48.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-k7mjf" for this suite.
Dec  5 22:06:54.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:06:55.038: INFO: namespace: e2e-tests-containers-k7mjf, resource: bindings, ignored listing per whitelist
Dec  5 22:06:55.089: INFO: namespace e2e-tests-containers-k7mjf deletion completed in 6.440375137s

• [SLOW TEST:11.053 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:06:55.092: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-vpdlw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-vpdlw
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-vpdlw
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-vpdlw
Dec  5 22:06:55.461: INFO: Found 0 stateful pods, waiting for 1
Dec  5 22:07:05.492: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec  5 22:07:05.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  5 22:07:05.823: INFO: stderr: ""
Dec  5 22:07:05.823: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  5 22:07:05.823: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  5 22:07:05.833: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  5 22:07:15.856: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 22:07:15.856: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 22:07:15.911: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Dec  5 22:07:15.911: INFO: ss-0  10.191.0.150  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:06:55 +0000 UTC  }]
Dec  5 22:07:15.911: INFO: ss-1                Pending         []
Dec  5 22:07:15.911: INFO: 
Dec  5 22:07:15.911: INFO: StatefulSet ss has not reached scale 3, at 2
Dec  5 22:07:16.922: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.987127169s
Dec  5 22:07:17.935: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.976281921s
Dec  5 22:07:18.945: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.962485763s
Dec  5 22:07:19.968: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.95334665s
Dec  5 22:07:20.977: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.929440903s
Dec  5 22:07:21.989: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.920482479s
Dec  5 22:07:22.999: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.908342458s
Dec  5 22:07:24.011: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.898728583s
Dec  5 22:07:25.020: INFO: Verifying statefulset ss doesn't scale past 3 for another 886.864674ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-vpdlw
Dec  5 22:07:26.046: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:07:26.428: INFO: stderr: ""
Dec  5 22:07:26.428: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  5 22:07:26.428: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  5 22:07:26.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:07:26.834: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec  5 22:07:26.834: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  5 22:07:26.834: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  5 22:07:26.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:07:27.225: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec  5 22:07:27.225: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  5 22:07:27.225: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  5 22:07:27.237: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 22:07:27.237: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 22:07:27.237: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec  5 22:07:27.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  5 22:07:27.578: INFO: stderr: ""
Dec  5 22:07:27.578: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  5 22:07:27.578: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  5 22:07:27.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  5 22:07:28.011: INFO: stderr: ""
Dec  5 22:07:28.011: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  5 22:07:28.011: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  5 22:07:28.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  5 22:07:28.371: INFO: stderr: ""
Dec  5 22:07:28.371: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  5 22:07:28.371: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  5 22:07:28.371: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 22:07:28.385: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Dec  5 22:07:38.427: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 22:07:38.427: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 22:07:38.427: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 22:07:38.463: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Dec  5 22:07:38.463: INFO: ss-0  10.191.0.150  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:06:55 +0000 UTC  }]
Dec  5 22:07:38.463: INFO: ss-1  10.191.0.147  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  }]
Dec  5 22:07:38.463: INFO: ss-2  10.191.0.134  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  }]
Dec  5 22:07:38.463: INFO: 
Dec  5 22:07:38.463: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  5 22:07:39.472: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Dec  5 22:07:39.472: INFO: ss-0  10.191.0.150  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:06:55 +0000 UTC  }]
Dec  5 22:07:39.472: INFO: ss-1  10.191.0.147  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  }]
Dec  5 22:07:39.472: INFO: ss-2  10.191.0.134  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  }]
Dec  5 22:07:39.473: INFO: 
Dec  5 22:07:39.473: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  5 22:07:40.484: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Dec  5 22:07:40.484: INFO: ss-0  10.191.0.150  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:06:55 +0000 UTC  }]
Dec  5 22:07:40.484: INFO: ss-1  10.191.0.147  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  }]
Dec  5 22:07:40.485: INFO: ss-2  10.191.0.134  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  }]
Dec  5 22:07:40.485: INFO: 
Dec  5 22:07:40.485: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  5 22:07:41.495: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Dec  5 22:07:41.495: INFO: ss-0  10.191.0.150  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:06:55 +0000 UTC  }]
Dec  5 22:07:41.495: INFO: ss-1  10.191.0.147  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  }]
Dec  5 22:07:41.495: INFO: ss-2  10.191.0.134  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  }]
Dec  5 22:07:41.495: INFO: 
Dec  5 22:07:41.495: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  5 22:07:42.504: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Dec  5 22:07:42.504: INFO: ss-0  10.191.0.150  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:06:55 +0000 UTC  }]
Dec  5 22:07:42.504: INFO: ss-1  10.191.0.147  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  }]
Dec  5 22:07:42.504: INFO: ss-2  10.191.0.134  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  }]
Dec  5 22:07:42.504: INFO: 
Dec  5 22:07:42.504: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  5 22:07:43.521: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Dec  5 22:07:43.521: INFO: ss-0  10.191.0.150  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:06:55 +0000 UTC  }]
Dec  5 22:07:43.521: INFO: ss-1  10.191.0.147  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  }]
Dec  5 22:07:43.522: INFO: ss-2  10.191.0.134  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  }]
Dec  5 22:07:43.522: INFO: 
Dec  5 22:07:43.522: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  5 22:07:44.531: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Dec  5 22:07:44.531: INFO: ss-0  10.191.0.150  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:06:55 +0000 UTC  }]
Dec  5 22:07:44.532: INFO: ss-1  10.191.0.147  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  }]
Dec  5 22:07:44.532: INFO: ss-2  10.191.0.134  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  }]
Dec  5 22:07:44.532: INFO: 
Dec  5 22:07:44.532: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  5 22:07:45.544: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Dec  5 22:07:45.544: INFO: ss-0  10.191.0.150  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:06:55 +0000 UTC  }]
Dec  5 22:07:45.544: INFO: ss-1  10.191.0.147  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  }]
Dec  5 22:07:45.544: INFO: 
Dec  5 22:07:45.544: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  5 22:07:46.557: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Dec  5 22:07:46.557: INFO: ss-0  10.191.0.150  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:06:55 +0000 UTC  }]
Dec  5 22:07:46.557: INFO: ss-1  10.191.0.147  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  }]
Dec  5 22:07:46.557: INFO: 
Dec  5 22:07:46.557: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  5 22:07:47.567: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Dec  5 22:07:47.567: INFO: ss-0  10.191.0.150  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:06:55 +0000 UTC  }]
Dec  5 22:07:47.567: INFO: ss-1  10.191.0.147  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:07:15 +0000 UTC  }]
Dec  5 22:07:47.567: INFO: 
Dec  5 22:07:47.567: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-vpdlw
Dec  5 22:07:48.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:07:48.838: INFO: rc: 1
Dec  5 22:07:48.838: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc42145db60 exit status 1 <nil> <nil> true [0xc420f8a650 0xc420f8a668 0xc420f8a6a0] [0xc420f8a650 0xc420f8a668 0xc420f8a6a0] [0xc420f8a660 0xc420f8a698] [0x8fd520 0x8fd520] 0xc4219e9c20 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Dec  5 22:07:58.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:07:59.038: INFO: rc: 1
Dec  5 22:07:59.038: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4219d6b40 exit status 1 <nil> <nil> true [0xc4215223f8 0xc421522410 0xc421522428] [0xc4215223f8 0xc421522410 0xc421522428] [0xc421522408 0xc421522420] [0x8fd520 0x8fd520] 0xc422096a20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 22:08:09.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:08:09.200: INFO: rc: 1
Dec  5 22:08:09.200: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4219d7020 exit status 1 <nil> <nil> true [0xc421522430 0xc421522448 0xc421522460] [0xc421522430 0xc421522448 0xc421522460] [0xc421522440 0xc421522458] [0x8fd520 0x8fd520] 0xc422096b40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 22:08:19.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:08:19.345: INFO: rc: 1
Dec  5 22:08:19.345: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42145def0 exit status 1 <nil> <nil> true [0xc420f8a6a8 0xc420f8a6c0 0xc420f8a6d8] [0xc420f8a6a8 0xc420f8a6c0 0xc420f8a6d8] [0xc420f8a6b8 0xc420f8a6d0] [0x8fd520 0x8fd520] 0xc4219e9d40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 22:08:29.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:08:29.499: INFO: rc: 1
Dec  5 22:08:29.499: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4219d77a0 exit status 1 <nil> <nil> true [0xc421522468 0xc421522480 0xc421522498] [0xc421522468 0xc421522480 0xc421522498] [0xc421522478 0xc421522490] [0x8fd520 0x8fd520] 0xc422096c60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 22:08:39.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:08:39.635: INFO: rc: 1
Dec  5 22:08:39.635: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4215d0330 exit status 1 <nil> <nil> true [0xc420f8a6f0 0xc420f8a718 0xc420f8a730] [0xc420f8a6f0 0xc420f8a718 0xc420f8a730] [0xc420f8a710 0xc420f8a728] [0x8fd520 0x8fd520] 0xc4219e9e60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 22:08:49.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:08:49.778: INFO: rc: 1
Dec  5 22:08:49.778: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4219d7bf0 exit status 1 <nil> <nil> true [0xc4215224a0 0xc4215224b8 0xc4215224d0] [0xc4215224a0 0xc4215224b8 0xc4215224d0] [0xc4215224b0 0xc4215224c8] [0x8fd520 0x8fd520] 0xc422096de0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 22:08:59.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:08:59.942: INFO: rc: 1
Dec  5 22:08:59.943: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42186a030 exit status 1 <nil> <nil> true [0xc4215224d8 0xc4215224f0 0xc421522508] [0xc4215224d8 0xc4215224f0 0xc421522508] [0xc4215224e8 0xc421522500] [0x8fd520 0x8fd520] 0xc422096fc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 22:09:09.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:09:10.096: INFO: rc: 1
Dec  5 22:09:10.096: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4219d6480 exit status 1 <nil> <nil> true [0xc420f8a020 0xc420f8a048 0xc420f8a070] [0xc420f8a020 0xc420f8a048 0xc420f8a070] [0xc420f8a030 0xc420f8a068] [0x8fd520 0x8fd520] 0xc42285e0c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 22:09:20.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:09:20.263: INFO: rc: 1
Dec  5 22:09:20.263: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42145c570 exit status 1 <nil> <nil> true [0xc421522000 0xc421522018 0xc421522030] [0xc421522000 0xc421522018 0xc421522030] [0xc421522010 0xc421522028] [0x8fd520 0x8fd520] 0xc42241c060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 22:09:30.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:09:30.434: INFO: rc: 1
Dec  5 22:09:30.434: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4219d6960 exit status 1 <nil> <nil> true [0xc420f8a088 0xc420f8a0b0 0xc420f8a0e8] [0xc420f8a088 0xc420f8a0b0 0xc420f8a0e8] [0xc420f8a0a8 0xc420f8a0e0] [0x8fd520 0x8fd520] 0xc42285e5a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 22:09:40.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:09:40.573: INFO: rc: 1
Dec  5 22:09:40.573: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42145ca80 exit status 1 <nil> <nil> true [0xc421522038 0xc421522050 0xc421522068] [0xc421522038 0xc421522050 0xc421522068] [0xc421522048 0xc421522060] [0x8fd520 0x8fd520] 0xc42241c180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 22:09:50.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:09:50.719: INFO: rc: 1
Dec  5 22:09:50.720: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4219d6d80 exit status 1 <nil> <nil> true [0xc420f8a0f0 0xc420f8a128 0xc420f8a160] [0xc420f8a0f0 0xc420f8a128 0xc420f8a160] [0xc420f8a120 0xc420f8a148] [0x8fd520 0x8fd520] 0xc42285e720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 22:10:00.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:10:00.847: INFO: rc: 1
Dec  5 22:10:00.847: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42145d1a0 exit status 1 <nil> <nil> true [0xc421522070 0xc421522088 0xc4215220a0] [0xc421522070 0xc421522088 0xc4215220a0] [0xc421522080 0xc421522098] [0x8fd520 0x8fd520] 0xc42241c2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 22:10:10.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:10:11.037: INFO: rc: 1
Dec  5 22:10:11.037: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42145da70 exit status 1 <nil> <nil> true [0xc4215220a8 0xc4215220c0 0xc4215220d8] [0xc4215220a8 0xc4215220c0 0xc4215220d8] [0xc4215220b8 0xc4215220d0] [0x8fd520 0x8fd520] 0xc42241d9e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 22:10:21.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:10:21.185: INFO: rc: 1
Dec  5 22:10:21.185: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4219d74a0 exit status 1 <nil> <nil> true [0xc420f8a168 0xc420f8a1a8 0xc420f8a1e0] [0xc420f8a168 0xc420f8a1a8 0xc420f8a1e0] [0xc420f8a1a0 0xc420f8a1c8] [0x8fd520 0x8fd520] 0xc42285e9c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 22:10:31.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:10:31.337: INFO: rc: 1
Dec  5 22:10:31.338: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42145de60 exit status 1 <nil> <nil> true [0xc4215220e0 0xc4215220f8 0xc421522110] [0xc4215220e0 0xc4215220f8 0xc421522110] [0xc4215220f0 0xc421522108] [0x8fd520 0x8fd520] 0xc42241db00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 22:10:41.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:10:41.463: INFO: rc: 1
Dec  5 22:10:41.463: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4219d7a10 exit status 1 <nil> <nil> true [0xc420f8a1f8 0xc420f8a248 0xc420f8a288] [0xc420f8a1f8 0xc420f8a248 0xc420f8a288] [0xc420f8a230 0xc420f8a270] [0x8fd520 0x8fd520] 0xc42285ecc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 22:10:51.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:10:51.638: INFO: rc: 1
Dec  5 22:10:51.638: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4219d7e00 exit status 1 <nil> <nil> true [0xc420f8a2a0 0xc420f8a2c0 0xc420f8a2d8] [0xc420f8a2a0 0xc420f8a2c0 0xc420f8a2d8] [0xc420f8a2b0 0xc420f8a2d0] [0x8fd520 0x8fd520] 0xc42285ede0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 22:11:01.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:11:01.825: INFO: rc: 1
Dec  5 22:11:01.825: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421e12390 exit status 1 <nil> <nil> true [0xc421522118 0xc421522130 0xc421522148] [0xc421522118 0xc421522130 0xc421522148] [0xc421522128 0xc421522140] [0x8fd520 0x8fd520] 0xc42241dc20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 22:11:11.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:11:11.976: INFO: rc: 1
Dec  5 22:11:11.976: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42145c5a0 exit status 1 <nil> <nil> true [0xc421522008 0xc421522020 0xc421522038] [0xc421522008 0xc421522020 0xc421522038] [0xc421522018 0xc421522030] [0x8fd520 0x8fd520] 0xc42241c060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 22:11:21.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:11:22.124: INFO: rc: 1
Dec  5 22:11:22.125: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42145cba0 exit status 1 <nil> <nil> true [0xc421522040 0xc421522058 0xc421522070] [0xc421522040 0xc421522058 0xc421522070] [0xc421522050 0xc421522068] [0x8fd520 0x8fd520] 0xc42241c180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 22:11:32.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:11:32.338: INFO: rc: 1
Dec  5 22:11:32.338: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42145d1d0 exit status 1 <nil> <nil> true [0xc421522078 0xc421522090 0xc4215220a8] [0xc421522078 0xc421522090 0xc4215220a8] [0xc421522088 0xc4215220a0] [0x8fd520 0x8fd520] 0xc42241c2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 22:11:42.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:11:42.467: INFO: rc: 1
Dec  5 22:11:42.467: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421e13cb0 exit status 1 <nil> <nil> true [0xc420f8a008 0xc420f8a030 0xc420f8a068] [0xc420f8a008 0xc420f8a030 0xc420f8a068] [0xc420f8a028 0xc420f8a060] [0x8fd520 0x8fd520] 0xc42285e0c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 22:11:52.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:11:52.659: INFO: rc: 1
Dec  5 22:11:52.659: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4219d61e0 exit status 1 <nil> <nil> true [0xc420f8a070 0xc420f8a0a8 0xc420f8a0e0] [0xc420f8a070 0xc420f8a0a8 0xc420f8a0e0] [0xc420f8a0a0 0xc420f8a0c8] [0x8fd520 0x8fd520] 0xc42285e5a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 22:12:02.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:12:02.804: INFO: rc: 1
Dec  5 22:12:02.804: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42145dad0 exit status 1 <nil> <nil> true [0xc4215220b0 0xc4215220c8 0xc4215220e0] [0xc4215220b0 0xc4215220c8 0xc4215220e0] [0xc4215220c0 0xc4215220d8] [0x8fd520 0x8fd520] 0xc42241d9e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 22:12:12.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:12:12.932: INFO: rc: 1
Dec  5 22:12:12.932: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4219d6660 exit status 1 <nil> <nil> true [0xc420f8a0e8 0xc420f8a120 0xc420f8a148] [0xc420f8a0e8 0xc420f8a120 0xc420f8a148] [0xc420f8a108 0xc420f8a130] [0x8fd520 0x8fd520] 0xc42285e720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 22:12:22.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:12:23.100: INFO: rc: 1
Dec  5 22:12:23.100: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4219d6b10 exit status 1 <nil> <nil> true [0xc420f8a160 0xc420f8a1a0 0xc420f8a1c8] [0xc420f8a160 0xc420f8a1a0 0xc420f8a1c8] [0xc420f8a188 0xc420f8a1b0] [0x8fd520 0x8fd520] 0xc42285e9c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 22:12:33.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:12:33.259: INFO: rc: 1
Dec  5 22:12:33.259: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42145dec0 exit status 1 <nil> <nil> true [0xc4215220e8 0xc421522100 0xc421522118] [0xc4215220e8 0xc421522100 0xc421522118] [0xc4215220f8 0xc421522110] [0x8fd520 0x8fd520] 0xc42241db00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 22:12:43.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:12:43.415: INFO: rc: 1
Dec  5 22:12:43.415: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4219d7020 exit status 1 <nil> <nil> true [0xc420f8a1e0 0xc420f8a230 0xc420f8a270] [0xc420f8a1e0 0xc420f8a230 0xc420f8a270] [0xc420f8a218 0xc420f8a268] [0x8fd520 0x8fd520] 0xc42285ecc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 22:12:53.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-vpdlw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:12:53.564: INFO: rc: 1
Dec  5 22:12:53.564: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Dec  5 22:12:53.564: INFO: Scaling statefulset ss to 0
Dec  5 22:12:53.657: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  5 22:12:53.667: INFO: Deleting all statefulset in ns e2e-tests-statefulset-vpdlw
Dec  5 22:12:53.677: INFO: Scaling statefulset ss to 0
Dec  5 22:12:53.708: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 22:12:53.716: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:12:53.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-vpdlw" for this suite.
Dec  5 22:13:01.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:13:01.882: INFO: namespace: e2e-tests-statefulset-vpdlw, resource: bindings, ignored listing per whitelist
Dec  5 22:13:02.280: INFO: namespace e2e-tests-statefulset-vpdlw deletion completed in 8.502710968s

• [SLOW TEST:367.189 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:13:02.280: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mpjjl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-eebd1a99-f8da-11e8-b962-c6dde3e93636
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-eebd1a99-f8da-11e8-b962-c6dde3e93636
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:13:06.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mpjjl" for this suite.
Dec  5 22:13:30.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:13:30.993: INFO: namespace: e2e-tests-projected-mpjjl, resource: bindings, ignored listing per whitelist
Dec  5 22:13:31.263: INFO: namespace e2e-tests-projected-mpjjl deletion completed in 24.35806874s

• [SLOW TEST:28.982 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:13:31.263: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-4ftjm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-fffb37b5-f8da-11e8-b962-c6dde3e93636
STEP: Creating a pod to test consume configMaps
Dec  5 22:13:31.631: INFO: Waiting up to 5m0s for pod "pod-configmaps-fffca427-f8da-11e8-b962-c6dde3e93636" in namespace "e2e-tests-configmap-4ftjm" to be "success or failure"
Dec  5 22:13:31.640: INFO: Pod "pod-configmaps-fffca427-f8da-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 9.624062ms
Dec  5 22:13:33.649: INFO: Pod "pod-configmaps-fffca427-f8da-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018696265s
STEP: Saw pod success
Dec  5 22:13:33.649: INFO: Pod "pod-configmaps-fffca427-f8da-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 22:13:33.658: INFO: Trying to get logs from node 10.191.0.150 pod pod-configmaps-fffca427-f8da-11e8-b962-c6dde3e93636 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 22:13:33.766: INFO: Waiting for pod pod-configmaps-fffca427-f8da-11e8-b962-c6dde3e93636 to disappear
Dec  5 22:13:33.773: INFO: Pod pod-configmaps-fffca427-f8da-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:13:33.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4ftjm" for this suite.
Dec  5 22:13:39.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:13:39.970: INFO: namespace: e2e-tests-configmap-4ftjm, resource: bindings, ignored listing per whitelist
Dec  5 22:13:40.296: INFO: namespace e2e-tests-configmap-4ftjm deletion completed in 6.509026915s

• [SLOW TEST:9.033 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:13:40.296: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-ft5lk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-ft5lk
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Dec  5 22:13:40.756: INFO: Found 0 stateful pods, waiting for 3
Dec  5 22:13:50.787: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 22:13:50.787: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 22:13:50.787: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec  5 22:13:50.877: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec  5 22:14:00.961: INFO: Updating stateful set ss2
Dec  5 22:14:01.036: INFO: Waiting for Pod e2e-tests-statefulset-ft5lk/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Dec  5 22:14:11.150: INFO: Found 1 stateful pods, waiting for 3
Dec  5 22:14:21.183: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 22:14:21.183: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 22:14:21.183: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec  5 22:14:21.239: INFO: Updating stateful set ss2
Dec  5 22:14:21.258: INFO: Waiting for Pod e2e-tests-statefulset-ft5lk/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  5 22:14:31.325: INFO: Updating stateful set ss2
Dec  5 22:14:31.343: INFO: Waiting for StatefulSet e2e-tests-statefulset-ft5lk/ss2 to complete update
Dec  5 22:14:31.343: INFO: Waiting for Pod e2e-tests-statefulset-ft5lk/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  5 22:14:41.388: INFO: Deleting all statefulset in ns e2e-tests-statefulset-ft5lk
Dec  5 22:14:41.398: INFO: Scaling statefulset ss2 to 0
Dec  5 22:15:01.444: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 22:15:01.461: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:15:01.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-ft5lk" for this suite.
Dec  5 22:15:09.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:15:09.752: INFO: namespace: e2e-tests-statefulset-ft5lk, resource: bindings, ignored listing per whitelist
Dec  5 22:15:09.965: INFO: namespace e2e-tests-statefulset-ft5lk deletion completed in 8.416138403s

• [SLOW TEST:89.668 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:15:09.965: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-gs2sl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-lj6b
STEP: Creating a pod to test atomic-volume-subpath
Dec  5 22:15:10.335: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-lj6b" in namespace "e2e-tests-subpath-gs2sl" to be "success or failure"
Dec  5 22:15:10.351: INFO: Pod "pod-subpath-test-projected-lj6b": Phase="Pending", Reason="", readiness=false. Elapsed: 15.665022ms
Dec  5 22:15:12.378: INFO: Pod "pod-subpath-test-projected-lj6b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043010366s
Dec  5 22:15:14.400: INFO: Pod "pod-subpath-test-projected-lj6b": Phase="Running", Reason="", readiness=false. Elapsed: 4.064809825s
Dec  5 22:15:16.411: INFO: Pod "pod-subpath-test-projected-lj6b": Phase="Running", Reason="", readiness=false. Elapsed: 6.075590448s
Dec  5 22:15:18.419: INFO: Pod "pod-subpath-test-projected-lj6b": Phase="Running", Reason="", readiness=false. Elapsed: 8.083923035s
Dec  5 22:15:20.431: INFO: Pod "pod-subpath-test-projected-lj6b": Phase="Running", Reason="", readiness=false. Elapsed: 10.095467735s
Dec  5 22:15:22.457: INFO: Pod "pod-subpath-test-projected-lj6b": Phase="Running", Reason="", readiness=false. Elapsed: 12.121251321s
Dec  5 22:15:24.467: INFO: Pod "pod-subpath-test-projected-lj6b": Phase="Running", Reason="", readiness=false. Elapsed: 14.131739954s
Dec  5 22:15:26.476: INFO: Pod "pod-subpath-test-projected-lj6b": Phase="Running", Reason="", readiness=false. Elapsed: 16.141002588s
Dec  5 22:15:28.487: INFO: Pod "pod-subpath-test-projected-lj6b": Phase="Running", Reason="", readiness=false. Elapsed: 18.151715439s
Dec  5 22:15:30.500: INFO: Pod "pod-subpath-test-projected-lj6b": Phase="Running", Reason="", readiness=false. Elapsed: 20.164886812s
Dec  5 22:15:32.537: INFO: Pod "pod-subpath-test-projected-lj6b": Phase="Running", Reason="", readiness=false. Elapsed: 22.201748787s
Dec  5 22:15:34.547: INFO: Pod "pod-subpath-test-projected-lj6b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.211141138s
STEP: Saw pod success
Dec  5 22:15:34.547: INFO: Pod "pod-subpath-test-projected-lj6b" satisfied condition "success or failure"
Dec  5 22:15:34.555: INFO: Trying to get logs from node 10.191.0.150 pod pod-subpath-test-projected-lj6b container test-container-subpath-projected-lj6b: <nil>
STEP: delete the pod
Dec  5 22:15:34.635: INFO: Waiting for pod pod-subpath-test-projected-lj6b to disappear
Dec  5 22:15:34.648: INFO: Pod pod-subpath-test-projected-lj6b no longer exists
STEP: Deleting pod pod-subpath-test-projected-lj6b
Dec  5 22:15:34.648: INFO: Deleting pod "pod-subpath-test-projected-lj6b" in namespace "e2e-tests-subpath-gs2sl"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:15:34.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-gs2sl" for this suite.
Dec  5 22:15:40.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:15:40.919: INFO: namespace: e2e-tests-subpath-gs2sl, resource: bindings, ignored listing per whitelist
Dec  5 22:15:41.017: INFO: namespace e2e-tests-subpath-gs2sl deletion completed in 6.348284384s

• [SLOW TEST:31.052 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:15:41.017: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-frqkq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  5 22:15:43.930: INFO: Successfully updated pod "pod-update-activedeadlineseconds-4d50d9fc-f8db-11e8-b962-c6dde3e93636"
Dec  5 22:15:43.930: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-4d50d9fc-f8db-11e8-b962-c6dde3e93636" in namespace "e2e-tests-pods-frqkq" to be "terminated due to deadline exceeded"
Dec  5 22:15:43.947: INFO: Pod "pod-update-activedeadlineseconds-4d50d9fc-f8db-11e8-b962-c6dde3e93636": Phase="Running", Reason="", readiness=true. Elapsed: 17.063623ms
Dec  5 22:15:45.956: INFO: Pod "pod-update-activedeadlineseconds-4d50d9fc-f8db-11e8-b962-c6dde3e93636": Phase="Running", Reason="", readiness=true. Elapsed: 2.025622559s
Dec  5 22:15:47.966: INFO: Pod "pod-update-activedeadlineseconds-4d50d9fc-f8db-11e8-b962-c6dde3e93636": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.03539805s
Dec  5 22:15:47.966: INFO: Pod "pod-update-activedeadlineseconds-4d50d9fc-f8db-11e8-b962-c6dde3e93636" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:15:47.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-frqkq" for this suite.
Dec  5 22:15:54.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:15:54.419: INFO: namespace: e2e-tests-pods-frqkq, resource: bindings, ignored listing per whitelist
Dec  5 22:15:54.550: INFO: namespace e2e-tests-pods-frqkq deletion completed in 6.572617639s

• [SLOW TEST:13.533 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:15:54.551: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-2twcp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-556b84a2-f8db-11e8-b962-c6dde3e93636
Dec  5 22:15:54.961: INFO: Pod name my-hostname-basic-556b84a2-f8db-11e8-b962-c6dde3e93636: Found 0 pods out of 1
Dec  5 22:15:59.969: INFO: Pod name my-hostname-basic-556b84a2-f8db-11e8-b962-c6dde3e93636: Found 1 pods out of 1
Dec  5 22:15:59.969: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-556b84a2-f8db-11e8-b962-c6dde3e93636" are running
Dec  5 22:15:59.978: INFO: Pod "my-hostname-basic-556b84a2-f8db-11e8-b962-c6dde3e93636-krb87" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-05 22:15:55 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-05 22:15:56 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-05 22:15:56 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-05 22:15:54 +0000 UTC Reason: Message:}])
Dec  5 22:15:59.978: INFO: Trying to dial the pod
Dec  5 22:16:05.043: INFO: Controller my-hostname-basic-556b84a2-f8db-11e8-b962-c6dde3e93636: Got expected result from replica 1 [my-hostname-basic-556b84a2-f8db-11e8-b962-c6dde3e93636-krb87]: "my-hostname-basic-556b84a2-f8db-11e8-b962-c6dde3e93636-krb87", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:16:05.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-2twcp" for this suite.
Dec  5 22:16:11.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:16:11.309: INFO: namespace: e2e-tests-replication-controller-2twcp, resource: bindings, ignored listing per whitelist
Dec  5 22:16:11.516: INFO: namespace e2e-tests-replication-controller-2twcp deletion completed in 6.458579856s

• [SLOW TEST:16.966 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:16:11.516: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-tvjd6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-tvjd6
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-tvjd6
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-tvjd6
Dec  5 22:16:11.962: INFO: Found 0 stateful pods, waiting for 1
Dec  5 22:16:21.985: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec  5 22:16:21.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-tvjd6 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  5 22:16:22.424: INFO: stderr: ""
Dec  5 22:16:22.424: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  5 22:16:22.424: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  5 22:16:22.434: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  5 22:16:32.470: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 22:16:32.470: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 22:16:32.518: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998712s
Dec  5 22:16:33.532: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.98810281s
Dec  5 22:16:34.546: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.974159105s
Dec  5 22:16:35.555: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.959539921s
Dec  5 22:16:36.564: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.950408311s
Dec  5 22:16:37.574: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.94143669s
Dec  5 22:16:38.587: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.931765715s
Dec  5 22:16:39.596: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.919022143s
Dec  5 22:16:40.606: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.909481216s
Dec  5 22:16:41.615: INFO: Verifying statefulset ss doesn't scale past 1 for another 899.601726ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-tvjd6
Dec  5 22:16:42.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-tvjd6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:16:43.115: INFO: stderr: ""
Dec  5 22:16:43.115: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  5 22:16:43.115: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  5 22:16:43.146: INFO: Found 1 stateful pods, waiting for 3
Dec  5 22:16:53.169: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 22:16:53.169: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 22:16:53.169: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec  5 22:16:53.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-tvjd6 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  5 22:16:53.523: INFO: stderr: ""
Dec  5 22:16:53.523: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  5 22:16:53.523: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  5 22:16:53.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-tvjd6 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  5 22:16:53.935: INFO: stderr: ""
Dec  5 22:16:53.935: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  5 22:16:53.935: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  5 22:16:53.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-tvjd6 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  5 22:16:54.302: INFO: stderr: ""
Dec  5 22:16:54.302: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  5 22:16:54.302: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  5 22:16:54.302: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 22:16:54.347: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec  5 22:17:04.393: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 22:17:04.393: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 22:17:04.393: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 22:17:04.435: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998446s
Dec  5 22:17:05.445: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.990283661s
Dec  5 22:17:06.454: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.980301435s
Dec  5 22:17:07.464: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.971079966s
Dec  5 22:17:08.473: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.961430718s
Dec  5 22:17:09.482: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.952110247s
Dec  5 22:17:10.499: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.943269886s
Dec  5 22:17:11.510: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.926633582s
Dec  5 22:17:12.527: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.914968431s
Dec  5 22:17:13.537: INFO: Verifying statefulset ss doesn't scale past 3 for another 898.469327ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-tvjd6
Dec  5 22:17:14.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-tvjd6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:17:14.974: INFO: stderr: ""
Dec  5 22:17:14.974: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  5 22:17:14.974: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  5 22:17:14.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-tvjd6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:17:15.412: INFO: stderr: ""
Dec  5 22:17:15.412: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  5 22:17:15.412: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  5 22:17:15.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 exec --namespace=e2e-tests-statefulset-tvjd6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 22:17:15.797: INFO: stderr: ""
Dec  5 22:17:15.797: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  5 22:17:15.797: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  5 22:17:15.797: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  5 22:17:35.835: INFO: Deleting all statefulset in ns e2e-tests-statefulset-tvjd6
Dec  5 22:17:35.845: INFO: Scaling statefulset ss to 0
Dec  5 22:17:35.883: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 22:17:35.893: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:17:35.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-tvjd6" for this suite.
Dec  5 22:17:43.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:17:44.155: INFO: namespace: e2e-tests-statefulset-tvjd6, resource: bindings, ignored listing per whitelist
Dec  5 22:17:44.289: INFO: namespace e2e-tests-statefulset-tvjd6 deletion completed in 8.350678598s

• [SLOW TEST:92.773 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:17:44.291: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-zmlrx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 22:17:44.625: INFO: Creating deployment "nginx-deployment"
Dec  5 22:17:44.634: INFO: Waiting for observed generation 1
Dec  5 22:17:46.910: INFO: Waiting for all required pods to come up
Dec  5 22:17:46.934: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec  5 22:17:48.955: INFO: Waiting for deployment "nginx-deployment" to complete
Dec  5 22:17:48.972: INFO: Updating deployment "nginx-deployment" with a non-existent image
Dec  5 22:17:48.989: INFO: Updating deployment nginx-deployment
Dec  5 22:17:48.989: INFO: Waiting for observed generation 2
Dec  5 22:17:51.007: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec  5 22:17:51.017: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec  5 22:17:51.027: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec  5 22:17:51.055: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec  5 22:17:51.055: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec  5 22:17:51.064: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec  5 22:17:51.082: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Dec  5 22:17:51.082: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Dec  5 22:17:51.098: INFO: Updating deployment nginx-deployment
Dec  5 22:17:51.098: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Dec  5 22:17:51.117: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec  5 22:17:51.130: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  5 22:17:51.148: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-zmlrx/deployments/nginx-deployment,UID:96cc78ba-f8db-11e8-9151-427614c96c42,ResourceVersion:27510,Generation:3,CreationTimestamp:2018-12-05 22:17:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2018-12-05 22:17:49 +0000 UTC 2018-12-05 22:17:44 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.} {Available False 2018-12-05 22:17:51 +0000 UTC 2018-12-05 22:17:51 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Dec  5 22:17:51.177: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-zmlrx/replicasets/nginx-deployment-7dc8f79789,UID:9966ed95-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27503,Generation:3,CreationTimestamp:2018-12-05 22:17:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 96cc78ba-f8db-11e8-9151-427614c96c42 0xc422150bf7 0xc422150bf8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  5 22:17:51.177: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Dec  5 22:17:51.177: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-zmlrx/replicasets/nginx-deployment-7f9675fb8b,UID:96cfec70-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27500,Generation:3,CreationTimestamp:2018-12-05 22:17:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 96cc78ba-f8db-11e8-9151-427614c96c42 0xc422150cb7 0xc422150cb8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Dec  5 22:17:51.208: INFO: Pod "nginx-deployment-7dc8f79789-2dpg7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-2dpg7,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zmlrx/pods/nginx-deployment-7dc8f79789-2dpg7,UID:996a1b7a-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27491,Generation:0,CreationTimestamp:2018-12-05 22:17:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9966ed95-f8db-11e8-bcf8-b20187c1163a 0xc422105e87 0xc422105e88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sj2t2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj2t2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sj2t2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.0.147,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422105f70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422105fa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:49 +0000 UTC  }],Message:,Reason:,HostIP:10.191.0.147,PodIP:172.30.46.186,StartTime:2018-12-05 22:17:49 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 22:17:51.208: INFO: Pod "nginx-deployment-7dc8f79789-7h7nb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-7h7nb,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zmlrx/pods/nginx-deployment-7dc8f79789-7h7nb,UID:9ab3e207-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27529,Generation:0,CreationTimestamp:2018-12-05 22:17:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9966ed95-f8db-11e8-bcf8-b20187c1163a 0xc421fd40d0 0xc421fd40d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sj2t2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj2t2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sj2t2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421fd4140} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421fd4160}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 22:17:51.209: INFO: Pod "nginx-deployment-7dc8f79789-d5ww5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-d5ww5,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zmlrx/pods/nginx-deployment-7dc8f79789-d5ww5,UID:996890f8-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27481,Generation:0,CreationTimestamp:2018-12-05 22:17:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9966ed95-f8db-11e8-bcf8-b20187c1163a 0xc421fd4307 0xc421fd4308}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sj2t2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj2t2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sj2t2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.0.150,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421fd4380} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421fd43a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:49 +0000 UTC  }],Message:,Reason:,HostIP:10.191.0.150,PodIP:172.30.248.91,StartTime:2018-12-05 22:17:49 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 22:17:51.209: INFO: Pod "nginx-deployment-7dc8f79789-f29wh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-f29wh,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zmlrx/pods/nginx-deployment-7dc8f79789-f29wh,UID:996a1a87-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27498,Generation:0,CreationTimestamp:2018-12-05 22:17:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9966ed95-f8db-11e8-bcf8-b20187c1163a 0xc421fd4880 0xc421fd4881}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sj2t2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj2t2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sj2t2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.0.134,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421fd4a30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421fd4a60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:49 +0000 UTC  }],Message:,Reason:,HostIP:10.191.0.134,PodIP:172.30.110.39,StartTime:2018-12-05 22:17:49 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 22:17:51.209: INFO: Pod "nginx-deployment-7dc8f79789-hx7vt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-hx7vt,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zmlrx/pods/nginx-deployment-7dc8f79789-hx7vt,UID:9aafd953-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27522,Generation:0,CreationTimestamp:2018-12-05 22:17:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9966ed95-f8db-11e8-bcf8-b20187c1163a 0xc421fd4d90 0xc421fd4d91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sj2t2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj2t2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sj2t2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.0.150,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421fd4e10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421fd4e30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 22:17:51.209: INFO: Pod "nginx-deployment-7dc8f79789-jnjf8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-jnjf8,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zmlrx/pods/nginx-deployment-7dc8f79789-jnjf8,UID:99729eb8-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27488,Generation:0,CreationTimestamp:2018-12-05 22:17:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9966ed95-f8db-11e8-bcf8-b20187c1163a 0xc421fd4f50 0xc421fd4f51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sj2t2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj2t2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sj2t2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.0.147,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421fd4fd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421fd4ff0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:49 +0000 UTC  }],Message:,Reason:,HostIP:10.191.0.147,PodIP:172.30.46.185,StartTime:2018-12-05 22:17:49 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 22:17:51.209: INFO: Pod "nginx-deployment-7dc8f79789-jp88v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-jp88v,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zmlrx/pods/nginx-deployment-7dc8f79789-jp88v,UID:9aafc1ea-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27525,Generation:0,CreationTimestamp:2018-12-05 22:17:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9966ed95-f8db-11e8-bcf8-b20187c1163a 0xc421fd51b0 0xc421fd51b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sj2t2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj2t2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sj2t2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.0.134,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421fd5230} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421fd5250}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 22:17:51.209: INFO: Pod "nginx-deployment-7dc8f79789-mhw87" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-mhw87,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zmlrx/pods/nginx-deployment-7dc8f79789-mhw87,UID:9aab8bb1-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27517,Generation:0,CreationTimestamp:2018-12-05 22:17:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9966ed95-f8db-11e8-bcf8-b20187c1163a 0xc421fd5360 0xc421fd5361}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sj2t2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj2t2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sj2t2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.0.150,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421fd53e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421fd5400}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 22:17:51.209: INFO: Pod "nginx-deployment-7dc8f79789-nrjdv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-nrjdv,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zmlrx/pods/nginx-deployment-7dc8f79789-nrjdv,UID:9973fa2b-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27495,Generation:0,CreationTimestamp:2018-12-05 22:17:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9966ed95-f8db-11e8-bcf8-b20187c1163a 0xc421fd5470 0xc421fd5471}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sj2t2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj2t2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sj2t2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.0.134,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421fd5560} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421fd5580}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:49 +0000 UTC  }],Message:,Reason:,HostIP:10.191.0.134,PodIP:172.30.110.40,StartTime:2018-12-05 22:17:49 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 22:17:51.209: INFO: Pod "nginx-deployment-7dc8f79789-r7xtv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-r7xtv,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zmlrx/pods/nginx-deployment-7dc8f79789-r7xtv,UID:9ab3f22c-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27527,Generation:0,CreationTimestamp:2018-12-05 22:17:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9966ed95-f8db-11e8-bcf8-b20187c1163a 0xc421fd5660 0xc421fd5661}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sj2t2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj2t2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sj2t2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421fd5820} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421fd5840}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 22:17:51.209: INFO: Pod "nginx-deployment-7dc8f79789-xw8g8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-xw8g8,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zmlrx/pods/nginx-deployment-7dc8f79789-xw8g8,UID:9ab3af04-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27526,Generation:0,CreationTimestamp:2018-12-05 22:17:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9966ed95-f8db-11e8-bcf8-b20187c1163a 0xc421fd58b7 0xc421fd58b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sj2t2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj2t2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sj2t2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421fd5a70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421fd5a90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 22:17:51.209: INFO: Pod "nginx-deployment-7f9675fb8b-56zgc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-56zgc,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zmlrx/pods/nginx-deployment-7f9675fb8b-56zgc,UID:9ab00079-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27530,Generation:0,CreationTimestamp:2018-12-05 22:17:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 96cfec70-f8db-11e8-bcf8-b20187c1163a 0xc421fd5af7 0xc421fd5af8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sj2t2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj2t2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj2t2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.0.150,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421fd5b80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421fd5bd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 22:17:51.210: INFO: Pod "nginx-deployment-7f9675fb8b-6mr97" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-6mr97,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zmlrx/pods/nginx-deployment-7f9675fb8b-6mr97,UID:9aa9cb6d-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27523,Generation:0,CreationTimestamp:2018-12-05 22:17:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 96cfec70-f8db-11e8-bcf8-b20187c1163a 0xc421fd5d10 0xc421fd5d11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sj2t2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj2t2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj2t2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.0.147,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421fd5e10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421fd5e30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:51 +0000 UTC  }],Message:,Reason:,HostIP:10.191.0.147,PodIP:,StartTime:2018-12-05 22:17:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 22:17:51.210: INFO: Pod "nginx-deployment-7f9675fb8b-8f6hg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-8f6hg,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zmlrx/pods/nginx-deployment-7f9675fb8b-8f6hg,UID:96d7cff9-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27359,Generation:0,CreationTimestamp:2018-12-05 22:17:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 96cfec70-f8db-11e8-bcf8-b20187c1163a 0xc421db4067 0xc421db4068}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sj2t2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj2t2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj2t2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.0.150,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421db4570} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421db4590}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:44 +0000 UTC  }],Message:,Reason:,HostIP:10.191.0.150,PodIP:172.30.248.90,StartTime:2018-12-05 22:17:44 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-05 22:17:46 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd containerd://6227fc28299a44759592603b2f22cd26eb9fbfb1d832a59522c504f29fbd157c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 22:17:51.210: INFO: Pod "nginx-deployment-7f9675fb8b-9f6jb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-9f6jb,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zmlrx/pods/nginx-deployment-7f9675fb8b-9f6jb,UID:96d5afc1-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27375,Generation:0,CreationTimestamp:2018-12-05 22:17:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 96cfec70-f8db-11e8-bcf8-b20187c1163a 0xc421db4657 0xc421db4658}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sj2t2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj2t2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj2t2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.0.147,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421db4c20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421db4c40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:44 +0000 UTC  }],Message:,Reason:,HostIP:10.191.0.147,PodIP:172.30.46.181,StartTime:2018-12-05 22:17:44 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-05 22:17:46 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd containerd://a2ccccb112556732cec957f34ef230036ee354ba0073d5605f83ff33d18e9d05}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 22:17:51.210: INFO: Pod "nginx-deployment-7f9675fb8b-cds6x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-cds6x,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zmlrx/pods/nginx-deployment-7f9675fb8b-cds6x,UID:9aab98fc-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27521,Generation:0,CreationTimestamp:2018-12-05 22:17:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 96cfec70-f8db-11e8-bcf8-b20187c1163a 0xc421db4d47 0xc421db4d48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sj2t2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj2t2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj2t2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.0.147,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421db5610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421db5630}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 22:17:51.210: INFO: Pod "nginx-deployment-7f9675fb8b-ck8ms" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-ck8ms,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zmlrx/pods/nginx-deployment-7f9675fb8b-ck8ms,UID:96d7daf3-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27368,Generation:0,CreationTimestamp:2018-12-05 22:17:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 96cfec70-f8db-11e8-bcf8-b20187c1163a 0xc421db56a0 0xc421db56a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sj2t2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj2t2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj2t2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.0.150,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421db5710} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421db5740}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:44 +0000 UTC  }],Message:,Reason:,HostIP:10.191.0.150,PodIP:172.30.248.88,StartTime:2018-12-05 22:17:44 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-05 22:17:46 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd containerd://297a9a7f378ecd567730036a6d8001ac15211879d2b43bb526a3ac4d96c3dffa}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 22:17:51.210: INFO: Pod "nginx-deployment-7f9675fb8b-cllwd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-cllwd,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zmlrx/pods/nginx-deployment-7f9675fb8b-cllwd,UID:96db5f23-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27356,Generation:0,CreationTimestamp:2018-12-05 22:17:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 96cfec70-f8db-11e8-bcf8-b20187c1163a 0xc421db5867 0xc421db5868}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sj2t2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj2t2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj2t2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.0.150,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421db5920} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421db5940}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:44 +0000 UTC  }],Message:,Reason:,HostIP:10.191.0.150,PodIP:172.30.248.89,StartTime:2018-12-05 22:17:44 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-05 22:17:46 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd containerd://4b7ee3303f7d2e78302bf26d229cc07d6b33a0233d235016afcd2155eaa71345}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 22:17:51.210: INFO: Pod "nginx-deployment-7f9675fb8b-fzm22" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-fzm22,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zmlrx/pods/nginx-deployment-7f9675fb8b-fzm22,UID:9aafda44-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27516,Generation:0,CreationTimestamp:2018-12-05 22:17:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 96cfec70-f8db-11e8-bcf8-b20187c1163a 0xc421db5ad7 0xc421db5ad8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sj2t2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj2t2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj2t2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421db5bd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421db5bf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 22:17:51.210: INFO: Pod "nginx-deployment-7f9675fb8b-g2cbx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-g2cbx,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zmlrx/pods/nginx-deployment-7f9675fb8b-g2cbx,UID:9ab00122-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27528,Generation:0,CreationTimestamp:2018-12-05 22:17:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 96cfec70-f8db-11e8-bcf8-b20187c1163a 0xc421db5c47 0xc421db5c48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sj2t2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj2t2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj2t2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.0.147,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421db5cc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421db5ce0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 22:17:51.210: INFO: Pod "nginx-deployment-7f9675fb8b-j2zbc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-j2zbc,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zmlrx/pods/nginx-deployment-7f9675fb8b-j2zbc,UID:9aab6dd7-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27518,Generation:0,CreationTimestamp:2018-12-05 22:17:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 96cfec70-f8db-11e8-bcf8-b20187c1163a 0xc421db5ed0 0xc421db5ed1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sj2t2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj2t2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj2t2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.0.134,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421db5f60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421db5f80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 22:17:51.211: INFO: Pod "nginx-deployment-7f9675fb8b-ldkx5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-ldkx5,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zmlrx/pods/nginx-deployment-7f9675fb8b-ldkx5,UID:9ab42f94-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27531,Generation:0,CreationTimestamp:2018-12-05 22:17:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 96cfec70-f8db-11e8-bcf8-b20187c1163a 0xc421f10010 0xc421f10011}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sj2t2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj2t2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj2t2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f10070} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f10090}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 22:17:51.211: INFO: Pod "nginx-deployment-7f9675fb8b-lw4jg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-lw4jg,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zmlrx/pods/nginx-deployment-7f9675fb8b-lw4jg,UID:96d3f172-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27363,Generation:0,CreationTimestamp:2018-12-05 22:17:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 96cfec70-f8db-11e8-bcf8-b20187c1163a 0xc421f100e7 0xc421f100e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sj2t2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj2t2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj2t2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.0.150,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f10160} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f10180}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:44 +0000 UTC  }],Message:,Reason:,HostIP:10.191.0.150,PodIP:172.30.248.85,StartTime:2018-12-05 22:17:44 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-05 22:17:46 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd containerd://0c63c86af0fc4a49ad4815f7c6245131b9bddf63ede72a898c715d2175a05fe6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 22:17:51.211: INFO: Pod "nginx-deployment-7f9675fb8b-nqhxb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-nqhxb,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zmlrx/pods/nginx-deployment-7f9675fb8b-nqhxb,UID:9ab023c6-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27520,Generation:0,CreationTimestamp:2018-12-05 22:17:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 96cfec70-f8db-11e8-bcf8-b20187c1163a 0xc421f10247 0xc421f10248}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sj2t2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj2t2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj2t2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f102b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f102d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 22:17:51.211: INFO: Pod "nginx-deployment-7f9675fb8b-s6dz2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-s6dz2,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zmlrx/pods/nginx-deployment-7f9675fb8b-s6dz2,UID:96d7df80-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27344,Generation:0,CreationTimestamp:2018-12-05 22:17:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 96cfec70-f8db-11e8-bcf8-b20187c1163a 0xc421f10327 0xc421f10328}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sj2t2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj2t2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj2t2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.0.134,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f103a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f10400}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:44 +0000 UTC  }],Message:,Reason:,HostIP:10.191.0.134,PodIP:172.30.110.37,StartTime:2018-12-05 22:17:44 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-05 22:17:45 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd containerd://8e74185ffe4695714e59ccd6e324dc49a42d832e098f780a76ff281a126bc3cb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 22:17:51.211: INFO: Pod "nginx-deployment-7f9675fb8b-sn9zl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-sn9zl,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zmlrx/pods/nginx-deployment-7f9675fb8b-sn9zl,UID:9ab426cd-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27533,Generation:0,CreationTimestamp:2018-12-05 22:17:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 96cfec70-f8db-11e8-bcf8-b20187c1163a 0xc421f104d7 0xc421f104d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sj2t2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj2t2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj2t2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f10540} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f10560}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 22:17:51.211: INFO: Pod "nginx-deployment-7f9675fb8b-t4z5w" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-t4z5w,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zmlrx/pods/nginx-deployment-7f9675fb8b-t4z5w,UID:96d7d04d-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27378,Generation:0,CreationTimestamp:2018-12-05 22:17:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 96cfec70-f8db-11e8-bcf8-b20187c1163a 0xc421f105b7 0xc421f105b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sj2t2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj2t2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj2t2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.0.147,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f10630} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f10650}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:44 +0000 UTC  }],Message:,Reason:,HostIP:10.191.0.147,PodIP:172.30.46.183,StartTime:2018-12-05 22:17:44 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-05 22:17:46 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd containerd://05ff0ce276e029e55cb3e1aaa80cc9c992141824d7d082b3d94eba61a8374e42}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 22:17:51.215: INFO: Pod "nginx-deployment-7f9675fb8b-x4z4d" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-x4z4d,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zmlrx/pods/nginx-deployment-7f9675fb8b-x4z4d,UID:96d5b303-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27381,Generation:0,CreationTimestamp:2018-12-05 22:17:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 96cfec70-f8db-11e8-bcf8-b20187c1163a 0xc421f10817 0xc421f10818}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sj2t2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj2t2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj2t2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.0.134,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f10900} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f10920}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 22:17:44 +0000 UTC  }],Message:,Reason:,HostIP:10.191.0.134,PodIP:172.30.110.38,StartTime:2018-12-05 22:17:44 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-05 22:17:45 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd containerd://b217fef8ed70266e1bcd084c7b48e6c9be296f7ad26a227f0799e1914fa34f53}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 22:17:51.215: INFO: Pod "nginx-deployment-7f9675fb8b-xgr8j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-xgr8j,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-zmlrx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zmlrx/pods/nginx-deployment-7f9675fb8b-xgr8j,UID:9ab42b10-f8db-11e8-bcf8-b20187c1163a,ResourceVersion:27532,Generation:0,CreationTimestamp:2018-12-05 22:17:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 96cfec70-f8db-11e8-bcf8-b20187c1163a 0xc421f109e7 0xc421f109e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sj2t2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sj2t2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sj2t2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f10ab0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f10ad0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:17:51.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-zmlrx" for this suite.
Dec  5 22:18:01.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:18:01.572: INFO: namespace: e2e-tests-deployment-zmlrx, resource: bindings, ignored listing per whitelist
Dec  5 22:18:01.793: INFO: namespace e2e-tests-deployment-zmlrx deletion completed in 10.553915928s

• [SLOW TEST:17.502 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:18:01.793: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-cwqrt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  5 22:18:02.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-cwqrt'
Dec  5 22:18:02.529: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec  5 22:18:02.529: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Dec  5 22:18:04.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-cwqrt'
Dec  5 22:18:04.743: INFO: stderr: ""
Dec  5 22:18:04.743: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:18:04.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cwqrt" for this suite.
Dec  5 22:18:28.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:18:29.029: INFO: namespace: e2e-tests-kubectl-cwqrt, resource: bindings, ignored listing per whitelist
Dec  5 22:18:29.458: INFO: namespace e2e-tests-kubectl-cwqrt deletion completed in 24.699910698s

• [SLOW TEST:27.665 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:18:29.458: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-v6trc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-crx6
STEP: Creating a pod to test atomic-volume-subpath
Dec  5 22:18:29.997: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-crx6" in namespace "e2e-tests-subpath-v6trc" to be "success or failure"
Dec  5 22:18:30.019: INFO: Pod "pod-subpath-test-secret-crx6": Phase="Pending", Reason="", readiness=false. Elapsed: 21.642678ms
Dec  5 22:18:32.042: INFO: Pod "pod-subpath-test-secret-crx6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045172298s
Dec  5 22:18:34.051: INFO: Pod "pod-subpath-test-secret-crx6": Phase="Running", Reason="", readiness=false. Elapsed: 4.054025484s
Dec  5 22:18:36.062: INFO: Pod "pod-subpath-test-secret-crx6": Phase="Running", Reason="", readiness=false. Elapsed: 6.064839039s
Dec  5 22:18:38.070: INFO: Pod "pod-subpath-test-secret-crx6": Phase="Running", Reason="", readiness=false. Elapsed: 8.073047593s
Dec  5 22:18:40.078: INFO: Pod "pod-subpath-test-secret-crx6": Phase="Running", Reason="", readiness=false. Elapsed: 10.081215347s
Dec  5 22:18:42.105: INFO: Pod "pod-subpath-test-secret-crx6": Phase="Running", Reason="", readiness=false. Elapsed: 12.107924722s
Dec  5 22:18:44.115: INFO: Pod "pod-subpath-test-secret-crx6": Phase="Running", Reason="", readiness=false. Elapsed: 14.118051193s
Dec  5 22:18:46.125: INFO: Pod "pod-subpath-test-secret-crx6": Phase="Running", Reason="", readiness=false. Elapsed: 16.128140922s
Dec  5 22:18:48.138: INFO: Pod "pod-subpath-test-secret-crx6": Phase="Running", Reason="", readiness=false. Elapsed: 18.140468378s
Dec  5 22:18:50.147: INFO: Pod "pod-subpath-test-secret-crx6": Phase="Running", Reason="", readiness=false. Elapsed: 20.149681752s
Dec  5 22:18:52.167: INFO: Pod "pod-subpath-test-secret-crx6": Phase="Running", Reason="", readiness=false. Elapsed: 22.170178592s
Dec  5 22:18:54.177: INFO: Pod "pod-subpath-test-secret-crx6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.18032722s
STEP: Saw pod success
Dec  5 22:18:54.177: INFO: Pod "pod-subpath-test-secret-crx6" satisfied condition "success or failure"
Dec  5 22:18:54.187: INFO: Trying to get logs from node 10.191.0.150 pod pod-subpath-test-secret-crx6 container test-container-subpath-secret-crx6: <nil>
STEP: delete the pod
Dec  5 22:18:54.242: INFO: Waiting for pod pod-subpath-test-secret-crx6 to disappear
Dec  5 22:18:54.251: INFO: Pod pod-subpath-test-secret-crx6 no longer exists
STEP: Deleting pod pod-subpath-test-secret-crx6
Dec  5 22:18:54.251: INFO: Deleting pod "pod-subpath-test-secret-crx6" in namespace "e2e-tests-subpath-v6trc"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:18:54.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-v6trc" for this suite.
Dec  5 22:19:00.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:19:00.362: INFO: namespace: e2e-tests-subpath-v6trc, resource: bindings, ignored listing per whitelist
Dec  5 22:19:00.709: INFO: namespace e2e-tests-subpath-v6trc deletion completed in 6.431624279s

• [SLOW TEST:31.251 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:19:00.710: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-pjw4z
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Dec  5 22:19:05.193: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-c4642690-f8db-11e8-b962-c6dde3e93636", GenerateName:"", Namespace:"e2e-tests-pods-pjw4z", SelfLink:"/api/v1/namespaces/e2e-tests-pods-pjw4z/pods/pod-submit-remove-c4642690-f8db-11e8-b962-c6dde3e93636", UID:"c467b127-f8db-11e8-9151-427614c96c42", ResourceVersion:"28289", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63679645141, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"time":"122427116", "name":"foo"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-m2wbq", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc4232ddc00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-m2wbq", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc4224c3c78), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.191.0.150", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc4229cc6c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4224c3cc0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4224c3ce0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc4224c3ce8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679645141, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679645143, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679645143, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679645141, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.191.0.150", PodIP:"172.30.248.100", StartTime:(*v1.Time)(0xc4227352a0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc4227352c0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"docker.io/library/nginx:1.14-alpine", ImageID:"docker.io/library/nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd", ContainerID:"containerd://e3f34dd7cdf96b34b9e5b748e263cb76ab2803be178f58f059e612267d713023"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Dec  5 22:19:10.276: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:19:10.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-pjw4z" for this suite.
Dec  5 22:19:16.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:19:16.649: INFO: namespace: e2e-tests-pods-pjw4z, resource: bindings, ignored listing per whitelist
Dec  5 22:19:16.706: INFO: namespace e2e-tests-pods-pjw4z deletion completed in 6.408623143s

• [SLOW TEST:15.996 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:19:16.707: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-mgpfc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Dec  5 22:19:17.168: INFO: Waiting up to 5m0s for pod "var-expansion-cdf07a79-f8db-11e8-b962-c6dde3e93636" in namespace "e2e-tests-var-expansion-mgpfc" to be "success or failure"
Dec  5 22:19:17.243: INFO: Pod "var-expansion-cdf07a79-f8db-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 75.7158ms
Dec  5 22:19:19.252: INFO: Pod "var-expansion-cdf07a79-f8db-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084517516s
STEP: Saw pod success
Dec  5 22:19:19.252: INFO: Pod "var-expansion-cdf07a79-f8db-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 22:19:19.263: INFO: Trying to get logs from node 10.191.0.150 pod var-expansion-cdf07a79-f8db-11e8-b962-c6dde3e93636 container dapi-container: <nil>
STEP: delete the pod
Dec  5 22:19:19.373: INFO: Waiting for pod var-expansion-cdf07a79-f8db-11e8-b962-c6dde3e93636 to disappear
Dec  5 22:19:19.418: INFO: Pod var-expansion-cdf07a79-f8db-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:19:19.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-mgpfc" for this suite.
Dec  5 22:19:25.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:19:25.802: INFO: namespace: e2e-tests-var-expansion-mgpfc, resource: bindings, ignored listing per whitelist
Dec  5 22:19:25.838: INFO: namespace e2e-tests-var-expansion-mgpfc deletion completed in 6.406826921s

• [SLOW TEST:9.132 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:19:25.839: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-l92g5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  5 22:19:26.335: INFO: Number of nodes with available pods: 0
Dec  5 22:19:26.335: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 22:19:27.362: INFO: Number of nodes with available pods: 0
Dec  5 22:19:27.362: INFO: Node 10.191.0.134 is running more than one daemon pod
Dec  5 22:19:28.358: INFO: Number of nodes with available pods: 3
Dec  5 22:19:28.358: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec  5 22:19:28.460: INFO: Number of nodes with available pods: 2
Dec  5 22:19:28.460: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:29.544: INFO: Number of nodes with available pods: 2
Dec  5 22:19:29.545: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:30.481: INFO: Number of nodes with available pods: 2
Dec  5 22:19:30.481: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:31.481: INFO: Number of nodes with available pods: 2
Dec  5 22:19:31.481: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:32.486: INFO: Number of nodes with available pods: 2
Dec  5 22:19:32.486: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:33.546: INFO: Number of nodes with available pods: 2
Dec  5 22:19:33.546: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:34.494: INFO: Number of nodes with available pods: 2
Dec  5 22:19:34.494: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:35.482: INFO: Number of nodes with available pods: 2
Dec  5 22:19:35.482: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:36.495: INFO: Number of nodes with available pods: 2
Dec  5 22:19:36.495: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:37.483: INFO: Number of nodes with available pods: 2
Dec  5 22:19:37.483: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:38.485: INFO: Number of nodes with available pods: 2
Dec  5 22:19:38.485: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:39.487: INFO: Number of nodes with available pods: 2
Dec  5 22:19:39.487: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:40.480: INFO: Number of nodes with available pods: 2
Dec  5 22:19:40.481: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:41.546: INFO: Number of nodes with available pods: 2
Dec  5 22:19:41.547: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:42.535: INFO: Number of nodes with available pods: 2
Dec  5 22:19:42.536: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:43.501: INFO: Number of nodes with available pods: 2
Dec  5 22:19:43.501: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:44.481: INFO: Number of nodes with available pods: 2
Dec  5 22:19:44.481: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:45.536: INFO: Number of nodes with available pods: 2
Dec  5 22:19:45.536: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:46.497: INFO: Number of nodes with available pods: 2
Dec  5 22:19:46.497: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:47.485: INFO: Number of nodes with available pods: 2
Dec  5 22:19:47.485: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:48.544: INFO: Number of nodes with available pods: 2
Dec  5 22:19:48.544: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:49.535: INFO: Number of nodes with available pods: 2
Dec  5 22:19:49.536: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:50.481: INFO: Number of nodes with available pods: 2
Dec  5 22:19:50.481: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:51.481: INFO: Number of nodes with available pods: 2
Dec  5 22:19:51.481: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:52.482: INFO: Number of nodes with available pods: 2
Dec  5 22:19:52.482: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:53.485: INFO: Number of nodes with available pods: 2
Dec  5 22:19:53.485: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:54.546: INFO: Number of nodes with available pods: 2
Dec  5 22:19:54.546: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:55.482: INFO: Number of nodes with available pods: 2
Dec  5 22:19:55.482: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:56.482: INFO: Number of nodes with available pods: 2
Dec  5 22:19:56.482: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:57.499: INFO: Number of nodes with available pods: 2
Dec  5 22:19:57.499: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:58.486: INFO: Number of nodes with available pods: 2
Dec  5 22:19:58.486: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:19:59.484: INFO: Number of nodes with available pods: 2
Dec  5 22:19:59.484: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:20:00.545: INFO: Number of nodes with available pods: 2
Dec  5 22:20:00.546: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:20:01.545: INFO: Number of nodes with available pods: 2
Dec  5 22:20:01.545: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:20:02.536: INFO: Number of nodes with available pods: 2
Dec  5 22:20:02.536: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:20:03.487: INFO: Number of nodes with available pods: 2
Dec  5 22:20:03.487: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:20:04.489: INFO: Number of nodes with available pods: 2
Dec  5 22:20:04.489: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:20:05.483: INFO: Number of nodes with available pods: 2
Dec  5 22:20:05.483: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:20:06.536: INFO: Number of nodes with available pods: 2
Dec  5 22:20:06.536: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:20:07.514: INFO: Number of nodes with available pods: 2
Dec  5 22:20:07.514: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:20:08.483: INFO: Number of nodes with available pods: 2
Dec  5 22:20:08.483: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:20:09.483: INFO: Number of nodes with available pods: 2
Dec  5 22:20:09.483: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:20:10.545: INFO: Number of nodes with available pods: 2
Dec  5 22:20:10.545: INFO: Node 10.191.0.150 is running more than one daemon pod
Dec  5 22:20:11.536: INFO: Number of nodes with available pods: 3
Dec  5 22:20:11.536: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-l92g5, will wait for the garbage collector to delete the pods
Dec  5 22:20:11.639: INFO: Deleting {extensions DaemonSet} daemon-set took: 29.286072ms
Dec  5 22:20:11.739: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.28278ms
Dec  5 22:20:49.868: INFO: Number of nodes with available pods: 0
Dec  5 22:20:49.868: INFO: Number of running nodes: 0, number of available pods: 0
Dec  5 22:20:49.878: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-l92g5/daemonsets","resourceVersion":"28617"},"items":null}

Dec  5 22:20:49.889: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-l92g5/pods","resourceVersion":"28617"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:20:49.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-l92g5" for this suite.
Dec  5 22:20:57.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:20:58.088: INFO: namespace: e2e-tests-daemonsets-l92g5, resource: bindings, ignored listing per whitelist
Dec  5 22:20:58.289: INFO: namespace e2e-tests-daemonsets-l92g5 deletion completed in 8.341734646s

• [SLOW TEST:92.450 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:20:58.290: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-tvk6s
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Dec  5 22:20:58.637: INFO: Waiting up to 5m0s for pod "client-containers-0a6d28a4-f8dc-11e8-b962-c6dde3e93636" in namespace "e2e-tests-containers-tvk6s" to be "success or failure"
Dec  5 22:20:58.648: INFO: Pod "client-containers-0a6d28a4-f8dc-11e8-b962-c6dde3e93636": Phase="Pending", Reason="", readiness=false. Elapsed: 10.038245ms
Dec  5 22:21:00.669: INFO: Pod "client-containers-0a6d28a4-f8dc-11e8-b962-c6dde3e93636": Phase="Running", Reason="", readiness=true. Elapsed: 2.031476352s
Dec  5 22:21:02.682: INFO: Pod "client-containers-0a6d28a4-f8dc-11e8-b962-c6dde3e93636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044491649s
STEP: Saw pod success
Dec  5 22:21:02.682: INFO: Pod "client-containers-0a6d28a4-f8dc-11e8-b962-c6dde3e93636" satisfied condition "success or failure"
Dec  5 22:21:02.691: INFO: Trying to get logs from node 10.191.0.150 pod client-containers-0a6d28a4-f8dc-11e8-b962-c6dde3e93636 container test-container: <nil>
STEP: delete the pod
Dec  5 22:21:02.755: INFO: Waiting for pod client-containers-0a6d28a4-f8dc-11e8-b962-c6dde3e93636 to disappear
Dec  5 22:21:02.767: INFO: Pod client-containers-0a6d28a4-f8dc-11e8-b962-c6dde3e93636 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:21:02.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-tvk6s" for this suite.
Dec  5 22:21:08.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:21:09.135: INFO: namespace: e2e-tests-containers-tvk6s, resource: bindings, ignored listing per whitelist
Dec  5 22:21:09.160: INFO: namespace e2e-tests-containers-tvk6s deletion completed in 6.380551925s

• [SLOW TEST:10.871 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:21:09.163: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-27ljm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Dec  5 22:21:09.497: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec  5 22:21:09.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 create -f - --namespace=e2e-tests-kubectl-27ljm'
Dec  5 22:21:09.872: INFO: stderr: ""
Dec  5 22:21:09.872: INFO: stdout: "service/redis-slave created\n"
Dec  5 22:21:09.873: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec  5 22:21:09.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 create -f - --namespace=e2e-tests-kubectl-27ljm'
Dec  5 22:21:10.225: INFO: stderr: ""
Dec  5 22:21:10.225: INFO: stdout: "service/redis-master created\n"
Dec  5 22:21:10.225: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec  5 22:21:10.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 create -f - --namespace=e2e-tests-kubectl-27ljm'
Dec  5 22:21:10.525: INFO: stderr: ""
Dec  5 22:21:10.525: INFO: stdout: "service/frontend created\n"
Dec  5 22:21:10.525: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec  5 22:21:10.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 create -f - --namespace=e2e-tests-kubectl-27ljm'
Dec  5 22:21:10.842: INFO: stderr: ""
Dec  5 22:21:10.842: INFO: stdout: "deployment.extensions/frontend created\n"
Dec  5 22:21:10.843: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec  5 22:21:10.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 create -f - --namespace=e2e-tests-kubectl-27ljm'
Dec  5 22:21:11.220: INFO: stderr: ""
Dec  5 22:21:11.220: INFO: stdout: "deployment.extensions/redis-master created\n"
Dec  5 22:21:11.220: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec  5 22:21:11.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 create -f - --namespace=e2e-tests-kubectl-27ljm'
Dec  5 22:21:11.629: INFO: stderr: ""
Dec  5 22:21:11.629: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Dec  5 22:21:11.629: INFO: Waiting for all frontend pods to be Running.
Dec  5 22:21:36.680: INFO: Waiting for frontend to serve content.
Dec  5 22:21:41.729: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Dec  5 22:21:46.774: INFO: Trying to add a new entry to the guestbook.
Dec  5 22:21:46.809: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Dec  5 22:21:46.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-27ljm'
Dec  5 22:21:47.294: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 22:21:47.294: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec  5 22:21:47.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-27ljm'
Dec  5 22:21:47.498: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 22:21:47.498: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  5 22:21:47.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-27ljm'
Dec  5 22:21:47.671: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 22:21:47.671: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  5 22:21:47.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-27ljm'
Dec  5 22:21:47.860: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 22:21:47.860: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  5 22:21:47.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-27ljm'
Dec  5 22:21:48.168: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 22:21:48.168: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  5 22:21:48.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-27ljm'
Dec  5 22:21:48.405: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 22:21:48.405: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:21:48.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-27ljm" for this suite.
Dec  5 22:22:32.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:22:32.585: INFO: namespace: e2e-tests-kubectl-27ljm, resource: bindings, ignored listing per whitelist
Dec  5 22:22:32.886: INFO: namespace e2e-tests-kubectl-27ljm deletion completed in 44.468654294s

• [SLOW TEST:83.723 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  5 22:22:32.887: INFO: >>> kubeConfig: /tmp/kubeconfig-794602807
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-8rf2w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  5 22:22:33.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-8rf2w'
Dec  5 22:22:33.377: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec  5 22:22:33.377: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Dec  5 22:22:33.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-794602807 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-8rf2w'
Dec  5 22:22:33.617: INFO: stderr: ""
Dec  5 22:22:33.617: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  5 22:22:33.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8rf2w" for this suite.
Dec  5 22:22:39.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 22:22:39.943: INFO: namespace: e2e-tests-kubectl-8rf2w, resource: bindings, ignored listing per whitelist
Dec  5 22:22:40.113: INFO: namespace e2e-tests-kubectl-8rf2w deletion completed in 6.475779995s

• [SLOW TEST:7.227 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSDec  5 22:22:40.115: INFO: Running AfterSuite actions on all node
Dec  5 22:22:40.115: INFO: Running AfterSuite actions on node 1
Dec  5 22:22:40.115: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 5457.982 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 1h30m59.036057163s
Test Suite Passed
