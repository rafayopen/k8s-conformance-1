Mar  4 22:10:08.111: INFO: Overriding default scale value of zero to 1
Mar  4 22:10:08.111: INFO: Overriding default milliseconds value of zero to 5000
I0304 22:10:08.679522      15 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-126132266
I0304 22:10:08.679642      15 e2e.go:304] Starting e2e run "456750ee-3eca-11e9-b56c-8631b5a7dc0e" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1551737407 - Will randomize all specs
Will run 188 of 1814 specs

Mar  4 22:10:08.978: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
Mar  4 22:10:08.980: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Mar  4 22:10:09.085: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Mar  4 22:10:09.136: INFO: 23 / 23 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Mar  4 22:10:09.136: INFO: expected 11 pod replicas in namespace 'kube-system', 11 are Running and Ready.
Mar  4 22:10:09.136: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Mar  4 22:10:09.149: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Mar  4 22:10:09.149: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
Mar  4 22:10:09.149: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-kube-fluentd' (0 seconds elapsed)
Mar  4 22:10:09.149: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'ibm-master-proxy' (0 seconds elapsed)
Mar  4 22:10:09.149: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
Mar  4 22:10:09.149: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Mar  4 22:10:09.149: INFO: e2e test version: v1.12.1
Mar  4 22:10:09.151: INFO: kube-apiserver version: v1.12.6+IKS
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:10:09.153: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename projected
Mar  4 22:10:09.286: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Mar  4 22:10:09.310: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-775jb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  4 22:10:09.443: INFO: Waiting up to 5m0s for pod "downwardapi-volume-463e4ca4-3eca-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-projected-775jb" to be "success or failure"
Mar  4 22:10:09.447: INFO: Pod "downwardapi-volume-463e4ca4-3eca-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.865845ms
Mar  4 22:10:11.458: INFO: Pod "downwardapi-volume-463e4ca4-3eca-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015486606s
Mar  4 22:10:13.464: INFO: Pod "downwardapi-volume-463e4ca4-3eca-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02168532s
STEP: Saw pod success
Mar  4 22:10:13.464: INFO: Pod "downwardapi-volume-463e4ca4-3eca-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:10:13.470: INFO: Trying to get logs from node 10.190.208.160 pod downwardapi-volume-463e4ca4-3eca-11e9-b56c-8631b5a7dc0e container client-container: <nil>
STEP: delete the pod
Mar  4 22:10:13.542: INFO: Waiting for pod downwardapi-volume-463e4ca4-3eca-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:10:13.548: INFO: Pod downwardapi-volume-463e4ca4-3eca-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:10:13.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-775jb" for this suite.
Mar  4 22:10:19.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:10:19.856: INFO: namespace: e2e-tests-projected-775jb, resource: bindings, ignored listing per whitelist
Mar  4 22:10:19.907: INFO: namespace e2e-tests-projected-775jb deletion completed in 6.32377402s

• [SLOW TEST:10.754 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:10:19.908: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-w29xh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0304 22:10:26.313154      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  4 22:10:26.313: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:10:26.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-w29xh" for this suite.
Mar  4 22:10:34.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:10:34.843: INFO: namespace: e2e-tests-gc-w29xh, resource: bindings, ignored listing per whitelist
Mar  4 22:10:35.102: INFO: namespace e2e-tests-gc-w29xh deletion completed in 8.777799279s

• [SLOW TEST:15.193 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:10:35.102: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-2zmgl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-gqlr6
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
Mar  4 22:10:46.813: INFO: error from create uninitialized namespace: Internal error occurred: object deleted while waiting for creation
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-wgc9g
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:11:04.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-2zmgl" for this suite.
Mar  4 22:11:10.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:11:11.073: INFO: namespace: e2e-tests-namespaces-2zmgl, resource: bindings, ignored listing per whitelist
Mar  4 22:11:11.128: INFO: namespace e2e-tests-namespaces-2zmgl deletion completed in 6.357629867s
STEP: Destroying namespace "e2e-tests-nsdeletetest-gqlr6" for this suite.
Mar  4 22:11:11.136: INFO: Namespace e2e-tests-nsdeletetest-gqlr6 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-wgc9g" for this suite.
Mar  4 22:11:17.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:11:17.318: INFO: namespace: e2e-tests-nsdeletetest-wgc9g, resource: bindings, ignored listing per whitelist
Mar  4 22:11:17.406: INFO: namespace e2e-tests-nsdeletetest-wgc9g deletion completed in 6.269982043s

• [SLOW TEST:42.304 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:11:17.407: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-jm8mp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar  4 22:11:17.655: INFO: Waiting up to 5m0s for pod "pod-6ee6f182-3eca-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-emptydir-jm8mp" to be "success or failure"
Mar  4 22:11:17.660: INFO: Pod "pod-6ee6f182-3eca-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.579738ms
Mar  4 22:11:19.666: INFO: Pod "pod-6ee6f182-3eca-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010247365s
Mar  4 22:11:21.671: INFO: Pod "pod-6ee6f182-3eca-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015757222s
STEP: Saw pod success
Mar  4 22:11:21.671: INFO: Pod "pod-6ee6f182-3eca-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:11:21.676: INFO: Trying to get logs from node 10.190.208.160 pod pod-6ee6f182-3eca-11e9-b56c-8631b5a7dc0e container test-container: <nil>
STEP: delete the pod
Mar  4 22:11:21.709: INFO: Waiting for pod pod-6ee6f182-3eca-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:11:21.714: INFO: Pod pod-6ee6f182-3eca-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:11:21.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jm8mp" for this suite.
Mar  4 22:11:27.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:11:28.051: INFO: namespace: e2e-tests-emptydir-jm8mp, resource: bindings, ignored listing per whitelist
Mar  4 22:11:28.109: INFO: namespace e2e-tests-emptydir-jm8mp deletion completed in 6.385546733s

• [SLOW TEST:10.702 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:11:28.111: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-gnw26
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Mar  4 22:11:28.362: INFO: Waiting up to 5m0s for pod "var-expansion-7548b2c5-3eca-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-var-expansion-gnw26" to be "success or failure"
Mar  4 22:11:28.368: INFO: Pod "var-expansion-7548b2c5-3eca-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.578859ms
Mar  4 22:11:30.373: INFO: Pod "var-expansion-7548b2c5-3eca-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011318394s
Mar  4 22:11:32.380: INFO: Pod "var-expansion-7548b2c5-3eca-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018234723s
STEP: Saw pod success
Mar  4 22:11:32.380: INFO: Pod "var-expansion-7548b2c5-3eca-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:11:32.385: INFO: Trying to get logs from node 10.190.208.160 pod var-expansion-7548b2c5-3eca-11e9-b56c-8631b5a7dc0e container dapi-container: <nil>
STEP: delete the pod
Mar  4 22:11:32.416: INFO: Waiting for pod var-expansion-7548b2c5-3eca-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:11:32.490: INFO: Pod var-expansion-7548b2c5-3eca-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:11:32.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-gnw26" for this suite.
Mar  4 22:11:38.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:11:38.963: INFO: namespace: e2e-tests-var-expansion-gnw26, resource: bindings, ignored listing per whitelist
Mar  4 22:11:39.102: INFO: namespace e2e-tests-var-expansion-gnw26 deletion completed in 6.601947818s

• [SLOW TEST:10.992 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:11:39.105: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-vh7m5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secret-namespace-tm6hd
STEP: Creating secret with name secret-test-7bdad7b2-3eca-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume secrets
Mar  4 22:11:39.579: INFO: Waiting up to 5m0s for pod "pod-secrets-7bf80d05-3eca-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-secrets-vh7m5" to be "success or failure"
Mar  4 22:11:39.585: INFO: Pod "pod-secrets-7bf80d05-3eca-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.208829ms
Mar  4 22:11:41.591: INFO: Pod "pod-secrets-7bf80d05-3eca-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011121382s
STEP: Saw pod success
Mar  4 22:11:41.591: INFO: Pod "pod-secrets-7bf80d05-3eca-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:11:41.596: INFO: Trying to get logs from node 10.190.208.160 pod pod-secrets-7bf80d05-3eca-11e9-b56c-8631b5a7dc0e container secret-volume-test: <nil>
STEP: delete the pod
Mar  4 22:11:41.699: INFO: Waiting for pod pod-secrets-7bf80d05-3eca-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:11:41.705: INFO: Pod pod-secrets-7bf80d05-3eca-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:11:41.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-vh7m5" for this suite.
Mar  4 22:11:47.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:11:47.869: INFO: namespace: e2e-tests-secrets-vh7m5, resource: bindings, ignored listing per whitelist
Mar  4 22:11:48.037: INFO: namespace e2e-tests-secrets-vh7m5 deletion completed in 6.322042977s
STEP: Destroying namespace "e2e-tests-secret-namespace-tm6hd" for this suite.
Mar  4 22:11:54.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:11:54.122: INFO: namespace: e2e-tests-secret-namespace-tm6hd, resource: bindings, ignored listing per whitelist
Mar  4 22:11:54.467: INFO: namespace e2e-tests-secret-namespace-tm6hd deletion completed in 6.430488198s

• [SLOW TEST:15.363 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:11:54.467: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-pvllt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  4 22:11:54.794: INFO: Waiting up to 5m0s for pod "downwardapi-volume-84fcd659-3eca-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-downward-api-pvllt" to be "success or failure"
Mar  4 22:11:54.799: INFO: Pod "downwardapi-volume-84fcd659-3eca-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.854262ms
Mar  4 22:11:56.805: INFO: Pod "downwardapi-volume-84fcd659-3eca-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010706125s
Mar  4 22:11:58.811: INFO: Pod "downwardapi-volume-84fcd659-3eca-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016726648s
STEP: Saw pod success
Mar  4 22:11:58.811: INFO: Pod "downwardapi-volume-84fcd659-3eca-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:11:58.815: INFO: Trying to get logs from node 10.190.208.162 pod downwardapi-volume-84fcd659-3eca-11e9-b56c-8631b5a7dc0e container client-container: <nil>
STEP: delete the pod
Mar  4 22:11:58.852: INFO: Waiting for pod downwardapi-volume-84fcd659-3eca-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:11:58.860: INFO: Pod downwardapi-volume-84fcd659-3eca-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:11:58.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pvllt" for this suite.
Mar  4 22:12:04.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:12:05.064: INFO: namespace: e2e-tests-downward-api-pvllt, resource: bindings, ignored listing per whitelist
Mar  4 22:12:05.254: INFO: namespace e2e-tests-downward-api-pvllt deletion completed in 6.383114983s

• [SLOW TEST:10.786 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:12:05.254: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-qtxsw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  4 22:12:05.591: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Mar  4 22:12:05.604: INFO: Number of nodes with available pods: 0
Mar  4 22:12:05.605: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Mar  4 22:12:05.633: INFO: failed to update node due to resource version conflict
Mar  4 22:12:06.659: INFO: Number of nodes with available pods: 0
Mar  4 22:12:06.659: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:07.665: INFO: Number of nodes with available pods: 0
Mar  4 22:12:07.665: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:08.665: INFO: Number of nodes with available pods: 0
Mar  4 22:12:08.665: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:09.665: INFO: Number of nodes with available pods: 1
Mar  4 22:12:09.665: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Mar  4 22:12:09.783: INFO: Number of nodes with available pods: 1
Mar  4 22:12:09.783: INFO: Number of running nodes: 0, number of available pods: 1
Mar  4 22:12:10.788: INFO: Number of nodes with available pods: 0
Mar  4 22:12:10.789: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Mar  4 22:12:10.800: INFO: Number of nodes with available pods: 0
Mar  4 22:12:10.800: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:11.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:11.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:12.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:12.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:13.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:13.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:14.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:14.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:15.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:15.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:16.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:16.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:17.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:17.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:18.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:18.807: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:19.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:19.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:20.807: INFO: Number of nodes with available pods: 0
Mar  4 22:12:20.807: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:21.807: INFO: Number of nodes with available pods: 0
Mar  4 22:12:21.807: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:22.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:22.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:23.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:23.807: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:24.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:24.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:25.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:25.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:26.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:26.807: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:27.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:27.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:28.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:28.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:29.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:29.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:30.810: INFO: Number of nodes with available pods: 0
Mar  4 22:12:30.810: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:31.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:31.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:32.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:32.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:33.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:33.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:34.805: INFO: Number of nodes with available pods: 0
Mar  4 22:12:34.805: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:35.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:35.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:36.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:36.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:37.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:37.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:38.916: INFO: Number of nodes with available pods: 0
Mar  4 22:12:38.916: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:39.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:39.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:40.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:40.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:41.807: INFO: Number of nodes with available pods: 0
Mar  4 22:12:41.807: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:42.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:42.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:43.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:43.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:44.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:44.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:45.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:45.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:46.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:46.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:47.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:47.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:48.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:48.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:49.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:49.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:50.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:50.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:51.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:51.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:52.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:52.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:53.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:53.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:54.806: INFO: Number of nodes with available pods: 0
Mar  4 22:12:54.806: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:12:55.806: INFO: Number of nodes with available pods: 1
Mar  4 22:12:55.807: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-qtxsw, will wait for the garbage collector to delete the pods
Mar  4 22:12:55.894: INFO: Deleting {extensions DaemonSet} daemon-set took: 23.303135ms
Mar  4 22:12:55.995: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.320206ms
Mar  4 22:13:34.088: INFO: Number of nodes with available pods: 0
Mar  4 22:13:34.088: INFO: Number of running nodes: 0, number of available pods: 0
Mar  4 22:13:34.095: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-qtxsw/daemonsets","resourceVersion":"7607"},"items":null}

Mar  4 22:13:34.100: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-qtxsw/pods","resourceVersion":"7607"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:13:34.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-qtxsw" for this suite.
Mar  4 22:13:40.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:13:40.284: INFO: namespace: e2e-tests-daemonsets-qtxsw, resource: bindings, ignored listing per whitelist
Mar  4 22:13:40.490: INFO: namespace e2e-tests-daemonsets-qtxsw deletion completed in 6.334620144s

• [SLOW TEST:95.236 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:13:40.490: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-p62qd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-c4396857-3eca-11e9-b56c-8631b5a7dc0e
STEP: Creating secret with name s-test-opt-upd-c43968b4-3eca-11e9-b56c-8631b5a7dc0e
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-c4396857-3eca-11e9-b56c-8631b5a7dc0e
STEP: Updating secret s-test-opt-upd-c43968b4-3eca-11e9-b56c-8631b5a7dc0e
STEP: Creating secret with name s-test-opt-create-c43968d7-3eca-11e9-b56c-8631b5a7dc0e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:13:45.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-p62qd" for this suite.
Mar  4 22:14:09.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:14:09.205: INFO: namespace: e2e-tests-projected-p62qd, resource: bindings, ignored listing per whitelist
Mar  4 22:14:09.409: INFO: namespace e2e-tests-projected-p62qd deletion completed in 24.351223065s

• [SLOW TEST:28.919 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:14:09.410: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-zdsgv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Mar  4 22:14:09.663: INFO: Waiting up to 5m0s for pod "client-containers-d56cc41c-3eca-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-containers-zdsgv" to be "success or failure"
Mar  4 22:14:09.668: INFO: Pod "client-containers-d56cc41c-3eca-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.732651ms
Mar  4 22:14:11.673: INFO: Pod "client-containers-d56cc41c-3eca-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010114806s
Mar  4 22:14:13.680: INFO: Pod "client-containers-d56cc41c-3eca-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016836273s
STEP: Saw pod success
Mar  4 22:14:13.680: INFO: Pod "client-containers-d56cc41c-3eca-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:14:13.685: INFO: Trying to get logs from node 10.190.208.160 pod client-containers-d56cc41c-3eca-11e9-b56c-8631b5a7dc0e container test-container: <nil>
STEP: delete the pod
Mar  4 22:14:13.728: INFO: Waiting for pod client-containers-d56cc41c-3eca-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:14:13.733: INFO: Pod client-containers-d56cc41c-3eca-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:14:13.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-zdsgv" for this suite.
Mar  4 22:14:19.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:14:19.905: INFO: namespace: e2e-tests-containers-zdsgv, resource: bindings, ignored listing per whitelist
Mar  4 22:14:20.020: INFO: namespace e2e-tests-containers-zdsgv deletion completed in 6.276806553s

• [SLOW TEST:10.610 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:14:20.020: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-4b852
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Mar  4 22:14:20.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 create -f - --namespace=e2e-tests-kubectl-4b852'
Mar  4 22:14:20.672: INFO: stderr: ""
Mar  4 22:14:20.672: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  4 22:14:20.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-4b852'
Mar  4 22:14:20.822: INFO: stderr: ""
Mar  4 22:14:20.822: INFO: stdout: "update-demo-nautilus-5nb4b update-demo-nautilus-lm9rz "
Mar  4 22:14:20.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods update-demo-nautilus-5nb4b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4b852'
Mar  4 22:14:20.946: INFO: stderr: ""
Mar  4 22:14:20.946: INFO: stdout: ""
Mar  4 22:14:20.946: INFO: update-demo-nautilus-5nb4b is created but not running
Mar  4 22:14:25.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-4b852'
Mar  4 22:14:26.087: INFO: stderr: ""
Mar  4 22:14:26.087: INFO: stdout: "update-demo-nautilus-5nb4b update-demo-nautilus-lm9rz "
Mar  4 22:14:26.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods update-demo-nautilus-5nb4b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4b852'
Mar  4 22:14:26.218: INFO: stderr: ""
Mar  4 22:14:26.218: INFO: stdout: "true"
Mar  4 22:14:26.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods update-demo-nautilus-5nb4b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4b852'
Mar  4 22:14:26.344: INFO: stderr: ""
Mar  4 22:14:26.344: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  4 22:14:26.344: INFO: validating pod update-demo-nautilus-5nb4b
Mar  4 22:14:26.358: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  4 22:14:26.358: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  4 22:14:26.358: INFO: update-demo-nautilus-5nb4b is verified up and running
Mar  4 22:14:26.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods update-demo-nautilus-lm9rz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4b852'
Mar  4 22:14:26.860: INFO: stderr: ""
Mar  4 22:14:26.860: INFO: stdout: "true"
Mar  4 22:14:26.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods update-demo-nautilus-lm9rz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4b852'
Mar  4 22:14:26.975: INFO: stderr: ""
Mar  4 22:14:26.975: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  4 22:14:26.975: INFO: validating pod update-demo-nautilus-lm9rz
Mar  4 22:14:26.987: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  4 22:14:26.987: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  4 22:14:26.987: INFO: update-demo-nautilus-lm9rz is verified up and running
STEP: scaling down the replication controller
Mar  4 22:14:26.988: INFO: scanned /root for discovery docs: <nil>
Mar  4 22:14:26.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-4b852'
Mar  4 22:14:27.192: INFO: stderr: ""
Mar  4 22:14:27.192: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  4 22:14:27.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-4b852'
Mar  4 22:14:27.330: INFO: stderr: ""
Mar  4 22:14:27.330: INFO: stdout: "update-demo-nautilus-5nb4b update-demo-nautilus-lm9rz "
STEP: Replicas for name=update-demo: expected=1 actual=2
Mar  4 22:14:32.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-4b852'
Mar  4 22:14:32.510: INFO: stderr: ""
Mar  4 22:14:32.510: INFO: stdout: "update-demo-nautilus-lm9rz "
Mar  4 22:14:32.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods update-demo-nautilus-lm9rz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4b852'
Mar  4 22:14:32.641: INFO: stderr: ""
Mar  4 22:14:32.641: INFO: stdout: "true"
Mar  4 22:14:32.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods update-demo-nautilus-lm9rz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4b852'
Mar  4 22:14:32.785: INFO: stderr: ""
Mar  4 22:14:32.785: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  4 22:14:32.785: INFO: validating pod update-demo-nautilus-lm9rz
Mar  4 22:14:32.794: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  4 22:14:32.794: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  4 22:14:32.794: INFO: update-demo-nautilus-lm9rz is verified up and running
STEP: scaling up the replication controller
Mar  4 22:14:32.796: INFO: scanned /root for discovery docs: <nil>
Mar  4 22:14:32.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-4b852'
Mar  4 22:14:34.043: INFO: stderr: ""
Mar  4 22:14:34.043: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  4 22:14:34.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-4b852'
Mar  4 22:14:34.184: INFO: stderr: ""
Mar  4 22:14:34.184: INFO: stdout: "update-demo-nautilus-fm5wx update-demo-nautilus-lm9rz "
Mar  4 22:14:34.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods update-demo-nautilus-fm5wx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4b852'
Mar  4 22:14:34.321: INFO: stderr: ""
Mar  4 22:14:34.321: INFO: stdout: ""
Mar  4 22:14:34.321: INFO: update-demo-nautilus-fm5wx is created but not running
Mar  4 22:14:39.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-4b852'
Mar  4 22:14:39.453: INFO: stderr: ""
Mar  4 22:14:39.453: INFO: stdout: "update-demo-nautilus-fm5wx update-demo-nautilus-lm9rz "
Mar  4 22:14:39.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods update-demo-nautilus-fm5wx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4b852'
Mar  4 22:14:39.577: INFO: stderr: ""
Mar  4 22:14:39.577: INFO: stdout: "true"
Mar  4 22:14:39.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods update-demo-nautilus-fm5wx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4b852'
Mar  4 22:14:39.703: INFO: stderr: ""
Mar  4 22:14:39.703: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  4 22:14:39.703: INFO: validating pod update-demo-nautilus-fm5wx
Mar  4 22:14:39.797: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  4 22:14:39.797: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  4 22:14:39.797: INFO: update-demo-nautilus-fm5wx is verified up and running
Mar  4 22:14:39.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods update-demo-nautilus-lm9rz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4b852'
Mar  4 22:14:39.935: INFO: stderr: ""
Mar  4 22:14:39.935: INFO: stdout: "true"
Mar  4 22:14:39.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods update-demo-nautilus-lm9rz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4b852'
Mar  4 22:14:40.063: INFO: stderr: ""
Mar  4 22:14:40.063: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  4 22:14:40.063: INFO: validating pod update-demo-nautilus-lm9rz
Mar  4 22:14:40.072: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  4 22:14:40.072: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  4 22:14:40.072: INFO: update-demo-nautilus-lm9rz is verified up and running
STEP: using delete to clean up resources
Mar  4 22:14:40.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-4b852'
Mar  4 22:14:40.253: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  4 22:14:40.253: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar  4 22:14:40.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-4b852'
Mar  4 22:14:40.445: INFO: stderr: "No resources found.\n"
Mar  4 22:14:40.445: INFO: stdout: ""
Mar  4 22:14:40.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods -l name=update-demo --namespace=e2e-tests-kubectl-4b852 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  4 22:14:40.611: INFO: stderr: ""
Mar  4 22:14:40.611: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:14:40.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4b852" for this suite.
Mar  4 22:15:04.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:15:04.967: INFO: namespace: e2e-tests-kubectl-4b852, resource: bindings, ignored listing per whitelist
Mar  4 22:15:05.100: INFO: namespace e2e-tests-kubectl-4b852 deletion completed in 24.478239451s

• [SLOW TEST:45.080 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:15:05.100: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-7xk22
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar  4 22:15:05.338: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:15:09.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-7xk22" for this suite.
Mar  4 22:15:31.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:15:31.981: INFO: namespace: e2e-tests-init-container-7xk22, resource: bindings, ignored listing per whitelist
Mar  4 22:15:32.109: INFO: namespace e2e-tests-init-container-7xk22 deletion completed in 22.38558472s

• [SLOW TEST:27.009 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:15:32.109: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-t4kss
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-06b7cb97-3ecb-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume configMaps
Mar  4 22:15:32.619: INFO: Waiting up to 5m0s for pod "pod-configmaps-06dee0b9-3ecb-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-configmap-t4kss" to be "success or failure"
Mar  4 22:15:32.626: INFO: Pod "pod-configmaps-06dee0b9-3ecb-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.414074ms
Mar  4 22:15:34.632: INFO: Pod "pod-configmaps-06dee0b9-3ecb-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01239851s
Mar  4 22:15:36.638: INFO: Pod "pod-configmaps-06dee0b9-3ecb-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018324909s
STEP: Saw pod success
Mar  4 22:15:36.638: INFO: Pod "pod-configmaps-06dee0b9-3ecb-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:15:36.643: INFO: Trying to get logs from node 10.190.208.160 pod pod-configmaps-06dee0b9-3ecb-11e9-b56c-8631b5a7dc0e container configmap-volume-test: <nil>
STEP: delete the pod
Mar  4 22:15:36.691: INFO: Waiting for pod pod-configmaps-06dee0b9-3ecb-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:15:36.783: INFO: Pod pod-configmaps-06dee0b9-3ecb-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:15:36.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-t4kss" for this suite.
Mar  4 22:15:42.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:15:43.173: INFO: namespace: e2e-tests-configmap-t4kss, resource: bindings, ignored listing per whitelist
Mar  4 22:15:43.181: INFO: namespace e2e-tests-configmap-t4kss deletion completed in 6.38864008s

• [SLOW TEST:11.072 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:15:43.182: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-4dbgp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar  4 22:15:51.492: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  4 22:15:51.497: INFO: Pod pod-with-prestop-http-hook still exists
Mar  4 22:15:53.497: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  4 22:15:53.503: INFO: Pod pod-with-prestop-http-hook still exists
Mar  4 22:15:55.497: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  4 22:15:55.503: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:15:55.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-4dbgp" for this suite.
Mar  4 22:16:19.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:16:19.710: INFO: namespace: e2e-tests-container-lifecycle-hook-4dbgp, resource: bindings, ignored listing per whitelist
Mar  4 22:16:19.954: INFO: namespace e2e-tests-container-lifecycle-hook-4dbgp deletion completed in 24.425546677s

• [SLOW TEST:36.773 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:16:19.955: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-lf7lq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  4 22:16:20.219: INFO: (0) /api/v1/nodes/10.190.208.160/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 16.283944ms)
Mar  4 22:16:20.282: INFO: (1) /api/v1/nodes/10.190.208.160/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 63.421707ms)
Mar  4 22:16:20.295: INFO: (2) /api/v1/nodes/10.190.208.160/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.047282ms)
Mar  4 22:16:20.308: INFO: (3) /api/v1/nodes/10.190.208.160/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.00305ms)
Mar  4 22:16:20.319: INFO: (4) /api/v1/nodes/10.190.208.160/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.497782ms)
Mar  4 22:16:20.331: INFO: (5) /api/v1/nodes/10.190.208.160/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.511958ms)
Mar  4 22:16:20.342: INFO: (6) /api/v1/nodes/10.190.208.160/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.089104ms)
Mar  4 22:16:20.353: INFO: (7) /api/v1/nodes/10.190.208.160/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.415287ms)
Mar  4 22:16:20.365: INFO: (8) /api/v1/nodes/10.190.208.160/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.597688ms)
Mar  4 22:16:20.376: INFO: (9) /api/v1/nodes/10.190.208.160/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.843468ms)
Mar  4 22:16:20.387: INFO: (10) /api/v1/nodes/10.190.208.160/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.232948ms)
Mar  4 22:16:20.398: INFO: (11) /api/v1/nodes/10.190.208.160/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.083888ms)
Mar  4 22:16:20.410: INFO: (12) /api/v1/nodes/10.190.208.160/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.29711ms)
Mar  4 22:16:20.421: INFO: (13) /api/v1/nodes/10.190.208.160/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.866968ms)
Mar  4 22:16:20.433: INFO: (14) /api/v1/nodes/10.190.208.160/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.777938ms)
Mar  4 22:16:20.638: INFO: (15) /api/v1/nodes/10.190.208.160/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 204.413526ms)
Mar  4 22:16:20.650: INFO: (16) /api/v1/nodes/10.190.208.160/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.309584ms)
Mar  4 22:16:20.662: INFO: (17) /api/v1/nodes/10.190.208.160/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.310228ms)
Mar  4 22:16:20.673: INFO: (18) /api/v1/nodes/10.190.208.160/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.239228ms)
Mar  4 22:16:20.684: INFO: (19) /api/v1/nodes/10.190.208.160/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.945463ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:16:20.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-lf7lq" for this suite.
Mar  4 22:16:26.724: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:16:26.982: INFO: namespace: e2e-tests-proxy-lf7lq, resource: bindings, ignored listing per whitelist
Mar  4 22:16:27.041: INFO: namespace e2e-tests-proxy-lf7lq deletion completed in 6.346869111s

• [SLOW TEST:7.086 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:16:27.042: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-h4xd6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar  4 22:16:27.287: INFO: Waiting up to 5m0s for pod "pod-2774e863-3ecb-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-emptydir-h4xd6" to be "success or failure"
Mar  4 22:16:27.291: INFO: Pod "pod-2774e863-3ecb-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.596484ms
Mar  4 22:16:29.298: INFO: Pod "pod-2774e863-3ecb-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01065746s
STEP: Saw pod success
Mar  4 22:16:29.298: INFO: Pod "pod-2774e863-3ecb-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:16:29.302: INFO: Trying to get logs from node 10.190.208.160 pod pod-2774e863-3ecb-11e9-b56c-8631b5a7dc0e container test-container: <nil>
STEP: delete the pod
Mar  4 22:16:29.383: INFO: Waiting for pod pod-2774e863-3ecb-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:16:29.388: INFO: Pod pod-2774e863-3ecb-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:16:29.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-h4xd6" for this suite.
Mar  4 22:16:35.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:16:35.567: INFO: namespace: e2e-tests-emptydir-h4xd6, resource: bindings, ignored listing per whitelist
Mar  4 22:16:35.689: INFO: namespace e2e-tests-emptydir-h4xd6 deletion completed in 6.291639299s

• [SLOW TEST:8.647 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:16:35.690: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-4lc92
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  4 22:16:35.981: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2ca37a00-3ecb-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-downward-api-4lc92" to be "success or failure"
Mar  4 22:16:35.985: INFO: Pod "downwardapi-volume-2ca37a00-3ecb-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.387724ms
Mar  4 22:16:37.990: INFO: Pod "downwardapi-volume-2ca37a00-3ecb-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009456609s
STEP: Saw pod success
Mar  4 22:16:37.990: INFO: Pod "downwardapi-volume-2ca37a00-3ecb-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:16:37.995: INFO: Trying to get logs from node 10.190.208.160 pod downwardapi-volume-2ca37a00-3ecb-11e9-b56c-8631b5a7dc0e container client-container: <nil>
STEP: delete the pod
Mar  4 22:16:38.027: INFO: Waiting for pod downwardapi-volume-2ca37a00-3ecb-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:16:38.032: INFO: Pod downwardapi-volume-2ca37a00-3ecb-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:16:38.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4lc92" for this suite.
Mar  4 22:16:44.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:16:44.179: INFO: namespace: e2e-tests-downward-api-4lc92, resource: bindings, ignored listing per whitelist
Mar  4 22:16:44.310: INFO: namespace e2e-tests-downward-api-4lc92 deletion completed in 6.268305485s

• [SLOW TEST:8.620 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:16:44.311: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-knwt2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-31bf3d47-3ecb-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume configMaps
Mar  4 22:16:44.599: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-31c673be-3ecb-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-projected-knwt2" to be "success or failure"
Mar  4 22:16:44.604: INFO: Pod "pod-projected-configmaps-31c673be-3ecb-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.504895ms
Mar  4 22:16:46.609: INFO: Pod "pod-projected-configmaps-31c673be-3ecb-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010310462s
STEP: Saw pod success
Mar  4 22:16:46.610: INFO: Pod "pod-projected-configmaps-31c673be-3ecb-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:16:46.615: INFO: Trying to get logs from node 10.190.208.160 pod pod-projected-configmaps-31c673be-3ecb-11e9-b56c-8631b5a7dc0e container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  4 22:16:46.683: INFO: Waiting for pod pod-projected-configmaps-31c673be-3ecb-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:16:46.688: INFO: Pod pod-projected-configmaps-31c673be-3ecb-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:16:46.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-knwt2" for this suite.
Mar  4 22:16:52.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:16:52.863: INFO: namespace: e2e-tests-projected-knwt2, resource: bindings, ignored listing per whitelist
Mar  4 22:16:53.118: INFO: namespace e2e-tests-projected-knwt2 deletion completed in 6.421585727s

• [SLOW TEST:8.808 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:16:53.121: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-6hq6h
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar  4 22:16:53.366: INFO: Waiting up to 5m0s for pod "downward-api-370030f6-3ecb-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-downward-api-6hq6h" to be "success or failure"
Mar  4 22:16:53.370: INFO: Pod "downward-api-370030f6-3ecb-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.423508ms
Mar  4 22:16:55.376: INFO: Pod "downward-api-370030f6-3ecb-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010399281s
STEP: Saw pod success
Mar  4 22:16:55.376: INFO: Pod "downward-api-370030f6-3ecb-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:16:55.382: INFO: Trying to get logs from node 10.190.208.160 pod downward-api-370030f6-3ecb-11e9-b56c-8631b5a7dc0e container dapi-container: <nil>
STEP: delete the pod
Mar  4 22:16:55.417: INFO: Waiting for pod downward-api-370030f6-3ecb-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:16:55.422: INFO: Pod downward-api-370030f6-3ecb-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:16:55.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6hq6h" for this suite.
Mar  4 22:17:01.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:17:01.579: INFO: namespace: e2e-tests-downward-api-6hq6h, resource: bindings, ignored listing per whitelist
Mar  4 22:17:01.712: INFO: namespace e2e-tests-downward-api-6hq6h deletion completed in 6.272614924s

• [SLOW TEST:8.591 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:17:01.713: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-lbjkr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-3c205659-3ecb-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume secrets
Mar  4 22:17:01.971: INFO: Waiting up to 5m0s for pod "pod-secrets-3c214a9d-3ecb-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-secrets-lbjkr" to be "success or failure"
Mar  4 22:17:01.975: INFO: Pod "pod-secrets-3c214a9d-3ecb-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.419829ms
Mar  4 22:17:03.981: INFO: Pod "pod-secrets-3c214a9d-3ecb-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010022413s
Mar  4 22:17:05.986: INFO: Pod "pod-secrets-3c214a9d-3ecb-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015623179s
STEP: Saw pod success
Mar  4 22:17:05.987: INFO: Pod "pod-secrets-3c214a9d-3ecb-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:17:05.991: INFO: Trying to get logs from node 10.190.208.160 pod pod-secrets-3c214a9d-3ecb-11e9-b56c-8631b5a7dc0e container secret-volume-test: <nil>
STEP: delete the pod
Mar  4 22:17:06.023: INFO: Waiting for pod pod-secrets-3c214a9d-3ecb-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:17:06.029: INFO: Pod pod-secrets-3c214a9d-3ecb-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:17:06.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-lbjkr" for this suite.
Mar  4 22:17:12.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:17:12.303: INFO: namespace: e2e-tests-secrets-lbjkr, resource: bindings, ignored listing per whitelist
Mar  4 22:17:12.403: INFO: namespace e2e-tests-secrets-lbjkr deletion completed in 6.320396471s

• [SLOW TEST:10.690 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:17:12.403: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-2fcdv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-42927407-3ecb-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume configMaps
Mar  4 22:17:12.785: INFO: Waiting up to 5m0s for pod "pod-configmaps-42937097-3ecb-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-configmap-2fcdv" to be "success or failure"
Mar  4 22:17:12.790: INFO: Pod "pod-configmaps-42937097-3ecb-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.493565ms
Mar  4 22:17:14.795: INFO: Pod "pod-configmaps-42937097-3ecb-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010259246s
STEP: Saw pod success
Mar  4 22:17:14.796: INFO: Pod "pod-configmaps-42937097-3ecb-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:17:14.801: INFO: Trying to get logs from node 10.190.208.160 pod pod-configmaps-42937097-3ecb-11e9-b56c-8631b5a7dc0e container configmap-volume-test: <nil>
STEP: delete the pod
Mar  4 22:17:14.897: INFO: Waiting for pod pod-configmaps-42937097-3ecb-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:17:14.903: INFO: Pod pod-configmaps-42937097-3ecb-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:17:14.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2fcdv" for this suite.
Mar  4 22:17:20.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:17:21.096: INFO: namespace: e2e-tests-configmap-2fcdv, resource: bindings, ignored listing per whitelist
Mar  4 22:17:21.570: INFO: namespace e2e-tests-configmap-2fcdv deletion completed in 6.648515515s

• [SLOW TEST:9.167 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:17:21.570: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-kcp9b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-6mpc
STEP: Creating a pod to test atomic-volume-subpath
Mar  4 22:17:22.204: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-6mpc" in namespace "e2e-tests-subpath-kcp9b" to be "success or failure"
Mar  4 22:17:22.209: INFO: Pod "pod-subpath-test-projected-6mpc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.9789ms
Mar  4 22:17:24.215: INFO: Pod "pod-subpath-test-projected-6mpc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010998132s
Mar  4 22:17:26.221: INFO: Pod "pod-subpath-test-projected-6mpc": Phase="Running", Reason="", readiness=false. Elapsed: 4.017152877s
Mar  4 22:17:28.227: INFO: Pod "pod-subpath-test-projected-6mpc": Phase="Running", Reason="", readiness=false. Elapsed: 6.023363896s
Mar  4 22:17:30.233: INFO: Pod "pod-subpath-test-projected-6mpc": Phase="Running", Reason="", readiness=false. Elapsed: 8.02902895s
Mar  4 22:17:32.240: INFO: Pod "pod-subpath-test-projected-6mpc": Phase="Running", Reason="", readiness=false. Elapsed: 10.036725996s
Mar  4 22:17:34.247: INFO: Pod "pod-subpath-test-projected-6mpc": Phase="Running", Reason="", readiness=false. Elapsed: 12.0434632s
Mar  4 22:17:36.253: INFO: Pod "pod-subpath-test-projected-6mpc": Phase="Running", Reason="", readiness=false. Elapsed: 14.049396059s
Mar  4 22:17:38.260: INFO: Pod "pod-subpath-test-projected-6mpc": Phase="Running", Reason="", readiness=false. Elapsed: 16.055828028s
Mar  4 22:17:40.265: INFO: Pod "pod-subpath-test-projected-6mpc": Phase="Running", Reason="", readiness=false. Elapsed: 18.061270939s
Mar  4 22:17:42.271: INFO: Pod "pod-subpath-test-projected-6mpc": Phase="Running", Reason="", readiness=false. Elapsed: 20.067285392s
Mar  4 22:17:44.277: INFO: Pod "pod-subpath-test-projected-6mpc": Phase="Running", Reason="", readiness=false. Elapsed: 22.072924471s
Mar  4 22:17:46.283: INFO: Pod "pod-subpath-test-projected-6mpc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.078770314s
STEP: Saw pod success
Mar  4 22:17:46.283: INFO: Pod "pod-subpath-test-projected-6mpc" satisfied condition "success or failure"
Mar  4 22:17:46.287: INFO: Trying to get logs from node 10.190.208.162 pod pod-subpath-test-projected-6mpc container test-container-subpath-projected-6mpc: <nil>
STEP: delete the pod
Mar  4 22:17:46.383: INFO: Waiting for pod pod-subpath-test-projected-6mpc to disappear
Mar  4 22:17:46.387: INFO: Pod pod-subpath-test-projected-6mpc no longer exists
STEP: Deleting pod pod-subpath-test-projected-6mpc
Mar  4 22:17:46.387: INFO: Deleting pod "pod-subpath-test-projected-6mpc" in namespace "e2e-tests-subpath-kcp9b"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:17:46.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-kcp9b" for this suite.
Mar  4 22:17:52.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:17:52.537: INFO: namespace: e2e-tests-subpath-kcp9b, resource: bindings, ignored listing per whitelist
Mar  4 22:17:52.720: INFO: namespace e2e-tests-subpath-kcp9b deletion completed in 6.317544973s

• [SLOW TEST:31.150 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:17:52.722: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-sczxb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-sczxb
Mar  4 22:17:55.002: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-sczxb
STEP: checking the pod's current state and verifying that restartCount is present
Mar  4 22:17:55.006: INFO: Initial restart count of pod liveness-exec is 0
Mar  4 22:18:43.152: INFO: Restart count of pod e2e-tests-container-probe-sczxb/liveness-exec is now 1 (48.14581605s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:18:43.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-sczxb" for this suite.
Mar  4 22:18:49.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:18:49.329: INFO: namespace: e2e-tests-container-probe-sczxb, resource: bindings, ignored listing per whitelist
Mar  4 22:18:49.511: INFO: namespace e2e-tests-container-probe-sczxb deletion completed in 6.330992362s

• [SLOW TEST:56.790 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:18:49.513: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-mkk99
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  4 22:18:49.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-mkk99'
Mar  4 22:18:49.914: INFO: stderr: ""
Mar  4 22:18:49.914: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Mar  4 22:18:54.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-mkk99 -o json'
Mar  4 22:18:55.132: INFO: stderr: ""
Mar  4 22:18:55.132: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-03-04T22:18:49Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-mkk99\",\n        \"resourceVersion\": \"8911\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-mkk99/pods/e2e-test-nginx-pod\",\n        \"uid\": \"7c771318-3ecb-11e9-967c-c655790ff683\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-fjpbt\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"10.190.208.160\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-fjpbt\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-fjpbt\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-04T22:18:49Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-04T22:18:51Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-04T22:18:51Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-04T22:18:49Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://80060a24277b2bee1a19016745609b80249e3a29cea2a7980e82d42cd4803a6f\",\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imageID\": \"docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-03-04T22:18:50Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.190.208.160\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.87.161\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-03-04T22:18:49Z\"\n    }\n}\n"
STEP: replace the image in the pod
Mar  4 22:18:55.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 replace -f - --namespace=e2e-tests-kubectl-mkk99'
Mar  4 22:18:55.425: INFO: stderr: ""
Mar  4 22:18:55.425: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Mar  4 22:18:55.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-mkk99'
Mar  4 22:19:03.944: INFO: stderr: ""
Mar  4 22:19:03.944: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:19:03.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mkk99" for this suite.
Mar  4 22:19:10.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:19:10.136: INFO: namespace: e2e-tests-kubectl-mkk99, resource: bindings, ignored listing per whitelist
Mar  4 22:19:10.314: INFO: namespace e2e-tests-kubectl-mkk99 deletion completed in 6.331380865s

• [SLOW TEST:20.802 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:19:10.315: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-2ml75
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-2ml75 A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-2ml75;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-2ml75 A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-2ml75;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-2ml75.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-2ml75.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-2ml75.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-2ml75.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-2ml75.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-2ml75.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-2ml75.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-2ml75.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-2ml75.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-2ml75.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-2ml75.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-2ml75.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-2ml75.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 127.210.21.172.in-addr.arpa. PTR)" && echo OK > /results/172.21.210.127_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 127.210.21.172.in-addr.arpa. PTR)" && echo OK > /results/172.21.210.127_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-2ml75 A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-2ml75;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-2ml75 A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-2ml75;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-2ml75.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-2ml75.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-2ml75.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-2ml75.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-2ml75.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-2ml75.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-2ml75.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-2ml75.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-2ml75.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-2ml75.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-2ml75.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-2ml75.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-2ml75.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 127.210.21.172.in-addr.arpa. PTR)" && echo OK > /results/172.21.210.127_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 127.210.21.172.in-addr.arpa. PTR)" && echo OK > /results/172.21.210.127_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  4 22:19:32.911: INFO: DNS probes using e2e-tests-dns-2ml75/dns-test-88cb9817-3ecb-11e9-b56c-8631b5a7dc0e succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:19:33.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-2ml75" for this suite.
Mar  4 22:19:39.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:19:39.267: INFO: namespace: e2e-tests-dns-2ml75, resource: bindings, ignored listing per whitelist
Mar  4 22:19:39.304: INFO: namespace e2e-tests-dns-2ml75 deletion completed in 6.278029578s

• [SLOW TEST:28.989 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:19:39.304: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-t96nt
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Mar  4 22:19:39.850: INFO: Waiting up to 5m0s for pod "pod-9a3bb67c-3ecb-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-emptydir-t96nt" to be "success or failure"
Mar  4 22:19:39.883: INFO: Pod "pod-9a3bb67c-3ecb-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 32.787189ms
Mar  4 22:19:41.888: INFO: Pod "pod-9a3bb67c-3ecb-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.037847639s
STEP: Saw pod success
Mar  4 22:19:41.888: INFO: Pod "pod-9a3bb67c-3ecb-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:19:41.893: INFO: Trying to get logs from node 10.190.208.160 pod pod-9a3bb67c-3ecb-11e9-b56c-8631b5a7dc0e container test-container: <nil>
STEP: delete the pod
Mar  4 22:19:41.982: INFO: Waiting for pod pod-9a3bb67c-3ecb-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:19:41.988: INFO: Pod pod-9a3bb67c-3ecb-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:19:41.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-t96nt" for this suite.
Mar  4 22:19:48.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:19:48.308: INFO: namespace: e2e-tests-emptydir-t96nt, resource: bindings, ignored listing per whitelist
Mar  4 22:19:48.315: INFO: namespace e2e-tests-emptydir-t96nt deletion completed in 6.316524241s

• [SLOW TEST:9.011 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:19:48.315: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-rn6kb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  4 22:19:48.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-rn6kb'
Mar  4 22:19:48.691: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar  4 22:19:48.691: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Mar  4 22:19:52.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-rn6kb'
Mar  4 22:19:52.862: INFO: stderr: ""
Mar  4 22:19:52.862: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:19:52.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rn6kb" for this suite.
Mar  4 22:19:58.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:19:59.144: INFO: namespace: e2e-tests-kubectl-rn6kb, resource: bindings, ignored listing per whitelist
Mar  4 22:19:59.256: INFO: namespace e2e-tests-kubectl-rn6kb deletion completed in 6.382064461s

• [SLOW TEST:10.941 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:19:59.257: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-z6hkm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-a5f20c42-3ecb-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume configMaps
Mar  4 22:19:59.506: INFO: Waiting up to 5m0s for pod "pod-configmaps-a5f2fb69-3ecb-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-configmap-z6hkm" to be "success or failure"
Mar  4 22:19:59.510: INFO: Pod "pod-configmaps-a5f2fb69-3ecb-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.304209ms
Mar  4 22:20:01.517: INFO: Pod "pod-configmaps-a5f2fb69-3ecb-11e9-b56c-8631b5a7dc0e": Phase="Running", Reason="", readiness=true. Elapsed: 2.010435016s
Mar  4 22:20:03.523: INFO: Pod "pod-configmaps-a5f2fb69-3ecb-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016447234s
STEP: Saw pod success
Mar  4 22:20:03.523: INFO: Pod "pod-configmaps-a5f2fb69-3ecb-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:20:03.528: INFO: Trying to get logs from node 10.190.208.160 pod pod-configmaps-a5f2fb69-3ecb-11e9-b56c-8631b5a7dc0e container configmap-volume-test: <nil>
STEP: delete the pod
Mar  4 22:20:03.560: INFO: Waiting for pod pod-configmaps-a5f2fb69-3ecb-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:20:03.566: INFO: Pod pod-configmaps-a5f2fb69-3ecb-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:20:03.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-z6hkm" for this suite.
Mar  4 22:20:09.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:20:09.902: INFO: namespace: e2e-tests-configmap-z6hkm, resource: bindings, ignored listing per whitelist
Mar  4 22:20:09.914: INFO: namespace e2e-tests-configmap-z6hkm deletion completed in 6.330685193s

• [SLOW TEST:10.657 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:20:09.915: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-6x2wt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  4 22:20:10.186: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ac50ad58-3ecb-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-downward-api-6x2wt" to be "success or failure"
Mar  4 22:20:10.191: INFO: Pod "downwardapi-volume-ac50ad58-3ecb-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.824968ms
Mar  4 22:20:12.198: INFO: Pod "downwardapi-volume-ac50ad58-3ecb-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011007133s
STEP: Saw pod success
Mar  4 22:20:12.198: INFO: Pod "downwardapi-volume-ac50ad58-3ecb-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:20:12.202: INFO: Trying to get logs from node 10.190.208.160 pod downwardapi-volume-ac50ad58-3ecb-11e9-b56c-8631b5a7dc0e container client-container: <nil>
STEP: delete the pod
Mar  4 22:20:12.282: INFO: Waiting for pod downwardapi-volume-ac50ad58-3ecb-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:20:12.287: INFO: Pod downwardapi-volume-ac50ad58-3ecb-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:20:12.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6x2wt" for this suite.
Mar  4 22:20:18.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:20:18.552: INFO: namespace: e2e-tests-downward-api-6x2wt, resource: bindings, ignored listing per whitelist
Mar  4 22:20:18.604: INFO: namespace e2e-tests-downward-api-6x2wt deletion completed in 6.308347463s

• [SLOW TEST:8.689 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:20:18.604: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-5mq4z
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  4 22:20:18.882: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:20:19.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-5mq4z" for this suite.
Mar  4 22:20:26.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:20:26.104: INFO: namespace: e2e-tests-custom-resource-definition-5mq4z, resource: bindings, ignored listing per whitelist
Mar  4 22:20:26.684: INFO: namespace e2e-tests-custom-resource-definition-5mq4z deletion completed in 6.685827198s

• [SLOW TEST:8.080 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:20:26.685: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-zdb8r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  4 22:20:26.945: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b64ddbe1-3ecb-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-projected-zdb8r" to be "success or failure"
Mar  4 22:20:26.949: INFO: Pod "downwardapi-volume-b64ddbe1-3ecb-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.363153ms
Mar  4 22:20:28.956: INFO: Pod "downwardapi-volume-b64ddbe1-3ecb-11e9-b56c-8631b5a7dc0e": Phase="Running", Reason="", readiness=true. Elapsed: 2.011346446s
Mar  4 22:20:30.963: INFO: Pod "downwardapi-volume-b64ddbe1-3ecb-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01825772s
STEP: Saw pod success
Mar  4 22:20:30.963: INFO: Pod "downwardapi-volume-b64ddbe1-3ecb-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:20:30.971: INFO: Trying to get logs from node 10.190.208.162 pod downwardapi-volume-b64ddbe1-3ecb-11e9-b56c-8631b5a7dc0e container client-container: <nil>
STEP: delete the pod
Mar  4 22:20:31.012: INFO: Waiting for pod downwardapi-volume-b64ddbe1-3ecb-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:20:31.017: INFO: Pod downwardapi-volume-b64ddbe1-3ecb-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:20:31.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zdb8r" for this suite.
Mar  4 22:20:37.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:20:37.110: INFO: namespace: e2e-tests-projected-zdb8r, resource: bindings, ignored listing per whitelist
Mar  4 22:20:37.380: INFO: namespace e2e-tests-projected-zdb8r deletion completed in 6.351423452s

• [SLOW TEST:10.695 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:20:37.382: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-vfc7w
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-bcb481da-3ecb-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume configMaps
Mar  4 22:20:37.691: INFO: Waiting up to 5m0s for pod "pod-configmaps-bcb584e3-3ecb-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-configmap-vfc7w" to be "success or failure"
Mar  4 22:20:37.696: INFO: Pod "pod-configmaps-bcb584e3-3ecb-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.427679ms
Mar  4 22:20:39.702: INFO: Pod "pod-configmaps-bcb584e3-3ecb-11e9-b56c-8631b5a7dc0e": Phase="Running", Reason="", readiness=true. Elapsed: 2.010179156s
Mar  4 22:20:41.708: INFO: Pod "pod-configmaps-bcb584e3-3ecb-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016406472s
STEP: Saw pod success
Mar  4 22:20:41.708: INFO: Pod "pod-configmaps-bcb584e3-3ecb-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:20:41.713: INFO: Trying to get logs from node 10.190.208.160 pod pod-configmaps-bcb584e3-3ecb-11e9-b56c-8631b5a7dc0e container configmap-volume-test: <nil>
STEP: delete the pod
Mar  4 22:20:41.783: INFO: Waiting for pod pod-configmaps-bcb584e3-3ecb-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:20:41.788: INFO: Pod pod-configmaps-bcb584e3-3ecb-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:20:41.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vfc7w" for this suite.
Mar  4 22:20:49.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:20:49.963: INFO: namespace: e2e-tests-configmap-vfc7w, resource: bindings, ignored listing per whitelist
Mar  4 22:20:50.097: INFO: namespace e2e-tests-configmap-vfc7w deletion completed in 8.299332828s

• [SLOW TEST:12.715 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:20:50.099: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-j9lqp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  4 22:20:50.346: INFO: Pod name rollover-pod: Found 0 pods out of 1
Mar  4 22:20:55.353: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar  4 22:20:55.353: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Mar  4 22:20:57.359: INFO: Creating deployment "test-rollover-deployment"
Mar  4 22:20:57.390: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Mar  4 22:20:59.409: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Mar  4 22:20:59.423: INFO: Ensure that both replica sets have 1 created replica
Mar  4 22:20:59.433: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Mar  4 22:20:59.492: INFO: Updating deployment test-rollover-deployment
Mar  4 22:20:59.493: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Mar  4 22:21:01.510: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Mar  4 22:21:01.524: INFO: Make sure deployment "test-rollover-deployment" is complete
Mar  4 22:21:01.537: INFO: all replica sets need to contain the pod-template-hash label
Mar  4 22:21:01.537: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687334857, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687334857, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687334859, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687334857, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  4 22:21:03.552: INFO: all replica sets need to contain the pod-template-hash label
Mar  4 22:21:03.552: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687334857, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687334857, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687334863, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687334857, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  4 22:21:05.554: INFO: all replica sets need to contain the pod-template-hash label
Mar  4 22:21:05.554: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687334857, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687334857, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687334863, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687334857, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  4 22:21:07.551: INFO: all replica sets need to contain the pod-template-hash label
Mar  4 22:21:07.551: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687334857, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687334857, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687334863, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687334857, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  4 22:21:09.555: INFO: all replica sets need to contain the pod-template-hash label
Mar  4 22:21:09.555: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687334857, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687334857, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687334863, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687334857, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  4 22:21:11.551: INFO: all replica sets need to contain the pod-template-hash label
Mar  4 22:21:11.552: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687334857, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687334857, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687334863, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687334857, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  4 22:21:13.551: INFO: 
Mar  4 22:21:13.551: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar  4 22:21:13.568: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-j9lqp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-j9lqp/deployments/test-rollover-deployment,UID:c8702aeb-3ecb-11e9-967c-c655790ff683,ResourceVersion:9626,Generation:2,CreationTimestamp:2019-03-04 22:20:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-04 22:20:57 +0000 UTC 2019-03-04 22:20:57 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-04 22:21:13 +0000 UTC 2019-03-04 22:20:57 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar  4 22:21:13.574: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-j9lqp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-j9lqp/replicasets/test-rollover-deployment-5b76ff8c4,UID:c9b59ca2-3ecb-11e9-967c-c655790ff683,ResourceVersion:9617,Generation:2,CreationTimestamp:2019-03-04 22:20:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment c8702aeb-3ecb-11e9-967c-c655790ff683 0xc42240edb7 0xc42240edb8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar  4 22:21:13.574: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Mar  4 22:21:13.574: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-j9lqp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-j9lqp/replicasets/test-rollover-controller,UID:c4406671-3ecb-11e9-967c-c655790ff683,ResourceVersion:9625,Generation:2,CreationTimestamp:2019-03-04 22:20:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment c8702aeb-3ecb-11e9-967c-c655790ff683 0xc42240ed07 0xc42240ed08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  4 22:21:13.574: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-j9lqp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-j9lqp/replicasets/test-rollover-deployment-6975f4fb87,UID:c8778ce8-3ecb-11e9-967c-c655790ff683,ResourceVersion:9574,Generation:2,CreationTimestamp:2019-03-04 22:20:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment c8702aeb-3ecb-11e9-967c-c655790ff683 0xc42240ee67 0xc42240ee68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  4 22:21:13.587: INFO: Pod "test-rollover-deployment-5b76ff8c4-6scqm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-6scqm,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-j9lqp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j9lqp/pods/test-rollover-deployment-5b76ff8c4-6scqm,UID:c9bafe5d-3ecb-11e9-967c-c655790ff683,ResourceVersion:9598,Generation:0,CreationTimestamp:2019-03-04 22:20:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 c9b59ca2-3ecb-11e9-967c-c655790ff683 0xc42240f940 0xc42240f941}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vtq4l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vtq4l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-vtq4l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42240f9b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42240f9d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:20:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:21:03 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:21:03 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:20:59 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.162,PodIP:172.30.86.141,StartTime:2019-03-04 22:20:59 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-04 22:21:02 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://d00145013498a089cdec37ec72b057b5d09add872dd666ea792d6993f0f13c77}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:21:13.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-j9lqp" for this suite.
Mar  4 22:21:19.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:21:19.886: INFO: namespace: e2e-tests-deployment-j9lqp, resource: bindings, ignored listing per whitelist
Mar  4 22:21:20.006: INFO: namespace e2e-tests-deployment-j9lqp deletion completed in 6.408077668s

• [SLOW TEST:29.908 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:21:20.006: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-gqgbt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  4 22:21:20.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-gqgbt'
Mar  4 22:21:20.437: INFO: stderr: ""
Mar  4 22:21:20.437: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Mar  4 22:21:20.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-gqgbt'
Mar  4 22:21:23.943: INFO: stderr: ""
Mar  4 22:21:23.943: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:21:23.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gqgbt" for this suite.
Mar  4 22:21:29.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:21:30.106: INFO: namespace: e2e-tests-kubectl-gqgbt, resource: bindings, ignored listing per whitelist
Mar  4 22:21:30.312: INFO: namespace e2e-tests-kubectl-gqgbt deletion completed in 6.355703024s

• [SLOW TEST:10.305 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:21:30.312: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-25kll
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar  4 22:21:34.629: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  4 22:21:34.634: INFO: Pod pod-with-poststart-http-hook still exists
Mar  4 22:21:36.635: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  4 22:21:36.641: INFO: Pod pod-with-poststart-http-hook still exists
Mar  4 22:21:38.635: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  4 22:21:38.642: INFO: Pod pod-with-poststart-http-hook still exists
Mar  4 22:21:40.634: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  4 22:21:40.640: INFO: Pod pod-with-poststart-http-hook still exists
Mar  4 22:21:42.635: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  4 22:21:42.641: INFO: Pod pod-with-poststart-http-hook still exists
Mar  4 22:21:44.634: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  4 22:21:44.640: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:21:44.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-25kll" for this suite.
Mar  4 22:22:08.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:22:08.912: INFO: namespace: e2e-tests-container-lifecycle-hook-25kll, resource: bindings, ignored listing per whitelist
Mar  4 22:22:09.041: INFO: namespace e2e-tests-container-lifecycle-hook-25kll deletion completed in 24.358815169s

• [SLOW TEST:38.729 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:22:09.042: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-r8l8d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-zxks
STEP: Creating a pod to test atomic-volume-subpath
Mar  4 22:22:09.298: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-zxks" in namespace "e2e-tests-subpath-r8l8d" to be "success or failure"
Mar  4 22:22:09.303: INFO: Pod "pod-subpath-test-secret-zxks": Phase="Pending", Reason="", readiness=false. Elapsed: 4.594214ms
Mar  4 22:22:11.309: INFO: Pod "pod-subpath-test-secret-zxks": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010509798s
Mar  4 22:22:13.314: INFO: Pod "pod-subpath-test-secret-zxks": Phase="Running", Reason="", readiness=false. Elapsed: 4.016352639s
Mar  4 22:22:15.320: INFO: Pod "pod-subpath-test-secret-zxks": Phase="Running", Reason="", readiness=false. Elapsed: 6.022143084s
Mar  4 22:22:17.416: INFO: Pod "pod-subpath-test-secret-zxks": Phase="Running", Reason="", readiness=false. Elapsed: 8.118002105s
Mar  4 22:22:19.422: INFO: Pod "pod-subpath-test-secret-zxks": Phase="Running", Reason="", readiness=false. Elapsed: 10.12408966s
Mar  4 22:22:21.428: INFO: Pod "pod-subpath-test-secret-zxks": Phase="Running", Reason="", readiness=false. Elapsed: 12.129810526s
Mar  4 22:22:23.434: INFO: Pod "pod-subpath-test-secret-zxks": Phase="Running", Reason="", readiness=false. Elapsed: 14.13557376s
Mar  4 22:22:25.440: INFO: Pod "pod-subpath-test-secret-zxks": Phase="Running", Reason="", readiness=false. Elapsed: 16.141731508s
Mar  4 22:22:27.446: INFO: Pod "pod-subpath-test-secret-zxks": Phase="Running", Reason="", readiness=false. Elapsed: 18.147544878s
Mar  4 22:22:29.452: INFO: Pod "pod-subpath-test-secret-zxks": Phase="Running", Reason="", readiness=false. Elapsed: 20.153699156s
Mar  4 22:22:31.457: INFO: Pod "pod-subpath-test-secret-zxks": Phase="Running", Reason="", readiness=false. Elapsed: 22.159009164s
Mar  4 22:22:33.463: INFO: Pod "pod-subpath-test-secret-zxks": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.16517408s
STEP: Saw pod success
Mar  4 22:22:33.463: INFO: Pod "pod-subpath-test-secret-zxks" satisfied condition "success or failure"
Mar  4 22:22:33.468: INFO: Trying to get logs from node 10.190.208.162 pod pod-subpath-test-secret-zxks container test-container-subpath-secret-zxks: <nil>
STEP: delete the pod
Mar  4 22:22:33.500: INFO: Waiting for pod pod-subpath-test-secret-zxks to disappear
Mar  4 22:22:33.588: INFO: Pod pod-subpath-test-secret-zxks no longer exists
STEP: Deleting pod pod-subpath-test-secret-zxks
Mar  4 22:22:33.588: INFO: Deleting pod "pod-subpath-test-secret-zxks" in namespace "e2e-tests-subpath-r8l8d"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:22:33.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-r8l8d" for this suite.
Mar  4 22:22:39.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:22:39.849: INFO: namespace: e2e-tests-subpath-r8l8d, resource: bindings, ignored listing per whitelist
Mar  4 22:22:40.032: INFO: namespace e2e-tests-subpath-r8l8d deletion completed in 6.429359831s

• [SLOW TEST:30.990 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:22:40.034: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-ldv7f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Mar  4 22:22:40.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 api-versions'
Mar  4 22:22:40.406: INFO: stderr: ""
Mar  4 22:22:40.406: INFO: stdout: "admissionregistration.k8s.io/v1alpha1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:22:40.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ldv7f" for this suite.
Mar  4 22:22:46.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:22:46.503: INFO: namespace: e2e-tests-kubectl-ldv7f, resource: bindings, ignored listing per whitelist
Mar  4 22:22:46.925: INFO: namespace e2e-tests-kubectl-ldv7f deletion completed in 6.509017489s

• [SLOW TEST:6.891 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:22:46.925: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-qhrg4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar  4 22:22:47.151: INFO: PodSpec: initContainers in spec.initContainers
Mar  4 22:23:31.584: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-09e13951-3ecc-11e9-b56c-8631b5a7dc0e", GenerateName:"", Namespace:"e2e-tests-init-container-qhrg4", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-qhrg4/pods/pod-init-09e13951-3ecc-11e9-b56c-8631b5a7dc0e", UID:"09e1dbfc-3ecc-11e9-967c-c655790ff683", ResourceVersion:"10093", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63687334967, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"151658291"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-ctnxb", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc421358a40), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-ctnxb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-ctnxb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-ctnxb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc42176cec8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.190.208.178", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc420eaa9c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc42176cf50)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc42176cf70)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc42176cf78), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687334967, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687334967, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687334967, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687334967, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.190.208.178", PodIP:"172.30.252.203", StartTime:(*v1.Time)(0xc421041ca0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc4210f1dc0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc4210f1ea0)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://c49b2ebb0e121d95041625d9987f5ad17b857a75d48bd1e2dc2c375e72fa3767"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc421041ce0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc421041cc0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:23:31.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-qhrg4" for this suite.
Mar  4 22:23:53.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:23:53.902: INFO: namespace: e2e-tests-init-container-qhrg4, resource: bindings, ignored listing per whitelist
Mar  4 22:23:54.010: INFO: namespace e2e-tests-init-container-qhrg4 deletion completed in 22.408960396s

• [SLOW TEST:67.085 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:23:54.013: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-wpsq6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-31dfc29d-3ecc-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume configMaps
Mar  4 22:23:54.268: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-31e0c18e-3ecc-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-projected-wpsq6" to be "success or failure"
Mar  4 22:23:54.272: INFO: Pod "pod-projected-configmaps-31e0c18e-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.673033ms
Mar  4 22:23:56.278: INFO: Pod "pod-projected-configmaps-31e0c18e-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010072634s
STEP: Saw pod success
Mar  4 22:23:56.278: INFO: Pod "pod-projected-configmaps-31e0c18e-3ecc-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:23:56.282: INFO: Trying to get logs from node 10.190.208.160 pod pod-projected-configmaps-31e0c18e-3ecc-11e9-b56c-8631b5a7dc0e container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  4 22:23:56.322: INFO: Waiting for pod pod-projected-configmaps-31e0c18e-3ecc-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:23:56.326: INFO: Pod pod-projected-configmaps-31e0c18e-3ecc-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:23:56.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wpsq6" for this suite.
Mar  4 22:24:02.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:24:02.390: INFO: namespace: e2e-tests-projected-wpsq6, resource: bindings, ignored listing per whitelist
Mar  4 22:24:02.901: INFO: namespace e2e-tests-projected-wpsq6 deletion completed in 6.565476641s

• [SLOW TEST:8.888 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:24:02.901: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-94hjb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar  4 22:24:05.811: INFO: Successfully updated pod "pod-update-activedeadlineseconds-3735b2e6-3ecc-11e9-b56c-8631b5a7dc0e"
Mar  4 22:24:05.811: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-3735b2e6-3ecc-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-pods-94hjb" to be "terminated due to deadline exceeded"
Mar  4 22:24:05.816: INFO: Pod "pod-update-activedeadlineseconds-3735b2e6-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Running", Reason="", readiness=true. Elapsed: 4.326178ms
Mar  4 22:24:07.821: INFO: Pod "pod-update-activedeadlineseconds-3735b2e6-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Running", Reason="", readiness=true. Elapsed: 2.009926966s
Mar  4 22:24:09.827: INFO: Pod "pod-update-activedeadlineseconds-3735b2e6-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.015456105s
Mar  4 22:24:09.827: INFO: Pod "pod-update-activedeadlineseconds-3735b2e6-3ecc-11e9-b56c-8631b5a7dc0e" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:24:09.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-94hjb" for this suite.
Mar  4 22:24:15.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:24:16.146: INFO: namespace: e2e-tests-pods-94hjb, resource: bindings, ignored listing per whitelist
Mar  4 22:24:16.182: INFO: namespace e2e-tests-pods-94hjb deletion completed in 6.343450003s

• [SLOW TEST:13.281 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:24:16.182: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-qsczx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-qsczx/configmap-test-3f170ff7-3ecc-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume configMaps
Mar  4 22:24:16.440: INFO: Waiting up to 5m0s for pod "pod-configmaps-3f17f7a9-3ecc-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-configmap-qsczx" to be "success or failure"
Mar  4 22:24:16.444: INFO: Pod "pod-configmaps-3f17f7a9-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.330862ms
Mar  4 22:24:18.450: INFO: Pod "pod-configmaps-3f17f7a9-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010237954s
STEP: Saw pod success
Mar  4 22:24:18.450: INFO: Pod "pod-configmaps-3f17f7a9-3ecc-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:24:18.455: INFO: Trying to get logs from node 10.190.208.160 pod pod-configmaps-3f17f7a9-3ecc-11e9-b56c-8631b5a7dc0e container env-test: <nil>
STEP: delete the pod
Mar  4 22:24:18.487: INFO: Waiting for pod pod-configmaps-3f17f7a9-3ecc-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:24:18.491: INFO: Pod pod-configmaps-3f17f7a9-3ecc-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:24:18.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-qsczx" for this suite.
Mar  4 22:24:24.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:24:24.758: INFO: namespace: e2e-tests-configmap-qsczx, resource: bindings, ignored listing per whitelist
Mar  4 22:24:24.801: INFO: namespace e2e-tests-configmap-qsczx deletion completed in 6.299633514s

• [SLOW TEST:8.619 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:24:24.802: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-kzwnz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  4 22:24:25.086: INFO: Waiting up to 5m0s for pod "downwardapi-volume-443e8284-3ecc-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-projected-kzwnz" to be "success or failure"
Mar  4 22:24:25.091: INFO: Pod "downwardapi-volume-443e8284-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.937304ms
Mar  4 22:24:27.096: INFO: Pod "downwardapi-volume-443e8284-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010495026s
STEP: Saw pod success
Mar  4 22:24:27.096: INFO: Pod "downwardapi-volume-443e8284-3ecc-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:24:27.101: INFO: Trying to get logs from node 10.190.208.160 pod downwardapi-volume-443e8284-3ecc-11e9-b56c-8631b5a7dc0e container client-container: <nil>
STEP: delete the pod
Mar  4 22:24:27.201: INFO: Waiting for pod downwardapi-volume-443e8284-3ecc-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:24:27.282: INFO: Pod downwardapi-volume-443e8284-3ecc-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:24:27.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kzwnz" for this suite.
Mar  4 22:24:33.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:24:33.485: INFO: namespace: e2e-tests-projected-kzwnz, resource: bindings, ignored listing per whitelist
Mar  4 22:24:34.268: INFO: namespace e2e-tests-projected-kzwnz deletion completed in 6.975054676s

• [SLOW TEST:9.466 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:24:34.268: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-9tdsl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar  4 22:24:34.514: INFO: Waiting up to 5m0s for pod "downward-api-49dde9fe-3ecc-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-downward-api-9tdsl" to be "success or failure"
Mar  4 22:24:34.519: INFO: Pod "downward-api-49dde9fe-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.605634ms
Mar  4 22:24:36.525: INFO: Pod "downward-api-49dde9fe-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Running", Reason="", readiness=true. Elapsed: 2.010698493s
Mar  4 22:24:38.531: INFO: Pod "downward-api-49dde9fe-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016245978s
STEP: Saw pod success
Mar  4 22:24:38.531: INFO: Pod "downward-api-49dde9fe-3ecc-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:24:38.535: INFO: Trying to get logs from node 10.190.208.162 pod downward-api-49dde9fe-3ecc-11e9-b56c-8631b5a7dc0e container dapi-container: <nil>
STEP: delete the pod
Mar  4 22:24:38.604: INFO: Waiting for pod downward-api-49dde9fe-3ecc-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:24:38.609: INFO: Pod downward-api-49dde9fe-3ecc-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:24:38.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9tdsl" for this suite.
Mar  4 22:24:46.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:24:46.819: INFO: namespace: e2e-tests-downward-api-9tdsl, resource: bindings, ignored listing per whitelist
Mar  4 22:24:46.924: INFO: namespace e2e-tests-downward-api-9tdsl deletion completed in 8.301830029s

• [SLOW TEST:12.656 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:24:46.924: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-x5x6r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-516b8aef-3ecc-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume configMaps
Mar  4 22:24:47.193: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-516c8bae-3ecc-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-projected-x5x6r" to be "success or failure"
Mar  4 22:24:47.198: INFO: Pod "pod-projected-configmaps-516c8bae-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.828408ms
Mar  4 22:24:49.204: INFO: Pod "pod-projected-configmaps-516c8bae-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010606569s
STEP: Saw pod success
Mar  4 22:24:49.204: INFO: Pod "pod-projected-configmaps-516c8bae-3ecc-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:24:49.209: INFO: Trying to get logs from node 10.190.208.160 pod pod-projected-configmaps-516c8bae-3ecc-11e9-b56c-8631b5a7dc0e container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  4 22:24:49.242: INFO: Waiting for pod pod-projected-configmaps-516c8bae-3ecc-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:24:49.282: INFO: Pod pod-projected-configmaps-516c8bae-3ecc-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:24:49.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-x5x6r" for this suite.
Mar  4 22:24:55.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:24:55.403: INFO: namespace: e2e-tests-projected-x5x6r, resource: bindings, ignored listing per whitelist
Mar  4 22:24:55.644: INFO: namespace e2e-tests-projected-x5x6r deletion completed in 6.349516015s

• [SLOW TEST:8.720 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:24:55.645: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-9ztrz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Mar  4 22:24:55.982: INFO: Waiting up to 5m0s for pod "var-expansion-56a972d4-3ecc-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-var-expansion-9ztrz" to be "success or failure"
Mar  4 22:24:55.986: INFO: Pod "var-expansion-56a972d4-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.660257ms
Mar  4 22:24:57.992: INFO: Pod "var-expansion-56a972d4-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010210545s
STEP: Saw pod success
Mar  4 22:24:57.992: INFO: Pod "var-expansion-56a972d4-3ecc-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:24:57.997: INFO: Trying to get logs from node 10.190.208.160 pod var-expansion-56a972d4-3ecc-11e9-b56c-8631b5a7dc0e container dapi-container: <nil>
STEP: delete the pod
Mar  4 22:24:58.029: INFO: Waiting for pod var-expansion-56a972d4-3ecc-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:24:58.082: INFO: Pod var-expansion-56a972d4-3ecc-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:24:58.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-9ztrz" for this suite.
Mar  4 22:25:04.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:25:04.194: INFO: namespace: e2e-tests-var-expansion-9ztrz, resource: bindings, ignored listing per whitelist
Mar  4 22:25:04.490: INFO: namespace e2e-tests-var-expansion-9ztrz deletion completed in 6.397223852s

• [SLOW TEST:8.846 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:25:04.491: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-5fd9w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Mar  4 22:25:04.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 --namespace=e2e-tests-kubectl-5fd9w run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Mar  4 22:25:06.630: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Mar  4 22:25:06.630: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:25:08.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5fd9w" for this suite.
Mar  4 22:25:14.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:25:14.994: INFO: namespace: e2e-tests-kubectl-5fd9w, resource: bindings, ignored listing per whitelist
Mar  4 22:25:15.096: INFO: namespace e2e-tests-kubectl-5fd9w deletion completed in 6.431338903s

• [SLOW TEST:10.605 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:25:15.097: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-5gbb6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  4 22:25:15.487: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6249bd69-3ecc-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-projected-5gbb6" to be "success or failure"
Mar  4 22:25:15.491: INFO: Pod "downwardapi-volume-6249bd69-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.32854ms
Mar  4 22:25:17.496: INFO: Pod "downwardapi-volume-6249bd69-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Running", Reason="", readiness=true. Elapsed: 2.009697469s
Mar  4 22:25:19.502: INFO: Pod "downwardapi-volume-6249bd69-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015559494s
STEP: Saw pod success
Mar  4 22:25:19.502: INFO: Pod "downwardapi-volume-6249bd69-3ecc-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:25:19.507: INFO: Trying to get logs from node 10.190.208.160 pod downwardapi-volume-6249bd69-3ecc-11e9-b56c-8631b5a7dc0e container client-container: <nil>
STEP: delete the pod
Mar  4 22:25:19.538: INFO: Waiting for pod downwardapi-volume-6249bd69-3ecc-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:25:19.545: INFO: Pod downwardapi-volume-6249bd69-3ecc-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:25:19.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5gbb6" for this suite.
Mar  4 22:25:25.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:25:26.006: INFO: namespace: e2e-tests-projected-5gbb6, resource: bindings, ignored listing per whitelist
Mar  4 22:25:26.119: INFO: namespace e2e-tests-projected-5gbb6 deletion completed in 6.563379032s

• [SLOW TEST:11.022 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:25:26.121: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-ltxxk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-68ca3b9b-3ecc-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume configMaps
Mar  4 22:25:26.501: INFO: Waiting up to 5m0s for pod "pod-configmaps-68d94608-3ecc-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-configmap-ltxxk" to be "success or failure"
Mar  4 22:25:26.506: INFO: Pod "pod-configmaps-68d94608-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.847602ms
Mar  4 22:25:28.565: INFO: Pod "pod-configmaps-68d94608-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.06319443s
STEP: Saw pod success
Mar  4 22:25:28.565: INFO: Pod "pod-configmaps-68d94608-3ecc-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:25:28.570: INFO: Trying to get logs from node 10.190.208.160 pod pod-configmaps-68d94608-3ecc-11e9-b56c-8631b5a7dc0e container configmap-volume-test: <nil>
STEP: delete the pod
Mar  4 22:25:28.607: INFO: Waiting for pod pod-configmaps-68d94608-3ecc-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:25:28.617: INFO: Pod pod-configmaps-68d94608-3ecc-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:25:28.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ltxxk" for this suite.
Mar  4 22:25:34.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:25:34.752: INFO: namespace: e2e-tests-configmap-ltxxk, resource: bindings, ignored listing per whitelist
Mar  4 22:25:34.917: INFO: namespace e2e-tests-configmap-ltxxk deletion completed in 6.291963664s

• [SLOW TEST:8.797 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:25:34.918: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-bj7c2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-6e053b3e-3ecc-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume configMaps
Mar  4 22:25:35.174: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6e060df5-3ecc-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-projected-bj7c2" to be "success or failure"
Mar  4 22:25:35.179: INFO: Pod "pod-projected-configmaps-6e060df5-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.52717ms
Mar  4 22:25:37.185: INFO: Pod "pod-projected-configmaps-6e060df5-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010348338s
STEP: Saw pod success
Mar  4 22:25:37.185: INFO: Pod "pod-projected-configmaps-6e060df5-3ecc-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:25:37.189: INFO: Trying to get logs from node 10.190.208.160 pod pod-projected-configmaps-6e060df5-3ecc-11e9-b56c-8631b5a7dc0e container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  4 22:25:37.220: INFO: Waiting for pod pod-projected-configmaps-6e060df5-3ecc-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:25:37.226: INFO: Pod pod-projected-configmaps-6e060df5-3ecc-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:25:37.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bj7c2" for this suite.
Mar  4 22:25:43.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:25:43.567: INFO: namespace: e2e-tests-projected-bj7c2, resource: bindings, ignored listing per whitelist
Mar  4 22:25:43.737: INFO: namespace e2e-tests-projected-bj7c2 deletion completed in 6.454336637s

• [SLOW TEST:8.819 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:25:43.737: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-n5ml9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  4 22:25:43.995: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7347ae36-3ecc-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-downward-api-n5ml9" to be "success or failure"
Mar  4 22:25:43.999: INFO: Pod "downwardapi-volume-7347ae36-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.64129ms
Mar  4 22:25:46.005: INFO: Pod "downwardapi-volume-7347ae36-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010133382s
STEP: Saw pod success
Mar  4 22:25:46.005: INFO: Pod "downwardapi-volume-7347ae36-3ecc-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:25:46.010: INFO: Trying to get logs from node 10.190.208.162 pod downwardapi-volume-7347ae36-3ecc-11e9-b56c-8631b5a7dc0e container client-container: <nil>
STEP: delete the pod
Mar  4 22:25:46.042: INFO: Waiting for pod downwardapi-volume-7347ae36-3ecc-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:25:46.048: INFO: Pod downwardapi-volume-7347ae36-3ecc-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:25:46.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-n5ml9" for this suite.
Mar  4 22:25:52.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:25:52.296: INFO: namespace: e2e-tests-downward-api-n5ml9, resource: bindings, ignored listing per whitelist
Mar  4 22:25:52.348: INFO: namespace e2e-tests-downward-api-n5ml9 deletion completed in 6.286485507s

• [SLOW TEST:8.611 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:25:52.349: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-m654p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  4 22:25:54.690: INFO: Waiting up to 5m0s for pod "client-envvars-799e6aea-3ecc-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-pods-m654p" to be "success or failure"
Mar  4 22:25:54.697: INFO: Pod "client-envvars-799e6aea-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.778211ms
Mar  4 22:25:56.702: INFO: Pod "client-envvars-799e6aea-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012110158s
STEP: Saw pod success
Mar  4 22:25:56.702: INFO: Pod "client-envvars-799e6aea-3ecc-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:25:56.707: INFO: Trying to get logs from node 10.190.208.160 pod client-envvars-799e6aea-3ecc-11e9-b56c-8631b5a7dc0e container env3cont: <nil>
STEP: delete the pod
Mar  4 22:25:56.747: INFO: Waiting for pod client-envvars-799e6aea-3ecc-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:25:56.752: INFO: Pod client-envvars-799e6aea-3ecc-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:25:56.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-m654p" for this suite.
Mar  4 22:26:50.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:26:50.898: INFO: namespace: e2e-tests-pods-m654p, resource: bindings, ignored listing per whitelist
Mar  4 22:26:51.117: INFO: namespace e2e-tests-pods-m654p deletion completed in 54.351771426s

• [SLOW TEST:58.768 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:26:51.117: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-grsjb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  4 22:26:51.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-grsjb'
Mar  4 22:26:51.525: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar  4 22:26:51.525: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Mar  4 22:26:53.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-grsjb'
Mar  4 22:26:53.743: INFO: stderr: ""
Mar  4 22:26:53.743: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:26:53.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-grsjb" for this suite.
Mar  4 22:27:15.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:27:16.030: INFO: namespace: e2e-tests-kubectl-grsjb, resource: bindings, ignored listing per whitelist
Mar  4 22:27:16.107: INFO: namespace e2e-tests-kubectl-grsjb deletion completed in 22.354580031s

• [SLOW TEST:24.990 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:27:16.108: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-zkntw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-aa53b161-3ecc-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume secrets
Mar  4 22:27:16.353: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-aa54a09b-3ecc-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-projected-zkntw" to be "success or failure"
Mar  4 22:27:16.358: INFO: Pod "pod-projected-secrets-aa54a09b-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.52714ms
Mar  4 22:27:18.363: INFO: Pod "pod-projected-secrets-aa54a09b-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010282316s
STEP: Saw pod success
Mar  4 22:27:18.364: INFO: Pod "pod-projected-secrets-aa54a09b-3ecc-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:27:18.368: INFO: Trying to get logs from node 10.190.208.160 pod pod-projected-secrets-aa54a09b-3ecc-11e9-b56c-8631b5a7dc0e container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  4 22:27:18.398: INFO: Waiting for pod pod-projected-secrets-aa54a09b-3ecc-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:27:18.403: INFO: Pod pod-projected-secrets-aa54a09b-3ecc-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:27:18.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zkntw" for this suite.
Mar  4 22:27:24.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:27:24.725: INFO: namespace: e2e-tests-projected-zkntw, resource: bindings, ignored listing per whitelist
Mar  4 22:27:24.731: INFO: namespace e2e-tests-projected-zkntw deletion completed in 6.318572045s

• [SLOW TEST:8.624 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:27:24.732: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-j9qhj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-j9qhj
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  4 22:27:24.957: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  4 22:27:47.112: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.30.252.204 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-j9qhj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  4 22:27:47.112: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
Mar  4 22:27:48.430: INFO: Found all expected endpoints: [netserver-0]
Mar  4 22:27:48.483: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.30.87.185 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-j9qhj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  4 22:27:48.483: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
Mar  4 22:27:49.705: INFO: Found all expected endpoints: [netserver-1]
Mar  4 22:27:49.710: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.30.86.146 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-j9qhj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  4 22:27:49.710: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
Mar  4 22:27:50.982: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:27:50.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-j9qhj" for this suite.
Mar  4 22:28:15.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:28:15.131: INFO: namespace: e2e-tests-pod-network-test-j9qhj, resource: bindings, ignored listing per whitelist
Mar  4 22:28:15.328: INFO: namespace e2e-tests-pod-network-test-j9qhj deletion completed in 24.332919214s

• [SLOW TEST:50.596 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:28:15.330: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-8tjgk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  4 22:28:15.572: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cda0a062-3ecc-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-downward-api-8tjgk" to be "success or failure"
Mar  4 22:28:15.576: INFO: Pod "downwardapi-volume-cda0a062-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.474064ms
Mar  4 22:28:17.582: INFO: Pod "downwardapi-volume-cda0a062-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010520631s
STEP: Saw pod success
Mar  4 22:28:17.583: INFO: Pod "downwardapi-volume-cda0a062-3ecc-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:28:17.588: INFO: Trying to get logs from node 10.190.208.160 pod downwardapi-volume-cda0a062-3ecc-11e9-b56c-8631b5a7dc0e container client-container: <nil>
STEP: delete the pod
Mar  4 22:28:17.683: INFO: Waiting for pod downwardapi-volume-cda0a062-3ecc-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:28:17.687: INFO: Pod downwardapi-volume-cda0a062-3ecc-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:28:17.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8tjgk" for this suite.
Mar  4 22:28:23.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:28:23.834: INFO: namespace: e2e-tests-downward-api-8tjgk, resource: bindings, ignored listing per whitelist
Mar  4 22:28:24.142: INFO: namespace e2e-tests-downward-api-8tjgk deletion completed in 6.444274893s

• [SLOW TEST:8.813 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:28:24.143: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-srxd7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-d2e0793e-3ecc-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume configMaps
Mar  4 22:28:24.385: INFO: Waiting up to 5m0s for pod "pod-configmaps-d2e15f75-3ecc-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-configmap-srxd7" to be "success or failure"
Mar  4 22:28:24.389: INFO: Pod "pod-configmaps-d2e15f75-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.316157ms
Mar  4 22:28:26.395: INFO: Pod "pod-configmaps-d2e15f75-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009908199s
STEP: Saw pod success
Mar  4 22:28:26.395: INFO: Pod "pod-configmaps-d2e15f75-3ecc-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:28:26.399: INFO: Trying to get logs from node 10.190.208.160 pod pod-configmaps-d2e15f75-3ecc-11e9-b56c-8631b5a7dc0e container configmap-volume-test: <nil>
STEP: delete the pod
Mar  4 22:28:26.483: INFO: Waiting for pod pod-configmaps-d2e15f75-3ecc-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:28:26.487: INFO: Pod pod-configmaps-d2e15f75-3ecc-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:28:26.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-srxd7" for this suite.
Mar  4 22:28:32.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:28:32.821: INFO: namespace: e2e-tests-configmap-srxd7, resource: bindings, ignored listing per whitelist
Mar  4 22:28:33.021: INFO: namespace e2e-tests-configmap-srxd7 deletion completed in 6.524131286s

• [SLOW TEST:8.878 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:28:33.022: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7kdzt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-d82e850f-3ecc-11e9-b56c-8631b5a7dc0e
STEP: Creating configMap with name cm-test-opt-upd-d82e857b-3ecc-11e9-b56c-8631b5a7dc0e
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-d82e850f-3ecc-11e9-b56c-8631b5a7dc0e
STEP: Updating configmap cm-test-opt-upd-d82e857b-3ecc-11e9-b56c-8631b5a7dc0e
STEP: Creating configMap with name cm-test-opt-create-d82e85aa-3ecc-11e9-b56c-8631b5a7dc0e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:28:37.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7kdzt" for this suite.
Mar  4 22:29:01.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:29:01.791: INFO: namespace: e2e-tests-projected-7kdzt, resource: bindings, ignored listing per whitelist
Mar  4 22:29:01.855: INFO: namespace e2e-tests-projected-7kdzt deletion completed in 24.399635293s

• [SLOW TEST:28.833 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:29:01.856: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-vxp2m
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar  4 22:29:02.187: INFO: Waiting up to 5m0s for pod "downward-api-e9694bd6-3ecc-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-downward-api-vxp2m" to be "success or failure"
Mar  4 22:29:02.193: INFO: Pod "downward-api-e9694bd6-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.423597ms
Mar  4 22:29:04.199: INFO: Pod "downward-api-e9694bd6-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Running", Reason="", readiness=true. Elapsed: 2.011683953s
Mar  4 22:29:06.205: INFO: Pod "downward-api-e9694bd6-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017465044s
STEP: Saw pod success
Mar  4 22:29:06.205: INFO: Pod "downward-api-e9694bd6-3ecc-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:29:06.209: INFO: Trying to get logs from node 10.190.208.162 pod downward-api-e9694bd6-3ecc-11e9-b56c-8631b5a7dc0e container dapi-container: <nil>
STEP: delete the pod
Mar  4 22:29:06.298: INFO: Waiting for pod downward-api-e9694bd6-3ecc-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:29:06.304: INFO: Pod downward-api-e9694bd6-3ecc-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:29:06.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vxp2m" for this suite.
Mar  4 22:29:14.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:29:14.486: INFO: namespace: e2e-tests-downward-api-vxp2m, resource: bindings, ignored listing per whitelist
Mar  4 22:29:14.596: INFO: namespace e2e-tests-downward-api-vxp2m deletion completed in 8.281404044s

• [SLOW TEST:12.740 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:29:14.596: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-6ck9m
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-vwn2t in namespace e2e-tests-proxy-6ck9m
I0304 22:29:14.907760      15 runners.go:180] Created replication controller with name: proxy-service-vwn2t, namespace: e2e-tests-proxy-6ck9m, replica count: 1
I0304 22:29:15.958237      15 runners.go:180] proxy-service-vwn2t Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0304 22:29:16.958502      15 runners.go:180] proxy-service-vwn2t Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0304 22:29:17.964958      15 runners.go:180] proxy-service-vwn2t Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0304 22:29:18.965145      15 runners.go:180] proxy-service-vwn2t Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0304 22:29:19.965370      15 runners.go:180] proxy-service-vwn2t Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0304 22:29:20.965574      15 runners.go:180] proxy-service-vwn2t Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  4 22:29:20.976: INFO: setup took 6.102571542s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Mar  4 22:29:20.992: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/rewriteme"... (200; 15.423596ms)
Mar  4 22:29:20.997: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 20.273376ms)
Mar  4 22:29:20.997: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/rewri... (200; 20.313737ms)
Mar  4 22:29:20.998: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 20.590026ms)
Mar  4 22:29:20.998: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 20.745505ms)
Mar  4 22:29:20.998: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 20.500425ms)
Mar  4 22:29:20.998: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname1/proxy/: foo (200; 21.034693ms)
Mar  4 22:29:20.998: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/... (200; 21.434666ms)
Mar  4 22:29:21.001: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname2/proxy/: bar (200; 24.678675ms)
Mar  4 22:29:21.002: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:460/proxy/: tls baz (200; 25.266655ms)
Mar  4 22:29:21.002: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname1/proxy/: foo (200; 25.414206ms)
Mar  4 22:29:21.002: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname2/proxy/: bar (200; 24.986141ms)
Mar  4 22:29:21.005: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/... (200; 28.155884ms)
Mar  4 22:29:21.005: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:462/proxy/: tls qux (200; 28.155174ms)
Mar  4 22:29:21.008: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname1/proxy/: tls baz (200; 31.322869ms)
Mar  4 22:29:21.082: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname2/proxy/: tls qux (200; 105.810465ms)
Mar  4 22:29:21.092: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 8.846513ms)
Mar  4 22:29:21.094: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/rewriteme"... (200; 11.406365ms)
Mar  4 22:29:21.095: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:462/proxy/: tls qux (200; 11.84533ms)
Mar  4 22:29:21.095: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/... (200; 11.578474ms)
Mar  4 22:29:21.095: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/... (200; 11.372038ms)
Mar  4 22:29:21.095: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 11.823405ms)
Mar  4 22:29:21.095: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 11.73502ms)
Mar  4 22:29:21.095: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 11.625303ms)
Mar  4 22:29:21.095: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/rewri... (200; 11.828538ms)
Mar  4 22:29:21.095: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:460/proxy/: tls baz (200; 11.472865ms)
Mar  4 22:29:21.098: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname2/proxy/: bar (200; 14.727998ms)
Mar  4 22:29:21.102: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname2/proxy/: bar (200; 19.191749ms)
Mar  4 22:29:21.106: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname2/proxy/: tls qux (200; 22.570221ms)
Mar  4 22:29:21.106: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname1/proxy/: foo (200; 22.618451ms)
Mar  4 22:29:21.106: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname1/proxy/: foo (200; 22.796871ms)
Mar  4 22:29:21.106: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname1/proxy/: tls baz (200; 23.042052ms)
Mar  4 22:29:21.114: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/... (200; 8.102151ms)
Mar  4 22:29:21.116: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/rewriteme"... (200; 10.111919ms)
Mar  4 22:29:21.116: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 10.398841ms)
Mar  4 22:29:21.116: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:460/proxy/: tls baz (200; 10.494482ms)
Mar  4 22:29:21.116: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 10.202051ms)
Mar  4 22:29:21.117: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/rewri... (200; 10.517063ms)
Mar  4 22:29:21.117: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/... (200; 10.329862ms)
Mar  4 22:29:21.117: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 10.450391ms)
Mar  4 22:29:21.117: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 10.802171ms)
Mar  4 22:29:21.117: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:462/proxy/: tls qux (200; 11.030692ms)
Mar  4 22:29:21.120: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname2/proxy/: tls qux (200; 13.305956ms)
Mar  4 22:29:21.121: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname1/proxy/: foo (200; 14.899515ms)
Mar  4 22:29:21.123: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname1/proxy/: foo (200; 17.155751ms)
Mar  4 22:29:21.126: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname2/proxy/: bar (200; 19.530187ms)
Mar  4 22:29:21.126: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname2/proxy/: bar (200; 19.282157ms)
Mar  4 22:29:21.126: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname1/proxy/: tls baz (200; 19.275829ms)
Mar  4 22:29:21.133: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:460/proxy/: tls baz (200; 7.320958ms)
Mar  4 22:29:21.134: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/... (200; 7.737602ms)
Mar  4 22:29:21.136: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 10.459557ms)
Mar  4 22:29:21.136: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 10.143547ms)
Mar  4 22:29:21.137: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:462/proxy/: tls qux (200; 10.308333ms)
Mar  4 22:29:21.137: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/... (200; 10.81577ms)
Mar  4 22:29:21.137: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/rewri... (200; 10.99886ms)
Mar  4 22:29:21.137: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 10.778493ms)
Mar  4 22:29:21.137: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/rewriteme"... (200; 10.633973ms)
Mar  4 22:29:21.141: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname1/proxy/: tls baz (200; 14.830814ms)
Mar  4 22:29:21.141: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 14.361322ms)
Mar  4 22:29:21.144: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname1/proxy/: foo (200; 17.670009ms)
Mar  4 22:29:21.144: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname1/proxy/: foo (200; 18.098484ms)
Mar  4 22:29:21.146: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname2/proxy/: bar (200; 19.482442ms)
Mar  4 22:29:21.146: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname2/proxy/: tls qux (200; 19.54572ms)
Mar  4 22:29:21.146: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname2/proxy/: bar (200; 19.910069ms)
Mar  4 22:29:21.154: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/... (200; 7.513123ms)
Mar  4 22:29:21.158: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/rewriteme"... (200; 11.634268ms)
Mar  4 22:29:21.158: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 11.58134ms)
Mar  4 22:29:21.158: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 11.706813ms)
Mar  4 22:29:21.158: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:462/proxy/: tls qux (200; 11.913671ms)
Mar  4 22:29:21.159: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/... (200; 11.995973ms)
Mar  4 22:29:21.159: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 12.066739ms)
Mar  4 22:29:21.159: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 12.078199ms)
Mar  4 22:29:21.159: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/rewri... (200; 11.874815ms)
Mar  4 22:29:21.159: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:460/proxy/: tls baz (200; 12.118545ms)
Mar  4 22:29:21.162: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname2/proxy/: bar (200; 16.117897ms)
Mar  4 22:29:21.165: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname2/proxy/: bar (200; 18.366917ms)
Mar  4 22:29:21.168: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname1/proxy/: foo (200; 20.867879ms)
Mar  4 22:29:21.170: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname1/proxy/: tls baz (200; 22.921326ms)
Mar  4 22:29:21.170: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname2/proxy/: tls qux (200; 23.137281ms)
Mar  4 22:29:21.170: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname1/proxy/: foo (200; 23.264321ms)
Mar  4 22:29:21.178: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 7.654886ms)
Mar  4 22:29:21.180: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/rewri... (200; 9.363623ms)
Mar  4 22:29:21.180: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:460/proxy/: tls baz (200; 9.347431ms)
Mar  4 22:29:21.180: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/... (200; 9.306616ms)
Mar  4 22:29:21.180: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/rewriteme"... (200; 10.019649ms)
Mar  4 22:29:21.180: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 10.066437ms)
Mar  4 22:29:21.180: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 9.767367ms)
Mar  4 22:29:21.180: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/... (200; 9.920093ms)
Mar  4 22:29:21.181: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:462/proxy/: tls qux (200; 10.185998ms)
Mar  4 22:29:21.181: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 10.603346ms)
Mar  4 22:29:21.188: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname1/proxy/: foo (200; 17.797992ms)
Mar  4 22:29:21.190: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname1/proxy/: foo (200; 19.866584ms)
Mar  4 22:29:21.193: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname2/proxy/: bar (200; 22.827782ms)
Mar  4 22:29:21.193: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname2/proxy/: bar (200; 22.331961ms)
Mar  4 22:29:21.193: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname2/proxy/: tls qux (200; 22.397684ms)
Mar  4 22:29:21.193: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname1/proxy/: tls baz (200; 23.02454ms)
Mar  4 22:29:21.201: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 7.812929ms)
Mar  4 22:29:21.206: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 12.144074ms)
Mar  4 22:29:21.206: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 12.327831ms)
Mar  4 22:29:21.206: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/... (200; 12.639061ms)
Mar  4 22:29:21.206: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 12.84757ms)
Mar  4 22:29:21.206: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/rewri... (200; 12.555693ms)
Mar  4 22:29:21.206: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/rewriteme"... (200; 12.602785ms)
Mar  4 22:29:21.206: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:462/proxy/: tls qux (200; 12.568022ms)
Mar  4 22:29:21.207: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/... (200; 13.195446ms)
Mar  4 22:29:21.207: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:460/proxy/: tls baz (200; 13.010342ms)
Mar  4 22:29:21.212: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname1/proxy/: foo (200; 18.001444ms)
Mar  4 22:29:21.212: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname2/proxy/: bar (200; 18.129472ms)
Mar  4 22:29:21.215: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname2/proxy/: bar (200; 20.908702ms)
Mar  4 22:29:21.217: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname2/proxy/: tls qux (200; 22.908858ms)
Mar  4 22:29:21.217: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname1/proxy/: tls baz (200; 22.845853ms)
Mar  4 22:29:21.217: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname1/proxy/: foo (200; 22.684614ms)
Mar  4 22:29:21.225: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/... (200; 7.915163ms)
Mar  4 22:29:21.234: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/rewriteme"... (200; 16.967099ms)
Mar  4 22:29:21.234: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:462/proxy/: tls qux (200; 17.223704ms)
Mar  4 22:29:21.234: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 17.419922ms)
Mar  4 22:29:21.235: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 17.42656ms)
Mar  4 22:29:21.235: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/rewri... (200; 17.341602ms)
Mar  4 22:29:21.235: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 17.286246ms)
Mar  4 22:29:21.235: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 17.353546ms)
Mar  4 22:29:21.235: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/... (200; 17.804453ms)
Mar  4 22:29:21.235: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:460/proxy/: tls baz (200; 17.615688ms)
Mar  4 22:29:21.236: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname1/proxy/: tls baz (200; 18.2811ms)
Mar  4 22:29:21.242: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname2/proxy/: tls qux (200; 25.260808ms)
Mar  4 22:29:21.244: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname2/proxy/: bar (200; 27.01571ms)
Mar  4 22:29:21.244: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname1/proxy/: foo (200; 26.634509ms)
Mar  4 22:29:21.244: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname2/proxy/: bar (200; 27.062931ms)
Mar  4 22:29:21.244: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname1/proxy/: foo (200; 26.838544ms)
Mar  4 22:29:21.252: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/... (200; 7.538469ms)
Mar  4 22:29:21.253: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:462/proxy/: tls qux (200; 8.567341ms)
Mar  4 22:29:21.253: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/rewriteme"... (200; 8.629427ms)
Mar  4 22:29:21.253: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/rewri... (200; 9.327386ms)
Mar  4 22:29:21.254: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 9.051529ms)
Mar  4 22:29:21.254: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:460/proxy/: tls baz (200; 9.705087ms)
Mar  4 22:29:21.254: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 9.60106ms)
Mar  4 22:29:21.254: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/... (200; 9.954401ms)
Mar  4 22:29:21.255: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 10.409966ms)
Mar  4 22:29:21.255: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 10.465561ms)
Mar  4 22:29:21.257: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname1/proxy/: foo (200; 12.800884ms)
Mar  4 22:29:21.261: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname2/proxy/: bar (200; 16.18522ms)
Mar  4 22:29:21.263: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname1/proxy/: foo (200; 18.458589ms)
Mar  4 22:29:21.263: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname1/proxy/: tls baz (200; 18.876419ms)
Mar  4 22:29:21.263: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname2/proxy/: tls qux (200; 18.455911ms)
Mar  4 22:29:21.263: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname2/proxy/: bar (200; 18.552082ms)
Mar  4 22:29:21.272: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/... (200; 8.383357ms)
Mar  4 22:29:21.274: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 10.128891ms)
Mar  4 22:29:21.274: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:462/proxy/: tls qux (200; 10.155844ms)
Mar  4 22:29:21.274: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/rewriteme"... (200; 10.210107ms)
Mar  4 22:29:21.274: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 10.403599ms)
Mar  4 22:29:21.274: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:460/proxy/: tls baz (200; 10.975916ms)
Mar  4 22:29:21.274: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 10.897119ms)
Mar  4 22:29:21.275: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/rewri... (200; 11.387064ms)
Mar  4 22:29:21.275: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/... (200; 11.255817ms)
Mar  4 22:29:21.275: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 11.19921ms)
Mar  4 22:29:21.277: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname1/proxy/: tls baz (200; 14.082281ms)
Mar  4 22:29:21.281: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname2/proxy/: bar (200; 17.436368ms)
Mar  4 22:29:21.283: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname1/proxy/: foo (200; 19.381653ms)
Mar  4 22:29:21.283: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname1/proxy/: foo (200; 19.559001ms)
Mar  4 22:29:21.283: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname2/proxy/: bar (200; 19.423619ms)
Mar  4 22:29:21.283: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname2/proxy/: tls qux (200; 19.559188ms)
Mar  4 22:29:21.292: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 8.659917ms)
Mar  4 22:29:21.293: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/... (200; 9.748415ms)
Mar  4 22:29:21.294: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/rewriteme"... (200; 9.879176ms)
Mar  4 22:29:21.294: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 10.453448ms)
Mar  4 22:29:21.294: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:460/proxy/: tls baz (200; 10.035104ms)
Mar  4 22:29:21.296: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:462/proxy/: tls qux (200; 12.70742ms)
Mar  4 22:29:21.296: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 12.19967ms)
Mar  4 22:29:21.296: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/... (200; 12.094716ms)
Mar  4 22:29:21.296: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/rewri... (200; 12.18661ms)
Mar  4 22:29:21.296: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 12.737325ms)
Mar  4 22:29:21.299: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname1/proxy/: foo (200; 14.624911ms)
Mar  4 22:29:21.303: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname1/proxy/: tls baz (200; 18.987998ms)
Mar  4 22:29:21.305: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname2/proxy/: tls qux (200; 21.239383ms)
Mar  4 22:29:21.305: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname2/proxy/: bar (200; 21.150243ms)
Mar  4 22:29:21.305: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname1/proxy/: foo (200; 21.854729ms)
Mar  4 22:29:21.305: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname2/proxy/: bar (200; 21.915666ms)
Mar  4 22:29:21.314: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:462/proxy/: tls qux (200; 7.899025ms)
Mar  4 22:29:21.316: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 10.296826ms)
Mar  4 22:29:21.316: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/rewri... (200; 10.430231ms)
Mar  4 22:29:21.317: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 10.584888ms)
Mar  4 22:29:21.316: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 10.385956ms)
Mar  4 22:29:21.317: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/... (200; 11.135369ms)
Mar  4 22:29:21.317: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/rewriteme"... (200; 10.965784ms)
Mar  4 22:29:21.317: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:460/proxy/: tls baz (200; 11.08124ms)
Mar  4 22:29:21.317: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 11.21755ms)
Mar  4 22:29:21.317: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/... (200; 10.795535ms)
Mar  4 22:29:21.319: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname1/proxy/: foo (200; 13.368945ms)
Mar  4 22:29:21.323: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname2/proxy/: bar (200; 17.566006ms)
Mar  4 22:29:21.326: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname1/proxy/: foo (200; 20.443364ms)
Mar  4 22:29:21.326: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname2/proxy/: bar (200; 20.52123ms)
Mar  4 22:29:21.326: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname1/proxy/: tls baz (200; 20.405085ms)
Mar  4 22:29:21.326: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname2/proxy/: tls qux (200; 20.470755ms)
Mar  4 22:29:21.334: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 7.094606ms)
Mar  4 22:29:21.336: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 9.561376ms)
Mar  4 22:29:21.336: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:460/proxy/: tls baz (200; 9.586719ms)
Mar  4 22:29:21.336: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 9.752667ms)
Mar  4 22:29:21.337: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:462/proxy/: tls qux (200; 9.515474ms)
Mar  4 22:29:21.337: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/... (200; 9.847076ms)
Mar  4 22:29:21.337: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 9.717494ms)
Mar  4 22:29:21.337: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/... (200; 9.740749ms)
Mar  4 22:29:21.337: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/rewriteme"... (200; 9.865557ms)
Mar  4 22:29:21.337: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/rewri... (200; 10.270012ms)
Mar  4 22:29:21.340: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname1/proxy/: tls baz (200; 13.601626ms)
Mar  4 22:29:21.344: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname2/proxy/: bar (200; 16.904452ms)
Mar  4 22:29:21.346: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname1/proxy/: foo (200; 19.131924ms)
Mar  4 22:29:21.346: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname1/proxy/: foo (200; 19.29136ms)
Mar  4 22:29:21.347: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname2/proxy/: bar (200; 19.892491ms)
Mar  4 22:29:21.347: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname2/proxy/: tls qux (200; 19.818584ms)
Mar  4 22:29:21.355: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:460/proxy/: tls baz (200; 7.643033ms)
Mar  4 22:29:21.355: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/rewriteme"... (200; 7.171805ms)
Mar  4 22:29:21.356: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 8.697111ms)
Mar  4 22:29:21.356: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:462/proxy/: tls qux (200; 8.499216ms)
Mar  4 22:29:21.357: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/... (200; 8.513403ms)
Mar  4 22:29:21.357: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 8.272684ms)
Mar  4 22:29:21.357: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/rewri... (200; 9.529341ms)
Mar  4 22:29:21.357: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/... (200; 9.335543ms)
Mar  4 22:29:21.357: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 9.009919ms)
Mar  4 22:29:21.358: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 9.414974ms)
Mar  4 22:29:21.364: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname1/proxy/: foo (200; 16.707228ms)
Mar  4 22:29:21.366: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname2/proxy/: bar (200; 19.047545ms)
Mar  4 22:29:21.369: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname1/proxy/: tls baz (200; 20.248576ms)
Mar  4 22:29:21.369: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname2/proxy/: tls qux (200; 21.043255ms)
Mar  4 22:29:21.371: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname1/proxy/: foo (200; 22.599552ms)
Mar  4 22:29:21.371: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname2/proxy/: bar (200; 22.756525ms)
Mar  4 22:29:21.378: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/... (200; 7.282891ms)
Mar  4 22:29:21.380: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 8.447088ms)
Mar  4 22:29:21.380: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/rewri... (200; 8.377461ms)
Mar  4 22:29:21.380: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/rewriteme"... (200; 8.016917ms)
Mar  4 22:29:21.380: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 8.229052ms)
Mar  4 22:29:21.381: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/... (200; 9.639903ms)
Mar  4 22:29:21.381: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:460/proxy/: tls baz (200; 8.917718ms)
Mar  4 22:29:21.381: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 9.478422ms)
Mar  4 22:29:21.381: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:462/proxy/: tls qux (200; 9.683683ms)
Mar  4 22:29:21.381: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 9.544596ms)
Mar  4 22:29:21.384: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname1/proxy/: tls baz (200; 12.625902ms)
Mar  4 22:29:21.386: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname2/proxy/: bar (200; 14.046746ms)
Mar  4 22:29:21.388: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname1/proxy/: foo (200; 16.314594ms)
Mar  4 22:29:21.389: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname2/proxy/: bar (200; 17.297705ms)
Mar  4 22:29:21.389: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname2/proxy/: tls qux (200; 17.298271ms)
Mar  4 22:29:21.390: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname1/proxy/: foo (200; 17.489493ms)
Mar  4 22:29:21.398: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:462/proxy/: tls qux (200; 8.442242ms)
Mar  4 22:29:21.400: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 10.334197ms)
Mar  4 22:29:21.400: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/... (200; 10.566111ms)
Mar  4 22:29:21.400: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 10.639746ms)
Mar  4 22:29:21.401: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/rewriteme"... (200; 10.868705ms)
Mar  4 22:29:21.401: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/rewri... (200; 11.18237ms)
Mar  4 22:29:21.401: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 11.237625ms)
Mar  4 22:29:21.401: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/... (200; 11.123781ms)
Mar  4 22:29:21.401: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 11.114523ms)
Mar  4 22:29:21.401: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:460/proxy/: tls baz (200; 11.438368ms)
Mar  4 22:29:21.404: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname2/proxy/: bar (200; 14.08336ms)
Mar  4 22:29:21.406: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname1/proxy/: foo (200; 16.919215ms)
Mar  4 22:29:21.407: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname1/proxy/: tls baz (200; 16.937931ms)
Mar  4 22:29:21.407: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname1/proxy/: foo (200; 17.172543ms)
Mar  4 22:29:21.409: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname2/proxy/: bar (200; 18.673453ms)
Mar  4 22:29:21.409: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname2/proxy/: tls qux (200; 19.045188ms)
Mar  4 22:29:21.416: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:460/proxy/: tls baz (200; 7.332468ms)
Mar  4 22:29:21.418: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 9.05363ms)
Mar  4 22:29:21.418: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/rewriteme"... (200; 9.075378ms)
Mar  4 22:29:21.418: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/rewri... (200; 9.090796ms)
Mar  4 22:29:21.419: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 9.420387ms)
Mar  4 22:29:21.419: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:462/proxy/: tls qux (200; 9.42114ms)
Mar  4 22:29:21.422: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/... (200; 13.356988ms)
Mar  4 22:29:21.423: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 13.574495ms)
Mar  4 22:29:21.423: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 13.539316ms)
Mar  4 22:29:21.423: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/... (200; 13.38122ms)
Mar  4 22:29:21.426: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname1/proxy/: foo (200; 17.026253ms)
Mar  4 22:29:21.427: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname1/proxy/: foo (200; 18.33569ms)
Mar  4 22:29:21.429: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname2/proxy/: bar (200; 19.7628ms)
Mar  4 22:29:21.429: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname2/proxy/: tls qux (200; 20.203839ms)
Mar  4 22:29:21.429: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname2/proxy/: bar (200; 20.151109ms)
Mar  4 22:29:21.429: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname1/proxy/: tls baz (200; 20.243459ms)
Mar  4 22:29:21.440: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 10.206902ms)
Mar  4 22:29:21.440: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/... (200; 10.41895ms)
Mar  4 22:29:21.440: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/rewriteme"... (200; 10.538696ms)
Mar  4 22:29:21.443: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/rewri... (200; 13.430346ms)
Mar  4 22:29:21.443: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 13.544635ms)
Mar  4 22:29:21.444: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:462/proxy/: tls qux (200; 13.428544ms)
Mar  4 22:29:21.444: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 13.80692ms)
Mar  4 22:29:21.444: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/... (200; 13.655705ms)
Mar  4 22:29:21.444: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:460/proxy/: tls baz (200; 13.813219ms)
Mar  4 22:29:21.444: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 14.132796ms)
Mar  4 22:29:21.444: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname2/proxy/: tls qux (200; 14.798789ms)
Mar  4 22:29:21.449: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname1/proxy/: foo (200; 18.952921ms)
Mar  4 22:29:21.453: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname1/proxy/: tls baz (200; 22.689609ms)
Mar  4 22:29:21.453: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname1/proxy/: foo (200; 23.061873ms)
Mar  4 22:29:21.453: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname2/proxy/: bar (200; 22.935257ms)
Mar  4 22:29:21.453: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname2/proxy/: bar (200; 23.075565ms)
Mar  4 22:29:21.462: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:462/proxy/: tls qux (200; 9.01667ms)
Mar  4 22:29:21.464: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 10.605109ms)
Mar  4 22:29:21.464: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/rewri... (200; 10.564676ms)
Mar  4 22:29:21.465: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/... (200; 11.056751ms)
Mar  4 22:29:21.465: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 11.368784ms)
Mar  4 22:29:21.465: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:460/proxy/: tls baz (200; 11.285755ms)
Mar  4 22:29:21.465: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/... (200; 11.432833ms)
Mar  4 22:29:21.465: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 11.389423ms)
Mar  4 22:29:21.465: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/rewriteme"... (200; 11.505267ms)
Mar  4 22:29:21.465: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 11.576816ms)
Mar  4 22:29:21.467: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname1/proxy/: foo (200; 14.240785ms)
Mar  4 22:29:21.471: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname1/proxy/: foo (200; 17.70979ms)
Mar  4 22:29:21.473: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname2/proxy/: bar (200; 19.629972ms)
Mar  4 22:29:21.473: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname2/proxy/: bar (200; 19.866019ms)
Mar  4 22:29:21.473: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname2/proxy/: tls qux (200; 20.10701ms)
Mar  4 22:29:21.473: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname1/proxy/: tls baz (200; 20.01049ms)
Mar  4 22:29:21.482: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 8.176059ms)
Mar  4 22:29:21.482: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:160/proxy/: foo (200; 8.234357ms)
Mar  4 22:29:21.483: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh/proxy/rewriteme"... (200; 9.396256ms)
Mar  4 22:29:21.484: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:443/proxy/... (200; 9.772956ms)
Mar  4 22:29:21.484: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:462/proxy/: tls qux (200; 9.73872ms)
Mar  4 22:29:21.484: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 9.737044ms)
Mar  4 22:29:21.484: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/http:proxy-service-vwn2t-p8rzh:1080/proxy/... (200; 9.389276ms)
Mar  4 22:29:21.484: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:1080/proxy/rewri... (200; 10.099261ms)
Mar  4 22:29:21.484: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/https:proxy-service-vwn2t-p8rzh:460/proxy/: tls baz (200; 10.410772ms)
Mar  4 22:29:21.484: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6ck9m/pods/proxy-service-vwn2t-p8rzh:162/proxy/: bar (200; 10.288024ms)
Mar  4 22:29:21.487: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname1/proxy/: tls baz (200; 13.326643ms)
Mar  4 22:29:21.490: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname1/proxy/: foo (200; 16.144881ms)
Mar  4 22:29:21.492: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname2/proxy/: bar (200; 18.029966ms)
Mar  4 22:29:21.493: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/http:proxy-service-vwn2t:portname2/proxy/: bar (200; 18.897833ms)
Mar  4 22:29:21.493: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/proxy-service-vwn2t:portname1/proxy/: foo (200; 18.987108ms)
Mar  4 22:29:21.493: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6ck9m/services/https:proxy-service-vwn2t:tlsportname2/proxy/: tls qux (200; 18.440523ms)
STEP: deleting { ReplicationController} proxy-service-vwn2t in namespace e2e-tests-proxy-6ck9m, will wait for the garbage collector to delete the pods
Mar  4 22:29:21.571: INFO: Deleting { ReplicationController} proxy-service-vwn2t took: 20.191055ms
Mar  4 22:29:21.671: INFO: Terminating { ReplicationController} proxy-service-vwn2t pods took: 100.271119ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:29:24.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-6ck9m" for this suite.
Mar  4 22:29:30.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:29:30.551: INFO: namespace: e2e-tests-proxy-6ck9m, resource: bindings, ignored listing per whitelist
Mar  4 22:29:30.577: INFO: namespace e2e-tests-proxy-6ck9m deletion completed in 6.379862812s

• [SLOW TEST:15.981 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:29:30.578: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-46w9d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  4 22:29:30.826: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fa7b6a95-3ecc-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-downward-api-46w9d" to be "success or failure"
Mar  4 22:29:30.832: INFO: Pod "downwardapi-volume-fa7b6a95-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.761222ms
Mar  4 22:29:32.838: INFO: Pod "downwardapi-volume-fa7b6a95-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011758682s
STEP: Saw pod success
Mar  4 22:29:32.838: INFO: Pod "downwardapi-volume-fa7b6a95-3ecc-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:29:32.843: INFO: Trying to get logs from node 10.190.208.160 pod downwardapi-volume-fa7b6a95-3ecc-11e9-b56c-8631b5a7dc0e container client-container: <nil>
STEP: delete the pod
Mar  4 22:29:32.883: INFO: Waiting for pod downwardapi-volume-fa7b6a95-3ecc-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:29:32.888: INFO: Pod downwardapi-volume-fa7b6a95-3ecc-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:29:32.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-46w9d" for this suite.
Mar  4 22:29:38.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:29:39.004: INFO: namespace: e2e-tests-downward-api-46w9d, resource: bindings, ignored listing per whitelist
Mar  4 22:29:39.193: INFO: namespace e2e-tests-downward-api-46w9d deletion completed in 6.295755175s

• [SLOW TEST:8.616 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:29:39.195: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-t6s28
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-ff9cf5c6-3ecc-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume secrets
Mar  4 22:29:39.493: INFO: Waiting up to 5m0s for pod "pod-secrets-ffa60613-3ecc-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-secrets-t6s28" to be "success or failure"
Mar  4 22:29:39.498: INFO: Pod "pod-secrets-ffa60613-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.733157ms
Mar  4 22:29:41.504: INFO: Pod "pod-secrets-ffa60613-3ecc-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010609034s
STEP: Saw pod success
Mar  4 22:29:41.504: INFO: Pod "pod-secrets-ffa60613-3ecc-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:29:41.509: INFO: Trying to get logs from node 10.190.208.160 pod pod-secrets-ffa60613-3ecc-11e9-b56c-8631b5a7dc0e container secret-volume-test: <nil>
STEP: delete the pod
Mar  4 22:29:41.546: INFO: Waiting for pod pod-secrets-ffa60613-3ecc-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:29:41.551: INFO: Pod pod-secrets-ffa60613-3ecc-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:29:41.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-t6s28" for this suite.
Mar  4 22:29:49.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:29:49.909: INFO: namespace: e2e-tests-secrets-t6s28, resource: bindings, ignored listing per whitelist
Mar  4 22:29:50.033: INFO: namespace e2e-tests-secrets-t6s28 deletion completed in 8.448888309s

• [SLOW TEST:10.838 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:29:50.033: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-rvmdh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Mar  4 22:29:50.270: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  4 22:29:50.289: INFO: Waiting for terminating namespaces to be deleted...
Mar  4 22:29:50.296: INFO: 
Logging pods the kubelet thinks is on node 10.190.208.160 before test
Mar  4 22:29:50.322: INFO: kubernetes-dashboard-b4bc7db5d-47nml from kube-system started at 2019-03-04 21:29:35 +0000 UTC (1 container statuses recorded)
Mar  4 22:29:50.322: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Mar  4 22:29:50.322: INFO: ibm-storage-watcher-54cf447885-vvkrq from kube-system started at 2019-03-04 21:29:35 +0000 UTC (1 container statuses recorded)
Mar  4 22:29:50.322: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Mar  4 22:29:50.322: INFO: ibm-kube-fluentd-xcfn9 from kube-system started at 2019-03-04 21:32:33 +0000 UTC (1 container statuses recorded)
Mar  4 22:29:50.322: INFO: 	Container fluentd ready: true, restart count 0
Mar  4 22:29:50.322: INFO: ibm-master-proxy-static-10.190.208.160 from kube-system started at <nil> (0 container statuses recorded)
Mar  4 22:29:50.322: INFO: sonobuoy-systemd-logs-daemon-set-96866c1b23744a30-zggp2 from heptio-sonobuoy started at 2019-03-04 22:09:43 +0000 UTC (2 container statuses recorded)
Mar  4 22:29:50.322: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar  4 22:29:50.322: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  4 22:29:50.322: INFO: calico-kube-controllers-5c699798bc-n5qdk from kube-system started at 2019-03-04 21:29:15 +0000 UTC (1 container statuses recorded)
Mar  4 22:29:50.322: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Mar  4 22:29:50.322: INFO: calico-node-jxfjl from kube-system started at 2019-03-04 21:29:15 +0000 UTC (2 container statuses recorded)
Mar  4 22:29:50.322: INFO: 	Container calico-node ready: true, restart count 0
Mar  4 22:29:50.322: INFO: 	Container install-cni ready: true, restart count 0
Mar  4 22:29:50.322: INFO: ibm-file-plugin-586bb8bf84-dqlk6 from kube-system started at 2019-03-04 21:29:35 +0000 UTC (1 container statuses recorded)
Mar  4 22:29:50.322: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Mar  4 22:29:50.322: INFO: kube-dns-amd64-fcdcf59c5-kqdfx from kube-system started at 2019-03-04 21:29:35 +0000 UTC (3 container statuses recorded)
Mar  4 22:29:50.322: INFO: 	Container dnsmasq ready: true, restart count 0
Mar  4 22:29:50.322: INFO: 	Container kubedns ready: true, restart count 0
Mar  4 22:29:50.322: INFO: 	Container sidecar ready: true, restart count 0
Mar  4 22:29:50.322: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-04 22:09:39 +0000 UTC (1 container statuses recorded)
Mar  4 22:29:50.322: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar  4 22:29:50.322: INFO: ibm-keepalived-watcher-nh5p6 from kube-system started at 2019-03-04 21:29:15 +0000 UTC (1 container statuses recorded)
Mar  4 22:29:50.322: INFO: 	Container keepalived-watcher ready: true, restart count 0
Mar  4 22:29:50.322: INFO: vpn-6c6b45457f-xmlwb from kube-system started at 2019-03-04 21:29:35 +0000 UTC (1 container statuses recorded)
Mar  4 22:29:50.322: INFO: 	Container vpn ready: true, restart count 0
Mar  4 22:29:50.322: INFO: kube-dns-autoscaler-587cd5cd44-8p94v from kube-system started at 2019-03-04 21:29:35 +0000 UTC (1 container statuses recorded)
Mar  4 22:29:50.322: INFO: 	Container autoscaler ready: true, restart count 0
Mar  4 22:29:50.322: INFO: ibm-cloud-provider-ip-169-62-14-102-5c8b94578f-6j5h8 from ibm-system started at 2019-03-04 21:30:11 +0000 UTC (1 container statuses recorded)
Mar  4 22:29:50.322: INFO: 	Container ibm-cloud-provider-ip-169-62-14-102 ready: true, restart count 0
Mar  4 22:29:50.322: INFO: 
Logging pods the kubelet thinks is on node 10.190.208.162 before test
Mar  4 22:29:50.384: INFO: ibm-master-proxy-static-10.190.208.162 from kube-system started at <nil> (0 container statuses recorded)
Mar  4 22:29:50.384: INFO: ibm-kube-fluentd-th2p5 from kube-system started at 2019-03-04 21:32:33 +0000 UTC (1 container statuses recorded)
Mar  4 22:29:50.384: INFO: 	Container fluentd ready: true, restart count 0
Mar  4 22:29:50.384: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-03-04 22:09:33 +0000 UTC (1 container statuses recorded)
Mar  4 22:29:50.384: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Mar  4 22:29:50.384: INFO: sonobuoy-e2e-job-13307d6f62184a08 from heptio-sonobuoy started at 2019-03-04 22:09:43 +0000 UTC (2 container statuses recorded)
Mar  4 22:29:50.384: INFO: 	Container e2e ready: true, restart count 0
Mar  4 22:29:50.384: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  4 22:29:50.384: INFO: calico-node-zcgq4 from kube-system started at 2019-03-04 21:30:51 +0000 UTC (2 container statuses recorded)
Mar  4 22:29:50.385: INFO: 	Container calico-node ready: true, restart count 0
Mar  4 22:29:50.385: INFO: 	Container install-cni ready: true, restart count 0
Mar  4 22:29:50.385: INFO: ibm-keepalived-watcher-mw942 from kube-system started at 2019-03-04 21:30:51 +0000 UTC (1 container statuses recorded)
Mar  4 22:29:50.385: INFO: 	Container keepalived-watcher ready: true, restart count 0
Mar  4 22:29:50.385: INFO: public-cr4b0320f2477b4ad1a9b3673fb5e37483-alb1-596b8cfb5f-xfbwf from kube-system started at 2019-03-04 21:34:56 +0000 UTC (4 container statuses recorded)
Mar  4 22:29:50.385: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Mar  4 22:29:50.385: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Mar  4 22:29:50.385: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Mar  4 22:29:50.385: INFO: 	Container nginx-ingress ready: true, restart count 0
Mar  4 22:29:50.385: INFO: sonobuoy-systemd-logs-daemon-set-96866c1b23744a30-86vwv from heptio-sonobuoy started at 2019-03-04 22:09:43 +0000 UTC (2 container statuses recorded)
Mar  4 22:29:50.385: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar  4 22:29:50.385: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  4 22:29:50.385: INFO: 
Logging pods the kubelet thinks is on node 10.190.208.178 before test
Mar  4 22:29:50.415: INFO: metrics-server-6db7656f6c-wm6gm from kube-system started at 2019-03-04 21:29:54 +0000 UTC (2 container statuses recorded)
Mar  4 22:29:50.416: INFO: 	Container metrics-server ready: true, restart count 0
Mar  4 22:29:50.416: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Mar  4 22:29:50.416: INFO: public-cr4b0320f2477b4ad1a9b3673fb5e37483-alb1-596b8cfb5f-trd2m from kube-system started at 2019-03-04 21:34:56 +0000 UTC (4 container statuses recorded)
Mar  4 22:29:50.416: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Mar  4 22:29:50.416: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Mar  4 22:29:50.416: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Mar  4 22:29:50.416: INFO: 	Container nginx-ingress ready: true, restart count 0
Mar  4 22:29:50.416: INFO: sonobuoy-systemd-logs-daemon-set-96866c1b23744a30-mlqpv from heptio-sonobuoy started at 2019-03-04 22:09:43 +0000 UTC (2 container statuses recorded)
Mar  4 22:29:50.416: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar  4 22:29:50.416: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  4 22:29:50.416: INFO: ibm-master-proxy-static-10.190.208.178 from kube-system started at <nil> (0 container statuses recorded)
Mar  4 22:29:50.416: INFO: calico-node-7g6nw from kube-system started at 2019-03-04 21:29:37 +0000 UTC (2 container statuses recorded)
Mar  4 22:29:50.416: INFO: 	Container calico-node ready: true, restart count 0
Mar  4 22:29:50.416: INFO: 	Container install-cni ready: true, restart count 0
Mar  4 22:29:50.416: INFO: kube-dns-amd64-fcdcf59c5-tldtv from kube-system started at 2019-03-04 21:29:47 +0000 UTC (3 container statuses recorded)
Mar  4 22:29:50.416: INFO: 	Container dnsmasq ready: true, restart count 0
Mar  4 22:29:50.416: INFO: 	Container kubedns ready: true, restart count 0
Mar  4 22:29:50.416: INFO: 	Container sidecar ready: true, restart count 0
Mar  4 22:29:50.417: INFO: ibm-keepalived-watcher-fqsjb from kube-system started at 2019-03-04 21:29:37 +0000 UTC (1 container statuses recorded)
Mar  4 22:29:50.417: INFO: 	Container keepalived-watcher ready: true, restart count 0
Mar  4 22:29:50.417: INFO: ibm-cloud-provider-ip-169-62-14-102-5c8b94578f-k5xwv from ibm-system started at 2019-03-04 21:30:11 +0000 UTC (1 container statuses recorded)
Mar  4 22:29:50.417: INFO: 	Container ibm-cloud-provider-ip-169-62-14-102 ready: true, restart count 0
Mar  4 22:29:50.417: INFO: ibm-kube-fluentd-9dt4m from kube-system started at 2019-03-04 21:32:33 +0000 UTC (1 container statuses recorded)
Mar  4 22:29:50.417: INFO: 	Container fluentd ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-0765a294-3ecd-11e9-b56c-8631b5a7dc0e 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-0765a294-3ecd-11e9-b56c-8631b5a7dc0e off the node 10.190.208.160
STEP: verifying the node doesn't have the label kubernetes.io/e2e-0765a294-3ecd-11e9-b56c-8631b5a7dc0e
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:29:54.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-rvmdh" for this suite.
Mar  4 22:30:04.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:30:05.196: INFO: namespace: e2e-tests-sched-pred-rvmdh, resource: bindings, ignored listing per whitelist
Mar  4 22:30:05.341: INFO: namespace e2e-tests-sched-pred-rvmdh deletion completed in 10.753495797s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:15.307 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:30:05.341: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-h747g
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-h747g
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-h747g
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-h747g
Mar  4 22:30:05.595: INFO: Found 0 stateful pods, waiting for 1
Mar  4 22:30:15.611: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Mar  4 22:30:15.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  4 22:30:15.981: INFO: stderr: ""
Mar  4 22:30:15.981: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  4 22:30:15.981: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  4 22:30:15.989: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar  4 22:30:25.996: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  4 22:30:25.996: INFO: Waiting for statefulset status.replicas updated to 0
Mar  4 22:30:26.099: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Mar  4 22:30:26.099: INFO: ss-0  10.190.208.160  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:05 +0000 UTC  }]
Mar  4 22:30:26.099: INFO: 
Mar  4 22:30:26.099: INFO: StatefulSet ss has not reached scale 3, at 1
Mar  4 22:30:27.105: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994378574s
Mar  4 22:30:28.111: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.987664136s
Mar  4 22:30:29.118: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.981546707s
Mar  4 22:30:30.123: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.97522197s
Mar  4 22:30:31.129: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.969647564s
Mar  4 22:30:32.135: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.963592298s
Mar  4 22:30:33.142: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.957530439s
Mar  4 22:30:34.149: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.950532697s
Mar  4 22:30:35.156: INFO: Verifying statefulset ss doesn't scale past 3 for another 943.878279ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-h747g
Mar  4 22:30:36.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:30:36.514: INFO: stderr: ""
Mar  4 22:30:36.514: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  4 22:30:36.514: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  4 22:30:36.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:30:36.810: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Mar  4 22:30:36.810: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  4 22:30:36.810: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  4 22:30:36.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:30:37.137: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Mar  4 22:30:37.137: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  4 22:30:37.137: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  4 22:30:37.143: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  4 22:30:37.143: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  4 22:30:37.143: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Mar  4 22:30:37.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  4 22:30:37.459: INFO: stderr: ""
Mar  4 22:30:37.459: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  4 22:30:37.459: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  4 22:30:37.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  4 22:30:37.766: INFO: stderr: ""
Mar  4 22:30:37.766: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  4 22:30:37.766: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  4 22:30:37.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  4 22:30:38.096: INFO: stderr: ""
Mar  4 22:30:38.096: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  4 22:30:38.096: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  4 22:30:38.096: INFO: Waiting for statefulset status.replicas updated to 0
Mar  4 22:30:38.101: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Mar  4 22:30:48.113: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  4 22:30:48.113: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar  4 22:30:48.113: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar  4 22:30:48.129: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Mar  4 22:30:48.129: INFO: ss-0  10.190.208.160  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:05 +0000 UTC  }]
Mar  4 22:30:48.129: INFO: ss-1  10.190.208.162  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  }]
Mar  4 22:30:48.129: INFO: ss-2  10.190.208.178  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  }]
Mar  4 22:30:48.129: INFO: 
Mar  4 22:30:48.129: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  4 22:30:49.135: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Mar  4 22:30:49.135: INFO: ss-0  10.190.208.160  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:05 +0000 UTC  }]
Mar  4 22:30:49.135: INFO: ss-1  10.190.208.162  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  }]
Mar  4 22:30:49.135: INFO: ss-2  10.190.208.178  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  }]
Mar  4 22:30:49.135: INFO: 
Mar  4 22:30:49.136: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  4 22:30:50.141: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Mar  4 22:30:50.141: INFO: ss-0  10.190.208.160  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:05 +0000 UTC  }]
Mar  4 22:30:50.141: INFO: ss-1  10.190.208.162  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  }]
Mar  4 22:30:50.141: INFO: ss-2  10.190.208.178  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  }]
Mar  4 22:30:50.141: INFO: 
Mar  4 22:30:50.141: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  4 22:30:51.147: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Mar  4 22:30:51.147: INFO: ss-1  10.190.208.162  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  }]
Mar  4 22:30:51.147: INFO: ss-2  10.190.208.178  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  }]
Mar  4 22:30:51.147: INFO: 
Mar  4 22:30:51.147: INFO: StatefulSet ss has not reached scale 0, at 2
Mar  4 22:30:52.153: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Mar  4 22:30:52.153: INFO: ss-1  10.190.208.162  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  }]
Mar  4 22:30:52.153: INFO: ss-2  10.190.208.178  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  }]
Mar  4 22:30:52.153: INFO: 
Mar  4 22:30:52.153: INFO: StatefulSet ss has not reached scale 0, at 2
Mar  4 22:30:53.159: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Mar  4 22:30:53.159: INFO: ss-1  10.190.208.162  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  }]
Mar  4 22:30:53.159: INFO: ss-2  10.190.208.178  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  }]
Mar  4 22:30:53.159: INFO: 
Mar  4 22:30:53.159: INFO: StatefulSet ss has not reached scale 0, at 2
Mar  4 22:30:54.166: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Mar  4 22:30:54.166: INFO: ss-1  10.190.208.162  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  }]
Mar  4 22:30:54.166: INFO: ss-2  10.190.208.178  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  }]
Mar  4 22:30:54.166: INFO: 
Mar  4 22:30:54.166: INFO: StatefulSet ss has not reached scale 0, at 2
Mar  4 22:30:55.172: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Mar  4 22:30:55.172: INFO: ss-1  10.190.208.162  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  }]
Mar  4 22:30:55.172: INFO: ss-2  10.190.208.178  Pending  0s     [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  }]
Mar  4 22:30:55.172: INFO: 
Mar  4 22:30:55.172: INFO: StatefulSet ss has not reached scale 0, at 2
Mar  4 22:30:56.178: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Mar  4 22:30:56.179: INFO: ss-1  10.190.208.162  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  }]
Mar  4 22:30:56.179: INFO: 
Mar  4 22:30:56.179: INFO: StatefulSet ss has not reached scale 0, at 1
Mar  4 22:30:57.184: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Mar  4 22:30:57.184: INFO: ss-1  10.190.208.162  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:30:26 +0000 UTC  }]
Mar  4 22:30:57.184: INFO: 
Mar  4 22:30:57.185: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-h747g
Mar  4 22:30:58.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:30:58.452: INFO: rc: 1
Mar  4 22:30:58.453: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc421873200 exit status 1 <nil> <nil> true [0xc42112af18 0xc42112af50 0xc42112af88] [0xc42112af18 0xc42112af50 0xc42112af88] [0xc42112af48 0xc42112af70] [0x8fd520 0x8fd520] 0xc421cda600 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Mar  4 22:31:08.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:31:08.554: INFO: rc: 1
Mar  4 22:31:08.554: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421fadef0 exit status 1 <nil> <nil> true [0xc4210ff1d0 0xc4210ff218 0xc4210ff250] [0xc4210ff1d0 0xc4210ff218 0xc4210ff250] [0xc4210ff1f8 0xc4210ff248] [0x8fd520 0x8fd520] 0xc421b9bce0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar  4 22:31:18.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:31:18.668: INFO: rc: 1
Mar  4 22:31:18.668: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc42236e360 exit status 1 <nil> <nil> true [0xc4210ff258 0xc4210ff270 0xc4210ff288] [0xc4210ff258 0xc4210ff270 0xc4210ff288] [0xc4210ff268 0xc4210ff280] [0x8fd520 0x8fd520] 0xc421b9be60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar  4 22:31:28.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:31:28.791: INFO: rc: 1
Mar  4 22:31:28.791: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc42236e870 exit status 1 <nil> <nil> true [0xc4210ff290 0xc4210ff2a8 0xc4210ff2c0] [0xc4210ff290 0xc4210ff2a8 0xc4210ff2c0] [0xc4210ff2a0 0xc4210ff2b8] [0x8fd520 0x8fd520] 0xc421b9bf80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar  4 22:31:38.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:31:38.925: INFO: rc: 1
Mar  4 22:31:38.925: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4218736b0 exit status 1 <nil> <nil> true [0xc42112af90 0xc42112afc8 0xc42112b010] [0xc42112af90 0xc42112afc8 0xc42112b010] [0xc42112afb0 0xc42112aff8] [0x8fd520 0x8fd520] 0xc421cda720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar  4 22:31:48.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:31:49.092: INFO: rc: 1
Mar  4 22:31:49.092: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc42236ed20 exit status 1 <nil> <nil> true [0xc4210ff2c8 0xc4210ff2e0 0xc4210ff2f8] [0xc4210ff2c8 0xc4210ff2e0 0xc4210ff2f8] [0xc4210ff2d8 0xc4210ff2f0] [0x8fd520 0x8fd520] 0xc421dd20c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar  4 22:31:59.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:31:59.236: INFO: rc: 1
Mar  4 22:31:59.236: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421fac5a0 exit status 1 <nil> <nil> true [0xc4210fe008 0xc4210fe020 0xc4210fe040] [0xc4210fe008 0xc4210fe020 0xc4210fe040] [0xc4210fe018 0xc4210fe038] [0x8fd520 0x8fd520] 0xc421ce0000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar  4 22:32:09.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:32:09.364: INFO: rc: 1
Mar  4 22:32:09.364: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4218ac690 exit status 1 <nil> <nil> true [0xc42112a000 0xc42112a018 0xc42112a030] [0xc42112a000 0xc42112a018 0xc42112a030] [0xc42112a010 0xc42112a028] [0x8fd520 0x8fd520] 0xc421b9a660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar  4 22:32:19.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:32:19.777: INFO: rc: 1
Mar  4 22:32:19.777: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4218aca80 exit status 1 <nil> <nil> true [0xc42112a038 0xc42112a050 0xc42112a068] [0xc42112a038 0xc42112a050 0xc42112a068] [0xc42112a048 0xc42112a060] [0x8fd520 0x8fd520] 0xc421b9a780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar  4 22:32:29.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:32:29.985: INFO: rc: 1
Mar  4 22:32:29.985: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421facb10 exit status 1 <nil> <nil> true [0xc4210fe048 0xc4210fe060 0xc4210fe078] [0xc4210fe048 0xc4210fe060 0xc4210fe078] [0xc4210fe058 0xc4210fe070] [0x8fd520 0x8fd520] 0xc421ce0120 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar  4 22:32:39.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:32:40.104: INFO: rc: 1
Mar  4 22:32:40.104: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4218acff0 exit status 1 <nil> <nil> true [0xc42112a070 0xc42112a088 0xc42112a0a0] [0xc42112a070 0xc42112a088 0xc42112a0a0] [0xc42112a080 0xc42112a098] [0x8fd520 0x8fd520] 0xc421b9a8a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar  4 22:32:50.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:32:50.229: INFO: rc: 1
Mar  4 22:32:50.229: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421facf30 exit status 1 <nil> <nil> true [0xc4210fe080 0xc4210fe098 0xc4210fe0b0] [0xc4210fe080 0xc4210fe098 0xc4210fe0b0] [0xc4210fe090 0xc4210fe0a8] [0x8fd520 0x8fd520] 0xc421ce0240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar  4 22:33:00.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:33:00.346: INFO: rc: 1
Mar  4 22:33:00.347: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4218ad470 exit status 1 <nil> <nil> true [0xc42112a0a8 0xc42112a0c0 0xc42112a0d8] [0xc42112a0a8 0xc42112a0c0 0xc42112a0d8] [0xc42112a0b8 0xc42112a0d0] [0x8fd520 0x8fd520] 0xc421b9a9c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar  4 22:33:10.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:33:10.480: INFO: rc: 1
Mar  4 22:33:10.480: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4218ad8c0 exit status 1 <nil> <nil> true [0xc42112a0e0 0xc42112a0f8 0xc42112a110] [0xc42112a0e0 0xc42112a0f8 0xc42112a110] [0xc42112a0f0 0xc42112a108] [0x8fd520 0x8fd520] 0xc421b9aae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar  4 22:33:20.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:33:20.601: INFO: rc: 1
Mar  4 22:33:20.601: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4218adcb0 exit status 1 <nil> <nil> true [0xc42112a118 0xc42112a130 0xc42112a150] [0xc42112a118 0xc42112a130 0xc42112a150] [0xc42112a128 0xc42112a148] [0x8fd520 0x8fd520] 0xc421b9ac60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar  4 22:33:30.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:33:30.712: INFO: rc: 1
Mar  4 22:33:30.712: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc422872270 exit status 1 <nil> <nil> true [0xc42112a168 0xc42112a188 0xc42112a1a0] [0xc42112a168 0xc42112a188 0xc42112a1a0] [0xc42112a180 0xc42112a198] [0x8fd520 0x8fd520] 0xc421b9ade0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar  4 22:33:40.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:33:40.842: INFO: rc: 1
Mar  4 22:33:40.842: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc422872750 exit status 1 <nil> <nil> true [0xc42112a1a8 0xc42112a1c8 0xc42112a1e8] [0xc42112a1a8 0xc42112a1c8 0xc42112a1e8] [0xc42112a1b8 0xc42112a1e0] [0x8fd520 0x8fd520] 0xc421b9af00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar  4 22:33:50.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:33:50.987: INFO: rc: 1
Mar  4 22:33:50.987: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc422872bd0 exit status 1 <nil> <nil> true [0xc42112a1f8 0xc42112a210 0xc42112a228] [0xc42112a1f8 0xc42112a210 0xc42112a228] [0xc42112a208 0xc42112a220] [0x8fd520 0x8fd520] 0xc421b9b080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar  4 22:34:00.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:34:01.143: INFO: rc: 1
Mar  4 22:34:01.144: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc422872fc0 exit status 1 <nil> <nil> true [0xc42112a238 0xc42112a250 0xc42112a268] [0xc42112a238 0xc42112a250 0xc42112a268] [0xc42112a248 0xc42112a260] [0x8fd520 0x8fd520] 0xc421b9b140 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar  4 22:34:11.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:34:11.285: INFO: rc: 1
Mar  4 22:34:11.285: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421fac570 exit status 1 <nil> <nil> true [0xc4210fe000 0xc4210fe018 0xc4210fe038] [0xc4210fe000 0xc4210fe018 0xc4210fe038] [0xc4210fe010 0xc4210fe030] [0x8fd520 0x8fd520] 0xc421ce0000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar  4 22:34:21.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:34:21.409: INFO: rc: 1
Mar  4 22:34:21.409: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4218ac6c0 exit status 1 <nil> <nil> true [0xc42112a000 0xc42112a018 0xc42112a030] [0xc42112a000 0xc42112a018 0xc42112a030] [0xc42112a010 0xc42112a028] [0x8fd520 0x8fd520] 0xc421b9a660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar  4 22:34:31.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:34:31.519: INFO: rc: 1
Mar  4 22:34:31.519: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421facb40 exit status 1 <nil> <nil> true [0xc4210fe040 0xc4210fe058 0xc4210fe070] [0xc4210fe040 0xc4210fe058 0xc4210fe070] [0xc4210fe050 0xc4210fe068] [0x8fd520 0x8fd520] 0xc421ce0120 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar  4 22:34:41.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:34:41.659: INFO: rc: 1
Mar  4 22:34:41.659: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421facfc0 exit status 1 <nil> <nil> true [0xc4210fe078 0xc4210fe090 0xc4210fe0a8] [0xc4210fe078 0xc4210fe090 0xc4210fe0a8] [0xc4210fe088 0xc4210fe0a0] [0x8fd520 0x8fd520] 0xc421ce0240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar  4 22:34:51.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:34:51.795: INFO: rc: 1
Mar  4 22:34:51.796: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4218acb40 exit status 1 <nil> <nil> true [0xc42112a038 0xc42112a050 0xc42112a068] [0xc42112a038 0xc42112a050 0xc42112a068] [0xc42112a048 0xc42112a060] [0x8fd520 0x8fd520] 0xc421b9a780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar  4 22:35:01.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:35:01.935: INFO: rc: 1
Mar  4 22:35:01.935: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4218ad0e0 exit status 1 <nil> <nil> true [0xc42112a070 0xc42112a088 0xc42112a0a0] [0xc42112a070 0xc42112a088 0xc42112a0a0] [0xc42112a080 0xc42112a098] [0x8fd520 0x8fd520] 0xc421b9a8a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar  4 22:35:11.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:35:12.032: INFO: rc: 1
Mar  4 22:35:12.032: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421fad470 exit status 1 <nil> <nil> true [0xc4210fe0b0 0xc4210fe0c8 0xc4210fe0e0] [0xc4210fe0b0 0xc4210fe0c8 0xc4210fe0e0] [0xc4210fe0c0 0xc4210fe0d8] [0x8fd520 0x8fd520] 0xc421ce03c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar  4 22:35:22.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:35:22.205: INFO: rc: 1
Mar  4 22:35:22.205: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4218ad560 exit status 1 <nil> <nil> true [0xc42112a0a8 0xc42112a0c0 0xc42112a0d8] [0xc42112a0a8 0xc42112a0c0 0xc42112a0d8] [0xc42112a0b8 0xc42112a0d0] [0x8fd520 0x8fd520] 0xc421b9a9c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar  4 22:35:32.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:35:32.351: INFO: rc: 1
Mar  4 22:35:32.351: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421fad8c0 exit status 1 <nil> <nil> true [0xc4210fe0e8 0xc4210fe100 0xc4210fe118] [0xc4210fe0e8 0xc4210fe100 0xc4210fe118] [0xc4210fe0f8 0xc4210fe110] [0x8fd520 0x8fd520] 0xc421ce04e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar  4 22:35:42.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:35:42.507: INFO: rc: 1
Mar  4 22:35:42.507: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421fadcb0 exit status 1 <nil> <nil> true [0xc4210fe120 0xc4210fe138 0xc4210fe150] [0xc4210fe120 0xc4210fe138 0xc4210fe150] [0xc4210fe130 0xc4210fe148] [0x8fd520 0x8fd520] 0xc421ce0600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar  4 22:35:52.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:35:52.663: INFO: rc: 1
Mar  4 22:35:52.664: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4218ad9b0 exit status 1 <nil> <nil> true [0xc42112a0e0 0xc42112a0f8 0xc42112a110] [0xc42112a0e0 0xc42112a0f8 0xc42112a110] [0xc42112a0f0 0xc42112a108] [0x8fd520 0x8fd520] 0xc421b9aae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar  4 22:36:02.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-h747g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 22:36:02.791: INFO: rc: 1
Mar  4 22:36:02.791: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: 
Mar  4 22:36:02.791: INFO: Scaling statefulset ss to 0
Mar  4 22:36:02.893: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar  4 22:36:02.898: INFO: Deleting all statefulset in ns e2e-tests-statefulset-h747g
Mar  4 22:36:02.903: INFO: Scaling statefulset ss to 0
Mar  4 22:36:02.916: INFO: Waiting for statefulset status.replicas updated to 0
Mar  4 22:36:02.921: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:36:02.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-h747g" for this suite.
Mar  4 22:36:10.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:36:11.364: INFO: namespace: e2e-tests-statefulset-h747g, resource: bindings, ignored listing per whitelist
Mar  4 22:36:11.414: INFO: namespace e2e-tests-statefulset-h747g deletion completed in 8.456651767s

• [SLOW TEST:366.073 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:36:11.414: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-v2sj7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  4 22:36:11.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 version'
Mar  4 22:36:11.814: INFO: stderr: ""
Mar  4 22:36:11.814: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.6+IKS\", GitCommit:\"2c3eb23229edae9a1f164f323d76a3192d94bccc\", GitTreeState:\"clean\", BuildDate:\"2019-02-28T08:09:00Z\", GoVersion:\"go1.10.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:36:11.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-v2sj7" for this suite.
Mar  4 22:36:17.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:36:18.222: INFO: namespace: e2e-tests-kubectl-v2sj7, resource: bindings, ignored listing per whitelist
Mar  4 22:36:18.348: INFO: namespace e2e-tests-kubectl-v2sj7 deletion completed in 6.523922329s

• [SLOW TEST:6.934 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:36:18.349: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-vnrzk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar  4 22:36:23.126: INFO: Successfully updated pod "pod-update-ed879010-3ecd-11e9-b56c-8631b5a7dc0e"
STEP: verifying the updated pod is in kubernetes
Mar  4 22:36:23.188: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:36:23.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-vnrzk" for this suite.
Mar  4 22:36:45.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:36:45.313: INFO: namespace: e2e-tests-pods-vnrzk, resource: bindings, ignored listing per whitelist
Mar  4 22:36:45.514: INFO: namespace e2e-tests-pods-vnrzk deletion completed in 22.314730875s

• [SLOW TEST:27.165 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:36:45.516: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-tcl2v
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar  4 22:36:45.816: INFO: Number of nodes with available pods: 0
Mar  4 22:36:45.816: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:36:46.836: INFO: Number of nodes with available pods: 0
Mar  4 22:36:46.836: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:36:47.834: INFO: Number of nodes with available pods: 1
Mar  4 22:36:47.834: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:36:48.835: INFO: Number of nodes with available pods: 1
Mar  4 22:36:48.835: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:36:49.835: INFO: Number of nodes with available pods: 3
Mar  4 22:36:49.835: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Mar  4 22:36:49.915: INFO: Number of nodes with available pods: 2
Mar  4 22:36:49.915: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:36:50.934: INFO: Number of nodes with available pods: 2
Mar  4 22:36:50.934: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:36:51.932: INFO: Number of nodes with available pods: 2
Mar  4 22:36:51.932: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:36:53.382: INFO: Number of nodes with available pods: 2
Mar  4 22:36:53.382: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:36:53.931: INFO: Number of nodes with available pods: 2
Mar  4 22:36:53.931: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:36:54.995: INFO: Number of nodes with available pods: 2
Mar  4 22:36:54.995: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:36:55.933: INFO: Number of nodes with available pods: 2
Mar  4 22:36:55.933: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:36:56.931: INFO: Number of nodes with available pods: 2
Mar  4 22:36:56.931: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:36:57.983: INFO: Number of nodes with available pods: 2
Mar  4 22:36:57.983: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:36:58.932: INFO: Number of nodes with available pods: 2
Mar  4 22:36:58.932: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:36:59.932: INFO: Number of nodes with available pods: 2
Mar  4 22:36:59.932: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:00.930: INFO: Number of nodes with available pods: 2
Mar  4 22:37:00.930: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:01.932: INFO: Number of nodes with available pods: 2
Mar  4 22:37:01.932: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:02.932: INFO: Number of nodes with available pods: 2
Mar  4 22:37:02.932: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:03.983: INFO: Number of nodes with available pods: 2
Mar  4 22:37:03.983: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:04.933: INFO: Number of nodes with available pods: 2
Mar  4 22:37:04.933: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:05.932: INFO: Number of nodes with available pods: 2
Mar  4 22:37:05.932: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:06.983: INFO: Number of nodes with available pods: 2
Mar  4 22:37:06.983: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:07.931: INFO: Number of nodes with available pods: 2
Mar  4 22:37:07.931: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:08.934: INFO: Number of nodes with available pods: 2
Mar  4 22:37:08.934: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:09.932: INFO: Number of nodes with available pods: 2
Mar  4 22:37:09.932: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:10.983: INFO: Number of nodes with available pods: 2
Mar  4 22:37:10.983: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:11.932: INFO: Number of nodes with available pods: 2
Mar  4 22:37:11.932: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:12.993: INFO: Number of nodes with available pods: 2
Mar  4 22:37:12.993: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:13.931: INFO: Number of nodes with available pods: 2
Mar  4 22:37:13.931: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:14.933: INFO: Number of nodes with available pods: 2
Mar  4 22:37:14.934: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:15.932: INFO: Number of nodes with available pods: 2
Mar  4 22:37:15.932: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:16.932: INFO: Number of nodes with available pods: 2
Mar  4 22:37:16.932: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:17.934: INFO: Number of nodes with available pods: 2
Mar  4 22:37:17.934: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:18.983: INFO: Number of nodes with available pods: 2
Mar  4 22:37:18.983: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:19.931: INFO: Number of nodes with available pods: 2
Mar  4 22:37:19.931: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:20.935: INFO: Number of nodes with available pods: 2
Mar  4 22:37:20.935: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:21.932: INFO: Number of nodes with available pods: 2
Mar  4 22:37:21.932: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:22.932: INFO: Number of nodes with available pods: 2
Mar  4 22:37:22.932: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:23.932: INFO: Number of nodes with available pods: 2
Mar  4 22:37:23.932: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:24.931: INFO: Number of nodes with available pods: 2
Mar  4 22:37:24.932: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:25.932: INFO: Number of nodes with available pods: 2
Mar  4 22:37:25.932: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:26.933: INFO: Number of nodes with available pods: 2
Mar  4 22:37:26.933: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:28.346: INFO: Number of nodes with available pods: 2
Mar  4 22:37:28.347: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:28.983: INFO: Number of nodes with available pods: 2
Mar  4 22:37:28.983: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:29.932: INFO: Number of nodes with available pods: 2
Mar  4 22:37:29.932: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:30.931: INFO: Number of nodes with available pods: 2
Mar  4 22:37:30.931: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:37:31.933: INFO: Number of nodes with available pods: 3
Mar  4 22:37:31.933: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-tcl2v, will wait for the garbage collector to delete the pods
Mar  4 22:37:32.006: INFO: Deleting {extensions DaemonSet} daemon-set took: 12.002536ms
Mar  4 22:37:32.306: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 300.286865ms
Mar  4 22:38:15.211: INFO: Number of nodes with available pods: 0
Mar  4 22:38:15.211: INFO: Number of running nodes: 0, number of available pods: 0
Mar  4 22:38:15.215: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-tcl2v/daemonsets","resourceVersion":"13093"},"items":null}

Mar  4 22:38:15.219: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-tcl2v/pods","resourceVersion":"13093"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:38:15.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-tcl2v" for this suite.
Mar  4 22:38:21.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:38:21.397: INFO: namespace: e2e-tests-daemonsets-tcl2v, resource: bindings, ignored listing per whitelist
Mar  4 22:38:22.013: INFO: namespace e2e-tests-daemonsets-tcl2v deletion completed in 6.752384743s

• [SLOW TEST:96.497 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:38:22.014: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-f7b2r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-f7b2r
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  4 22:38:22.263: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  4 22:38:46.417: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.86.153:8080/dial?request=hostName&protocol=http&host=172.30.87.141&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-f7b2r PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  4 22:38:46.417: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
Mar  4 22:38:46.640: INFO: Waiting for endpoints: map[]
Mar  4 22:38:46.646: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.86.153:8080/dial?request=hostName&protocol=http&host=172.30.86.152&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-f7b2r PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  4 22:38:46.646: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
Mar  4 22:38:46.857: INFO: Waiting for endpoints: map[]
Mar  4 22:38:46.863: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.86.153:8080/dial?request=hostName&protocol=http&host=172.30.252.207&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-f7b2r PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  4 22:38:46.863: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
Mar  4 22:38:47.062: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:38:47.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-f7b2r" for this suite.
Mar  4 22:39:11.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:39:11.253: INFO: namespace: e2e-tests-pod-network-test-f7b2r, resource: bindings, ignored listing per whitelist
Mar  4 22:39:11.432: INFO: namespace e2e-tests-pod-network-test-f7b2r deletion completed in 24.358597912s

• [SLOW TEST:49.418 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:39:11.435: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-r9f58
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-54b5c1cf-3ece-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume configMaps
Mar  4 22:39:11.799: INFO: Waiting up to 5m0s for pod "pod-configmaps-54c4fc2f-3ece-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-configmap-r9f58" to be "success or failure"
Mar  4 22:39:11.804: INFO: Pod "pod-configmaps-54c4fc2f-3ece-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.173694ms
Mar  4 22:39:13.810: INFO: Pod "pod-configmaps-54c4fc2f-3ece-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010359476s
STEP: Saw pod success
Mar  4 22:39:13.810: INFO: Pod "pod-configmaps-54c4fc2f-3ece-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:39:13.815: INFO: Trying to get logs from node 10.190.208.160 pod pod-configmaps-54c4fc2f-3ece-11e9-b56c-8631b5a7dc0e container configmap-volume-test: <nil>
STEP: delete the pod
Mar  4 22:39:13.852: INFO: Waiting for pod pod-configmaps-54c4fc2f-3ece-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:39:13.858: INFO: Pod pod-configmaps-54c4fc2f-3ece-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:39:13.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-r9f58" for this suite.
Mar  4 22:39:19.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:39:20.071: INFO: namespace: e2e-tests-configmap-r9f58, resource: bindings, ignored listing per whitelist
Mar  4 22:39:20.202: INFO: namespace e2e-tests-configmap-r9f58 deletion completed in 6.310352979s

• [SLOW TEST:8.768 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:39:20.203: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-krtcw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-krtcw
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-krtcw
STEP: Deleting pre-stop pod
Mar  4 22:39:33.550: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:39:33.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-krtcw" for this suite.
Mar  4 22:40:13.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:40:13.764: INFO: namespace: e2e-tests-prestop-krtcw, resource: bindings, ignored listing per whitelist
Mar  4 22:40:13.921: INFO: namespace e2e-tests-prestop-krtcw deletion completed in 40.351190185s

• [SLOW TEST:53.719 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:40:13.922: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-8tn6k
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar  4 22:40:14.171: INFO: Waiting up to 5m0s for pod "pod-79f23885-3ece-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-emptydir-8tn6k" to be "success or failure"
Mar  4 22:40:14.175: INFO: Pod "pod-79f23885-3ece-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.502658ms
Mar  4 22:40:16.181: INFO: Pod "pod-79f23885-3ece-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010402861s
STEP: Saw pod success
Mar  4 22:40:16.181: INFO: Pod "pod-79f23885-3ece-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:40:16.186: INFO: Trying to get logs from node 10.190.208.160 pod pod-79f23885-3ece-11e9-b56c-8631b5a7dc0e container test-container: <nil>
STEP: delete the pod
Mar  4 22:40:16.219: INFO: Waiting for pod pod-79f23885-3ece-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:40:16.225: INFO: Pod pod-79f23885-3ece-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:40:16.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8tn6k" for this suite.
Mar  4 22:40:22.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:40:22.611: INFO: namespace: e2e-tests-emptydir-8tn6k, resource: bindings, ignored listing per whitelist
Mar  4 22:40:22.611: INFO: namespace e2e-tests-emptydir-8tn6k deletion completed in 6.327950123s

• [SLOW TEST:8.689 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:40:22.613: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-hdsqd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Mar  4 22:40:23.190: INFO: Waiting up to 5m0s for pod "client-containers-7f1e9549-3ece-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-containers-hdsqd" to be "success or failure"
Mar  4 22:40:23.195: INFO: Pod "client-containers-7f1e9549-3ece-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.858566ms
Mar  4 22:40:25.201: INFO: Pod "client-containers-7f1e9549-3ece-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010987751s
STEP: Saw pod success
Mar  4 22:40:25.201: INFO: Pod "client-containers-7f1e9549-3ece-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:40:25.207: INFO: Trying to get logs from node 10.190.208.160 pod client-containers-7f1e9549-3ece-11e9-b56c-8631b5a7dc0e container test-container: <nil>
STEP: delete the pod
Mar  4 22:40:25.297: INFO: Waiting for pod client-containers-7f1e9549-3ece-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:40:25.303: INFO: Pod client-containers-7f1e9549-3ece-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:40:25.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-hdsqd" for this suite.
Mar  4 22:40:31.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:40:31.797: INFO: namespace: e2e-tests-containers-hdsqd, resource: bindings, ignored listing per whitelist
Mar  4 22:40:31.829: INFO: namespace e2e-tests-containers-hdsqd deletion completed in 6.517042186s

• [SLOW TEST:9.216 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:40:31.830: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-6dgs4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-84a06110-3ece-11e9-b56c-8631b5a7dc0e
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-84a06110-3ece-11e9-b56c-8631b5a7dc0e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:40:36.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6dgs4" for this suite.
Mar  4 22:41:08.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:41:08.356: INFO: namespace: e2e-tests-projected-6dgs4, resource: bindings, ignored listing per whitelist
Mar  4 22:41:08.596: INFO: namespace e2e-tests-projected-6dgs4 deletion completed in 32.409201744s

• [SLOW TEST:36.767 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:41:08.597: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-fmjdl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Mar  4 22:41:08.912: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fmjdl,SelfLink:/api/v1/namespaces/e2e-tests-watch-fmjdl/configmaps/e2e-watch-test-configmap-a,UID:9a938a54-3ece-11e9-967c-c655790ff683,ResourceVersion:13771,Generation:0,CreationTimestamp:2019-03-04 22:41:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  4 22:41:08.912: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fmjdl,SelfLink:/api/v1/namespaces/e2e-tests-watch-fmjdl/configmaps/e2e-watch-test-configmap-a,UID:9a938a54-3ece-11e9-967c-c655790ff683,ResourceVersion:13771,Generation:0,CreationTimestamp:2019-03-04 22:41:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Mar  4 22:41:18.926: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fmjdl,SelfLink:/api/v1/namespaces/e2e-tests-watch-fmjdl/configmaps/e2e-watch-test-configmap-a,UID:9a938a54-3ece-11e9-967c-c655790ff683,ResourceVersion:13787,Generation:0,CreationTimestamp:2019-03-04 22:41:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar  4 22:41:18.926: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fmjdl,SelfLink:/api/v1/namespaces/e2e-tests-watch-fmjdl/configmaps/e2e-watch-test-configmap-a,UID:9a938a54-3ece-11e9-967c-c655790ff683,ResourceVersion:13787,Generation:0,CreationTimestamp:2019-03-04 22:41:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Mar  4 22:41:28.939: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fmjdl,SelfLink:/api/v1/namespaces/e2e-tests-watch-fmjdl/configmaps/e2e-watch-test-configmap-a,UID:9a938a54-3ece-11e9-967c-c655790ff683,ResourceVersion:13806,Generation:0,CreationTimestamp:2019-03-04 22:41:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  4 22:41:28.939: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fmjdl,SelfLink:/api/v1/namespaces/e2e-tests-watch-fmjdl/configmaps/e2e-watch-test-configmap-a,UID:9a938a54-3ece-11e9-967c-c655790ff683,ResourceVersion:13806,Generation:0,CreationTimestamp:2019-03-04 22:41:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Mar  4 22:41:38.951: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fmjdl,SelfLink:/api/v1/namespaces/e2e-tests-watch-fmjdl/configmaps/e2e-watch-test-configmap-a,UID:9a938a54-3ece-11e9-967c-c655790ff683,ResourceVersion:13823,Generation:0,CreationTimestamp:2019-03-04 22:41:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  4 22:41:38.951: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fmjdl,SelfLink:/api/v1/namespaces/e2e-tests-watch-fmjdl/configmaps/e2e-watch-test-configmap-a,UID:9a938a54-3ece-11e9-967c-c655790ff683,ResourceVersion:13823,Generation:0,CreationTimestamp:2019-03-04 22:41:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Mar  4 22:41:48.964: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-fmjdl,SelfLink:/api/v1/namespaces/e2e-tests-watch-fmjdl/configmaps/e2e-watch-test-configmap-b,UID:b27224c8-3ece-11e9-967c-c655790ff683,ResourceVersion:13840,Generation:0,CreationTimestamp:2019-03-04 22:41:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  4 22:41:48.964: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-fmjdl,SelfLink:/api/v1/namespaces/e2e-tests-watch-fmjdl/configmaps/e2e-watch-test-configmap-b,UID:b27224c8-3ece-11e9-967c-c655790ff683,ResourceVersion:13840,Generation:0,CreationTimestamp:2019-03-04 22:41:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Mar  4 22:41:58.976: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-fmjdl,SelfLink:/api/v1/namespaces/e2e-tests-watch-fmjdl/configmaps/e2e-watch-test-configmap-b,UID:b27224c8-3ece-11e9-967c-c655790ff683,ResourceVersion:13857,Generation:0,CreationTimestamp:2019-03-04 22:41:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  4 22:41:58.976: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-fmjdl,SelfLink:/api/v1/namespaces/e2e-tests-watch-fmjdl/configmaps/e2e-watch-test-configmap-b,UID:b27224c8-3ece-11e9-967c-c655790ff683,ResourceVersion:13857,Generation:0,CreationTimestamp:2019-03-04 22:41:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:42:08.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-fmjdl" for this suite.
Mar  4 22:42:15.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:42:15.141: INFO: namespace: e2e-tests-watch-fmjdl, resource: bindings, ignored listing per whitelist
Mar  4 22:42:15.453: INFO: namespace e2e-tests-watch-fmjdl deletion completed in 6.464565421s

• [SLOW TEST:66.856 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:42:15.454: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-4f5ff
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-4f5ff
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  4 22:42:15.703: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  4 22:42:35.913: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.86.155:8080/dial?request=hostName&protocol=udp&host=172.30.86.154&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-4f5ff PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  4 22:42:35.913: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
Mar  4 22:42:36.215: INFO: Waiting for endpoints: map[]
Mar  4 22:42:36.288: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.86.155:8080/dial?request=hostName&protocol=udp&host=172.30.252.208&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-4f5ff PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  4 22:42:36.288: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
Mar  4 22:42:36.515: INFO: Waiting for endpoints: map[]
Mar  4 22:42:36.521: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.86.155:8080/dial?request=hostName&protocol=udp&host=172.30.87.148&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-4f5ff PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  4 22:42:36.521: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
Mar  4 22:42:36.745: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:42:36.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-4f5ff" for this suite.
Mar  4 22:43:00.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:43:01.165: INFO: namespace: e2e-tests-pod-network-test-4f5ff, resource: bindings, ignored listing per whitelist
Mar  4 22:43:01.171: INFO: namespace e2e-tests-pod-network-test-4f5ff deletion completed in 24.413423074s

• [SLOW TEST:45.717 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:43:01.171: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-ppvkj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-ppvkj
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-ppvkj to expose endpoints map[]
Mar  4 22:43:01.443: INFO: Get endpoints failed (11.052523ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Mar  4 22:43:02.452: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-ppvkj exposes endpoints map[] (1.020043525s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-ppvkj
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-ppvkj to expose endpoints map[pod1:[80]]
Mar  4 22:43:04.509: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-ppvkj exposes endpoints map[pod1:[80]] (2.046847391s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-ppvkj
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-ppvkj to expose endpoints map[pod1:[80] pod2:[80]]
Mar  4 22:43:07.590: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-ppvkj exposes endpoints map[pod1:[80] pod2:[80]] (3.0747585s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-ppvkj
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-ppvkj to expose endpoints map[pod2:[80]]
Mar  4 22:43:08.625: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-ppvkj exposes endpoints map[pod2:[80]] (1.025151157s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-ppvkj
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-ppvkj to expose endpoints map[]
Mar  4 22:43:09.662: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-ppvkj exposes endpoints map[] (1.027433264s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:43:09.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-ppvkj" for this suite.
Mar  4 22:43:33.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:43:34.000: INFO: namespace: e2e-tests-services-ppvkj, resource: bindings, ignored listing per whitelist
Mar  4 22:43:34.005: INFO: namespace e2e-tests-services-ppvkj deletion completed in 24.275282929s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:32.834 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:43:34.006: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-hzk5b
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  4 22:43:34.318: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"f13d8c08-3ece-11e9-967c-c655790ff683", Controller:(*bool)(0xc42190f8ae), BlockOwnerDeletion:(*bool)(0xc42190f8af)}}
Mar  4 22:43:34.327: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"f13b5d06-3ece-11e9-967c-c655790ff683", Controller:(*bool)(0xc4209fbe2e), BlockOwnerDeletion:(*bool)(0xc4209fbe2f)}}
Mar  4 22:43:34.334: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"f13c5aa8-3ece-11e9-967c-c655790ff683", Controller:(*bool)(0xc421d7230e), BlockOwnerDeletion:(*bool)(0xc421d7230f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:43:39.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-hzk5b" for this suite.
Mar  4 22:43:45.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:43:45.535: INFO: namespace: e2e-tests-gc-hzk5b, resource: bindings, ignored listing per whitelist
Mar  4 22:43:45.751: INFO: namespace e2e-tests-gc-hzk5b deletion completed in 6.390958041s

• [SLOW TEST:11.746 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:43:45.752: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-bfps8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  4 22:43:45.987: INFO: Creating ReplicaSet my-hostname-basic-f8345929-3ece-11e9-b56c-8631b5a7dc0e
Mar  4 22:43:46.000: INFO: Pod name my-hostname-basic-f8345929-3ece-11e9-b56c-8631b5a7dc0e: Found 0 pods out of 1
Mar  4 22:43:51.005: INFO: Pod name my-hostname-basic-f8345929-3ece-11e9-b56c-8631b5a7dc0e: Found 1 pods out of 1
Mar  4 22:43:51.005: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-f8345929-3ece-11e9-b56c-8631b5a7dc0e" is running
Mar  4 22:43:51.010: INFO: Pod "my-hostname-basic-f8345929-3ece-11e9-b56c-8631b5a7dc0e-kng8q" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-04 22:43:46 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-04 22:43:47 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-04 22:43:47 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-04 22:43:46 +0000 UTC Reason: Message:}])
Mar  4 22:43:51.010: INFO: Trying to dial the pod
Mar  4 22:43:56.031: INFO: Controller my-hostname-basic-f8345929-3ece-11e9-b56c-8631b5a7dc0e: Got expected result from replica 1 [my-hostname-basic-f8345929-3ece-11e9-b56c-8631b5a7dc0e-kng8q]: "my-hostname-basic-f8345929-3ece-11e9-b56c-8631b5a7dc0e-kng8q", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:43:56.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-bfps8" for this suite.
Mar  4 22:44:02.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:44:02.371: INFO: namespace: e2e-tests-replicaset-bfps8, resource: bindings, ignored listing per whitelist
Mar  4 22:44:02.505: INFO: namespace e2e-tests-replicaset-bfps8 deletion completed in 6.463364601s

• [SLOW TEST:16.754 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:44:02.508: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-p9qg7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-023164a2-3ecf-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume secrets
Mar  4 22:44:02.761: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-02323fec-3ecf-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-projected-p9qg7" to be "success or failure"
Mar  4 22:44:02.766: INFO: Pod "pod-projected-secrets-02323fec-3ecf-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.527071ms
Mar  4 22:44:04.772: INFO: Pod "pod-projected-secrets-02323fec-3ecf-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010541584s
STEP: Saw pod success
Mar  4 22:44:04.772: INFO: Pod "pod-projected-secrets-02323fec-3ecf-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:44:04.776: INFO: Trying to get logs from node 10.190.208.160 pod pod-projected-secrets-02323fec-3ecf-11e9-b56c-8631b5a7dc0e container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  4 22:44:04.807: INFO: Waiting for pod pod-projected-secrets-02323fec-3ecf-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:44:04.812: INFO: Pod pod-projected-secrets-02323fec-3ecf-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:44:04.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-p9qg7" for this suite.
Mar  4 22:44:10.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:44:11.029: INFO: namespace: e2e-tests-projected-p9qg7, resource: bindings, ignored listing per whitelist
Mar  4 22:44:11.152: INFO: namespace e2e-tests-projected-p9qg7 deletion completed in 6.329685288s

• [SLOW TEST:8.644 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:44:11.153: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-jfd5x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Mar  4 22:44:11.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 create -f - --namespace=e2e-tests-kubectl-jfd5x'
Mar  4 22:44:11.934: INFO: stderr: ""
Mar  4 22:44:11.934: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  4 22:44:11.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-jfd5x'
Mar  4 22:44:12.108: INFO: stderr: ""
Mar  4 22:44:12.108: INFO: stdout: "update-demo-nautilus-ckd2b update-demo-nautilus-n7r2m "
Mar  4 22:44:12.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods update-demo-nautilus-ckd2b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jfd5x'
Mar  4 22:44:12.218: INFO: stderr: ""
Mar  4 22:44:12.218: INFO: stdout: ""
Mar  4 22:44:12.218: INFO: update-demo-nautilus-ckd2b is created but not running
Mar  4 22:44:17.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-jfd5x'
Mar  4 22:44:17.353: INFO: stderr: ""
Mar  4 22:44:17.353: INFO: stdout: "update-demo-nautilus-ckd2b update-demo-nautilus-n7r2m "
Mar  4 22:44:17.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods update-demo-nautilus-ckd2b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jfd5x'
Mar  4 22:44:17.491: INFO: stderr: ""
Mar  4 22:44:17.491: INFO: stdout: "true"
Mar  4 22:44:17.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods update-demo-nautilus-ckd2b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jfd5x'
Mar  4 22:44:17.618: INFO: stderr: ""
Mar  4 22:44:17.618: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  4 22:44:17.618: INFO: validating pod update-demo-nautilus-ckd2b
Mar  4 22:44:17.631: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  4 22:44:17.631: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  4 22:44:17.631: INFO: update-demo-nautilus-ckd2b is verified up and running
Mar  4 22:44:17.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods update-demo-nautilus-n7r2m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jfd5x'
Mar  4 22:44:17.776: INFO: stderr: ""
Mar  4 22:44:17.776: INFO: stdout: "true"
Mar  4 22:44:17.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods update-demo-nautilus-n7r2m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jfd5x'
Mar  4 22:44:17.887: INFO: stderr: ""
Mar  4 22:44:17.887: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  4 22:44:17.887: INFO: validating pod update-demo-nautilus-n7r2m
Mar  4 22:44:17.901: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  4 22:44:17.901: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  4 22:44:17.901: INFO: update-demo-nautilus-n7r2m is verified up and running
STEP: using delete to clean up resources
Mar  4 22:44:17.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-jfd5x'
Mar  4 22:44:18.089: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  4 22:44:18.089: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar  4 22:44:18.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-jfd5x'
Mar  4 22:44:18.232: INFO: stderr: "No resources found.\n"
Mar  4 22:44:18.232: INFO: stdout: ""
Mar  4 22:44:18.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods -l name=update-demo --namespace=e2e-tests-kubectl-jfd5x -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  4 22:44:18.361: INFO: stderr: ""
Mar  4 22:44:18.361: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:44:18.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jfd5x" for this suite.
Mar  4 22:44:42.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:44:42.992: INFO: namespace: e2e-tests-kubectl-jfd5x, resource: bindings, ignored listing per whitelist
Mar  4 22:44:43.065: INFO: namespace e2e-tests-kubectl-jfd5x deletion completed in 24.693173755s

• [SLOW TEST:31.913 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:44:43.067: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-s4xwr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-1a5dd5fd-3ecf-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume secrets
Mar  4 22:44:43.323: INFO: Waiting up to 5m0s for pod "pod-secrets-1a5f6847-3ecf-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-secrets-s4xwr" to be "success or failure"
Mar  4 22:44:43.328: INFO: Pod "pod-secrets-1a5f6847-3ecf-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.45285ms
Mar  4 22:44:45.333: INFO: Pod "pod-secrets-1a5f6847-3ecf-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009965915s
STEP: Saw pod success
Mar  4 22:44:45.333: INFO: Pod "pod-secrets-1a5f6847-3ecf-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:44:45.338: INFO: Trying to get logs from node 10.190.208.160 pod pod-secrets-1a5f6847-3ecf-11e9-b56c-8631b5a7dc0e container secret-volume-test: <nil>
STEP: delete the pod
Mar  4 22:44:45.371: INFO: Waiting for pod pod-secrets-1a5f6847-3ecf-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:44:45.377: INFO: Pod pod-secrets-1a5f6847-3ecf-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:44:45.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-s4xwr" for this suite.
Mar  4 22:44:51.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:44:51.570: INFO: namespace: e2e-tests-secrets-s4xwr, resource: bindings, ignored listing per whitelist
Mar  4 22:44:51.758: INFO: namespace e2e-tests-secrets-s4xwr deletion completed in 6.369684608s

• [SLOW TEST:8.691 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:44:51.758: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-hqmjf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Mar  4 22:44:52.008: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-hqmjf,SelfLink:/api/v1/namespaces/e2e-tests-watch-hqmjf/configmaps/e2e-watch-test-label-changed,UID:1f8a3cfd-3ecf-11e9-967c-c655790ff683,ResourceVersion:14608,Generation:0,CreationTimestamp:2019-03-04 22:44:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  4 22:44:52.008: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-hqmjf,SelfLink:/api/v1/namespaces/e2e-tests-watch-hqmjf/configmaps/e2e-watch-test-label-changed,UID:1f8a3cfd-3ecf-11e9-967c-c655790ff683,ResourceVersion:14609,Generation:0,CreationTimestamp:2019-03-04 22:44:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar  4 22:44:52.008: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-hqmjf,SelfLink:/api/v1/namespaces/e2e-tests-watch-hqmjf/configmaps/e2e-watch-test-label-changed,UID:1f8a3cfd-3ecf-11e9-967c-c655790ff683,ResourceVersion:14610,Generation:0,CreationTimestamp:2019-03-04 22:44:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Mar  4 22:45:02.082: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-hqmjf,SelfLink:/api/v1/namespaces/e2e-tests-watch-hqmjf/configmaps/e2e-watch-test-label-changed,UID:1f8a3cfd-3ecf-11e9-967c-c655790ff683,ResourceVersion:14628,Generation:0,CreationTimestamp:2019-03-04 22:44:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  4 22:45:02.083: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-hqmjf,SelfLink:/api/v1/namespaces/e2e-tests-watch-hqmjf/configmaps/e2e-watch-test-label-changed,UID:1f8a3cfd-3ecf-11e9-967c-c655790ff683,ResourceVersion:14629,Generation:0,CreationTimestamp:2019-03-04 22:44:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Mar  4 22:45:02.083: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-hqmjf,SelfLink:/api/v1/namespaces/e2e-tests-watch-hqmjf/configmaps/e2e-watch-test-label-changed,UID:1f8a3cfd-3ecf-11e9-967c-c655790ff683,ResourceVersion:14630,Generation:0,CreationTimestamp:2019-03-04 22:44:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:45:02.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-hqmjf" for this suite.
Mar  4 22:45:08.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:45:08.213: INFO: namespace: e2e-tests-watch-hqmjf, resource: bindings, ignored listing per whitelist
Mar  4 22:45:08.628: INFO: namespace e2e-tests-watch-hqmjf deletion completed in 6.533928371s

• [SLOW TEST:16.870 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:45:08.630: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-j45xl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Mar  4 22:45:10.908: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-299b714f-3ecf-11e9-b56c-8631b5a7dc0e", GenerateName:"", Namespace:"e2e-tests-pods-j45xl", SelfLink:"/api/v1/namespaces/e2e-tests-pods-j45xl/pods/pod-submit-remove-299b714f-3ecf-11e9-b56c-8631b5a7dc0e", UID:"299d14be-3ecf-11e9-967c-c655790ff683", ResourceVersion:"14669", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63687336308, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"871620745"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-dqkgh", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc420dbeb00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-dqkgh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc4210fce48), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.190.208.160", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc4224167e0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4210fce90)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4210fceb0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc4210fceb8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687336308, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687336310, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687336310, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687336308, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.190.208.160", PodIP:"172.30.87.154", StartTime:(*v1.Time)(0xc4224196c0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc4224196e0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"docker.io/library/nginx:1.14-alpine", ImageID:"docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632", ContainerID:"containerd://2d68bf0c3d9d04e05bc50c3ec472946d987dba9e68e4dcbee6f65fd577333984"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Mar  4 22:45:15.942: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:45:15.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-j45xl" for this suite.
Mar  4 22:45:22.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:45:22.173: INFO: namespace: e2e-tests-pods-j45xl, resource: bindings, ignored listing per whitelist
Mar  4 22:45:22.300: INFO: namespace e2e-tests-pods-j45xl deletion completed in 6.303473201s

• [SLOW TEST:13.669 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:45:22.301: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-k7r7b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar  4 22:45:25.134: INFO: Successfully updated pod "annotationupdate31c095bb-3ecf-11e9-b56c-8631b5a7dc0e"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:45:27.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k7r7b" for this suite.
Mar  4 22:45:49.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:45:49.466: INFO: namespace: e2e-tests-projected-k7r7b, resource: bindings, ignored listing per whitelist
Mar  4 22:45:49.498: INFO: namespace e2e-tests-projected-k7r7b deletion completed in 22.320871998s

• [SLOW TEST:27.198 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:45:49.500: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-g7252
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  4 22:45:49.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-g7252'
Mar  4 22:45:49.990: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar  4 22:45:49.990: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Mar  4 22:45:50.003: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-dmh2t]
Mar  4 22:45:50.003: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-dmh2t" in namespace "e2e-tests-kubectl-g7252" to be "running and ready"
Mar  4 22:45:50.010: INFO: Pod "e2e-test-nginx-rc-dmh2t": Phase="Pending", Reason="", readiness=false. Elapsed: 6.497918ms
Mar  4 22:45:52.016: INFO: Pod "e2e-test-nginx-rc-dmh2t": Phase="Running", Reason="", readiness=true. Elapsed: 2.012296182s
Mar  4 22:45:52.016: INFO: Pod "e2e-test-nginx-rc-dmh2t" satisfied condition "running and ready"
Mar  4 22:45:52.016: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-dmh2t]
Mar  4 22:45:52.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-g7252'
Mar  4 22:45:52.187: INFO: stderr: ""
Mar  4 22:45:52.187: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Mar  4 22:45:52.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-g7252'
Mar  4 22:45:52.389: INFO: stderr: ""
Mar  4 22:45:52.389: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:45:52.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-g7252" for this suite.
Mar  4 22:46:14.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:46:14.652: INFO: namespace: e2e-tests-kubectl-g7252, resource: bindings, ignored listing per whitelist
Mar  4 22:46:14.792: INFO: namespace e2e-tests-kubectl-g7252 deletion completed in 22.392552879s

• [SLOW TEST:25.293 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:46:14.794: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-bmk7l
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Mar  4 22:46:17.055: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-5109b3b0-3ecf-11e9-b56c-8631b5a7dc0e,GenerateName:,Namespace:e2e-tests-events-bmk7l,SelfLink:/api/v1/namespaces/e2e-tests-events-bmk7l/pods/send-events-5109b3b0-3ecf-11e9-b56c-8631b5a7dc0e,UID:510a5235-3ecf-11e9-967c-c655790ff683,ResourceVersion:14894,Generation:0,CreationTimestamp:2019-03-04 22:46:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 25355090,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdmjt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdmjt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-qdmjt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.160,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4225f6a40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4225f6a60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:46:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:46:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:46:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:46:15 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.160,PodIP:172.30.87.157,StartTime:2019-03-04 22:46:15 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-03-04 22:46:16 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 containerd://a8b3a26e360ae98381623acd1e08971e9a0406525dc87574a343edb33114765d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Mar  4 22:46:19.063: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Mar  4 22:46:21.073: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:46:21.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-bmk7l" for this suite.
Mar  4 22:47:05.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:47:05.801: INFO: namespace: e2e-tests-events-bmk7l, resource: bindings, ignored listing per whitelist
Mar  4 22:47:05.890: INFO: namespace e2e-tests-events-bmk7l deletion completed in 44.297307885s

• [SLOW TEST:51.097 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:47:05.891: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-jmxs4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0304 22:47:07.248207      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  4 22:47:07.248: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:47:07.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-jmxs4" for this suite.
Mar  4 22:47:13.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:47:13.521: INFO: namespace: e2e-tests-gc-jmxs4, resource: bindings, ignored listing per whitelist
Mar  4 22:47:13.635: INFO: namespace e2e-tests-gc-jmxs4 deletion completed in 6.377104117s

• [SLOW TEST:7.744 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:47:13.635: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-z59dk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:48:13.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-z59dk" for this suite.
Mar  4 22:48:37.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:48:37.992: INFO: namespace: e2e-tests-container-probe-z59dk, resource: bindings, ignored listing per whitelist
Mar  4 22:48:38.184: INFO: namespace e2e-tests-container-probe-z59dk deletion completed in 24.303341609s

• [SLOW TEST:84.549 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:48:38.186: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-tx2fw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-a687c4ce-3ecf-11e9-b56c-8631b5a7dc0e
STEP: Creating secret with name secret-projected-all-test-volume-a687c4b3-3ecf-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test Check all projections for projected volume plugin
Mar  4 22:48:38.480: INFO: Waiting up to 5m0s for pod "projected-volume-a687c47e-3ecf-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-projected-tx2fw" to be "success or failure"
Mar  4 22:48:38.485: INFO: Pod "projected-volume-a687c47e-3ecf-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.804953ms
Mar  4 22:48:40.554: INFO: Pod "projected-volume-a687c47e-3ecf-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.073954157s
STEP: Saw pod success
Mar  4 22:48:40.554: INFO: Pod "projected-volume-a687c47e-3ecf-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:48:40.560: INFO: Trying to get logs from node 10.190.208.160 pod projected-volume-a687c47e-3ecf-11e9-b56c-8631b5a7dc0e container projected-all-volume-test: <nil>
STEP: delete the pod
Mar  4 22:48:40.591: INFO: Waiting for pod projected-volume-a687c47e-3ecf-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:48:40.595: INFO: Pod projected-volume-a687c47e-3ecf-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:48:40.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tx2fw" for this suite.
Mar  4 22:48:46.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:48:46.707: INFO: namespace: e2e-tests-projected-tx2fw, resource: bindings, ignored listing per whitelist
Mar  4 22:48:46.904: INFO: namespace e2e-tests-projected-tx2fw deletion completed in 6.298290122s

• [SLOW TEST:8.718 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:48:46.905: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-fhrs7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  4 22:48:47.144: INFO: Waiting up to 5m0s for pod "downwardapi-volume-abb37a55-3ecf-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-projected-fhrs7" to be "success or failure"
Mar  4 22:48:47.149: INFO: Pod "downwardapi-volume-abb37a55-3ecf-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.531817ms
Mar  4 22:48:49.155: INFO: Pod "downwardapi-volume-abb37a55-3ecf-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010841093s
STEP: Saw pod success
Mar  4 22:48:49.155: INFO: Pod "downwardapi-volume-abb37a55-3ecf-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:48:49.161: INFO: Trying to get logs from node 10.190.208.160 pod downwardapi-volume-abb37a55-3ecf-11e9-b56c-8631b5a7dc0e container client-container: <nil>
STEP: delete the pod
Mar  4 22:48:49.195: INFO: Waiting for pod downwardapi-volume-abb37a55-3ecf-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:48:49.199: INFO: Pod downwardapi-volume-abb37a55-3ecf-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:48:49.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fhrs7" for this suite.
Mar  4 22:48:55.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:48:55.434: INFO: namespace: e2e-tests-projected-fhrs7, resource: bindings, ignored listing per whitelist
Mar  4 22:48:55.737: INFO: namespace e2e-tests-projected-fhrs7 deletion completed in 6.454064787s

• [SLOW TEST:8.832 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:48:55.737: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-4wb8h
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-4wb8h
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-4wb8h
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-4wb8h
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-4wb8h
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-4wb8h
Mar  4 22:49:00.027: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-4wb8h, name: ss-0, uid: b3267323-3ecf-11e9-967c-c655790ff683, status phase: Pending. Waiting for statefulset controller to delete.
Mar  4 22:49:00.215: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-4wb8h, name: ss-0, uid: b3267323-3ecf-11e9-967c-c655790ff683, status phase: Failed. Waiting for statefulset controller to delete.
Mar  4 22:49:00.224: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-4wb8h, name: ss-0, uid: b3267323-3ecf-11e9-967c-c655790ff683, status phase: Failed. Waiting for statefulset controller to delete.
Mar  4 22:49:00.231: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-4wb8h
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-4wb8h
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-4wb8h and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar  4 22:49:04.299: INFO: Deleting all statefulset in ns e2e-tests-statefulset-4wb8h
Mar  4 22:49:04.304: INFO: Scaling statefulset ss to 0
Mar  4 22:49:14.326: INFO: Waiting for statefulset status.replicas updated to 0
Mar  4 22:49:14.331: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:49:14.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-4wb8h" for this suite.
Mar  4 22:49:20.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:49:20.655: INFO: namespace: e2e-tests-statefulset-4wb8h, resource: bindings, ignored listing per whitelist
Mar  4 22:49:20.684: INFO: namespace e2e-tests-statefulset-4wb8h deletion completed in 6.315848223s

• [SLOW TEST:24.947 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:49:20.685: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-zjlrs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  4 22:49:21.001: INFO: (0) /api/v1/nodes/10.190.208.160:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 17.81548ms)
Mar  4 22:49:21.012: INFO: (1) /api/v1/nodes/10.190.208.160:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.509797ms)
Mar  4 22:49:21.024: INFO: (2) /api/v1/nodes/10.190.208.160:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.347964ms)
Mar  4 22:49:21.036: INFO: (3) /api/v1/nodes/10.190.208.160:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.338423ms)
Mar  4 22:49:21.048: INFO: (4) /api/v1/nodes/10.190.208.160:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.551285ms)
Mar  4 22:49:21.061: INFO: (5) /api/v1/nodes/10.190.208.160:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.783952ms)
Mar  4 22:49:21.073: INFO: (6) /api/v1/nodes/10.190.208.160:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.870487ms)
Mar  4 22:49:21.085: INFO: (7) /api/v1/nodes/10.190.208.160:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.959883ms)
Mar  4 22:49:21.097: INFO: (8) /api/v1/nodes/10.190.208.160:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.591038ms)
Mar  4 22:49:21.109: INFO: (9) /api/v1/nodes/10.190.208.160:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.553951ms)
Mar  4 22:49:21.121: INFO: (10) /api/v1/nodes/10.190.208.160:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.987787ms)
Mar  4 22:49:21.132: INFO: (11) /api/v1/nodes/10.190.208.160:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.026625ms)
Mar  4 22:49:21.144: INFO: (12) /api/v1/nodes/10.190.208.160:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.025628ms)
Mar  4 22:49:21.155: INFO: (13) /api/v1/nodes/10.190.208.160:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.301223ms)
Mar  4 22:49:21.168: INFO: (14) /api/v1/nodes/10.190.208.160:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.693518ms)
Mar  4 22:49:21.181: INFO: (15) /api/v1/nodes/10.190.208.160:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.297554ms)
Mar  4 22:49:21.194: INFO: (16) /api/v1/nodes/10.190.208.160:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.146659ms)
Mar  4 22:49:21.210: INFO: (17) /api/v1/nodes/10.190.208.160:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 16.864774ms)
Mar  4 22:49:21.222: INFO: (18) /api/v1/nodes/10.190.208.160:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.122893ms)
Mar  4 22:49:21.233: INFO: (19) /api/v1/nodes/10.190.208.160:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.102686ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:49:21.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-zjlrs" for this suite.
Mar  4 22:49:27.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:49:27.400: INFO: namespace: e2e-tests-proxy-zjlrs, resource: bindings, ignored listing per whitelist
Mar  4 22:49:27.493: INFO: namespace e2e-tests-proxy-zjlrs deletion completed in 6.252014862s

• [SLOW TEST:6.809 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:49:27.494: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-dn2z5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Mar  4 22:49:27.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 create -f - --namespace=e2e-tests-kubectl-dn2z5'
Mar  4 22:49:28.065: INFO: stderr: ""
Mar  4 22:49:28.065: INFO: stdout: "pod/pause created\n"
Mar  4 22:49:28.065: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Mar  4 22:49:28.065: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-dn2z5" to be "running and ready"
Mar  4 22:49:28.070: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.316687ms
Mar  4 22:49:30.076: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.010904236s
Mar  4 22:49:30.076: INFO: Pod "pause" satisfied condition "running and ready"
Mar  4 22:49:30.076: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Mar  4 22:49:30.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-dn2z5'
Mar  4 22:49:30.201: INFO: stderr: ""
Mar  4 22:49:30.201: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Mar  4 22:49:30.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pod pause -L testing-label --namespace=e2e-tests-kubectl-dn2z5'
Mar  4 22:49:30.330: INFO: stderr: ""
Mar  4 22:49:30.330: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Mar  4 22:49:30.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 label pods pause testing-label- --namespace=e2e-tests-kubectl-dn2z5'
Mar  4 22:49:30.472: INFO: stderr: ""
Mar  4 22:49:30.472: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Mar  4 22:49:30.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pod pause -L testing-label --namespace=e2e-tests-kubectl-dn2z5'
Mar  4 22:49:30.597: INFO: stderr: ""
Mar  4 22:49:30.597: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Mar  4 22:49:30.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-dn2z5'
Mar  4 22:49:30.795: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  4 22:49:30.795: INFO: stdout: "pod \"pause\" force deleted\n"
Mar  4 22:49:30.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-dn2z5'
Mar  4 22:49:30.938: INFO: stderr: "No resources found.\n"
Mar  4 22:49:30.938: INFO: stdout: ""
Mar  4 22:49:30.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods -l name=pause --namespace=e2e-tests-kubectl-dn2z5 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  4 22:49:31.047: INFO: stderr: ""
Mar  4 22:49:31.047: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:49:31.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dn2z5" for this suite.
Mar  4 22:49:37.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:49:37.370: INFO: namespace: e2e-tests-kubectl-dn2z5, resource: bindings, ignored listing per whitelist
Mar  4 22:49:37.387: INFO: namespace e2e-tests-kubectl-dn2z5 deletion completed in 6.303591399s

• [SLOW TEST:9.893 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:49:37.388: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-9bpk8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-9bpk8
Mar  4 22:49:40.289: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-9bpk8
STEP: checking the pod's current state and verifying that restartCount is present
Mar  4 22:49:40.293: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:53:41.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-9bpk8" for this suite.
Mar  4 22:53:47.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:53:47.690: INFO: namespace: e2e-tests-container-probe-9bpk8, resource: bindings, ignored listing per whitelist
Mar  4 22:53:47.704: INFO: namespace e2e-tests-container-probe-9bpk8 deletion completed in 6.370218165s

• [SLOW TEST:250.317 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:53:47.705: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-nmbs6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0304 22:53:58.006719      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  4 22:53:58.006: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:53:58.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-nmbs6" for this suite.
Mar  4 22:54:04.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:54:04.121: INFO: namespace: e2e-tests-gc-nmbs6, resource: bindings, ignored listing per whitelist
Mar  4 22:54:04.330: INFO: namespace e2e-tests-gc-nmbs6 deletion completed in 6.314884312s

• [SLOW TEST:16.625 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:54:04.330: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-4bw8d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  4 22:54:04.578: INFO: Creating deployment "test-recreate-deployment"
Mar  4 22:54:04.588: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Mar  4 22:54:04.600: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Mar  4 22:54:06.613: INFO: Waiting deployment "test-recreate-deployment" to complete
Mar  4 22:54:06.621: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687336844, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687336844, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687336844, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687336844, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  4 22:54:08.630: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Mar  4 22:54:08.649: INFO: Updating deployment test-recreate-deployment
Mar  4 22:54:08.649: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar  4 22:54:08.735: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-4bw8d,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4bw8d/deployments/test-recreate-deployment,UID:68e9ead9-3ed0-11e9-967c-c655790ff683,ResourceVersion:16245,Generation:2,CreationTimestamp:2019-03-04 22:54:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-03-04 22:54:08 +0000 UTC 2019-03-04 22:54:08 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-03-04 22:54:08 +0000 UTC 2019-03-04 22:54:04 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Mar  4 22:54:08.741: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-4bw8d,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4bw8d/replicasets/test-recreate-deployment-7cf749666b,UID:6b5b6342-3ed0-11e9-967c-c655790ff683,ResourceVersion:16243,Generation:1,CreationTimestamp:2019-03-04 22:54:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 68e9ead9-3ed0-11e9-967c-c655790ff683 0xc422333887 0xc422333888}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  4 22:54:08.741: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Mar  4 22:54:08.741: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-4bw8d,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4bw8d/replicasets/test-recreate-deployment-79f694ff59,UID:68ec828b-3ed0-11e9-967c-c655790ff683,ResourceVersion:16235,Generation:2,CreationTimestamp:2019-03-04 22:54:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 68e9ead9-3ed0-11e9-967c-c655790ff683 0xc4223335f7 0xc4223335f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  4 22:54:08.746: INFO: Pod "test-recreate-deployment-7cf749666b-zz76k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-zz76k,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-4bw8d,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4bw8d/pods/test-recreate-deployment-7cf749666b-zz76k,UID:6b5c1f83-3ed0-11e9-967c-c655790ff683,ResourceVersion:16246,Generation:0,CreationTimestamp:2019-03-04 22:54:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b 6b5b6342-3ed0-11e9-967c-c655790ff683 0xc421ac3977 0xc421ac3978}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vkpfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vkpfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vkpfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.160,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421ac3a40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421ac3a70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:54:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:54:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:54:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:54:08 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.160,PodIP:,StartTime:2019-03-04 22:54:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:54:08.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-4bw8d" for this suite.
Mar  4 22:54:14.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:54:15.333: INFO: namespace: e2e-tests-deployment-4bw8d, resource: bindings, ignored listing per whitelist
Mar  4 22:54:15.385: INFO: namespace e2e-tests-deployment-4bw8d deletion completed in 6.627228929s

• [SLOW TEST:11.055 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:54:15.387: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-szz8t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Mar  4 22:54:15.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 create -f - --namespace=e2e-tests-kubectl-szz8t'
Mar  4 22:54:16.071: INFO: stderr: ""
Mar  4 22:54:16.071: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Mar  4 22:54:17.077: INFO: Selector matched 1 pods for map[app:redis]
Mar  4 22:54:17.078: INFO: Found 0 / 1
Mar  4 22:54:18.077: INFO: Selector matched 1 pods for map[app:redis]
Mar  4 22:54:18.077: INFO: Found 1 / 1
Mar  4 22:54:18.077: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar  4 22:54:18.081: INFO: Selector matched 1 pods for map[app:redis]
Mar  4 22:54:18.081: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Mar  4 22:54:18.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 logs redis-master-v5ggq redis-master --namespace=e2e-tests-kubectl-szz8t'
Mar  4 22:54:18.318: INFO: stderr: ""
Mar  4 22:54:18.318: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 04 Mar 22:54:17.321 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 04 Mar 22:54:17.321 # Server started, Redis version 3.2.12\n1:M 04 Mar 22:54:17.321 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 04 Mar 22:54:17.322 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Mar  4 22:54:18.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 log redis-master-v5ggq redis-master --namespace=e2e-tests-kubectl-szz8t --tail=1'
Mar  4 22:54:18.473: INFO: stderr: ""
Mar  4 22:54:18.473: INFO: stdout: "1:M 04 Mar 22:54:17.322 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Mar  4 22:54:18.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 log redis-master-v5ggq redis-master --namespace=e2e-tests-kubectl-szz8t --limit-bytes=1'
Mar  4 22:54:18.702: INFO: stderr: ""
Mar  4 22:54:18.702: INFO: stdout: " "
STEP: exposing timestamps
Mar  4 22:54:18.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 log redis-master-v5ggq redis-master --namespace=e2e-tests-kubectl-szz8t --tail=1 --timestamps'
Mar  4 22:54:18.901: INFO: stderr: ""
Mar  4 22:54:18.901: INFO: stdout: "2019-03-04T22:54:17.322054658Z 1:M 04 Mar 22:54:17.322 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Mar  4 22:54:21.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 log redis-master-v5ggq redis-master --namespace=e2e-tests-kubectl-szz8t --since=1s'
Mar  4 22:54:21.552: INFO: stderr: ""
Mar  4 22:54:21.552: INFO: stdout: ""
Mar  4 22:54:21.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 log redis-master-v5ggq redis-master --namespace=e2e-tests-kubectl-szz8t --since=24h'
Mar  4 22:54:21.709: INFO: stderr: ""
Mar  4 22:54:21.709: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 04 Mar 22:54:17.321 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 04 Mar 22:54:17.321 # Server started, Redis version 3.2.12\n1:M 04 Mar 22:54:17.321 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 04 Mar 22:54:17.322 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Mar  4 22:54:21.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-szz8t'
Mar  4 22:54:21.872: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  4 22:54:21.872: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Mar  4 22:54:21.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-szz8t'
Mar  4 22:54:22.007: INFO: stderr: "No resources found.\n"
Mar  4 22:54:22.007: INFO: stdout: ""
Mar  4 22:54:22.007: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods -l name=nginx --namespace=e2e-tests-kubectl-szz8t -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  4 22:54:22.129: INFO: stderr: ""
Mar  4 22:54:22.129: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:54:22.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-szz8t" for this suite.
Mar  4 22:54:46.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:54:46.205: INFO: namespace: e2e-tests-kubectl-szz8t, resource: bindings, ignored listing per whitelist
Mar  4 22:54:46.406: INFO: namespace e2e-tests-kubectl-szz8t deletion completed in 24.265363455s

• [SLOW TEST:31.020 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:54:46.407: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-6q85n
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-81fd748b-3ed0-11e9-b56c-8631b5a7dc0e
STEP: Creating configMap with name cm-test-opt-upd-81fd74cc-3ed0-11e9-b56c-8631b5a7dc0e
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-81fd748b-3ed0-11e9-b56c-8631b5a7dc0e
STEP: Updating configmap cm-test-opt-upd-81fd74cc-3ed0-11e9-b56c-8631b5a7dc0e
STEP: Creating configMap with name cm-test-opt-create-81fd74f3-3ed0-11e9-b56c-8631b5a7dc0e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:56:07.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-6q85n" for this suite.
Mar  4 22:56:29.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:56:29.861: INFO: namespace: e2e-tests-configmap-6q85n, resource: bindings, ignored listing per whitelist
Mar  4 22:56:30.011: INFO: namespace e2e-tests-configmap-6q85n deletion completed in 22.377507985s

• [SLOW TEST:103.604 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:56:30.012: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-nv2tg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  4 22:56:30.263: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bfbdc464-3ed0-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-projected-nv2tg" to be "success or failure"
Mar  4 22:56:30.267: INFO: Pod "downwardapi-volume-bfbdc464-3ed0-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.803009ms
Mar  4 22:56:32.274: INFO: Pod "downwardapi-volume-bfbdc464-3ed0-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011344939s
STEP: Saw pod success
Mar  4 22:56:32.274: INFO: Pod "downwardapi-volume-bfbdc464-3ed0-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:56:32.280: INFO: Trying to get logs from node 10.190.208.160 pod downwardapi-volume-bfbdc464-3ed0-11e9-b56c-8631b5a7dc0e container client-container: <nil>
STEP: delete the pod
Mar  4 22:56:32.329: INFO: Waiting for pod downwardapi-volume-bfbdc464-3ed0-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:56:32.335: INFO: Pod downwardapi-volume-bfbdc464-3ed0-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:56:32.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nv2tg" for this suite.
Mar  4 22:56:38.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:56:38.490: INFO: namespace: e2e-tests-projected-nv2tg, resource: bindings, ignored listing per whitelist
Mar  4 22:56:38.679: INFO: namespace e2e-tests-projected-nv2tg deletion completed in 6.333780085s

• [SLOW TEST:8.667 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:56:38.679: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-qcbvn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar  4 22:56:41.529: INFO: Successfully updated pod "labelsupdatec4e8de74-3ed0-11e9-b56c-8631b5a7dc0e"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:56:45.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qcbvn" for this suite.
Mar  4 22:57:07.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:57:07.879: INFO: namespace: e2e-tests-projected-qcbvn, resource: bindings, ignored listing per whitelist
Mar  4 22:57:08.086: INFO: namespace e2e-tests-projected-qcbvn deletion completed in 22.498203487s

• [SLOW TEST:29.407 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:57:08.087: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-kkb87
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  4 22:57:08.331: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d66eb60f-3ed0-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-downward-api-kkb87" to be "success or failure"
Mar  4 22:57:08.335: INFO: Pod "downwardapi-volume-d66eb60f-3ed0-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.419453ms
Mar  4 22:57:10.341: INFO: Pod "downwardapi-volume-d66eb60f-3ed0-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010187742s
STEP: Saw pod success
Mar  4 22:57:10.341: INFO: Pod "downwardapi-volume-d66eb60f-3ed0-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:57:10.383: INFO: Trying to get logs from node 10.190.208.160 pod downwardapi-volume-d66eb60f-3ed0-11e9-b56c-8631b5a7dc0e container client-container: <nil>
STEP: delete the pod
Mar  4 22:57:10.416: INFO: Waiting for pod downwardapi-volume-d66eb60f-3ed0-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:57:10.422: INFO: Pod downwardapi-volume-d66eb60f-3ed0-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:57:10.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kkb87" for this suite.
Mar  4 22:57:16.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:57:16.695: INFO: namespace: e2e-tests-downward-api-kkb87, resource: bindings, ignored listing per whitelist
Mar  4 22:57:16.743: INFO: namespace e2e-tests-downward-api-kkb87 deletion completed in 6.308315335s

• [SLOW TEST:8.656 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:57:16.743: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-rz5cl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-rz5cl/secret-test-db97b37b-3ed0-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume secrets
Mar  4 22:57:16.995: INFO: Waiting up to 5m0s for pod "pod-configmaps-db98a91b-3ed0-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-secrets-rz5cl" to be "success or failure"
Mar  4 22:57:16.999: INFO: Pod "pod-configmaps-db98a91b-3ed0-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.143836ms
Mar  4 22:57:19.005: INFO: Pod "pod-configmaps-db98a91b-3ed0-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009575421s
STEP: Saw pod success
Mar  4 22:57:19.005: INFO: Pod "pod-configmaps-db98a91b-3ed0-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:57:19.009: INFO: Trying to get logs from node 10.190.208.160 pod pod-configmaps-db98a91b-3ed0-11e9-b56c-8631b5a7dc0e container env-test: <nil>
STEP: delete the pod
Mar  4 22:57:19.044: INFO: Waiting for pod pod-configmaps-db98a91b-3ed0-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:57:19.050: INFO: Pod pod-configmaps-db98a91b-3ed0-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:57:19.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-rz5cl" for this suite.
Mar  4 22:57:25.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:57:25.239: INFO: namespace: e2e-tests-secrets-rz5cl, resource: bindings, ignored listing per whitelist
Mar  4 22:57:25.442: INFO: namespace e2e-tests-secrets-rz5cl deletion completed in 6.380850805s

• [SLOW TEST:8.699 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:57:25.443: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-cns4q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  4 22:57:25.695: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e0c80de3-3ed0-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-projected-cns4q" to be "success or failure"
Mar  4 22:57:25.699: INFO: Pod "downwardapi-volume-e0c80de3-3ed0-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.347692ms
Mar  4 22:57:27.704: INFO: Pod "downwardapi-volume-e0c80de3-3ed0-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009774096s
STEP: Saw pod success
Mar  4 22:57:27.704: INFO: Pod "downwardapi-volume-e0c80de3-3ed0-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:57:27.709: INFO: Trying to get logs from node 10.190.208.162 pod downwardapi-volume-e0c80de3-3ed0-11e9-b56c-8631b5a7dc0e container client-container: <nil>
STEP: delete the pod
Mar  4 22:57:27.756: INFO: Waiting for pod downwardapi-volume-e0c80de3-3ed0-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:57:27.762: INFO: Pod downwardapi-volume-e0c80de3-3ed0-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:57:27.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cns4q" for this suite.
Mar  4 22:57:35.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:57:36.005: INFO: namespace: e2e-tests-projected-cns4q, resource: bindings, ignored listing per whitelist
Mar  4 22:57:36.204: INFO: namespace e2e-tests-projected-cns4q deletion completed in 8.427080345s

• [SLOW TEST:10.761 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:57:36.207: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-4fzmq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar  4 22:57:36.452: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:57:40.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-4fzmq" for this suite.
Mar  4 22:57:46.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:57:46.427: INFO: namespace: e2e-tests-init-container-4fzmq, resource: bindings, ignored listing per whitelist
Mar  4 22:57:46.598: INFO: namespace e2e-tests-init-container-4fzmq deletion completed in 6.315848109s

• [SLOW TEST:10.392 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:57:46.598: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-q2kkp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  4 22:57:46.842: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Mar  4 22:57:46.865: INFO: Pod name sample-pod: Found 0 pods out of 1
Mar  4 22:57:51.871: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar  4 22:57:51.871: INFO: Creating deployment "test-rolling-update-deployment"
Mar  4 22:57:51.880: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Mar  4 22:57:51.892: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Mar  4 22:57:53.907: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Mar  4 22:57:53.914: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687337071, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687337071, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687337071, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687337071, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  4 22:57:55.923: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar  4 22:57:55.944: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-q2kkp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-q2kkp/deployments/test-rolling-update-deployment,UID:f063f84f-3ed0-11e9-967c-c655790ff683,ResourceVersion:17078,Generation:1,CreationTimestamp:2019-03-04 22:57:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-04 22:57:51 +0000 UTC 2019-03-04 22:57:51 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-04 22:57:54 +0000 UTC 2019-03-04 22:57:51 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar  4 22:57:55.949: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-q2kkp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-q2kkp/replicasets/test-rolling-update-deployment-65b7695dcf,UID:f068f261-3ed0-11e9-967c-c655790ff683,ResourceVersion:17069,Generation:1,CreationTimestamp:2019-03-04 22:57:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment f063f84f-3ed0-11e9-967c-c655790ff683 0xc4228b82f7 0xc4228b82f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar  4 22:57:55.949: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Mar  4 22:57:55.949: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-q2kkp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-q2kkp/replicasets/test-rolling-update-controller,UID:ed64b141-3ed0-11e9-967c-c655790ff683,ResourceVersion:17077,Generation:2,CreationTimestamp:2019-03-04 22:57:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment f063f84f-3ed0-11e9-967c-c655790ff683 0xc422145fae 0xc422145faf}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  4 22:57:55.955: INFO: Pod "test-rolling-update-deployment-65b7695dcf-kcrxr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-kcrxr,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-q2kkp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-q2kkp/pods/test-rolling-update-deployment-65b7695dcf-kcrxr,UID:f069b84f-3ed0-11e9-967c-c655790ff683,ResourceVersion:17068,Generation:0,CreationTimestamp:2019-03-04 22:57:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf f068f261-3ed0-11e9-967c-c655790ff683 0xc4228b9b77 0xc4228b9b78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jggxp {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jggxp,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-jggxp true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.178,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4228b9bf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4228b9c10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:57:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:57:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:57:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 22:57:51 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.178,PodIP:172.30.252.211,StartTime:2019-03-04 22:57:52 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-04 22:57:54 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://2173ed6f6b83bf9915820e835052ab4eefcdfb92b269ad04cd84bc4a120c87a3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:57:55.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-q2kkp" for this suite.
Mar  4 22:58:02.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:58:02.069: INFO: namespace: e2e-tests-deployment-q2kkp, resource: bindings, ignored listing per whitelist
Mar  4 22:58:02.229: INFO: namespace e2e-tests-deployment-q2kkp deletion completed in 6.245754147s

• [SLOW TEST:15.631 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:58:02.229: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-7w4vl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar  4 22:58:02.542: INFO: Number of nodes with available pods: 0
Mar  4 22:58:02.542: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:58:03.575: INFO: Number of nodes with available pods: 0
Mar  4 22:58:03.575: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:58:04.563: INFO: Number of nodes with available pods: 2
Mar  4 22:58:04.563: INFO: Node 10.190.208.162 is running more than one daemon pod
Mar  4 22:58:05.560: INFO: Number of nodes with available pods: 3
Mar  4 22:58:05.561: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Mar  4 22:58:05.606: INFO: Number of nodes with available pods: 2
Mar  4 22:58:05.606: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:58:06.622: INFO: Number of nodes with available pods: 2
Mar  4 22:58:06.622: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 22:58:07.682: INFO: Number of nodes with available pods: 3
Mar  4 22:58:07.683: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-7w4vl, will wait for the garbage collector to delete the pods
Mar  4 22:58:07.761: INFO: Deleting {extensions DaemonSet} daemon-set took: 11.290063ms
Mar  4 22:58:07.861: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.384468ms
Mar  4 22:58:44.082: INFO: Number of nodes with available pods: 0
Mar  4 22:58:44.082: INFO: Number of running nodes: 0, number of available pods: 0
Mar  4 22:58:44.087: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-7w4vl/daemonsets","resourceVersion":"17295"},"items":null}

Mar  4 22:58:44.092: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-7w4vl/pods","resourceVersion":"17295"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:58:44.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-7w4vl" for this suite.
Mar  4 22:58:50.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:58:50.253: INFO: namespace: e2e-tests-daemonsets-7w4vl, resource: bindings, ignored listing per whitelist
Mar  4 22:58:50.577: INFO: namespace e2e-tests-daemonsets-7w4vl deletion completed in 6.442316465s

• [SLOW TEST:48.348 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:58:50.578: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-8rzg7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-8rzg7
I0304 22:58:50.826287      15 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-8rzg7, replica count: 1
I0304 22:58:51.876735      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0304 22:58:52.877084      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  4 22:58:53.007: INFO: Created: latency-svc-l6bcf
Mar  4 22:58:53.236: INFO: Got endpoints: latency-svc-l6bcf [259.212089ms]
Mar  4 22:58:53.283: INFO: Created: latency-svc-m7n92
Mar  4 22:58:53.283: INFO: Created: latency-svc-qcqjz
Mar  4 22:58:53.283: INFO: Got endpoints: latency-svc-qcqjz [46.058212ms]
Mar  4 22:58:53.287: INFO: Got endpoints: latency-svc-m7n92 [50.830329ms]
Mar  4 22:58:53.293: INFO: Created: latency-svc-q88kk
Mar  4 22:58:53.302: INFO: Got endpoints: latency-svc-q88kk [65.39693ms]
Mar  4 22:58:53.309: INFO: Created: latency-svc-pblxk
Mar  4 22:58:53.318: INFO: Got endpoints: latency-svc-pblxk [81.32774ms]
Mar  4 22:58:53.325: INFO: Created: latency-svc-pfz4k
Mar  4 22:58:53.338: INFO: Got endpoints: latency-svc-pfz4k [100.518554ms]
Mar  4 22:58:53.349: INFO: Created: latency-svc-nkh6p
Mar  4 22:58:53.357: INFO: Got endpoints: latency-svc-nkh6p [120.572493ms]
Mar  4 22:58:53.366: INFO: Created: latency-svc-58fw6
Mar  4 22:58:53.374: INFO: Got endpoints: latency-svc-58fw6 [136.893236ms]
Mar  4 22:58:53.382: INFO: Created: latency-svc-f4dtk
Mar  4 22:58:53.392: INFO: Got endpoints: latency-svc-f4dtk [154.068572ms]
Mar  4 22:58:53.398: INFO: Created: latency-svc-xk5qw
Mar  4 22:58:53.406: INFO: Got endpoints: latency-svc-xk5qw [31.616805ms]
Mar  4 22:58:53.412: INFO: Created: latency-svc-vd6v2
Mar  4 22:58:53.422: INFO: Got endpoints: latency-svc-vd6v2 [184.661117ms]
Mar  4 22:58:53.436: INFO: Created: latency-svc-g2smz
Mar  4 22:58:53.443: INFO: Got endpoints: latency-svc-g2smz [205.841659ms]
Mar  4 22:58:53.449: INFO: Created: latency-svc-m58bc
Mar  4 22:58:53.457: INFO: Got endpoints: latency-svc-m58bc [219.772295ms]
Mar  4 22:58:53.464: INFO: Created: latency-svc-5xtwh
Mar  4 22:58:53.471: INFO: Got endpoints: latency-svc-5xtwh [233.106219ms]
Mar  4 22:58:53.478: INFO: Created: latency-svc-6cb64
Mar  4 22:58:53.489: INFO: Got endpoints: latency-svc-6cb64 [251.12065ms]
Mar  4 22:58:53.495: INFO: Created: latency-svc-4gbmv
Mar  4 22:58:53.504: INFO: Got endpoints: latency-svc-4gbmv [266.155924ms]
Mar  4 22:58:53.509: INFO: Created: latency-svc-ssd5r
Mar  4 22:58:53.518: INFO: Got endpoints: latency-svc-ssd5r [280.617649ms]
Mar  4 22:58:53.525: INFO: Created: latency-svc-sklcl
Mar  4 22:58:53.534: INFO: Got endpoints: latency-svc-sklcl [251.6494ms]
Mar  4 22:58:53.541: INFO: Created: latency-svc-798ms
Mar  4 22:58:53.549: INFO: Got endpoints: latency-svc-798ms [261.926329ms]
Mar  4 22:58:53.554: INFO: Created: latency-svc-485vz
Mar  4 22:58:53.564: INFO: Got endpoints: latency-svc-485vz [261.607678ms]
Mar  4 22:58:53.570: INFO: Created: latency-svc-nhjdt
Mar  4 22:58:53.582: INFO: Got endpoints: latency-svc-nhjdt [263.308305ms]
Mar  4 22:58:53.587: INFO: Created: latency-svc-c9x9d
Mar  4 22:58:53.596: INFO: Got endpoints: latency-svc-c9x9d [258.668474ms]
Mar  4 22:58:53.602: INFO: Created: latency-svc-zb6x7
Mar  4 22:58:53.610: INFO: Got endpoints: latency-svc-zb6x7 [252.444665ms]
Mar  4 22:58:53.617: INFO: Created: latency-svc-nnlnc
Mar  4 22:58:53.626: INFO: Got endpoints: latency-svc-nnlnc [234.379812ms]
Mar  4 22:58:53.632: INFO: Created: latency-svc-5nx74
Mar  4 22:58:53.640: INFO: Got endpoints: latency-svc-5nx74 [234.467487ms]
Mar  4 22:58:53.645: INFO: Created: latency-svc-k97bq
Mar  4 22:58:53.652: INFO: Got endpoints: latency-svc-k97bq [230.360427ms]
Mar  4 22:58:53.660: INFO: Created: latency-svc-bk2jm
Mar  4 22:58:53.668: INFO: Got endpoints: latency-svc-bk2jm [224.633406ms]
Mar  4 22:58:53.673: INFO: Created: latency-svc-swwgq
Mar  4 22:58:53.685: INFO: Got endpoints: latency-svc-swwgq [227.82474ms]
Mar  4 22:58:53.691: INFO: Created: latency-svc-42d55
Mar  4 22:58:53.700: INFO: Got endpoints: latency-svc-42d55 [228.831914ms]
Mar  4 22:58:53.705: INFO: Created: latency-svc-sh7ls
Mar  4 22:58:53.713: INFO: Got endpoints: latency-svc-sh7ls [224.368746ms]
Mar  4 22:58:53.720: INFO: Created: latency-svc-lwtgm
Mar  4 22:58:53.731: INFO: Got endpoints: latency-svc-lwtgm [226.989468ms]
Mar  4 22:58:53.738: INFO: Created: latency-svc-2gbf8
Mar  4 22:58:53.750: INFO: Got endpoints: latency-svc-2gbf8 [231.170419ms]
Mar  4 22:58:53.756: INFO: Created: latency-svc-rpsn2
Mar  4 22:58:53.767: INFO: Got endpoints: latency-svc-rpsn2 [232.630149ms]
Mar  4 22:58:53.774: INFO: Created: latency-svc-ktwf6
Mar  4 22:58:53.782: INFO: Got endpoints: latency-svc-ktwf6 [232.682019ms]
Mar  4 22:58:53.788: INFO: Created: latency-svc-5tcp4
Mar  4 22:58:53.798: INFO: Got endpoints: latency-svc-5tcp4 [233.576636ms]
Mar  4 22:58:53.803: INFO: Created: latency-svc-c8xrj
Mar  4 22:58:53.813: INFO: Got endpoints: latency-svc-c8xrj [230.945229ms]
Mar  4 22:58:53.819: INFO: Created: latency-svc-5vk9d
Mar  4 22:58:53.828: INFO: Got endpoints: latency-svc-5vk9d [231.198315ms]
Mar  4 22:58:53.834: INFO: Created: latency-svc-fpxrw
Mar  4 22:58:53.842: INFO: Got endpoints: latency-svc-fpxrw [232.504695ms]
Mar  4 22:58:53.848: INFO: Created: latency-svc-jcqbn
Mar  4 22:58:53.858: INFO: Got endpoints: latency-svc-jcqbn [231.624352ms]
Mar  4 22:58:53.864: INFO: Created: latency-svc-k2pb6
Mar  4 22:58:53.878: INFO: Got endpoints: latency-svc-k2pb6 [237.702146ms]
Mar  4 22:58:53.887: INFO: Created: latency-svc-d4bfs
Mar  4 22:58:53.895: INFO: Got endpoints: latency-svc-d4bfs [242.533744ms]
Mar  4 22:58:53.905: INFO: Created: latency-svc-vjsr5
Mar  4 22:58:53.913: INFO: Got endpoints: latency-svc-vjsr5 [244.643025ms]
Mar  4 22:58:53.920: INFO: Created: latency-svc-n7pmf
Mar  4 22:58:53.930: INFO: Got endpoints: latency-svc-n7pmf [244.510169ms]
Mar  4 22:58:53.933: INFO: Created: latency-svc-v5sc8
Mar  4 22:58:53.942: INFO: Got endpoints: latency-svc-v5sc8 [242.798366ms]
Mar  4 22:58:53.949: INFO: Created: latency-svc-74stv
Mar  4 22:58:53.964: INFO: Created: latency-svc-nmc45
Mar  4 22:58:53.966: INFO: Got endpoints: latency-svc-74stv [252.718531ms]
Mar  4 22:58:53.979: INFO: Created: latency-svc-wrkpw
Mar  4 22:58:53.993: INFO: Created: latency-svc-xhclf
Mar  4 22:58:54.007: INFO: Created: latency-svc-69g9j
Mar  4 22:58:54.015: INFO: Got endpoints: latency-svc-nmc45 [284.411073ms]
Mar  4 22:58:54.021: INFO: Created: latency-svc-qqz4f
Mar  4 22:58:54.035: INFO: Created: latency-svc-ph8sf
Mar  4 22:58:54.051: INFO: Created: latency-svc-zrt9l
Mar  4 22:58:54.065: INFO: Got endpoints: latency-svc-wrkpw [315.330647ms]
Mar  4 22:58:54.065: INFO: Created: latency-svc-lhf99
Mar  4 22:58:54.079: INFO: Created: latency-svc-vwg5z
Mar  4 22:58:54.093: INFO: Created: latency-svc-t7zmt
Mar  4 22:58:54.105: INFO: Created: latency-svc-hfz7k
Mar  4 22:58:54.116: INFO: Got endpoints: latency-svc-xhclf [349.342268ms]
Mar  4 22:58:54.118: INFO: Created: latency-svc-xxdft
Mar  4 22:58:54.134: INFO: Created: latency-svc-rrb92
Mar  4 22:58:54.153: INFO: Created: latency-svc-hdsch
Mar  4 22:58:54.165: INFO: Got endpoints: latency-svc-69g9j [383.538409ms]
Mar  4 22:58:54.166: INFO: Created: latency-svc-6xprs
Mar  4 22:58:54.183: INFO: Created: latency-svc-q458m
Mar  4 22:58:54.198: INFO: Created: latency-svc-49xgp
Mar  4 22:58:54.212: INFO: Created: latency-svc-n7ssn
Mar  4 22:58:54.217: INFO: Got endpoints: latency-svc-qqz4f [419.149175ms]
Mar  4 22:58:54.225: INFO: Created: latency-svc-8xqwq
Mar  4 22:58:54.240: INFO: Created: latency-svc-6wl7x
Mar  4 22:58:54.267: INFO: Got endpoints: latency-svc-ph8sf [454.464073ms]
Mar  4 22:58:54.291: INFO: Created: latency-svc-ftlzz
Mar  4 22:58:54.316: INFO: Got endpoints: latency-svc-zrt9l [488.482318ms]
Mar  4 22:58:54.341: INFO: Created: latency-svc-fwmq9
Mar  4 22:58:54.367: INFO: Got endpoints: latency-svc-lhf99 [524.735386ms]
Mar  4 22:58:54.389: INFO: Created: latency-svc-qsfww
Mar  4 22:58:54.417: INFO: Got endpoints: latency-svc-vwg5z [559.631915ms]
Mar  4 22:58:54.448: INFO: Created: latency-svc-lgbgb
Mar  4 22:58:54.467: INFO: Got endpoints: latency-svc-t7zmt [588.425863ms]
Mar  4 22:58:54.493: INFO: Created: latency-svc-d2chg
Mar  4 22:58:54.518: INFO: Got endpoints: latency-svc-hfz7k [623.257351ms]
Mar  4 22:58:54.541: INFO: Created: latency-svc-k7xvn
Mar  4 22:58:54.568: INFO: Got endpoints: latency-svc-xxdft [654.949798ms]
Mar  4 22:58:54.591: INFO: Created: latency-svc-z2h99
Mar  4 22:58:54.619: INFO: Got endpoints: latency-svc-rrb92 [688.976847ms]
Mar  4 22:58:54.648: INFO: Created: latency-svc-tzbzd
Mar  4 22:58:54.668: INFO: Got endpoints: latency-svc-hdsch [725.151214ms]
Mar  4 22:58:54.695: INFO: Created: latency-svc-2f244
Mar  4 22:58:54.718: INFO: Got endpoints: latency-svc-6xprs [752.274947ms]
Mar  4 22:58:54.741: INFO: Created: latency-svc-b2m9z
Mar  4 22:58:54.767: INFO: Got endpoints: latency-svc-q458m [751.899267ms]
Mar  4 22:58:54.792: INFO: Created: latency-svc-mp5qk
Mar  4 22:58:54.817: INFO: Got endpoints: latency-svc-49xgp [751.369836ms]
Mar  4 22:58:54.839: INFO: Created: latency-svc-jgf4p
Mar  4 22:58:54.866: INFO: Got endpoints: latency-svc-n7ssn [749.788972ms]
Mar  4 22:58:54.889: INFO: Created: latency-svc-dkb7p
Mar  4 22:58:54.917: INFO: Got endpoints: latency-svc-8xqwq [751.504561ms]
Mar  4 22:58:54.943: INFO: Created: latency-svc-2fssk
Mar  4 22:58:54.971: INFO: Got endpoints: latency-svc-6wl7x [753.988204ms]
Mar  4 22:58:55.005: INFO: Created: latency-svc-gf74k
Mar  4 22:58:55.018: INFO: Got endpoints: latency-svc-ftlzz [751.151401ms]
Mar  4 22:58:55.043: INFO: Created: latency-svc-r445q
Mar  4 22:58:55.066: INFO: Got endpoints: latency-svc-fwmq9 [750.069836ms]
Mar  4 22:58:55.089: INFO: Created: latency-svc-jwkqx
Mar  4 22:58:55.117: INFO: Got endpoints: latency-svc-qsfww [750.004925ms]
Mar  4 22:58:55.149: INFO: Created: latency-svc-58rtq
Mar  4 22:58:55.170: INFO: Got endpoints: latency-svc-lgbgb [752.965693ms]
Mar  4 22:58:55.197: INFO: Created: latency-svc-kxgdk
Mar  4 22:58:55.218: INFO: Got endpoints: latency-svc-d2chg [751.181427ms]
Mar  4 22:58:55.240: INFO: Created: latency-svc-z9bzz
Mar  4 22:58:55.267: INFO: Got endpoints: latency-svc-k7xvn [747.987391ms]
Mar  4 22:58:55.289: INFO: Created: latency-svc-2lppx
Mar  4 22:58:55.319: INFO: Got endpoints: latency-svc-z2h99 [750.599695ms]
Mar  4 22:58:55.345: INFO: Created: latency-svc-n2srp
Mar  4 22:58:55.370: INFO: Got endpoints: latency-svc-tzbzd [750.566242ms]
Mar  4 22:58:55.392: INFO: Created: latency-svc-zc5ht
Mar  4 22:58:55.419: INFO: Got endpoints: latency-svc-2f244 [750.650541ms]
Mar  4 22:58:55.441: INFO: Created: latency-svc-rdnb6
Mar  4 22:58:55.467: INFO: Got endpoints: latency-svc-b2m9z [749.098624ms]
Mar  4 22:58:55.494: INFO: Created: latency-svc-lscfm
Mar  4 22:58:55.516: INFO: Got endpoints: latency-svc-mp5qk [748.357037ms]
Mar  4 22:58:55.538: INFO: Created: latency-svc-wssvf
Mar  4 22:58:55.568: INFO: Got endpoints: latency-svc-jgf4p [750.553353ms]
Mar  4 22:58:55.592: INFO: Created: latency-svc-2vhtf
Mar  4 22:58:55.617: INFO: Got endpoints: latency-svc-dkb7p [750.688062ms]
Mar  4 22:58:55.644: INFO: Created: latency-svc-ssn2t
Mar  4 22:58:55.666: INFO: Got endpoints: latency-svc-2fssk [748.83149ms]
Mar  4 22:58:55.688: INFO: Created: latency-svc-sql7l
Mar  4 22:58:55.717: INFO: Got endpoints: latency-svc-gf74k [745.983527ms]
Mar  4 22:58:55.741: INFO: Created: latency-svc-8xr5m
Mar  4 22:58:55.767: INFO: Got endpoints: latency-svc-r445q [748.192293ms]
Mar  4 22:58:55.788: INFO: Created: latency-svc-tjqkn
Mar  4 22:58:55.818: INFO: Got endpoints: latency-svc-jwkqx [750.869112ms]
Mar  4 22:58:55.843: INFO: Created: latency-svc-zqbdr
Mar  4 22:58:55.867: INFO: Got endpoints: latency-svc-58rtq [749.51611ms]
Mar  4 22:58:55.891: INFO: Created: latency-svc-5th2x
Mar  4 22:58:55.931: INFO: Got endpoints: latency-svc-kxgdk [760.367414ms]
Mar  4 22:58:55.965: INFO: Created: latency-svc-wnm2v
Mar  4 22:58:55.970: INFO: Got endpoints: latency-svc-z9bzz [751.977661ms]
Mar  4 22:58:55.995: INFO: Created: latency-svc-285zc
Mar  4 22:58:56.016: INFO: Got endpoints: latency-svc-2lppx [749.03505ms]
Mar  4 22:58:56.036: INFO: Created: latency-svc-s2cnn
Mar  4 22:58:56.067: INFO: Got endpoints: latency-svc-n2srp [747.993177ms]
Mar  4 22:58:56.088: INFO: Created: latency-svc-v4qgx
Mar  4 22:58:56.116: INFO: Got endpoints: latency-svc-zc5ht [746.405011ms]
Mar  4 22:58:56.138: INFO: Created: latency-svc-dcbf8
Mar  4 22:58:56.166: INFO: Got endpoints: latency-svc-rdnb6 [747.626112ms]
Mar  4 22:58:56.189: INFO: Created: latency-svc-kbdwc
Mar  4 22:58:56.219: INFO: Got endpoints: latency-svc-lscfm [751.632989ms]
Mar  4 22:58:56.243: INFO: Created: latency-svc-c75gr
Mar  4 22:58:56.272: INFO: Got endpoints: latency-svc-wssvf [756.364403ms]
Mar  4 22:58:56.295: INFO: Created: latency-svc-jrrzs
Mar  4 22:58:56.317: INFO: Got endpoints: latency-svc-2vhtf [748.847398ms]
Mar  4 22:58:56.341: INFO: Created: latency-svc-pxt7z
Mar  4 22:58:56.366: INFO: Got endpoints: latency-svc-ssn2t [749.045922ms]
Mar  4 22:58:56.387: INFO: Created: latency-svc-98gmd
Mar  4 22:58:56.417: INFO: Got endpoints: latency-svc-sql7l [751.188848ms]
Mar  4 22:58:56.445: INFO: Created: latency-svc-snvjr
Mar  4 22:58:56.466: INFO: Got endpoints: latency-svc-8xr5m [749.356631ms]
Mar  4 22:58:56.494: INFO: Created: latency-svc-qwnhv
Mar  4 22:58:56.516: INFO: Got endpoints: latency-svc-tjqkn [749.572666ms]
Mar  4 22:58:56.538: INFO: Created: latency-svc-scsbh
Mar  4 22:58:56.567: INFO: Got endpoints: latency-svc-zqbdr [749.017876ms]
Mar  4 22:58:56.588: INFO: Created: latency-svc-kxfgm
Mar  4 22:58:56.615: INFO: Got endpoints: latency-svc-5th2x [748.40642ms]
Mar  4 22:58:56.637: INFO: Created: latency-svc-44kmv
Mar  4 22:58:56.667: INFO: Got endpoints: latency-svc-wnm2v [735.664229ms]
Mar  4 22:58:56.688: INFO: Created: latency-svc-m5554
Mar  4 22:58:56.717: INFO: Got endpoints: latency-svc-285zc [747.444867ms]
Mar  4 22:58:56.741: INFO: Created: latency-svc-59frh
Mar  4 22:58:56.770: INFO: Got endpoints: latency-svc-s2cnn [753.912247ms]
Mar  4 22:58:56.813: INFO: Created: latency-svc-w2knb
Mar  4 22:58:56.818: INFO: Got endpoints: latency-svc-v4qgx [750.759678ms]
Mar  4 22:58:56.841: INFO: Created: latency-svc-wfzgk
Mar  4 22:58:56.868: INFO: Got endpoints: latency-svc-dcbf8 [751.680744ms]
Mar  4 22:58:56.891: INFO: Created: latency-svc-q6tsr
Mar  4 22:58:56.917: INFO: Got endpoints: latency-svc-kbdwc [750.562832ms]
Mar  4 22:58:56.943: INFO: Created: latency-svc-k256f
Mar  4 22:58:56.968: INFO: Got endpoints: latency-svc-c75gr [749.242595ms]
Mar  4 22:58:56.996: INFO: Created: latency-svc-vprhd
Mar  4 22:58:57.022: INFO: Got endpoints: latency-svc-jrrzs [749.16696ms]
Mar  4 22:58:57.044: INFO: Created: latency-svc-tqcpw
Mar  4 22:58:57.067: INFO: Got endpoints: latency-svc-pxt7z [749.350131ms]
Mar  4 22:58:57.089: INFO: Created: latency-svc-zssst
Mar  4 22:58:57.122: INFO: Got endpoints: latency-svc-98gmd [756.201519ms]
Mar  4 22:58:57.153: INFO: Created: latency-svc-tw8m9
Mar  4 22:58:57.166: INFO: Got endpoints: latency-svc-snvjr [749.138087ms]
Mar  4 22:58:57.193: INFO: Created: latency-svc-qfsnq
Mar  4 22:58:57.219: INFO: Got endpoints: latency-svc-qwnhv [753.083295ms]
Mar  4 22:58:57.256: INFO: Created: latency-svc-v7jmj
Mar  4 22:58:57.267: INFO: Got endpoints: latency-svc-scsbh [750.774548ms]
Mar  4 22:58:57.291: INFO: Created: latency-svc-gm8fk
Mar  4 22:58:57.317: INFO: Got endpoints: latency-svc-kxfgm [750.494644ms]
Mar  4 22:58:57.339: INFO: Created: latency-svc-c22wz
Mar  4 22:58:57.367: INFO: Got endpoints: latency-svc-44kmv [751.507582ms]
Mar  4 22:58:57.393: INFO: Created: latency-svc-hqmwf
Mar  4 22:58:57.419: INFO: Got endpoints: latency-svc-m5554 [751.929272ms]
Mar  4 22:58:57.446: INFO: Created: latency-svc-2hxxw
Mar  4 22:58:57.467: INFO: Got endpoints: latency-svc-59frh [749.75304ms]
Mar  4 22:58:57.492: INFO: Created: latency-svc-pnpds
Mar  4 22:58:57.516: INFO: Got endpoints: latency-svc-w2knb [746.544022ms]
Mar  4 22:58:57.539: INFO: Created: latency-svc-thzds
Mar  4 22:58:57.566: INFO: Got endpoints: latency-svc-wfzgk [748.45021ms]
Mar  4 22:58:57.588: INFO: Created: latency-svc-jwzmr
Mar  4 22:58:57.617: INFO: Got endpoints: latency-svc-q6tsr [749.467094ms]
Mar  4 22:58:57.646: INFO: Created: latency-svc-vxn2w
Mar  4 22:58:57.666: INFO: Got endpoints: latency-svc-k256f [749.11857ms]
Mar  4 22:58:57.689: INFO: Created: latency-svc-zm6qx
Mar  4 22:58:57.717: INFO: Got endpoints: latency-svc-vprhd [748.981722ms]
Mar  4 22:58:57.745: INFO: Created: latency-svc-n49lm
Mar  4 22:58:57.766: INFO: Got endpoints: latency-svc-tqcpw [744.775115ms]
Mar  4 22:58:57.790: INFO: Created: latency-svc-gx2dx
Mar  4 22:58:57.818: INFO: Got endpoints: latency-svc-zssst [751.016099ms]
Mar  4 22:58:57.843: INFO: Created: latency-svc-n8r7l
Mar  4 22:58:57.872: INFO: Got endpoints: latency-svc-tw8m9 [749.98917ms]
Mar  4 22:58:57.897: INFO: Created: latency-svc-4gcwz
Mar  4 22:58:57.917: INFO: Got endpoints: latency-svc-qfsnq [750.068659ms]
Mar  4 22:58:57.939: INFO: Created: latency-svc-s8zrp
Mar  4 22:58:57.968: INFO: Got endpoints: latency-svc-v7jmj [748.227863ms]
Mar  4 22:58:57.991: INFO: Created: latency-svc-62vdw
Mar  4 22:58:58.026: INFO: Got endpoints: latency-svc-gm8fk [758.691231ms]
Mar  4 22:58:58.048: INFO: Created: latency-svc-78sbk
Mar  4 22:58:58.066: INFO: Got endpoints: latency-svc-c22wz [748.937846ms]
Mar  4 22:58:58.523: INFO: Got endpoints: latency-svc-hqmwf [1.156321115s]
Mar  4 22:58:58.524: INFO: Got endpoints: latency-svc-2hxxw [1.104937763s]
Mar  4 22:58:58.583: INFO: Got endpoints: latency-svc-n8r7l [765.608532ms]
Mar  4 22:58:58.584: INFO: Created: latency-svc-5vphb
Mar  4 22:58:58.584: INFO: Got endpoints: latency-svc-pnpds [1.116159609s]
Mar  4 22:58:58.584: INFO: Got endpoints: latency-svc-thzds [1.067179656s]
Mar  4 22:58:58.584: INFO: Got endpoints: latency-svc-jwzmr [1.017169576s]
Mar  4 22:58:58.584: INFO: Got endpoints: latency-svc-gx2dx [816.775714ms]
Mar  4 22:58:58.584: INFO: Got endpoints: latency-svc-n49lm [865.951965ms]
Mar  4 22:58:58.584: INFO: Created: latency-svc-fl8p9
Mar  4 22:58:58.584: INFO: Got endpoints: latency-svc-zm6qx [917.208146ms]
Mar  4 22:58:58.584: INFO: Got endpoints: latency-svc-vxn2w [966.086734ms]
Mar  4 22:58:58.591: INFO: Created: latency-svc-q95cd
Mar  4 22:58:58.610: INFO: Created: latency-svc-2dzrk
Mar  4 22:58:58.618: INFO: Got endpoints: latency-svc-4gcwz [745.239885ms]
Mar  4 22:58:58.625: INFO: Created: latency-svc-fw2q8
Mar  4 22:58:58.640: INFO: Created: latency-svc-tmbh2
Mar  4 22:58:58.654: INFO: Created: latency-svc-78l7b
Mar  4 22:58:58.669: INFO: Created: latency-svc-t5k55
Mar  4 22:58:58.678: INFO: Got endpoints: latency-svc-s8zrp [761.177284ms]
Mar  4 22:58:58.692: INFO: Created: latency-svc-lkzjs
Mar  4 22:58:58.706: INFO: Created: latency-svc-w4cqq
Mar  4 22:58:58.720: INFO: Got endpoints: latency-svc-62vdw [752.61889ms]
Mar  4 22:58:58.722: INFO: Created: latency-svc-pnrp7
Mar  4 22:58:58.737: INFO: Created: latency-svc-gzgpb
Mar  4 22:58:58.755: INFO: Created: latency-svc-8bjls
Mar  4 22:58:58.771: INFO: Created: latency-svc-zrvcw
Mar  4 22:58:58.771: INFO: Got endpoints: latency-svc-78sbk [745.224148ms]
Mar  4 22:58:58.794: INFO: Created: latency-svc-88npn
Mar  4 22:58:58.816: INFO: Got endpoints: latency-svc-5vphb [749.694466ms]
Mar  4 22:58:58.838: INFO: Created: latency-svc-s9nlb
Mar  4 22:58:58.866: INFO: Got endpoints: latency-svc-fl8p9 [342.257769ms]
Mar  4 22:58:58.898: INFO: Created: latency-svc-jbb4k
Mar  4 22:58:58.917: INFO: Got endpoints: latency-svc-q95cd [393.393049ms]
Mar  4 22:58:58.940: INFO: Created: latency-svc-lwkj4
Mar  4 22:58:58.980: INFO: Got endpoints: latency-svc-2dzrk [396.211141ms]
Mar  4 22:58:59.014: INFO: Created: latency-svc-6zt9n
Mar  4 22:58:59.018: INFO: Got endpoints: latency-svc-fw2q8 [434.15393ms]
Mar  4 22:58:59.045: INFO: Created: latency-svc-7k8rs
Mar  4 22:58:59.067: INFO: Got endpoints: latency-svc-tmbh2 [482.915483ms]
Mar  4 22:58:59.092: INFO: Created: latency-svc-b2pj5
Mar  4 22:58:59.116: INFO: Got endpoints: latency-svc-78l7b [532.104355ms]
Mar  4 22:58:59.139: INFO: Created: latency-svc-n7bbr
Mar  4 22:58:59.167: INFO: Got endpoints: latency-svc-t5k55 [582.011236ms]
Mar  4 22:58:59.189: INFO: Created: latency-svc-btz6g
Mar  4 22:58:59.220: INFO: Got endpoints: latency-svc-lkzjs [635.60815ms]
Mar  4 22:58:59.242: INFO: Created: latency-svc-vmhbj
Mar  4 22:58:59.267: INFO: Got endpoints: latency-svc-w4cqq [683.062429ms]
Mar  4 22:58:59.293: INFO: Created: latency-svc-pksff
Mar  4 22:58:59.317: INFO: Got endpoints: latency-svc-pnrp7 [732.577445ms]
Mar  4 22:58:59.343: INFO: Created: latency-svc-8z5gs
Mar  4 22:58:59.366: INFO: Got endpoints: latency-svc-gzgpb [748.245042ms]
Mar  4 22:58:59.387: INFO: Created: latency-svc-nqw79
Mar  4 22:58:59.416: INFO: Got endpoints: latency-svc-8bjls [738.191681ms]
Mar  4 22:58:59.450: INFO: Created: latency-svc-9zrtl
Mar  4 22:58:59.466: INFO: Got endpoints: latency-svc-zrvcw [745.759402ms]
Mar  4 22:58:59.489: INFO: Created: latency-svc-cnw4b
Mar  4 22:58:59.521: INFO: Got endpoints: latency-svc-88npn [749.111329ms]
Mar  4 22:58:59.544: INFO: Created: latency-svc-q2h54
Mar  4 22:58:59.566: INFO: Got endpoints: latency-svc-s9nlb [749.875497ms]
Mar  4 22:58:59.588: INFO: Created: latency-svc-5gj9c
Mar  4 22:58:59.617: INFO: Got endpoints: latency-svc-jbb4k [751.185653ms]
Mar  4 22:58:59.638: INFO: Created: latency-svc-gtjc6
Mar  4 22:58:59.666: INFO: Got endpoints: latency-svc-lwkj4 [749.167364ms]
Mar  4 22:58:59.693: INFO: Created: latency-svc-nhs75
Mar  4 22:58:59.716: INFO: Got endpoints: latency-svc-6zt9n [736.369518ms]
Mar  4 22:58:59.744: INFO: Created: latency-svc-mzc8d
Mar  4 22:58:59.769: INFO: Got endpoints: latency-svc-7k8rs [750.364169ms]
Mar  4 22:58:59.792: INFO: Created: latency-svc-bgvpr
Mar  4 22:58:59.817: INFO: Got endpoints: latency-svc-b2pj5 [749.76806ms]
Mar  4 22:58:59.841: INFO: Created: latency-svc-478fg
Mar  4 22:58:59.867: INFO: Got endpoints: latency-svc-n7bbr [750.603886ms]
Mar  4 22:58:59.888: INFO: Created: latency-svc-2p595
Mar  4 22:58:59.917: INFO: Got endpoints: latency-svc-btz6g [749.959653ms]
Mar  4 22:58:59.943: INFO: Created: latency-svc-6zxfj
Mar  4 22:58:59.966: INFO: Got endpoints: latency-svc-vmhbj [745.985311ms]
Mar  4 22:58:59.988: INFO: Created: latency-svc-cwxw4
Mar  4 22:59:00.017: INFO: Got endpoints: latency-svc-pksff [749.575141ms]
Mar  4 22:59:00.039: INFO: Created: latency-svc-4kgx2
Mar  4 22:59:00.066: INFO: Got endpoints: latency-svc-8z5gs [749.097543ms]
Mar  4 22:59:00.091: INFO: Created: latency-svc-5tkt8
Mar  4 22:59:00.117: INFO: Got endpoints: latency-svc-nqw79 [750.635083ms]
Mar  4 22:59:00.141: INFO: Created: latency-svc-gbm4s
Mar  4 22:59:00.166: INFO: Got endpoints: latency-svc-9zrtl [749.948479ms]
Mar  4 22:59:00.188: INFO: Created: latency-svc-2hvvk
Mar  4 22:59:00.216: INFO: Got endpoints: latency-svc-cnw4b [749.75574ms]
Mar  4 22:59:00.240: INFO: Created: latency-svc-tmc9k
Mar  4 22:59:00.267: INFO: Got endpoints: latency-svc-q2h54 [745.746441ms]
Mar  4 22:59:00.290: INFO: Created: latency-svc-zg446
Mar  4 22:59:00.317: INFO: Got endpoints: latency-svc-5gj9c [750.85151ms]
Mar  4 22:59:00.341: INFO: Created: latency-svc-stjjd
Mar  4 22:59:00.367: INFO: Got endpoints: latency-svc-gtjc6 [749.458796ms]
Mar  4 22:59:00.389: INFO: Created: latency-svc-bjvc2
Mar  4 22:59:00.417: INFO: Got endpoints: latency-svc-nhs75 [750.490691ms]
Mar  4 22:59:00.446: INFO: Created: latency-svc-zhm64
Mar  4 22:59:00.469: INFO: Got endpoints: latency-svc-mzc8d [752.19697ms]
Mar  4 22:59:00.494: INFO: Created: latency-svc-mmlnb
Mar  4 22:59:00.520: INFO: Got endpoints: latency-svc-bgvpr [751.110887ms]
Mar  4 22:59:00.541: INFO: Created: latency-svc-7tkzg
Mar  4 22:59:00.567: INFO: Got endpoints: latency-svc-478fg [750.78441ms]
Mar  4 22:59:00.590: INFO: Created: latency-svc-vc7kc
Mar  4 22:59:00.623: INFO: Got endpoints: latency-svc-2p595 [755.674764ms]
Mar  4 22:59:00.649: INFO: Created: latency-svc-h4x5b
Mar  4 22:59:00.667: INFO: Got endpoints: latency-svc-6zxfj [750.573364ms]
Mar  4 22:59:00.691: INFO: Created: latency-svc-6vjs6
Mar  4 22:59:00.716: INFO: Got endpoints: latency-svc-cwxw4 [750.224638ms]
Mar  4 22:59:00.740: INFO: Created: latency-svc-696kx
Mar  4 22:59:00.766: INFO: Got endpoints: latency-svc-4kgx2 [749.423144ms]
Mar  4 22:59:00.788: INFO: Created: latency-svc-br9mb
Mar  4 22:59:00.816: INFO: Got endpoints: latency-svc-5tkt8 [749.566438ms]
Mar  4 22:59:00.839: INFO: Created: latency-svc-jvlww
Mar  4 22:59:00.870: INFO: Got endpoints: latency-svc-gbm4s [752.766956ms]
Mar  4 22:59:00.895: INFO: Created: latency-svc-svhs4
Mar  4 22:59:00.916: INFO: Got endpoints: latency-svc-2hvvk [749.425963ms]
Mar  4 22:59:00.943: INFO: Created: latency-svc-xnnq5
Mar  4 22:59:00.968: INFO: Got endpoints: latency-svc-tmc9k [751.810239ms]
Mar  4 22:59:00.993: INFO: Created: latency-svc-5sb5b
Mar  4 22:59:01.016: INFO: Got endpoints: latency-svc-zg446 [749.501907ms]
Mar  4 22:59:01.040: INFO: Created: latency-svc-lsfg4
Mar  4 22:59:01.067: INFO: Got endpoints: latency-svc-stjjd [750.011779ms]
Mar  4 22:59:01.117: INFO: Got endpoints: latency-svc-bjvc2 [750.263379ms]
Mar  4 22:59:01.168: INFO: Got endpoints: latency-svc-zhm64 [751.287492ms]
Mar  4 22:59:01.217: INFO: Got endpoints: latency-svc-mmlnb [748.762121ms]
Mar  4 22:59:01.282: INFO: Got endpoints: latency-svc-7tkzg [762.485866ms]
Mar  4 22:59:01.320: INFO: Got endpoints: latency-svc-vc7kc [752.119843ms]
Mar  4 22:59:01.371: INFO: Got endpoints: latency-svc-h4x5b [748.005629ms]
Mar  4 22:59:01.417: INFO: Got endpoints: latency-svc-6vjs6 [749.251026ms]
Mar  4 22:59:01.468: INFO: Got endpoints: latency-svc-696kx [750.975845ms]
Mar  4 22:59:01.518: INFO: Got endpoints: latency-svc-br9mb [751.269426ms]
Mar  4 22:59:01.570: INFO: Got endpoints: latency-svc-jvlww [754.030842ms]
Mar  4 22:59:01.616: INFO: Got endpoints: latency-svc-svhs4 [746.723386ms]
Mar  4 22:59:01.667: INFO: Got endpoints: latency-svc-xnnq5 [750.982762ms]
Mar  4 22:59:01.718: INFO: Got endpoints: latency-svc-5sb5b [749.660483ms]
Mar  4 22:59:01.771: INFO: Got endpoints: latency-svc-lsfg4 [754.756002ms]
Mar  4 22:59:01.771: INFO: Latencies: [31.616805ms 46.058212ms 50.830329ms 65.39693ms 81.32774ms 100.518554ms 120.572493ms 136.893236ms 154.068572ms 184.661117ms 205.841659ms 219.772295ms 224.368746ms 224.633406ms 226.989468ms 227.82474ms 228.831914ms 230.360427ms 230.945229ms 231.170419ms 231.198315ms 231.624352ms 232.504695ms 232.630149ms 232.682019ms 233.106219ms 233.576636ms 234.379812ms 234.467487ms 237.702146ms 242.533744ms 242.798366ms 244.510169ms 244.643025ms 251.12065ms 251.6494ms 252.444665ms 252.718531ms 258.668474ms 261.607678ms 261.926329ms 263.308305ms 266.155924ms 280.617649ms 284.411073ms 315.330647ms 342.257769ms 349.342268ms 383.538409ms 393.393049ms 396.211141ms 419.149175ms 434.15393ms 454.464073ms 482.915483ms 488.482318ms 524.735386ms 532.104355ms 559.631915ms 582.011236ms 588.425863ms 623.257351ms 635.60815ms 654.949798ms 683.062429ms 688.976847ms 725.151214ms 732.577445ms 735.664229ms 736.369518ms 738.191681ms 744.775115ms 745.224148ms 745.239885ms 745.746441ms 745.759402ms 745.983527ms 745.985311ms 746.405011ms 746.544022ms 746.723386ms 747.444867ms 747.626112ms 747.987391ms 747.993177ms 748.005629ms 748.192293ms 748.227863ms 748.245042ms 748.357037ms 748.40642ms 748.45021ms 748.762121ms 748.83149ms 748.847398ms 748.937846ms 748.981722ms 749.017876ms 749.03505ms 749.045922ms 749.097543ms 749.098624ms 749.111329ms 749.11857ms 749.138087ms 749.16696ms 749.167364ms 749.242595ms 749.251026ms 749.350131ms 749.356631ms 749.423144ms 749.425963ms 749.458796ms 749.467094ms 749.501907ms 749.51611ms 749.566438ms 749.572666ms 749.575141ms 749.660483ms 749.694466ms 749.75304ms 749.75574ms 749.76806ms 749.788972ms 749.875497ms 749.948479ms 749.959653ms 749.98917ms 750.004925ms 750.011779ms 750.068659ms 750.069836ms 750.224638ms 750.263379ms 750.364169ms 750.490691ms 750.494644ms 750.553353ms 750.562832ms 750.566242ms 750.573364ms 750.599695ms 750.603886ms 750.635083ms 750.650541ms 750.688062ms 750.759678ms 750.774548ms 750.78441ms 750.85151ms 750.869112ms 750.975845ms 750.982762ms 751.016099ms 751.110887ms 751.151401ms 751.181427ms 751.185653ms 751.188848ms 751.269426ms 751.287492ms 751.369836ms 751.504561ms 751.507582ms 751.632989ms 751.680744ms 751.810239ms 751.899267ms 751.929272ms 751.977661ms 752.119843ms 752.19697ms 752.274947ms 752.61889ms 752.766956ms 752.965693ms 753.083295ms 753.912247ms 753.988204ms 754.030842ms 754.756002ms 755.674764ms 756.201519ms 756.364403ms 758.691231ms 760.367414ms 761.177284ms 762.485866ms 765.608532ms 816.775714ms 865.951965ms 917.208146ms 966.086734ms 1.017169576s 1.067179656s 1.104937763s 1.116159609s 1.156321115s]
Mar  4 22:59:01.771: INFO: 50 %ile: 749.097543ms
Mar  4 22:59:01.772: INFO: 90 %ile: 753.988204ms
Mar  4 22:59:01.772: INFO: 99 %ile: 1.116159609s
Mar  4 22:59:01.772: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:59:01.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-8rzg7" for this suite.
Mar  4 22:59:19.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:59:19.920: INFO: namespace: e2e-tests-svc-latency-8rzg7, resource: bindings, ignored listing per whitelist
Mar  4 22:59:20.094: INFO: namespace e2e-tests-svc-latency-8rzg7 deletion completed in 18.313309284s

• [SLOW TEST:29.517 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:59:20.096: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-cpvqg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  4 22:59:20.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-cpvqg'
Mar  4 22:59:20.939: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar  4 22:59:20.939: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Mar  4 22:59:20.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-cpvqg'
Mar  4 22:59:21.117: INFO: stderr: ""
Mar  4 22:59:21.117: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:59:21.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cpvqg" for this suite.
Mar  4 22:59:27.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:59:27.362: INFO: namespace: e2e-tests-kubectl-cpvqg, resource: bindings, ignored listing per whitelist
Mar  4 22:59:27.594: INFO: namespace e2e-tests-kubectl-cpvqg deletion completed in 6.464360304s

• [SLOW TEST:7.498 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:59:27.595: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-xb6vp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0304 22:59:38.083099      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  4 22:59:38.083: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:59:38.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-xb6vp" for this suite.
Mar  4 22:59:46.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:59:46.334: INFO: namespace: e2e-tests-gc-xb6vp, resource: bindings, ignored listing per whitelist
Mar  4 22:59:46.450: INFO: namespace e2e-tests-gc-xb6vp deletion completed in 8.358203037s

• [SLOW TEST:18.856 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:59:46.452: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-rqsgc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Mar  4 22:59:46.708: INFO: Waiting up to 5m0s for pod "var-expansion-34d53123-3ed1-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-var-expansion-rqsgc" to be "success or failure"
Mar  4 22:59:46.787: INFO: Pod "var-expansion-34d53123-3ed1-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 78.949339ms
Mar  4 22:59:48.794: INFO: Pod "var-expansion-34d53123-3ed1-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085180107s
STEP: Saw pod success
Mar  4 22:59:48.794: INFO: Pod "var-expansion-34d53123-3ed1-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:59:48.799: INFO: Trying to get logs from node 10.190.208.160 pod var-expansion-34d53123-3ed1-11e9-b56c-8631b5a7dc0e container dapi-container: <nil>
STEP: delete the pod
Mar  4 22:59:48.840: INFO: Waiting for pod var-expansion-34d53123-3ed1-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:59:48.846: INFO: Pod var-expansion-34d53123-3ed1-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:59:48.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-rqsgc" for this suite.
Mar  4 22:59:54.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 22:59:55.355: INFO: namespace: e2e-tests-var-expansion-rqsgc, resource: bindings, ignored listing per whitelist
Mar  4 22:59:55.413: INFO: namespace e2e-tests-var-expansion-rqsgc deletion completed in 6.525316693s

• [SLOW TEST:8.962 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 22:59:55.413: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-gqg2q
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Mar  4 22:59:55.660: INFO: Waiting up to 5m0s for pod "client-containers-3a2afd8d-3ed1-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-containers-gqg2q" to be "success or failure"
Mar  4 22:59:55.665: INFO: Pod "client-containers-3a2afd8d-3ed1-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.689567ms
Mar  4 22:59:57.670: INFO: Pod "client-containers-3a2afd8d-3ed1-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010231637s
STEP: Saw pod success
Mar  4 22:59:57.671: INFO: Pod "client-containers-3a2afd8d-3ed1-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 22:59:57.675: INFO: Trying to get logs from node 10.190.208.160 pod client-containers-3a2afd8d-3ed1-11e9-b56c-8631b5a7dc0e container test-container: <nil>
STEP: delete the pod
Mar  4 22:59:57.710: INFO: Waiting for pod client-containers-3a2afd8d-3ed1-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 22:59:57.782: INFO: Pod client-containers-3a2afd8d-3ed1-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 22:59:57.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-gqg2q" for this suite.
Mar  4 23:00:03.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:00:04.196: INFO: namespace: e2e-tests-containers-gqg2q, resource: bindings, ignored listing per whitelist
Mar  4 23:00:04.201: INFO: namespace e2e-tests-containers-gqg2q deletion completed in 6.408635741s

• [SLOW TEST:8.788 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:00:04.201: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-cm27k
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar  4 23:00:04.524: INFO: Waiting up to 5m0s for pod "downward-api-3f68c091-3ed1-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-downward-api-cm27k" to be "success or failure"
Mar  4 23:00:04.545: INFO: Pod "downward-api-3f68c091-3ed1-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 20.762247ms
Mar  4 23:00:06.551: INFO: Pod "downward-api-3f68c091-3ed1-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02693336s
STEP: Saw pod success
Mar  4 23:00:06.551: INFO: Pod "downward-api-3f68c091-3ed1-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 23:00:06.556: INFO: Trying to get logs from node 10.190.208.162 pod downward-api-3f68c091-3ed1-11e9-b56c-8631b5a7dc0e container dapi-container: <nil>
STEP: delete the pod
Mar  4 23:00:06.587: INFO: Waiting for pod downward-api-3f68c091-3ed1-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 23:00:06.594: INFO: Pod downward-api-3f68c091-3ed1-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:00:06.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cm27k" for this suite.
Mar  4 23:00:12.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:00:12.803: INFO: namespace: e2e-tests-downward-api-cm27k, resource: bindings, ignored listing per whitelist
Mar  4 23:00:12.892: INFO: namespace e2e-tests-downward-api-cm27k deletion completed in 6.287366313s

• [SLOW TEST:8.691 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:00:12.895: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-gcmgj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0304 23:00:43.692756      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  4 23:00:43.692: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:00:43.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-gcmgj" for this suite.
Mar  4 23:00:51.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:00:51.838: INFO: namespace: e2e-tests-gc-gcmgj, resource: bindings, ignored listing per whitelist
Mar  4 23:00:52.013: INFO: namespace e2e-tests-gc-gcmgj deletion completed in 8.310915573s

• [SLOW TEST:39.118 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:00:52.013: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7nfmf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  4 23:00:52.262: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5be7c225-3ed1-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-projected-7nfmf" to be "success or failure"
Mar  4 23:00:52.267: INFO: Pod "downwardapi-volume-5be7c225-3ed1-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.829556ms
Mar  4 23:00:54.273: INFO: Pod "downwardapi-volume-5be7c225-3ed1-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010385952s
STEP: Saw pod success
Mar  4 23:00:54.273: INFO: Pod "downwardapi-volume-5be7c225-3ed1-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 23:00:54.277: INFO: Trying to get logs from node 10.190.208.162 pod downwardapi-volume-5be7c225-3ed1-11e9-b56c-8631b5a7dc0e container client-container: <nil>
STEP: delete the pod
Mar  4 23:00:54.315: INFO: Waiting for pod downwardapi-volume-5be7c225-3ed1-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 23:00:54.320: INFO: Pod downwardapi-volume-5be7c225-3ed1-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:00:54.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7nfmf" for this suite.
Mar  4 23:01:00.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:01:00.634: INFO: namespace: e2e-tests-projected-7nfmf, resource: bindings, ignored listing per whitelist
Mar  4 23:01:00.676: INFO: namespace e2e-tests-projected-7nfmf deletion completed in 6.346528768s

• [SLOW TEST:8.663 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:01:00.677: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-vt9m2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Mar  4 23:01:04.951: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-vt9m2 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  4 23:01:04.951: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
Mar  4 23:01:05.124: INFO: Exec stderr: ""
Mar  4 23:01:05.124: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-vt9m2 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  4 23:01:05.124: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
Mar  4 23:01:05.406: INFO: Exec stderr: ""
Mar  4 23:01:05.406: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-vt9m2 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  4 23:01:05.407: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
Mar  4 23:01:05.689: INFO: Exec stderr: ""
Mar  4 23:01:05.689: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-vt9m2 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  4 23:01:05.689: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
Mar  4 23:01:05.919: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Mar  4 23:01:05.919: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-vt9m2 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  4 23:01:05.919: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
Mar  4 23:01:06.141: INFO: Exec stderr: ""
Mar  4 23:01:06.141: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-vt9m2 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  4 23:01:06.141: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
Mar  4 23:01:06.363: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Mar  4 23:01:06.364: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-vt9m2 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  4 23:01:06.364: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
Mar  4 23:01:06.566: INFO: Exec stderr: ""
Mar  4 23:01:06.566: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-vt9m2 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  4 23:01:06.566: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
Mar  4 23:01:06.782: INFO: Exec stderr: ""
Mar  4 23:01:06.782: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-vt9m2 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  4 23:01:06.782: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
Mar  4 23:01:07.000: INFO: Exec stderr: ""
Mar  4 23:01:07.000: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-vt9m2 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  4 23:01:07.000: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
Mar  4 23:01:07.263: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:01:07.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-vt9m2" for this suite.
Mar  4 23:01:55.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:01:55.418: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-vt9m2, resource: bindings, ignored listing per whitelist
Mar  4 23:01:55.655: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-vt9m2 deletion completed in 48.381517931s

• [SLOW TEST:54.978 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:01:55.655: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-58hd4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-58hd4
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  4 23:01:55.981: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  4 23:02:22.187: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.30.86.165:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-58hd4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  4 23:02:22.187: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
Mar  4 23:02:22.376: INFO: Found all expected endpoints: [netserver-0]
Mar  4 23:02:22.386: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.30.87.188:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-58hd4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  4 23:02:22.386: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
Mar  4 23:02:22.629: INFO: Found all expected endpoints: [netserver-1]
Mar  4 23:02:22.635: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.30.252.216:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-58hd4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  4 23:02:22.635: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
Mar  4 23:02:22.860: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:02:22.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-58hd4" for this suite.
Mar  4 23:02:46.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:02:47.201: INFO: namespace: e2e-tests-pod-network-test-58hd4, resource: bindings, ignored listing per whitelist
Mar  4 23:02:47.331: INFO: namespace e2e-tests-pod-network-test-58hd4 deletion completed in 24.460574687s

• [SLOW TEST:51.677 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:02:47.333: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-l4flt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Mar  4 23:02:47.579: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Mar  4 23:02:47.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 create -f - --namespace=e2e-tests-kubectl-l4flt'
Mar  4 23:02:47.902: INFO: stderr: ""
Mar  4 23:02:47.902: INFO: stdout: "service/redis-slave created\n"
Mar  4 23:02:47.902: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Mar  4 23:02:47.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 create -f - --namespace=e2e-tests-kubectl-l4flt'
Mar  4 23:02:48.289: INFO: stderr: ""
Mar  4 23:02:48.289: INFO: stdout: "service/redis-master created\n"
Mar  4 23:02:48.289: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Mar  4 23:02:48.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 create -f - --namespace=e2e-tests-kubectl-l4flt'
Mar  4 23:02:48.591: INFO: stderr: ""
Mar  4 23:02:48.591: INFO: stdout: "service/frontend created\n"
Mar  4 23:02:48.591: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Mar  4 23:02:48.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 create -f - --namespace=e2e-tests-kubectl-l4flt'
Mar  4 23:02:48.822: INFO: stderr: ""
Mar  4 23:02:48.822: INFO: stdout: "deployment.extensions/frontend created\n"
Mar  4 23:02:48.822: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Mar  4 23:02:48.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 create -f - --namespace=e2e-tests-kubectl-l4flt'
Mar  4 23:02:49.096: INFO: stderr: ""
Mar  4 23:02:49.096: INFO: stdout: "deployment.extensions/redis-master created\n"
Mar  4 23:02:49.096: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Mar  4 23:02:49.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 create -f - --namespace=e2e-tests-kubectl-l4flt'
Mar  4 23:02:49.348: INFO: stderr: ""
Mar  4 23:02:49.348: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Mar  4 23:02:49.348: INFO: Waiting for all frontend pods to be Running.
Mar  4 23:03:04.401: INFO: Waiting for frontend to serve content.
Mar  4 23:03:09.438: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Mar  4 23:03:14.463: INFO: Trying to add a new entry to the guestbook.
Mar  4 23:03:14.489: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Mar  4 23:03:14.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-l4flt'
Mar  4 23:03:14.698: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  4 23:03:14.698: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Mar  4 23:03:14.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-l4flt'
Mar  4 23:03:14.893: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  4 23:03:14.893: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar  4 23:03:14.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-l4flt'
Mar  4 23:03:15.084: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  4 23:03:15.084: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar  4 23:03:15.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-l4flt'
Mar  4 23:03:15.237: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  4 23:03:15.237: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar  4 23:03:15.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-l4flt'
Mar  4 23:03:15.506: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  4 23:03:15.506: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar  4 23:03:15.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-l4flt'
Mar  4 23:03:15.757: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  4 23:03:15.757: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:03:15.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-l4flt" for this suite.
Mar  4 23:03:55.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:03:55.999: INFO: namespace: e2e-tests-kubectl-l4flt, resource: bindings, ignored listing per whitelist
Mar  4 23:03:57.130: INFO: namespace e2e-tests-kubectl-l4flt deletion completed in 41.362586418s

• [SLOW TEST:69.797 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:03:57.132: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-ffckt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-ffckt
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-ffckt
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-ffckt
Mar  4 23:03:57.397: INFO: Found 0 stateful pods, waiting for 1
Mar  4 23:04:07.403: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Mar  4 23:04:07.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-ffckt ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  4 23:04:08.172: INFO: stderr: ""
Mar  4 23:04:08.172: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  4 23:04:08.172: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  4 23:04:08.178: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar  4 23:04:18.184: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  4 23:04:18.184: INFO: Waiting for statefulset status.replicas updated to 0
Mar  4 23:04:18.206: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998982s
Mar  4 23:04:19.212: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.994541167s
Mar  4 23:04:20.218: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.988130597s
Mar  4 23:04:21.224: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.982118422s
Mar  4 23:04:22.230: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.976215173s
Mar  4 23:04:23.237: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.9705182s
Mar  4 23:04:24.243: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.963235083s
Mar  4 23:04:25.248: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.957335584s
Mar  4 23:04:26.255: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.951734489s
Mar  4 23:04:27.261: INFO: Verifying statefulset ss doesn't scale past 1 for another 945.444479ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-ffckt
Mar  4 23:04:28.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-ffckt ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 23:04:28.600: INFO: stderr: ""
Mar  4 23:04:28.600: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  4 23:04:28.600: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  4 23:04:28.609: INFO: Found 1 stateful pods, waiting for 3
Mar  4 23:04:38.616: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  4 23:04:38.616: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  4 23:04:38.616: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Mar  4 23:04:38.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-ffckt ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  4 23:04:39.021: INFO: stderr: ""
Mar  4 23:04:39.021: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  4 23:04:39.021: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  4 23:04:39.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-ffckt ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  4 23:04:39.367: INFO: stderr: ""
Mar  4 23:04:39.367: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  4 23:04:39.367: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  4 23:04:39.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-ffckt ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  4 23:04:39.723: INFO: stderr: ""
Mar  4 23:04:39.723: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  4 23:04:39.723: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  4 23:04:39.723: INFO: Waiting for statefulset status.replicas updated to 0
Mar  4 23:04:39.783: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Mar  4 23:04:49.794: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  4 23:04:49.794: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar  4 23:04:49.794: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar  4 23:04:49.895: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999997941s
Mar  4 23:04:50.902: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.986862156s
Mar  4 23:04:51.908: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.980772464s
Mar  4 23:04:52.914: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.974561773s
Mar  4 23:04:53.921: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.968466983s
Mar  4 23:04:54.927: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.961457417s
Mar  4 23:04:55.933: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.954830364s
Mar  4 23:04:56.939: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.949204678s
Mar  4 23:04:57.946: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.943068567s
Mar  4 23:04:58.952: INFO: Verifying statefulset ss doesn't scale past 3 for another 936.825542ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-ffckt
Mar  4 23:04:59.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-ffckt ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 23:05:00.304: INFO: stderr: ""
Mar  4 23:05:00.304: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  4 23:05:00.304: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  4 23:05:00.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-ffckt ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 23:05:00.631: INFO: stderr: ""
Mar  4 23:05:00.631: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  4 23:05:00.631: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  4 23:05:00.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-ffckt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 23:05:00.978: INFO: stderr: ""
Mar  4 23:05:00.978: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  4 23:05:00.978: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  4 23:05:00.978: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar  4 23:05:31.003: INFO: Deleting all statefulset in ns e2e-tests-statefulset-ffckt
Mar  4 23:05:31.008: INFO: Scaling statefulset ss to 0
Mar  4 23:05:31.022: INFO: Waiting for statefulset status.replicas updated to 0
Mar  4 23:05:31.027: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:05:31.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-ffckt" for this suite.
Mar  4 23:05:37.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:05:37.291: INFO: namespace: e2e-tests-statefulset-ffckt, resource: bindings, ignored listing per whitelist
Mar  4 23:05:37.680: INFO: namespace e2e-tests-statefulset-ffckt deletion completed in 6.615480432s

• [SLOW TEST:100.548 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:05:37.680: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-wss76
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-06317182-3ed2-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume secrets
Mar  4 23:05:37.999: INFO: Waiting up to 5m0s for pod "pod-secrets-0637d429-3ed2-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-secrets-wss76" to be "success or failure"
Mar  4 23:05:38.003: INFO: Pod "pod-secrets-0637d429-3ed2-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.349307ms
Mar  4 23:05:40.009: INFO: Pod "pod-secrets-0637d429-3ed2-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010280638s
STEP: Saw pod success
Mar  4 23:05:40.010: INFO: Pod "pod-secrets-0637d429-3ed2-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 23:05:40.014: INFO: Trying to get logs from node 10.190.208.160 pod pod-secrets-0637d429-3ed2-11e9-b56c-8631b5a7dc0e container secret-env-test: <nil>
STEP: delete the pod
Mar  4 23:05:40.100: INFO: Waiting for pod pod-secrets-0637d429-3ed2-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 23:05:40.105: INFO: Pod pod-secrets-0637d429-3ed2-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:05:40.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-wss76" for this suite.
Mar  4 23:05:46.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:05:46.343: INFO: namespace: e2e-tests-secrets-wss76, resource: bindings, ignored listing per whitelist
Mar  4 23:05:46.402: INFO: namespace e2e-tests-secrets-wss76 deletion completed in 6.28475596s

• [SLOW TEST:8.723 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:05:46.405: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-g2k9l
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Mar  4 23:05:46.646: INFO: Waiting up to 5m0s for pod "pod-0b5f74c9-3ed2-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-emptydir-g2k9l" to be "success or failure"
Mar  4 23:05:46.651: INFO: Pod "pod-0b5f74c9-3ed2-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.252334ms
Mar  4 23:05:48.657: INFO: Pod "pod-0b5f74c9-3ed2-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010375208s
STEP: Saw pod success
Mar  4 23:05:48.657: INFO: Pod "pod-0b5f74c9-3ed2-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 23:05:48.662: INFO: Trying to get logs from node 10.190.208.160 pod pod-0b5f74c9-3ed2-11e9-b56c-8631b5a7dc0e container test-container: <nil>
STEP: delete the pod
Mar  4 23:05:48.761: INFO: Waiting for pod pod-0b5f74c9-3ed2-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 23:05:48.767: INFO: Pod pod-0b5f74c9-3ed2-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:05:48.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-g2k9l" for this suite.
Mar  4 23:05:54.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:05:54.972: INFO: namespace: e2e-tests-emptydir-g2k9l, resource: bindings, ignored listing per whitelist
Mar  4 23:05:55.119: INFO: namespace e2e-tests-emptydir-g2k9l deletion completed in 6.341758172s

• [SLOW TEST:8.715 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:05:55.119: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-48b5w
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Mar  4 23:05:55.905: INFO: created pod pod-service-account-defaultsa
Mar  4 23:05:55.905: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Mar  4 23:05:55.911: INFO: created pod pod-service-account-mountsa
Mar  4 23:05:55.911: INFO: pod pod-service-account-mountsa service account token volume mount: true
Mar  4 23:05:55.983: INFO: created pod pod-service-account-nomountsa
Mar  4 23:05:55.983: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Mar  4 23:05:55.989: INFO: created pod pod-service-account-defaultsa-mountspec
Mar  4 23:05:55.989: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Mar  4 23:05:55.996: INFO: created pod pod-service-account-mountsa-mountspec
Mar  4 23:05:55.996: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Mar  4 23:05:56.001: INFO: created pod pod-service-account-nomountsa-mountspec
Mar  4 23:05:56.001: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Mar  4 23:05:56.011: INFO: created pod pod-service-account-defaultsa-nomountspec
Mar  4 23:05:56.017: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Mar  4 23:05:56.024: INFO: created pod pod-service-account-mountsa-nomountspec
Mar  4 23:05:56.024: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Mar  4 23:05:56.031: INFO: created pod pod-service-account-nomountsa-nomountspec
Mar  4 23:05:56.031: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:05:56.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-48b5w" for this suite.
Mar  4 23:06:04.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:06:04.437: INFO: namespace: e2e-tests-svcaccounts-48b5w, resource: bindings, ignored listing per whitelist
Mar  4 23:06:04.473: INFO: namespace e2e-tests-svcaccounts-48b5w deletion completed in 8.431182877s

• [SLOW TEST:9.354 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:06:04.473: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-44mqw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-1623c879-3ed2-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume secrets
Mar  4 23:06:04.717: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1624cbaf-3ed2-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-projected-44mqw" to be "success or failure"
Mar  4 23:06:04.722: INFO: Pod "pod-projected-secrets-1624cbaf-3ed2-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.529716ms
Mar  4 23:06:06.727: INFO: Pod "pod-projected-secrets-1624cbaf-3ed2-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009934209s
STEP: Saw pod success
Mar  4 23:06:06.728: INFO: Pod "pod-projected-secrets-1624cbaf-3ed2-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 23:06:06.733: INFO: Trying to get logs from node 10.190.208.160 pod pod-projected-secrets-1624cbaf-3ed2-11e9-b56c-8631b5a7dc0e container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  4 23:06:06.769: INFO: Waiting for pod pod-projected-secrets-1624cbaf-3ed2-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 23:06:06.782: INFO: Pod pod-projected-secrets-1624cbaf-3ed2-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:06:06.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-44mqw" for this suite.
Mar  4 23:06:12.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:06:12.884: INFO: namespace: e2e-tests-projected-44mqw, resource: bindings, ignored listing per whitelist
Mar  4 23:06:13.155: INFO: namespace e2e-tests-projected-44mqw deletion completed in 6.361891191s

• [SLOW TEST:8.682 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:06:13.155: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-g4cxz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-1b51045c-3ed2-11e9-b56c-8631b5a7dc0e
Mar  4 23:06:13.401: INFO: Pod name my-hostname-basic-1b51045c-3ed2-11e9-b56c-8631b5a7dc0e: Found 0 pods out of 1
Mar  4 23:06:18.407: INFO: Pod name my-hostname-basic-1b51045c-3ed2-11e9-b56c-8631b5a7dc0e: Found 1 pods out of 1
Mar  4 23:06:18.407: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-1b51045c-3ed2-11e9-b56c-8631b5a7dc0e" are running
Mar  4 23:06:18.412: INFO: Pod "my-hostname-basic-1b51045c-3ed2-11e9-b56c-8631b5a7dc0e-v9p2b" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-04 23:06:13 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-04 23:06:14 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-04 23:06:14 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-04 23:06:13 +0000 UTC Reason: Message:}])
Mar  4 23:06:18.412: INFO: Trying to dial the pod
Mar  4 23:06:23.436: INFO: Controller my-hostname-basic-1b51045c-3ed2-11e9-b56c-8631b5a7dc0e: Got expected result from replica 1 [my-hostname-basic-1b51045c-3ed2-11e9-b56c-8631b5a7dc0e-v9p2b]: "my-hostname-basic-1b51045c-3ed2-11e9-b56c-8631b5a7dc0e-v9p2b", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:06:23.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-g4cxz" for this suite.
Mar  4 23:06:29.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:06:29.787: INFO: namespace: e2e-tests-replication-controller-g4cxz, resource: bindings, ignored listing per whitelist
Mar  4 23:06:29.787: INFO: namespace e2e-tests-replication-controller-g4cxz deletion completed in 6.339674213s

• [SLOW TEST:16.632 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:06:29.788: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-lss4d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar  4 23:06:32.893: INFO: Successfully updated pod "labelsupdate2543a211-3ed2-11e9-b56c-8631b5a7dc0e"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:06:37.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lss4d" for this suite.
Mar  4 23:06:59.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:06:59.130: INFO: namespace: e2e-tests-downward-api-lss4d, resource: bindings, ignored listing per whitelist
Mar  4 23:06:59.298: INFO: namespace e2e-tests-downward-api-lss4d deletion completed in 22.267054981s

• [SLOW TEST:29.510 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:06:59.299: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-8gksl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:06:59.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-8gksl" for this suite.
Mar  4 23:07:21.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:07:21.958: INFO: namespace: e2e-tests-pods-8gksl, resource: bindings, ignored listing per whitelist
Mar  4 23:07:22.000: INFO: namespace e2e-tests-pods-8gksl deletion completed in 22.317130615s

• [SLOW TEST:22.701 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:07:22.004: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-8pf2w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Mar  4 23:07:22.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 create -f - --namespace=e2e-tests-kubectl-8pf2w'
Mar  4 23:07:22.718: INFO: stderr: ""
Mar  4 23:07:22.718: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar  4 23:07:23.724: INFO: Selector matched 1 pods for map[app:redis]
Mar  4 23:07:23.724: INFO: Found 0 / 1
Mar  4 23:07:24.724: INFO: Selector matched 1 pods for map[app:redis]
Mar  4 23:07:24.724: INFO: Found 1 / 1
Mar  4 23:07:24.724: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Mar  4 23:07:24.729: INFO: Selector matched 1 pods for map[app:redis]
Mar  4 23:07:24.729: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar  4 23:07:24.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 patch pod redis-master-94wcc --namespace=e2e-tests-kubectl-8pf2w -p {"metadata":{"annotations":{"x":"y"}}}'
Mar  4 23:07:24.897: INFO: stderr: ""
Mar  4 23:07:24.897: INFO: stdout: "pod/redis-master-94wcc patched\n"
STEP: checking annotations
Mar  4 23:07:24.911: INFO: Selector matched 1 pods for map[app:redis]
Mar  4 23:07:24.911: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:07:24.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8pf2w" for this suite.
Mar  4 23:07:49.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:07:49.226: INFO: namespace: e2e-tests-kubectl-8pf2w, resource: bindings, ignored listing per whitelist
Mar  4 23:07:49.312: INFO: namespace e2e-tests-kubectl-8pf2w deletion completed in 24.386795264s

• [SLOW TEST:27.309 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:07:49.313: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-kxsz7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar  4 23:07:49.559: INFO: Waiting up to 5m0s for pod "pod-54a2585a-3ed2-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-emptydir-kxsz7" to be "success or failure"
Mar  4 23:07:49.564: INFO: Pod "pod-54a2585a-3ed2-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.653205ms
Mar  4 23:07:51.569: INFO: Pod "pod-54a2585a-3ed2-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010331645s
STEP: Saw pod success
Mar  4 23:07:51.569: INFO: Pod "pod-54a2585a-3ed2-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 23:07:51.574: INFO: Trying to get logs from node 10.190.208.160 pod pod-54a2585a-3ed2-11e9-b56c-8631b5a7dc0e container test-container: <nil>
STEP: delete the pod
Mar  4 23:07:51.606: INFO: Waiting for pod pod-54a2585a-3ed2-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 23:07:51.611: INFO: Pod pod-54a2585a-3ed2-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:07:51.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kxsz7" for this suite.
Mar  4 23:07:57.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:07:58.022: INFO: namespace: e2e-tests-emptydir-kxsz7, resource: bindings, ignored listing per whitelist
Mar  4 23:07:58.079: INFO: namespace e2e-tests-emptydir-kxsz7 deletion completed in 6.396289115s

• [SLOW TEST:8.767 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:07:58.081: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-9f465
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-5a2d2342-3ed2-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume secrets
Mar  4 23:07:58.864: INFO: Waiting up to 5m0s for pod "pod-secrets-5a2e4342-3ed2-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-secrets-9f465" to be "success or failure"
Mar  4 23:07:58.869: INFO: Pod "pod-secrets-5a2e4342-3ed2-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.58815ms
Mar  4 23:08:00.875: INFO: Pod "pod-secrets-5a2e4342-3ed2-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010212323s
STEP: Saw pod success
Mar  4 23:08:00.875: INFO: Pod "pod-secrets-5a2e4342-3ed2-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 23:08:00.879: INFO: Trying to get logs from node 10.190.208.160 pod pod-secrets-5a2e4342-3ed2-11e9-b56c-8631b5a7dc0e container secret-volume-test: <nil>
STEP: delete the pod
Mar  4 23:08:00.922: INFO: Waiting for pod pod-secrets-5a2e4342-3ed2-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 23:08:00.926: INFO: Pod pod-secrets-5a2e4342-3ed2-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:08:00.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9f465" for this suite.
Mar  4 23:08:06.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:08:07.179: INFO: namespace: e2e-tests-secrets-9f465, resource: bindings, ignored listing per whitelist
Mar  4 23:08:07.253: INFO: namespace e2e-tests-secrets-9f465 deletion completed in 6.316898758s

• [SLOW TEST:9.172 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:08:07.254: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-k5sn8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar  4 23:08:13.725: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  4 23:08:13.730: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  4 23:08:15.730: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  4 23:08:15.736: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  4 23:08:17.730: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  4 23:08:17.737: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  4 23:08:19.730: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  4 23:08:19.735: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  4 23:08:21.730: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  4 23:08:21.736: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  4 23:08:23.730: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  4 23:08:23.736: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  4 23:08:25.730: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  4 23:08:25.736: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  4 23:08:27.734: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  4 23:08:27.742: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  4 23:08:29.730: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  4 23:08:29.736: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  4 23:08:31.730: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  4 23:08:31.736: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  4 23:08:33.730: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  4 23:08:33.736: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  4 23:08:35.730: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  4 23:08:35.741: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:08:35.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-k5sn8" for this suite.
Mar  4 23:08:59.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:08:59.928: INFO: namespace: e2e-tests-container-lifecycle-hook-k5sn8, resource: bindings, ignored listing per whitelist
Mar  4 23:09:00.096: INFO: namespace e2e-tests-container-lifecycle-hook-k5sn8 deletion completed in 24.343114726s

• [SLOW TEST:52.842 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:09:00.096: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-cbf8b
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar  4 23:09:00.393: INFO: Waiting up to 5m0s for pod "pod-7ed37444-3ed2-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-emptydir-cbf8b" to be "success or failure"
Mar  4 23:09:00.398: INFO: Pod "pod-7ed37444-3ed2-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.52773ms
Mar  4 23:09:02.451: INFO: Pod "pod-7ed37444-3ed2-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.057349323s
STEP: Saw pod success
Mar  4 23:09:02.451: INFO: Pod "pod-7ed37444-3ed2-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 23:09:02.456: INFO: Trying to get logs from node 10.190.208.160 pod pod-7ed37444-3ed2-11e9-b56c-8631b5a7dc0e container test-container: <nil>
STEP: delete the pod
Mar  4 23:09:02.487: INFO: Waiting for pod pod-7ed37444-3ed2-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 23:09:02.493: INFO: Pod pod-7ed37444-3ed2-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:09:02.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cbf8b" for this suite.
Mar  4 23:09:08.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:09:08.598: INFO: namespace: e2e-tests-emptydir-cbf8b, resource: bindings, ignored listing per whitelist
Mar  4 23:09:08.874: INFO: namespace e2e-tests-emptydir-cbf8b deletion completed in 6.369957751s

• [SLOW TEST:8.778 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:09:08.874: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-dtzg4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-dtzg4
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Mar  4 23:09:09.198: INFO: Found 0 stateful pods, waiting for 3
Mar  4 23:09:19.205: INFO: Found 2 stateful pods, waiting for 3
Mar  4 23:09:29.204: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  4 23:09:29.205: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  4 23:09:29.205: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar  4 23:09:29.240: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Mar  4 23:09:39.321: INFO: Updating stateful set ss2
Mar  4 23:09:39.383: INFO: Waiting for Pod e2e-tests-statefulset-dtzg4/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Mar  4 23:09:49.488: INFO: Found 2 stateful pods, waiting for 3
Mar  4 23:09:59.495: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  4 23:09:59.495: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  4 23:09:59.495: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Mar  4 23:09:59.525: INFO: Updating stateful set ss2
Mar  4 23:09:59.535: INFO: Waiting for Pod e2e-tests-statefulset-dtzg4/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar  4 23:10:09.549: INFO: Waiting for Pod e2e-tests-statefulset-dtzg4/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar  4 23:10:19.568: INFO: Updating stateful set ss2
Mar  4 23:10:19.582: INFO: Waiting for StatefulSet e2e-tests-statefulset-dtzg4/ss2 to complete update
Mar  4 23:10:19.582: INFO: Waiting for Pod e2e-tests-statefulset-dtzg4/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar  4 23:10:29.594: INFO: Deleting all statefulset in ns e2e-tests-statefulset-dtzg4
Mar  4 23:10:29.599: INFO: Scaling statefulset ss2 to 0
Mar  4 23:10:39.622: INFO: Waiting for statefulset status.replicas updated to 0
Mar  4 23:10:39.628: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:10:39.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-dtzg4" for this suite.
Mar  4 23:10:47.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:10:48.034: INFO: namespace: e2e-tests-statefulset-dtzg4, resource: bindings, ignored listing per whitelist
Mar  4 23:10:48.118: INFO: namespace e2e-tests-statefulset-dtzg4 deletion completed in 8.423659476s

• [SLOW TEST:99.244 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:10:48.119: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-m7dsq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Mar  4 23:10:48.886: INFO: Waiting up to 5m0s for pod "pod-service-account-bf8581c9-3ed2-11e9-b56c-8631b5a7dc0e-82795" in namespace "e2e-tests-svcaccounts-m7dsq" to be "success or failure"
Mar  4 23:10:48.891: INFO: Pod "pod-service-account-bf8581c9-3ed2-11e9-b56c-8631b5a7dc0e-82795": Phase="Pending", Reason="", readiness=false. Elapsed: 4.31451ms
Mar  4 23:10:50.897: INFO: Pod "pod-service-account-bf8581c9-3ed2-11e9-b56c-8631b5a7dc0e-82795": Phase="Running", Reason="", readiness=false. Elapsed: 2.010335212s
Mar  4 23:10:52.903: INFO: Pod "pod-service-account-bf8581c9-3ed2-11e9-b56c-8631b5a7dc0e-82795": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016781784s
STEP: Saw pod success
Mar  4 23:10:52.903: INFO: Pod "pod-service-account-bf8581c9-3ed2-11e9-b56c-8631b5a7dc0e-82795" satisfied condition "success or failure"
Mar  4 23:10:52.909: INFO: Trying to get logs from node 10.190.208.160 pod pod-service-account-bf8581c9-3ed2-11e9-b56c-8631b5a7dc0e-82795 container token-test: <nil>
STEP: delete the pod
Mar  4 23:10:52.982: INFO: Waiting for pod pod-service-account-bf8581c9-3ed2-11e9-b56c-8631b5a7dc0e-82795 to disappear
Mar  4 23:10:52.987: INFO: Pod pod-service-account-bf8581c9-3ed2-11e9-b56c-8631b5a7dc0e-82795 no longer exists
STEP: Creating a pod to test consume service account root CA
Mar  4 23:10:52.994: INFO: Waiting up to 5m0s for pod "pod-service-account-bf8581c9-3ed2-11e9-b56c-8631b5a7dc0e-sqsrv" in namespace "e2e-tests-svcaccounts-m7dsq" to be "success or failure"
Mar  4 23:10:52.999: INFO: Pod "pod-service-account-bf8581c9-3ed2-11e9-b56c-8631b5a7dc0e-sqsrv": Phase="Pending", Reason="", readiness=false. Elapsed: 4.508337ms
Mar  4 23:10:55.006: INFO: Pod "pod-service-account-bf8581c9-3ed2-11e9-b56c-8631b5a7dc0e-sqsrv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011879402s
STEP: Saw pod success
Mar  4 23:10:55.007: INFO: Pod "pod-service-account-bf8581c9-3ed2-11e9-b56c-8631b5a7dc0e-sqsrv" satisfied condition "success or failure"
Mar  4 23:10:55.012: INFO: Trying to get logs from node 10.190.208.160 pod pod-service-account-bf8581c9-3ed2-11e9-b56c-8631b5a7dc0e-sqsrv container root-ca-test: <nil>
STEP: delete the pod
Mar  4 23:10:55.050: INFO: Waiting for pod pod-service-account-bf8581c9-3ed2-11e9-b56c-8631b5a7dc0e-sqsrv to disappear
Mar  4 23:10:55.056: INFO: Pod pod-service-account-bf8581c9-3ed2-11e9-b56c-8631b5a7dc0e-sqsrv no longer exists
STEP: Creating a pod to test consume service account namespace
Mar  4 23:10:55.083: INFO: Waiting up to 5m0s for pod "pod-service-account-bf8581c9-3ed2-11e9-b56c-8631b5a7dc0e-f5k69" in namespace "e2e-tests-svcaccounts-m7dsq" to be "success or failure"
Mar  4 23:10:55.088: INFO: Pod "pod-service-account-bf8581c9-3ed2-11e9-b56c-8631b5a7dc0e-f5k69": Phase="Pending", Reason="", readiness=false. Elapsed: 5.202916ms
Mar  4 23:10:57.093: INFO: Pod "pod-service-account-bf8581c9-3ed2-11e9-b56c-8631b5a7dc0e-f5k69": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010609825s
Mar  4 23:10:59.100: INFO: Pod "pod-service-account-bf8581c9-3ed2-11e9-b56c-8631b5a7dc0e-f5k69": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017512587s
STEP: Saw pod success
Mar  4 23:10:59.100: INFO: Pod "pod-service-account-bf8581c9-3ed2-11e9-b56c-8631b5a7dc0e-f5k69" satisfied condition "success or failure"
Mar  4 23:10:59.105: INFO: Trying to get logs from node 10.190.208.160 pod pod-service-account-bf8581c9-3ed2-11e9-b56c-8631b5a7dc0e-f5k69 container namespace-test: <nil>
STEP: delete the pod
Mar  4 23:10:59.142: INFO: Waiting for pod pod-service-account-bf8581c9-3ed2-11e9-b56c-8631b5a7dc0e-f5k69 to disappear
Mar  4 23:10:59.148: INFO: Pod pod-service-account-bf8581c9-3ed2-11e9-b56c-8631b5a7dc0e-f5k69 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:10:59.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-m7dsq" for this suite.
Mar  4 23:11:05.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:11:05.619: INFO: namespace: e2e-tests-svcaccounts-m7dsq, resource: bindings, ignored listing per whitelist
Mar  4 23:11:05.660: INFO: namespace e2e-tests-svcaccounts-m7dsq deletion completed in 6.499818711s

• [SLOW TEST:17.542 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:11:05.661: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wkjgl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar  4 23:11:05.902: INFO: Waiting up to 5m0s for pod "pod-c9a9c51c-3ed2-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-emptydir-wkjgl" to be "success or failure"
Mar  4 23:11:05.906: INFO: Pod "pod-c9a9c51c-3ed2-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.31019ms
Mar  4 23:11:07.912: INFO: Pod "pod-c9a9c51c-3ed2-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010324927s
STEP: Saw pod success
Mar  4 23:11:07.912: INFO: Pod "pod-c9a9c51c-3ed2-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 23:11:07.921: INFO: Trying to get logs from node 10.190.208.160 pod pod-c9a9c51c-3ed2-11e9-b56c-8631b5a7dc0e container test-container: <nil>
STEP: delete the pod
Mar  4 23:11:07.998: INFO: Waiting for pod pod-c9a9c51c-3ed2-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 23:11:08.006: INFO: Pod pod-c9a9c51c-3ed2-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:11:08.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wkjgl" for this suite.
Mar  4 23:11:14.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:11:14.119: INFO: namespace: e2e-tests-emptydir-wkjgl, resource: bindings, ignored listing per whitelist
Mar  4 23:11:14.319: INFO: namespace e2e-tests-emptydir-wkjgl deletion completed in 6.301330554s

• [SLOW TEST:8.658 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:11:14.319: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-j4hdv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar  4 23:11:14.593: INFO: Waiting up to 5m0s for pod "pod-ced20a7d-3ed2-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-emptydir-j4hdv" to be "success or failure"
Mar  4 23:11:14.597: INFO: Pod "pod-ced20a7d-3ed2-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.459725ms
Mar  4 23:11:16.602: INFO: Pod "pod-ced20a7d-3ed2-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009592074s
STEP: Saw pod success
Mar  4 23:11:16.602: INFO: Pod "pod-ced20a7d-3ed2-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 23:11:16.615: INFO: Trying to get logs from node 10.190.208.160 pod pod-ced20a7d-3ed2-11e9-b56c-8631b5a7dc0e container test-container: <nil>
STEP: delete the pod
Mar  4 23:11:16.644: INFO: Waiting for pod pod-ced20a7d-3ed2-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 23:11:16.650: INFO: Pod pod-ced20a7d-3ed2-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:11:16.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-j4hdv" for this suite.
Mar  4 23:11:22.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:11:23.015: INFO: namespace: e2e-tests-emptydir-j4hdv, resource: bindings, ignored listing per whitelist
Mar  4 23:11:23.073: INFO: namespace e2e-tests-emptydir-j4hdv deletion completed in 6.412370277s

• [SLOW TEST:8.754 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:11:23.076: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-k98qx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-pcwh2
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-x26p5
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:11:29.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-k98qx" for this suite.
Mar  4 23:11:35.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:11:36.107: INFO: namespace: e2e-tests-namespaces-k98qx, resource: bindings, ignored listing per whitelist
Mar  4 23:11:36.190: INFO: namespace e2e-tests-namespaces-k98qx deletion completed in 6.271708113s
STEP: Destroying namespace "e2e-tests-nsdeletetest-pcwh2" for this suite.
Mar  4 23:11:36.197: INFO: Namespace e2e-tests-nsdeletetest-pcwh2 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-x26p5" for this suite.
Mar  4 23:11:42.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:11:42.990: INFO: namespace: e2e-tests-nsdeletetest-x26p5, resource: bindings, ignored listing per whitelist
Mar  4 23:11:43.013: INFO: namespace e2e-tests-nsdeletetest-x26p5 deletion completed in 6.815532976s

• [SLOW TEST:19.938 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:11:43.014: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-nr5dg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar  4 23:11:43.297: INFO: Waiting up to 5m0s for pod "pod-dff41362-3ed2-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-emptydir-nr5dg" to be "success or failure"
Mar  4 23:11:43.302: INFO: Pod "pod-dff41362-3ed2-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.588441ms
Mar  4 23:11:45.309: INFO: Pod "pod-dff41362-3ed2-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011118112s
STEP: Saw pod success
Mar  4 23:11:45.309: INFO: Pod "pod-dff41362-3ed2-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 23:11:45.314: INFO: Trying to get logs from node 10.190.208.160 pod pod-dff41362-3ed2-11e9-b56c-8631b5a7dc0e container test-container: <nil>
STEP: delete the pod
Mar  4 23:11:45.350: INFO: Waiting for pod pod-dff41362-3ed2-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 23:11:45.354: INFO: Pod pod-dff41362-3ed2-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:11:45.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-nr5dg" for this suite.
Mar  4 23:11:51.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:11:51.566: INFO: namespace: e2e-tests-emptydir-nr5dg, resource: bindings, ignored listing per whitelist
Mar  4 23:11:51.702: INFO: namespace e2e-tests-emptydir-nr5dg deletion completed in 6.335552784s

• [SLOW TEST:8.688 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:11:51.703: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-6mwmh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Mar  4 23:11:52.108: INFO: Waiting up to 5m0s for pod "client-containers-e5348754-3ed2-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-containers-6mwmh" to be "success or failure"
Mar  4 23:11:52.113: INFO: Pod "client-containers-e5348754-3ed2-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.351318ms
Mar  4 23:11:54.119: INFO: Pod "client-containers-e5348754-3ed2-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011059827s
STEP: Saw pod success
Mar  4 23:11:54.119: INFO: Pod "client-containers-e5348754-3ed2-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 23:11:54.124: INFO: Trying to get logs from node 10.190.208.160 pod client-containers-e5348754-3ed2-11e9-b56c-8631b5a7dc0e container test-container: <nil>
STEP: delete the pod
Mar  4 23:11:54.155: INFO: Waiting for pod client-containers-e5348754-3ed2-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 23:11:54.182: INFO: Pod client-containers-e5348754-3ed2-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:11:54.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-6mwmh" for this suite.
Mar  4 23:12:02.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:12:02.773: INFO: namespace: e2e-tests-containers-6mwmh, resource: bindings, ignored listing per whitelist
Mar  4 23:12:02.812: INFO: namespace e2e-tests-containers-6mwmh deletion completed in 8.435860624s

• [SLOW TEST:11.109 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:12:02.812: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-6lg64
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  4 23:12:03.106: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ebc26ff5-3ed2-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-downward-api-6lg64" to be "success or failure"
Mar  4 23:12:03.112: INFO: Pod "downwardapi-volume-ebc26ff5-3ed2-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.024958ms
Mar  4 23:12:05.117: INFO: Pod "downwardapi-volume-ebc26ff5-3ed2-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010417771s
STEP: Saw pod success
Mar  4 23:12:05.117: INFO: Pod "downwardapi-volume-ebc26ff5-3ed2-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 23:12:05.122: INFO: Trying to get logs from node 10.190.208.162 pod downwardapi-volume-ebc26ff5-3ed2-11e9-b56c-8631b5a7dc0e container client-container: <nil>
STEP: delete the pod
Mar  4 23:12:05.164: INFO: Waiting for pod downwardapi-volume-ebc26ff5-3ed2-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 23:12:05.182: INFO: Pod downwardapi-volume-ebc26ff5-3ed2-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:12:05.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6lg64" for this suite.
Mar  4 23:12:11.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:12:11.302: INFO: namespace: e2e-tests-downward-api-6lg64, resource: bindings, ignored listing per whitelist
Mar  4 23:12:11.771: INFO: namespace e2e-tests-downward-api-6lg64 deletion completed in 6.577574275s

• [SLOW TEST:8.959 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:12:11.771: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-7n8pw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  4 23:12:12.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-7n8pw'
Mar  4 23:12:12.406: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar  4 23:12:12.406: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Mar  4 23:12:12.416: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Mar  4 23:12:12.424: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Mar  4 23:12:12.433: INFO: scanned /root for discovery docs: <nil>
Mar  4 23:12:12.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-7n8pw'
Mar  4 23:12:28.492: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar  4 23:12:28.492: INFO: stdout: "Created e2e-test-nginx-rc-a571eb5e34e0498a7a443b17da74f320\nScaling up e2e-test-nginx-rc-a571eb5e34e0498a7a443b17da74f320 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-a571eb5e34e0498a7a443b17da74f320 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-a571eb5e34e0498a7a443b17da74f320 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Mar  4 23:12:28.492: INFO: stdout: "Created e2e-test-nginx-rc-a571eb5e34e0498a7a443b17da74f320\nScaling up e2e-test-nginx-rc-a571eb5e34e0498a7a443b17da74f320 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-a571eb5e34e0498a7a443b17da74f320 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-a571eb5e34e0498a7a443b17da74f320 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Mar  4 23:12:28.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-7n8pw'
Mar  4 23:12:28.629: INFO: stderr: ""
Mar  4 23:12:28.629: INFO: stdout: "e2e-test-nginx-rc-a571eb5e34e0498a7a443b17da74f320-8r29g "
Mar  4 23:12:28.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods e2e-test-nginx-rc-a571eb5e34e0498a7a443b17da74f320-8r29g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7n8pw'
Mar  4 23:12:28.750: INFO: stderr: ""
Mar  4 23:12:28.750: INFO: stdout: "true"
Mar  4 23:12:28.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods e2e-test-nginx-rc-a571eb5e34e0498a7a443b17da74f320-8r29g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7n8pw'
Mar  4 23:12:28.877: INFO: stderr: ""
Mar  4 23:12:28.877: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Mar  4 23:12:28.877: INFO: e2e-test-nginx-rc-a571eb5e34e0498a7a443b17da74f320-8r29g is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Mar  4 23:12:28.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-7n8pw'
Mar  4 23:12:29.019: INFO: stderr: ""
Mar  4 23:12:29.019: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:12:29.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7n8pw" for this suite.
Mar  4 23:12:35.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:12:35.181: INFO: namespace: e2e-tests-kubectl-7n8pw, resource: bindings, ignored listing per whitelist
Mar  4 23:12:35.341: INFO: namespace e2e-tests-kubectl-7n8pw deletion completed in 6.310757479s

• [SLOW TEST:23.570 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:12:35.342: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-qz7mp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-qz7mp
Mar  4 23:12:39.693: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-qz7mp
STEP: checking the pod's current state and verifying that restartCount is present
Mar  4 23:12:39.698: INFO: Initial restart count of pod liveness-http is 0
Mar  4 23:13:03.774: INFO: Restart count of pod e2e-tests-container-probe-qz7mp/liveness-http is now 1 (24.076379997s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:13:03.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-qz7mp" for this suite.
Mar  4 23:13:11.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:13:11.983: INFO: namespace: e2e-tests-container-probe-qz7mp, resource: bindings, ignored listing per whitelist
Mar  4 23:13:12.199: INFO: namespace e2e-tests-container-probe-qz7mp deletion completed in 8.399442283s

• [SLOW TEST:36.857 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:13:12.199: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-hsjr4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-7lbq
STEP: Creating a pod to test atomic-volume-subpath
Mar  4 23:13:12.463: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-7lbq" in namespace "e2e-tests-subpath-hsjr4" to be "success or failure"
Mar  4 23:13:12.467: INFO: Pod "pod-subpath-test-configmap-7lbq": Phase="Pending", Reason="", readiness=false. Elapsed: 4.534988ms
Mar  4 23:13:14.473: INFO: Pod "pod-subpath-test-configmap-7lbq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010118853s
Mar  4 23:13:16.479: INFO: Pod "pod-subpath-test-configmap-7lbq": Phase="Running", Reason="", readiness=false. Elapsed: 4.015989416s
Mar  4 23:13:18.485: INFO: Pod "pod-subpath-test-configmap-7lbq": Phase="Running", Reason="", readiness=false. Elapsed: 6.021754585s
Mar  4 23:13:20.491: INFO: Pod "pod-subpath-test-configmap-7lbq": Phase="Running", Reason="", readiness=false. Elapsed: 8.028018323s
Mar  4 23:13:22.497: INFO: Pod "pod-subpath-test-configmap-7lbq": Phase="Running", Reason="", readiness=false. Elapsed: 10.03404939s
Mar  4 23:13:24.502: INFO: Pod "pod-subpath-test-configmap-7lbq": Phase="Running", Reason="", readiness=false. Elapsed: 12.039588192s
Mar  4 23:13:26.509: INFO: Pod "pod-subpath-test-configmap-7lbq": Phase="Running", Reason="", readiness=false. Elapsed: 14.046023027s
Mar  4 23:13:28.515: INFO: Pod "pod-subpath-test-configmap-7lbq": Phase="Running", Reason="", readiness=false. Elapsed: 16.052051877s
Mar  4 23:13:30.521: INFO: Pod "pod-subpath-test-configmap-7lbq": Phase="Running", Reason="", readiness=false. Elapsed: 18.058410311s
Mar  4 23:13:32.844: INFO: Pod "pod-subpath-test-configmap-7lbq": Phase="Running", Reason="", readiness=false. Elapsed: 20.381381329s
Mar  4 23:13:34.850: INFO: Pod "pod-subpath-test-configmap-7lbq": Phase="Running", Reason="", readiness=false. Elapsed: 22.386867368s
Mar  4 23:13:36.856: INFO: Pod "pod-subpath-test-configmap-7lbq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.392805947s
STEP: Saw pod success
Mar  4 23:13:36.856: INFO: Pod "pod-subpath-test-configmap-7lbq" satisfied condition "success or failure"
Mar  4 23:13:36.860: INFO: Trying to get logs from node 10.190.208.162 pod pod-subpath-test-configmap-7lbq container test-container-subpath-configmap-7lbq: <nil>
STEP: delete the pod
Mar  4 23:13:36.893: INFO: Waiting for pod pod-subpath-test-configmap-7lbq to disappear
Mar  4 23:13:36.897: INFO: Pod pod-subpath-test-configmap-7lbq no longer exists
STEP: Deleting pod pod-subpath-test-configmap-7lbq
Mar  4 23:13:36.897: INFO: Deleting pod "pod-subpath-test-configmap-7lbq" in namespace "e2e-tests-subpath-hsjr4"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:13:36.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-hsjr4" for this suite.
Mar  4 23:13:42.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:13:43.322: INFO: namespace: e2e-tests-subpath-hsjr4, resource: bindings, ignored listing per whitelist
Mar  4 23:13:43.322: INFO: namespace e2e-tests-subpath-hsjr4 deletion completed in 6.408694927s

• [SLOW TEST:31.123 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:13:43.323: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-vq4lw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar  4 23:13:47.611: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  4 23:13:47.683: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  4 23:13:49.683: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  4 23:13:49.689: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  4 23:13:51.683: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  4 23:13:51.689: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  4 23:13:53.683: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  4 23:13:53.689: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  4 23:13:55.683: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  4 23:13:55.691: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  4 23:13:57.684: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  4 23:13:57.713: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  4 23:13:59.683: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  4 23:13:59.689: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  4 23:14:01.683: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  4 23:14:01.689: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  4 23:14:03.683: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  4 23:14:03.689: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  4 23:14:05.683: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  4 23:14:05.688: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  4 23:14:07.683: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  4 23:14:07.690: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:14:07.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-vq4lw" for this suite.
Mar  4 23:14:31.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:14:31.872: INFO: namespace: e2e-tests-container-lifecycle-hook-vq4lw, resource: bindings, ignored listing per whitelist
Mar  4 23:14:32.011: INFO: namespace e2e-tests-container-lifecycle-hook-vq4lw deletion completed in 24.294877453s

• [SLOW TEST:48.689 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:14:32.013: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-8jtd2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-44abb753-3ed3-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume configMaps
Mar  4 23:14:32.281: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-44acb070-3ed3-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-projected-8jtd2" to be "success or failure"
Mar  4 23:14:32.291: INFO: Pod "pod-projected-configmaps-44acb070-3ed3-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 9.694926ms
Mar  4 23:14:34.297: INFO: Pod "pod-projected-configmaps-44acb070-3ed3-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01529654s
STEP: Saw pod success
Mar  4 23:14:34.297: INFO: Pod "pod-projected-configmaps-44acb070-3ed3-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 23:14:34.302: INFO: Trying to get logs from node 10.190.208.160 pod pod-projected-configmaps-44acb070-3ed3-11e9-b56c-8631b5a7dc0e container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  4 23:14:34.382: INFO: Waiting for pod pod-projected-configmaps-44acb070-3ed3-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 23:14:34.387: INFO: Pod pod-projected-configmaps-44acb070-3ed3-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:14:34.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8jtd2" for this suite.
Mar  4 23:14:40.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:14:40.497: INFO: namespace: e2e-tests-projected-8jtd2, resource: bindings, ignored listing per whitelist
Mar  4 23:14:40.694: INFO: namespace e2e-tests-projected-8jtd2 deletion completed in 6.297151854s

• [SLOW TEST:8.682 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:14:40.695: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-86fl7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-86fl7.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-86fl7.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-86fl7.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-86fl7.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-86fl7.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-86fl7.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  4 23:14:55.187: INFO: DNS probes using e2e-tests-dns-86fl7/dns-test-49d4f282-3ed3-11e9-b56c-8631b5a7dc0e succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:14:55.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-86fl7" for this suite.
Mar  4 23:15:01.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:15:01.329: INFO: namespace: e2e-tests-dns-86fl7, resource: bindings, ignored listing per whitelist
Mar  4 23:15:02.169: INFO: namespace e2e-tests-dns-86fl7 deletion completed in 6.956064301s

• [SLOW TEST:21.474 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:15:02.170: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-bjv88
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  4 23:15:02.419: INFO: Waiting up to 5m0s for pod "downwardapi-volume-56a3976e-3ed3-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-projected-bjv88" to be "success or failure"
Mar  4 23:15:02.424: INFO: Pod "downwardapi-volume-56a3976e-3ed3-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.400425ms
Mar  4 23:15:04.430: INFO: Pod "downwardapi-volume-56a3976e-3ed3-11e9-b56c-8631b5a7dc0e": Phase="Running", Reason="", readiness=true. Elapsed: 2.010640224s
Mar  4 23:15:06.436: INFO: Pod "downwardapi-volume-56a3976e-3ed3-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016917223s
STEP: Saw pod success
Mar  4 23:15:06.437: INFO: Pod "downwardapi-volume-56a3976e-3ed3-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 23:15:06.441: INFO: Trying to get logs from node 10.190.208.162 pod downwardapi-volume-56a3976e-3ed3-11e9-b56c-8631b5a7dc0e container client-container: <nil>
STEP: delete the pod
Mar  4 23:15:06.477: INFO: Waiting for pod downwardapi-volume-56a3976e-3ed3-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 23:15:06.483: INFO: Pod downwardapi-volume-56a3976e-3ed3-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:15:06.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bjv88" for this suite.
Mar  4 23:15:12.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:15:13.033: INFO: namespace: e2e-tests-projected-bjv88, resource: bindings, ignored listing per whitelist
Mar  4 23:15:13.109: INFO: namespace e2e-tests-projected-bjv88 deletion completed in 6.616559009s

• [SLOW TEST:10.940 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:15:13.111: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-rnh9l
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar  4 23:15:13.353: INFO: Waiting up to 5m0s for pod "pod-5d27ca14-3ed3-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-emptydir-rnh9l" to be "success or failure"
Mar  4 23:15:13.357: INFO: Pod "pod-5d27ca14-3ed3-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.520829ms
Mar  4 23:15:15.363: INFO: Pod "pod-5d27ca14-3ed3-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009827784s
STEP: Saw pod success
Mar  4 23:15:15.363: INFO: Pod "pod-5d27ca14-3ed3-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 23:15:15.367: INFO: Trying to get logs from node 10.190.208.160 pod pod-5d27ca14-3ed3-11e9-b56c-8631b5a7dc0e container test-container: <nil>
STEP: delete the pod
Mar  4 23:15:15.399: INFO: Waiting for pod pod-5d27ca14-3ed3-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 23:15:15.483: INFO: Pod pod-5d27ca14-3ed3-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:15:15.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rnh9l" for this suite.
Mar  4 23:15:21.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:15:21.651: INFO: namespace: e2e-tests-emptydir-rnh9l, resource: bindings, ignored listing per whitelist
Mar  4 23:15:21.926: INFO: namespace e2e-tests-emptydir-rnh9l deletion completed in 6.43228264s

• [SLOW TEST:8.815 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:15:21.926: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-j7b7g
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0304 23:16:02.224097      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  4 23:16:02.224: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:16:02.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-j7b7g" for this suite.
Mar  4 23:16:10.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:16:10.749: INFO: namespace: e2e-tests-gc-j7b7g, resource: bindings, ignored listing per whitelist
Mar  4 23:16:10.764: INFO: namespace e2e-tests-gc-j7b7g deletion completed in 8.472580585s

• [SLOW TEST:48.838 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:16:10.765: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-4d28m
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-7f91b783-3ed3-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume secrets
Mar  4 23:16:11.094: INFO: Waiting up to 5m0s for pod "pod-secrets-7f929b02-3ed3-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-secrets-4d28m" to be "success or failure"
Mar  4 23:16:11.099: INFO: Pod "pod-secrets-7f929b02-3ed3-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.765607ms
Mar  4 23:16:13.105: INFO: Pod "pod-secrets-7f929b02-3ed3-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01127337s
STEP: Saw pod success
Mar  4 23:16:13.105: INFO: Pod "pod-secrets-7f929b02-3ed3-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 23:16:13.110: INFO: Trying to get logs from node 10.190.208.160 pod pod-secrets-7f929b02-3ed3-11e9-b56c-8631b5a7dc0e container secret-volume-test: <nil>
STEP: delete the pod
Mar  4 23:16:13.146: INFO: Waiting for pod pod-secrets-7f929b02-3ed3-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 23:16:13.150: INFO: Pod pod-secrets-7f929b02-3ed3-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:16:13.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-4d28m" for this suite.
Mar  4 23:16:19.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:16:19.673: INFO: namespace: e2e-tests-secrets-4d28m, resource: bindings, ignored listing per whitelist
Mar  4 23:16:19.701: INFO: namespace e2e-tests-secrets-4d28m deletion completed in 6.364928045s

• [SLOW TEST:8.936 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:16:19.702: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-fh4pc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-fh4pc
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Mar  4 23:16:19.951: INFO: Found 0 stateful pods, waiting for 3
Mar  4 23:16:29.958: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  4 23:16:29.958: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  4 23:16:29.958: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Mar  4 23:16:29.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-fh4pc ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  4 23:16:30.388: INFO: stderr: ""
Mar  4 23:16:30.388: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  4 23:16:30.388: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar  4 23:16:40.437: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Mar  4 23:16:50.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-fh4pc ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 23:16:50.814: INFO: stderr: ""
Mar  4 23:16:50.814: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  4 23:16:50.815: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  4 23:16:50.834: INFO: Waiting for StatefulSet e2e-tests-statefulset-fh4pc/ss2 to complete update
Mar  4 23:16:50.834: INFO: Waiting for Pod e2e-tests-statefulset-fh4pc/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar  4 23:16:50.834: INFO: Waiting for Pod e2e-tests-statefulset-fh4pc/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar  4 23:16:50.835: INFO: Waiting for Pod e2e-tests-statefulset-fh4pc/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar  4 23:17:00.883: INFO: Waiting for StatefulSet e2e-tests-statefulset-fh4pc/ss2 to complete update
Mar  4 23:17:00.883: INFO: Waiting for Pod e2e-tests-statefulset-fh4pc/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar  4 23:17:10.845: INFO: Waiting for StatefulSet e2e-tests-statefulset-fh4pc/ss2 to complete update
Mar  4 23:17:10.845: INFO: Waiting for Pod e2e-tests-statefulset-fh4pc/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Mar  4 23:17:20.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-fh4pc ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  4 23:17:21.201: INFO: stderr: ""
Mar  4 23:17:21.201: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  4 23:17:21.201: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  4 23:17:31.362: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Mar  4 23:17:41.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 exec --namespace=e2e-tests-statefulset-fh4pc ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  4 23:17:41.736: INFO: stderr: ""
Mar  4 23:17:41.736: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  4 23:17:41.736: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  4 23:17:41.759: INFO: Waiting for StatefulSet e2e-tests-statefulset-fh4pc/ss2 to complete update
Mar  4 23:17:41.759: INFO: Waiting for Pod e2e-tests-statefulset-fh4pc/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar  4 23:17:41.759: INFO: Waiting for Pod e2e-tests-statefulset-fh4pc/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar  4 23:17:41.759: INFO: Waiting for Pod e2e-tests-statefulset-fh4pc/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar  4 23:17:51.770: INFO: Waiting for StatefulSet e2e-tests-statefulset-fh4pc/ss2 to complete update
Mar  4 23:17:51.770: INFO: Waiting for Pod e2e-tests-statefulset-fh4pc/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar  4 23:17:51.770: INFO: Waiting for Pod e2e-tests-statefulset-fh4pc/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar  4 23:17:51.770: INFO: Waiting for Pod e2e-tests-statefulset-fh4pc/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar  4 23:18:01.772: INFO: Waiting for StatefulSet e2e-tests-statefulset-fh4pc/ss2 to complete update
Mar  4 23:18:01.772: INFO: Waiting for Pod e2e-tests-statefulset-fh4pc/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar  4 23:18:11.777: INFO: Deleting all statefulset in ns e2e-tests-statefulset-fh4pc
Mar  4 23:18:11.781: INFO: Scaling statefulset ss2 to 0
Mar  4 23:18:41.806: INFO: Waiting for statefulset status.replicas updated to 0
Mar  4 23:18:41.811: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:18:41.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-fh4pc" for this suite.
Mar  4 23:18:49.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:18:50.304: INFO: namespace: e2e-tests-statefulset-fh4pc, resource: bindings, ignored listing per whitelist
Mar  4 23:18:50.496: INFO: namespace e2e-tests-statefulset-fh4pc deletion completed in 8.643783867s

• [SLOW TEST:150.794 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:18:50.498: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-2cfxf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar  4 23:18:50.795: INFO: Waiting up to 5m0s for pod "pod-dec1770a-3ed3-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-emptydir-2cfxf" to be "success or failure"
Mar  4 23:18:50.802: INFO: Pod "pod-dec1770a-3ed3-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.477022ms
Mar  4 23:18:52.808: INFO: Pod "pod-dec1770a-3ed3-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012248622s
STEP: Saw pod success
Mar  4 23:18:52.808: INFO: Pod "pod-dec1770a-3ed3-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 23:18:52.812: INFO: Trying to get logs from node 10.190.208.160 pod pod-dec1770a-3ed3-11e9-b56c-8631b5a7dc0e container test-container: <nil>
STEP: delete the pod
Mar  4 23:18:52.843: INFO: Waiting for pod pod-dec1770a-3ed3-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 23:18:52.851: INFO: Pod pod-dec1770a-3ed3-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:18:52.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2cfxf" for this suite.
Mar  4 23:18:58.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:18:59.006: INFO: namespace: e2e-tests-emptydir-2cfxf, resource: bindings, ignored listing per whitelist
Mar  4 23:18:59.211: INFO: namespace e2e-tests-emptydir-2cfxf deletion completed in 6.326626374s

• [SLOW TEST:8.713 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:18:59.212: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-2mfbn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-e3f2786d-3ed3-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume configMaps
Mar  4 23:18:59.502: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e3f35c07-3ed3-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-projected-2mfbn" to be "success or failure"
Mar  4 23:18:59.506: INFO: Pod "pod-projected-configmaps-e3f35c07-3ed3-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.325304ms
Mar  4 23:19:01.511: INFO: Pod "pod-projected-configmaps-e3f35c07-3ed3-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009648092s
STEP: Saw pod success
Mar  4 23:19:01.511: INFO: Pod "pod-projected-configmaps-e3f35c07-3ed3-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 23:19:01.517: INFO: Trying to get logs from node 10.190.208.160 pod pod-projected-configmaps-e3f35c07-3ed3-11e9-b56c-8631b5a7dc0e container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  4 23:19:01.582: INFO: Waiting for pod pod-projected-configmaps-e3f35c07-3ed3-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 23:19:01.588: INFO: Pod pod-projected-configmaps-e3f35c07-3ed3-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:19:01.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2mfbn" for this suite.
Mar  4 23:19:07.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:19:07.893: INFO: namespace: e2e-tests-projected-2mfbn, resource: bindings, ignored listing per whitelist
Mar  4 23:19:07.911: INFO: namespace e2e-tests-projected-2mfbn deletion completed in 6.312211336s

• [SLOW TEST:8.700 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:19:07.911: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-45bjg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-e91fdb45-3ed3-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume secrets
Mar  4 23:19:08.186: INFO: Waiting up to 5m0s for pod "pod-secrets-e920c317-3ed3-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-secrets-45bjg" to be "success or failure"
Mar  4 23:19:08.191: INFO: Pod "pod-secrets-e920c317-3ed3-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.297051ms
Mar  4 23:19:10.197: INFO: Pod "pod-secrets-e920c317-3ed3-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01083218s
STEP: Saw pod success
Mar  4 23:19:10.197: INFO: Pod "pod-secrets-e920c317-3ed3-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 23:19:10.202: INFO: Trying to get logs from node 10.190.208.160 pod pod-secrets-e920c317-3ed3-11e9-b56c-8631b5a7dc0e container secret-volume-test: <nil>
STEP: delete the pod
Mar  4 23:19:10.234: INFO: Waiting for pod pod-secrets-e920c317-3ed3-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 23:19:10.238: INFO: Pod pod-secrets-e920c317-3ed3-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:19:10.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-45bjg" for this suite.
Mar  4 23:19:16.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:19:16.389: INFO: namespace: e2e-tests-secrets-45bjg, resource: bindings, ignored listing per whitelist
Mar  4 23:19:16.628: INFO: namespace e2e-tests-secrets-45bjg deletion completed in 6.33438179s

• [SLOW TEST:8.717 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:19:16.630: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-pxmkm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-pxmkm
Mar  4 23:19:18.887: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-pxmkm
STEP: checking the pod's current state and verifying that restartCount is present
Mar  4 23:19:18.892: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:23:19.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-pxmkm" for this suite.
Mar  4 23:23:26.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:23:26.221: INFO: namespace: e2e-tests-container-probe-pxmkm, resource: bindings, ignored listing per whitelist
Mar  4 23:23:26.297: INFO: namespace e2e-tests-container-probe-pxmkm deletion completed in 6.313645511s

• [SLOW TEST:249.667 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:23:26.297: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-lcqzj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  4 23:23:26.540: INFO: Creating deployment "nginx-deployment"
Mar  4 23:23:26.552: INFO: Waiting for observed generation 1
Mar  4 23:23:28.569: INFO: Waiting for all required pods to come up
Mar  4 23:23:28.576: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Mar  4 23:23:28.576: INFO: Waiting for deployment "nginx-deployment" to complete
Mar  4 23:23:28.591: INFO: Updating deployment "nginx-deployment" with a non-existent image
Mar  4 23:23:28.607: INFO: Updating deployment nginx-deployment
Mar  4 23:23:28.607: INFO: Waiting for observed generation 2
Mar  4 23:23:30.626: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Mar  4 23:23:30.632: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Mar  4 23:23:30.637: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar  4 23:23:30.652: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Mar  4 23:23:30.652: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Mar  4 23:23:30.657: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar  4 23:23:30.666: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Mar  4 23:23:30.666: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Mar  4 23:23:30.685: INFO: Updating deployment nginx-deployment
Mar  4 23:23:30.685: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Mar  4 23:23:30.695: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Mar  4 23:23:32.707: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar  4 23:23:32.729: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lcqzj/deployments/nginx-deployment,UID:831ffead-3ed4-11e9-967c-c655790ff683,ResourceVersion:25615,Generation:3,CreationTimestamp:2019-03-04 23:23:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:9,UnavailableReplicas:24,Conditions:[{Available False 2019-03-04 23:23:30 +0000 UTC 2019-03-04 23:23:30 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-03-04 23:23:31 +0000 UTC 2019-03-04 23:23:26 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.}],ReadyReplicas:9,CollisionCount:nil,},}

Mar  4 23:23:32.743: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lcqzj/replicasets/nginx-deployment-7dc8f79789,UID:845b4982-3ed4-11e9-967c-c655790ff683,ResourceVersion:25455,Generation:3,CreationTimestamp:2019-03-04 23:23:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 831ffead-3ed4-11e9-967c-c655790ff683 0xc422886637 0xc422886638}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  4 23:23:32.743: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Mar  4 23:23:32.743: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lcqzj/replicasets/nginx-deployment-7f9675fb8b,UID:8322f46d-3ed4-11e9-967c-c655790ff683,ResourceVersion:25573,Generation:3,CreationTimestamp:2019-03-04 23:23:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 831ffead-3ed4-11e9-967c-c655790ff683 0xc4228868e7 0xc4228868e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:9,AvailableReplicas:9,Conditions:[],},}
Mar  4 23:23:32.761: INFO: Pod "nginx-deployment-7dc8f79789-28dx6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-28dx6,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7dc8f79789-28dx6,UID:859bfa2d-3ed4-11e9-967c-c655790ff683,ResourceVersion:25523,Generation:0,CreationTimestamp:2019-03-04 23:23:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 845b4982-3ed4-11e9-967c-c655790ff683 0xc42224a1b7 0xc42224a1b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.178,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42224a230} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42224a250}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.178,PodIP:,StartTime:2019-03-04 23:23:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.761: INFO: Pod "nginx-deployment-7dc8f79789-2fk4p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-2fk4p,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7dc8f79789-2fk4p,UID:859bfe96-3ed4-11e9-967c-c655790ff683,ResourceVersion:25600,Generation:0,CreationTimestamp:2019-03-04 23:23:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 845b4982-3ed4-11e9-967c-c655790ff683 0xc42224a310 0xc42224a311}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.178,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42224a3a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42224a3c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.178,PodIP:172.30.252.238,StartTime:2019-03-04 23:23:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.761: INFO: Pod "nginx-deployment-7dc8f79789-462j6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-462j6,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7dc8f79789-462j6,UID:859af4f5-3ed4-11e9-967c-c655790ff683,ResourceVersion:25481,Generation:0,CreationTimestamp:2019-03-04 23:23:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 845b4982-3ed4-11e9-967c-c655790ff683 0xc42224a4a0 0xc42224a4a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.178,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42224a520} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42224a540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.178,PodIP:,StartTime:2019-03-04 23:23:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.762: INFO: Pod "nginx-deployment-7dc8f79789-82q7d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-82q7d,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7dc8f79789-82q7d,UID:859b1267-3ed4-11e9-967c-c655790ff683,ResourceVersion:25556,Generation:0,CreationTimestamp:2019-03-04 23:23:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 845b4982-3ed4-11e9-967c-c655790ff683 0xc42224a860 0xc42224a861}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42224a8e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42224a900}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.162,PodIP:,StartTime:2019-03-04 23:23:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.762: INFO: Pod "nginx-deployment-7dc8f79789-dhqzg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-dhqzg,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7dc8f79789-dhqzg,UID:845d0698-3ed4-11e9-967c-c655790ff683,ResourceVersion:25389,Generation:0,CreationTimestamp:2019-03-04 23:23:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 845b4982-3ed4-11e9-967c-c655790ff683 0xc42224a9c0 0xc42224a9c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.178,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42224aa90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42224aac0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:28 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.178,PodIP:172.30.252.236,StartTime:2019-03-04 23:23:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.762: INFO: Pod "nginx-deployment-7dc8f79789-f7vg2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-f7vg2,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7dc8f79789-f7vg2,UID:84618a1e-3ed4-11e9-967c-c655790ff683,ResourceVersion:25399,Generation:0,CreationTimestamp:2019-03-04 23:23:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 845b4982-3ed4-11e9-967c-c655790ff683 0xc42224aba0 0xc42224aba1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42224ac30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42224ac50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:28 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.162,PodIP:172.30.86.190,StartTime:2019-03-04 23:23:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.762: INFO: Pod "nginx-deployment-7dc8f79789-fj7r2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-fj7r2,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7dc8f79789-fj7r2,UID:859d1b60-3ed4-11e9-967c-c655790ff683,ResourceVersion:25502,Generation:0,CreationTimestamp:2019-03-04 23:23:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 845b4982-3ed4-11e9-967c-c655790ff683 0xc42224ad30 0xc42224ad31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.160,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42224adb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42224add0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.160,PodIP:,StartTime:2019-03-04 23:23:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.762: INFO: Pod "nginx-deployment-7dc8f79789-lmhpb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-lmhpb,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7dc8f79789-lmhpb,UID:84627840-3ed4-11e9-967c-c655790ff683,ResourceVersion:25392,Generation:0,CreationTimestamp:2019-03-04 23:23:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 845b4982-3ed4-11e9-967c-c655790ff683 0xc42224ae90 0xc42224ae91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.160,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42224af10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42224af30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:28 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.160,PodIP:172.30.87.187,StartTime:2019-03-04 23:23:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.762: INFO: Pod "nginx-deployment-7dc8f79789-mjkkr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-mjkkr,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7dc8f79789-mjkkr,UID:859bfad3-3ed4-11e9-967c-c655790ff683,ResourceVersion:25451,Generation:0,CreationTimestamp:2019-03-04 23:23:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 845b4982-3ed4-11e9-967c-c655790ff683 0xc42224b010 0xc42224b011}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42224b090} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42224b0b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.765: INFO: Pod "nginx-deployment-7dc8f79789-nm5n5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-nm5n5,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7dc8f79789-nm5n5,UID:845d0577-3ed4-11e9-967c-c655790ff683,ResourceVersion:25402,Generation:0,CreationTimestamp:2019-03-04 23:23:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 845b4982-3ed4-11e9-967c-c655790ff683 0xc42224b120 0xc42224b121}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42224b1a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42224b1c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:28 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.162,PodIP:172.30.86.189,StartTime:2019-03-04 23:23:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.765: INFO: Pod "nginx-deployment-7dc8f79789-q9h6b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-q9h6b,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7dc8f79789-q9h6b,UID:859c09f0-3ed4-11e9-967c-c655790ff683,ResourceVersion:25483,Generation:0,CreationTimestamp:2019-03-04 23:23:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 845b4982-3ed4-11e9-967c-c655790ff683 0xc42224b2a0 0xc42224b2a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.160,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42224b330} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42224b350}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.160,PodIP:,StartTime:2019-03-04 23:23:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.765: INFO: Pod "nginx-deployment-7dc8f79789-s4t8b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-s4t8b,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7dc8f79789-s4t8b,UID:845c0f0d-3ed4-11e9-967c-c655790ff683,ResourceVersion:25396,Generation:0,CreationTimestamp:2019-03-04 23:23:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 845b4982-3ed4-11e9-967c-c655790ff683 0xc42224b410 0xc42224b411}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.160,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42224b4a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42224b4c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:28 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.160,PodIP:172.30.87.186,StartTime:2019-03-04 23:23:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.766: INFO: Pod "nginx-deployment-7dc8f79789-s7kt5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-s7kt5,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7dc8f79789-s7kt5,UID:8599ff57-3ed4-11e9-967c-c655790ff683,ResourceVersion:25473,Generation:0,CreationTimestamp:2019-03-04 23:23:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 845b4982-3ed4-11e9-967c-c655790ff683 0xc42224b5a0 0xc42224b5a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.160,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42224b760} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42224b780}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.160,PodIP:,StartTime:2019-03-04 23:23:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.766: INFO: Pod "nginx-deployment-7f9675fb8b-2hgqn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-2hgqn,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7f9675fb8b-2hgqn,UID:85992e13-3ed4-11e9-967c-c655790ff683,ResourceVersion:25497,Generation:0,CreationTimestamp:2019-03-04 23:23:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8322f46d-3ed4-11e9-967c-c655790ff683 0xc42224b850 0xc42224b851}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42224b8c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42224b8f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.162,PodIP:,StartTime:2019-03-04 23:23:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.766: INFO: Pod "nginx-deployment-7f9675fb8b-7rcwp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-7rcwp,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7f9675fb8b-7rcwp,UID:859c80ac-3ed4-11e9-967c-c655790ff683,ResourceVersion:25490,Generation:0,CreationTimestamp:2019-03-04 23:23:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8322f46d-3ed4-11e9-967c-c655790ff683 0xc42224b9a7 0xc42224b9a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.160,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42224ba20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42224ba40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.160,PodIP:,StartTime:2019-03-04 23:23:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.766: INFO: Pod "nginx-deployment-7f9675fb8b-bc8z2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-bc8z2,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7f9675fb8b-bc8z2,UID:83277689-3ed4-11e9-967c-c655790ff683,ResourceVersion:25273,Generation:0,CreationTimestamp:2019-03-04 23:23:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8322f46d-3ed4-11e9-967c-c655790ff683 0xc42224bb07 0xc42224bb08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.160,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42224bbf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42224bc20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:26 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.160,PodIP:172.30.87.184,StartTime:2019-03-04 23:23:26 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-04 23:23:27 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://369f3c6536b09a23526465c7dcc1984c704b1b6e9ce76cdd0575286a7b1eb1a3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.766: INFO: Pod "nginx-deployment-7f9675fb8b-c4j58" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-c4j58,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7f9675fb8b-c4j58,UID:859a4a53-3ed4-11e9-967c-c655790ff683,ResourceVersion:25478,Generation:0,CreationTimestamp:2019-03-04 23:23:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8322f46d-3ed4-11e9-967c-c655790ff683 0xc42224bce7 0xc42224bce8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.160,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42224bd60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42224bd80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.160,PodIP:,StartTime:2019-03-04 23:23:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.769: INFO: Pod "nginx-deployment-7f9675fb8b-f56vt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-f56vt,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7f9675fb8b-f56vt,UID:859c9f25-3ed4-11e9-967c-c655790ff683,ResourceVersion:25454,Generation:0,CreationTimestamp:2019-03-04 23:23:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8322f46d-3ed4-11e9-967c-c655790ff683 0xc42224be37 0xc42224be38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42224beb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42224bed0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.769: INFO: Pod "nginx-deployment-7f9675fb8b-g67hc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-g67hc,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7f9675fb8b-g67hc,UID:8329018b-3ed4-11e9-967c-c655790ff683,ResourceVersion:25274,Generation:0,CreationTimestamp:2019-03-04 23:23:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8322f46d-3ed4-11e9-967c-c655790ff683 0xc42224bf40 0xc42224bf41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.178,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42224bfb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42224bfd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:26 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.178,PodIP:172.30.252.235,StartTime:2019-03-04 23:23:26 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-04 23:23:27 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://bdc3f80e5b504d9390e217777b272199c46bfe651a643fb7db5e2f5d2af12b3b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.779: INFO: Pod "nginx-deployment-7f9675fb8b-hc59q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-hc59q,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7f9675fb8b-hc59q,UID:859b8090-3ed4-11e9-967c-c655790ff683,ResourceVersion:25486,Generation:0,CreationTimestamp:2019-03-04 23:23:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8322f46d-3ed4-11e9-967c-c655790ff683 0xc421c70207 0xc421c70208}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.178,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421c70280} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421c703c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.178,PodIP:,StartTime:2019-03-04 23:23:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.779: INFO: Pod "nginx-deployment-7f9675fb8b-jbwzt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-jbwzt,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7f9675fb8b-jbwzt,UID:8327827b-3ed4-11e9-967c-c655790ff683,ResourceVersion:25268,Generation:0,CreationTimestamp:2019-03-04 23:23:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8322f46d-3ed4-11e9-967c-c655790ff683 0xc421c706e7 0xc421c706e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.160,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421c70810} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421c70830}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:26 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.160,PodIP:172.30.87.185,StartTime:2019-03-04 23:23:26 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-04 23:23:27 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://4aa3c7110a85f8eaaa784902512563b0d41c62cfdf2b217b4d67210c89c59d78}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.779: INFO: Pod "nginx-deployment-7f9675fb8b-lqlch" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-lqlch,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7f9675fb8b-lqlch,UID:83290f21-3ed4-11e9-967c-c655790ff683,ResourceVersion:25288,Generation:0,CreationTimestamp:2019-03-04 23:23:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8322f46d-3ed4-11e9-967c-c655790ff683 0xc421c709a7 0xc421c709a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421c70a80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421c70aa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:26 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.162,PodIP:172.30.86.187,StartTime:2019-03-04 23:23:26 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-04 23:23:28 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://bbaff53d78cdc7e2aae53f4474913839e35eb29479756421be8480edb0ef49d8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.779: INFO: Pod "nginx-deployment-7f9675fb8b-njpsp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-njpsp,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7f9675fb8b-njpsp,UID:859a336b-3ed4-11e9-967c-c655790ff683,ResourceVersion:25525,Generation:0,CreationTimestamp:2019-03-04 23:23:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8322f46d-3ed4-11e9-967c-c655790ff683 0xc421c70bf7 0xc421c70bf8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421c70cf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421c70d10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.162,PodIP:,StartTime:2019-03-04 23:23:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.780: INFO: Pod "nginx-deployment-7f9675fb8b-p8t8z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-p8t8z,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7f9675fb8b-p8t8z,UID:859c9708-3ed4-11e9-967c-c655790ff683,ResourceVersion:25456,Generation:0,CreationTimestamp:2019-03-04 23:23:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8322f46d-3ed4-11e9-967c-c655790ff683 0xc421c70f97 0xc421c70f98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421c71080} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421c710a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.780: INFO: Pod "nginx-deployment-7f9675fb8b-qbmvk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-qbmvk,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7f9675fb8b-qbmvk,UID:859b730a-3ed4-11e9-967c-c655790ff683,ResourceVersion:25601,Generation:0,CreationTimestamp:2019-03-04 23:23:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8322f46d-3ed4-11e9-967c-c655790ff683 0xc421c71110 0xc421c71111}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421c71190} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421c711b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.162,PodIP:,StartTime:2019-03-04 23:23:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.780: INFO: Pod "nginx-deployment-7f9675fb8b-tjt78" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-tjt78,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7f9675fb8b-tjt78,UID:8326945a-3ed4-11e9-967c-c655790ff683,ResourceVersion:25259,Generation:0,CreationTimestamp:2019-03-04 23:23:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8322f46d-3ed4-11e9-967c-c655790ff683 0xc421c71267 0xc421c71268}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.178,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421c71300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421c71320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:26 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.178,PodIP:172.30.252.234,StartTime:2019-03-04 23:23:26 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-04 23:23:27 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://5f846148f32acc22ac06e35678ed37a6afc99f0cec8cac31584d710eedb09426}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.786: INFO: Pod "nginx-deployment-7f9675fb8b-twhb2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-twhb2,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7f9675fb8b-twhb2,UID:859c9df3-3ed4-11e9-967c-c655790ff683,ResourceVersion:25496,Generation:0,CreationTimestamp:2019-03-04 23:23:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8322f46d-3ed4-11e9-967c-c655790ff683 0xc421c714c7 0xc421c714c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.178,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421c71540} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421c71560}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.178,PodIP:,StartTime:2019-03-04 23:23:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.786: INFO: Pod "nginx-deployment-7f9675fb8b-v7sw5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-v7sw5,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7f9675fb8b-v7sw5,UID:859b7faf-3ed4-11e9-967c-c655790ff683,ResourceVersion:25571,Generation:0,CreationTimestamp:2019-03-04 23:23:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8322f46d-3ed4-11e9-967c-c655790ff683 0xc421c716a7 0xc421c716a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.178,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421c71740} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421c71760}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.178,PodIP:172.30.252.237,StartTime:2019-03-04 23:23:30 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-04 23:23:31 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://35938fc917fc49979e1ce93ae9b0a627687017e2b4fd96a5fd96141665726683}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.786: INFO: Pod "nginx-deployment-7f9675fb8b-vc225" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-vc225,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7f9675fb8b-vc225,UID:859b880a-3ed4-11e9-967c-c655790ff683,ResourceVersion:25622,Generation:0,CreationTimestamp:2019-03-04 23:23:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8322f46d-3ed4-11e9-967c-c655790ff683 0xc421c71837 0xc421c71838}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421c718b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421c718d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.162,PodIP:,StartTime:2019-03-04 23:23:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.786: INFO: Pod "nginx-deployment-7f9675fb8b-vxl69" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-vxl69,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7f9675fb8b-vxl69,UID:83275f0e-3ed4-11e9-967c-c655790ff683,ResourceVersion:25294,Generation:0,CreationTimestamp:2019-03-04 23:23:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8322f46d-3ed4-11e9-967c-c655790ff683 0xc421c71987 0xc421c71988}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.162,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421c71a00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421c71a30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:26 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.162,PodIP:172.30.86.185,StartTime:2019-03-04 23:23:26 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-04 23:23:28 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://f9379f20bebe4304118bb07bea3ab9a7845f8633db934c725baba4353d2ee1d4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.787: INFO: Pod "nginx-deployment-7f9675fb8b-wplhx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-wplhx,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7f9675fb8b-wplhx,UID:8325be85-3ed4-11e9-967c-c655790ff683,ResourceVersion:25264,Generation:0,CreationTimestamp:2019-03-04 23:23:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8322f46d-3ed4-11e9-967c-c655790ff683 0xc421c71af7 0xc421c71af8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.160,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421c71b70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421c71b90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:26 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.160,PodIP:172.30.87.182,StartTime:2019-03-04 23:23:26 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-04 23:23:27 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://5cc80cebda350f30e8ef25ff36125064046d699319cae28456465a8e48770d20}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.787: INFO: Pod "nginx-deployment-7f9675fb8b-xmjjb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-xmjjb,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7f9675fb8b-xmjjb,UID:832781bb-3ed4-11e9-967c-c655790ff683,ResourceVersion:25269,Generation:0,CreationTimestamp:2019-03-04 23:23:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8322f46d-3ed4-11e9-967c-c655790ff683 0xc421c71c57 0xc421c71c58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.178,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421c71cd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421c71cf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:26 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.178,PodIP:172.30.252.233,StartTime:2019-03-04 23:23:26 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-04 23:23:27 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://640110a3ab8d385f234b682e2153ed12b3c43d6cfb1d672d41ea15ddb578680d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  4 23:23:32.787: INFO: Pod "nginx-deployment-7f9675fb8b-zzcxt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-zzcxt,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-lcqzj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lcqzj/pods/nginx-deployment-7f9675fb8b-zzcxt,UID:859ca264-3ed4-11e9-967c-c655790ff683,ResourceVersion:25494,Generation:0,CreationTimestamp:2019-03-04 23:23:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8322f46d-3ed4-11e9-967c-c655790ff683 0xc421c71db7 0xc421c71db8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zcpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zcpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7zcpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.160,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421c71e30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421c71e50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:23:30 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.160,PodIP:,StartTime:2019-03-04 23:23:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:23:32.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-lcqzj" for this suite.
Mar  4 23:23:42.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:23:43.138: INFO: namespace: e2e-tests-deployment-lcqzj, resource: bindings, ignored listing per whitelist
Mar  4 23:23:43.142: INFO: namespace e2e-tests-deployment-lcqzj deletion completed in 10.341480269s

• [SLOW TEST:16.845 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:23:43.143: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-jxdpp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar  4 23:23:43.384: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:23:46.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-jxdpp" for this suite.
Mar  4 23:23:52.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:23:52.540: INFO: namespace: e2e-tests-init-container-jxdpp, resource: bindings, ignored listing per whitelist
Mar  4 23:23:52.770: INFO: namespace e2e-tests-init-container-jxdpp deletion completed in 6.458037001s

• [SLOW TEST:9.628 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:23:52.771: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-xppcf
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-92eab163-3ed4-11e9-b56c-8631b5a7dc0e
STEP: Creating secret with name s-test-opt-upd-92eab1b5-3ed4-11e9-b56c-8631b5a7dc0e
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-92eab163-3ed4-11e9-b56c-8631b5a7dc0e
STEP: Updating secret s-test-opt-upd-92eab1b5-3ed4-11e9-b56c-8631b5a7dc0e
STEP: Creating secret with name s-test-opt-create-92eab1d4-3ed4-11e9-b56c-8631b5a7dc0e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:25:22.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-xppcf" for this suite.
Mar  4 23:25:47.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:25:47.358: INFO: namespace: e2e-tests-secrets-xppcf, resource: bindings, ignored listing per whitelist
Mar  4 23:25:47.406: INFO: namespace e2e-tests-secrets-xppcf deletion completed in 24.4045507s

• [SLOW TEST:114.635 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:25:47.408: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-rk67m
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar  4 23:25:47.662: INFO: Waiting up to 5m0s for pod "downward-api-d73bc662-3ed4-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-downward-api-rk67m" to be "success or failure"
Mar  4 23:25:47.667: INFO: Pod "downward-api-d73bc662-3ed4-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.658268ms
Mar  4 23:25:49.688: INFO: Pod "downward-api-d73bc662-3ed4-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025801034s
STEP: Saw pod success
Mar  4 23:25:49.688: INFO: Pod "downward-api-d73bc662-3ed4-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 23:25:49.702: INFO: Trying to get logs from node 10.190.208.162 pod downward-api-d73bc662-3ed4-11e9-b56c-8631b5a7dc0e container dapi-container: <nil>
STEP: delete the pod
Mar  4 23:25:49.751: INFO: Waiting for pod downward-api-d73bc662-3ed4-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 23:25:49.758: INFO: Pod downward-api-d73bc662-3ed4-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:25:49.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rk67m" for this suite.
Mar  4 23:25:55.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:25:56.008: INFO: namespace: e2e-tests-downward-api-rk67m, resource: bindings, ignored listing per whitelist
Mar  4 23:25:56.132: INFO: namespace e2e-tests-downward-api-rk67m deletion completed in 6.357165899s

• [SLOW TEST:8.724 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:25:56.132: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-h7c5x
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-dc704811-3ed4-11e9-b56c-8631b5a7dc0e
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-dc704811-3ed4-11e9-b56c-8631b5a7dc0e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:27:31.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-h7c5x" for this suite.
Mar  4 23:27:53.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:27:53.700: INFO: namespace: e2e-tests-configmap-h7c5x, resource: bindings, ignored listing per whitelist
Mar  4 23:27:53.731: INFO: namespace e2e-tests-configmap-h7c5x deletion completed in 22.384493359s

• [SLOW TEST:117.599 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:27:53.733: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-tcmbq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  4 23:28:13.993: INFO: Container started at 2019-03-04 23:27:54 +0000 UTC, pod became ready at 2019-03-04 23:28:13 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:28:13.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-tcmbq" for this suite.
Mar  4 23:28:36.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:28:36.104: INFO: namespace: e2e-tests-container-probe-tcmbq, resource: bindings, ignored listing per whitelist
Mar  4 23:28:36.296: INFO: namespace e2e-tests-container-probe-tcmbq deletion completed in 22.293033524s

• [SLOW TEST:42.563 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:28:36.297: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-4xbz4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  4 23:28:36.558: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3be6bc32-3ed5-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-downward-api-4xbz4" to be "success or failure"
Mar  4 23:28:36.562: INFO: Pod "downwardapi-volume-3be6bc32-3ed5-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.570192ms
Mar  4 23:28:38.587: INFO: Pod "downwardapi-volume-3be6bc32-3ed5-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029519832s
STEP: Saw pod success
Mar  4 23:28:38.587: INFO: Pod "downwardapi-volume-3be6bc32-3ed5-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 23:28:38.592: INFO: Trying to get logs from node 10.190.208.162 pod downwardapi-volume-3be6bc32-3ed5-11e9-b56c-8631b5a7dc0e container client-container: <nil>
STEP: delete the pod
Mar  4 23:28:38.623: INFO: Waiting for pod downwardapi-volume-3be6bc32-3ed5-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 23:28:38.629: INFO: Pod downwardapi-volume-3be6bc32-3ed5-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:28:38.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4xbz4" for this suite.
Mar  4 23:28:44.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:28:44.725: INFO: namespace: e2e-tests-downward-api-4xbz4, resource: bindings, ignored listing per whitelist
Mar  4 23:28:45.083: INFO: namespace e2e-tests-downward-api-4xbz4 deletion completed in 6.441820215s

• [SLOW TEST:8.786 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:28:45.084: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-bnd8f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  4 23:28:45.380: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Mar  4 23:28:50.385: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar  4 23:28:50.385: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar  4 23:28:50.423: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-bnd8f,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bnd8f/deployments/test-cleanup-deployment,UID:4427bfe4-3ed5-11e9-967c-c655790ff683,ResourceVersion:26816,Generation:1,CreationTimestamp:2019-03-04 23:28:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Mar  4 23:28:50.427: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Mar  4 23:28:50.427: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Mar  4 23:28:50.428: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-bnd8f,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bnd8f/replicasets/test-cleanup-controller,UID:41296f52-3ed5-11e9-967c-c655790ff683,ResourceVersion:26817,Generation:1,CreationTimestamp:2019-03-04 23:28:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 4427bfe4-3ed5-11e9-967c-c655790ff683 0xc420e2ce57 0xc420e2ce58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar  4 23:28:50.433: INFO: Pod "test-cleanup-controller-w57fh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-w57fh,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-bnd8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bnd8f/pods/test-cleanup-controller-w57fh,UID:412c7429-3ed5-11e9-967c-c655790ff683,ResourceVersion:26806,Generation:0,CreationTimestamp:2019-03-04 23:28:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 41296f52-3ed5-11e9-967c-c655790ff683 0xc4225416f7 0xc4225416f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-v4nh4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-v4nh4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-v4nh4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.208.160,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422541770} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422541790}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:28:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:28:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:28:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-04 23:28:45 +0000 UTC  }],Message:,Reason:,HostIP:10.190.208.160,PodIP:172.30.87.142,StartTime:2019-03-04 23:28:45 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-04 23:28:46 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://28e79ff6f0cd8bf7dc2e3f9a0c89729d6befcee5e63bec9c1d2e7944401db790}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:28:50.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-bnd8f" for this suite.
Mar  4 23:28:56.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:28:57.570: INFO: namespace: e2e-tests-deployment-bnd8f, resource: bindings, ignored listing per whitelist
Mar  4 23:28:57.588: INFO: namespace e2e-tests-deployment-bnd8f deletion completed in 7.144063844s

• [SLOW TEST:12.504 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:28:57.588: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-s84t9
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-48aa3cd1-3ed5-11e9-b56c-8631b5a7dc0e
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:29:00.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-s84t9" for this suite.
Mar  4 23:29:22.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:29:22.095: INFO: namespace: e2e-tests-configmap-s84t9, resource: bindings, ignored listing per whitelist
Mar  4 23:29:22.346: INFO: namespace e2e-tests-configmap-s84t9 deletion completed in 22.296670179s

• [SLOW TEST:24.759 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:29:22.347: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-8btq9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-8btq9/configmap-test-57568e74-3ed5-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume configMaps
Mar  4 23:29:22.593: INFO: Waiting up to 5m0s for pod "pod-configmaps-575796a5-3ed5-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-configmap-8btq9" to be "success or failure"
Mar  4 23:29:22.598: INFO: Pod "pod-configmaps-575796a5-3ed5-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.002311ms
Mar  4 23:29:24.604: INFO: Pod "pod-configmaps-575796a5-3ed5-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011421544s
STEP: Saw pod success
Mar  4 23:29:24.604: INFO: Pod "pod-configmaps-575796a5-3ed5-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 23:29:24.609: INFO: Trying to get logs from node 10.190.208.160 pod pod-configmaps-575796a5-3ed5-11e9-b56c-8631b5a7dc0e container env-test: <nil>
STEP: delete the pod
Mar  4 23:29:24.682: INFO: Waiting for pod pod-configmaps-575796a5-3ed5-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 23:29:24.687: INFO: Pod pod-configmaps-575796a5-3ed5-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:29:24.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8btq9" for this suite.
Mar  4 23:29:30.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:29:30.819: INFO: namespace: e2e-tests-configmap-8btq9, resource: bindings, ignored listing per whitelist
Mar  4 23:29:31.008: INFO: namespace e2e-tests-configmap-8btq9 deletion completed in 6.309312451s

• [SLOW TEST:8.661 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:29:31.009: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-sd5f5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-5c82b9b2-3ed5-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume secrets
Mar  4 23:29:31.270: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5c83a84b-3ed5-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-projected-sd5f5" to be "success or failure"
Mar  4 23:29:31.274: INFO: Pod "pod-projected-secrets-5c83a84b-3ed5-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.616006ms
Mar  4 23:29:33.280: INFO: Pod "pod-projected-secrets-5c83a84b-3ed5-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010224634s
STEP: Saw pod success
Mar  4 23:29:33.280: INFO: Pod "pod-projected-secrets-5c83a84b-3ed5-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 23:29:33.285: INFO: Trying to get logs from node 10.190.208.160 pod pod-projected-secrets-5c83a84b-3ed5-11e9-b56c-8631b5a7dc0e container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  4 23:29:33.383: INFO: Waiting for pod pod-projected-secrets-5c83a84b-3ed5-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 23:29:33.405: INFO: Pod pod-projected-secrets-5c83a84b-3ed5-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:29:33.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sd5f5" for this suite.
Mar  4 23:29:41.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:29:41.635: INFO: namespace: e2e-tests-projected-sd5f5, resource: bindings, ignored listing per whitelist
Mar  4 23:29:41.783: INFO: namespace e2e-tests-projected-sd5f5 deletion completed in 8.366980617s

• [SLOW TEST:10.774 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:29:41.783: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-nk2sq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-nk2sq
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-nk2sq to expose endpoints map[]
Mar  4 23:29:42.123: INFO: Get endpoints failed (9.460806ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Mar  4 23:29:43.132: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-nk2sq exposes endpoints map[] (1.018692322s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-nk2sq
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-nk2sq to expose endpoints map[pod1:[100]]
Mar  4 23:29:44.200: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-nk2sq exposes endpoints map[pod1:[100]] (1.056582487s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-nk2sq
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-nk2sq to expose endpoints map[pod1:[100] pod2:[101]]
Mar  4 23:29:46.257: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-nk2sq exposes endpoints map[pod1:[100] pod2:[101]] (2.050455699s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-nk2sq
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-nk2sq to expose endpoints map[pod2:[101]]
Mar  4 23:29:46.278: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-nk2sq exposes endpoints map[pod2:[101]] (12.700657ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-nk2sq
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-nk2sq to expose endpoints map[]
Mar  4 23:29:47.313: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-nk2sq exposes endpoints map[] (1.017730002s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:29:47.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-nk2sq" for this suite.
Mar  4 23:30:11.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:30:11.633: INFO: namespace: e2e-tests-services-nk2sq, resource: bindings, ignored listing per whitelist
Mar  4 23:30:11.797: INFO: namespace e2e-tests-services-nk2sq deletion completed in 24.415340384s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:30.014 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:30:11.799: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-cfhvf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar  4 23:30:12.125: INFO: Waiting up to 5m0s for pod "pod-74ddb225-3ed5-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-emptydir-cfhvf" to be "success or failure"
Mar  4 23:30:12.187: INFO: Pod "pod-74ddb225-3ed5-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 61.716378ms
Mar  4 23:30:14.192: INFO: Pod "pod-74ddb225-3ed5-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.066899312s
STEP: Saw pod success
Mar  4 23:30:14.192: INFO: Pod "pod-74ddb225-3ed5-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 23:30:14.197: INFO: Trying to get logs from node 10.190.208.160 pod pod-74ddb225-3ed5-11e9-b56c-8631b5a7dc0e container test-container: <nil>
STEP: delete the pod
Mar  4 23:30:14.298: INFO: Waiting for pod pod-74ddb225-3ed5-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 23:30:14.303: INFO: Pod pod-74ddb225-3ed5-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:30:14.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cfhvf" for this suite.
Mar  4 23:30:20.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:30:20.443: INFO: namespace: e2e-tests-emptydir-cfhvf, resource: bindings, ignored listing per whitelist
Mar  4 23:30:20.857: INFO: namespace e2e-tests-emptydir-cfhvf deletion completed in 6.545579805s

• [SLOW TEST:9.059 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:30:20.859: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-7ghf9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-5lmg
STEP: Creating a pod to test atomic-volume-subpath
Mar  4 23:30:21.124: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-5lmg" in namespace "e2e-tests-subpath-7ghf9" to be "success or failure"
Mar  4 23:30:21.128: INFO: Pod "pod-subpath-test-configmap-5lmg": Phase="Pending", Reason="", readiness=false. Elapsed: 4.716176ms
Mar  4 23:30:23.134: INFO: Pod "pod-subpath-test-configmap-5lmg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010749599s
Mar  4 23:30:25.140: INFO: Pod "pod-subpath-test-configmap-5lmg": Phase="Running", Reason="", readiness=false. Elapsed: 4.01613514s
Mar  4 23:30:27.146: INFO: Pod "pod-subpath-test-configmap-5lmg": Phase="Running", Reason="", readiness=false. Elapsed: 6.022267925s
Mar  4 23:30:29.151: INFO: Pod "pod-subpath-test-configmap-5lmg": Phase="Running", Reason="", readiness=false. Elapsed: 8.027813388s
Mar  4 23:30:31.157: INFO: Pod "pod-subpath-test-configmap-5lmg": Phase="Running", Reason="", readiness=false. Elapsed: 10.033450615s
Mar  4 23:30:33.163: INFO: Pod "pod-subpath-test-configmap-5lmg": Phase="Running", Reason="", readiness=false. Elapsed: 12.03936231s
Mar  4 23:30:35.169: INFO: Pod "pod-subpath-test-configmap-5lmg": Phase="Running", Reason="", readiness=false. Elapsed: 14.045015819s
Mar  4 23:30:37.174: INFO: Pod "pod-subpath-test-configmap-5lmg": Phase="Running", Reason="", readiness=false. Elapsed: 16.050693974s
Mar  4 23:30:39.180: INFO: Pod "pod-subpath-test-configmap-5lmg": Phase="Running", Reason="", readiness=false. Elapsed: 18.056293639s
Mar  4 23:30:41.185: INFO: Pod "pod-subpath-test-configmap-5lmg": Phase="Running", Reason="", readiness=false. Elapsed: 20.061768942s
Mar  4 23:30:43.192: INFO: Pod "pod-subpath-test-configmap-5lmg": Phase="Running", Reason="", readiness=false. Elapsed: 22.067977041s
Mar  4 23:30:45.197: INFO: Pod "pod-subpath-test-configmap-5lmg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.073287897s
STEP: Saw pod success
Mar  4 23:30:45.197: INFO: Pod "pod-subpath-test-configmap-5lmg" satisfied condition "success or failure"
Mar  4 23:30:45.202: INFO: Trying to get logs from node 10.190.208.160 pod pod-subpath-test-configmap-5lmg container test-container-subpath-configmap-5lmg: <nil>
STEP: delete the pod
Mar  4 23:30:45.234: INFO: Waiting for pod pod-subpath-test-configmap-5lmg to disappear
Mar  4 23:30:45.238: INFO: Pod pod-subpath-test-configmap-5lmg no longer exists
STEP: Deleting pod pod-subpath-test-configmap-5lmg
Mar  4 23:30:45.238: INFO: Deleting pod "pod-subpath-test-configmap-5lmg" in namespace "e2e-tests-subpath-7ghf9"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:30:45.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-7ghf9" for this suite.
Mar  4 23:30:51.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:30:51.632: INFO: namespace: e2e-tests-subpath-7ghf9, resource: bindings, ignored listing per whitelist
Mar  4 23:30:51.818: INFO: namespace e2e-tests-subpath-7ghf9 deletion completed in 6.563458716s

• [SLOW TEST:30.959 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:30:51.818: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-brt7d
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar  4 23:30:52.062: INFO: Waiting up to 5m0s for pod "pod-8cab91ad-3ed5-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-emptydir-brt7d" to be "success or failure"
Mar  4 23:30:52.066: INFO: Pod "pod-8cab91ad-3ed5-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.58002ms
Mar  4 23:30:54.072: INFO: Pod "pod-8cab91ad-3ed5-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010689163s
STEP: Saw pod success
Mar  4 23:30:54.073: INFO: Pod "pod-8cab91ad-3ed5-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 23:30:54.077: INFO: Trying to get logs from node 10.190.208.160 pod pod-8cab91ad-3ed5-11e9-b56c-8631b5a7dc0e container test-container: <nil>
STEP: delete the pod
Mar  4 23:30:54.107: INFO: Waiting for pod pod-8cab91ad-3ed5-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 23:30:54.113: INFO: Pod pod-8cab91ad-3ed5-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:30:54.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-brt7d" for this suite.
Mar  4 23:31:00.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:31:00.320: INFO: namespace: e2e-tests-emptydir-brt7d, resource: bindings, ignored listing per whitelist
Mar  4 23:31:00.443: INFO: namespace e2e-tests-emptydir-brt7d deletion completed in 6.319143548s

• [SLOW TEST:8.625 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:31:00.443: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-jh5k4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-jh5k4
Mar  4 23:31:02.691: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-jh5k4
STEP: checking the pod's current state and verifying that restartCount is present
Mar  4 23:31:02.696: INFO: Initial restart count of pod liveness-http is 0
Mar  4 23:31:22.756: INFO: Restart count of pod e2e-tests-container-probe-jh5k4/liveness-http is now 1 (20.060117785s elapsed)
Mar  4 23:31:42.814: INFO: Restart count of pod e2e-tests-container-probe-jh5k4/liveness-http is now 2 (40.1179858s elapsed)
Mar  4 23:32:02.872: INFO: Restart count of pod e2e-tests-container-probe-jh5k4/liveness-http is now 3 (1m0.175995119s elapsed)
Mar  4 23:32:22.940: INFO: Restart count of pod e2e-tests-container-probe-jh5k4/liveness-http is now 4 (1m20.244237091s elapsed)
Mar  4 23:33:33.477: INFO: Restart count of pod e2e-tests-container-probe-jh5k4/liveness-http is now 5 (2m30.781506633s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:33:33.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-jh5k4" for this suite.
Mar  4 23:33:41.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:33:41.684: INFO: namespace: e2e-tests-container-probe-jh5k4, resource: bindings, ignored listing per whitelist
Mar  4 23:33:41.808: INFO: namespace e2e-tests-container-probe-jh5k4 deletion completed in 8.30327452s

• [SLOW TEST:161.365 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:33:41.809: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-qcxr5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  4 23:33:42.085: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Mar  4 23:33:42.108: INFO: Number of nodes with available pods: 0
Mar  4 23:33:42.108: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 23:33:43.133: INFO: Number of nodes with available pods: 0
Mar  4 23:33:43.133: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 23:33:44.125: INFO: Number of nodes with available pods: 3
Mar  4 23:33:44.125: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Mar  4 23:33:44.165: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:44.165: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:44.165: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:45.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:45.182: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:45.182: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:46.188: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:46.188: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:46.188: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:47.184: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:47.184: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:47.184: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:48.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:48.183: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:48.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:49.185: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:49.185: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:49.185: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:50.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:50.182: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:50.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:51.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:51.183: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:51.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:52.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:52.183: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:52.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:53.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:53.182: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:53.182: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:54.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:54.183: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:54.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:55.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:55.183: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:55.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:56.184: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:56.184: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:56.184: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:57.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:57.182: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:57.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:58.184: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:58.184: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:58.184: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:59.184: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:59.184: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:33:59.184: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:00.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:00.182: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:00.182: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:01.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:01.182: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:01.182: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:02.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:02.182: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:02.182: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:03.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:03.183: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:03.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:04.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:04.183: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:04.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:05.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:05.183: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:05.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:06.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:06.182: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:06.182: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:07.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:07.183: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:07.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:08.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:08.183: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:08.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:09.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:09.183: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:09.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:10.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:10.183: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:10.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:11.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:11.183: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:11.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:12.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:12.182: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:12.182: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:13.187: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:13.187: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:13.187: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:14.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:14.183: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:14.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:15.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:15.183: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:15.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:16.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:16.183: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:16.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:17.185: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:17.185: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:17.185: INFO: Pod daemon-set-9qjkq is not available
Mar  4 23:34:17.185: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:18.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:18.183: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:18.183: INFO: Pod daemon-set-9qjkq is not available
Mar  4 23:34:18.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:19.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:19.183: INFO: Wrong image for pod: daemon-set-9qjkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:19.183: INFO: Pod daemon-set-9qjkq is not available
Mar  4 23:34:19.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:20.188: INFO: Pod daemon-set-6xdp9 is not available
Mar  4 23:34:20.188: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:20.188: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:21.182: INFO: Pod daemon-set-6xdp9 is not available
Mar  4 23:34:21.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:21.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:22.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:22.182: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:23.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:23.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:24.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:24.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:25.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:25.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:26.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:26.182: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:27.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:27.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:28.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:28.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:29.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:29.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:30.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:30.182: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:31.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:31.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:32.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:32.182: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:33.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:33.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:34.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:34.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:35.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:35.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:36.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:36.182: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:37.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:37.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:38.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:38.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:39.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:39.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:40.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:40.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:41.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:41.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:42.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:42.182: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:43.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:43.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:44.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:44.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:45.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:45.182: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:46.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:46.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:47.184: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:47.184: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:48.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:48.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:49.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:49.182: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:50.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:50.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:51.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:51.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:52.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:52.183: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:53.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:53.182: INFO: Wrong image for pod: daemon-set-lfxs2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:53.183: INFO: Pod daemon-set-lfxs2 is not available
Mar  4 23:34:54.184: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:54.184: INFO: Pod daemon-set-cs4kt is not available
Mar  4 23:34:55.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:56.191: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:57.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:58.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:34:59.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:00.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:01.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:02.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:03.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:04.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:05.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:06.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:07.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:08.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:09.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:10.185: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:11.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:12.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:13.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:14.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:15.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:16.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:17.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:18.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:19.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:20.188: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:21.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:22.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:23.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:24.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:25.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:26.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:26.183: INFO: Pod daemon-set-94745 is not available
Mar  4 23:35:27.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:27.183: INFO: Pod daemon-set-94745 is not available
Mar  4 23:35:28.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:28.182: INFO: Pod daemon-set-94745 is not available
Mar  4 23:35:29.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:29.183: INFO: Pod daemon-set-94745 is not available
Mar  4 23:35:30.184: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:30.184: INFO: Pod daemon-set-94745 is not available
Mar  4 23:35:31.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:31.183: INFO: Pod daemon-set-94745 is not available
Mar  4 23:35:32.182: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:32.182: INFO: Pod daemon-set-94745 is not available
Mar  4 23:35:33.183: INFO: Wrong image for pod: daemon-set-94745. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  4 23:35:33.183: INFO: Pod daemon-set-94745 is not available
Mar  4 23:35:34.183: INFO: Pod daemon-set-q5bvt is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Mar  4 23:35:34.207: INFO: Number of nodes with available pods: 2
Mar  4 23:35:34.207: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 23:35:35.224: INFO: Number of nodes with available pods: 2
Mar  4 23:35:35.224: INFO: Node 10.190.208.160 is running more than one daemon pod
Mar  4 23:35:36.224: INFO: Number of nodes with available pods: 3
Mar  4 23:35:36.225: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-qcxr5, will wait for the garbage collector to delete the pods
Mar  4 23:35:36.378: INFO: Deleting {extensions DaemonSet} daemon-set took: 11.695103ms
Mar  4 23:35:36.479: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.172521ms
Mar  4 23:35:49.687: INFO: Number of nodes with available pods: 0
Mar  4 23:35:49.687: INFO: Number of running nodes: 0, number of available pods: 0
Mar  4 23:35:49.692: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-qcxr5/daemonsets","resourceVersion":"28137"},"items":null}

Mar  4 23:35:49.696: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-qcxr5/pods","resourceVersion":"28137"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:35:49.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-qcxr5" for this suite.
Mar  4 23:35:57.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:35:57.819: INFO: namespace: e2e-tests-daemonsets-qcxr5, resource: bindings, ignored listing per whitelist
Mar  4 23:35:58.097: INFO: namespace e2e-tests-daemonsets-qcxr5 deletion completed in 8.356498747s

• [SLOW TEST:136.288 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:35:58.097: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-hq85p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-4346113f-3ed6-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume configMaps
Mar  4 23:35:58.493: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4347090d-3ed6-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-projected-hq85p" to be "success or failure"
Mar  4 23:35:58.498: INFO: Pod "pod-projected-configmaps-4347090d-3ed6-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.784228ms
Mar  4 23:36:00.504: INFO: Pod "pod-projected-configmaps-4347090d-3ed6-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010712956s
STEP: Saw pod success
Mar  4 23:36:00.504: INFO: Pod "pod-projected-configmaps-4347090d-3ed6-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 23:36:00.509: INFO: Trying to get logs from node 10.190.208.160 pod pod-projected-configmaps-4347090d-3ed6-11e9-b56c-8631b5a7dc0e container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  4 23:36:00.583: INFO: Waiting for pod pod-projected-configmaps-4347090d-3ed6-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 23:36:00.588: INFO: Pod pod-projected-configmaps-4347090d-3ed6-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:36:00.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hq85p" for this suite.
Mar  4 23:36:06.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:36:06.774: INFO: namespace: e2e-tests-projected-hq85p, resource: bindings, ignored listing per whitelist
Mar  4 23:36:06.907: INFO: namespace e2e-tests-projected-hq85p deletion completed in 6.308149326s

• [SLOW TEST:8.810 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:36:06.907: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-mcdth
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Mar  4 23:36:07.167: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  4 23:36:07.186: INFO: Waiting for terminating namespaces to be deleted...
Mar  4 23:36:07.193: INFO: 
Logging pods the kubelet thinks is on node 10.190.208.160 before test
Mar  4 23:36:07.215: INFO: calico-kube-controllers-5c699798bc-n5qdk from kube-system started at 2019-03-04 21:29:15 +0000 UTC (1 container statuses recorded)
Mar  4 23:36:07.215: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Mar  4 23:36:07.215: INFO: calico-node-jxfjl from kube-system started at 2019-03-04 21:29:15 +0000 UTC (2 container statuses recorded)
Mar  4 23:36:07.215: INFO: 	Container calico-node ready: true, restart count 0
Mar  4 23:36:07.215: INFO: 	Container install-cni ready: true, restart count 0
Mar  4 23:36:07.216: INFO: ibm-file-plugin-586bb8bf84-dqlk6 from kube-system started at 2019-03-04 21:29:35 +0000 UTC (1 container statuses recorded)
Mar  4 23:36:07.216: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Mar  4 23:36:07.216: INFO: kube-dns-amd64-fcdcf59c5-kqdfx from kube-system started at 2019-03-04 21:29:35 +0000 UTC (3 container statuses recorded)
Mar  4 23:36:07.216: INFO: 	Container dnsmasq ready: true, restart count 0
Mar  4 23:36:07.216: INFO: 	Container kubedns ready: true, restart count 0
Mar  4 23:36:07.216: INFO: 	Container sidecar ready: true, restart count 0
Mar  4 23:36:07.216: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-04 22:09:39 +0000 UTC (1 container statuses recorded)
Mar  4 23:36:07.216: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar  4 23:36:07.216: INFO: ibm-keepalived-watcher-nh5p6 from kube-system started at 2019-03-04 21:29:15 +0000 UTC (1 container statuses recorded)
Mar  4 23:36:07.216: INFO: 	Container keepalived-watcher ready: true, restart count 0
Mar  4 23:36:07.216: INFO: vpn-6c6b45457f-xmlwb from kube-system started at 2019-03-04 21:29:35 +0000 UTC (1 container statuses recorded)
Mar  4 23:36:07.216: INFO: 	Container vpn ready: true, restart count 0
Mar  4 23:36:07.217: INFO: kube-dns-autoscaler-587cd5cd44-8p94v from kube-system started at 2019-03-04 21:29:35 +0000 UTC (1 container statuses recorded)
Mar  4 23:36:07.217: INFO: 	Container autoscaler ready: true, restart count 0
Mar  4 23:36:07.217: INFO: ibm-cloud-provider-ip-169-62-14-102-5c8b94578f-6j5h8 from ibm-system started at 2019-03-04 21:30:11 +0000 UTC (1 container statuses recorded)
Mar  4 23:36:07.217: INFO: 	Container ibm-cloud-provider-ip-169-62-14-102 ready: true, restart count 0
Mar  4 23:36:07.217: INFO: kubernetes-dashboard-b4bc7db5d-47nml from kube-system started at 2019-03-04 21:29:35 +0000 UTC (1 container statuses recorded)
Mar  4 23:36:07.217: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Mar  4 23:36:07.217: INFO: ibm-storage-watcher-54cf447885-vvkrq from kube-system started at 2019-03-04 21:29:35 +0000 UTC (1 container statuses recorded)
Mar  4 23:36:07.217: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Mar  4 23:36:07.217: INFO: ibm-kube-fluentd-xcfn9 from kube-system started at 2019-03-04 21:32:33 +0000 UTC (1 container statuses recorded)
Mar  4 23:36:07.217: INFO: 	Container fluentd ready: true, restart count 0
Mar  4 23:36:07.217: INFO: ibm-master-proxy-static-10.190.208.160 from kube-system started at <nil> (0 container statuses recorded)
Mar  4 23:36:07.217: INFO: sonobuoy-systemd-logs-daemon-set-96866c1b23744a30-zggp2 from heptio-sonobuoy started at 2019-03-04 22:09:43 +0000 UTC (2 container statuses recorded)
Mar  4 23:36:07.218: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Mar  4 23:36:07.218: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar  4 23:36:07.218: INFO: 
Logging pods the kubelet thinks is on node 10.190.208.162 before test
Mar  4 23:36:07.245: INFO: ibm-master-proxy-static-10.190.208.162 from kube-system started at <nil> (0 container statuses recorded)
Mar  4 23:36:07.245: INFO: ibm-kube-fluentd-th2p5 from kube-system started at 2019-03-04 21:32:33 +0000 UTC (1 container statuses recorded)
Mar  4 23:36:07.245: INFO: 	Container fluentd ready: true, restart count 0
Mar  4 23:36:07.245: INFO: calico-node-zcgq4 from kube-system started at 2019-03-04 21:30:51 +0000 UTC (2 container statuses recorded)
Mar  4 23:36:07.245: INFO: 	Container calico-node ready: true, restart count 0
Mar  4 23:36:07.245: INFO: 	Container install-cni ready: true, restart count 0
Mar  4 23:36:07.245: INFO: ibm-keepalived-watcher-mw942 from kube-system started at 2019-03-04 21:30:51 +0000 UTC (1 container statuses recorded)
Mar  4 23:36:07.245: INFO: 	Container keepalived-watcher ready: true, restart count 0
Mar  4 23:36:07.245: INFO: public-cr4b0320f2477b4ad1a9b3673fb5e37483-alb1-596b8cfb5f-xfbwf from kube-system started at 2019-03-04 21:34:56 +0000 UTC (4 container statuses recorded)
Mar  4 23:36:07.245: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Mar  4 23:36:07.245: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Mar  4 23:36:07.245: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Mar  4 23:36:07.245: INFO: 	Container nginx-ingress ready: true, restart count 0
Mar  4 23:36:07.245: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-03-04 22:09:33 +0000 UTC (1 container statuses recorded)
Mar  4 23:36:07.245: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Mar  4 23:36:07.245: INFO: sonobuoy-e2e-job-13307d6f62184a08 from heptio-sonobuoy started at 2019-03-04 22:09:43 +0000 UTC (2 container statuses recorded)
Mar  4 23:36:07.245: INFO: 	Container e2e ready: true, restart count 0
Mar  4 23:36:07.245: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  4 23:36:07.245: INFO: sonobuoy-systemd-logs-daemon-set-96866c1b23744a30-86vwv from heptio-sonobuoy started at 2019-03-04 22:09:43 +0000 UTC (2 container statuses recorded)
Mar  4 23:36:07.245: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Mar  4 23:36:07.245: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar  4 23:36:07.245: INFO: 
Logging pods the kubelet thinks is on node 10.190.208.178 before test
Mar  4 23:36:07.272: INFO: ibm-master-proxy-static-10.190.208.178 from kube-system started at <nil> (0 container statuses recorded)
Mar  4 23:36:07.272: INFO: ibm-cloud-provider-ip-169-62-14-102-5c8b94578f-k5xwv from ibm-system started at 2019-03-04 21:30:11 +0000 UTC (1 container statuses recorded)
Mar  4 23:36:07.272: INFO: 	Container ibm-cloud-provider-ip-169-62-14-102 ready: true, restart count 0
Mar  4 23:36:07.272: INFO: ibm-kube-fluentd-9dt4m from kube-system started at 2019-03-04 21:32:33 +0000 UTC (1 container statuses recorded)
Mar  4 23:36:07.272: INFO: 	Container fluentd ready: true, restart count 0
Mar  4 23:36:07.273: INFO: public-cr4b0320f2477b4ad1a9b3673fb5e37483-alb1-596b8cfb5f-trd2m from kube-system started at 2019-03-04 21:34:56 +0000 UTC (4 container statuses recorded)
Mar  4 23:36:07.273: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Mar  4 23:36:07.273: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Mar  4 23:36:07.273: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Mar  4 23:36:07.273: INFO: 	Container nginx-ingress ready: true, restart count 0
Mar  4 23:36:07.273: INFO: metrics-server-6db7656f6c-wm6gm from kube-system started at 2019-03-04 21:29:54 +0000 UTC (2 container statuses recorded)
Mar  4 23:36:07.273: INFO: 	Container metrics-server ready: true, restart count 0
Mar  4 23:36:07.273: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Mar  4 23:36:07.273: INFO: calico-node-7g6nw from kube-system started at 2019-03-04 21:29:37 +0000 UTC (2 container statuses recorded)
Mar  4 23:36:07.273: INFO: 	Container calico-node ready: true, restart count 0
Mar  4 23:36:07.273: INFO: 	Container install-cni ready: true, restart count 0
Mar  4 23:36:07.274: INFO: kube-dns-amd64-fcdcf59c5-tldtv from kube-system started at 2019-03-04 21:29:47 +0000 UTC (3 container statuses recorded)
Mar  4 23:36:07.274: INFO: 	Container dnsmasq ready: true, restart count 0
Mar  4 23:36:07.274: INFO: 	Container kubedns ready: true, restart count 0
Mar  4 23:36:07.274: INFO: 	Container sidecar ready: true, restart count 0
Mar  4 23:36:07.274: INFO: ibm-keepalived-watcher-fqsjb from kube-system started at 2019-03-04 21:29:37 +0000 UTC (1 container statuses recorded)
Mar  4 23:36:07.274: INFO: 	Container keepalived-watcher ready: true, restart count 0
Mar  4 23:36:07.274: INFO: sonobuoy-systemd-logs-daemon-set-96866c1b23744a30-mlqpv from heptio-sonobuoy started at 2019-03-04 22:09:43 +0000 UTC (2 container statuses recorded)
Mar  4 23:36:07.274: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Mar  4 23:36:07.274: INFO: 	Container sonobuoy-worker ready: true, restart count 1
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node 10.190.208.160
STEP: verifying the node has the label node 10.190.208.162
STEP: verifying the node has the label node 10.190.208.178
Mar  4 23:36:07.367: INFO: Pod test-k8s-e2e-pvg-master-verification requesting resource cpu=0m on Node 10.190.208.162
Mar  4 23:36:07.367: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.190.208.160
Mar  4 23:36:07.367: INFO: Pod sonobuoy-e2e-job-13307d6f62184a08 requesting resource cpu=0m on Node 10.190.208.162
Mar  4 23:36:07.367: INFO: Pod sonobuoy-systemd-logs-daemon-set-96866c1b23744a30-86vwv requesting resource cpu=0m on Node 10.190.208.162
Mar  4 23:36:07.367: INFO: Pod sonobuoy-systemd-logs-daemon-set-96866c1b23744a30-mlqpv requesting resource cpu=0m on Node 10.190.208.178
Mar  4 23:36:07.367: INFO: Pod sonobuoy-systemd-logs-daemon-set-96866c1b23744a30-zggp2 requesting resource cpu=0m on Node 10.190.208.160
Mar  4 23:36:07.367: INFO: Pod ibm-cloud-provider-ip-169-62-14-102-5c8b94578f-6j5h8 requesting resource cpu=5m on Node 10.190.208.160
Mar  4 23:36:07.367: INFO: Pod ibm-cloud-provider-ip-169-62-14-102-5c8b94578f-k5xwv requesting resource cpu=5m on Node 10.190.208.178
Mar  4 23:36:07.367: INFO: Pod calico-kube-controllers-5c699798bc-n5qdk requesting resource cpu=10m on Node 10.190.208.160
Mar  4 23:36:07.367: INFO: Pod calico-node-7g6nw requesting resource cpu=255m on Node 10.190.208.178
Mar  4 23:36:07.367: INFO: Pod calico-node-jxfjl requesting resource cpu=255m on Node 10.190.208.160
Mar  4 23:36:07.367: INFO: Pod calico-node-zcgq4 requesting resource cpu=255m on Node 10.190.208.162
Mar  4 23:36:07.368: INFO: Pod ibm-file-plugin-586bb8bf84-dqlk6 requesting resource cpu=50m on Node 10.190.208.160
Mar  4 23:36:07.368: INFO: Pod ibm-keepalived-watcher-fqsjb requesting resource cpu=5m on Node 10.190.208.178
Mar  4 23:36:07.368: INFO: Pod ibm-keepalived-watcher-mw942 requesting resource cpu=5m on Node 10.190.208.162
Mar  4 23:36:07.368: INFO: Pod ibm-keepalived-watcher-nh5p6 requesting resource cpu=5m on Node 10.190.208.160
Mar  4 23:36:07.368: INFO: Pod ibm-kube-fluentd-9dt4m requesting resource cpu=25m on Node 10.190.208.178
Mar  4 23:36:07.368: INFO: Pod ibm-kube-fluentd-th2p5 requesting resource cpu=25m on Node 10.190.208.162
Mar  4 23:36:07.368: INFO: Pod ibm-kube-fluentd-xcfn9 requesting resource cpu=25m on Node 10.190.208.160
Mar  4 23:36:07.368: INFO: Pod ibm-master-proxy-static-10.190.208.160 requesting resource cpu=25m on Node 10.190.208.160
Mar  4 23:36:07.368: INFO: Pod ibm-master-proxy-static-10.190.208.162 requesting resource cpu=25m on Node 10.190.208.162
Mar  4 23:36:07.368: INFO: Pod ibm-master-proxy-static-10.190.208.178 requesting resource cpu=25m on Node 10.190.208.178
Mar  4 23:36:07.368: INFO: Pod ibm-storage-watcher-54cf447885-vvkrq requesting resource cpu=50m on Node 10.190.208.160
Mar  4 23:36:07.368: INFO: Pod kube-dns-amd64-fcdcf59c5-kqdfx requesting resource cpu=260m on Node 10.190.208.160
Mar  4 23:36:07.368: INFO: Pod kube-dns-amd64-fcdcf59c5-tldtv requesting resource cpu=260m on Node 10.190.208.178
Mar  4 23:36:07.368: INFO: Pod kube-dns-autoscaler-587cd5cd44-8p94v requesting resource cpu=20m on Node 10.190.208.160
Mar  4 23:36:07.368: INFO: Pod kubernetes-dashboard-b4bc7db5d-47nml requesting resource cpu=50m on Node 10.190.208.160
Mar  4 23:36:07.368: INFO: Pod metrics-server-6db7656f6c-wm6gm requesting resource cpu=53m on Node 10.190.208.178
Mar  4 23:36:07.368: INFO: Pod public-cr4b0320f2477b4ad1a9b3673fb5e37483-alb1-596b8cfb5f-trd2m requesting resource cpu=0m on Node 10.190.208.178
Mar  4 23:36:07.368: INFO: Pod public-cr4b0320f2477b4ad1a9b3673fb5e37483-alb1-596b8cfb5f-xfbwf requesting resource cpu=0m on Node 10.190.208.162
Mar  4 23:36:07.368: INFO: Pod vpn-6c6b45457f-xmlwb requesting resource cpu=5m on Node 10.190.208.160
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-489d0933-3ed6-11e9-b56c-8631b5a7dc0e.1588e5a4c03212d2], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-mcdth/filler-pod-489d0933-3ed6-11e9-b56c-8631b5a7dc0e to 10.190.208.160]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-489d0933-3ed6-11e9-b56c-8631b5a7dc0e.1588e5a4edd8d9a1], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-489d0933-3ed6-11e9-b56c-8631b5a7dc0e.1588e5a4f02de70e], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-489d0933-3ed6-11e9-b56c-8631b5a7dc0e.1588e5a4f819e224], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-489e90b7-3ed6-11e9-b56c-8631b5a7dc0e.1588e5a4c09afc76], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-mcdth/filler-pod-489e90b7-3ed6-11e9-b56c-8631b5a7dc0e to 10.190.208.162]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-489e90b7-3ed6-11e9-b56c-8631b5a7dc0e.1588e5a4ef174af7], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-489e90b7-3ed6-11e9-b56c-8631b5a7dc0e.1588e5a4f181f14f], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-489e90b7-3ed6-11e9-b56c-8631b5a7dc0e.1588e5a4f8494668], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-489f804d-3ed6-11e9-b56c-8631b5a7dc0e.1588e5a4c0e32ff4], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-mcdth/filler-pod-489f804d-3ed6-11e9-b56c-8631b5a7dc0e to 10.190.208.178]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-489f804d-3ed6-11e9-b56c-8631b5a7dc0e.1588e5a4ef899d8f], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-489f804d-3ed6-11e9-b56c-8631b5a7dc0e.1588e5a4f1ca0c32], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-489f804d-3ed6-11e9-b56c-8631b5a7dc0e.1588e5a4f9fddea4], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1588e5a54d7830e5], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 10.190.208.160
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.190.208.162
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.190.208.178
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:36:10.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-mcdth" for this suite.
Mar  4 23:36:16.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:36:17.216: INFO: namespace: e2e-tests-sched-pred-mcdth, resource: bindings, ignored listing per whitelist
Mar  4 23:36:17.252: INFO: namespace e2e-tests-sched-pred-mcdth deletion completed in 6.395452846s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:10.345 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:36:17.252: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-769dd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Mar  4 23:36:17.492: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-126132266 proxy --unix-socket=/tmp/kubectl-proxy-unix480672641/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:36:17.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-769dd" for this suite.
Mar  4 23:36:23.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:36:23.719: INFO: namespace: e2e-tests-kubectl-769dd, resource: bindings, ignored listing per whitelist
Mar  4 23:36:24.062: INFO: namespace e2e-tests-kubectl-769dd deletion completed in 6.488014449s

• [SLOW TEST:6.810 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:36:24.063: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-wv7pt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Mar  4 23:36:24.404: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-wv7pt,SelfLink:/api/v1/namespaces/e2e-tests-watch-wv7pt/configmaps/e2e-watch-test-resource-version,UID:52bea663-3ed6-11e9-967c-c655790ff683,ResourceVersion:28396,Generation:0,CreationTimestamp:2019-03-04 23:36:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  4 23:36:24.404: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-wv7pt,SelfLink:/api/v1/namespaces/e2e-tests-watch-wv7pt/configmaps/e2e-watch-test-resource-version,UID:52bea663-3ed6-11e9-967c-c655790ff683,ResourceVersion:28397,Generation:0,CreationTimestamp:2019-03-04 23:36:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:36:24.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-wv7pt" for this suite.
Mar  4 23:36:30.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:36:30.464: INFO: namespace: e2e-tests-watch-wv7pt, resource: bindings, ignored listing per whitelist
Mar  4 23:36:30.665: INFO: namespace e2e-tests-watch-wv7pt deletion completed in 6.248100284s

• [SLOW TEST:6.603 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:36:30.668: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-l78xh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Mar  4 23:36:31.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 create -f - --namespace=e2e-tests-kubectl-l78xh'
Mar  4 23:36:31.826: INFO: stderr: ""
Mar  4 23:36:31.826: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  4 23:36:31.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-l78xh'
Mar  4 23:36:31.961: INFO: stderr: ""
Mar  4 23:36:31.961: INFO: stdout: "update-demo-nautilus-46shj update-demo-nautilus-mg7jh "
Mar  4 23:36:31.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods update-demo-nautilus-46shj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-l78xh'
Mar  4 23:36:32.075: INFO: stderr: ""
Mar  4 23:36:32.075: INFO: stdout: ""
Mar  4 23:36:32.075: INFO: update-demo-nautilus-46shj is created but not running
Mar  4 23:36:37.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-l78xh'
Mar  4 23:36:37.212: INFO: stderr: ""
Mar  4 23:36:37.212: INFO: stdout: "update-demo-nautilus-46shj update-demo-nautilus-mg7jh "
Mar  4 23:36:37.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods update-demo-nautilus-46shj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-l78xh'
Mar  4 23:36:37.316: INFO: stderr: ""
Mar  4 23:36:37.316: INFO: stdout: "true"
Mar  4 23:36:37.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods update-demo-nautilus-46shj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-l78xh'
Mar  4 23:36:37.484: INFO: stderr: ""
Mar  4 23:36:37.484: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  4 23:36:37.484: INFO: validating pod update-demo-nautilus-46shj
Mar  4 23:36:37.502: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  4 23:36:37.502: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  4 23:36:37.502: INFO: update-demo-nautilus-46shj is verified up and running
Mar  4 23:36:37.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods update-demo-nautilus-mg7jh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-l78xh'
Mar  4 23:36:37.620: INFO: stderr: ""
Mar  4 23:36:37.620: INFO: stdout: "true"
Mar  4 23:36:37.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods update-demo-nautilus-mg7jh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-l78xh'
Mar  4 23:36:37.764: INFO: stderr: ""
Mar  4 23:36:37.764: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  4 23:36:37.764: INFO: validating pod update-demo-nautilus-mg7jh
Mar  4 23:36:37.777: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  4 23:36:37.777: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  4 23:36:37.777: INFO: update-demo-nautilus-mg7jh is verified up and running
STEP: rolling-update to new replication controller
Mar  4 23:36:37.779: INFO: scanned /root for discovery docs: <nil>
Mar  4 23:36:37.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-l78xh'
Mar  4 23:36:59.771: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar  4 23:36:59.771: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  4 23:36:59.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-l78xh'
Mar  4 23:36:59.988: INFO: stderr: ""
Mar  4 23:36:59.988: INFO: stdout: "update-demo-kitten-cds88 update-demo-kitten-sdzzg "
Mar  4 23:36:59.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods update-demo-kitten-cds88 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-l78xh'
Mar  4 23:37:00.095: INFO: stderr: ""
Mar  4 23:37:00.095: INFO: stdout: "true"
Mar  4 23:37:00.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods update-demo-kitten-cds88 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-l78xh'
Mar  4 23:37:00.214: INFO: stderr: ""
Mar  4 23:37:00.214: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar  4 23:37:00.214: INFO: validating pod update-demo-kitten-cds88
Mar  4 23:37:00.226: INFO: got data: {
  "image": "kitten.jpg"
}

Mar  4 23:37:00.226: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar  4 23:37:00.227: INFO: update-demo-kitten-cds88 is verified up and running
Mar  4 23:37:00.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods update-demo-kitten-sdzzg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-l78xh'
Mar  4 23:37:00.680: INFO: stderr: ""
Mar  4 23:37:00.680: INFO: stdout: "true"
Mar  4 23:37:00.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 get pods update-demo-kitten-sdzzg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-l78xh'
Mar  4 23:37:00.885: INFO: stderr: ""
Mar  4 23:37:00.885: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar  4 23:37:00.885: INFO: validating pod update-demo-kitten-sdzzg
Mar  4 23:37:00.898: INFO: got data: {
  "image": "kitten.jpg"
}

Mar  4 23:37:00.898: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar  4 23:37:00.898: INFO: update-demo-kitten-sdzzg is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:37:00.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-l78xh" for this suite.
Mar  4 23:37:24.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:37:25.098: INFO: namespace: e2e-tests-kubectl-l78xh, resource: bindings, ignored listing per whitelist
Mar  4 23:37:25.322: INFO: namespace e2e-tests-kubectl-l78xh deletion completed in 24.413954107s

• [SLOW TEST:54.655 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:37:25.322: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-qkfmv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Mar  4 23:37:25.581: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-qkfmv,SelfLink:/api/v1/namespaces/e2e-tests-watch-qkfmv/configmaps/e2e-watch-test-watch-closed,UID:7738a120-3ed6-11e9-967c-c655790ff683,ResourceVersion:28671,Generation:0,CreationTimestamp:2019-03-04 23:37:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  4 23:37:25.581: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-qkfmv,SelfLink:/api/v1/namespaces/e2e-tests-watch-qkfmv/configmaps/e2e-watch-test-watch-closed,UID:7738a120-3ed6-11e9-967c-c655790ff683,ResourceVersion:28672,Generation:0,CreationTimestamp:2019-03-04 23:37:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Mar  4 23:37:25.605: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-qkfmv,SelfLink:/api/v1/namespaces/e2e-tests-watch-qkfmv/configmaps/e2e-watch-test-watch-closed,UID:7738a120-3ed6-11e9-967c-c655790ff683,ResourceVersion:28673,Generation:0,CreationTimestamp:2019-03-04 23:37:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  4 23:37:25.606: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-qkfmv,SelfLink:/api/v1/namespaces/e2e-tests-watch-qkfmv/configmaps/e2e-watch-test-watch-closed,UID:7738a120-3ed6-11e9-967c-c655790ff683,ResourceVersion:28674,Generation:0,CreationTimestamp:2019-03-04 23:37:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:37:25.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-qkfmv" for this suite.
Mar  4 23:37:33.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:37:33.683: INFO: namespace: e2e-tests-watch-qkfmv, resource: bindings, ignored listing per whitelist
Mar  4 23:37:33.897: INFO: namespace e2e-tests-watch-qkfmv deletion completed in 8.281235081s

• [SLOW TEST:8.574 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:37:33.897: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-znzgq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Mar  4 23:37:34.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 cluster-info'
Mar  4 23:37:34.246: INFO: stderr: ""
Mar  4 23:37:34.246: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:37:34.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-znzgq" for this suite.
Mar  4 23:37:40.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:37:40.511: INFO: namespace: e2e-tests-kubectl-znzgq, resource: bindings, ignored listing per whitelist
Mar  4 23:37:40.618: INFO: namespace e2e-tests-kubectl-znzgq deletion completed in 6.335009307s

• [SLOW TEST:6.721 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:37:40.618: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-2rl7z
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  4 23:37:40.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 version --client'
Mar  4 23:37:40.949: INFO: stderr: ""
Mar  4 23:37:40.949: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Mar  4 23:37:40.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 create -f - --namespace=e2e-tests-kubectl-2rl7z'
Mar  4 23:37:41.180: INFO: stderr: ""
Mar  4 23:37:41.180: INFO: stdout: "replicationcontroller/redis-master created\n"
Mar  4 23:37:41.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 create -f - --namespace=e2e-tests-kubectl-2rl7z'
Mar  4 23:37:41.394: INFO: stderr: ""
Mar  4 23:37:41.394: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar  4 23:37:42.402: INFO: Selector matched 1 pods for map[app:redis]
Mar  4 23:37:42.402: INFO: Found 0 / 1
Mar  4 23:37:43.401: INFO: Selector matched 1 pods for map[app:redis]
Mar  4 23:37:43.401: INFO: Found 1 / 1
Mar  4 23:37:43.401: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar  4 23:37:43.405: INFO: Selector matched 1 pods for map[app:redis]
Mar  4 23:37:43.405: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar  4 23:37:43.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 describe pod redis-master-gl6hv --namespace=e2e-tests-kubectl-2rl7z'
Mar  4 23:37:43.564: INFO: stderr: ""
Mar  4 23:37:43.565: INFO: stdout: "Name:               redis-master-gl6hv\nNamespace:          e2e-tests-kubectl-2rl7z\nPriority:           0\nPriorityClassName:  <none>\nNode:               10.190.208.160/10.190.208.160\nStart Time:         Mon, 04 Mar 2019 23:37:41 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        kubernetes.io/psp: e2e-test-privileged-psp\nStatus:             Running\nIP:                 172.30.87.156\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://9b400f4d80a820d1f1ee28736a8bd730c241a9a73b002efa2f36ef1362ff1a8c\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 04 Mar 2019 23:37:42 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-jpqm4 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-jpqm4:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-jpqm4\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                     Message\n  ----    ------     ----  ----                     -------\n  Normal  Scheduled  2s    default-scheduler        Successfully assigned e2e-tests-kubectl-2rl7z/redis-master-gl6hv to 10.190.208.160\n  Normal  Pulled     1s    kubelet, 10.190.208.160  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, 10.190.208.160  Created container\n  Normal  Started    1s    kubelet, 10.190.208.160  Started container\n"
Mar  4 23:37:43.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 describe rc redis-master --namespace=e2e-tests-kubectl-2rl7z'
Mar  4 23:37:43.734: INFO: stderr: ""
Mar  4 23:37:43.734: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-2rl7z\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-gl6hv\n"
Mar  4 23:37:43.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 describe service redis-master --namespace=e2e-tests-kubectl-2rl7z'
Mar  4 23:37:43.886: INFO: stderr: ""
Mar  4 23:37:43.886: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-2rl7z\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.21.15.241\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.30.87.156:6379\nSession Affinity:  None\nEvents:            <none>\n"
Mar  4 23:37:43.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 describe node 10.190.208.160'
Mar  4 23:37:44.138: INFO: stderr: ""
Mar  4 23:37:44.138: INFO: stdout: "Name:               10.190.208.160\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=u2c.2x4.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-east\n                    failure-domain.beta.kubernetes.io/zone=wdc07\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/machine-type=u2c.2x4.encrypted\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-pool-id=4b0320f2477b4ad1a9b3673fb5e37483-0839371\n                    ibm-cloud.kubernetes.io/worker-version=1.12.6_1541\n                    kubernetes.io/hostname=10.190.208.160\n                    privateVLAN=2561669\n                    publicVLAN=2561667\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 04 Mar 2019 21:29:15 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Mon, 04 Mar 2019 23:37:35 +0000   Mon, 04 Mar 2019 21:29:15 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Mon, 04 Mar 2019 23:37:35 +0000   Mon, 04 Mar 2019 21:29:15 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 04 Mar 2019 23:37:35 +0000   Mon, 04 Mar 2019 21:29:15 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 04 Mar 2019 23:37:35 +0000   Mon, 04 Mar 2019 21:29:15 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 04 Mar 2019 23:37:35 +0000   Mon, 04 Mar 2019 21:29:35 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.190.208.160\n  ExternalIP:  169.62.47.89\n  Hostname:    10.190.208.160\nCapacity:\n cpu:                2\n ephemeral-storage:  103079200Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             4041552Ki\n pods:               110\nAllocatable:\n cpu:                1920m\n ephemeral-storage:  100275445682\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             3535696Ki\n pods:               110\nSystem Info:\n Machine ID:                 266c2075dace453da02500b328c9e325\n System UUID:                9D42D6CC-BDDF-E86B-F24B-A8DDE7687E86\n Boot ID:                    db372269-db7d-4c06-9702-ff282d092ace\n Kernel Version:             4.4.0-142-generic\n OS Image:                   Ubuntu 16.04.6 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.1.6\n Kubelet Version:            v1.12.6+IKS\n Kube-Proxy Version:         v1.12.6+IKS\nProviderID:                  ibm://d18c889395112a40d2f4e3065f237a7d///4b0320f2477b4ad1a9b3673fb5e37483/kube-wdc07-cr4b0320f2477b4ad1a9b3673fb5e37483-w3\nNon-terminated Pods:         (15 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  e2e-tests-kubectl-2rl7z    redis-master-gl6hv                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-96866c1b23744a30-zggp2    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  ibm-system                 ibm-cloud-provider-ip-169-62-14-102-5c8b94578f-6j5h8       5m (0%)       0 (0%)      10Mi (0%)        0 (0%)\n  kube-system                calico-kube-controllers-5c699798bc-n5qdk                   10m (0%)      0 (0%)      25Mi (0%)        0 (0%)\n  kube-system                calico-node-jxfjl                                          255m (13%)    0 (0%)      85Mi (2%)        0 (0%)\n  kube-system                ibm-file-plugin-586bb8bf84-dqlk6                           50m (2%)      200m (10%)  100Mi (2%)       0 (0%)\n  kube-system                ibm-keepalived-watcher-nh5p6                               5m (0%)       0 (0%)      10Mi (0%)        0 (0%)\n  kube-system                ibm-kube-fluentd-xcfn9                                     25m (1%)      300m (15%)  50Mi (1%)        800M (22%)\n  kube-system                ibm-master-proxy-static-10.190.208.160                     25m (1%)      300m (15%)  32M (0%)         512M (14%)\n  kube-system                ibm-storage-watcher-54cf447885-vvkrq                       50m (2%)      200m (10%)  100Mi (2%)       0 (0%)\n  kube-system                kube-dns-amd64-fcdcf59c5-kqdfx                             260m (13%)    0 (0%)      110Mi (3%)       400Mi (11%)\n  kube-system                kube-dns-autoscaler-587cd5cd44-8p94v                       20m (1%)      0 (0%)      10Mi (0%)        0 (0%)\n  kube-system                kubernetes-dashboard-b4bc7db5d-47nml                       50m (2%)      0 (0%)      100Mi (2%)       0 (0%)\n  kube-system                vpn-6c6b45457f-xmlwb                                       5m (0%)       0 (0%)      5Mi (0%)         0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource  Requests        Limits\n  --------  --------        ------\n  cpu       760m (39%)      1 (52%)\n  memory    650770Ki (18%)  1731430400 (47%)\nEvents:     <none>\n"
Mar  4 23:37:44.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 describe namespace e2e-tests-kubectl-2rl7z'
Mar  4 23:37:44.284: INFO: stderr: ""
Mar  4 23:37:44.284: INFO: stdout: "Name:         e2e-tests-kubectl-2rl7z\nLabels:       e2e-framework=kubectl\n              e2e-run=456750ee-3eca-11e9-b56c-8631b5a7dc0e\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:37:44.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2rl7z" for this suite.
Mar  4 23:38:08.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:38:08.907: INFO: namespace: e2e-tests-kubectl-2rl7z, resource: bindings, ignored listing per whitelist
Mar  4 23:38:09.004: INFO: namespace e2e-tests-kubectl-2rl7z deletion completed in 24.634344796s

• [SLOW TEST:28.386 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:38:09.005: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-6g5sl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-tn7d
STEP: Creating a pod to test atomic-volume-subpath
Mar  4 23:38:09.303: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-tn7d" in namespace "e2e-tests-subpath-6g5sl" to be "success or failure"
Mar  4 23:38:09.308: INFO: Pod "pod-subpath-test-downwardapi-tn7d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.573448ms
Mar  4 23:38:11.313: INFO: Pod "pod-subpath-test-downwardapi-tn7d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010230383s
Mar  4 23:38:13.319: INFO: Pod "pod-subpath-test-downwardapi-tn7d": Phase="Running", Reason="", readiness=false. Elapsed: 4.016110276s
Mar  4 23:38:15.325: INFO: Pod "pod-subpath-test-downwardapi-tn7d": Phase="Running", Reason="", readiness=false. Elapsed: 6.02225533s
Mar  4 23:38:17.331: INFO: Pod "pod-subpath-test-downwardapi-tn7d": Phase="Running", Reason="", readiness=false. Elapsed: 8.028224622s
Mar  4 23:38:19.337: INFO: Pod "pod-subpath-test-downwardapi-tn7d": Phase="Running", Reason="", readiness=false. Elapsed: 10.034052151s
Mar  4 23:38:21.344: INFO: Pod "pod-subpath-test-downwardapi-tn7d": Phase="Running", Reason="", readiness=false. Elapsed: 12.040671235s
Mar  4 23:38:23.349: INFO: Pod "pod-subpath-test-downwardapi-tn7d": Phase="Running", Reason="", readiness=false. Elapsed: 14.046287535s
Mar  4 23:38:25.355: INFO: Pod "pod-subpath-test-downwardapi-tn7d": Phase="Running", Reason="", readiness=false. Elapsed: 16.052218372s
Mar  4 23:38:27.362: INFO: Pod "pod-subpath-test-downwardapi-tn7d": Phase="Running", Reason="", readiness=false. Elapsed: 18.058652907s
Mar  4 23:38:29.367: INFO: Pod "pod-subpath-test-downwardapi-tn7d": Phase="Running", Reason="", readiness=false. Elapsed: 20.064399672s
Mar  4 23:38:31.374: INFO: Pod "pod-subpath-test-downwardapi-tn7d": Phase="Running", Reason="", readiness=false. Elapsed: 22.070698374s
Mar  4 23:38:33.380: INFO: Pod "pod-subpath-test-downwardapi-tn7d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.076767765s
STEP: Saw pod success
Mar  4 23:38:33.380: INFO: Pod "pod-subpath-test-downwardapi-tn7d" satisfied condition "success or failure"
Mar  4 23:38:33.384: INFO: Trying to get logs from node 10.190.208.160 pod pod-subpath-test-downwardapi-tn7d container test-container-subpath-downwardapi-tn7d: <nil>
STEP: delete the pod
Mar  4 23:38:33.418: INFO: Waiting for pod pod-subpath-test-downwardapi-tn7d to disappear
Mar  4 23:38:33.423: INFO: Pod pod-subpath-test-downwardapi-tn7d no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-tn7d
Mar  4 23:38:33.423: INFO: Deleting pod "pod-subpath-test-downwardapi-tn7d" in namespace "e2e-tests-subpath-6g5sl"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:38:33.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-6g5sl" for this suite.
Mar  4 23:38:39.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:38:39.659: INFO: namespace: e2e-tests-subpath-6g5sl, resource: bindings, ignored listing per whitelist
Mar  4 23:38:39.787: INFO: namespace e2e-tests-subpath-6g5sl deletion completed in 6.303584743s

• [SLOW TEST:30.782 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:38:39.787: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-bl2fs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Mar  4 23:38:42.098: INFO: Pod pod-hostip-a39a132e-3ed6-11e9-b56c-8631b5a7dc0e has hostIP: 10.190.208.160
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:38:42.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-bl2fs" for this suite.
Mar  4 23:39:04.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:39:04.310: INFO: namespace: e2e-tests-pods-bl2fs, resource: bindings, ignored listing per whitelist
Mar  4 23:39:04.403: INFO: namespace e2e-tests-pods-bl2fs deletion completed in 22.293224458s

• [SLOW TEST:24.616 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:39:04.403: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-n48ns
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Mar  4 23:39:04.655: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-n48ns" to be "success or failure"
Mar  4 23:39:04.660: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.41939ms
Mar  4 23:39:06.665: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009894916s
STEP: Saw pod success
Mar  4 23:39:06.665: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Mar  4 23:39:06.670: INFO: Trying to get logs from node 10.190.208.162 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Mar  4 23:39:06.700: INFO: Waiting for pod pod-host-path-test to disappear
Mar  4 23:39:06.783: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:39:06.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-n48ns" for this suite.
Mar  4 23:39:12.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:39:13.017: INFO: namespace: e2e-tests-hostpath-n48ns, resource: bindings, ignored listing per whitelist
Mar  4 23:39:13.117: INFO: namespace e2e-tests-hostpath-n48ns deletion completed in 6.321098046s

• [SLOW TEST:8.714 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:39:13.119: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-gzr6l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Mar  4 23:39:13.683: INFO: namespace e2e-tests-kubectl-gzr6l
Mar  4 23:39:13.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 create -f - --namespace=e2e-tests-kubectl-gzr6l'
Mar  4 23:39:13.972: INFO: stderr: ""
Mar  4 23:39:13.972: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar  4 23:39:14.978: INFO: Selector matched 1 pods for map[app:redis]
Mar  4 23:39:14.978: INFO: Found 0 / 1
Mar  4 23:39:15.978: INFO: Selector matched 1 pods for map[app:redis]
Mar  4 23:39:15.978: INFO: Found 1 / 1
Mar  4 23:39:15.978: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar  4 23:39:15.982: INFO: Selector matched 1 pods for map[app:redis]
Mar  4 23:39:15.982: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar  4 23:39:15.982: INFO: wait on redis-master startup in e2e-tests-kubectl-gzr6l 
Mar  4 23:39:15.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 logs redis-master-xbfgz redis-master --namespace=e2e-tests-kubectl-gzr6l'
Mar  4 23:39:16.130: INFO: stderr: ""
Mar  4 23:39:16.130: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 04 Mar 23:39:14.966 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 04 Mar 23:39:14.966 # Server started, Redis version 3.2.12\n1:M 04 Mar 23:39:14.966 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 04 Mar 23:39:14.966 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Mar  4 23:39:16.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-gzr6l'
Mar  4 23:39:16.317: INFO: stderr: ""
Mar  4 23:39:16.317: INFO: stdout: "service/rm2 exposed\n"
Mar  4 23:39:16.324: INFO: Service rm2 in namespace e2e-tests-kubectl-gzr6l found.
STEP: exposing service
Mar  4 23:39:18.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-126132266 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-gzr6l'
Mar  4 23:39:18.497: INFO: stderr: ""
Mar  4 23:39:18.497: INFO: stdout: "service/rm3 exposed\n"
Mar  4 23:39:18.583: INFO: Service rm3 in namespace e2e-tests-kubectl-gzr6l found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:39:20.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gzr6l" for this suite.
Mar  4 23:39:44.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:39:44.806: INFO: namespace: e2e-tests-kubectl-gzr6l, resource: bindings, ignored listing per whitelist
Mar  4 23:39:44.920: INFO: namespace e2e-tests-kubectl-gzr6l deletion completed in 24.31067283s

• [SLOW TEST:31.801 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:39:44.920: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-f96lm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Mar  4 23:39:45.150: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-126132266 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:39:45.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-f96lm" for this suite.
Mar  4 23:39:51.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:39:51.358: INFO: namespace: e2e-tests-kubectl-f96lm, resource: bindings, ignored listing per whitelist
Mar  4 23:39:51.599: INFO: namespace e2e-tests-kubectl-f96lm deletion completed in 6.332888252s

• [SLOW TEST:6.679 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:39:51.600: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-qs487
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-ce66ca70-3ed6-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume secrets
Mar  4 23:39:51.844: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ce67c27b-3ed6-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-projected-qs487" to be "success or failure"
Mar  4 23:39:51.849: INFO: Pod "pod-projected-secrets-ce67c27b-3ed6-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.956761ms
Mar  4 23:39:53.854: INFO: Pod "pod-projected-secrets-ce67c27b-3ed6-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010713449s
STEP: Saw pod success
Mar  4 23:39:53.854: INFO: Pod "pod-projected-secrets-ce67c27b-3ed6-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 23:39:53.859: INFO: Trying to get logs from node 10.190.208.160 pod pod-projected-secrets-ce67c27b-3ed6-11e9-b56c-8631b5a7dc0e container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  4 23:39:53.896: INFO: Waiting for pod pod-projected-secrets-ce67c27b-3ed6-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 23:39:53.900: INFO: Pod pod-projected-secrets-ce67c27b-3ed6-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:39:53.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qs487" for this suite.
Mar  4 23:39:59.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:40:00.208: INFO: namespace: e2e-tests-projected-qs487, resource: bindings, ignored listing per whitelist
Mar  4 23:40:00.456: INFO: namespace e2e-tests-projected-qs487 deletion completed in 6.54597181s

• [SLOW TEST:8.856 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:40:00.458: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-rl5xl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-d3b04933-3ed6-11e9-b56c-8631b5a7dc0e
STEP: Creating a pod to test consume secrets
Mar  4 23:40:00.798: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d3be2b3b-3ed6-11e9-b56c-8631b5a7dc0e" in namespace "e2e-tests-projected-rl5xl" to be "success or failure"
Mar  4 23:40:00.803: INFO: Pod "pod-projected-secrets-d3be2b3b-3ed6-11e9-b56c-8631b5a7dc0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.376656ms
Mar  4 23:40:02.808: INFO: Pod "pod-projected-secrets-d3be2b3b-3ed6-11e9-b56c-8631b5a7dc0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010008123s
STEP: Saw pod success
Mar  4 23:40:02.809: INFO: Pod "pod-projected-secrets-d3be2b3b-3ed6-11e9-b56c-8631b5a7dc0e" satisfied condition "success or failure"
Mar  4 23:40:02.814: INFO: Trying to get logs from node 10.190.208.160 pod pod-projected-secrets-d3be2b3b-3ed6-11e9-b56c-8631b5a7dc0e container secret-volume-test: <nil>
STEP: delete the pod
Mar  4 23:40:02.882: INFO: Waiting for pod pod-projected-secrets-d3be2b3b-3ed6-11e9-b56c-8631b5a7dc0e to disappear
Mar  4 23:40:02.888: INFO: Pod pod-projected-secrets-d3be2b3b-3ed6-11e9-b56c-8631b5a7dc0e no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:40:02.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rl5xl" for this suite.
Mar  4 23:40:08.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:40:09.144: INFO: namespace: e2e-tests-projected-rl5xl, resource: bindings, ignored listing per whitelist
Mar  4 23:40:09.197: INFO: namespace e2e-tests-projected-rl5xl deletion completed in 6.298784355s

• [SLOW TEST:8.739 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:40:09.197: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-h22tj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Mar  4 23:40:09.558: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  4 23:40:09.577: INFO: Waiting for terminating namespaces to be deleted...
Mar  4 23:40:09.586: INFO: 
Logging pods the kubelet thinks is on node 10.190.208.160 before test
Mar  4 23:40:09.608: INFO: ibm-master-proxy-static-10.190.208.160 from kube-system started at <nil> (0 container statuses recorded)
Mar  4 23:40:09.608: INFO: sonobuoy-systemd-logs-daemon-set-96866c1b23744a30-zggp2 from heptio-sonobuoy started at 2019-03-04 22:09:43 +0000 UTC (2 container statuses recorded)
Mar  4 23:40:09.608: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Mar  4 23:40:09.608: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar  4 23:40:09.608: INFO: calico-kube-controllers-5c699798bc-n5qdk from kube-system started at 2019-03-04 21:29:15 +0000 UTC (1 container statuses recorded)
Mar  4 23:40:09.609: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Mar  4 23:40:09.609: INFO: calico-node-jxfjl from kube-system started at 2019-03-04 21:29:15 +0000 UTC (2 container statuses recorded)
Mar  4 23:40:09.609: INFO: 	Container calico-node ready: true, restart count 0
Mar  4 23:40:09.609: INFO: 	Container install-cni ready: true, restart count 0
Mar  4 23:40:09.609: INFO: ibm-file-plugin-586bb8bf84-dqlk6 from kube-system started at 2019-03-04 21:29:35 +0000 UTC (1 container statuses recorded)
Mar  4 23:40:09.609: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Mar  4 23:40:09.609: INFO: kube-dns-amd64-fcdcf59c5-kqdfx from kube-system started at 2019-03-04 21:29:35 +0000 UTC (3 container statuses recorded)
Mar  4 23:40:09.609: INFO: 	Container dnsmasq ready: true, restart count 0
Mar  4 23:40:09.609: INFO: 	Container kubedns ready: true, restart count 0
Mar  4 23:40:09.609: INFO: 	Container sidecar ready: true, restart count 0
Mar  4 23:40:09.609: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-04 22:09:39 +0000 UTC (1 container statuses recorded)
Mar  4 23:40:09.609: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar  4 23:40:09.609: INFO: ibm-keepalived-watcher-nh5p6 from kube-system started at 2019-03-04 21:29:15 +0000 UTC (1 container statuses recorded)
Mar  4 23:40:09.609: INFO: 	Container keepalived-watcher ready: true, restart count 0
Mar  4 23:40:09.609: INFO: vpn-6c6b45457f-xmlwb from kube-system started at 2019-03-04 21:29:35 +0000 UTC (1 container statuses recorded)
Mar  4 23:40:09.609: INFO: 	Container vpn ready: true, restart count 0
Mar  4 23:40:09.609: INFO: kube-dns-autoscaler-587cd5cd44-8p94v from kube-system started at 2019-03-04 21:29:35 +0000 UTC (1 container statuses recorded)
Mar  4 23:40:09.609: INFO: 	Container autoscaler ready: true, restart count 0
Mar  4 23:40:09.609: INFO: ibm-cloud-provider-ip-169-62-14-102-5c8b94578f-6j5h8 from ibm-system started at 2019-03-04 21:30:11 +0000 UTC (1 container statuses recorded)
Mar  4 23:40:09.609: INFO: 	Container ibm-cloud-provider-ip-169-62-14-102 ready: true, restart count 0
Mar  4 23:40:09.609: INFO: kubernetes-dashboard-b4bc7db5d-47nml from kube-system started at 2019-03-04 21:29:35 +0000 UTC (1 container statuses recorded)
Mar  4 23:40:09.609: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Mar  4 23:40:09.609: INFO: ibm-storage-watcher-54cf447885-vvkrq from kube-system started at 2019-03-04 21:29:35 +0000 UTC (1 container statuses recorded)
Mar  4 23:40:09.609: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Mar  4 23:40:09.609: INFO: ibm-kube-fluentd-xcfn9 from kube-system started at 2019-03-04 21:32:33 +0000 UTC (1 container statuses recorded)
Mar  4 23:40:09.609: INFO: 	Container fluentd ready: true, restart count 0
Mar  4 23:40:09.609: INFO: 
Logging pods the kubelet thinks is on node 10.190.208.162 before test
Mar  4 23:40:09.631: INFO: public-cr4b0320f2477b4ad1a9b3673fb5e37483-alb1-596b8cfb5f-xfbwf from kube-system started at 2019-03-04 21:34:56 +0000 UTC (4 container statuses recorded)
Mar  4 23:40:09.631: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Mar  4 23:40:09.631: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Mar  4 23:40:09.631: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Mar  4 23:40:09.631: INFO: 	Container nginx-ingress ready: true, restart count 0
Mar  4 23:40:09.631: INFO: calico-node-zcgq4 from kube-system started at 2019-03-04 21:30:51 +0000 UTC (2 container statuses recorded)
Mar  4 23:40:09.631: INFO: 	Container calico-node ready: true, restart count 0
Mar  4 23:40:09.631: INFO: 	Container install-cni ready: true, restart count 0
Mar  4 23:40:09.631: INFO: ibm-keepalived-watcher-mw942 from kube-system started at 2019-03-04 21:30:51 +0000 UTC (1 container statuses recorded)
Mar  4 23:40:09.631: INFO: 	Container keepalived-watcher ready: true, restart count 0
Mar  4 23:40:09.631: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-03-04 22:09:33 +0000 UTC (1 container statuses recorded)
Mar  4 23:40:09.631: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Mar  4 23:40:09.631: INFO: sonobuoy-e2e-job-13307d6f62184a08 from heptio-sonobuoy started at 2019-03-04 22:09:43 +0000 UTC (2 container statuses recorded)
Mar  4 23:40:09.631: INFO: 	Container e2e ready: true, restart count 0
Mar  4 23:40:09.631: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  4 23:40:09.631: INFO: sonobuoy-systemd-logs-daemon-set-96866c1b23744a30-86vwv from heptio-sonobuoy started at 2019-03-04 22:09:43 +0000 UTC (2 container statuses recorded)
Mar  4 23:40:09.631: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Mar  4 23:40:09.631: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar  4 23:40:09.631: INFO: ibm-master-proxy-static-10.190.208.162 from kube-system started at <nil> (0 container statuses recorded)
Mar  4 23:40:09.631: INFO: ibm-kube-fluentd-th2p5 from kube-system started at 2019-03-04 21:32:33 +0000 UTC (1 container statuses recorded)
Mar  4 23:40:09.631: INFO: 	Container fluentd ready: true, restart count 0
Mar  4 23:40:09.631: INFO: 
Logging pods the kubelet thinks is on node 10.190.208.178 before test
Mar  4 23:40:09.658: INFO: ibm-master-proxy-static-10.190.208.178 from kube-system started at <nil> (0 container statuses recorded)
Mar  4 23:40:09.658: INFO: ibm-cloud-provider-ip-169-62-14-102-5c8b94578f-k5xwv from ibm-system started at 2019-03-04 21:30:11 +0000 UTC (1 container statuses recorded)
Mar  4 23:40:09.658: INFO: 	Container ibm-cloud-provider-ip-169-62-14-102 ready: true, restart count 0
Mar  4 23:40:09.658: INFO: ibm-kube-fluentd-9dt4m from kube-system started at 2019-03-04 21:32:33 +0000 UTC (1 container statuses recorded)
Mar  4 23:40:09.658: INFO: 	Container fluentd ready: true, restart count 0
Mar  4 23:40:09.658: INFO: public-cr4b0320f2477b4ad1a9b3673fb5e37483-alb1-596b8cfb5f-trd2m from kube-system started at 2019-03-04 21:34:56 +0000 UTC (4 container statuses recorded)
Mar  4 23:40:09.658: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Mar  4 23:40:09.658: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Mar  4 23:40:09.658: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Mar  4 23:40:09.658: INFO: 	Container nginx-ingress ready: true, restart count 0
Mar  4 23:40:09.658: INFO: metrics-server-6db7656f6c-wm6gm from kube-system started at 2019-03-04 21:29:54 +0000 UTC (2 container statuses recorded)
Mar  4 23:40:09.658: INFO: 	Container metrics-server ready: true, restart count 0
Mar  4 23:40:09.658: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Mar  4 23:40:09.658: INFO: calico-node-7g6nw from kube-system started at 2019-03-04 21:29:37 +0000 UTC (2 container statuses recorded)
Mar  4 23:40:09.658: INFO: 	Container calico-node ready: true, restart count 0
Mar  4 23:40:09.658: INFO: 	Container install-cni ready: true, restart count 0
Mar  4 23:40:09.658: INFO: kube-dns-amd64-fcdcf59c5-tldtv from kube-system started at 2019-03-04 21:29:47 +0000 UTC (3 container statuses recorded)
Mar  4 23:40:09.658: INFO: 	Container dnsmasq ready: true, restart count 0
Mar  4 23:40:09.658: INFO: 	Container kubedns ready: true, restart count 0
Mar  4 23:40:09.658: INFO: 	Container sidecar ready: true, restart count 0
Mar  4 23:40:09.658: INFO: ibm-keepalived-watcher-fqsjb from kube-system started at 2019-03-04 21:29:37 +0000 UTC (1 container statuses recorded)
Mar  4 23:40:09.658: INFO: 	Container keepalived-watcher ready: true, restart count 0
Mar  4 23:40:09.658: INFO: sonobuoy-systemd-logs-daemon-set-96866c1b23744a30-mlqpv from heptio-sonobuoy started at 2019-03-04 22:09:43 +0000 UTC (2 container statuses recorded)
Mar  4 23:40:09.658: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Mar  4 23:40:09.658: INFO: 	Container sonobuoy-worker ready: true, restart count 1
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1588e5dd2a795c40], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:40:10.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-h22tj" for this suite.
Mar  4 23:40:16.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:40:17.018: INFO: namespace: e2e-tests-sched-pred-h22tj, resource: bindings, ignored listing per whitelist
Mar  4 23:40:17.148: INFO: namespace e2e-tests-sched-pred-h22tj deletion completed in 6.365186727s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:7.951 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:40:17.148: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-rqkhv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:40:17.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-rqkhv" for this suite.
Mar  4 23:40:23.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:40:23.571: INFO: namespace: e2e-tests-services-rqkhv, resource: bindings, ignored listing per whitelist
Mar  4 23:40:23.827: INFO: namespace e2e-tests-services-rqkhv deletion completed in 6.426203292s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.679 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:40:23.828: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-6vbqh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  4 23:40:24.206: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Mar  4 23:40:24.216: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-6vbqh/daemonsets","resourceVersion":"29398"},"items":null}

Mar  4 23:40:24.221: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-6vbqh/pods","resourceVersion":"29398"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:40:24.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-6vbqh" for this suite.
Mar  4 23:40:30.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:40:30.709: INFO: namespace: e2e-tests-daemonsets-6vbqh, resource: bindings, ignored listing per whitelist
Mar  4 23:40:30.767: INFO: namespace e2e-tests-daemonsets-6vbqh deletion completed in 6.504378485s

S [SKIPPING] [6.939 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Mar  4 23:40:24.206: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  4 23:40:30.767: INFO: >>> kubeConfig: /tmp/kubeconfig-126132266
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-9szft
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar  4 23:40:33.561: INFO: Successfully updated pod "annotationupdatee5c04069-3ed6-11e9-b56c-8631b5a7dc0e"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  4 23:40:35.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9szft" for this suite.
Mar  4 23:41:07.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  4 23:41:07.724: INFO: namespace: e2e-tests-downward-api-9szft, resource: bindings, ignored listing per whitelist
Mar  4 23:41:07.902: INFO: namespace e2e-tests-downward-api-9szft deletion completed in 32.296091938s

• [SLOW TEST:37.135 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSMar  4 23:41:07.903: INFO: Running AfterSuite actions on all node
Mar  4 23:41:07.903: INFO: Running AfterSuite actions on node 1
Mar  4 23:41:07.903: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 5458.930 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 1h31m0.064277282s
Test Suite Passed
