Mar 19 09:59:47.140: INFO: Overriding default scale value of zero to 1
Mar 19 09:59:47.140: INFO: Overriding default milliseconds value of zero to 5000
I0319 09:59:47.470606      17 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-715664315
I0319 09:59:47.470685      17 e2e.go:304] Starting e2e run "ba44dd46-4a2d-11e9-989b-da33bd6188b3" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1552989586 - Will randomize all specs
Will run 188 of 1814 specs

Mar 19 09:59:47.563: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
Mar 19 09:59:47.564: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Mar 19 09:59:47.574: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Mar 19 09:59:47.608: INFO: 9 / 9 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Mar 19 09:59:47.608: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Mar 19 09:59:47.608: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Mar 19 09:59:47.614: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'jdcloud-k8s-ipamd' (0 seconds elapsed)
Mar 19 09:59:47.614: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Mar 19 09:59:47.614: INFO: e2e test version: v1.12.1
Mar 19 09:59:47.614: INFO: kube-apiserver version: v1.12.3-23.56f6f14
SSS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 09:59:47.615: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename downward-api
Mar 19 09:59:47.705: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 19 09:59:47.719: INFO: Waiting up to 5m0s for pod "downward-api-baa7ea9c-4a2d-11e9-989b-da33bd6188b3" in namespace "e2e-tests-downward-api-ddgwk" to be "success or failure"
Mar 19 09:59:47.727: INFO: Pod "downward-api-baa7ea9c-4a2d-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.681332ms
Mar 19 09:59:49.733: INFO: Pod "downward-api-baa7ea9c-4a2d-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013368097s
STEP: Saw pod success
Mar 19 09:59:49.733: INFO: Pod "downward-api-baa7ea9c-4a2d-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 09:59:49.738: INFO: Trying to get logs from node k8s-node-vmwvcc-lkllt8nnod pod downward-api-baa7ea9c-4a2d-11e9-989b-da33bd6188b3 container dapi-container: <nil>
STEP: delete the pod
Mar 19 09:59:49.775: INFO: Waiting for pod downward-api-baa7ea9c-4a2d-11e9-989b-da33bd6188b3 to disappear
Mar 19 09:59:49.780: INFO: Pod downward-api-baa7ea9c-4a2d-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 09:59:49.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ddgwk" for this suite.
Mar 19 09:59:55.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 09:59:55.903: INFO: namespace: e2e-tests-downward-api-ddgwk, resource: bindings, ignored listing per whitelist
Mar 19 09:59:55.997: INFO: namespace e2e-tests-downward-api-ddgwk deletion completed in 6.207547022s

• [SLOW TEST:8.383 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 09:59:55.997: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-t459w
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Mar 19 09:59:56.101: INFO: Found 0 stateful pods, waiting for 3
Mar 19 10:00:06.107: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 19 10:00:06.107: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 19 10:00:06.107: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar 19 10:00:06.139: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Mar 19 10:00:16.173: INFO: Updating stateful set ss2
Mar 19 10:00:16.182: INFO: Waiting for Pod e2e-tests-statefulset-t459w/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Mar 19 10:00:26.257: INFO: Found 2 stateful pods, waiting for 3
Mar 19 10:00:36.263: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 19 10:00:36.263: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 19 10:00:36.263: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Mar 19 10:00:36.289: INFO: Updating stateful set ss2
Mar 19 10:00:36.298: INFO: Waiting for Pod e2e-tests-statefulset-t459w/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 19 10:00:46.324: INFO: Updating stateful set ss2
Mar 19 10:00:46.333: INFO: Waiting for StatefulSet e2e-tests-statefulset-t459w/ss2 to complete update
Mar 19 10:00:46.333: INFO: Waiting for Pod e2e-tests-statefulset-t459w/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 19 10:00:56.345: INFO: Deleting all statefulset in ns e2e-tests-statefulset-t459w
Mar 19 10:00:56.348: INFO: Scaling statefulset ss2 to 0
Mar 19 10:01:06.366: INFO: Waiting for statefulset status.replicas updated to 0
Mar 19 10:01:06.370: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:01:06.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-t459w" for this suite.
Mar 19 10:01:14.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:01:14.549: INFO: namespace: e2e-tests-statefulset-t459w, resource: bindings, ignored listing per whitelist
Mar 19 10:01:14.615: INFO: namespace e2e-tests-statefulset-t459w deletion completed in 8.213315506s

• [SLOW TEST:78.618 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:01:14.616: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 19 10:01:14.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-r2bsw'
Mar 19 10:01:15.042: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar 19 10:01:15.042: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Mar 19 10:01:15.050: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Mar 19 10:01:15.068: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Mar 19 10:01:15.093: INFO: scanned /root for discovery docs: <nil>
Mar 19 10:01:15.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-r2bsw'
Mar 19 10:01:30.973: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar 19 10:01:30.973: INFO: stdout: "Created e2e-test-nginx-rc-e3526b4ec77a3eb8bbfd7719302bc16e\nScaling up e2e-test-nginx-rc-e3526b4ec77a3eb8bbfd7719302bc16e from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-e3526b4ec77a3eb8bbfd7719302bc16e up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-e3526b4ec77a3eb8bbfd7719302bc16e to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Mar 19 10:01:30.973: INFO: stdout: "Created e2e-test-nginx-rc-e3526b4ec77a3eb8bbfd7719302bc16e\nScaling up e2e-test-nginx-rc-e3526b4ec77a3eb8bbfd7719302bc16e from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-e3526b4ec77a3eb8bbfd7719302bc16e up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-e3526b4ec77a3eb8bbfd7719302bc16e to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Mar 19 10:01:30.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-r2bsw'
Mar 19 10:01:31.043: INFO: stderr: ""
Mar 19 10:01:31.043: INFO: stdout: "e2e-test-nginx-rc-e3526b4ec77a3eb8bbfd7719302bc16e-jzhrp "
Mar 19 10:01:31.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods e2e-test-nginx-rc-e3526b4ec77a3eb8bbfd7719302bc16e-jzhrp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r2bsw'
Mar 19 10:01:31.127: INFO: stderr: ""
Mar 19 10:01:31.127: INFO: stdout: "true"
Mar 19 10:01:31.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods e2e-test-nginx-rc-e3526b4ec77a3eb8bbfd7719302bc16e-jzhrp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r2bsw'
Mar 19 10:01:31.193: INFO: stderr: ""
Mar 19 10:01:31.193: INFO: stdout: "nginx:1.14-alpine"
Mar 19 10:01:31.193: INFO: e2e-test-nginx-rc-e3526b4ec77a3eb8bbfd7719302bc16e-jzhrp is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Mar 19 10:01:31.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-r2bsw'
Mar 19 10:01:31.280: INFO: stderr: ""
Mar 19 10:01:31.280: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:01:31.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-r2bsw" for this suite.
Mar 19 10:01:37.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:01:37.446: INFO: namespace: e2e-tests-kubectl-r2bsw, resource: bindings, ignored listing per whitelist
Mar 19 10:01:37.499: INFO: namespace e2e-tests-kubectl-r2bsw deletion completed in 6.206558285s

• [SLOW TEST:22.884 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:01:37.499: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-t7zv7 A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-t7zv7;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-t7zv7 A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-t7zv7;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-t7zv7.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-t7zv7.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-t7zv7.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-t7zv7.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-t7zv7.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-t7zv7.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-t7zv7.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-t7zv7.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-t7zv7.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-t7zv7.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-t7zv7.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-t7zv7.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-t7zv7.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 73.227.16.172.in-addr.arpa. PTR)" && echo OK > /results/172.16.227.73_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 73.227.16.172.in-addr.arpa. PTR)" && echo OK > /results/172.16.227.73_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-t7zv7 A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-t7zv7;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-t7zv7 A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-t7zv7;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-t7zv7.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-t7zv7.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-t7zv7.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-t7zv7.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-t7zv7.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-t7zv7.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-t7zv7.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-t7zv7.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-t7zv7.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-t7zv7.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-t7zv7.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-t7zv7.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-t7zv7.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 73.227.16.172.in-addr.arpa. PTR)" && echo OK > /results/172.16.227.73_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 73.227.16.172.in-addr.arpa. PTR)" && echo OK > /results/172.16.227.73_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 19 10:01:49.670: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-t7zv7/dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3: the server could not find the requested resource (get pods dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3)
Mar 19 10:01:49.681: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-t7zv7 from pod e2e-tests-dns-t7zv7/dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3: the server could not find the requested resource (get pods dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3)
Mar 19 10:01:49.691: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-t7zv7.svc from pod e2e-tests-dns-t7zv7/dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3: the server could not find the requested resource (get pods dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3)
Mar 19 10:01:49.737: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-t7zv7/dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3: the server could not find the requested resource (get pods dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3)
Mar 19 10:01:49.742: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-t7zv7/dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3: the server could not find the requested resource (get pods dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3)
Mar 19 10:01:49.747: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-t7zv7 from pod e2e-tests-dns-t7zv7/dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3: the server could not find the requested resource (get pods dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3)
Mar 19 10:01:49.752: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-t7zv7 from pod e2e-tests-dns-t7zv7/dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3: the server could not find the requested resource (get pods dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3)
Mar 19 10:01:49.757: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-t7zv7.svc from pod e2e-tests-dns-t7zv7/dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3: the server could not find the requested resource (get pods dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3)
Mar 19 10:01:49.762: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-t7zv7.svc from pod e2e-tests-dns-t7zv7/dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3: the server could not find the requested resource (get pods dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3)
Mar 19 10:01:49.803: INFO: Lookups using e2e-tests-dns-t7zv7/dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3 failed for: [wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-t7zv7 wheezy_tcp@dns-test-service.e2e-tests-dns-t7zv7.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-t7zv7 jessie_tcp@dns-test-service.e2e-tests-dns-t7zv7 jessie_udp@dns-test-service.e2e-tests-dns-t7zv7.svc jessie_tcp@dns-test-service.e2e-tests-dns-t7zv7.svc]

Mar 19 10:01:59.669: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-t7zv7/dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3: the server could not find the requested resource (get pods dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3)
Mar 19 10:01:59.679: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-t7zv7 from pod e2e-tests-dns-t7zv7/dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3: the server could not find the requested resource (get pods dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3)
Mar 19 10:01:59.689: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-t7zv7.svc from pod e2e-tests-dns-t7zv7/dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3: the server could not find the requested resource (get pods dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3)
Mar 19 10:01:59.735: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-t7zv7/dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3: the server could not find the requested resource (get pods dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3)
Mar 19 10:01:59.740: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-t7zv7/dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3: the server could not find the requested resource (get pods dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3)
Mar 19 10:01:59.745: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-t7zv7 from pod e2e-tests-dns-t7zv7/dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3: the server could not find the requested resource (get pods dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3)
Mar 19 10:01:59.750: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-t7zv7 from pod e2e-tests-dns-t7zv7/dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3: the server could not find the requested resource (get pods dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3)
Mar 19 10:01:59.755: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-t7zv7.svc from pod e2e-tests-dns-t7zv7/dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3: the server could not find the requested resource (get pods dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3)
Mar 19 10:01:59.760: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-t7zv7.svc from pod e2e-tests-dns-t7zv7/dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3: the server could not find the requested resource (get pods dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3)
Mar 19 10:01:59.800: INFO: Lookups using e2e-tests-dns-t7zv7/dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3 failed for: [wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-t7zv7 wheezy_tcp@dns-test-service.e2e-tests-dns-t7zv7.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-t7zv7 jessie_tcp@dns-test-service.e2e-tests-dns-t7zv7 jessie_udp@dns-test-service.e2e-tests-dns-t7zv7.svc jessie_tcp@dns-test-service.e2e-tests-dns-t7zv7.svc]

Mar 19 10:02:09.803: INFO: DNS probes using e2e-tests-dns-t7zv7/dns-test-fc2bf77b-4a2d-11e9-989b-da33bd6188b3 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:02:09.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-t7zv7" for this suite.
Mar 19 10:02:15.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:02:16.004: INFO: namespace: e2e-tests-dns-t7zv7, resource: bindings, ignored listing per whitelist
Mar 19 10:02:16.135: INFO: namespace e2e-tests-dns-t7zv7 deletion completed in 6.208460722s

• [SLOW TEST:38.636 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:02:16.135: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 10:02:16.239: INFO: Waiting up to 5m0s for pod "downwardapi-volume-132e4d00-4a2e-11e9-989b-da33bd6188b3" in namespace "e2e-tests-projected-s6t65" to be "success or failure"
Mar 19 10:02:16.244: INFO: Pod "downwardapi-volume-132e4d00-4a2e-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.713514ms
Mar 19 10:02:18.250: INFO: Pod "downwardapi-volume-132e4d00-4a2e-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010516627s
STEP: Saw pod success
Mar 19 10:02:18.250: INFO: Pod "downwardapi-volume-132e4d00-4a2e-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:02:18.254: INFO: Trying to get logs from node k8s-node-vmwvcc-lkllt8nnod pod downwardapi-volume-132e4d00-4a2e-11e9-989b-da33bd6188b3 container client-container: <nil>
STEP: delete the pod
Mar 19 10:02:18.294: INFO: Waiting for pod downwardapi-volume-132e4d00-4a2e-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:02:18.298: INFO: Pod downwardapi-volume-132e4d00-4a2e-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:02:18.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-s6t65" for this suite.
Mar 19 10:02:24.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:02:24.446: INFO: namespace: e2e-tests-projected-s6t65, resource: bindings, ignored listing per whitelist
Mar 19 10:02:24.515: INFO: namespace e2e-tests-projected-s6t65 deletion completed in 6.206312522s

• [SLOW TEST:8.379 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:02:24.515: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-182b6995-4a2e-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume configMaps
Mar 19 10:02:24.619: INFO: Waiting up to 5m0s for pod "pod-configmaps-182cc6c7-4a2e-11e9-989b-da33bd6188b3" in namespace "e2e-tests-configmap-wj9w2" to be "success or failure"
Mar 19 10:02:24.625: INFO: Pod "pod-configmaps-182cc6c7-4a2e-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.184698ms
Mar 19 10:02:26.631: INFO: Pod "pod-configmaps-182cc6c7-4a2e-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011591776s
STEP: Saw pod success
Mar 19 10:02:26.631: INFO: Pod "pod-configmaps-182cc6c7-4a2e-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:02:26.636: INFO: Trying to get logs from node k8s-node-vm1y1w-lkllt8nnod pod pod-configmaps-182cc6c7-4a2e-11e9-989b-da33bd6188b3 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 19 10:02:26.674: INFO: Waiting for pod pod-configmaps-182cc6c7-4a2e-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:02:26.679: INFO: Pod pod-configmaps-182cc6c7-4a2e-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:02:26.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wj9w2" for this suite.
Mar 19 10:02:32.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:02:32.798: INFO: namespace: e2e-tests-configmap-wj9w2, resource: bindings, ignored listing per whitelist
Mar 19 10:02:32.890: INFO: namespace e2e-tests-configmap-wj9w2 deletion completed in 6.202342953s

• [SLOW TEST:8.376 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:02:32.891: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 10:02:32.981: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:02:34.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-578zq" for this suite.
Mar 19 10:02:40.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:02:40.234: INFO: namespace: e2e-tests-custom-resource-definition-578zq, resource: bindings, ignored listing per whitelist
Mar 19 10:02:40.253: INFO: namespace e2e-tests-custom-resource-definition-578zq deletion completed in 6.212146271s

• [SLOW TEST:7.363 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:02:40.253: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Mar 19 10:02:40.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 create -f - --namespace=e2e-tests-kubectl-gptgt'
Mar 19 10:02:40.550: INFO: stderr: ""
Mar 19 10:02:40.550: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 19 10:02:40.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gptgt'
Mar 19 10:02:40.634: INFO: stderr: ""
Mar 19 10:02:40.634: INFO: stdout: "update-demo-nautilus-4f9h8 update-demo-nautilus-cnhnt "
Mar 19 10:02:40.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods update-demo-nautilus-4f9h8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gptgt'
Mar 19 10:02:40.698: INFO: stderr: ""
Mar 19 10:02:40.698: INFO: stdout: ""
Mar 19 10:02:40.698: INFO: update-demo-nautilus-4f9h8 is created but not running
Mar 19 10:02:45.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gptgt'
Mar 19 10:02:45.779: INFO: stderr: ""
Mar 19 10:02:45.779: INFO: stdout: "update-demo-nautilus-4f9h8 update-demo-nautilus-cnhnt "
Mar 19 10:02:45.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods update-demo-nautilus-4f9h8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gptgt'
Mar 19 10:02:45.845: INFO: stderr: ""
Mar 19 10:02:45.846: INFO: stdout: "true"
Mar 19 10:02:45.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods update-demo-nautilus-4f9h8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gptgt'
Mar 19 10:02:45.907: INFO: stderr: ""
Mar 19 10:02:45.907: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 19 10:02:45.907: INFO: validating pod update-demo-nautilus-4f9h8
Mar 19 10:02:45.913: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 19 10:02:45.914: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 19 10:02:45.914: INFO: update-demo-nautilus-4f9h8 is verified up and running
Mar 19 10:02:45.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods update-demo-nautilus-cnhnt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gptgt'
Mar 19 10:02:45.985: INFO: stderr: ""
Mar 19 10:02:45.985: INFO: stdout: "true"
Mar 19 10:02:45.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods update-demo-nautilus-cnhnt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gptgt'
Mar 19 10:02:46.051: INFO: stderr: ""
Mar 19 10:02:46.051: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 19 10:02:46.051: INFO: validating pod update-demo-nautilus-cnhnt
Mar 19 10:02:46.059: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 19 10:02:46.059: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 19 10:02:46.059: INFO: update-demo-nautilus-cnhnt is verified up and running
STEP: scaling down the replication controller
Mar 19 10:02:46.060: INFO: scanned /root for discovery docs: <nil>
Mar 19 10:02:46.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-gptgt'
Mar 19 10:02:47.173: INFO: stderr: ""
Mar 19 10:02:47.173: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 19 10:02:47.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gptgt'
Mar 19 10:02:47.249: INFO: stderr: ""
Mar 19 10:02:47.249: INFO: stdout: "update-demo-nautilus-4f9h8 update-demo-nautilus-cnhnt "
STEP: Replicas for name=update-demo: expected=1 actual=2
Mar 19 10:02:52.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gptgt'
Mar 19 10:02:52.324: INFO: stderr: ""
Mar 19 10:02:52.324: INFO: stdout: "update-demo-nautilus-4f9h8 "
Mar 19 10:02:52.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods update-demo-nautilus-4f9h8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gptgt'
Mar 19 10:02:52.386: INFO: stderr: ""
Mar 19 10:02:52.386: INFO: stdout: "true"
Mar 19 10:02:52.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods update-demo-nautilus-4f9h8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gptgt'
Mar 19 10:02:52.468: INFO: stderr: ""
Mar 19 10:02:52.468: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 19 10:02:52.468: INFO: validating pod update-demo-nautilus-4f9h8
Mar 19 10:02:52.474: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 19 10:02:52.474: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 19 10:02:52.474: INFO: update-demo-nautilus-4f9h8 is verified up and running
STEP: scaling up the replication controller
Mar 19 10:02:52.474: INFO: scanned /root for discovery docs: <nil>
Mar 19 10:02:52.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-gptgt'
Mar 19 10:02:53.589: INFO: stderr: ""
Mar 19 10:02:53.589: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 19 10:02:53.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gptgt'
Mar 19 10:02:53.658: INFO: stderr: ""
Mar 19 10:02:53.658: INFO: stdout: "update-demo-nautilus-4f9h8 update-demo-nautilus-l8d98 "
Mar 19 10:02:53.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods update-demo-nautilus-4f9h8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gptgt'
Mar 19 10:02:53.730: INFO: stderr: ""
Mar 19 10:02:53.730: INFO: stdout: "true"
Mar 19 10:02:53.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods update-demo-nautilus-4f9h8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gptgt'
Mar 19 10:02:53.793: INFO: stderr: ""
Mar 19 10:02:53.793: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 19 10:02:53.793: INFO: validating pod update-demo-nautilus-4f9h8
Mar 19 10:02:53.799: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 19 10:02:53.799: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 19 10:02:53.799: INFO: update-demo-nautilus-4f9h8 is verified up and running
Mar 19 10:02:53.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods update-demo-nautilus-l8d98 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gptgt'
Mar 19 10:02:53.859: INFO: stderr: ""
Mar 19 10:02:53.859: INFO: stdout: "true"
Mar 19 10:02:53.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods update-demo-nautilus-l8d98 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gptgt'
Mar 19 10:02:53.929: INFO: stderr: ""
Mar 19 10:02:53.929: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 19 10:02:53.929: INFO: validating pod update-demo-nautilus-l8d98
Mar 19 10:02:53.939: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 19 10:02:53.939: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 19 10:02:53.939: INFO: update-demo-nautilus-l8d98 is verified up and running
STEP: using delete to clean up resources
Mar 19 10:02:53.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-gptgt'
Mar 19 10:02:54.025: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 19 10:02:54.025: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar 19 10:02:54.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-gptgt'
Mar 19 10:02:54.107: INFO: stderr: "No resources found.\n"
Mar 19 10:02:54.107: INFO: stdout: ""
Mar 19 10:02:54.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods -l name=update-demo --namespace=e2e-tests-kubectl-gptgt -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 19 10:02:54.193: INFO: stderr: ""
Mar 19 10:02:54.193: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:02:54.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gptgt" for this suite.
Mar 19 10:03:16.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:03:16.365: INFO: namespace: e2e-tests-kubectl-gptgt, resource: bindings, ignored listing per whitelist
Mar 19 10:03:16.412: INFO: namespace e2e-tests-kubectl-gptgt deletion completed in 22.209028691s

• [SLOW TEST:36.159 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:03:16.412: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 10:03:16.512: INFO: Waiting up to 5m0s for pod "downwardapi-volume-371af58a-4a2e-11e9-989b-da33bd6188b3" in namespace "e2e-tests-downward-api-7b2fj" to be "success or failure"
Mar 19 10:03:16.517: INFO: Pod "downwardapi-volume-371af58a-4a2e-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.123526ms
Mar 19 10:03:18.523: INFO: Pod "downwardapi-volume-371af58a-4a2e-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010990122s
STEP: Saw pod success
Mar 19 10:03:18.523: INFO: Pod "downwardapi-volume-371af58a-4a2e-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:03:18.528: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod downwardapi-volume-371af58a-4a2e-11e9-989b-da33bd6188b3 container client-container: <nil>
STEP: delete the pod
Mar 19 10:03:18.565: INFO: Waiting for pod downwardapi-volume-371af58a-4a2e-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:03:18.570: INFO: Pod downwardapi-volume-371af58a-4a2e-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:03:18.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7b2fj" for this suite.
Mar 19 10:03:24.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:03:24.641: INFO: namespace: e2e-tests-downward-api-7b2fj, resource: bindings, ignored listing per whitelist
Mar 19 10:03:24.786: INFO: namespace e2e-tests-downward-api-7b2fj deletion completed in 6.204154605s

• [SLOW TEST:8.374 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:03:24.786: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:03:24.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-lpwpw" for this suite.
Mar 19 10:03:30.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:03:30.914: INFO: namespace: e2e-tests-services-lpwpw, resource: bindings, ignored listing per whitelist
Mar 19 10:03:31.089: INFO: namespace e2e-tests-services-lpwpw deletion completed in 6.208923262s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.303 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:03:31.089: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-3fda78ee-4a2e-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume secrets
Mar 19 10:03:31.195: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3fdb92b4-4a2e-11e9-989b-da33bd6188b3" in namespace "e2e-tests-projected-vhrlp" to be "success or failure"
Mar 19 10:03:31.199: INFO: Pod "pod-projected-secrets-3fdb92b4-4a2e-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.547365ms
Mar 19 10:03:33.204: INFO: Pod "pod-projected-secrets-3fdb92b4-4a2e-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009968809s
STEP: Saw pod success
Mar 19 10:03:33.205: INFO: Pod "pod-projected-secrets-3fdb92b4-4a2e-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:03:33.209: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod pod-projected-secrets-3fdb92b4-4a2e-11e9-989b-da33bd6188b3 container secret-volume-test: <nil>
STEP: delete the pod
Mar 19 10:03:33.244: INFO: Waiting for pod pod-projected-secrets-3fdb92b4-4a2e-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:03:33.249: INFO: Pod pod-projected-secrets-3fdb92b4-4a2e-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:03:33.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vhrlp" for this suite.
Mar 19 10:03:39.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:03:39.340: INFO: namespace: e2e-tests-projected-vhrlp, resource: bindings, ignored listing per whitelist
Mar 19 10:03:39.463: INFO: namespace e2e-tests-projected-vhrlp deletion completed in 6.204714707s

• [SLOW TEST:8.374 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:03:39.463: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 19 10:03:44.108: INFO: Successfully updated pod "labelsupdate44d7bc62-4a2e-11e9-989b-da33bd6188b3"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:03:46.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-85twv" for this suite.
Mar 19 10:04:08.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:04:08.284: INFO: namespace: e2e-tests-downward-api-85twv, resource: bindings, ignored listing per whitelist
Mar 19 10:04:08.350: INFO: namespace e2e-tests-downward-api-85twv deletion completed in 22.201103281s

• [SLOW TEST:28.886 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:04:08.350: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0319 10:04:14.501882      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 19 10:04:14.501: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:04:14.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-mg6qw" for this suite.
Mar 19 10:04:20.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:04:20.597: INFO: namespace: e2e-tests-gc-mg6qw, resource: bindings, ignored listing per whitelist
Mar 19 10:04:20.716: INFO: namespace e2e-tests-gc-mg6qw deletion completed in 6.206768568s

• [SLOW TEST:12.366 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:04:20.716: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
Mar 19 10:04:30.160: INFO: error from create uninitialized namespace: Internal error occurred: object deleted while waiting for creation
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:04:46.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-2q72x" for this suite.
Mar 19 10:04:53.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:04:53.055: INFO: namespace: e2e-tests-namespaces-2q72x, resource: bindings, ignored listing per whitelist
Mar 19 10:04:53.207: INFO: namespace e2e-tests-namespaces-2q72x deletion completed in 6.202808899s
STEP: Destroying namespace "e2e-tests-nsdeletetest-47hj8" for this suite.
Mar 19 10:04:53.214: INFO: Namespace e2e-tests-nsdeletetest-47hj8 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-clznj" for this suite.
Mar 19 10:04:59.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:04:59.386: INFO: namespace: e2e-tests-nsdeletetest-clznj, resource: bindings, ignored listing per whitelist
Mar 19 10:04:59.419: INFO: namespace e2e-tests-nsdeletetest-clznj deletion completed in 6.204322001s

• [SLOW TEST:38.703 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:04:59.419: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-74830ed2-4a2e-11e9-989b-da33bd6188b3
STEP: Creating secret with name s-test-opt-upd-74830f56-4a2e-11e9-989b-da33bd6188b3
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-74830ed2-4a2e-11e9-989b-da33bd6188b3
STEP: Updating secret s-test-opt-upd-74830f56-4a2e-11e9-989b-da33bd6188b3
STEP: Creating secret with name s-test-opt-create-74830f69-4a2e-11e9-989b-da33bd6188b3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:05:03.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mrtkw" for this suite.
Mar 19 10:05:25.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:05:25.816: INFO: namespace: e2e-tests-projected-mrtkw, resource: bindings, ignored listing per whitelist
Mar 19 10:05:25.915: INFO: namespace e2e-tests-projected-mrtkw deletion completed in 22.204485253s

• [SLOW TEST:26.496 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:05:25.915: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 10:05:26.022: INFO: (0) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 11.26125ms)
Mar 19 10:05:26.032: INFO: (1) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.852023ms)
Mar 19 10:05:26.041: INFO: (2) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.792373ms)
Mar 19 10:05:26.051: INFO: (3) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.773566ms)
Mar 19 10:05:26.061: INFO: (4) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.8648ms)
Mar 19 10:05:26.070: INFO: (5) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.370746ms)
Mar 19 10:05:26.080: INFO: (6) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.698976ms)
Mar 19 10:05:26.090: INFO: (7) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.39168ms)
Mar 19 10:05:26.099: INFO: (8) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.792083ms)
Mar 19 10:05:26.109: INFO: (9) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.546962ms)
Mar 19 10:05:26.118: INFO: (10) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.485452ms)
Mar 19 10:05:26.128: INFO: (11) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.441039ms)
Mar 19 10:05:26.137: INFO: (12) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.284923ms)
Mar 19 10:05:26.147: INFO: (13) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.634197ms)
Mar 19 10:05:26.157: INFO: (14) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.670583ms)
Mar 19 10:05:26.166: INFO: (15) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.657757ms)
Mar 19 10:05:26.177: INFO: (16) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.723568ms)
Mar 19 10:05:26.190: INFO: (17) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 12.601027ms)
Mar 19 10:05:26.202: INFO: (18) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 12.715732ms)
Mar 19 10:05:26.214: INFO: (19) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 11.8598ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:05:26.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-fr4gh" for this suite.
Mar 19 10:05:32.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:05:32.379: INFO: namespace: e2e-tests-proxy-fr4gh, resource: bindings, ignored listing per whitelist
Mar 19 10:05:32.425: INFO: namespace e2e-tests-proxy-fr4gh deletion completed in 6.203518941s

• [SLOW TEST:6.511 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:05:32.425: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar 19 10:05:36.583: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 19 10:05:36.588: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 19 10:05:38.588: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 19 10:05:38.594: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 19 10:05:40.588: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 19 10:05:40.596: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 19 10:05:42.588: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 19 10:05:42.594: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 19 10:05:44.588: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 19 10:05:44.594: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 19 10:05:46.588: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 19 10:05:46.594: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 19 10:05:48.588: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 19 10:05:48.594: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 19 10:05:50.588: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 19 10:05:50.594: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 19 10:05:52.589: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 19 10:05:52.594: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 19 10:05:54.588: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 19 10:05:54.596: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 19 10:05:56.588: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 19 10:05:56.594: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 19 10:05:58.588: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 19 10:05:58.594: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 19 10:06:00.588: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 19 10:06:00.594: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 19 10:06:02.588: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 19 10:06:02.594: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 19 10:06:04.588: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 19 10:06:04.594: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:06:04.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-4xgg5" for this suite.
Mar 19 10:06:26.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:06:26.775: INFO: namespace: e2e-tests-container-lifecycle-hook-4xgg5, resource: bindings, ignored listing per whitelist
Mar 19 10:06:26.813: INFO: namespace e2e-tests-container-lifecycle-hook-4xgg5 deletion completed in 22.208919826s

• [SLOW TEST:54.388 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:06:26.814: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-qdmfs
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-qdmfs
STEP: Deleting pre-stop pod
Mar 19 10:06:35.968: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:06:35.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-qdmfs" for this suite.
Mar 19 10:07:14.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:07:14.158: INFO: namespace: e2e-tests-prestop-qdmfs, resource: bindings, ignored listing per whitelist
Mar 19 10:07:14.208: INFO: namespace e2e-tests-prestop-qdmfs deletion completed in 38.218306139s

• [SLOW TEST:47.394 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:07:14.208: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-c4d792c5-4a2e-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume secrets
Mar 19 10:07:14.313: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c4d88225-4a2e-11e9-989b-da33bd6188b3" in namespace "e2e-tests-projected-swrbp" to be "success or failure"
Mar 19 10:07:14.318: INFO: Pod "pod-projected-secrets-c4d88225-4a2e-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.248336ms
Mar 19 10:07:16.324: INFO: Pod "pod-projected-secrets-c4d88225-4a2e-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011236752s
STEP: Saw pod success
Mar 19 10:07:16.324: INFO: Pod "pod-projected-secrets-c4d88225-4a2e-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:07:16.329: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod pod-projected-secrets-c4d88225-4a2e-11e9-989b-da33bd6188b3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 19 10:07:16.366: INFO: Waiting for pod pod-projected-secrets-c4d88225-4a2e-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:07:16.370: INFO: Pod pod-projected-secrets-c4d88225-4a2e-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:07:16.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-swrbp" for this suite.
Mar 19 10:07:22.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:07:22.451: INFO: namespace: e2e-tests-projected-swrbp, resource: bindings, ignored listing per whitelist
Mar 19 10:07:22.583: INFO: namespace e2e-tests-projected-swrbp deletion completed in 6.203924675s

• [SLOW TEST:8.375 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:07:22.584: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 10:07:22.676: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c9d4b2fc-4a2e-11e9-989b-da33bd6188b3" in namespace "e2e-tests-downward-api-jn8xm" to be "success or failure"
Mar 19 10:07:22.682: INFO: Pod "downwardapi-volume-c9d4b2fc-4a2e-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.022881ms
Mar 19 10:07:24.688: INFO: Pod "downwardapi-volume-c9d4b2fc-4a2e-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011983388s
STEP: Saw pod success
Mar 19 10:07:24.688: INFO: Pod "downwardapi-volume-c9d4b2fc-4a2e-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:07:24.693: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod downwardapi-volume-c9d4b2fc-4a2e-11e9-989b-da33bd6188b3 container client-container: <nil>
STEP: delete the pod
Mar 19 10:07:24.728: INFO: Waiting for pod downwardapi-volume-c9d4b2fc-4a2e-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:07:24.734: INFO: Pod downwardapi-volume-c9d4b2fc-4a2e-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:07:24.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jn8xm" for this suite.
Mar 19 10:07:30.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:07:30.795: INFO: namespace: e2e-tests-downward-api-jn8xm, resource: bindings, ignored listing per whitelist
Mar 19 10:07:30.955: INFO: namespace e2e-tests-downward-api-jn8xm deletion completed in 6.211557962s

• [SLOW TEST:8.372 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:07:30.955: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-ced3d8f0-4a2e-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume configMaps
Mar 19 10:07:31.067: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ced52855-4a2e-11e9-989b-da33bd6188b3" in namespace "e2e-tests-projected-2cggt" to be "success or failure"
Mar 19 10:07:31.072: INFO: Pod "pod-projected-configmaps-ced52855-4a2e-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.948321ms
Mar 19 10:07:33.078: INFO: Pod "pod-projected-configmaps-ced52855-4a2e-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010959577s
Mar 19 10:07:35.084: INFO: Pod "pod-projected-configmaps-ced52855-4a2e-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017116198s
STEP: Saw pod success
Mar 19 10:07:35.084: INFO: Pod "pod-projected-configmaps-ced52855-4a2e-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:07:35.089: INFO: Trying to get logs from node k8s-node-vmwvcc-lkllt8nnod pod pod-projected-configmaps-ced52855-4a2e-11e9-989b-da33bd6188b3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 19 10:07:35.126: INFO: Waiting for pod pod-projected-configmaps-ced52855-4a2e-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:07:35.131: INFO: Pod pod-projected-configmaps-ced52855-4a2e-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:07:35.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2cggt" for this suite.
Mar 19 10:07:41.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:07:41.222: INFO: namespace: e2e-tests-projected-2cggt, resource: bindings, ignored listing per whitelist
Mar 19 10:07:41.344: INFO: namespace e2e-tests-projected-2cggt deletion completed in 6.203601603s

• [SLOW TEST:10.389 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:07:41.345: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 19 10:07:43.987: INFO: Successfully updated pod "labelsupdated504e2c3-4a2e-11e9-989b-da33bd6188b3"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:07:48.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vc2jl" for this suite.
Mar 19 10:08:10.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:08:10.138: INFO: namespace: e2e-tests-projected-vc2jl, resource: bindings, ignored listing per whitelist
Mar 19 10:08:10.243: INFO: namespace e2e-tests-projected-vc2jl deletion completed in 22.205192009s

• [SLOW TEST:28.898 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:08:10.243: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-e63e5ab7-4a2e-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume secrets
Mar 19 10:08:10.355: INFO: Waiting up to 5m0s for pod "pod-secrets-e63f503f-4a2e-11e9-989b-da33bd6188b3" in namespace "e2e-tests-secrets-9lm6m" to be "success or failure"
Mar 19 10:08:10.360: INFO: Pod "pod-secrets-e63f503f-4a2e-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.598288ms
Mar 19 10:08:12.366: INFO: Pod "pod-secrets-e63f503f-4a2e-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010324236s
STEP: Saw pod success
Mar 19 10:08:12.366: INFO: Pod "pod-secrets-e63f503f-4a2e-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:08:12.371: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod pod-secrets-e63f503f-4a2e-11e9-989b-da33bd6188b3 container secret-volume-test: <nil>
STEP: delete the pod
Mar 19 10:08:12.406: INFO: Waiting for pod pod-secrets-e63f503f-4a2e-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:08:12.411: INFO: Pod pod-secrets-e63f503f-4a2e-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:08:12.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9lm6m" for this suite.
Mar 19 10:08:18.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:08:18.550: INFO: namespace: e2e-tests-secrets-9lm6m, resource: bindings, ignored listing per whitelist
Mar 19 10:08:18.623: INFO: namespace e2e-tests-secrets-9lm6m deletion completed in 6.20229691s

• [SLOW TEST:8.380 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:08:18.623: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-4ckcb
I0319 10:08:18.715200      17 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-4ckcb, replica count: 1
I0319 10:08:19.765651      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0319 10:08:20.765894      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 19 10:08:20.884: INFO: Created: latency-svc-nk2vn
Mar 19 10:08:20.899: INFO: Got endpoints: latency-svc-nk2vn [33.459009ms]
Mar 19 10:08:20.922: INFO: Created: latency-svc-sm7xr
Mar 19 10:08:20.937: INFO: Got endpoints: latency-svc-sm7xr [37.56742ms]
Mar 19 10:08:20.946: INFO: Created: latency-svc-rc6qr
Mar 19 10:08:20.954: INFO: Got endpoints: latency-svc-rc6qr [54.641813ms]
Mar 19 10:08:20.971: INFO: Created: latency-svc-2ndcl
Mar 19 10:08:20.983: INFO: Got endpoints: latency-svc-2ndcl [83.324018ms]
Mar 19 10:08:20.988: INFO: Created: latency-svc-sdzns
Mar 19 10:08:20.997: INFO: Got endpoints: latency-svc-sdzns [97.253925ms]
Mar 19 10:08:21.000: INFO: Created: latency-svc-9m8vm
Mar 19 10:08:21.011: INFO: Got endpoints: latency-svc-9m8vm [111.40767ms]
Mar 19 10:08:21.013: INFO: Created: latency-svc-8zhzd
Mar 19 10:08:21.025: INFO: Created: latency-svc-5n2zz
Mar 19 10:08:21.026: INFO: Got endpoints: latency-svc-8zhzd [126.505353ms]
Mar 19 10:08:21.035: INFO: Got endpoints: latency-svc-5n2zz [135.852047ms]
Mar 19 10:08:21.046: INFO: Created: latency-svc-vt2kq
Mar 19 10:08:21.054: INFO: Got endpoints: latency-svc-vt2kq [154.535459ms]
Mar 19 10:08:21.056: INFO: Created: latency-svc-rmqd6
Mar 19 10:08:21.063: INFO: Got endpoints: latency-svc-rmqd6 [163.553791ms]
Mar 19 10:08:21.069: INFO: Created: latency-svc-z2sm6
Mar 19 10:08:21.081: INFO: Got endpoints: latency-svc-z2sm6 [181.736256ms]
Mar 19 10:08:21.085: INFO: Created: latency-svc-hws72
Mar 19 10:08:21.093: INFO: Got endpoints: latency-svc-hws72 [193.740698ms]
Mar 19 10:08:21.096: INFO: Created: latency-svc-2rl8x
Mar 19 10:08:21.107: INFO: Got endpoints: latency-svc-2rl8x [207.131787ms]
Mar 19 10:08:21.111: INFO: Created: latency-svc-29k77
Mar 19 10:08:21.122: INFO: Got endpoints: latency-svc-29k77 [222.498758ms]
Mar 19 10:08:21.124: INFO: Created: latency-svc-vm2vw
Mar 19 10:08:21.133: INFO: Got endpoints: latency-svc-vm2vw [233.804432ms]
Mar 19 10:08:21.143: INFO: Created: latency-svc-qflbm
Mar 19 10:08:21.152: INFO: Got endpoints: latency-svc-qflbm [252.212627ms]
Mar 19 10:08:21.159: INFO: Created: latency-svc-sqdmj
Mar 19 10:08:21.169: INFO: Got endpoints: latency-svc-sqdmj [232.524199ms]
Mar 19 10:08:21.175: INFO: Created: latency-svc-ddl9q
Mar 19 10:08:21.184: INFO: Got endpoints: latency-svc-ddl9q [229.764462ms]
Mar 19 10:08:21.189: INFO: Created: latency-svc-tklws
Mar 19 10:08:21.199: INFO: Got endpoints: latency-svc-tklws [216.949035ms]
Mar 19 10:08:21.202: INFO: Created: latency-svc-scsh2
Mar 19 10:08:21.211: INFO: Got endpoints: latency-svc-scsh2 [214.916046ms]
Mar 19 10:08:21.218: INFO: Created: latency-svc-64prh
Mar 19 10:08:21.226: INFO: Got endpoints: latency-svc-64prh [215.024628ms]
Mar 19 10:08:21.232: INFO: Created: latency-svc-jqfd4
Mar 19 10:08:21.240: INFO: Got endpoints: latency-svc-jqfd4 [213.88895ms]
Mar 19 10:08:21.246: INFO: Created: latency-svc-4mzd9
Mar 19 10:08:21.257: INFO: Got endpoints: latency-svc-4mzd9 [221.331863ms]
Mar 19 10:08:21.258: INFO: Created: latency-svc-tfzp9
Mar 19 10:08:21.269: INFO: Got endpoints: latency-svc-tfzp9 [214.987673ms]
Mar 19 10:08:21.277: INFO: Created: latency-svc-hv445
Mar 19 10:08:21.284: INFO: Got endpoints: latency-svc-hv445 [220.968686ms]
Mar 19 10:08:21.290: INFO: Created: latency-svc-m6bjk
Mar 19 10:08:21.299: INFO: Got endpoints: latency-svc-m6bjk [218.300905ms]
Mar 19 10:08:21.302: INFO: Created: latency-svc-qdfd6
Mar 19 10:08:21.313: INFO: Got endpoints: latency-svc-qdfd6 [219.75024ms]
Mar 19 10:08:21.321: INFO: Created: latency-svc-vnzvw
Mar 19 10:08:21.329: INFO: Got endpoints: latency-svc-vnzvw [222.863783ms]
Mar 19 10:08:21.333: INFO: Created: latency-svc-h9szv
Mar 19 10:08:21.344: INFO: Got endpoints: latency-svc-h9szv [221.57433ms]
Mar 19 10:08:21.350: INFO: Created: latency-svc-zcxqz
Mar 19 10:08:21.359: INFO: Got endpoints: latency-svc-zcxqz [225.35112ms]
Mar 19 10:08:21.362: INFO: Created: latency-svc-slxlw
Mar 19 10:08:21.370: INFO: Got endpoints: latency-svc-slxlw [218.324122ms]
Mar 19 10:08:21.381: INFO: Created: latency-svc-x8k24
Mar 19 10:08:21.393: INFO: Created: latency-svc-zrwmn
Mar 19 10:08:21.393: INFO: Got endpoints: latency-svc-x8k24 [223.772054ms]
Mar 19 10:08:21.402: INFO: Got endpoints: latency-svc-zrwmn [218.284488ms]
Mar 19 10:08:21.404: INFO: Created: latency-svc-kzn4j
Mar 19 10:08:21.414: INFO: Got endpoints: latency-svc-kzn4j [214.143908ms]
Mar 19 10:08:21.416: INFO: Created: latency-svc-ggfhv
Mar 19 10:08:21.426: INFO: Got endpoints: latency-svc-ggfhv [214.094753ms]
Mar 19 10:08:21.430: INFO: Created: latency-svc-wrhl2
Mar 19 10:08:21.445: INFO: Got endpoints: latency-svc-wrhl2 [218.691141ms]
Mar 19 10:08:21.446: INFO: Created: latency-svc-zpc7j
Mar 19 10:08:21.454: INFO: Got endpoints: latency-svc-zpc7j [214.048706ms]
Mar 19 10:08:21.459: INFO: Created: latency-svc-z7wvf
Mar 19 10:08:21.469: INFO: Got endpoints: latency-svc-z7wvf [212.6853ms]
Mar 19 10:08:21.473: INFO: Created: latency-svc-4wpnw
Mar 19 10:08:21.484: INFO: Got endpoints: latency-svc-4wpnw [214.610038ms]
Mar 19 10:08:21.490: INFO: Created: latency-svc-j4znp
Mar 19 10:08:21.500: INFO: Got endpoints: latency-svc-j4znp [216.310798ms]
Mar 19 10:08:21.501: INFO: Created: latency-svc-2dpp2
Mar 19 10:08:21.510: INFO: Got endpoints: latency-svc-2dpp2 [210.636399ms]
Mar 19 10:08:21.516: INFO: Created: latency-svc-xl67p
Mar 19 10:08:21.523: INFO: Got endpoints: latency-svc-xl67p [210.043598ms]
Mar 19 10:08:21.532: INFO: Created: latency-svc-tx2t9
Mar 19 10:08:21.543: INFO: Created: latency-svc-9j7nk
Mar 19 10:08:21.544: INFO: Got endpoints: latency-svc-tx2t9 [214.045998ms]
Mar 19 10:08:21.557: INFO: Created: latency-svc-4jswf
Mar 19 10:08:21.570: INFO: Created: latency-svc-rn9bx
Mar 19 10:08:21.584: INFO: Created: latency-svc-ncrds
Mar 19 10:08:21.592: INFO: Got endpoints: latency-svc-9j7nk [248.827138ms]
Mar 19 10:08:21.600: INFO: Created: latency-svc-5nxhj
Mar 19 10:08:21.608: INFO: Created: latency-svc-cdk4t
Mar 19 10:08:21.621: INFO: Created: latency-svc-pgxrt
Mar 19 10:08:21.631: INFO: Created: latency-svc-qg56h
Mar 19 10:08:21.644: INFO: Got endpoints: latency-svc-4jswf [285.126238ms]
Mar 19 10:08:21.646: INFO: Created: latency-svc-sjtj6
Mar 19 10:08:21.662: INFO: Created: latency-svc-w6sjg
Mar 19 10:08:21.674: INFO: Created: latency-svc-t5n4h
Mar 19 10:08:21.686: INFO: Created: latency-svc-75dll
Mar 19 10:08:21.694: INFO: Got endpoints: latency-svc-rn9bx [323.818074ms]
Mar 19 10:08:21.700: INFO: Created: latency-svc-bvspb
Mar 19 10:08:21.715: INFO: Created: latency-svc-kddld
Mar 19 10:08:21.732: INFO: Created: latency-svc-2gn9p
Mar 19 10:08:21.747: INFO: Got endpoints: latency-svc-ncrds [353.583758ms]
Mar 19 10:08:21.752: INFO: Created: latency-svc-bxlxr
Mar 19 10:08:21.765: INFO: Created: latency-svc-ctmqp
Mar 19 10:08:21.782: INFO: Created: latency-svc-fnxch
Mar 19 10:08:21.788: INFO: Created: latency-svc-4d2km
Mar 19 10:08:21.792: INFO: Got endpoints: latency-svc-5nxhj [389.967356ms]
Mar 19 10:08:21.812: INFO: Created: latency-svc-rnqqz
Mar 19 10:08:21.842: INFO: Got endpoints: latency-svc-cdk4t [427.956666ms]
Mar 19 10:08:21.860: INFO: Created: latency-svc-k7cgh
Mar 19 10:08:21.892: INFO: Got endpoints: latency-svc-pgxrt [466.254528ms]
Mar 19 10:08:21.916: INFO: Created: latency-svc-nwlrs
Mar 19 10:08:21.941: INFO: Got endpoints: latency-svc-qg56h [496.676501ms]
Mar 19 10:08:21.962: INFO: Created: latency-svc-87s5t
Mar 19 10:08:21.992: INFO: Got endpoints: latency-svc-sjtj6 [538.623526ms]
Mar 19 10:08:22.011: INFO: Created: latency-svc-kq994
Mar 19 10:08:22.042: INFO: Got endpoints: latency-svc-w6sjg [572.471168ms]
Mar 19 10:08:22.062: INFO: Created: latency-svc-tr6vr
Mar 19 10:08:22.092: INFO: Got endpoints: latency-svc-t5n4h [607.976232ms]
Mar 19 10:08:22.112: INFO: Created: latency-svc-4l895
Mar 19 10:08:22.142: INFO: Got endpoints: latency-svc-75dll [641.887113ms]
Mar 19 10:08:22.165: INFO: Created: latency-svc-t7vqb
Mar 19 10:08:22.192: INFO: Got endpoints: latency-svc-bvspb [681.68415ms]
Mar 19 10:08:22.211: INFO: Created: latency-svc-6cjkf
Mar 19 10:08:22.243: INFO: Got endpoints: latency-svc-kddld [720.250694ms]
Mar 19 10:08:22.264: INFO: Created: latency-svc-ng9cf
Mar 19 10:08:22.292: INFO: Got endpoints: latency-svc-2gn9p [748.479588ms]
Mar 19 10:08:22.313: INFO: Created: latency-svc-bzzx7
Mar 19 10:08:22.343: INFO: Got endpoints: latency-svc-bxlxr [751.047337ms]
Mar 19 10:08:22.364: INFO: Created: latency-svc-t9prh
Mar 19 10:08:22.392: INFO: Got endpoints: latency-svc-ctmqp [747.774083ms]
Mar 19 10:08:22.414: INFO: Created: latency-svc-g55bt
Mar 19 10:08:22.441: INFO: Got endpoints: latency-svc-fnxch [747.493052ms]
Mar 19 10:08:22.459: INFO: Created: latency-svc-2ds7s
Mar 19 10:08:22.492: INFO: Got endpoints: latency-svc-4d2km [745.04805ms]
Mar 19 10:08:22.511: INFO: Created: latency-svc-6cq7t
Mar 19 10:08:22.542: INFO: Got endpoints: latency-svc-rnqqz [749.536406ms]
Mar 19 10:08:22.560: INFO: Created: latency-svc-jrgqn
Mar 19 10:08:22.592: INFO: Got endpoints: latency-svc-k7cgh [750.095218ms]
Mar 19 10:08:22.613: INFO: Created: latency-svc-24vc5
Mar 19 10:08:22.641: INFO: Got endpoints: latency-svc-nwlrs [749.588457ms]
Mar 19 10:08:22.661: INFO: Created: latency-svc-rf8f8
Mar 19 10:08:22.692: INFO: Got endpoints: latency-svc-87s5t [751.136551ms]
Mar 19 10:08:22.712: INFO: Created: latency-svc-krmjf
Mar 19 10:08:22.742: INFO: Got endpoints: latency-svc-kq994 [749.688067ms]
Mar 19 10:08:22.763: INFO: Created: latency-svc-n4txz
Mar 19 10:08:22.792: INFO: Got endpoints: latency-svc-tr6vr [750.049413ms]
Mar 19 10:08:22.814: INFO: Created: latency-svc-ljxh9
Mar 19 10:08:22.841: INFO: Got endpoints: latency-svc-4l895 [749.550845ms]
Mar 19 10:08:22.865: INFO: Created: latency-svc-sgq94
Mar 19 10:08:22.891: INFO: Got endpoints: latency-svc-t7vqb [749.15305ms]
Mar 19 10:08:22.913: INFO: Created: latency-svc-rf5dj
Mar 19 10:08:22.945: INFO: Got endpoints: latency-svc-6cjkf [753.108052ms]
Mar 19 10:08:22.970: INFO: Created: latency-svc-4c2bj
Mar 19 10:08:22.991: INFO: Got endpoints: latency-svc-ng9cf [748.154163ms]
Mar 19 10:08:23.012: INFO: Created: latency-svc-n8kgr
Mar 19 10:08:23.043: INFO: Got endpoints: latency-svc-bzzx7 [750.631871ms]
Mar 19 10:08:23.065: INFO: Created: latency-svc-tbdhx
Mar 19 10:08:23.092: INFO: Got endpoints: latency-svc-t9prh [748.040143ms]
Mar 19 10:08:23.114: INFO: Created: latency-svc-8xt2r
Mar 19 10:08:23.143: INFO: Got endpoints: latency-svc-g55bt [751.301775ms]
Mar 19 10:08:23.164: INFO: Created: latency-svc-rdz7t
Mar 19 10:08:23.192: INFO: Got endpoints: latency-svc-2ds7s [750.188879ms]
Mar 19 10:08:23.213: INFO: Created: latency-svc-zqrcj
Mar 19 10:08:23.242: INFO: Got endpoints: latency-svc-6cq7t [749.952022ms]
Mar 19 10:08:23.262: INFO: Created: latency-svc-n6cxz
Mar 19 10:08:23.292: INFO: Got endpoints: latency-svc-jrgqn [750.43375ms]
Mar 19 10:08:23.313: INFO: Created: latency-svc-9h5gz
Mar 19 10:08:23.344: INFO: Got endpoints: latency-svc-24vc5 [752.445557ms]
Mar 19 10:08:23.364: INFO: Created: latency-svc-s4l6c
Mar 19 10:08:23.392: INFO: Got endpoints: latency-svc-rf8f8 [750.149133ms]
Mar 19 10:08:23.411: INFO: Created: latency-svc-45l4r
Mar 19 10:08:23.442: INFO: Got endpoints: latency-svc-krmjf [749.045931ms]
Mar 19 10:08:23.462: INFO: Created: latency-svc-84qxf
Mar 19 10:08:23.492: INFO: Got endpoints: latency-svc-n4txz [749.741045ms]
Mar 19 10:08:23.511: INFO: Created: latency-svc-dhrzv
Mar 19 10:08:23.542: INFO: Got endpoints: latency-svc-ljxh9 [750.082725ms]
Mar 19 10:08:23.563: INFO: Created: latency-svc-5dv2q
Mar 19 10:08:23.593: INFO: Got endpoints: latency-svc-sgq94 [752.186957ms]
Mar 19 10:08:23.614: INFO: Created: latency-svc-mdqzt
Mar 19 10:08:23.646: INFO: Got endpoints: latency-svc-rf5dj [754.380801ms]
Mar 19 10:08:23.666: INFO: Created: latency-svc-l8ml4
Mar 19 10:08:23.692: INFO: Got endpoints: latency-svc-4c2bj [746.971235ms]
Mar 19 10:08:23.715: INFO: Created: latency-svc-7xl92
Mar 19 10:08:23.742: INFO: Got endpoints: latency-svc-n8kgr [750.098077ms]
Mar 19 10:08:23.762: INFO: Created: latency-svc-hl2gd
Mar 19 10:08:23.793: INFO: Got endpoints: latency-svc-tbdhx [749.84789ms]
Mar 19 10:08:23.812: INFO: Created: latency-svc-wx4vx
Mar 19 10:08:23.842: INFO: Got endpoints: latency-svc-8xt2r [750.455689ms]
Mar 19 10:08:23.864: INFO: Created: latency-svc-5v48r
Mar 19 10:08:23.892: INFO: Got endpoints: latency-svc-rdz7t [748.627511ms]
Mar 19 10:08:23.912: INFO: Created: latency-svc-cs6rs
Mar 19 10:08:23.942: INFO: Got endpoints: latency-svc-zqrcj [750.150407ms]
Mar 19 10:08:23.962: INFO: Created: latency-svc-6dtcq
Mar 19 10:08:23.991: INFO: Got endpoints: latency-svc-n6cxz [749.728044ms]
Mar 19 10:08:24.013: INFO: Created: latency-svc-n4q7g
Mar 19 10:08:24.042: INFO: Got endpoints: latency-svc-9h5gz [749.886155ms]
Mar 19 10:08:24.063: INFO: Created: latency-svc-srmxv
Mar 19 10:08:24.092: INFO: Got endpoints: latency-svc-s4l6c [748.113253ms]
Mar 19 10:08:24.111: INFO: Created: latency-svc-kj6zs
Mar 19 10:08:24.142: INFO: Got endpoints: latency-svc-45l4r [750.106981ms]
Mar 19 10:08:24.164: INFO: Created: latency-svc-mjh64
Mar 19 10:08:24.191: INFO: Got endpoints: latency-svc-84qxf [749.840169ms]
Mar 19 10:08:24.214: INFO: Created: latency-svc-5rqcj
Mar 19 10:08:24.246: INFO: Got endpoints: latency-svc-dhrzv [753.932947ms]
Mar 19 10:08:24.266: INFO: Created: latency-svc-kpw4s
Mar 19 10:08:24.296: INFO: Got endpoints: latency-svc-5dv2q [754.462234ms]
Mar 19 10:08:24.324: INFO: Created: latency-svc-rwhdn
Mar 19 10:08:24.342: INFO: Got endpoints: latency-svc-mdqzt [748.638725ms]
Mar 19 10:08:24.365: INFO: Created: latency-svc-pw2wg
Mar 19 10:08:24.392: INFO: Got endpoints: latency-svc-l8ml4 [745.963373ms]
Mar 19 10:08:24.411: INFO: Created: latency-svc-xrv8v
Mar 19 10:08:24.443: INFO: Got endpoints: latency-svc-7xl92 [750.966422ms]
Mar 19 10:08:24.462: INFO: Created: latency-svc-wkv4z
Mar 19 10:08:24.494: INFO: Got endpoints: latency-svc-hl2gd [752.028016ms]
Mar 19 10:08:24.522: INFO: Created: latency-svc-jzbn9
Mar 19 10:08:24.542: INFO: Got endpoints: latency-svc-wx4vx [749.167723ms]
Mar 19 10:08:24.568: INFO: Created: latency-svc-cl9cj
Mar 19 10:08:24.592: INFO: Got endpoints: latency-svc-5v48r [750.124963ms]
Mar 19 10:08:24.617: INFO: Created: latency-svc-jlt7d
Mar 19 10:08:24.642: INFO: Got endpoints: latency-svc-cs6rs [750.049604ms]
Mar 19 10:08:24.661: INFO: Created: latency-svc-v6st5
Mar 19 10:08:24.695: INFO: Got endpoints: latency-svc-6dtcq [753.267772ms]
Mar 19 10:08:24.717: INFO: Created: latency-svc-s9bvk
Mar 19 10:08:24.743: INFO: Got endpoints: latency-svc-n4q7g [751.422372ms]
Mar 19 10:08:24.777: INFO: Created: latency-svc-lrzfw
Mar 19 10:08:24.794: INFO: Got endpoints: latency-svc-srmxv [752.316614ms]
Mar 19 10:08:24.819: INFO: Created: latency-svc-5wdck
Mar 19 10:08:24.844: INFO: Got endpoints: latency-svc-kj6zs [752.113679ms]
Mar 19 10:08:24.864: INFO: Created: latency-svc-v7fql
Mar 19 10:08:24.892: INFO: Got endpoints: latency-svc-mjh64 [750.184005ms]
Mar 19 10:08:24.913: INFO: Created: latency-svc-xv64z
Mar 19 10:08:24.942: INFO: Got endpoints: latency-svc-5rqcj [751.023865ms]
Mar 19 10:08:24.966: INFO: Created: latency-svc-jv9qb
Mar 19 10:08:24.992: INFO: Got endpoints: latency-svc-kpw4s [745.670194ms]
Mar 19 10:08:25.011: INFO: Created: latency-svc-fvzs7
Mar 19 10:08:25.049: INFO: Got endpoints: latency-svc-rwhdn [752.240511ms]
Mar 19 10:08:25.068: INFO: Created: latency-svc-dmp7b
Mar 19 10:08:25.092: INFO: Got endpoints: latency-svc-pw2wg [750.290135ms]
Mar 19 10:08:25.120: INFO: Created: latency-svc-sk55d
Mar 19 10:08:25.142: INFO: Got endpoints: latency-svc-xrv8v [749.916644ms]
Mar 19 10:08:25.163: INFO: Created: latency-svc-nn756
Mar 19 10:08:25.192: INFO: Got endpoints: latency-svc-wkv4z [748.890754ms]
Mar 19 10:08:25.212: INFO: Created: latency-svc-2q6vz
Mar 19 10:08:25.243: INFO: Got endpoints: latency-svc-jzbn9 [749.044095ms]
Mar 19 10:08:25.263: INFO: Created: latency-svc-rsmpz
Mar 19 10:08:25.292: INFO: Got endpoints: latency-svc-cl9cj [750.575462ms]
Mar 19 10:08:25.313: INFO: Created: latency-svc-tft56
Mar 19 10:08:25.341: INFO: Got endpoints: latency-svc-jlt7d [749.287474ms]
Mar 19 10:08:25.360: INFO: Created: latency-svc-hpf5w
Mar 19 10:08:25.395: INFO: Got endpoints: latency-svc-v6st5 [753.671975ms]
Mar 19 10:08:25.414: INFO: Created: latency-svc-vrdjl
Mar 19 10:08:25.442: INFO: Got endpoints: latency-svc-s9bvk [746.596657ms]
Mar 19 10:08:25.462: INFO: Created: latency-svc-5sjcq
Mar 19 10:08:25.493: INFO: Got endpoints: latency-svc-lrzfw [749.647713ms]
Mar 19 10:08:25.512: INFO: Created: latency-svc-7rmdc
Mar 19 10:08:25.542: INFO: Got endpoints: latency-svc-5wdck [747.472506ms]
Mar 19 10:08:25.569: INFO: Created: latency-svc-tbqb4
Mar 19 10:08:25.592: INFO: Got endpoints: latency-svc-v7fql [747.940119ms]
Mar 19 10:08:25.614: INFO: Created: latency-svc-jr4z5
Mar 19 10:08:25.642: INFO: Got endpoints: latency-svc-xv64z [750.406223ms]
Mar 19 10:08:25.662: INFO: Created: latency-svc-557xv
Mar 19 10:08:25.693: INFO: Got endpoints: latency-svc-jv9qb [750.036581ms]
Mar 19 10:08:25.716: INFO: Created: latency-svc-2vsvn
Mar 19 10:08:25.742: INFO: Got endpoints: latency-svc-fvzs7 [750.104166ms]
Mar 19 10:08:25.762: INFO: Created: latency-svc-b6nxm
Mar 19 10:08:25.792: INFO: Got endpoints: latency-svc-dmp7b [743.329799ms]
Mar 19 10:08:25.814: INFO: Created: latency-svc-vnbpt
Mar 19 10:08:25.842: INFO: Got endpoints: latency-svc-sk55d [749.272826ms]
Mar 19 10:08:25.861: INFO: Created: latency-svc-gl6hk
Mar 19 10:08:25.892: INFO: Got endpoints: latency-svc-nn756 [750.50068ms]
Mar 19 10:08:25.912: INFO: Created: latency-svc-vp9f8
Mar 19 10:08:25.942: INFO: Got endpoints: latency-svc-2q6vz [750.185839ms]
Mar 19 10:08:25.962: INFO: Created: latency-svc-cmzj8
Mar 19 10:08:25.992: INFO: Got endpoints: latency-svc-rsmpz [749.799384ms]
Mar 19 10:08:26.014: INFO: Created: latency-svc-p757x
Mar 19 10:08:26.042: INFO: Got endpoints: latency-svc-tft56 [749.347802ms]
Mar 19 10:08:26.061: INFO: Created: latency-svc-vvhfw
Mar 19 10:08:26.092: INFO: Got endpoints: latency-svc-hpf5w [750.94646ms]
Mar 19 10:08:26.112: INFO: Created: latency-svc-jzvcx
Mar 19 10:08:26.143: INFO: Got endpoints: latency-svc-vrdjl [747.856428ms]
Mar 19 10:08:26.165: INFO: Created: latency-svc-gc9x2
Mar 19 10:08:26.192: INFO: Got endpoints: latency-svc-5sjcq [750.219431ms]
Mar 19 10:08:26.216: INFO: Created: latency-svc-29wxl
Mar 19 10:08:26.242: INFO: Got endpoints: latency-svc-7rmdc [749.069608ms]
Mar 19 10:08:26.261: INFO: Created: latency-svc-gbjq5
Mar 19 10:08:26.292: INFO: Got endpoints: latency-svc-tbqb4 [749.967371ms]
Mar 19 10:08:26.312: INFO: Created: latency-svc-db9mt
Mar 19 10:08:26.342: INFO: Got endpoints: latency-svc-jr4z5 [750.031044ms]
Mar 19 10:08:26.361: INFO: Created: latency-svc-5s6w6
Mar 19 10:08:26.396: INFO: Got endpoints: latency-svc-557xv [753.248447ms]
Mar 19 10:08:26.416: INFO: Created: latency-svc-tgggk
Mar 19 10:08:26.442: INFO: Got endpoints: latency-svc-2vsvn [749.970862ms]
Mar 19 10:08:26.462: INFO: Created: latency-svc-wmsmn
Mar 19 10:08:26.497: INFO: Got endpoints: latency-svc-b6nxm [755.185713ms]
Mar 19 10:08:26.520: INFO: Created: latency-svc-4dsbd
Mar 19 10:08:26.542: INFO: Got endpoints: latency-svc-vnbpt [749.742961ms]
Mar 19 10:08:26.563: INFO: Created: latency-svc-fxddg
Mar 19 10:08:26.593: INFO: Got endpoints: latency-svc-gl6hk [751.137708ms]
Mar 19 10:08:26.617: INFO: Created: latency-svc-b5wh4
Mar 19 10:08:26.643: INFO: Got endpoints: latency-svc-vp9f8 [750.88478ms]
Mar 19 10:08:26.664: INFO: Created: latency-svc-2qh9n
Mar 19 10:08:26.692: INFO: Got endpoints: latency-svc-cmzj8 [749.9393ms]
Mar 19 10:08:26.715: INFO: Created: latency-svc-4w55x
Mar 19 10:08:26.743: INFO: Got endpoints: latency-svc-p757x [750.398003ms]
Mar 19 10:08:26.762: INFO: Created: latency-svc-lczjl
Mar 19 10:08:26.793: INFO: Got endpoints: latency-svc-vvhfw [751.027722ms]
Mar 19 10:08:26.815: INFO: Created: latency-svc-tpmws
Mar 19 10:08:26.845: INFO: Got endpoints: latency-svc-jzvcx [752.310756ms]
Mar 19 10:08:26.866: INFO: Created: latency-svc-bvq6q
Mar 19 10:08:26.892: INFO: Got endpoints: latency-svc-gc9x2 [748.769535ms]
Mar 19 10:08:26.920: INFO: Created: latency-svc-4kr5r
Mar 19 10:08:26.946: INFO: Got endpoints: latency-svc-29wxl [754.225402ms]
Mar 19 10:08:26.966: INFO: Created: latency-svc-5sjzp
Mar 19 10:08:26.993: INFO: Got endpoints: latency-svc-gbjq5 [750.81298ms]
Mar 19 10:08:27.015: INFO: Created: latency-svc-mf7dv
Mar 19 10:08:27.043: INFO: Got endpoints: latency-svc-db9mt [751.665655ms]
Mar 19 10:08:27.064: INFO: Created: latency-svc-9vkbw
Mar 19 10:08:27.093: INFO: Got endpoints: latency-svc-5s6w6 [750.58814ms]
Mar 19 10:08:27.113: INFO: Created: latency-svc-dwcqf
Mar 19 10:08:27.142: INFO: Got endpoints: latency-svc-tgggk [746.457219ms]
Mar 19 10:08:27.166: INFO: Created: latency-svc-pt9df
Mar 19 10:08:27.192: INFO: Got endpoints: latency-svc-wmsmn [749.776673ms]
Mar 19 10:08:27.211: INFO: Created: latency-svc-4fjb5
Mar 19 10:08:27.243: INFO: Got endpoints: latency-svc-4dsbd [746.479001ms]
Mar 19 10:08:27.267: INFO: Created: latency-svc-g9shx
Mar 19 10:08:27.292: INFO: Got endpoints: latency-svc-fxddg [750.165469ms]
Mar 19 10:08:27.312: INFO: Created: latency-svc-npmhv
Mar 19 10:08:27.343: INFO: Got endpoints: latency-svc-b5wh4 [750.166204ms]
Mar 19 10:08:27.368: INFO: Created: latency-svc-5zqcn
Mar 19 10:08:27.392: INFO: Got endpoints: latency-svc-2qh9n [748.564568ms]
Mar 19 10:08:27.414: INFO: Created: latency-svc-8ljls
Mar 19 10:08:27.447: INFO: Got endpoints: latency-svc-4w55x [754.540468ms]
Mar 19 10:08:27.464: INFO: Created: latency-svc-p6l8w
Mar 19 10:08:27.492: INFO: Got endpoints: latency-svc-lczjl [749.004361ms]
Mar 19 10:08:27.518: INFO: Created: latency-svc-xs68f
Mar 19 10:08:27.543: INFO: Got endpoints: latency-svc-tpmws [750.022271ms]
Mar 19 10:08:27.566: INFO: Created: latency-svc-7b2bd
Mar 19 10:08:27.592: INFO: Got endpoints: latency-svc-bvq6q [747.238757ms]
Mar 19 10:08:27.615: INFO: Created: latency-svc-pldz2
Mar 19 10:08:27.643: INFO: Got endpoints: latency-svc-4kr5r [751.337767ms]
Mar 19 10:08:27.662: INFO: Created: latency-svc-2l6kd
Mar 19 10:08:27.696: INFO: Got endpoints: latency-svc-5sjzp [749.348997ms]
Mar 19 10:08:27.716: INFO: Created: latency-svc-fzglg
Mar 19 10:08:27.742: INFO: Got endpoints: latency-svc-mf7dv [749.27435ms]
Mar 19 10:08:27.779: INFO: Created: latency-svc-nmzm9
Mar 19 10:08:27.793: INFO: Got endpoints: latency-svc-9vkbw [749.36929ms]
Mar 19 10:08:27.812: INFO: Created: latency-svc-bnmhn
Mar 19 10:08:27.842: INFO: Got endpoints: latency-svc-dwcqf [748.743298ms]
Mar 19 10:08:27.864: INFO: Created: latency-svc-4gzc5
Mar 19 10:08:27.892: INFO: Got endpoints: latency-svc-pt9df [749.793623ms]
Mar 19 10:08:27.914: INFO: Created: latency-svc-drqw2
Mar 19 10:08:27.943: INFO: Got endpoints: latency-svc-4fjb5 [750.263928ms]
Mar 19 10:08:27.964: INFO: Created: latency-svc-mg9bw
Mar 19 10:08:27.992: INFO: Got endpoints: latency-svc-g9shx [748.508885ms]
Mar 19 10:08:28.013: INFO: Created: latency-svc-l2mzd
Mar 19 10:08:28.046: INFO: Got endpoints: latency-svc-npmhv [753.658231ms]
Mar 19 10:08:28.066: INFO: Created: latency-svc-cd9l9
Mar 19 10:08:28.093: INFO: Got endpoints: latency-svc-5zqcn [749.764675ms]
Mar 19 10:08:28.115: INFO: Created: latency-svc-g4xb6
Mar 19 10:08:28.142: INFO: Got endpoints: latency-svc-8ljls [750.366944ms]
Mar 19 10:08:28.164: INFO: Created: latency-svc-zmstw
Mar 19 10:08:28.194: INFO: Got endpoints: latency-svc-p6l8w [747.4513ms]
Mar 19 10:08:28.220: INFO: Created: latency-svc-pb4x7
Mar 19 10:08:28.242: INFO: Got endpoints: latency-svc-xs68f [750.003717ms]
Mar 19 10:08:28.264: INFO: Created: latency-svc-bxqnz
Mar 19 10:08:28.294: INFO: Got endpoints: latency-svc-7b2bd [751.496257ms]
Mar 19 10:08:28.314: INFO: Created: latency-svc-8sbvp
Mar 19 10:08:28.342: INFO: Got endpoints: latency-svc-pldz2 [750.085134ms]
Mar 19 10:08:28.376: INFO: Created: latency-svc-ffnsb
Mar 19 10:08:28.393: INFO: Got endpoints: latency-svc-2l6kd [749.422391ms]
Mar 19 10:08:28.411: INFO: Created: latency-svc-4kmq4
Mar 19 10:08:28.445: INFO: Got endpoints: latency-svc-fzglg [749.235499ms]
Mar 19 10:08:28.465: INFO: Created: latency-svc-4f7vb
Mar 19 10:08:28.492: INFO: Got endpoints: latency-svc-nmzm9 [750.647821ms]
Mar 19 10:08:28.516: INFO: Created: latency-svc-w5q2x
Mar 19 10:08:28.542: INFO: Got endpoints: latency-svc-bnmhn [749.166594ms]
Mar 19 10:08:28.562: INFO: Created: latency-svc-2qfqx
Mar 19 10:08:28.594: INFO: Got endpoints: latency-svc-4gzc5 [751.97039ms]
Mar 19 10:08:28.619: INFO: Created: latency-svc-k4vc2
Mar 19 10:08:28.642: INFO: Got endpoints: latency-svc-drqw2 [749.912616ms]
Mar 19 10:08:28.662: INFO: Created: latency-svc-wfnh9
Mar 19 10:08:28.692: INFO: Got endpoints: latency-svc-mg9bw [749.542857ms]
Mar 19 10:08:28.713: INFO: Created: latency-svc-dzrm9
Mar 19 10:08:28.742: INFO: Got endpoints: latency-svc-l2mzd [750.021029ms]
Mar 19 10:08:28.792: INFO: Got endpoints: latency-svc-cd9l9 [746.441576ms]
Mar 19 10:08:28.844: INFO: Got endpoints: latency-svc-g4xb6 [751.48667ms]
Mar 19 10:08:28.892: INFO: Got endpoints: latency-svc-zmstw [750.200987ms]
Mar 19 10:08:28.946: INFO: Got endpoints: latency-svc-pb4x7 [752.287489ms]
Mar 19 10:08:28.992: INFO: Got endpoints: latency-svc-bxqnz [749.717395ms]
Mar 19 10:08:29.042: INFO: Got endpoints: latency-svc-8sbvp [747.95647ms]
Mar 19 10:08:29.092: INFO: Got endpoints: latency-svc-ffnsb [750.055841ms]
Mar 19 10:08:29.142: INFO: Got endpoints: latency-svc-4kmq4 [749.205993ms]
Mar 19 10:08:29.192: INFO: Got endpoints: latency-svc-4f7vb [747.418711ms]
Mar 19 10:08:29.242: INFO: Got endpoints: latency-svc-w5q2x [749.799265ms]
Mar 19 10:08:29.293: INFO: Got endpoints: latency-svc-2qfqx [750.784934ms]
Mar 19 10:08:29.342: INFO: Got endpoints: latency-svc-k4vc2 [748.285963ms]
Mar 19 10:08:29.392: INFO: Got endpoints: latency-svc-wfnh9 [750.012159ms]
Mar 19 10:08:29.442: INFO: Got endpoints: latency-svc-dzrm9 [749.804313ms]
Mar 19 10:08:29.442: INFO: Latencies: [37.56742ms 54.641813ms 83.324018ms 97.253925ms 111.40767ms 126.505353ms 135.852047ms 154.535459ms 163.553791ms 181.736256ms 193.740698ms 207.131787ms 210.043598ms 210.636399ms 212.6853ms 213.88895ms 214.045998ms 214.048706ms 214.094753ms 214.143908ms 214.610038ms 214.916046ms 214.987673ms 215.024628ms 216.310798ms 216.949035ms 218.284488ms 218.300905ms 218.324122ms 218.691141ms 219.75024ms 220.968686ms 221.331863ms 221.57433ms 222.498758ms 222.863783ms 223.772054ms 225.35112ms 229.764462ms 232.524199ms 233.804432ms 248.827138ms 252.212627ms 285.126238ms 323.818074ms 353.583758ms 389.967356ms 427.956666ms 466.254528ms 496.676501ms 538.623526ms 572.471168ms 607.976232ms 641.887113ms 681.68415ms 720.250694ms 743.329799ms 745.04805ms 745.670194ms 745.963373ms 746.441576ms 746.457219ms 746.479001ms 746.596657ms 746.971235ms 747.238757ms 747.418711ms 747.4513ms 747.472506ms 747.493052ms 747.774083ms 747.856428ms 747.940119ms 747.95647ms 748.040143ms 748.113253ms 748.154163ms 748.285963ms 748.479588ms 748.508885ms 748.564568ms 748.627511ms 748.638725ms 748.743298ms 748.769535ms 748.890754ms 749.004361ms 749.044095ms 749.045931ms 749.069608ms 749.15305ms 749.166594ms 749.167723ms 749.205993ms 749.235499ms 749.272826ms 749.27435ms 749.287474ms 749.347802ms 749.348997ms 749.36929ms 749.422391ms 749.536406ms 749.542857ms 749.550845ms 749.588457ms 749.647713ms 749.688067ms 749.717395ms 749.728044ms 749.741045ms 749.742961ms 749.764675ms 749.776673ms 749.793623ms 749.799265ms 749.799384ms 749.804313ms 749.840169ms 749.84789ms 749.886155ms 749.912616ms 749.916644ms 749.9393ms 749.952022ms 749.967371ms 749.970862ms 750.003717ms 750.012159ms 750.021029ms 750.022271ms 750.031044ms 750.036581ms 750.049413ms 750.049604ms 750.055841ms 750.082725ms 750.085134ms 750.095218ms 750.098077ms 750.104166ms 750.106981ms 750.124963ms 750.149133ms 750.150407ms 750.165469ms 750.166204ms 750.184005ms 750.185839ms 750.188879ms 750.200987ms 750.219431ms 750.263928ms 750.290135ms 750.366944ms 750.398003ms 750.406223ms 750.43375ms 750.455689ms 750.50068ms 750.575462ms 750.58814ms 750.631871ms 750.647821ms 750.784934ms 750.81298ms 750.88478ms 750.94646ms 750.966422ms 751.023865ms 751.027722ms 751.047337ms 751.136551ms 751.137708ms 751.301775ms 751.337767ms 751.422372ms 751.48667ms 751.496257ms 751.665655ms 751.97039ms 752.028016ms 752.113679ms 752.186957ms 752.240511ms 752.287489ms 752.310756ms 752.316614ms 752.445557ms 753.108052ms 753.248447ms 753.267772ms 753.658231ms 753.671975ms 753.932947ms 754.225402ms 754.380801ms 754.462234ms 754.540468ms 755.185713ms]
Mar 19 10:08:29.442: INFO: 50 %ile: 749.36929ms
Mar 19 10:08:29.442: INFO: 90 %ile: 751.97039ms
Mar 19 10:08:29.442: INFO: 99 %ile: 754.540468ms
Mar 19 10:08:29.442: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:08:29.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-4ckcb" for this suite.
Mar 19 10:08:45.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:08:45.658: INFO: namespace: e2e-tests-svc-latency-4ckcb, resource: bindings, ignored listing per whitelist
Mar 19 10:08:45.665: INFO: namespace e2e-tests-svc-latency-4ckcb deletion completed in 16.210755521s

• [SLOW TEST:27.042 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:08:45.665: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-fb5b3bb5-4a2e-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume secrets
Mar 19 10:08:45.833: INFO: Waiting up to 5m0s for pod "pod-secrets-fb657d15-4a2e-11e9-989b-da33bd6188b3" in namespace "e2e-tests-secrets-rjxhh" to be "success or failure"
Mar 19 10:08:45.838: INFO: Pod "pod-secrets-fb657d15-4a2e-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.840378ms
Mar 19 10:08:47.844: INFO: Pod "pod-secrets-fb657d15-4a2e-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011728174s
STEP: Saw pod success
Mar 19 10:08:47.844: INFO: Pod "pod-secrets-fb657d15-4a2e-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:08:47.849: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod pod-secrets-fb657d15-4a2e-11e9-989b-da33bd6188b3 container secret-volume-test: <nil>
STEP: delete the pod
Mar 19 10:08:47.900: INFO: Waiting for pod pod-secrets-fb657d15-4a2e-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:08:47.905: INFO: Pod pod-secrets-fb657d15-4a2e-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:08:47.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-rjxhh" for this suite.
Mar 19 10:08:53.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:08:54.046: INFO: namespace: e2e-tests-secrets-rjxhh, resource: bindings, ignored listing per whitelist
Mar 19 10:08:54.119: INFO: namespace e2e-tests-secrets-rjxhh deletion completed in 6.204341773s
STEP: Destroying namespace "e2e-tests-secret-namespace-4kjn4" for this suite.
Mar 19 10:09:00.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:09:00.209: INFO: namespace: e2e-tests-secret-namespace-4kjn4, resource: bindings, ignored listing per whitelist
Mar 19 10:09:00.324: INFO: namespace e2e-tests-secret-namespace-4kjn4 deletion completed in 6.204685518s

• [SLOW TEST:14.658 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:09:00.324: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 10:09:00.432: INFO: (0) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.499786ms)
Mar 19 10:09:00.442: INFO: (1) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.804783ms)
Mar 19 10:09:00.451: INFO: (2) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.384502ms)
Mar 19 10:09:00.461: INFO: (3) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.724122ms)
Mar 19 10:09:00.471: INFO: (4) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.852763ms)
Mar 19 10:09:00.481: INFO: (5) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.010265ms)
Mar 19 10:09:00.491: INFO: (6) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.799371ms)
Mar 19 10:09:00.501: INFO: (7) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.852662ms)
Mar 19 10:09:00.512: INFO: (8) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.972408ms)
Mar 19 10:09:00.522: INFO: (9) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.645321ms)
Mar 19 10:09:00.532: INFO: (10) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.596653ms)
Mar 19 10:09:00.542: INFO: (11) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.884054ms)
Mar 19 10:09:00.552: INFO: (12) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.036269ms)
Mar 19 10:09:00.562: INFO: (13) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.882834ms)
Mar 19 10:09:00.571: INFO: (14) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.603338ms)
Mar 19 10:09:00.581: INFO: (15) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.730458ms)
Mar 19 10:09:00.591: INFO: (16) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.812748ms)
Mar 19 10:09:00.600: INFO: (17) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.69949ms)
Mar 19 10:09:00.610: INFO: (18) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.608446ms)
Mar 19 10:09:00.620: INFO: (19) /api/v1/nodes/k8s-node-vm1y1w-lkllt8nnod:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.829803ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:09:00.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-w6qgv" for this suite.
Mar 19 10:09:06.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:09:06.774: INFO: namespace: e2e-tests-proxy-w6qgv, resource: bindings, ignored listing per whitelist
Mar 19 10:09:06.837: INFO: namespace e2e-tests-proxy-w6qgv deletion completed in 6.209567708s

• [SLOW TEST:6.513 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:09:06.837: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Mar 19 10:09:06.931: INFO: Waiting up to 5m0s for pod "client-containers-07f8c305-4a2f-11e9-989b-da33bd6188b3" in namespace "e2e-tests-containers-zcwgw" to be "success or failure"
Mar 19 10:09:06.937: INFO: Pod "client-containers-07f8c305-4a2f-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.273087ms
Mar 19 10:09:08.943: INFO: Pod "client-containers-07f8c305-4a2f-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011982959s
STEP: Saw pod success
Mar 19 10:09:08.943: INFO: Pod "client-containers-07f8c305-4a2f-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:09:08.948: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod client-containers-07f8c305-4a2f-11e9-989b-da33bd6188b3 container test-container: <nil>
STEP: delete the pod
Mar 19 10:09:08.982: INFO: Waiting for pod client-containers-07f8c305-4a2f-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:09:08.987: INFO: Pod client-containers-07f8c305-4a2f-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:09:08.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-zcwgw" for this suite.
Mar 19 10:09:15.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:09:15.157: INFO: namespace: e2e-tests-containers-zcwgw, resource: bindings, ignored listing per whitelist
Mar 19 10:09:15.200: INFO: namespace e2e-tests-containers-zcwgw deletion completed in 6.203841816s

• [SLOW TEST:8.363 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:09:15.200: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Mar 19 10:09:15.285: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 19 10:09:15.302: INFO: Waiting for terminating namespaces to be deleted...
Mar 19 10:09:15.309: INFO: 
Logging pods the kubelet thinks is on node k8s-node-vm1y1w-lkllt8nnod before test
Mar 19 10:09:15.324: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-19 09:59:45 +0000 UTC (1 container statuses recorded)
Mar 19 10:09:15.324: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 19 10:09:15.324: INFO: sonobuoy-systemd-logs-daemon-set-421c51583ba54221-jfpn4 from heptio-sonobuoy started at 2019-03-19 09:59:46 +0000 UTC (2 container statuses recorded)
Mar 19 10:09:15.324: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 19 10:09:15.324: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 19 10:09:15.324: INFO: jdcloud-k8s-ipamd-9pz6x from kube-system started at 2019-03-18 06:26:18 +0000 UTC (1 container statuses recorded)
Mar 19 10:09:15.324: INFO: 	Container jdcloud-k8s-ipamd ready: true, restart count 0
Mar 19 10:09:15.324: INFO: kube-proxy-89266 from kube-system started at 2019-03-18 06:26:37 +0000 UTC (1 container statuses recorded)
Mar 19 10:09:15.324: INFO: 	Container kube-proxy ready: true, restart count 0
Mar 19 10:09:15.324: INFO: prometheus-6f5dfd9fcd-zxm4n from jke-system started at 2019-03-18 06:46:24 +0000 UTC (1 container statuses recorded)
Mar 19 10:09:15.324: INFO: 	Container prometheus ready: true, restart count 0
Mar 19 10:09:15.324: INFO: node-exporter-lm4pq from jke-system started at 2019-03-18 06:26:37 +0000 UTC (1 container statuses recorded)
Mar 19 10:09:15.324: INFO: 	Container node-exporter ready: true, restart count 0
Mar 19 10:09:15.324: INFO: kube-state-metrics-c866955d-j29vx from jke-system started at 2019-03-18 06:26:56 +0000 UTC (2 container statuses recorded)
Mar 19 10:09:15.324: INFO: 	Container addon-resizer ready: true, restart count 0
Mar 19 10:09:15.324: INFO: 	Container kube-state-metrics ready: true, restart count 0
Mar 19 10:09:15.324: INFO: 
Logging pods the kubelet thinks is on node k8s-node-vmepd8-lkllt8nnod before test
Mar 19 10:09:15.333: INFO: kube-proxy-h74kb from kube-system started at 2019-03-18 06:26:51 +0000 UTC (1 container statuses recorded)
Mar 19 10:09:15.333: INFO: 	Container kube-proxy ready: true, restart count 0
Mar 19 10:09:15.333: INFO: coredns-6b474698f5-6qcd7 from kube-system started at 2019-03-18 06:46:24 +0000 UTC (1 container statuses recorded)
Mar 19 10:09:15.333: INFO: 	Container coredns ready: true, restart count 0
Mar 19 10:09:15.333: INFO: sonobuoy-systemd-logs-daemon-set-421c51583ba54221-wk6bb from heptio-sonobuoy started at 2019-03-19 09:59:46 +0000 UTC (2 container statuses recorded)
Mar 19 10:09:15.333: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 19 10:09:15.333: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 19 10:09:15.333: INFO: jdcloud-k8s-ipamd-9lcf8 from kube-system started at 2019-03-18 06:26:51 +0000 UTC (1 container statuses recorded)
Mar 19 10:09:15.333: INFO: 	Container jdcloud-k8s-ipamd ready: true, restart count 0
Mar 19 10:09:15.333: INFO: node-exporter-s8d56 from jke-system started at 2019-03-18 06:27:10 +0000 UTC (1 container statuses recorded)
Mar 19 10:09:15.333: INFO: 	Container node-exporter ready: true, restart count 0
Mar 19 10:09:15.333: INFO: heapster-5899f7978c-f6x7x from kube-system started at 2019-03-18 06:46:24 +0000 UTC (1 container statuses recorded)
Mar 19 10:09:15.333: INFO: 	Container heapster ready: true, restart count 0
Mar 19 10:09:15.333: INFO: sonobuoy-e2e-job-7e66631fb61c4f2f from heptio-sonobuoy started at 2019-03-19 09:59:46 +0000 UTC (2 container statuses recorded)
Mar 19 10:09:15.333: INFO: 	Container e2e ready: true, restart count 0
Mar 19 10:09:15.333: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 19 10:09:15.333: INFO: 
Logging pods the kubelet thinks is on node k8s-node-vmwvcc-lkllt8nnod before test
Mar 19 10:09:15.344: INFO: sonobuoy-systemd-logs-daemon-set-421c51583ba54221-86srx from heptio-sonobuoy started at 2019-03-19 09:59:46 +0000 UTC (2 container statuses recorded)
Mar 19 10:09:15.344: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 19 10:09:15.344: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 19 10:09:15.344: INFO: kube-proxy-n5vt5 from kube-system started at 2019-03-18 06:25:45 +0000 UTC (1 container statuses recorded)
Mar 19 10:09:15.344: INFO: 	Container kube-proxy ready: true, restart count 0
Mar 19 10:09:15.344: INFO: prometheus-jdmon-69d8fd6b87-sf5hc from jke-system started at 2019-03-18 06:46:24 +0000 UTC (2 container statuses recorded)
Mar 19 10:09:15.344: INFO: 	Container k8s-metrics-to-jdmon ready: true, restart count 0
Mar 19 10:09:15.344: INFO: 	Container refresher ready: true, restart count 0
Mar 19 10:09:15.344: INFO: coredns-6b474698f5-hgplj from kube-system started at 2019-03-18 06:46:24 +0000 UTC (1 container statuses recorded)
Mar 19 10:09:15.344: INFO: 	Container coredns ready: true, restart count 0
Mar 19 10:09:15.344: INFO: jdcloud-k8s-ipamd-tfr8l from kube-system started at 2019-03-18 06:25:27 +0000 UTC (1 container statuses recorded)
Mar 19 10:09:15.344: INFO: 	Container jdcloud-k8s-ipamd ready: true, restart count 0
Mar 19 10:09:15.344: INFO: node-exporter-nx6zb from jke-system started at 2019-03-18 06:25:45 +0000 UTC (1 container statuses recorded)
Mar 19 10:09:15.344: INFO: 	Container node-exporter ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.158d5446fb192efd], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:09:16.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-z2cnn" for this suite.
Mar 19 10:09:22.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:09:22.536: INFO: namespace: e2e-tests-sched-pred-z2cnn, resource: bindings, ignored listing per whitelist
Mar 19 10:09:22.595: INFO: namespace e2e-tests-sched-pred-z2cnn deletion completed in 6.205612417s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:7.395 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:09:22.596: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 10:09:24.728: INFO: Waiting up to 5m0s for pod "client-envvars-12954a27-4a2f-11e9-989b-da33bd6188b3" in namespace "e2e-tests-pods-7bz8v" to be "success or failure"
Mar 19 10:09:24.734: INFO: Pod "client-envvars-12954a27-4a2f-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.88855ms
Mar 19 10:09:26.740: INFO: Pod "client-envvars-12954a27-4a2f-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01153979s
STEP: Saw pod success
Mar 19 10:09:26.740: INFO: Pod "client-envvars-12954a27-4a2f-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:09:26.745: INFO: Trying to get logs from node k8s-node-vm1y1w-lkllt8nnod pod client-envvars-12954a27-4a2f-11e9-989b-da33bd6188b3 container env3cont: <nil>
STEP: delete the pod
Mar 19 10:09:26.783: INFO: Waiting for pod client-envvars-12954a27-4a2f-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:09:26.789: INFO: Pod client-envvars-12954a27-4a2f-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:09:26.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-7bz8v" for this suite.
Mar 19 10:10:14.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:10:14.979: INFO: namespace: e2e-tests-pods-7bz8v, resource: bindings, ignored listing per whitelist
Mar 19 10:10:15.002: INFO: namespace e2e-tests-pods-7bz8v deletion completed in 48.204078644s

• [SLOW TEST:52.406 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:10:15.002: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-309b10f7-4a2f-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume configMaps
Mar 19 10:10:15.111: INFO: Waiting up to 5m0s for pod "pod-configmaps-309c4eee-4a2f-11e9-989b-da33bd6188b3" in namespace "e2e-tests-configmap-sdm84" to be "success or failure"
Mar 19 10:10:15.116: INFO: Pod "pod-configmaps-309c4eee-4a2f-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.739531ms
Mar 19 10:10:17.121: INFO: Pod "pod-configmaps-309c4eee-4a2f-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010275404s
STEP: Saw pod success
Mar 19 10:10:17.121: INFO: Pod "pod-configmaps-309c4eee-4a2f-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:10:17.126: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod pod-configmaps-309c4eee-4a2f-11e9-989b-da33bd6188b3 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 19 10:10:17.160: INFO: Waiting for pod pod-configmaps-309c4eee-4a2f-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:10:17.165: INFO: Pod pod-configmaps-309c4eee-4a2f-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:10:17.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-sdm84" for this suite.
Mar 19 10:10:23.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:10:23.216: INFO: namespace: e2e-tests-configmap-sdm84, resource: bindings, ignored listing per whitelist
Mar 19 10:10:23.391: INFO: namespace e2e-tests-configmap-sdm84 deletion completed in 6.214348896s

• [SLOW TEST:8.388 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:10:23.391: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-vh5w5
Mar 19 10:10:25.499: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-vh5w5
STEP: checking the pod's current state and verifying that restartCount is present
Mar 19 10:10:25.505: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:14:26.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-vh5w5" for this suite.
Mar 19 10:14:32.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:14:32.365: INFO: namespace: e2e-tests-container-probe-vh5w5, resource: bindings, ignored listing per whitelist
Mar 19 10:14:32.443: INFO: namespace e2e-tests-container-probe-vh5w5 deletion completed in 6.208005328s

• [SLOW TEST:249.053 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:14:32.443: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Mar 19 10:14:32.560: INFO: Waiting up to 5m0s for pod "client-containers-ca0f769a-4a2f-11e9-989b-da33bd6188b3" in namespace "e2e-tests-containers-fnl2v" to be "success or failure"
Mar 19 10:14:32.568: INFO: Pod "client-containers-ca0f769a-4a2f-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.992235ms
Mar 19 10:14:34.574: INFO: Pod "client-containers-ca0f769a-4a2f-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01376509s
STEP: Saw pod success
Mar 19 10:14:34.574: INFO: Pod "client-containers-ca0f769a-4a2f-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:14:34.578: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod client-containers-ca0f769a-4a2f-11e9-989b-da33bd6188b3 container test-container: <nil>
STEP: delete the pod
Mar 19 10:14:34.616: INFO: Waiting for pod client-containers-ca0f769a-4a2f-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:14:34.621: INFO: Pod client-containers-ca0f769a-4a2f-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:14:34.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-fnl2v" for this suite.
Mar 19 10:14:40.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:14:40.722: INFO: namespace: e2e-tests-containers-fnl2v, resource: bindings, ignored listing per whitelist
Mar 19 10:14:40.833: INFO: namespace e2e-tests-containers-fnl2v deletion completed in 6.202252501s

• [SLOW TEST:8.389 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:14:40.833: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar 19 10:14:44.994: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 19 10:14:44.999: INFO: Pod pod-with-poststart-http-hook still exists
Mar 19 10:14:46.999: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 19 10:14:47.005: INFO: Pod pod-with-poststart-http-hook still exists
Mar 19 10:14:48.999: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 19 10:14:49.004: INFO: Pod pod-with-poststart-http-hook still exists
Mar 19 10:14:50.999: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 19 10:14:51.005: INFO: Pod pod-with-poststart-http-hook still exists
Mar 19 10:14:52.999: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 19 10:14:53.005: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:14:53.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-qmkzg" for this suite.
Mar 19 10:15:15.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:15:15.157: INFO: namespace: e2e-tests-container-lifecycle-hook-qmkzg, resource: bindings, ignored listing per whitelist
Mar 19 10:15:15.224: INFO: namespace e2e-tests-container-lifecycle-hook-qmkzg deletion completed in 22.210055108s

• [SLOW TEST:34.391 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:15:15.225: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar 19 10:15:15.322: INFO: Waiting up to 5m0s for pod "pod-e38ce91f-4a2f-11e9-989b-da33bd6188b3" in namespace "e2e-tests-emptydir-cm8pw" to be "success or failure"
Mar 19 10:15:15.327: INFO: Pod "pod-e38ce91f-4a2f-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.717426ms
Mar 19 10:15:17.332: INFO: Pod "pod-e38ce91f-4a2f-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01025874s
STEP: Saw pod success
Mar 19 10:15:17.332: INFO: Pod "pod-e38ce91f-4a2f-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:15:17.337: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod pod-e38ce91f-4a2f-11e9-989b-da33bd6188b3 container test-container: <nil>
STEP: delete the pod
Mar 19 10:15:17.371: INFO: Waiting for pod pod-e38ce91f-4a2f-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:15:17.376: INFO: Pod pod-e38ce91f-4a2f-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:15:17.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cm8pw" for this suite.
Mar 19 10:15:23.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:15:23.553: INFO: namespace: e2e-tests-emptydir-cm8pw, resource: bindings, ignored listing per whitelist
Mar 19 10:15:23.585: INFO: namespace e2e-tests-emptydir-cm8pw deletion completed in 6.201268423s

• [SLOW TEST:8.360 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:15:23.585: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 10:15:23.665: INFO: Creating ReplicaSet my-hostname-basic-e8880517-4a2f-11e9-989b-da33bd6188b3
Mar 19 10:15:23.676: INFO: Pod name my-hostname-basic-e8880517-4a2f-11e9-989b-da33bd6188b3: Found 0 pods out of 1
Mar 19 10:15:28.682: INFO: Pod name my-hostname-basic-e8880517-4a2f-11e9-989b-da33bd6188b3: Found 1 pods out of 1
Mar 19 10:15:28.682: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-e8880517-4a2f-11e9-989b-da33bd6188b3" is running
Mar 19 10:15:28.686: INFO: Pod "my-hostname-basic-e8880517-4a2f-11e9-989b-da33bd6188b3-vdl8l" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-19 10:15:23 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-19 10:15:25 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-19 10:15:25 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-19 10:14:30 +0000 UTC Reason: Message:}])
Mar 19 10:15:28.687: INFO: Trying to dial the pod
Mar 19 10:15:33.705: INFO: Controller my-hostname-basic-e8880517-4a2f-11e9-989b-da33bd6188b3: Got expected result from replica 1 [my-hostname-basic-e8880517-4a2f-11e9-989b-da33bd6188b3-vdl8l]: "my-hostname-basic-e8880517-4a2f-11e9-989b-da33bd6188b3-vdl8l", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:15:33.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-tmdnh" for this suite.
Mar 19 10:15:39.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:15:39.825: INFO: namespace: e2e-tests-replicaset-tmdnh, resource: bindings, ignored listing per whitelist
Mar 19 10:15:39.916: INFO: namespace e2e-tests-replicaset-tmdnh deletion completed in 6.201694393s

• [SLOW TEST:16.331 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:15:39.917: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 10:15:40.017: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f244de84-4a2f-11e9-989b-da33bd6188b3" in namespace "e2e-tests-downward-api-rzg7g" to be "success or failure"
Mar 19 10:15:40.024: INFO: Pod "downwardapi-volume-f244de84-4a2f-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.863188ms
Mar 19 10:15:42.030: INFO: Pod "downwardapi-volume-f244de84-4a2f-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012876142s
STEP: Saw pod success
Mar 19 10:15:42.030: INFO: Pod "downwardapi-volume-f244de84-4a2f-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:15:42.038: INFO: Trying to get logs from node k8s-node-vm1y1w-lkllt8nnod pod downwardapi-volume-f244de84-4a2f-11e9-989b-da33bd6188b3 container client-container: <nil>
STEP: delete the pod
Mar 19 10:15:42.075: INFO: Waiting for pod downwardapi-volume-f244de84-4a2f-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:15:42.080: INFO: Pod downwardapi-volume-f244de84-4a2f-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:15:42.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rzg7g" for this suite.
Mar 19 10:15:48.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:15:48.244: INFO: namespace: e2e-tests-downward-api-rzg7g, resource: bindings, ignored listing per whitelist
Mar 19 10:15:48.293: INFO: namespace e2e-tests-downward-api-rzg7g deletion completed in 6.202474663s

• [SLOW TEST:8.376 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:15:48.293: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 19 10:15:48.386: INFO: Waiting up to 5m0s for pod "downward-api-f74210f0-4a2f-11e9-989b-da33bd6188b3" in namespace "e2e-tests-downward-api-sjw67" to be "success or failure"
Mar 19 10:15:48.391: INFO: Pod "downward-api-f74210f0-4a2f-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.231354ms
Mar 19 10:15:50.397: INFO: Pod "downward-api-f74210f0-4a2f-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011100739s
STEP: Saw pod success
Mar 19 10:15:50.397: INFO: Pod "downward-api-f74210f0-4a2f-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:15:50.402: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod downward-api-f74210f0-4a2f-11e9-989b-da33bd6188b3 container dapi-container: <nil>
STEP: delete the pod
Mar 19 10:15:50.439: INFO: Waiting for pod downward-api-f74210f0-4a2f-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:15:50.444: INFO: Pod downward-api-f74210f0-4a2f-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:15:50.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-sjw67" for this suite.
Mar 19 10:15:56.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:15:56.604: INFO: namespace: e2e-tests-downward-api-sjw67, resource: bindings, ignored listing per whitelist
Mar 19 10:15:56.653: INFO: namespace e2e-tests-downward-api-sjw67 deletion completed in 6.199871723s

• [SLOW TEST:8.361 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:15:56.654: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-fc3ee1b8-4a2f-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume secrets
Mar 19 10:15:56.760: INFO: Waiting up to 5m0s for pod "pod-secrets-fc3fd284-4a2f-11e9-989b-da33bd6188b3" in namespace "e2e-tests-secrets-2kqh9" to be "success or failure"
Mar 19 10:15:56.765: INFO: Pod "pod-secrets-fc3fd284-4a2f-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.780692ms
Mar 19 10:15:58.771: INFO: Pod "pod-secrets-fc3fd284-4a2f-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010578194s
STEP: Saw pod success
Mar 19 10:15:58.771: INFO: Pod "pod-secrets-fc3fd284-4a2f-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:15:58.776: INFO: Trying to get logs from node k8s-node-vmwvcc-lkllt8nnod pod pod-secrets-fc3fd284-4a2f-11e9-989b-da33bd6188b3 container secret-env-test: <nil>
STEP: delete the pod
Mar 19 10:15:58.813: INFO: Waiting for pod pod-secrets-fc3fd284-4a2f-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:15:58.819: INFO: Pod pod-secrets-fc3fd284-4a2f-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:15:58.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2kqh9" for this suite.
Mar 19 10:16:04.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:16:04.988: INFO: namespace: e2e-tests-secrets-2kqh9, resource: bindings, ignored listing per whitelist
Mar 19 10:16:05.035: INFO: namespace e2e-tests-secrets-2kqh9 deletion completed in 6.206357866s

• [SLOW TEST:8.382 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:16:05.035: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-r9vpv/configmap-test-013cf11e-4a30-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume configMaps
Mar 19 10:16:05.139: INFO: Waiting up to 5m0s for pod "pod-configmaps-013e66bb-4a30-11e9-989b-da33bd6188b3" in namespace "e2e-tests-configmap-r9vpv" to be "success or failure"
Mar 19 10:16:05.145: INFO: Pod "pod-configmaps-013e66bb-4a30-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.782131ms
Mar 19 10:16:07.152: INFO: Pod "pod-configmaps-013e66bb-4a30-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012907826s
STEP: Saw pod success
Mar 19 10:16:07.152: INFO: Pod "pod-configmaps-013e66bb-4a30-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:16:07.157: INFO: Trying to get logs from node k8s-node-vm1y1w-lkllt8nnod pod pod-configmaps-013e66bb-4a30-11e9-989b-da33bd6188b3 container env-test: <nil>
STEP: delete the pod
Mar 19 10:16:07.198: INFO: Waiting for pod pod-configmaps-013e66bb-4a30-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:16:07.206: INFO: Pod pod-configmaps-013e66bb-4a30-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:16:07.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-r9vpv" for this suite.
Mar 19 10:16:13.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:16:13.350: INFO: namespace: e2e-tests-configmap-r9vpv, resource: bindings, ignored listing per whitelist
Mar 19 10:16:13.421: INFO: namespace e2e-tests-configmap-r9vpv deletion completed in 6.205399811s

• [SLOW TEST:8.386 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:16:13.421: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar 19 10:16:16.057: INFO: Successfully updated pod "pod-update-063db62b-4a30-11e9-989b-da33bd6188b3"
STEP: verifying the updated pod is in kubernetes
Mar 19 10:16:16.067: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:16:16.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-nqdhg" for this suite.
Mar 19 10:16:38.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:16:38.222: INFO: namespace: e2e-tests-pods-nqdhg, resource: bindings, ignored listing per whitelist
Mar 19 10:16:38.281: INFO: namespace e2e-tests-pods-nqdhg deletion completed in 22.205041823s

• [SLOW TEST:24.860 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:16:38.281: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-150f0886-4a30-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume secrets
Mar 19 10:16:38.389: INFO: Waiting up to 5m0s for pod "pod-secrets-150ff7b0-4a30-11e9-989b-da33bd6188b3" in namespace "e2e-tests-secrets-92996" to be "success or failure"
Mar 19 10:16:38.394: INFO: Pod "pod-secrets-150ff7b0-4a30-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.605993ms
Mar 19 10:16:40.400: INFO: Pod "pod-secrets-150ff7b0-4a30-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010591983s
STEP: Saw pod success
Mar 19 10:16:40.400: INFO: Pod "pod-secrets-150ff7b0-4a30-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:16:40.404: INFO: Trying to get logs from node k8s-node-vmwvcc-lkllt8nnod pod pod-secrets-150ff7b0-4a30-11e9-989b-da33bd6188b3 container secret-volume-test: <nil>
STEP: delete the pod
Mar 19 10:16:40.440: INFO: Waiting for pod pod-secrets-150ff7b0-4a30-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:16:40.445: INFO: Pod pod-secrets-150ff7b0-4a30-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:16:40.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-92996" for this suite.
Mar 19 10:16:46.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:16:46.521: INFO: namespace: e2e-tests-secrets-92996, resource: bindings, ignored listing per whitelist
Mar 19 10:16:46.658: INFO: namespace e2e-tests-secrets-92996 deletion completed in 6.203686158s

• [SLOW TEST:8.377 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:16:46.658: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Mar 19 10:16:46.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 create -f - --namespace=e2e-tests-kubectl-xzsx8'
Mar 19 10:16:47.076: INFO: stderr: ""
Mar 19 10:16:47.076: INFO: stdout: "pod/pause created\n"
Mar 19 10:16:47.076: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Mar 19 10:16:47.076: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-xzsx8" to be "running and ready"
Mar 19 10:16:47.081: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.930658ms
Mar 19 10:16:49.087: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.011364497s
Mar 19 10:16:49.087: INFO: Pod "pause" satisfied condition "running and ready"
Mar 19 10:16:49.087: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Mar 19 10:16:49.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-xzsx8'
Mar 19 10:16:49.179: INFO: stderr: ""
Mar 19 10:16:49.179: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Mar 19 10:16:49.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pod pause -L testing-label --namespace=e2e-tests-kubectl-xzsx8'
Mar 19 10:16:49.251: INFO: stderr: ""
Mar 19 10:16:49.251: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          9s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Mar 19 10:16:49.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 label pods pause testing-label- --namespace=e2e-tests-kubectl-xzsx8'
Mar 19 10:16:49.320: INFO: stderr: ""
Mar 19 10:16:49.320: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Mar 19 10:16:49.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pod pause -L testing-label --namespace=e2e-tests-kubectl-xzsx8'
Mar 19 10:16:49.390: INFO: stderr: ""
Mar 19 10:16:49.390: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          1s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Mar 19 10:16:49.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-xzsx8'
Mar 19 10:16:49.472: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 19 10:16:49.472: INFO: stdout: "pod \"pause\" force deleted\n"
Mar 19 10:16:49.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-xzsx8'
Mar 19 10:16:49.548: INFO: stderr: "No resources found.\n"
Mar 19 10:16:49.548: INFO: stdout: ""
Mar 19 10:16:49.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods -l name=pause --namespace=e2e-tests-kubectl-xzsx8 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 19 10:16:49.619: INFO: stderr: ""
Mar 19 10:16:49.619: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:16:49.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xzsx8" for this suite.
Mar 19 10:16:55.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:16:55.812: INFO: namespace: e2e-tests-kubectl-xzsx8, resource: bindings, ignored listing per whitelist
Mar 19 10:16:55.831: INFO: namespace e2e-tests-kubectl-xzsx8 deletion completed in 6.201981467s

• [SLOW TEST:9.172 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:16:55.831: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Mar 19 10:16:57.959: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-1f8489f5-4a30-11e9-989b-da33bd6188b3", GenerateName:"", Namespace:"e2e-tests-pods-752kf", SelfLink:"/api/v1/namespaces/e2e-tests-pods-752kf/pods/pod-submit-remove-1f8489f5-4a30-11e9-989b-da33bd6188b3", UID:"0111541e-4a30-11e9-b857-fa163eaabeb9", ResourceVersion:"1195694", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63688587364, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"917622026"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-bmj4m", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc420e47440), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-bmj4m", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc42193de68), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k8s-node-vmepd8-lkllt8nnod", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc42029d560), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc42193dea0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc42193def0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688587415, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688587416, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688587416, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688587362, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.16.128.14", PodIP:"172.16.0.41", StartTime:(*v1.Time)(0xc421cf5f20), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc421cf5f80), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d", ContainerID:"docker://2d47c86777bf851b9d3276aaaa90613ba4554cb038b11b7417253bd05e638206"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:17:05.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-752kf" for this suite.
Mar 19 10:17:11.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:17:11.858: INFO: namespace: e2e-tests-pods-752kf, resource: bindings, ignored listing per whitelist
Mar 19 10:17:11.951: INFO: namespace e2e-tests-pods-752kf deletion completed in 6.205766719s

• [SLOW TEST:16.120 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:17:11.951: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 10:17:12.053: INFO: Waiting up to 5m0s for pod "downwardapi-volume-29200aeb-4a30-11e9-989b-da33bd6188b3" in namespace "e2e-tests-projected-jpg49" to be "success or failure"
Mar 19 10:17:12.057: INFO: Pod "downwardapi-volume-29200aeb-4a30-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.702489ms
Mar 19 10:17:14.063: INFO: Pod "downwardapi-volume-29200aeb-4a30-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010511357s
STEP: Saw pod success
Mar 19 10:17:14.063: INFO: Pod "downwardapi-volume-29200aeb-4a30-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:17:14.068: INFO: Trying to get logs from node k8s-node-vmwvcc-lkllt8nnod pod downwardapi-volume-29200aeb-4a30-11e9-989b-da33bd6188b3 container client-container: <nil>
STEP: delete the pod
Mar 19 10:17:14.105: INFO: Waiting for pod downwardapi-volume-29200aeb-4a30-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:17:14.109: INFO: Pod downwardapi-volume-29200aeb-4a30-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:17:14.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jpg49" for this suite.
Mar 19 10:17:20.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:17:20.243: INFO: namespace: e2e-tests-projected-jpg49, resource: bindings, ignored listing per whitelist
Mar 19 10:17:20.319: INFO: namespace e2e-tests-projected-jpg49 deletion completed in 6.202510927s

• [SLOW TEST:8.368 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:17:20.319: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-2e1d9df8-4a30-11e9-989b-da33bd6188b3
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:17:22.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9bzs2" for this suite.
Mar 19 10:17:44.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:17:44.601: INFO: namespace: e2e-tests-configmap-9bzs2, resource: bindings, ignored listing per whitelist
Mar 19 10:17:44.699: INFO: namespace e2e-tests-configmap-9bzs2 deletion completed in 22.20946487s

• [SLOW TEST:24.380 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:17:44.699: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Mar 19 10:17:44.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 create -f - --namespace=e2e-tests-kubectl-hcftj'
Mar 19 10:17:44.958: INFO: stderr: ""
Mar 19 10:17:44.958: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar 19 10:17:45.964: INFO: Selector matched 1 pods for map[app:redis]
Mar 19 10:17:45.964: INFO: Found 1 / 1
Mar 19 10:17:45.964: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Mar 19 10:17:45.969: INFO: Selector matched 1 pods for map[app:redis]
Mar 19 10:17:45.969: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 19 10:17:45.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 patch pod redis-master-chzcw --namespace=e2e-tests-kubectl-hcftj -p {"metadata":{"annotations":{"x":"y"}}}'
Mar 19 10:17:46.043: INFO: stderr: ""
Mar 19 10:17:46.043: INFO: stdout: "pod/redis-master-chzcw patched\n"
STEP: checking annotations
Mar 19 10:17:46.048: INFO: Selector matched 1 pods for map[app:redis]
Mar 19 10:17:46.048: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:17:46.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hcftj" for this suite.
Mar 19 10:18:08.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:18:08.102: INFO: namespace: e2e-tests-kubectl-hcftj, resource: bindings, ignored listing per whitelist
Mar 19 10:18:08.266: INFO: namespace e2e-tests-kubectl-hcftj deletion completed in 22.20651388s

• [SLOW TEST:23.567 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:18:08.266: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Mar 19 10:18:08.370: INFO: Waiting up to 5m0s for pod "client-containers-4ab1d04f-4a30-11e9-989b-da33bd6188b3" in namespace "e2e-tests-containers-42mn6" to be "success or failure"
Mar 19 10:18:08.381: INFO: Pod "client-containers-4ab1d04f-4a30-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.72345ms
Mar 19 10:18:10.387: INFO: Pod "client-containers-4ab1d04f-4a30-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01664023s
STEP: Saw pod success
Mar 19 10:18:10.387: INFO: Pod "client-containers-4ab1d04f-4a30-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:18:10.391: INFO: Trying to get logs from node k8s-node-vm1y1w-lkllt8nnod pod client-containers-4ab1d04f-4a30-11e9-989b-da33bd6188b3 container test-container: <nil>
STEP: delete the pod
Mar 19 10:18:10.429: INFO: Waiting for pod client-containers-4ab1d04f-4a30-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:18:10.433: INFO: Pod client-containers-4ab1d04f-4a30-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:18:10.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-42mn6" for this suite.
Mar 19 10:18:16.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:18:16.636: INFO: namespace: e2e-tests-containers-42mn6, resource: bindings, ignored listing per whitelist
Mar 19 10:18:16.650: INFO: namespace e2e-tests-containers-42mn6 deletion completed in 6.206834648s

• [SLOW TEST:8.384 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:18:16.650: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-4faf4189-4a30-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume secrets
Mar 19 10:18:16.749: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4fb0401d-4a30-11e9-989b-da33bd6188b3" in namespace "e2e-tests-projected-98jzz" to be "success or failure"
Mar 19 10:18:16.754: INFO: Pod "pod-projected-secrets-4fb0401d-4a30-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.804032ms
Mar 19 10:18:18.760: INFO: Pod "pod-projected-secrets-4fb0401d-4a30-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010825519s
STEP: Saw pod success
Mar 19 10:18:18.760: INFO: Pod "pod-projected-secrets-4fb0401d-4a30-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:18:18.765: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod pod-projected-secrets-4fb0401d-4a30-11e9-989b-da33bd6188b3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 19 10:18:18.800: INFO: Waiting for pod pod-projected-secrets-4fb0401d-4a30-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:18:18.805: INFO: Pod pod-projected-secrets-4fb0401d-4a30-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:18:18.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-98jzz" for this suite.
Mar 19 10:18:24.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:18:24.849: INFO: namespace: e2e-tests-projected-98jzz, resource: bindings, ignored listing per whitelist
Mar 19 10:18:25.017: INFO: namespace e2e-tests-projected-98jzz deletion completed in 6.201958219s

• [SLOW TEST:8.367 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:18:25.017: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-dj6rl
Mar 19 10:18:27.127: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-dj6rl
STEP: checking the pod's current state and verifying that restartCount is present
Mar 19 10:18:27.132: INFO: Initial restart count of pod liveness-http is 0
Mar 19 10:18:43.183: INFO: Restart count of pod e2e-tests-container-probe-dj6rl/liveness-http is now 1 (16.051405877s elapsed)
Mar 19 10:19:05.247: INFO: Restart count of pod e2e-tests-container-probe-dj6rl/liveness-http is now 2 (38.11550089s elapsed)
Mar 19 10:19:25.307: INFO: Restart count of pod e2e-tests-container-probe-dj6rl/liveness-http is now 3 (58.174691798s elapsed)
Mar 19 10:19:45.365: INFO: Restart count of pod e2e-tests-container-probe-dj6rl/liveness-http is now 4 (1m18.232729507s elapsed)
Mar 19 10:20:53.567: INFO: Restart count of pod e2e-tests-container-probe-dj6rl/liveness-http is now 5 (2m26.434813586s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:20:53.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-dj6rl" for this suite.
Mar 19 10:20:59.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:20:59.739: INFO: namespace: e2e-tests-container-probe-dj6rl, resource: bindings, ignored listing per whitelist
Mar 19 10:20:59.802: INFO: namespace e2e-tests-container-probe-dj6rl deletion completed in 6.206452236s

• [SLOW TEST:154.785 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:20:59.802: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Mar 19 10:20:59.903: INFO: Waiting up to 5m0s for pod "pod-b0efbc4d-4a30-11e9-989b-da33bd6188b3" in namespace "e2e-tests-emptydir-r2cd5" to be "success or failure"
Mar 19 10:20:59.908: INFO: Pod "pod-b0efbc4d-4a30-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.979736ms
Mar 19 10:21:01.914: INFO: Pod "pod-b0efbc4d-4a30-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010616685s
STEP: Saw pod success
Mar 19 10:21:01.914: INFO: Pod "pod-b0efbc4d-4a30-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:21:01.921: INFO: Trying to get logs from node k8s-node-vm1y1w-lkllt8nnod pod pod-b0efbc4d-4a30-11e9-989b-da33bd6188b3 container test-container: <nil>
STEP: delete the pod
Mar 19 10:21:01.959: INFO: Waiting for pod pod-b0efbc4d-4a30-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:21:01.963: INFO: Pod pod-b0efbc4d-4a30-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:21:01.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-r2cd5" for this suite.
Mar 19 10:21:08.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:21:08.168: INFO: namespace: e2e-tests-emptydir-r2cd5, resource: bindings, ignored listing per whitelist
Mar 19 10:21:08.183: INFO: namespace e2e-tests-emptydir-r2cd5 deletion completed in 6.210444559s

• [SLOW TEST:8.381 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:21:08.183: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0319 10:21:18.380601      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 19 10:21:18.380: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:21:18.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-6q52z" for this suite.
Mar 19 10:21:24.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:21:24.422: INFO: namespace: e2e-tests-gc-6q52z, resource: bindings, ignored listing per whitelist
Mar 19 10:21:24.602: INFO: namespace e2e-tests-gc-6q52z deletion completed in 6.21500192s

• [SLOW TEST:16.419 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:21:24.602: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 10:21:24.704: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bfb7f3cf-4a30-11e9-989b-da33bd6188b3" in namespace "e2e-tests-downward-api-gtzsl" to be "success or failure"
Mar 19 10:21:24.709: INFO: Pod "downwardapi-volume-bfb7f3cf-4a30-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.780707ms
Mar 19 10:21:26.715: INFO: Pod "downwardapi-volume-bfb7f3cf-4a30-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01066633s
STEP: Saw pod success
Mar 19 10:21:26.715: INFO: Pod "downwardapi-volume-bfb7f3cf-4a30-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:21:26.720: INFO: Trying to get logs from node k8s-node-vmwvcc-lkllt8nnod pod downwardapi-volume-bfb7f3cf-4a30-11e9-989b-da33bd6188b3 container client-container: <nil>
STEP: delete the pod
Mar 19 10:21:26.756: INFO: Waiting for pod downwardapi-volume-bfb7f3cf-4a30-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:21:26.761: INFO: Pod downwardapi-volume-bfb7f3cf-4a30-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:21:26.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-gtzsl" for this suite.
Mar 19 10:21:32.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:21:32.914: INFO: namespace: e2e-tests-downward-api-gtzsl, resource: bindings, ignored listing per whitelist
Mar 19 10:21:32.974: INFO: namespace e2e-tests-downward-api-gtzsl deletion completed in 6.203860043s

• [SLOW TEST:8.371 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:21:32.974: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Mar 19 10:21:33.052: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Mar 19 10:21:33.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 create -f - --namespace=e2e-tests-kubectl-w5k84'
Mar 19 10:21:33.230: INFO: stderr: ""
Mar 19 10:21:33.230: INFO: stdout: "service/redis-slave created\n"
Mar 19 10:21:33.230: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Mar 19 10:21:33.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 create -f - --namespace=e2e-tests-kubectl-w5k84'
Mar 19 10:21:33.397: INFO: stderr: ""
Mar 19 10:21:33.397: INFO: stdout: "service/redis-master created\n"
Mar 19 10:21:33.397: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Mar 19 10:21:33.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 create -f - --namespace=e2e-tests-kubectl-w5k84'
Mar 19 10:21:33.594: INFO: stderr: ""
Mar 19 10:21:33.594: INFO: stdout: "service/frontend created\n"
Mar 19 10:21:33.595: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Mar 19 10:21:33.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 create -f - --namespace=e2e-tests-kubectl-w5k84'
Mar 19 10:21:33.752: INFO: stderr: ""
Mar 19 10:21:33.752: INFO: stdout: "deployment.extensions/frontend created\n"
Mar 19 10:21:33.752: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Mar 19 10:21:33.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 create -f - --namespace=e2e-tests-kubectl-w5k84'
Mar 19 10:21:33.904: INFO: stderr: ""
Mar 19 10:21:33.904: INFO: stdout: "deployment.extensions/redis-master created\n"
Mar 19 10:21:33.904: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Mar 19 10:21:33.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 create -f - --namespace=e2e-tests-kubectl-w5k84'
Mar 19 10:21:34.069: INFO: stderr: ""
Mar 19 10:21:34.069: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Mar 19 10:21:34.069: INFO: Waiting for all frontend pods to be Running.
Mar 19 10:21:39.120: INFO: Waiting for frontend to serve content.
Mar 19 10:21:39.136: INFO: Trying to add a new entry to the guestbook.
Mar 19 10:21:39.156: INFO: Verifying that added entry can be retrieved.
Mar 19 10:21:39.180: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Mar 19 10:21:44.204: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Mar 19 10:21:49.222: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Mar 19 10:21:54.247: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Mar 19 10:21:59.262: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Mar 19 10:22:04.280: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Mar 19 10:22:09.306: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Mar 19 10:22:14.330: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Mar 19 10:22:19.348: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Mar 19 10:22:24.365: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Mar 19 10:22:29.385: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Mar 19 10:22:34.403: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Mar 19 10:22:39.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-w5k84'
Mar 19 10:22:39.547: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 19 10:22:39.547: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Mar 19 10:22:39.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-w5k84'
Mar 19 10:22:39.659: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 19 10:22:39.659: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar 19 10:22:39.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-w5k84'
Mar 19 10:22:39.788: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 19 10:22:39.788: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar 19 10:22:39.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-w5k84'
Mar 19 10:22:39.867: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 19 10:22:39.867: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar 19 10:22:39.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-w5k84'
Mar 19 10:22:39.954: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 19 10:22:39.954: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar 19 10:22:39.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-w5k84'
Mar 19 10:22:40.054: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 19 10:22:40.054: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:22:40.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-w5k84" for this suite.
Mar 19 10:23:20.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:23:20.141: INFO: namespace: e2e-tests-kubectl-w5k84, resource: bindings, ignored listing per whitelist
Mar 19 10:23:20.273: INFO: namespace e2e-tests-kubectl-w5k84 deletion completed in 40.205775723s

• [SLOW TEST:107.299 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:23:20.273: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0319 10:23:21.451471      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 19 10:23:21.451: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:23:21.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-2h7s5" for this suite.
Mar 19 10:23:27.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:23:27.611: INFO: namespace: e2e-tests-gc-2h7s5, resource: bindings, ignored listing per whitelist
Mar 19 10:23:27.658: INFO: namespace e2e-tests-gc-2h7s5 deletion completed in 6.199142821s

• [SLOW TEST:7.385 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:23:27.658: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 19 10:23:27.751: INFO: Waiting up to 5m0s for pod "downward-api-090f983c-4a31-11e9-989b-da33bd6188b3" in namespace "e2e-tests-downward-api-8626k" to be "success or failure"
Mar 19 10:23:27.756: INFO: Pod "downward-api-090f983c-4a31-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.661579ms
Mar 19 10:23:29.762: INFO: Pod "downward-api-090f983c-4a31-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010858461s
STEP: Saw pod success
Mar 19 10:23:29.762: INFO: Pod "downward-api-090f983c-4a31-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:23:29.767: INFO: Trying to get logs from node k8s-node-vmwvcc-lkllt8nnod pod downward-api-090f983c-4a31-11e9-989b-da33bd6188b3 container dapi-container: <nil>
STEP: delete the pod
Mar 19 10:23:29.804: INFO: Waiting for pod downward-api-090f983c-4a31-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:23:29.809: INFO: Pod downward-api-090f983c-4a31-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:23:29.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8626k" for this suite.
Mar 19 10:23:35.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:23:36.011: INFO: namespace: e2e-tests-downward-api-8626k, resource: bindings, ignored listing per whitelist
Mar 19 10:23:36.024: INFO: namespace e2e-tests-downward-api-8626k deletion completed in 6.205753238s

• [SLOW TEST:8.366 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:23:36.024: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-0e0e8b94-4a31-11e9-989b-da33bd6188b3
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-0e0e8b94-4a31-11e9-989b-da33bd6188b3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:24:44.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jn8x4" for this suite.
Mar 19 10:25:06.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:25:06.885: INFO: namespace: e2e-tests-projected-jn8x4, resource: bindings, ignored listing per whitelist
Mar 19 10:25:07.023: INFO: namespace e2e-tests-projected-jn8x4 deletion completed in 22.210197867s

• [SLOW TEST:90.999 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:25:07.023: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 10:25:07.124: INFO: Waiting up to 5m0s for pod "downwardapi-volume-444a9d4f-4a31-11e9-989b-da33bd6188b3" in namespace "e2e-tests-projected-6jd9c" to be "success or failure"
Mar 19 10:25:07.129: INFO: Pod "downwardapi-volume-444a9d4f-4a31-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.774927ms
Mar 19 10:25:09.139: INFO: Pod "downwardapi-volume-444a9d4f-4a31-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014519119s
STEP: Saw pod success
Mar 19 10:25:09.139: INFO: Pod "downwardapi-volume-444a9d4f-4a31-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:25:09.167: INFO: Trying to get logs from node k8s-node-vmwvcc-lkllt8nnod pod downwardapi-volume-444a9d4f-4a31-11e9-989b-da33bd6188b3 container client-container: <nil>
STEP: delete the pod
Mar 19 10:25:09.206: INFO: Waiting for pod downwardapi-volume-444a9d4f-4a31-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:25:09.211: INFO: Pod downwardapi-volume-444a9d4f-4a31-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:25:09.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6jd9c" for this suite.
Mar 19 10:25:15.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:25:15.291: INFO: namespace: e2e-tests-projected-6jd9c, resource: bindings, ignored listing per whitelist
Mar 19 10:25:15.425: INFO: namespace e2e-tests-projected-6jd9c deletion completed in 6.204752534s

• [SLOW TEST:8.402 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:25:15.425: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-58tm9
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-58tm9 to expose endpoints map[]
Mar 19 10:25:15.530: INFO: Get endpoints failed (4.913142ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Mar 19 10:25:16.535: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-58tm9 exposes endpoints map[] (1.010572687s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-58tm9
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-58tm9 to expose endpoints map[pod1:[80]]
Mar 19 10:25:18.581: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-58tm9 exposes endpoints map[pod1:[80]] (2.031463719s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-58tm9
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-58tm9 to expose endpoints map[pod1:[80] pod2:[80]]
Mar 19 10:25:19.623: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-58tm9 exposes endpoints map[pod1:[80] pod2:[80]] (1.035558785s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-58tm9
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-58tm9 to expose endpoints map[pod2:[80]]
Mar 19 10:25:20.656: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-58tm9 exposes endpoints map[pod2:[80]] (1.021396643s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-58tm9
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-58tm9 to expose endpoints map[]
Mar 19 10:25:21.684: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-58tm9 exposes endpoints map[] (1.01202547s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:25:21.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-58tm9" for this suite.
Mar 19 10:25:43.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:25:43.808: INFO: namespace: e2e-tests-services-58tm9, resource: bindings, ignored listing per whitelist
Mar 19 10:25:43.948: INFO: namespace e2e-tests-services-58tm9 deletion completed in 22.204630822s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:28.522 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:25:43.948: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Mar 19 10:25:48.087: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xxt9m PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 10:25:48.087: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
Mar 19 10:25:48.189: INFO: Exec stderr: ""
Mar 19 10:25:48.189: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xxt9m PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 10:25:48.189: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
Mar 19 10:25:48.255: INFO: Exec stderr: ""
Mar 19 10:25:48.255: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xxt9m PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 10:25:48.255: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
Mar 19 10:25:48.331: INFO: Exec stderr: ""
Mar 19 10:25:48.331: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xxt9m PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 10:25:48.331: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
Mar 19 10:25:48.406: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Mar 19 10:25:48.406: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xxt9m PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 10:25:48.406: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
Mar 19 10:25:48.481: INFO: Exec stderr: ""
Mar 19 10:25:48.481: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xxt9m PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 10:25:48.481: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
Mar 19 10:25:48.542: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Mar 19 10:25:48.542: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xxt9m PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 10:25:48.542: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
Mar 19 10:25:48.627: INFO: Exec stderr: ""
Mar 19 10:25:48.627: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xxt9m PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 10:25:48.627: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
Mar 19 10:25:48.712: INFO: Exec stderr: ""
Mar 19 10:25:48.712: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xxt9m PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 10:25:48.712: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
Mar 19 10:25:48.798: INFO: Exec stderr: ""
Mar 19 10:25:48.798: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xxt9m PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 10:25:48.798: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
Mar 19 10:25:48.882: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:25:48.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-xxt9m" for this suite.
Mar 19 10:26:36.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:26:37.083: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-xxt9m, resource: bindings, ignored listing per whitelist
Mar 19 10:26:37.090: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-xxt9m deletion completed in 48.200403346s

• [SLOW TEST:53.142 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:26:37.090: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Mar 19 10:26:37.191: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-xp79p,SelfLink:/api/v1/namespaces/e2e-tests-watch-xp79p/configmaps/e2e-watch-test-configmap-a,UID:5b7e2e94-4a31-11e9-b857-fa163eaabeb9,ResourceVersion:1197584,Generation:0,CreationTimestamp:2019-03-19 10:25:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 19 10:26:37.191: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-xp79p,SelfLink:/api/v1/namespaces/e2e-tests-watch-xp79p/configmaps/e2e-watch-test-configmap-a,UID:5b7e2e94-4a31-11e9-b857-fa163eaabeb9,ResourceVersion:1197584,Generation:0,CreationTimestamp:2019-03-19 10:25:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Mar 19 10:26:47.208: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-xp79p,SelfLink:/api/v1/namespaces/e2e-tests-watch-xp79p/configmaps/e2e-watch-test-configmap-a,UID:5b7e2e94-4a31-11e9-b857-fa163eaabeb9,ResourceVersion:1197601,Generation:0,CreationTimestamp:2019-03-19 10:25:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar 19 10:26:47.208: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-xp79p,SelfLink:/api/v1/namespaces/e2e-tests-watch-xp79p/configmaps/e2e-watch-test-configmap-a,UID:5b7e2e94-4a31-11e9-b857-fa163eaabeb9,ResourceVersion:1197601,Generation:0,CreationTimestamp:2019-03-19 10:25:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Mar 19 10:26:57.226: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-xp79p,SelfLink:/api/v1/namespaces/e2e-tests-watch-xp79p/configmaps/e2e-watch-test-configmap-a,UID:5b7e2e94-4a31-11e9-b857-fa163eaabeb9,ResourceVersion:1197618,Generation:0,CreationTimestamp:2019-03-19 10:25:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 19 10:26:57.226: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-xp79p,SelfLink:/api/v1/namespaces/e2e-tests-watch-xp79p/configmaps/e2e-watch-test-configmap-a,UID:5b7e2e94-4a31-11e9-b857-fa163eaabeb9,ResourceVersion:1197618,Generation:0,CreationTimestamp:2019-03-19 10:25:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Mar 19 10:27:07.248: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-xp79p,SelfLink:/api/v1/namespaces/e2e-tests-watch-xp79p/configmaps/e2e-watch-test-configmap-a,UID:5b7e2e94-4a31-11e9-b857-fa163eaabeb9,ResourceVersion:1197635,Generation:0,CreationTimestamp:2019-03-19 10:25:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 19 10:27:07.248: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-xp79p,SelfLink:/api/v1/namespaces/e2e-tests-watch-xp79p/configmaps/e2e-watch-test-configmap-a,UID:5b7e2e94-4a31-11e9-b857-fa163eaabeb9,ResourceVersion:1197635,Generation:0,CreationTimestamp:2019-03-19 10:25:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Mar 19 10:27:17.262: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-xp79p,SelfLink:/api/v1/namespaces/e2e-tests-watch-xp79p/configmaps/e2e-watch-test-configmap-b,UID:735f34a8-4a31-11e9-b857-fa163eaabeb9,ResourceVersion:1197653,Generation:0,CreationTimestamp:2019-03-19 10:26:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 19 10:27:17.262: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-xp79p,SelfLink:/api/v1/namespaces/e2e-tests-watch-xp79p/configmaps/e2e-watch-test-configmap-b,UID:735f34a8-4a31-11e9-b857-fa163eaabeb9,ResourceVersion:1197653,Generation:0,CreationTimestamp:2019-03-19 10:26:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Mar 19 10:27:27.284: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-xp79p,SelfLink:/api/v1/namespaces/e2e-tests-watch-xp79p/configmaps/e2e-watch-test-configmap-b,UID:735f34a8-4a31-11e9-b857-fa163eaabeb9,ResourceVersion:1197671,Generation:0,CreationTimestamp:2019-03-19 10:26:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 19 10:27:27.284: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-xp79p,SelfLink:/api/v1/namespaces/e2e-tests-watch-xp79p/configmaps/e2e-watch-test-configmap-b,UID:735f34a8-4a31-11e9-b857-fa163eaabeb9,ResourceVersion:1197671,Generation:0,CreationTimestamp:2019-03-19 10:26:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:27:37.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-xp79p" for this suite.
Mar 19 10:27:43.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:27:43.397: INFO: namespace: e2e-tests-watch-xp79p, resource: bindings, ignored listing per whitelist
Mar 19 10:27:43.503: INFO: namespace e2e-tests-watch-xp79p deletion completed in 6.208186327s

• [SLOW TEST:66.413 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:27:43.503: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-a1907f10-4a31-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume configMaps
Mar 19 10:27:43.619: INFO: Waiting up to 5m0s for pod "pod-configmaps-a191e6d6-4a31-11e9-989b-da33bd6188b3" in namespace "e2e-tests-configmap-n47hh" to be "success or failure"
Mar 19 10:27:43.623: INFO: Pod "pod-configmaps-a191e6d6-4a31-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.618403ms
Mar 19 10:27:45.629: INFO: Pod "pod-configmaps-a191e6d6-4a31-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01054065s
STEP: Saw pod success
Mar 19 10:27:45.629: INFO: Pod "pod-configmaps-a191e6d6-4a31-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:27:45.635: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod pod-configmaps-a191e6d6-4a31-11e9-989b-da33bd6188b3 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 19 10:27:45.671: INFO: Waiting for pod pod-configmaps-a191e6d6-4a31-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:27:45.676: INFO: Pod pod-configmaps-a191e6d6-4a31-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:27:45.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-n47hh" for this suite.
Mar 19 10:27:51.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:27:51.875: INFO: namespace: e2e-tests-configmap-n47hh, resource: bindings, ignored listing per whitelist
Mar 19 10:27:51.895: INFO: namespace e2e-tests-configmap-n47hh deletion completed in 6.209430966s

• [SLOW TEST:8.392 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:27:51.895: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-a68f0b87-4a31-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume configMaps
Mar 19 10:27:51.998: INFO: Waiting up to 5m0s for pod "pod-configmaps-a690647c-4a31-11e9-989b-da33bd6188b3" in namespace "e2e-tests-configmap-89rwq" to be "success or failure"
Mar 19 10:27:52.002: INFO: Pod "pod-configmaps-a690647c-4a31-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.839561ms
Mar 19 10:27:54.008: INFO: Pod "pod-configmaps-a690647c-4a31-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010704071s
STEP: Saw pod success
Mar 19 10:27:54.008: INFO: Pod "pod-configmaps-a690647c-4a31-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:27:54.013: INFO: Trying to get logs from node k8s-node-vmwvcc-lkllt8nnod pod pod-configmaps-a690647c-4a31-11e9-989b-da33bd6188b3 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 19 10:27:54.050: INFO: Waiting for pod pod-configmaps-a690647c-4a31-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:27:54.055: INFO: Pod pod-configmaps-a690647c-4a31-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:27:54.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-89rwq" for this suite.
Mar 19 10:28:00.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:28:00.247: INFO: namespace: e2e-tests-configmap-89rwq, resource: bindings, ignored listing per whitelist
Mar 19 10:28:00.269: INFO: namespace e2e-tests-configmap-89rwq deletion completed in 6.204436581s

• [SLOW TEST:8.374 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:28:00.269: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Mar 19 10:28:00.373: INFO: Waiting up to 5m0s for pod "var-expansion-ab8e43a9-4a31-11e9-989b-da33bd6188b3" in namespace "e2e-tests-var-expansion-7pqrm" to be "success or failure"
Mar 19 10:28:00.378: INFO: Pod "var-expansion-ab8e43a9-4a31-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.834249ms
Mar 19 10:28:02.384: INFO: Pod "var-expansion-ab8e43a9-4a31-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010629877s
STEP: Saw pod success
Mar 19 10:28:02.384: INFO: Pod "var-expansion-ab8e43a9-4a31-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:28:02.389: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod var-expansion-ab8e43a9-4a31-11e9-989b-da33bd6188b3 container dapi-container: <nil>
STEP: delete the pod
Mar 19 10:28:02.425: INFO: Waiting for pod var-expansion-ab8e43a9-4a31-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:28:02.430: INFO: Pod var-expansion-ab8e43a9-4a31-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:28:02.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-7pqrm" for this suite.
Mar 19 10:28:08.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:28:08.590: INFO: namespace: e2e-tests-var-expansion-7pqrm, resource: bindings, ignored listing per whitelist
Mar 19 10:28:08.645: INFO: namespace e2e-tests-var-expansion-7pqrm deletion completed in 6.207344788s

• [SLOW TEST:8.376 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:28:08.645: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 19 10:28:08.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-7g7bb'
Mar 19 10:28:09.006: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar 19 10:28:09.006: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Mar 19 10:28:11.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-7g7bb'
Mar 19 10:28:11.105: INFO: stderr: ""
Mar 19 10:28:11.105: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:28:11.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7g7bb" for this suite.
Mar 19 10:28:17.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:28:17.243: INFO: namespace: e2e-tests-kubectl-7g7bb, resource: bindings, ignored listing per whitelist
Mar 19 10:28:17.333: INFO: namespace e2e-tests-kubectl-7g7bb deletion completed in 6.218625794s

• [SLOW TEST:8.689 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:28:17.334: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 10:28:17.432: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b5b977e2-4a31-11e9-989b-da33bd6188b3" in namespace "e2e-tests-projected-nmkk5" to be "success or failure"
Mar 19 10:28:17.437: INFO: Pod "downwardapi-volume-b5b977e2-4a31-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.877506ms
Mar 19 10:28:19.443: INFO: Pod "downwardapi-volume-b5b977e2-4a31-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010574894s
STEP: Saw pod success
Mar 19 10:28:19.443: INFO: Pod "downwardapi-volume-b5b977e2-4a31-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:28:19.448: INFO: Trying to get logs from node k8s-node-vmwvcc-lkllt8nnod pod downwardapi-volume-b5b977e2-4a31-11e9-989b-da33bd6188b3 container client-container: <nil>
STEP: delete the pod
Mar 19 10:28:19.484: INFO: Waiting for pod downwardapi-volume-b5b977e2-4a31-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:28:19.489: INFO: Pod downwardapi-volume-b5b977e2-4a31-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:28:19.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nmkk5" for this suite.
Mar 19 10:28:25.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:28:25.630: INFO: namespace: e2e-tests-projected-nmkk5, resource: bindings, ignored listing per whitelist
Mar 19 10:28:25.701: INFO: namespace e2e-tests-projected-nmkk5 deletion completed in 6.202869247s

• [SLOW TEST:8.368 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:28:25.702: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar 19 10:28:25.793: INFO: Waiting up to 5m0s for pod "pod-bab52d07-4a31-11e9-989b-da33bd6188b3" in namespace "e2e-tests-emptydir-j8tv8" to be "success or failure"
Mar 19 10:28:25.797: INFO: Pod "pod-bab52d07-4a31-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.698226ms
Mar 19 10:28:27.803: INFO: Pod "pod-bab52d07-4a31-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010164408s
STEP: Saw pod success
Mar 19 10:28:27.803: INFO: Pod "pod-bab52d07-4a31-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:28:27.808: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod pod-bab52d07-4a31-11e9-989b-da33bd6188b3 container test-container: <nil>
STEP: delete the pod
Mar 19 10:28:27.843: INFO: Waiting for pod pod-bab52d07-4a31-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:28:27.848: INFO: Pod pod-bab52d07-4a31-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:28:27.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-j8tv8" for this suite.
Mar 19 10:28:33.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:28:34.024: INFO: namespace: e2e-tests-emptydir-j8tv8, resource: bindings, ignored listing per whitelist
Mar 19 10:28:34.068: INFO: namespace e2e-tests-emptydir-j8tv8 deletion completed in 6.210027279s

• [SLOW TEST:8.367 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:28:34.068: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 10:28:34.170: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bfb36175-4a31-11e9-989b-da33bd6188b3" in namespace "e2e-tests-projected-pzm7w" to be "success or failure"
Mar 19 10:28:34.178: INFO: Pod "downwardapi-volume-bfb36175-4a31-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.298789ms
Mar 19 10:28:36.184: INFO: Pod "downwardapi-volume-bfb36175-4a31-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014274484s
STEP: Saw pod success
Mar 19 10:28:36.184: INFO: Pod "downwardapi-volume-bfb36175-4a31-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:28:36.189: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod downwardapi-volume-bfb36175-4a31-11e9-989b-da33bd6188b3 container client-container: <nil>
STEP: delete the pod
Mar 19 10:28:36.223: INFO: Waiting for pod downwardapi-volume-bfb36175-4a31-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:28:36.228: INFO: Pod downwardapi-volume-bfb36175-4a31-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:28:36.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pzm7w" for this suite.
Mar 19 10:28:42.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:28:42.388: INFO: namespace: e2e-tests-projected-pzm7w, resource: bindings, ignored listing per whitelist
Mar 19 10:28:42.445: INFO: namespace e2e-tests-projected-pzm7w deletion completed in 6.207143813s

• [SLOW TEST:8.376 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:28:42.445: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-jc5jb
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 19 10:28:42.525: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 19 10:29:04.657: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.0.48:8080/dial?request=hostName&protocol=http&host=172.16.0.20&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-jc5jb PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 10:29:04.657: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
Mar 19 10:29:04.759: INFO: Waiting for endpoints: map[]
Mar 19 10:29:04.764: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.0.48:8080/dial?request=hostName&protocol=http&host=172.16.0.35&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-jc5jb PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 10:29:04.764: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
Mar 19 10:29:04.854: INFO: Waiting for endpoints: map[]
Mar 19 10:29:04.859: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.0.48:8080/dial?request=hostName&protocol=http&host=172.16.0.53&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-jc5jb PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 10:29:04.859: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
Mar 19 10:29:04.945: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:29:04.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-jc5jb" for this suite.
Mar 19 10:29:26.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:29:27.123: INFO: namespace: e2e-tests-pod-network-test-jc5jb, resource: bindings, ignored listing per whitelist
Mar 19 10:29:27.162: INFO: namespace e2e-tests-pod-network-test-jc5jb deletion completed in 22.207086818s

• [SLOW TEST:44.717 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:29:27.162: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar 19 10:29:27.265: INFO: Waiting up to 5m0s for pod "pod-df585e46-4a31-11e9-989b-da33bd6188b3" in namespace "e2e-tests-emptydir-c244v" to be "success or failure"
Mar 19 10:29:27.270: INFO: Pod "pod-df585e46-4a31-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.707217ms
Mar 19 10:29:29.276: INFO: Pod "pod-df585e46-4a31-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010455478s
STEP: Saw pod success
Mar 19 10:29:29.276: INFO: Pod "pod-df585e46-4a31-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:29:29.281: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod pod-df585e46-4a31-11e9-989b-da33bd6188b3 container test-container: <nil>
STEP: delete the pod
Mar 19 10:29:29.315: INFO: Waiting for pod pod-df585e46-4a31-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:29:29.319: INFO: Pod pod-df585e46-4a31-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:29:29.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-c244v" for this suite.
Mar 19 10:29:35.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:29:35.527: INFO: namespace: e2e-tests-emptydir-c244v, resource: bindings, ignored listing per whitelist
Mar 19 10:29:35.532: INFO: namespace e2e-tests-emptydir-c244v deletion completed in 6.202897649s

• [SLOW TEST:8.370 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:29:35.532: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-tfljz in namespace e2e-tests-proxy-bv6hw
I0319 10:29:35.642098      17 runners.go:180] Created replication controller with name: proxy-service-tfljz, namespace: e2e-tests-proxy-bv6hw, replica count: 1
I0319 10:29:36.692549      17 runners.go:180] proxy-service-tfljz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0319 10:29:37.692784      17 runners.go:180] proxy-service-tfljz Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 19 10:29:37.698: INFO: setup took 2.085919776s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Mar 19 10:29:37.706: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/rewri... (200; 8.630956ms)
Mar 19 10:29:37.709: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/... (200; 11.228329ms)
Mar 19 10:29:37.715: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname2/proxy/: bar (200; 16.965359ms)
Mar 19 10:29:37.715: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 16.734476ms)
Mar 19 10:29:37.715: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/rewriteme"... (200; 16.680618ms)
Mar 19 10:29:37.715: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 16.974276ms)
Mar 19 10:29:37.715: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 17.171114ms)
Mar 19 10:29:37.715: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 17.157439ms)
Mar 19 10:29:37.718: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname2/proxy/: bar (200; 19.636739ms)
Mar 19 10:29:37.723: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname1/proxy/: foo (200; 24.49862ms)
Mar 19 10:29:37.723: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname1/proxy/: foo (200; 24.647868ms)
Mar 19 10:29:37.724: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:462/proxy/: tls qux (200; 26.421876ms)
Mar 19 10:29:37.724: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/... (200; 26.325456ms)
Mar 19 10:29:37.726: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname2/proxy/: tls qux (200; 28.228226ms)
Mar 19 10:29:37.726: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname1/proxy/: tls baz (200; 28.030086ms)
Mar 19 10:29:37.727: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:460/proxy/: tls baz (200; 29.162604ms)
Mar 19 10:29:37.733: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/... (200; 6.385069ms)
Mar 19 10:29:37.736: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 9.093194ms)
Mar 19 10:29:37.736: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:460/proxy/: tls baz (200; 9.189867ms)
Mar 19 10:29:37.736: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:462/proxy/: tls qux (200; 8.994381ms)
Mar 19 10:29:37.736: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 9.162232ms)
Mar 19 10:29:37.737: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/rewri... (200; 9.857304ms)
Mar 19 10:29:37.737: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 9.915055ms)
Mar 19 10:29:37.737: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/rewriteme"... (200; 9.722188ms)
Mar 19 10:29:37.737: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 9.940986ms)
Mar 19 10:29:37.737: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/... (200; 9.99522ms)
Mar 19 10:29:37.740: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname1/proxy/: tls baz (200; 12.699791ms)
Mar 19 10:29:37.743: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname2/proxy/: bar (200; 15.627963ms)
Mar 19 10:29:37.743: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname2/proxy/: bar (200; 15.511708ms)
Mar 19 10:29:37.743: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname1/proxy/: foo (200; 15.628812ms)
Mar 19 10:29:37.743: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname1/proxy/: foo (200; 15.576388ms)
Mar 19 10:29:37.743: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname2/proxy/: tls qux (200; 15.606282ms)
Mar 19 10:29:37.749: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/... (200; 6.351348ms)
Mar 19 10:29:37.753: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:462/proxy/: tls qux (200; 9.886052ms)
Mar 19 10:29:37.753: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/rewriteme"... (200; 9.947583ms)
Mar 19 10:29:37.753: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 9.74887ms)
Mar 19 10:29:37.753: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 10.052288ms)
Mar 19 10:29:37.753: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:460/proxy/: tls baz (200; 9.862453ms)
Mar 19 10:29:37.753: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/rewri... (200; 9.964838ms)
Mar 19 10:29:37.753: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 9.809196ms)
Mar 19 10:29:37.753: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 10.16839ms)
Mar 19 10:29:37.754: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/... (200; 11.403885ms)
Mar 19 10:29:37.756: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname2/proxy/: bar (200; 12.748471ms)
Mar 19 10:29:37.758: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname2/proxy/: bar (200; 15.437208ms)
Mar 19 10:29:37.758: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname2/proxy/: tls qux (200; 15.423638ms)
Mar 19 10:29:37.759: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname1/proxy/: foo (200; 15.459575ms)
Mar 19 10:29:37.759: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname1/proxy/: tls baz (200; 15.388521ms)
Mar 19 10:29:37.759: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname1/proxy/: foo (200; 15.617052ms)
Mar 19 10:29:37.765: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 6.53604ms)
Mar 19 10:29:37.770: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 11.336416ms)
Mar 19 10:29:37.770: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:460/proxy/: tls baz (200; 11.386631ms)
Mar 19 10:29:37.770: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/... (200; 11.479007ms)
Mar 19 10:29:37.770: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/rewriteme"... (200; 11.388993ms)
Mar 19 10:29:37.770: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:462/proxy/: tls qux (200; 11.526141ms)
Mar 19 10:29:37.770: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 11.426054ms)
Mar 19 10:29:37.771: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 11.604842ms)
Mar 19 10:29:37.771: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/rewri... (200; 11.624403ms)
Mar 19 10:29:37.771: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/... (200; 11.751988ms)
Mar 19 10:29:37.772: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname1/proxy/: foo (200; 13.271331ms)
Mar 19 10:29:37.775: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname2/proxy/: bar (200; 16.423446ms)
Mar 19 10:29:37.775: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname1/proxy/: foo (200; 16.254779ms)
Mar 19 10:29:37.775: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname1/proxy/: tls baz (200; 16.411601ms)
Mar 19 10:29:37.775: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname2/proxy/: tls qux (200; 16.50401ms)
Mar 19 10:29:37.775: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname2/proxy/: bar (200; 16.452159ms)
Mar 19 10:29:37.781: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 6.174286ms)
Mar 19 10:29:37.785: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/rewriteme"... (200; 8.906813ms)
Mar 19 10:29:37.785: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/... (200; 9.804671ms)
Mar 19 10:29:37.785: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 9.921389ms)
Mar 19 10:29:37.785: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/rewri... (200; 9.717467ms)
Mar 19 10:29:37.786: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:462/proxy/: tls qux (200; 10.155727ms)
Mar 19 10:29:37.786: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/... (200; 10.412691ms)
Mar 19 10:29:37.786: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 10.247295ms)
Mar 19 10:29:37.786: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:460/proxy/: tls baz (200; 10.633111ms)
Mar 19 10:29:37.786: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 10.85512ms)
Mar 19 10:29:37.787: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname2/proxy/: bar (200; 12.013166ms)
Mar 19 10:29:37.790: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname1/proxy/: foo (200; 14.568059ms)
Mar 19 10:29:37.790: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname2/proxy/: bar (200; 14.553395ms)
Mar 19 10:29:37.790: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname1/proxy/: foo (200; 14.214772ms)
Mar 19 10:29:37.790: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname2/proxy/: tls qux (200; 14.681828ms)
Mar 19 10:29:37.790: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname1/proxy/: tls baz (200; 14.607471ms)
Mar 19 10:29:37.800: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:462/proxy/: tls qux (200; 10.053532ms)
Mar 19 10:29:37.800: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 9.954741ms)
Mar 19 10:29:37.800: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:460/proxy/: tls baz (200; 9.987252ms)
Mar 19 10:29:37.800: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 10.439353ms)
Mar 19 10:29:37.801: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/... (200; 10.486757ms)
Mar 19 10:29:37.801: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/... (200; 10.498181ms)
Mar 19 10:29:37.801: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/rewri... (200; 10.388892ms)
Mar 19 10:29:37.801: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 10.644786ms)
Mar 19 10:29:37.801: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 10.573544ms)
Mar 19 10:29:37.801: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/rewriteme"... (200; 10.549757ms)
Mar 19 10:29:37.802: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname2/proxy/: tls qux (200; 11.883158ms)
Mar 19 10:29:37.806: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname1/proxy/: tls baz (200; 15.586841ms)
Mar 19 10:29:37.806: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname2/proxy/: bar (200; 15.632278ms)
Mar 19 10:29:37.806: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname1/proxy/: foo (200; 15.744913ms)
Mar 19 10:29:37.806: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname1/proxy/: foo (200; 15.666828ms)
Mar 19 10:29:37.806: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname2/proxy/: bar (200; 15.658776ms)
Mar 19 10:29:37.816: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/rewriteme"... (200; 10.217835ms)
Mar 19 10:29:37.816: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:462/proxy/: tls qux (200; 9.785834ms)
Mar 19 10:29:37.816: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/rewri... (200; 10.217342ms)
Mar 19 10:29:37.816: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:460/proxy/: tls baz (200; 10.392834ms)
Mar 19 10:29:37.816: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/... (200; 9.851276ms)
Mar 19 10:29:37.816: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 9.873747ms)
Mar 19 10:29:37.816: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 9.823546ms)
Mar 19 10:29:37.816: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 10.403414ms)
Mar 19 10:29:37.816: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 10.457024ms)
Mar 19 10:29:37.816: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/... (200; 9.901674ms)
Mar 19 10:29:37.818: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname1/proxy/: foo (200; 11.862383ms)
Mar 19 10:29:37.821: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname2/proxy/: bar (200; 14.739988ms)
Mar 19 10:29:37.821: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname2/proxy/: tls qux (200; 14.721969ms)
Mar 19 10:29:37.821: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname2/proxy/: bar (200; 14.629305ms)
Mar 19 10:29:37.821: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname1/proxy/: foo (200; 14.688956ms)
Mar 19 10:29:37.821: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname1/proxy/: tls baz (200; 14.59565ms)
Mar 19 10:29:37.830: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 9.183997ms)
Mar 19 10:29:37.830: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:462/proxy/: tls qux (200; 9.231022ms)
Mar 19 10:29:37.830: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:460/proxy/: tls baz (200; 9.147845ms)
Mar 19 10:29:37.830: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/... (200; 9.289408ms)
Mar 19 10:29:37.831: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 9.349558ms)
Mar 19 10:29:37.831: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/... (200; 9.481367ms)
Mar 19 10:29:37.833: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 11.148148ms)
Mar 19 10:29:37.833: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/rewri... (200; 11.272648ms)
Mar 19 10:29:37.833: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 11.214207ms)
Mar 19 10:29:37.833: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname2/proxy/: tls qux (200; 11.817986ms)
Mar 19 10:29:37.833: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/rewriteme"... (200; 11.348713ms)
Mar 19 10:29:37.835: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname2/proxy/: bar (200; 14.287585ms)
Mar 19 10:29:37.835: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname1/proxy/: foo (200; 14.338635ms)
Mar 19 10:29:37.835: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname1/proxy/: tls baz (200; 14.274942ms)
Mar 19 10:29:37.838: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname2/proxy/: bar (200; 16.124993ms)
Mar 19 10:29:37.838: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname1/proxy/: foo (200; 16.426882ms)
Mar 19 10:29:37.844: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 6.277984ms)
Mar 19 10:29:37.848: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/rewri... (200; 9.752141ms)
Mar 19 10:29:37.848: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:462/proxy/: tls qux (200; 9.632468ms)
Mar 19 10:29:37.848: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 9.972408ms)
Mar 19 10:29:37.848: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/rewriteme"... (200; 9.798516ms)
Mar 19 10:29:37.848: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/... (200; 9.942924ms)
Mar 19 10:29:37.848: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/... (200; 9.824093ms)
Mar 19 10:29:37.848: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:460/proxy/: tls baz (200; 10.025082ms)
Mar 19 10:29:37.848: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 9.93024ms)
Mar 19 10:29:37.848: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 10.23491ms)
Mar 19 10:29:37.851: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname2/proxy/: tls qux (200; 13.006869ms)
Mar 19 10:29:37.854: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname2/proxy/: bar (200; 15.798206ms)
Mar 19 10:29:37.854: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname1/proxy/: foo (200; 15.667146ms)
Mar 19 10:29:37.854: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname1/proxy/: foo (200; 15.729696ms)
Mar 19 10:29:37.854: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname2/proxy/: bar (200; 16.018131ms)
Mar 19 10:29:37.854: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname1/proxy/: tls baz (200; 16.130245ms)
Mar 19 10:29:37.861: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:462/proxy/: tls qux (200; 6.645789ms)
Mar 19 10:29:37.863: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/rewri... (200; 8.934566ms)
Mar 19 10:29:37.864: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/rewriteme"... (200; 9.829079ms)
Mar 19 10:29:37.864: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:460/proxy/: tls baz (200; 9.92131ms)
Mar 19 10:29:37.864: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/... (200; 9.590918ms)
Mar 19 10:29:37.864: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 9.863511ms)
Mar 19 10:29:37.864: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 9.893126ms)
Mar 19 10:29:37.864: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 10.152613ms)
Mar 19 10:29:37.865: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 10.225304ms)
Mar 19 10:29:37.865: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/... (200; 10.158566ms)
Mar 19 10:29:37.867: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname1/proxy/: foo (200; 12.890551ms)
Mar 19 10:29:37.870: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname2/proxy/: bar (200; 15.407737ms)
Mar 19 10:29:37.870: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname2/proxy/: bar (200; 15.322758ms)
Mar 19 10:29:37.870: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname1/proxy/: foo (200; 15.371125ms)
Mar 19 10:29:37.870: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname2/proxy/: tls qux (200; 15.402452ms)
Mar 19 10:29:37.870: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname1/proxy/: tls baz (200; 15.320294ms)
Mar 19 10:29:37.877: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 6.611872ms)
Mar 19 10:29:37.880: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/... (200; 9.943457ms)
Mar 19 10:29:37.880: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/rewriteme"... (200; 10.023439ms)
Mar 19 10:29:37.880: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 10.198082ms)
Mar 19 10:29:37.880: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 10.210005ms)
Mar 19 10:29:37.880: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/... (200; 10.309874ms)
Mar 19 10:29:37.880: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:460/proxy/: tls baz (200; 10.297216ms)
Mar 19 10:29:37.881: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 10.40518ms)
Mar 19 10:29:37.881: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:462/proxy/: tls qux (200; 10.300337ms)
Mar 19 10:29:37.881: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/rewri... (200; 10.431116ms)
Mar 19 10:29:37.883: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname2/proxy/: bar (200; 13.21589ms)
Mar 19 10:29:37.886: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname1/proxy/: tls baz (200; 15.618577ms)
Mar 19 10:29:37.886: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname2/proxy/: tls qux (200; 15.854411ms)
Mar 19 10:29:37.886: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname2/proxy/: bar (200; 15.669096ms)
Mar 19 10:29:37.886: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname1/proxy/: foo (200; 15.853677ms)
Mar 19 10:29:37.886: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname1/proxy/: foo (200; 15.758889ms)
Mar 19 10:29:37.892: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:460/proxy/: tls baz (200; 6.299444ms)
Mar 19 10:29:37.895: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 8.839886ms)
Mar 19 10:29:37.895: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 8.877277ms)
Mar 19 10:29:37.896: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 9.408987ms)
Mar 19 10:29:37.896: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/rewri... (200; 10.006768ms)
Mar 19 10:29:37.896: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:462/proxy/: tls qux (200; 10.101673ms)
Mar 19 10:29:37.896: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/rewriteme"... (200; 10.039433ms)
Mar 19 10:29:37.896: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/... (200; 9.925805ms)
Mar 19 10:29:37.896: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 9.959096ms)
Mar 19 10:29:37.896: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/... (200; 10.034859ms)
Mar 19 10:29:37.899: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname2/proxy/: bar (200; 12.828116ms)
Mar 19 10:29:37.902: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname2/proxy/: bar (200; 16.039707ms)
Mar 19 10:29:37.902: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname2/proxy/: tls qux (200; 15.961905ms)
Mar 19 10:29:37.902: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname1/proxy/: foo (200; 16.201544ms)
Mar 19 10:29:37.902: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname1/proxy/: tls baz (200; 16.130084ms)
Mar 19 10:29:37.902: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname1/proxy/: foo (200; 16.16528ms)
Mar 19 10:29:37.913: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 10.628806ms)
Mar 19 10:29:37.913: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/rewri... (200; 10.730083ms)
Mar 19 10:29:37.913: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:460/proxy/: tls baz (200; 10.845268ms)
Mar 19 10:29:37.914: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 10.752622ms)
Mar 19 10:29:37.914: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 11.069499ms)
Mar 19 10:29:37.914: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 11.104302ms)
Mar 19 10:29:37.914: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/... (200; 11.051711ms)
Mar 19 10:29:37.914: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/... (200; 11.225079ms)
Mar 19 10:29:37.914: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:462/proxy/: tls qux (200; 11.371304ms)
Mar 19 10:29:37.914: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/rewriteme"... (200; 11.217918ms)
Mar 19 10:29:37.915: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname2/proxy/: tls qux (200; 12.872254ms)
Mar 19 10:29:37.918: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname1/proxy/: foo (200; 15.23065ms)
Mar 19 10:29:37.918: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname2/proxy/: bar (200; 15.086999ms)
Mar 19 10:29:37.920: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname1/proxy/: foo (200; 18.032185ms)
Mar 19 10:29:37.920: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname1/proxy/: tls baz (200; 17.948339ms)
Mar 19 10:29:37.920: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname2/proxy/: bar (200; 17.989208ms)
Mar 19 10:29:37.930: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 9.837995ms)
Mar 19 10:29:37.930: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 9.903518ms)
Mar 19 10:29:37.930: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 10.026034ms)
Mar 19 10:29:37.931: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/rewriteme"... (200; 10.211054ms)
Mar 19 10:29:37.931: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/... (200; 10.264624ms)
Mar 19 10:29:37.931: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 10.23574ms)
Mar 19 10:29:37.931: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/... (200; 10.329298ms)
Mar 19 10:29:37.931: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:460/proxy/: tls baz (200; 10.345977ms)
Mar 19 10:29:37.931: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/rewri... (200; 10.256005ms)
Mar 19 10:29:37.931: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:462/proxy/: tls qux (200; 10.233388ms)
Mar 19 10:29:37.932: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname1/proxy/: foo (200; 11.229359ms)
Mar 19 10:29:37.934: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname2/proxy/: bar (200; 13.648072ms)
Mar 19 10:29:37.934: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname1/proxy/: foo (200; 13.691647ms)
Mar 19 10:29:37.934: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname2/proxy/: bar (200; 13.778248ms)
Mar 19 10:29:37.934: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname1/proxy/: tls baz (200; 13.738056ms)
Mar 19 10:29:37.934: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname2/proxy/: tls qux (200; 13.832824ms)
Mar 19 10:29:37.941: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:462/proxy/: tls qux (200; 6.395942ms)
Mar 19 10:29:37.944: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/rewri... (200; 9.98384ms)
Mar 19 10:29:37.945: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 9.992865ms)
Mar 19 10:29:37.945: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/rewriteme"... (200; 10.219618ms)
Mar 19 10:29:37.945: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 10.156658ms)
Mar 19 10:29:37.945: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 10.361364ms)
Mar 19 10:29:37.945: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 10.228257ms)
Mar 19 10:29:37.945: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:460/proxy/: tls baz (200; 10.268845ms)
Mar 19 10:29:37.945: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/... (200; 10.307331ms)
Mar 19 10:29:37.945: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/... (200; 10.294168ms)
Mar 19 10:29:37.948: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname2/proxy/: bar (200; 13.134518ms)
Mar 19 10:29:37.950: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname2/proxy/: bar (200; 15.805977ms)
Mar 19 10:29:37.950: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname1/proxy/: foo (200; 15.677836ms)
Mar 19 10:29:37.950: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname2/proxy/: tls qux (200; 15.911005ms)
Mar 19 10:29:37.950: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname1/proxy/: tls baz (200; 15.886273ms)
Mar 19 10:29:37.950: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname1/proxy/: foo (200; 16.035239ms)
Mar 19 10:29:37.957: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 6.170385ms)
Mar 19 10:29:37.960: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 9.262092ms)
Mar 19 10:29:37.960: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/... (200; 9.409206ms)
Mar 19 10:29:37.960: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 9.628726ms)
Mar 19 10:29:37.960: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/rewriteme"... (200; 9.825182ms)
Mar 19 10:29:37.960: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:462/proxy/: tls qux (200; 9.917406ms)
Mar 19 10:29:37.961: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/rewri... (200; 10.014502ms)
Mar 19 10:29:37.961: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:460/proxy/: tls baz (200; 10.001334ms)
Mar 19 10:29:37.961: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/... (200; 10.129121ms)
Mar 19 10:29:37.961: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 10.172605ms)
Mar 19 10:29:37.962: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname2/proxy/: bar (200; 11.499971ms)
Mar 19 10:29:37.965: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname1/proxy/: foo (200; 14.433073ms)
Mar 19 10:29:37.965: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname2/proxy/: bar (200; 14.431376ms)
Mar 19 10:29:37.965: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname2/proxy/: tls qux (200; 14.665968ms)
Mar 19 10:29:37.965: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname1/proxy/: tls baz (200; 14.591712ms)
Mar 19 10:29:37.965: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname1/proxy/: foo (200; 14.626979ms)
Mar 19 10:29:37.972: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 6.440581ms)
Mar 19 10:29:37.975: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:460/proxy/: tls baz (200; 10.21648ms)
Mar 19 10:29:37.975: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/rewriteme"... (200; 10.103131ms)
Mar 19 10:29:37.975: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/... (200; 9.624857ms)
Mar 19 10:29:37.976: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:462/proxy/: tls qux (200; 10.077571ms)
Mar 19 10:29:37.976: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 10.240456ms)
Mar 19 10:29:37.976: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 10.017575ms)
Mar 19 10:29:37.976: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/... (200; 10.096513ms)
Mar 19 10:29:37.976: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 10.016762ms)
Mar 19 10:29:37.976: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/rewri... (200; 10.49116ms)
Mar 19 10:29:37.978: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname1/proxy/: foo (200; 13.219133ms)
Mar 19 10:29:37.983: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname2/proxy/: tls qux (200; 17.684342ms)
Mar 19 10:29:37.983: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname1/proxy/: foo (200; 17.61968ms)
Mar 19 10:29:37.983: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname2/proxy/: bar (200; 17.756301ms)
Mar 19 10:29:37.983: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname1/proxy/: tls baz (200; 17.541804ms)
Mar 19 10:29:37.983: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname2/proxy/: bar (200; 17.599147ms)
Mar 19 10:29:37.994: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/... (200; 10.652991ms)
Mar 19 10:29:37.994: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/rewriteme"... (200; 10.65693ms)
Mar 19 10:29:37.994: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 10.520289ms)
Mar 19 10:29:37.994: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 10.628726ms)
Mar 19 10:29:37.994: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 10.606947ms)
Mar 19 10:29:37.994: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:460/proxy/: tls baz (200; 10.725004ms)
Mar 19 10:29:37.994: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/rewri... (200; 10.919178ms)
Mar 19 10:29:37.994: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/... (200; 10.995181ms)
Mar 19 10:29:37.994: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:462/proxy/: tls qux (200; 11.114335ms)
Mar 19 10:29:37.994: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 11.014648ms)
Mar 19 10:29:37.995: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname2/proxy/: bar (200; 12.279871ms)
Mar 19 10:29:37.999: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname1/proxy/: foo (200; 15.656991ms)
Mar 19 10:29:37.999: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname1/proxy/: foo (200; 15.620052ms)
Mar 19 10:29:37.999: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname1/proxy/: tls baz (200; 15.684439ms)
Mar 19 10:29:37.999: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname2/proxy/: bar (200; 15.62168ms)
Mar 19 10:29:37.999: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname2/proxy/: tls qux (200; 15.601302ms)
Mar 19 10:29:38.005: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/... (200; 6.263298ms)
Mar 19 10:29:38.009: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 9.600073ms)
Mar 19 10:29:38.009: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 9.652762ms)
Mar 19 10:29:38.009: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 9.939775ms)
Mar 19 10:29:38.009: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/... (200; 9.943659ms)
Mar 19 10:29:38.009: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:460/proxy/: tls baz (200; 9.956339ms)
Mar 19 10:29:38.009: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:462/proxy/: tls qux (200; 9.715317ms)
Mar 19 10:29:38.009: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/rewri... (200; 9.897188ms)
Mar 19 10:29:38.009: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 10.012525ms)
Mar 19 10:29:38.009: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/rewriteme"... (200; 10.014736ms)
Mar 19 10:29:38.012: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname2/proxy/: tls qux (200; 13.049114ms)
Mar 19 10:29:38.015: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname1/proxy/: foo (200; 15.668367ms)
Mar 19 10:29:38.015: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname1/proxy/: tls baz (200; 15.650303ms)
Mar 19 10:29:38.015: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname2/proxy/: bar (200; 15.695403ms)
Mar 19 10:29:38.015: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname1/proxy/: foo (200; 15.970474ms)
Mar 19 10:29:38.015: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname2/proxy/: bar (200; 15.870295ms)
Mar 19 10:29:38.022: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:462/proxy/: tls qux (200; 6.536878ms)
Mar 19 10:29:38.026: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:1080/proxy/... (200; 10.430087ms)
Mar 19 10:29:38.026: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc/proxy/rewriteme"... (200; 10.675213ms)
Mar 19 10:29:38.026: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:443/proxy/... (200; 10.40718ms)
Mar 19 10:29:38.026: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 10.428847ms)
Mar 19 10:29:38.026: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:162/proxy/: bar (200; 10.573489ms)
Mar 19 10:29:38.026: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 10.599541ms)
Mar 19 10:29:38.026: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/http:proxy-service-tfljz-rfdxc:160/proxy/: foo (200; 10.664177ms)
Mar 19 10:29:38.026: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/https:proxy-service-tfljz-rfdxc:460/proxy/: tls baz (200; 10.469252ms)
Mar 19 10:29:38.026: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bv6hw/pods/proxy-service-tfljz-rfdxc:1080/proxy/rewri... (200; 10.654996ms)
Mar 19 10:29:38.029: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname2/proxy/: tls qux (200; 13.214584ms)
Mar 19 10:29:38.031: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname1/proxy/: foo (200; 15.739288ms)
Mar 19 10:29:38.031: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/https:proxy-service-tfljz:tlsportname1/proxy/: tls baz (200; 15.971441ms)
Mar 19 10:29:38.031: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/proxy-service-tfljz:portname2/proxy/: bar (200; 16.052203ms)
Mar 19 10:29:38.031: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname2/proxy/: bar (200; 16.011919ms)
Mar 19 10:29:38.031: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bv6hw/services/http:proxy-service-tfljz:portname1/proxy/: foo (200; 16.036797ms)
STEP: deleting { ReplicationController} proxy-service-tfljz in namespace e2e-tests-proxy-bv6hw, will wait for the garbage collector to delete the pods
Mar 19 10:29:38.110: INFO: Deleting { ReplicationController} proxy-service-tfljz took: 21.572287ms
Mar 19 10:29:38.211: INFO: Terminating { ReplicationController} proxy-service-tfljz pods took: 100.268486ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:29:51.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-bv6hw" for this suite.
Mar 19 10:29:57.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:29:57.787: INFO: namespace: e2e-tests-proxy-bv6hw, resource: bindings, ignored listing per whitelist
Mar 19 10:29:57.928: INFO: namespace e2e-tests-proxy-bv6hw deletion completed in 6.207093218s

• [SLOW TEST:22.396 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:29:57.928: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-f1af0c6d-4a31-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume configMaps
Mar 19 10:29:58.037: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f1b04e59-4a31-11e9-989b-da33bd6188b3" in namespace "e2e-tests-projected-vl46m" to be "success or failure"
Mar 19 10:29:58.043: INFO: Pod "pod-projected-configmaps-f1b04e59-4a31-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.953556ms
Mar 19 10:30:00.049: INFO: Pod "pod-projected-configmaps-f1b04e59-4a31-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011938923s
STEP: Saw pod success
Mar 19 10:30:00.049: INFO: Pod "pod-projected-configmaps-f1b04e59-4a31-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:30:00.054: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod pod-projected-configmaps-f1b04e59-4a31-11e9-989b-da33bd6188b3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 19 10:30:00.088: INFO: Waiting for pod pod-projected-configmaps-f1b04e59-4a31-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:30:00.092: INFO: Pod pod-projected-configmaps-f1b04e59-4a31-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:30:00.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vl46m" for this suite.
Mar 19 10:30:06.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:30:06.142: INFO: namespace: e2e-tests-projected-vl46m, resource: bindings, ignored listing per whitelist
Mar 19 10:30:06.309: INFO: namespace e2e-tests-projected-vl46m deletion completed in 6.207121262s

• [SLOW TEST:8.381 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:30:06.309: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-rtqwz
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-rtqwz
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-rtqwz
Mar 19 10:30:06.409: INFO: Found 0 stateful pods, waiting for 1
Mar 19 10:30:16.415: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Mar 19 10:30:16.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 exec --namespace=e2e-tests-statefulset-rtqwz ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 19 10:30:16.582: INFO: stderr: ""
Mar 19 10:30:16.582: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 19 10:30:16.582: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 19 10:30:16.587: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar 19 10:30:26.593: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 19 10:30:26.593: INFO: Waiting for statefulset status.replicas updated to 0
Mar 19 10:30:26.611: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Mar 19 10:30:26.611: INFO: ss-0  k8s-node-vm1y1w-lkllt8nnod  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:29:13 +0000 UTC  }]
Mar 19 10:30:26.611: INFO: 
Mar 19 10:30:26.611: INFO: StatefulSet ss has not reached scale 3, at 1
Mar 19 10:30:27.617: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99325712s
Mar 19 10:30:28.623: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.987258944s
Mar 19 10:30:29.629: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.981160607s
Mar 19 10:30:30.635: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.975128104s
Mar 19 10:30:31.641: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.968607682s
Mar 19 10:30:32.648: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.962511328s
Mar 19 10:30:33.654: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.955861562s
Mar 19 10:30:34.660: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.949810625s
Mar 19 10:30:35.666: INFO: Verifying statefulset ss doesn't scale past 3 for another 943.415655ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-rtqwz
Mar 19 10:30:36.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 exec --namespace=e2e-tests-statefulset-rtqwz ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 19 10:30:36.847: INFO: stderr: ""
Mar 19 10:30:36.847: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 19 10:30:36.847: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 19 10:30:36.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 exec --namespace=e2e-tests-statefulset-rtqwz ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 19 10:30:37.013: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Mar 19 10:30:37.013: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 19 10:30:37.013: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 19 10:30:37.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 exec --namespace=e2e-tests-statefulset-rtqwz ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 19 10:30:37.160: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Mar 19 10:30:37.160: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 19 10:30:37.160: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 19 10:30:37.166: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Mar 19 10:30:47.173: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 19 10:30:47.173: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 19 10:30:47.173: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Mar 19 10:30:47.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 exec --namespace=e2e-tests-statefulset-rtqwz ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 19 10:30:47.353: INFO: stderr: ""
Mar 19 10:30:47.353: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 19 10:30:47.353: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 19 10:30:47.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 exec --namespace=e2e-tests-statefulset-rtqwz ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 19 10:30:47.511: INFO: stderr: ""
Mar 19 10:30:47.511: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 19 10:30:47.511: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 19 10:30:47.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 exec --namespace=e2e-tests-statefulset-rtqwz ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 19 10:30:47.656: INFO: stderr: ""
Mar 19 10:30:47.656: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 19 10:30:47.656: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 19 10:30:47.656: INFO: Waiting for statefulset status.replicas updated to 0
Mar 19 10:30:47.660: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Mar 19 10:30:57.668: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 19 10:30:57.668: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar 19 10:30:57.668: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar 19 10:30:57.682: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Mar 19 10:30:57.682: INFO: ss-0  k8s-node-vm1y1w-lkllt8nnod  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:29:13 +0000 UTC  }]
Mar 19 10:30:57.682: INFO: ss-1  k8s-node-vmepd8-lkllt8nnod  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:29:33 +0000 UTC  }]
Mar 19 10:30:57.682: INFO: ss-2  k8s-node-vmwvcc-lkllt8nnod  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:29:33 +0000 UTC  }]
Mar 19 10:30:57.682: INFO: 
Mar 19 10:30:57.682: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 19 10:30:58.689: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Mar 19 10:30:58.689: INFO: ss-0  k8s-node-vm1y1w-lkllt8nnod  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:29:13 +0000 UTC  }]
Mar 19 10:30:58.689: INFO: ss-1  k8s-node-vmepd8-lkllt8nnod  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:29:33 +0000 UTC  }]
Mar 19 10:30:58.689: INFO: ss-2  k8s-node-vmwvcc-lkllt8nnod  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:29:33 +0000 UTC  }]
Mar 19 10:30:58.689: INFO: 
Mar 19 10:30:58.689: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 19 10:30:59.695: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Mar 19 10:30:59.695: INFO: ss-0  k8s-node-vm1y1w-lkllt8nnod  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:29:13 +0000 UTC  }]
Mar 19 10:30:59.695: INFO: ss-1  k8s-node-vmepd8-lkllt8nnod  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:29:33 +0000 UTC  }]
Mar 19 10:30:59.695: INFO: ss-2  k8s-node-vmwvcc-lkllt8nnod  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:29:33 +0000 UTC  }]
Mar 19 10:30:59.695: INFO: 
Mar 19 10:30:59.695: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 19 10:31:00.701: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Mar 19 10:31:00.701: INFO: ss-0  k8s-node-vm1y1w-lkllt8nnod  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:29:13 +0000 UTC  }]
Mar 19 10:31:00.701: INFO: ss-1  k8s-node-vmepd8-lkllt8nnod  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:29:33 +0000 UTC  }]
Mar 19 10:31:00.701: INFO: ss-2  k8s-node-vmwvcc-lkllt8nnod  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:29:33 +0000 UTC  }]
Mar 19 10:31:00.701: INFO: 
Mar 19 10:31:00.701: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 19 10:31:01.710: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Mar 19 10:31:01.710: INFO: ss-0  k8s-node-vm1y1w-lkllt8nnod  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:29:13 +0000 UTC  }]
Mar 19 10:31:01.710: INFO: ss-1  k8s-node-vmepd8-lkllt8nnod  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:29:33 +0000 UTC  }]
Mar 19 10:31:01.710: INFO: ss-2  k8s-node-vmwvcc-lkllt8nnod  Running  0s     [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:29:33 +0000 UTC  }]
Mar 19 10:31:01.710: INFO: 
Mar 19 10:31:01.710: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 19 10:31:02.716: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Mar 19 10:31:02.716: INFO: ss-1  k8s-node-vmepd8-lkllt8nnod  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:29:33 +0000 UTC  }]
Mar 19 10:31:02.716: INFO: 
Mar 19 10:31:02.716: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 19 10:31:03.722: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Mar 19 10:31:03.722: INFO: ss-1  k8s-node-vmepd8-lkllt8nnod  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:29:33 +0000 UTC  }]
Mar 19 10:31:03.722: INFO: 
Mar 19 10:31:03.722: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 19 10:31:04.728: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Mar 19 10:31:04.728: INFO: ss-1  k8s-node-vmepd8-lkllt8nnod  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:30:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:29:33 +0000 UTC  }]
Mar 19 10:31:04.728: INFO: 
Mar 19 10:31:04.728: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 19 10:31:05.735: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.947879939s
Mar 19 10:31:06.742: INFO: Verifying statefulset ss doesn't scale past 0 for another 940.876292ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-rtqwz
Mar 19 10:31:07.747: INFO: Scaling statefulset ss to 0
Mar 19 10:31:07.759: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 19 10:31:07.761: INFO: Deleting all statefulset in ns e2e-tests-statefulset-rtqwz
Mar 19 10:31:07.764: INFO: Scaling statefulset ss to 0
Mar 19 10:31:07.774: INFO: Waiting for statefulset status.replicas updated to 0
Mar 19 10:31:07.777: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:31:07.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-rtqwz" for this suite.
Mar 19 10:31:13.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:31:13.906: INFO: namespace: e2e-tests-statefulset-rtqwz, resource: bindings, ignored listing per whitelist
Mar 19 10:31:14.026: INFO: namespace e2e-tests-statefulset-rtqwz deletion completed in 6.219596829s

• [SLOW TEST:67.717 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:31:14.027: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-7k57x
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-7k57x to expose endpoints map[]
Mar 19 10:31:14.140: INFO: Get endpoints failed (6.912987ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Mar 19 10:31:15.146: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-7k57x exposes endpoints map[] (1.012532646s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-7k57x
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-7k57x to expose endpoints map[pod1:[100]]
Mar 19 10:31:17.192: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-7k57x exposes endpoints map[pod1:[100]] (2.031406133s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-7k57x
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-7k57x to expose endpoints map[pod1:[100] pod2:[101]]
Mar 19 10:31:19.249: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-7k57x exposes endpoints map[pod1:[100] pod2:[101]] (2.050303111s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-7k57x
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-7k57x to expose endpoints map[pod2:[101]]
Mar 19 10:31:20.284: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-7k57x exposes endpoints map[pod2:[101]] (1.022437568s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-7k57x
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-7k57x to expose endpoints map[]
Mar 19 10:31:21.308: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-7k57x exposes endpoints map[] (1.01015958s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:31:21.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-7k57x" for this suite.
Mar 19 10:31:27.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:31:27.541: INFO: namespace: e2e-tests-services-7k57x, resource: bindings, ignored listing per whitelist
Mar 19 10:31:27.573: INFO: namespace e2e-tests-services-7k57x deletion completed in 6.207658015s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:13.546 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:31:27.573: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 19 10:31:30.222: INFO: Successfully updated pod "annotationupdate271da339-4a32-11e9-989b-da33bd6188b3"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:31:32.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rl2ln" for this suite.
Mar 19 10:31:54.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:31:54.364: INFO: namespace: e2e-tests-downward-api-rl2ln, resource: bindings, ignored listing per whitelist
Mar 19 10:31:54.470: INFO: namespace e2e-tests-downward-api-rl2ln deletion completed in 22.207014528s

• [SLOW TEST:26.897 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:31:54.470: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar 19 10:31:54.588: INFO: Waiting up to 5m0s for pod "pod-372856a4-4a32-11e9-989b-da33bd6188b3" in namespace "e2e-tests-emptydir-zn8vb" to be "success or failure"
Mar 19 10:31:54.592: INFO: Pod "pod-372856a4-4a32-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.855818ms
Mar 19 10:31:56.598: INFO: Pod "pod-372856a4-4a32-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010640225s
STEP: Saw pod success
Mar 19 10:31:56.598: INFO: Pod "pod-372856a4-4a32-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:31:56.603: INFO: Trying to get logs from node k8s-node-vmwvcc-lkllt8nnod pod pod-372856a4-4a32-11e9-989b-da33bd6188b3 container test-container: <nil>
STEP: delete the pod
Mar 19 10:31:56.643: INFO: Waiting for pod pod-372856a4-4a32-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:31:56.647: INFO: Pod pod-372856a4-4a32-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:31:56.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-zn8vb" for this suite.
Mar 19 10:32:02.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:32:02.765: INFO: namespace: e2e-tests-emptydir-zn8vb, resource: bindings, ignored listing per whitelist
Mar 19 10:32:02.865: INFO: namespace e2e-tests-emptydir-zn8vb deletion completed in 6.20785033s

• [SLOW TEST:8.395 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:32:02.865: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-3c25e51a-4a32-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume secrets
Mar 19 10:32:02.964: INFO: Waiting up to 5m0s for pod "pod-secrets-3c26d2dc-4a32-11e9-989b-da33bd6188b3" in namespace "e2e-tests-secrets-t9ddm" to be "success or failure"
Mar 19 10:32:02.969: INFO: Pod "pod-secrets-3c26d2dc-4a32-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.652036ms
Mar 19 10:32:04.975: INFO: Pod "pod-secrets-3c26d2dc-4a32-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010488508s
STEP: Saw pod success
Mar 19 10:32:04.975: INFO: Pod "pod-secrets-3c26d2dc-4a32-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:32:04.979: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod pod-secrets-3c26d2dc-4a32-11e9-989b-da33bd6188b3 container secret-volume-test: <nil>
STEP: delete the pod
Mar 19 10:32:05.015: INFO: Waiting for pod pod-secrets-3c26d2dc-4a32-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:32:05.019: INFO: Pod pod-secrets-3c26d2dc-4a32-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:32:05.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-t9ddm" for this suite.
Mar 19 10:32:11.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:32:11.206: INFO: namespace: e2e-tests-secrets-t9ddm, resource: bindings, ignored listing per whitelist
Mar 19 10:32:11.239: INFO: namespace e2e-tests-secrets-t9ddm deletion completed in 6.212045843s

• [SLOW TEST:8.374 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:32:11.239: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Mar 19 10:32:11.400: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-p7vhh,SelfLink:/api/v1/namespaces/e2e-tests-watch-p7vhh/configmaps/e2e-watch-test-resource-version,UID:22a5ee7e-4a32-11e9-b857-fa163eaabeb9,ResourceVersion:1198819,Generation:0,CreationTimestamp:2019-03-19 10:31:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 19 10:32:11.400: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-p7vhh,SelfLink:/api/v1/namespaces/e2e-tests-watch-p7vhh/configmaps/e2e-watch-test-resource-version,UID:22a5ee7e-4a32-11e9-b857-fa163eaabeb9,ResourceVersion:1198820,Generation:0,CreationTimestamp:2019-03-19 10:31:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:32:11.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-p7vhh" for this suite.
Mar 19 10:32:17.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:32:17.494: INFO: namespace: e2e-tests-watch-p7vhh, resource: bindings, ignored listing per whitelist
Mar 19 10:32:17.617: INFO: namespace e2e-tests-watch-p7vhh deletion completed in 6.20671915s

• [SLOW TEST:6.377 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:32:17.617: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-44f2b240-4a32-11e9-989b-da33bd6188b3
STEP: Creating configMap with name cm-test-opt-upd-44f2b268-4a32-11e9-989b-da33bd6188b3
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-44f2b240-4a32-11e9-989b-da33bd6188b3
STEP: Updating configmap cm-test-opt-upd-44f2b268-4a32-11e9-989b-da33bd6188b3
STEP: Creating configMap with name cm-test-opt-create-44f2b2c3-4a32-11e9-989b-da33bd6188b3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:33:26.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-nx9w9" for this suite.
Mar 19 10:33:48.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:33:48.506: INFO: namespace: e2e-tests-configmap-nx9w9, resource: bindings, ignored listing per whitelist
Mar 19 10:33:48.612: INFO: namespace e2e-tests-configmap-nx9w9 deletion completed in 22.206436578s

• [SLOW TEST:90.995 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:33:48.612: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 10:33:48.698: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Mar 19 10:33:48.707: INFO: Pod name sample-pod: Found 0 pods out of 1
Mar 19 10:33:53.713: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 19 10:33:53.713: INFO: Creating deployment "test-rolling-update-deployment"
Mar 19 10:33:53.719: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Mar 19 10:33:53.724: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Mar 19 10:33:55.731: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Mar 19 10:33:55.734: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 19 10:33:55.742: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-48svx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-48svx/deployments/test-rolling-update-deployment,UID:5fa9f1d7-4a32-11e9-b857-fa163eaabeb9,ResourceVersion:1199086,Generation:1,CreationTimestamp:2019-03-19 10:33:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-19 10:33:08 +0000 UTC 2019-03-19 10:33:08 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-19 10:33:09 +0000 UTC 2019-03-19 10:33:08 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar 19 10:33:55.745: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-48svx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-48svx/replicasets/test-rolling-update-deployment-65b7695dcf,UID:63493d0c-4a32-11e9-8b0a-fa163ecd2a50,ResourceVersion:1199077,Generation:1,CreationTimestamp:2019-03-19 10:33:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 5fa9f1d7-4a32-11e9-b857-fa163eaabeb9 0xc4229b97d7 0xc4229b97d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 19 10:33:55.745: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Mar 19 10:33:55.745: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-48svx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-48svx/replicasets/test-rolling-update-controller,UID:5cacab25-4a32-11e9-b857-fa163eaabeb9,ResourceVersion:1199085,Generation:2,CreationTimestamp:2019-03-19 10:32:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 5fa9f1d7-4a32-11e9-b857-fa163eaabeb9 0xc4229b955e 0xc4229b955f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 19 10:33:55.751: INFO: Pod "test-rolling-update-deployment-65b7695dcf-grpxs" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-grpxs,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-48svx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-48svx/pods/test-rolling-update-deployment-65b7695dcf-grpxs,UID:634a76e9-4a32-11e9-8b0a-fa163ecd2a50,ResourceVersion:1199076,Generation:0,CreationTimestamp:2019-03-19 10:33:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf 63493d0c-4a32-11e9-8b0a-fa163ecd2a50 0xc4220ee957 0xc4220ee958}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cknrq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cknrq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-cknrq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm1y1w-lkllt8nnod,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4220ee9c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4220ee9e0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:33:53 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:33:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:33:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:33:00 +0000 UTC  }],Message:,Reason:,HostIP:172.16.128.12,PodIP:172.16.0.22,StartTime:2019-03-19 10:33:53 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-19 10:33:54 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker://sha256:e4423e943a205fe1d81768e60603c8f2c5821576bad0801c1e91b8ba586124a0 docker://ed629899521d8c4dceb72924a507f4169aea40ea144ce636386173c13b40a079}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:33:55.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-48svx" for this suite.
Mar 19 10:34:01.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:34:01.858: INFO: namespace: e2e-tests-deployment-48svx, resource: bindings, ignored listing per whitelist
Mar 19 10:34:01.970: INFO: namespace e2e-tests-deployment-48svx deletion completed in 6.209161964s

• [SLOW TEST:13.358 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:34:01.970: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar 19 10:34:02.105: INFO: Number of nodes with available pods: 0
Mar 19 10:34:02.105: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:34:03.121: INFO: Number of nodes with available pods: 0
Mar 19 10:34:03.121: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:34:04.121: INFO: Number of nodes with available pods: 3
Mar 19 10:34:04.121: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Mar 19 10:34:04.153: INFO: Number of nodes with available pods: 2
Mar 19 10:34:04.153: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:34:05.169: INFO: Number of nodes with available pods: 2
Mar 19 10:34:05.169: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:34:06.169: INFO: Number of nodes with available pods: 3
Mar 19 10:34:06.169: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-wrhfb, will wait for the garbage collector to delete the pods
Mar 19 10:34:06.254: INFO: Deleting {extensions DaemonSet} daemon-set took: 21.271781ms
Mar 19 10:34:06.355: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.257287ms
Mar 19 10:34:41.760: INFO: Number of nodes with available pods: 0
Mar 19 10:34:41.760: INFO: Number of running nodes: 0, number of available pods: 0
Mar 19 10:34:41.765: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-wrhfb/daemonsets","resourceVersion":"1199260"},"items":null}

Mar 19 10:34:41.770: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-wrhfb/pods","resourceVersion":"1199260"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:34:41.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-wrhfb" for this suite.
Mar 19 10:34:47.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:34:47.887: INFO: namespace: e2e-tests-daemonsets-wrhfb, resource: bindings, ignored listing per whitelist
Mar 19 10:34:48.017: INFO: namespace e2e-tests-daemonsets-wrhfb deletion completed in 6.208565328s

• [SLOW TEST:46.047 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:34:48.018: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 19 10:34:48.103: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:34:51.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-zpl6p" for this suite.
Mar 19 10:34:57.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:34:57.515: INFO: namespace: e2e-tests-init-container-zpl6p, resource: bindings, ignored listing per whitelist
Mar 19 10:34:57.607: INFO: namespace e2e-tests-init-container-zpl6p deletion completed in 6.207000834s

• [SLOW TEST:9.590 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:34:57.607: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-zz9km
Mar 19 10:34:59.711: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-zz9km
STEP: checking the pod's current state and verifying that restartCount is present
Mar 19 10:34:59.716: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:39:00.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-zz9km" for this suite.
Mar 19 10:39:06.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:39:06.477: INFO: namespace: e2e-tests-container-probe-zz9km, resource: bindings, ignored listing per whitelist
Mar 19 10:39:06.648: INFO: namespace e2e-tests-container-probe-zz9km deletion completed in 6.207929835s

• [SLOW TEST:249.041 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:39:06.648: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-d7n22
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-d7n22
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-d7n22
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-d7n22
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-d7n22
Mar 19 10:39:08.789: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-d7n22, name: ss-0, uid: 1de4a613-4a33-11e9-8b0a-fa163ecd2a50, status phase: Pending. Waiting for statefulset controller to delete.
Mar 19 10:39:12.590: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-d7n22, name: ss-0, uid: 1de4a613-4a33-11e9-8b0a-fa163ecd2a50, status phase: Failed. Waiting for statefulset controller to delete.
Mar 19 10:39:12.600: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-d7n22, name: ss-0, uid: 1de4a613-4a33-11e9-8b0a-fa163ecd2a50, status phase: Failed. Waiting for statefulset controller to delete.
Mar 19 10:39:12.607: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-d7n22
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-d7n22
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-d7n22 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 19 10:39:22.675: INFO: Deleting all statefulset in ns e2e-tests-statefulset-d7n22
Mar 19 10:39:22.678: INFO: Scaling statefulset ss to 0
Mar 19 10:39:32.698: INFO: Waiting for statefulset status.replicas updated to 0
Mar 19 10:39:32.700: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:39:32.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-d7n22" for this suite.
Mar 19 10:39:38.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:39:38.821: INFO: namespace: e2e-tests-statefulset-d7n22, resource: bindings, ignored listing per whitelist
Mar 19 10:39:38.933: INFO: namespace e2e-tests-statefulset-d7n22 deletion completed in 6.203726021s

• [SLOW TEST:32.284 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:39:38.933: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-4bfd6d29-4a33-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume configMaps
Mar 19 10:39:39.043: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4bfeac9a-4a33-11e9-989b-da33bd6188b3" in namespace "e2e-tests-projected-fhkzm" to be "success or failure"
Mar 19 10:39:39.047: INFO: Pod "pod-projected-configmaps-4bfeac9a-4a33-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.625296ms
Mar 19 10:39:41.053: INFO: Pod "pod-projected-configmaps-4bfeac9a-4a33-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01066668s
STEP: Saw pod success
Mar 19 10:39:41.053: INFO: Pod "pod-projected-configmaps-4bfeac9a-4a33-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:39:41.059: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod pod-projected-configmaps-4bfeac9a-4a33-11e9-989b-da33bd6188b3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 19 10:39:41.098: INFO: Waiting for pod pod-projected-configmaps-4bfeac9a-4a33-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:39:41.102: INFO: Pod pod-projected-configmaps-4bfeac9a-4a33-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:39:41.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fhkzm" for this suite.
Mar 19 10:39:47.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:39:47.212: INFO: namespace: e2e-tests-projected-fhkzm, resource: bindings, ignored listing per whitelist
Mar 19 10:39:47.320: INFO: namespace e2e-tests-projected-fhkzm deletion completed in 6.207992367s

• [SLOW TEST:8.387 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:39:47.320: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Mar 19 10:39:49.439: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-50fce586-4a33-11e9-989b-da33bd6188b3,GenerateName:,Namespace:e2e-tests-events-26qhs,SelfLink:/api/v1/namespaces/e2e-tests-events-26qhs/pods/send-events-50fce586-4a33-11e9-989b-da33bd6188b3,UID:32775c5c-4a33-11e9-b857-fa163eaabeb9,ResourceVersion:1199991,Generation:0,CreationTimestamp:2019-03-19 10:38:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 404946336,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kbr59 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kbr59,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-kbr59 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vmwvcc-lkllt8nnod,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f38ee0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f38f00}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:39:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:39:48 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:39:48 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:38:53 +0000 UTC  }],Message:,Reason:,HostIP:172.16.128.13,PodIP:172.16.0.7,StartTime:2019-03-19 10:39:47 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-03-19 10:39:47 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker://sha256:c6b8a28d5611cf83d297661ddd7f40672d286eafd7eb3852267e634e8eee0948 docker://aba1b046d795cc792cf978844d58c1680d9d8a7d9043637540e86ce2da27d61d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Mar 19 10:39:51.447: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Mar 19 10:39:53.455: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:39:53.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-26qhs" for this suite.
Mar 19 10:40:33.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:40:33.646: INFO: namespace: e2e-tests-events-26qhs, resource: bindings, ignored listing per whitelist
Mar 19 10:40:33.698: INFO: namespace e2e-tests-events-26qhs deletion completed in 40.222267218s

• [SLOW TEST:46.378 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:40:33.698: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Mar 19 10:40:33.787: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-715664315 proxy --unix-socket=/tmp/kubectl-proxy-unix287546846/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:40:33.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ctxq2" for this suite.
Mar 19 10:40:39.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:40:39.950: INFO: namespace: e2e-tests-kubectl-ctxq2, resource: bindings, ignored listing per whitelist
Mar 19 10:40:40.048: INFO: namespace e2e-tests-kubectl-ctxq2 deletion completed in 6.205899279s

• [SLOW TEST:6.350 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:40:40.048: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar 19 10:40:40.177: INFO: Number of nodes with available pods: 0
Mar 19 10:40:40.177: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:40:41.192: INFO: Number of nodes with available pods: 3
Mar 19 10:40:41.192: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Mar 19 10:40:41.224: INFO: Number of nodes with available pods: 2
Mar 19 10:40:41.224: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:40:42.239: INFO: Number of nodes with available pods: 2
Mar 19 10:40:42.239: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:40:43.240: INFO: Number of nodes with available pods: 2
Mar 19 10:40:43.240: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:40:44.239: INFO: Number of nodes with available pods: 2
Mar 19 10:40:44.240: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:40:45.238: INFO: Number of nodes with available pods: 2
Mar 19 10:40:45.238: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:40:46.238: INFO: Number of nodes with available pods: 2
Mar 19 10:40:46.238: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:40:47.240: INFO: Number of nodes with available pods: 2
Mar 19 10:40:47.240: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:40:48.239: INFO: Number of nodes with available pods: 2
Mar 19 10:40:48.239: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:40:49.239: INFO: Number of nodes with available pods: 2
Mar 19 10:40:49.239: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:40:50.240: INFO: Number of nodes with available pods: 2
Mar 19 10:40:50.240: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:40:51.239: INFO: Number of nodes with available pods: 2
Mar 19 10:40:51.239: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:40:52.239: INFO: Number of nodes with available pods: 2
Mar 19 10:40:52.240: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:40:53.240: INFO: Number of nodes with available pods: 2
Mar 19 10:40:53.240: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:40:54.239: INFO: Number of nodes with available pods: 2
Mar 19 10:40:54.239: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:40:55.238: INFO: Number of nodes with available pods: 2
Mar 19 10:40:55.238: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:40:56.238: INFO: Number of nodes with available pods: 2
Mar 19 10:40:56.238: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:40:57.240: INFO: Number of nodes with available pods: 2
Mar 19 10:40:57.240: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:40:58.240: INFO: Number of nodes with available pods: 2
Mar 19 10:40:58.240: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:40:59.240: INFO: Number of nodes with available pods: 2
Mar 19 10:40:59.240: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:41:00.239: INFO: Number of nodes with available pods: 2
Mar 19 10:41:00.239: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:41:01.240: INFO: Number of nodes with available pods: 2
Mar 19 10:41:01.240: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:41:02.240: INFO: Number of nodes with available pods: 2
Mar 19 10:41:02.240: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:41:03.242: INFO: Number of nodes with available pods: 2
Mar 19 10:41:03.242: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:41:04.240: INFO: Number of nodes with available pods: 2
Mar 19 10:41:04.240: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:41:05.240: INFO: Number of nodes with available pods: 2
Mar 19 10:41:05.240: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:41:06.242: INFO: Number of nodes with available pods: 2
Mar 19 10:41:06.242: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:41:07.240: INFO: Number of nodes with available pods: 2
Mar 19 10:41:07.240: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:41:08.240: INFO: Number of nodes with available pods: 2
Mar 19 10:41:08.240: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:41:09.240: INFO: Number of nodes with available pods: 2
Mar 19 10:41:09.240: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:41:10.240: INFO: Number of nodes with available pods: 2
Mar 19 10:41:10.240: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:41:11.240: INFO: Number of nodes with available pods: 2
Mar 19 10:41:11.240: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:41:12.240: INFO: Number of nodes with available pods: 2
Mar 19 10:41:12.240: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:41:13.240: INFO: Number of nodes with available pods: 2
Mar 19 10:41:13.241: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:41:14.240: INFO: Number of nodes with available pods: 2
Mar 19 10:41:14.240: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:41:15.240: INFO: Number of nodes with available pods: 2
Mar 19 10:41:15.240: INFO: Node k8s-node-vmwvcc-lkllt8nnod is running more than one daemon pod
Mar 19 10:41:16.240: INFO: Number of nodes with available pods: 3
Mar 19 10:41:16.240: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-nklm7, will wait for the garbage collector to delete the pods
Mar 19 10:41:16.325: INFO: Deleting {extensions DaemonSet} daemon-set took: 25.129432ms
Mar 19 10:41:16.425: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.250246ms
Mar 19 10:41:52.631: INFO: Number of nodes with available pods: 0
Mar 19 10:41:52.631: INFO: Number of running nodes: 0, number of available pods: 0
Mar 19 10:41:52.633: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-nklm7/daemonsets","resourceVersion":"1200284"},"items":null}

Mar 19 10:41:52.639: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-nklm7/pods","resourceVersion":"1200284"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:41:52.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-nklm7" for this suite.
Mar 19 10:41:58.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:41:58.755: INFO: namespace: e2e-tests-daemonsets-nklm7, resource: bindings, ignored listing per whitelist
Mar 19 10:41:58.888: INFO: namespace e2e-tests-daemonsets-nklm7 deletion completed in 6.210987154s

• [SLOW TEST:78.840 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:41:58.888: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 19 10:41:58.989: INFO: Waiting up to 5m0s for pod "downward-api-9f691106-4a33-11e9-989b-da33bd6188b3" in namespace "e2e-tests-downward-api-ccgv5" to be "success or failure"
Mar 19 10:41:58.995: INFO: Pod "downward-api-9f691106-4a33-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.446329ms
Mar 19 10:42:01.001: INFO: Pod "downward-api-9f691106-4a33-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011449889s
STEP: Saw pod success
Mar 19 10:42:01.001: INFO: Pod "downward-api-9f691106-4a33-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:42:01.011: INFO: Trying to get logs from node k8s-node-vm1y1w-lkllt8nnod pod downward-api-9f691106-4a33-11e9-989b-da33bd6188b3 container dapi-container: <nil>
STEP: delete the pod
Mar 19 10:42:01.050: INFO: Waiting for pod downward-api-9f691106-4a33-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:42:01.055: INFO: Pod downward-api-9f691106-4a33-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:42:01.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ccgv5" for this suite.
Mar 19 10:42:07.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:42:07.144: INFO: namespace: e2e-tests-downward-api-ccgv5, resource: bindings, ignored listing per whitelist
Mar 19 10:42:07.272: INFO: namespace e2e-tests-downward-api-ccgv5 deletion completed in 6.207566098s

• [SLOW TEST:8.384 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:42:07.272: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-srcd4
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-srcd4
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-srcd4
Mar 19 10:42:07.369: INFO: Found 0 stateful pods, waiting for 1
Mar 19 10:42:17.376: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Mar 19 10:42:17.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 exec --namespace=e2e-tests-statefulset-srcd4 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 19 10:42:17.540: INFO: stderr: ""
Mar 19 10:42:17.540: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 19 10:42:17.540: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 19 10:42:17.545: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar 19 10:42:27.551: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 19 10:42:27.551: INFO: Waiting for statefulset status.replicas updated to 0
Mar 19 10:42:27.569: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999724s
Mar 19 10:42:28.575: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.994251428s
Mar 19 10:42:29.581: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.988266995s
Mar 19 10:42:30.587: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.982262077s
Mar 19 10:42:31.593: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.976262309s
Mar 19 10:42:32.599: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.97016507s
Mar 19 10:42:33.605: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.964095642s
Mar 19 10:42:34.611: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.958180933s
Mar 19 10:42:35.617: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.951605562s
Mar 19 10:42:36.623: INFO: Verifying statefulset ss doesn't scale past 1 for another 945.702215ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-srcd4
Mar 19 10:42:37.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 exec --namespace=e2e-tests-statefulset-srcd4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 19 10:42:37.790: INFO: stderr: ""
Mar 19 10:42:37.790: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 19 10:42:37.790: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 19 10:42:37.795: INFO: Found 1 stateful pods, waiting for 3
Mar 19 10:42:47.801: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 19 10:42:47.801: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 19 10:42:47.801: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Mar 19 10:42:47.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 exec --namespace=e2e-tests-statefulset-srcd4 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 19 10:42:47.983: INFO: stderr: ""
Mar 19 10:42:47.983: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 19 10:42:47.983: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 19 10:42:47.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 exec --namespace=e2e-tests-statefulset-srcd4 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 19 10:42:48.146: INFO: stderr: ""
Mar 19 10:42:48.147: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 19 10:42:48.147: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 19 10:42:48.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 exec --namespace=e2e-tests-statefulset-srcd4 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 19 10:42:48.300: INFO: stderr: ""
Mar 19 10:42:48.300: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 19 10:42:48.300: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 19 10:42:48.300: INFO: Waiting for statefulset status.replicas updated to 0
Mar 19 10:42:48.303: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Mar 19 10:42:58.312: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 19 10:42:58.312: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar 19 10:42:58.312: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar 19 10:42:58.325: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999733s
Mar 19 10:42:59.331: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994270559s
Mar 19 10:43:00.337: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.988212147s
Mar 19 10:43:01.344: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.982069601s
Mar 19 10:43:02.350: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.97574874s
Mar 19 10:43:03.356: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.969680212s
Mar 19 10:43:04.362: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.963390057s
Mar 19 10:43:05.368: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.957453588s
Mar 19 10:43:06.374: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.951366915s
Mar 19 10:43:07.380: INFO: Verifying statefulset ss doesn't scale past 3 for another 945.266055ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-srcd4
Mar 19 10:43:08.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 exec --namespace=e2e-tests-statefulset-srcd4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 19 10:43:08.544: INFO: stderr: ""
Mar 19 10:43:08.544: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 19 10:43:08.544: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 19 10:43:08.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 exec --namespace=e2e-tests-statefulset-srcd4 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 19 10:43:08.706: INFO: stderr: ""
Mar 19 10:43:08.706: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 19 10:43:08.706: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 19 10:43:08.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 exec --namespace=e2e-tests-statefulset-srcd4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 19 10:43:08.871: INFO: stderr: ""
Mar 19 10:43:08.871: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 19 10:43:08.871: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 19 10:43:08.871: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 19 10:43:28.889: INFO: Deleting all statefulset in ns e2e-tests-statefulset-srcd4
Mar 19 10:43:28.892: INFO: Scaling statefulset ss to 0
Mar 19 10:43:28.903: INFO: Waiting for statefulset status.replicas updated to 0
Mar 19 10:43:28.906: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:43:28.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-srcd4" for this suite.
Mar 19 10:43:34.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:43:35.116: INFO: namespace: e2e-tests-statefulset-srcd4, resource: bindings, ignored listing per whitelist
Mar 19 10:43:35.138: INFO: namespace e2e-tests-statefulset-srcd4 deletion completed in 6.202045281s

• [SLOW TEST:87.866 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:43:35.138: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-d8c76831-4a33-11e9-989b-da33bd6188b3
STEP: Creating secret with name secret-projected-all-test-volume-d8c7681e-4a33-11e9-989b-da33bd6188b3
STEP: Creating a pod to test Check all projections for projected volume plugin
Mar 19 10:43:35.254: INFO: Waiting up to 5m0s for pod "projected-volume-d8c767f2-4a33-11e9-989b-da33bd6188b3" in namespace "e2e-tests-projected-wsk5w" to be "success or failure"
Mar 19 10:43:35.259: INFO: Pod "projected-volume-d8c767f2-4a33-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.781317ms
Mar 19 10:43:37.265: INFO: Pod "projected-volume-d8c767f2-4a33-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010708091s
STEP: Saw pod success
Mar 19 10:43:37.265: INFO: Pod "projected-volume-d8c767f2-4a33-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:43:37.270: INFO: Trying to get logs from node k8s-node-vmwvcc-lkllt8nnod pod projected-volume-d8c767f2-4a33-11e9-989b-da33bd6188b3 container projected-all-volume-test: <nil>
STEP: delete the pod
Mar 19 10:43:37.308: INFO: Waiting for pod projected-volume-d8c767f2-4a33-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:43:37.312: INFO: Pod projected-volume-d8c767f2-4a33-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:43:37.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wsk5w" for this suite.
Mar 19 10:43:43.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:43:43.499: INFO: namespace: e2e-tests-projected-wsk5w, resource: bindings, ignored listing per whitelist
Mar 19 10:43:43.531: INFO: namespace e2e-tests-projected-wsk5w deletion completed in 6.209474115s

• [SLOW TEST:8.393 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:43:43.532: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-r2kcz/secret-test-ddc6bb02-4a33-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume secrets
Mar 19 10:43:43.628: INFO: Waiting up to 5m0s for pod "pod-configmaps-ddc7ad02-4a33-11e9-989b-da33bd6188b3" in namespace "e2e-tests-secrets-r2kcz" to be "success or failure"
Mar 19 10:43:43.632: INFO: Pod "pod-configmaps-ddc7ad02-4a33-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.617544ms
Mar 19 10:43:45.638: INFO: Pod "pod-configmaps-ddc7ad02-4a33-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010200097s
STEP: Saw pod success
Mar 19 10:43:45.638: INFO: Pod "pod-configmaps-ddc7ad02-4a33-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:43:45.643: INFO: Trying to get logs from node k8s-node-vm1y1w-lkllt8nnod pod pod-configmaps-ddc7ad02-4a33-11e9-989b-da33bd6188b3 container env-test: <nil>
STEP: delete the pod
Mar 19 10:43:45.682: INFO: Waiting for pod pod-configmaps-ddc7ad02-4a33-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:43:45.686: INFO: Pod pod-configmaps-ddc7ad02-4a33-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:43:45.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-r2kcz" for this suite.
Mar 19 10:43:51.724: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:43:51.812: INFO: namespace: e2e-tests-secrets-r2kcz, resource: bindings, ignored listing per whitelist
Mar 19 10:43:51.901: INFO: namespace e2e-tests-secrets-r2kcz deletion completed in 6.207105061s

• [SLOW TEST:8.370 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:43:51.901: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 10:43:52.001: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e2c523ab-4a33-11e9-989b-da33bd6188b3" in namespace "e2e-tests-projected-cxqws" to be "success or failure"
Mar 19 10:43:52.006: INFO: Pod "downwardapi-volume-e2c523ab-4a33-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.656565ms
Mar 19 10:43:54.012: INFO: Pod "downwardapi-volume-e2c523ab-4a33-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011544622s
STEP: Saw pod success
Mar 19 10:43:54.012: INFO: Pod "downwardapi-volume-e2c523ab-4a33-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:43:54.017: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod downwardapi-volume-e2c523ab-4a33-11e9-989b-da33bd6188b3 container client-container: <nil>
STEP: delete the pod
Mar 19 10:43:54.051: INFO: Waiting for pod downwardapi-volume-e2c523ab-4a33-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:43:54.056: INFO: Pod downwardapi-volume-e2c523ab-4a33-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:43:54.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cxqws" for this suite.
Mar 19 10:44:00.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:44:00.194: INFO: namespace: e2e-tests-projected-cxqws, resource: bindings, ignored listing per whitelist
Mar 19 10:44:00.272: INFO: namespace e2e-tests-projected-cxqws deletion completed in 6.205820966s

• [SLOW TEST:8.371 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:44:00.272: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Mar 19 10:44:00.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 create -f - --namespace=e2e-tests-kubectl-ngwhw'
Mar 19 10:44:00.716: INFO: stderr: ""
Mar 19 10:44:00.716: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Mar 19 10:44:01.721: INFO: Selector matched 1 pods for map[app:redis]
Mar 19 10:44:01.721: INFO: Found 0 / 1
Mar 19 10:44:02.723: INFO: Selector matched 1 pods for map[app:redis]
Mar 19 10:44:02.723: INFO: Found 1 / 1
Mar 19 10:44:02.723: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 19 10:44:02.729: INFO: Selector matched 1 pods for map[app:redis]
Mar 19 10:44:02.729: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Mar 19 10:44:02.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 logs redis-master-hrj6r redis-master --namespace=e2e-tests-kubectl-ngwhw'
Mar 19 10:44:02.812: INFO: stderr: ""
Mar 19 10:44:02.812: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 19 Mar 10:44:01.296 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 19 Mar 10:44:01.296 # Server started, Redis version 3.2.12\n1:M 19 Mar 10:44:01.296 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 19 Mar 10:44:01.296 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Mar 19 10:44:02.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 log redis-master-hrj6r redis-master --namespace=e2e-tests-kubectl-ngwhw --tail=1'
Mar 19 10:44:02.912: INFO: stderr: ""
Mar 19 10:44:02.912: INFO: stdout: "1:M 19 Mar 10:44:01.296 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Mar 19 10:44:02.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 log redis-master-hrj6r redis-master --namespace=e2e-tests-kubectl-ngwhw --limit-bytes=1'
Mar 19 10:44:02.993: INFO: stderr: ""
Mar 19 10:44:02.993: INFO: stdout: " "
STEP: exposing timestamps
Mar 19 10:44:02.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 log redis-master-hrj6r redis-master --namespace=e2e-tests-kubectl-ngwhw --tail=1 --timestamps'
Mar 19 10:44:03.075: INFO: stderr: ""
Mar 19 10:44:03.075: INFO: stdout: "2019-03-19T10:44:01.297579785Z 1:M 19 Mar 10:44:01.296 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Mar 19 10:44:05.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 log redis-master-hrj6r redis-master --namespace=e2e-tests-kubectl-ngwhw --since=1s'
Mar 19 10:44:05.668: INFO: stderr: ""
Mar 19 10:44:05.668: INFO: stdout: ""
Mar 19 10:44:05.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 log redis-master-hrj6r redis-master --namespace=e2e-tests-kubectl-ngwhw --since=24h'
Mar 19 10:44:05.754: INFO: stderr: ""
Mar 19 10:44:05.754: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 19 Mar 10:44:01.296 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 19 Mar 10:44:01.296 # Server started, Redis version 3.2.12\n1:M 19 Mar 10:44:01.296 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 19 Mar 10:44:01.296 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Mar 19 10:44:05.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-ngwhw'
Mar 19 10:44:05.842: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 19 10:44:05.842: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Mar 19 10:44:05.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-ngwhw'
Mar 19 10:44:05.920: INFO: stderr: "No resources found.\n"
Mar 19 10:44:05.920: INFO: stdout: ""
Mar 19 10:44:05.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods -l name=nginx --namespace=e2e-tests-kubectl-ngwhw -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 19 10:44:05.982: INFO: stderr: ""
Mar 19 10:44:05.982: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:44:05.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ngwhw" for this suite.
Mar 19 10:44:28.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:44:28.184: INFO: namespace: e2e-tests-kubectl-ngwhw, resource: bindings, ignored listing per whitelist
Mar 19 10:44:28.204: INFO: namespace e2e-tests-kubectl-ngwhw deletion completed in 22.210092491s

• [SLOW TEST:27.932 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:44:28.204: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar 19 10:44:28.305: INFO: Waiting up to 5m0s for pod "pod-f868e4fe-4a33-11e9-989b-da33bd6188b3" in namespace "e2e-tests-emptydir-djv4x" to be "success or failure"
Mar 19 10:44:28.310: INFO: Pod "pod-f868e4fe-4a33-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.636352ms
Mar 19 10:44:30.316: INFO: Pod "pod-f868e4fe-4a33-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010422746s
STEP: Saw pod success
Mar 19 10:44:30.316: INFO: Pod "pod-f868e4fe-4a33-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:44:30.321: INFO: Trying to get logs from node k8s-node-vm1y1w-lkllt8nnod pod pod-f868e4fe-4a33-11e9-989b-da33bd6188b3 container test-container: <nil>
STEP: delete the pod
Mar 19 10:44:30.358: INFO: Waiting for pod pod-f868e4fe-4a33-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:44:30.363: INFO: Pod pod-f868e4fe-4a33-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:44:30.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-djv4x" for this suite.
Mar 19 10:44:36.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:44:36.454: INFO: namespace: e2e-tests-emptydir-djv4x, resource: bindings, ignored listing per whitelist
Mar 19 10:44:36.575: INFO: namespace e2e-tests-emptydir-djv4x deletion completed in 6.204196283s

• [SLOW TEST:8.371 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:44:36.575: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 10:44:36.704: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"dedee7f0-4a33-11e9-b857-fa163eaabeb9", Controller:(*bool)(0xc421774372), BlockOwnerDeletion:(*bool)(0xc421774373)}}
Mar 19 10:44:36.714: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"dedcc252-4a33-11e9-b857-fa163eaabeb9", Controller:(*bool)(0xc421a8a2c6), BlockOwnerDeletion:(*bool)(0xc421a8a2c7)}}
Mar 19 10:44:36.725: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"deddead1-4a33-11e9-b857-fa163eaabeb9", Controller:(*bool)(0xc4217745f2), BlockOwnerDeletion:(*bool)(0xc4217745f3)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:44:41.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-vpjc9" for this suite.
Mar 19 10:44:47.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:44:47.957: INFO: namespace: e2e-tests-gc-vpjc9, resource: bindings, ignored listing per whitelist
Mar 19 10:44:47.969: INFO: namespace e2e-tests-gc-vpjc9 deletion completed in 6.213301064s

• [SLOW TEST:11.394 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:44:47.969: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0319 10:44:58.111314      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 19 10:44:58.111: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:44:58.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-cmxvl" for this suite.
Mar 19 10:45:04.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:45:04.226: INFO: namespace: e2e-tests-gc-cmxvl, resource: bindings, ignored listing per whitelist
Mar 19 10:45:04.332: INFO: namespace e2e-tests-gc-cmxvl deletion completed in 6.214206516s

• [SLOW TEST:16.363 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:45:04.332: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-ghn5
STEP: Creating a pod to test atomic-volume-subpath
Mar 19 10:45:04.447: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-ghn5" in namespace "e2e-tests-subpath-hw4qg" to be "success or failure"
Mar 19 10:45:04.451: INFO: Pod "pod-subpath-test-configmap-ghn5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.811161ms
Mar 19 10:45:06.457: INFO: Pod "pod-subpath-test-configmap-ghn5": Phase="Running", Reason="", readiness=false. Elapsed: 2.010611429s
Mar 19 10:45:08.463: INFO: Pod "pod-subpath-test-configmap-ghn5": Phase="Running", Reason="", readiness=false. Elapsed: 4.016302678s
Mar 19 10:45:10.469: INFO: Pod "pod-subpath-test-configmap-ghn5": Phase="Running", Reason="", readiness=false. Elapsed: 6.022169898s
Mar 19 10:45:12.475: INFO: Pod "pod-subpath-test-configmap-ghn5": Phase="Running", Reason="", readiness=false. Elapsed: 8.028248617s
Mar 19 10:45:14.481: INFO: Pod "pod-subpath-test-configmap-ghn5": Phase="Running", Reason="", readiness=false. Elapsed: 10.034041268s
Mar 19 10:45:16.486: INFO: Pod "pod-subpath-test-configmap-ghn5": Phase="Running", Reason="", readiness=false. Elapsed: 12.039948407s
Mar 19 10:45:18.492: INFO: Pod "pod-subpath-test-configmap-ghn5": Phase="Running", Reason="", readiness=false. Elapsed: 14.045772965s
Mar 19 10:45:20.498: INFO: Pod "pod-subpath-test-configmap-ghn5": Phase="Running", Reason="", readiness=false. Elapsed: 16.051644428s
Mar 19 10:45:22.504: INFO: Pod "pod-subpath-test-configmap-ghn5": Phase="Running", Reason="", readiness=false. Elapsed: 18.057678233s
Mar 19 10:45:24.510: INFO: Pod "pod-subpath-test-configmap-ghn5": Phase="Running", Reason="", readiness=false. Elapsed: 20.063026957s
Mar 19 10:45:26.515: INFO: Pod "pod-subpath-test-configmap-ghn5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.068813119s
STEP: Saw pod success
Mar 19 10:45:26.515: INFO: Pod "pod-subpath-test-configmap-ghn5" satisfied condition "success or failure"
Mar 19 10:45:26.521: INFO: Trying to get logs from node k8s-node-vm1y1w-lkllt8nnod pod pod-subpath-test-configmap-ghn5 container test-container-subpath-configmap-ghn5: <nil>
STEP: delete the pod
Mar 19 10:45:26.563: INFO: Waiting for pod pod-subpath-test-configmap-ghn5 to disappear
Mar 19 10:45:26.568: INFO: Pod pod-subpath-test-configmap-ghn5 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-ghn5
Mar 19 10:45:26.568: INFO: Deleting pod "pod-subpath-test-configmap-ghn5" in namespace "e2e-tests-subpath-hw4qg"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:45:26.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-hw4qg" for this suite.
Mar 19 10:45:32.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:45:32.793: INFO: namespace: e2e-tests-subpath-hw4qg, resource: bindings, ignored listing per whitelist
Mar 19 10:45:32.793: INFO: namespace e2e-tests-subpath-hw4qg deletion completed in 6.211552732s

• [SLOW TEST:28.461 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:45:32.794: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-1ee85f2b-4a34-11e9-989b-da33bd6188b3
Mar 19 10:45:32.895: INFO: Pod name my-hostname-basic-1ee85f2b-4a34-11e9-989b-da33bd6188b3: Found 0 pods out of 1
Mar 19 10:45:37.901: INFO: Pod name my-hostname-basic-1ee85f2b-4a34-11e9-989b-da33bd6188b3: Found 1 pods out of 1
Mar 19 10:45:37.901: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-1ee85f2b-4a34-11e9-989b-da33bd6188b3" are running
Mar 19 10:45:37.906: INFO: Pod "my-hostname-basic-1ee85f2b-4a34-11e9-989b-da33bd6188b3-8j7zr" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-19 10:45:32 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-19 10:45:34 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-19 10:45:34 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-19 10:44:39 +0000 UTC Reason: Message:}])
Mar 19 10:45:37.906: INFO: Trying to dial the pod
Mar 19 10:45:42.922: INFO: Controller my-hostname-basic-1ee85f2b-4a34-11e9-989b-da33bd6188b3: Got expected result from replica 1 [my-hostname-basic-1ee85f2b-4a34-11e9-989b-da33bd6188b3-8j7zr]: "my-hostname-basic-1ee85f2b-4a34-11e9-989b-da33bd6188b3-8j7zr", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:45:42.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-5dxx4" for this suite.
Mar 19 10:45:48.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:45:49.021: INFO: namespace: e2e-tests-replication-controller-5dxx4, resource: bindings, ignored listing per whitelist
Mar 19 10:45:49.136: INFO: namespace e2e-tests-replication-controller-5dxx4 deletion completed in 6.203926024s

• [SLOW TEST:16.342 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:45:49.136: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-2prmz
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 19 10:45:49.224: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 19 10:46:03.367: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.0.47:8080/dial?request=hostName&protocol=udp&host=172.16.0.56&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-2prmz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 10:46:03.367: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
Mar 19 10:46:03.460: INFO: Waiting for endpoints: map[]
Mar 19 10:46:03.465: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.0.47:8080/dial?request=hostName&protocol=udp&host=172.16.0.49&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-2prmz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 10:46:03.465: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
Mar 19 10:46:03.549: INFO: Waiting for endpoints: map[]
Mar 19 10:46:03.554: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.0.47:8080/dial?request=hostName&protocol=udp&host=172.16.0.39&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-2prmz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 10:46:03.554: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
Mar 19 10:46:03.647: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:46:03.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-2prmz" for this suite.
Mar 19 10:46:27.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:46:27.710: INFO: namespace: e2e-tests-pod-network-test-2prmz, resource: bindings, ignored listing per whitelist
Mar 19 10:46:27.863: INFO: namespace e2e-tests-pod-network-test-2prmz deletion completed in 24.206038193s

• [SLOW TEST:38.727 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:46:27.863: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 19 10:46:27.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-ktdjq'
Mar 19 10:46:28.035: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar 19 10:46:28.035: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Mar 19 10:46:30.053: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-zjqtn]
Mar 19 10:46:30.053: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-zjqtn" in namespace "e2e-tests-kubectl-ktdjq" to be "running and ready"
Mar 19 10:46:30.058: INFO: Pod "e2e-test-nginx-rc-zjqtn": Phase="Running", Reason="", readiness=true. Elapsed: 4.787348ms
Mar 19 10:46:30.058: INFO: Pod "e2e-test-nginx-rc-zjqtn" satisfied condition "running and ready"
Mar 19 10:46:30.058: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-zjqtn]
Mar 19 10:46:30.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-ktdjq'
Mar 19 10:46:30.152: INFO: stderr: ""
Mar 19 10:46:30.153: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Mar 19 10:46:30.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-ktdjq'
Mar 19 10:46:30.251: INFO: stderr: ""
Mar 19 10:46:30.251: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:46:30.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ktdjq" for this suite.
Mar 19 10:46:52.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:46:52.424: INFO: namespace: e2e-tests-kubectl-ktdjq, resource: bindings, ignored listing per whitelist
Mar 19 10:46:52.458: INFO: namespace e2e-tests-kubectl-ktdjq deletion completed in 22.196679099s

• [SLOW TEST:24.594 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:46:52.458: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Mar 19 10:46:52.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 api-versions'
Mar 19 10:46:52.620: INFO: stderr: ""
Mar 19 10:46:52.620: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:46:52.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d626d" for this suite.
Mar 19 10:46:58.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:46:58.672: INFO: namespace: e2e-tests-kubectl-d626d, resource: bindings, ignored listing per whitelist
Mar 19 10:46:58.838: INFO: namespace e2e-tests-kubectl-d626d deletion completed in 6.207195318s

• [SLOW TEST:6.380 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:46:58.838: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-ppb74/configmap-test-52309ecc-4a34-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume configMaps
Mar 19 10:46:58.941: INFO: Waiting up to 5m0s for pod "pod-configmaps-5231e1fc-4a34-11e9-989b-da33bd6188b3" in namespace "e2e-tests-configmap-ppb74" to be "success or failure"
Mar 19 10:46:58.946: INFO: Pod "pod-configmaps-5231e1fc-4a34-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.865959ms
Mar 19 10:47:00.951: INFO: Pod "pod-configmaps-5231e1fc-4a34-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010392814s
STEP: Saw pod success
Mar 19 10:47:00.951: INFO: Pod "pod-configmaps-5231e1fc-4a34-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:47:00.956: INFO: Trying to get logs from node k8s-node-vmwvcc-lkllt8nnod pod pod-configmaps-5231e1fc-4a34-11e9-989b-da33bd6188b3 container env-test: <nil>
STEP: delete the pod
Mar 19 10:47:00.994: INFO: Waiting for pod pod-configmaps-5231e1fc-4a34-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:47:00.998: INFO: Pod pod-configmaps-5231e1fc-4a34-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:47:00.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ppb74" for this suite.
Mar 19 10:47:07.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:47:07.065: INFO: namespace: e2e-tests-configmap-ppb74, resource: bindings, ignored listing per whitelist
Mar 19 10:47:07.215: INFO: namespace e2e-tests-configmap-ppb74 deletion completed in 6.207374521s

• [SLOW TEST:8.377 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:47:07.215: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:47:13.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-fcxgh" for this suite.
Mar 19 10:47:19.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:47:19.601: INFO: namespace: e2e-tests-namespaces-fcxgh, resource: bindings, ignored listing per whitelist
Mar 19 10:47:19.681: INFO: namespace e2e-tests-namespaces-fcxgh deletion completed in 6.206878465s
STEP: Destroying namespace "e2e-tests-nsdeletetest-tdbtb" for this suite.
Mar 19 10:47:19.688: INFO: Namespace e2e-tests-nsdeletetest-tdbtb was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-7kpcq" for this suite.
Mar 19 10:47:25.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:47:25.750: INFO: namespace: e2e-tests-nsdeletetest-7kpcq, resource: bindings, ignored listing per whitelist
Mar 19 10:47:25.890: INFO: namespace e2e-tests-nsdeletetest-7kpcq deletion completed in 6.201892407s

• [SLOW TEST:18.674 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:47:25.890: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0319 10:47:56.549520      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 19 10:47:56.549: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:47:56.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-mv7z5" for this suite.
Mar 19 10:48:02.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:48:02.622: INFO: namespace: e2e-tests-gc-mv7z5, resource: bindings, ignored listing per whitelist
Mar 19 10:48:02.761: INFO: namespace e2e-tests-gc-mv7z5 deletion completed in 6.202581827s

• [SLOW TEST:36.871 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:48:02.761: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Mar 19 10:48:03.389: INFO: created pod pod-service-account-defaultsa
Mar 19 10:48:03.389: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Mar 19 10:48:03.397: INFO: created pod pod-service-account-mountsa
Mar 19 10:48:03.397: INFO: pod pod-service-account-mountsa service account token volume mount: true
Mar 19 10:48:03.404: INFO: created pod pod-service-account-nomountsa
Mar 19 10:48:03.404: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Mar 19 10:48:03.425: INFO: created pod pod-service-account-defaultsa-mountspec
Mar 19 10:48:03.425: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Mar 19 10:48:03.434: INFO: created pod pod-service-account-mountsa-mountspec
Mar 19 10:48:03.434: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Mar 19 10:48:03.457: INFO: created pod pod-service-account-nomountsa-mountspec
Mar 19 10:48:03.457: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Mar 19 10:48:03.466: INFO: created pod pod-service-account-defaultsa-nomountspec
Mar 19 10:48:03.466: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Mar 19 10:48:03.474: INFO: created pod pod-service-account-mountsa-nomountspec
Mar 19 10:48:03.474: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Mar 19 10:48:03.486: INFO: created pod pod-service-account-nomountsa-nomountspec
Mar 19 10:48:03.486: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:48:03.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-4ft4k" for this suite.
Mar 19 10:48:09.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:48:09.545: INFO: namespace: e2e-tests-svcaccounts-4ft4k, resource: bindings, ignored listing per whitelist
Mar 19 10:48:09.702: INFO: namespace e2e-tests-svcaccounts-4ft4k deletion completed in 6.204822577s

• [SLOW TEST:6.942 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:48:09.702: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar 19 10:48:09.795: INFO: Waiting up to 5m0s for pod "pod-7c6d7f18-4a34-11e9-989b-da33bd6188b3" in namespace "e2e-tests-emptydir-qf5pw" to be "success or failure"
Mar 19 10:48:09.799: INFO: Pod "pod-7c6d7f18-4a34-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.612206ms
Mar 19 10:48:11.805: INFO: Pod "pod-7c6d7f18-4a34-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010327707s
STEP: Saw pod success
Mar 19 10:48:11.805: INFO: Pod "pod-7c6d7f18-4a34-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:48:11.810: INFO: Trying to get logs from node k8s-node-vmwvcc-lkllt8nnod pod pod-7c6d7f18-4a34-11e9-989b-da33bd6188b3 container test-container: <nil>
STEP: delete the pod
Mar 19 10:48:11.847: INFO: Waiting for pod pod-7c6d7f18-4a34-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:48:11.852: INFO: Pod pod-7c6d7f18-4a34-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:48:11.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qf5pw" for this suite.
Mar 19 10:48:17.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:48:18.061: INFO: namespace: e2e-tests-emptydir-qf5pw, resource: bindings, ignored listing per whitelist
Mar 19 10:48:18.068: INFO: namespace e2e-tests-emptydir-qf5pw deletion completed in 6.205781732s

• [SLOW TEST:8.365 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:48:18.068: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 19 10:48:18.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-jq544'
Mar 19 10:48:18.251: INFO: stderr: ""
Mar 19 10:48:18.251: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Mar 19 10:48:18.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-jq544'
Mar 19 10:48:22.610: INFO: stderr: ""
Mar 19 10:48:22.610: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:48:22.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jq544" for this suite.
Mar 19 10:48:28.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:48:28.823: INFO: namespace: e2e-tests-kubectl-jq544, resource: bindings, ignored listing per whitelist
Mar 19 10:48:28.830: INFO: namespace e2e-tests-kubectl-jq544 deletion completed in 6.209291108s

• [SLOW TEST:10.762 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:48:28.830: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-dqdsc
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Mar 19 10:48:28.939: INFO: Found 0 stateful pods, waiting for 3
Mar 19 10:48:38.945: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 19 10:48:38.945: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 19 10:48:38.945: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Mar 19 10:48:38.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 exec --namespace=e2e-tests-statefulset-dqdsc ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 19 10:48:39.119: INFO: stderr: ""
Mar 19 10:48:39.119: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 19 10:48:39.119: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar 19 10:48:49.155: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Mar 19 10:48:59.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 exec --namespace=e2e-tests-statefulset-dqdsc ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 19 10:48:59.339: INFO: stderr: ""
Mar 19 10:48:59.339: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 19 10:48:59.339: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 19 10:49:09.364: INFO: Waiting for StatefulSet e2e-tests-statefulset-dqdsc/ss2 to complete update
Mar 19 10:49:09.364: INFO: Waiting for Pod e2e-tests-statefulset-dqdsc/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 19 10:49:09.364: INFO: Waiting for Pod e2e-tests-statefulset-dqdsc/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 19 10:49:09.364: INFO: Waiting for Pod e2e-tests-statefulset-dqdsc/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 19 10:49:19.373: INFO: Waiting for StatefulSet e2e-tests-statefulset-dqdsc/ss2 to complete update
Mar 19 10:49:19.373: INFO: Waiting for Pod e2e-tests-statefulset-dqdsc/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 19 10:49:19.373: INFO: Waiting for Pod e2e-tests-statefulset-dqdsc/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Mar 19 10:49:29.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 exec --namespace=e2e-tests-statefulset-dqdsc ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 19 10:49:29.548: INFO: stderr: ""
Mar 19 10:49:29.548: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 19 10:49:29.548: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 19 10:49:39.584: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Mar 19 10:49:49.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 exec --namespace=e2e-tests-statefulset-dqdsc ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 19 10:49:49.768: INFO: stderr: ""
Mar 19 10:49:49.768: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 19 10:49:49.768: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 19 10:49:59.794: INFO: Waiting for StatefulSet e2e-tests-statefulset-dqdsc/ss2 to complete update
Mar 19 10:49:59.794: INFO: Waiting for Pod e2e-tests-statefulset-dqdsc/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 19 10:50:09.803: INFO: Deleting all statefulset in ns e2e-tests-statefulset-dqdsc
Mar 19 10:50:09.806: INFO: Scaling statefulset ss2 to 0
Mar 19 10:50:29.826: INFO: Waiting for statefulset status.replicas updated to 0
Mar 19 10:50:29.839: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:50:29.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-dqdsc" for this suite.
Mar 19 10:50:35.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:50:36.047: INFO: namespace: e2e-tests-statefulset-dqdsc, resource: bindings, ignored listing per whitelist
Mar 19 10:50:36.077: INFO: namespace e2e-tests-statefulset-dqdsc deletion completed in 6.204716444s

• [SLOW TEST:127.247 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:50:36.078: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar 19 10:50:38.716: INFO: Successfully updated pod "pod-update-activedeadlineseconds-d3ad2dc6-4a34-11e9-989b-da33bd6188b3"
Mar 19 10:50:38.716: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-d3ad2dc6-4a34-11e9-989b-da33bd6188b3" in namespace "e2e-tests-pods-bxcz4" to be "terminated due to deadline exceeded"
Mar 19 10:50:38.725: INFO: Pod "pod-update-activedeadlineseconds-d3ad2dc6-4a34-11e9-989b-da33bd6188b3": Phase="Running", Reason="", readiness=true. Elapsed: 9.538499ms
Mar 19 10:50:40.731: INFO: Pod "pod-update-activedeadlineseconds-d3ad2dc6-4a34-11e9-989b-da33bd6188b3": Phase="Running", Reason="", readiness=true. Elapsed: 2.015158798s
Mar 19 10:50:42.737: INFO: Pod "pod-update-activedeadlineseconds-d3ad2dc6-4a34-11e9-989b-da33bd6188b3": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.020905783s
Mar 19 10:50:42.737: INFO: Pod "pod-update-activedeadlineseconds-d3ad2dc6-4a34-11e9-989b-da33bd6188b3" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:50:42.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-bxcz4" for this suite.
Mar 19 10:50:48.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:50:48.796: INFO: namespace: e2e-tests-pods-bxcz4, resource: bindings, ignored listing per whitelist
Mar 19 10:50:48.952: INFO: namespace e2e-tests-pods-bxcz4 deletion completed in 6.204297181s

• [SLOW TEST:12.874 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:50:48.952: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 10:50:49.039: INFO: Creating deployment "test-recreate-deployment"
Mar 19 10:50:49.043: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Mar 19 10:50:49.048: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Mar 19 10:50:51.055: INFO: Waiting deployment "test-recreate-deployment" to complete
Mar 19 10:50:51.058: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Mar 19 10:50:51.065: INFO: Updating deployment test-recreate-deployment
Mar 19 10:50:51.065: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 19 10:50:51.162: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-cb29p,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-cb29p/deployments/test-recreate-deployment,UID:bccb5c6c-4a34-11e9-b857-fa163eaabeb9,ResourceVersion:1202520,Generation:2,CreationTimestamp:2019-03-19 10:49:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-03-19 10:50:05 +0000 UTC 2019-03-19 10:50:05 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-03-19 10:50:05 +0000 UTC 2019-03-19 10:50:03 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Mar 19 10:50:51.166: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-cb29p,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-cb29p/replicasets/test-recreate-deployment-7cf749666b,UID:c1a3e180-4a34-11e9-8b0a-fa163ecd2a50,ResourceVersion:1202518,Generation:1,CreationTimestamp:2019-03-19 10:50:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment bccb5c6c-4a34-11e9-b857-fa163eaabeb9 0xc42284dd57 0xc42284dd58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 19 10:50:51.166: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Mar 19 10:50:51.166: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-cb29p,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-cb29p/replicasets/test-recreate-deployment-79f694ff59,UID:c06a019c-4a34-11e9-8b0a-fa163ecd2a50,ResourceVersion:1202511,Generation:2,CreationTimestamp:2019-03-19 10:50:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment bccb5c6c-4a34-11e9-b857-fa163eaabeb9 0xc42284dc97 0xc42284dc98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 19 10:50:51.172: INFO: Pod "test-recreate-deployment-7cf749666b-l2d5l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-l2d5l,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-cb29p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cb29p/pods/test-recreate-deployment-7cf749666b-l2d5l,UID:c1a508ab-4a34-11e9-8b0a-fa163ecd2a50,ResourceVersion:1202521,Generation:0,CreationTimestamp:2019-03-19 10:50:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b c1a3e180-4a34-11e9-8b0a-fa163ecd2a50 0xc421b74497 0xc421b74498}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9hmq4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9hmq4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9hmq4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vmepd8-lkllt8nnod,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421b74500} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421b74520}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 10:49:57 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:50:51.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-cb29p" for this suite.
Mar 19 10:50:57.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:50:57.220: INFO: namespace: e2e-tests-deployment-cb29p, resource: bindings, ignored listing per whitelist
Mar 19 10:50:57.386: INFO: namespace e2e-tests-deployment-cb29p deletion completed in 6.203836834s

• [SLOW TEST:8.434 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:50:57.386: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Mar 19 10:50:57.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 --namespace=e2e-tests-kubectl-jnjsv run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Mar 19 10:50:59.390: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Mar 19 10:50:59.390: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:51:01.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jnjsv" for this suite.
Mar 19 10:51:13.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:51:13.578: INFO: namespace: e2e-tests-kubectl-jnjsv, resource: bindings, ignored listing per whitelist
Mar 19 10:51:13.611: INFO: namespace e2e-tests-kubectl-jnjsv deletion completed in 12.206178568s

• [SLOW TEST:16.225 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:51:13.611: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 10:51:13.714: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ea0d44b2-4a34-11e9-989b-da33bd6188b3" in namespace "e2e-tests-projected-gpzml" to be "success or failure"
Mar 19 10:51:13.719: INFO: Pod "downwardapi-volume-ea0d44b2-4a34-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.41775ms
Mar 19 10:51:15.725: INFO: Pod "downwardapi-volume-ea0d44b2-4a34-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010930139s
STEP: Saw pod success
Mar 19 10:51:15.725: INFO: Pod "downwardapi-volume-ea0d44b2-4a34-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:51:15.730: INFO: Trying to get logs from node k8s-node-vm1y1w-lkllt8nnod pod downwardapi-volume-ea0d44b2-4a34-11e9-989b-da33bd6188b3 container client-container: <nil>
STEP: delete the pod
Mar 19 10:51:15.770: INFO: Waiting for pod downwardapi-volume-ea0d44b2-4a34-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:51:15.774: INFO: Pod downwardapi-volume-ea0d44b2-4a34-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:51:15.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gpzml" for this suite.
Mar 19 10:51:21.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:51:21.972: INFO: namespace: e2e-tests-projected-gpzml, resource: bindings, ignored listing per whitelist
Mar 19 10:51:21.988: INFO: namespace e2e-tests-projected-gpzml deletion completed in 6.205800434s

• [SLOW TEST:8.377 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:51:21.988: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-f4fcc.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-f4fcc.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-f4fcc.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-f4fcc.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-f4fcc.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-f4fcc.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 19 10:51:34.212: INFO: DNS probes using e2e-tests-dns-f4fcc/dns-test-ef0a0c5e-4a34-11e9-989b-da33bd6188b3 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:51:34.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-f4fcc" for this suite.
Mar 19 10:51:40.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:51:40.348: INFO: namespace: e2e-tests-dns-f4fcc, resource: bindings, ignored listing per whitelist
Mar 19 10:51:40.452: INFO: namespace e2e-tests-dns-f4fcc deletion completed in 6.204323561s

• [SLOW TEST:18.464 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:51:40.452: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Mar 19 10:51:40.552: INFO: Waiting up to 5m0s for pod "var-expansion-fa0c5fe3-4a34-11e9-989b-da33bd6188b3" in namespace "e2e-tests-var-expansion-vxttr" to be "success or failure"
Mar 19 10:51:40.557: INFO: Pod "var-expansion-fa0c5fe3-4a34-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.674423ms
Mar 19 10:51:42.563: INFO: Pod "var-expansion-fa0c5fe3-4a34-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010495142s
STEP: Saw pod success
Mar 19 10:51:42.563: INFO: Pod "var-expansion-fa0c5fe3-4a34-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:51:42.568: INFO: Trying to get logs from node k8s-node-vmwvcc-lkllt8nnod pod var-expansion-fa0c5fe3-4a34-11e9-989b-da33bd6188b3 container dapi-container: <nil>
STEP: delete the pod
Mar 19 10:51:42.612: INFO: Waiting for pod var-expansion-fa0c5fe3-4a34-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:51:42.616: INFO: Pod var-expansion-fa0c5fe3-4a34-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:51:42.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-vxttr" for this suite.
Mar 19 10:51:48.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:51:48.740: INFO: namespace: e2e-tests-var-expansion-vxttr, resource: bindings, ignored listing per whitelist
Mar 19 10:51:48.832: INFO: namespace e2e-tests-var-expansion-vxttr deletion completed in 6.205394161s

• [SLOW TEST:8.379 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:51:48.832: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-9r56z
Mar 19 10:51:50.938: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-9r56z
STEP: checking the pod's current state and verifying that restartCount is present
Mar 19 10:51:50.943: INFO: Initial restart count of pod liveness-exec is 0
Mar 19 10:52:39.087: INFO: Restart count of pod e2e-tests-container-probe-9r56z/liveness-exec is now 1 (48.144703644s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:52:39.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-9r56z" for this suite.
Mar 19 10:52:45.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:52:45.243: INFO: namespace: e2e-tests-container-probe-9r56z, resource: bindings, ignored listing per whitelist
Mar 19 10:52:45.329: INFO: namespace e2e-tests-container-probe-9r56z deletion completed in 6.203955304s

• [SLOW TEST:56.497 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:52:45.329: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Mar 19 10:52:45.417: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 19 10:52:45.434: INFO: Waiting for terminating namespaces to be deleted...
Mar 19 10:52:45.441: INFO: 
Logging pods the kubelet thinks is on node k8s-node-vm1y1w-lkllt8nnod before test
Mar 19 10:52:45.455: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-19 09:59:45 +0000 UTC (1 container statuses recorded)
Mar 19 10:52:45.455: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 19 10:52:45.455: INFO: sonobuoy-systemd-logs-daemon-set-421c51583ba54221-jfpn4 from heptio-sonobuoy started at 2019-03-19 09:59:46 +0000 UTC (2 container statuses recorded)
Mar 19 10:52:45.455: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 19 10:52:45.455: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 19 10:52:45.455: INFO: jdcloud-k8s-ipamd-9pz6x from kube-system started at 2019-03-18 06:26:18 +0000 UTC (1 container statuses recorded)
Mar 19 10:52:45.455: INFO: 	Container jdcloud-k8s-ipamd ready: true, restart count 0
Mar 19 10:52:45.455: INFO: kube-proxy-89266 from kube-system started at 2019-03-18 06:26:37 +0000 UTC (1 container statuses recorded)
Mar 19 10:52:45.455: INFO: 	Container kube-proxy ready: true, restart count 0
Mar 19 10:52:45.455: INFO: prometheus-6f5dfd9fcd-zxm4n from jke-system started at 2019-03-18 06:46:24 +0000 UTC (1 container statuses recorded)
Mar 19 10:52:45.455: INFO: 	Container prometheus ready: true, restart count 0
Mar 19 10:52:45.455: INFO: node-exporter-lm4pq from jke-system started at 2019-03-18 06:26:37 +0000 UTC (1 container statuses recorded)
Mar 19 10:52:45.455: INFO: 	Container node-exporter ready: true, restart count 0
Mar 19 10:52:45.455: INFO: kube-state-metrics-c866955d-j29vx from jke-system started at 2019-03-18 06:26:56 +0000 UTC (2 container statuses recorded)
Mar 19 10:52:45.455: INFO: 	Container addon-resizer ready: true, restart count 0
Mar 19 10:52:45.455: INFO: 	Container kube-state-metrics ready: true, restart count 0
Mar 19 10:52:45.455: INFO: 
Logging pods the kubelet thinks is on node k8s-node-vmepd8-lkllt8nnod before test
Mar 19 10:52:45.467: INFO: heapster-5899f7978c-f6x7x from kube-system started at 2019-03-18 06:46:24 +0000 UTC (1 container statuses recorded)
Mar 19 10:52:45.467: INFO: 	Container heapster ready: true, restart count 0
Mar 19 10:52:45.467: INFO: sonobuoy-e2e-job-7e66631fb61c4f2f from heptio-sonobuoy started at 2019-03-19 09:59:46 +0000 UTC (2 container statuses recorded)
Mar 19 10:52:45.467: INFO: 	Container e2e ready: true, restart count 0
Mar 19 10:52:45.467: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 19 10:52:45.467: INFO: kube-proxy-h74kb from kube-system started at 2019-03-18 06:26:51 +0000 UTC (1 container statuses recorded)
Mar 19 10:52:45.467: INFO: 	Container kube-proxy ready: true, restart count 0
Mar 19 10:52:45.467: INFO: coredns-6b474698f5-6qcd7 from kube-system started at 2019-03-18 06:46:24 +0000 UTC (1 container statuses recorded)
Mar 19 10:52:45.467: INFO: 	Container coredns ready: true, restart count 0
Mar 19 10:52:45.467: INFO: sonobuoy-systemd-logs-daemon-set-421c51583ba54221-wk6bb from heptio-sonobuoy started at 2019-03-19 09:59:46 +0000 UTC (2 container statuses recorded)
Mar 19 10:52:45.467: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 19 10:52:45.467: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 19 10:52:45.467: INFO: jdcloud-k8s-ipamd-9lcf8 from kube-system started at 2019-03-18 06:26:51 +0000 UTC (1 container statuses recorded)
Mar 19 10:52:45.468: INFO: 	Container jdcloud-k8s-ipamd ready: true, restart count 0
Mar 19 10:52:45.468: INFO: node-exporter-s8d56 from jke-system started at 2019-03-18 06:27:10 +0000 UTC (1 container statuses recorded)
Mar 19 10:52:45.468: INFO: 	Container node-exporter ready: true, restart count 0
Mar 19 10:52:45.468: INFO: 
Logging pods the kubelet thinks is on node k8s-node-vmwvcc-lkllt8nnod before test
Mar 19 10:52:45.479: INFO: sonobuoy-systemd-logs-daemon-set-421c51583ba54221-86srx from heptio-sonobuoy started at 2019-03-19 09:59:46 +0000 UTC (2 container statuses recorded)
Mar 19 10:52:45.479: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 19 10:52:45.479: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 19 10:52:45.479: INFO: kube-proxy-n5vt5 from kube-system started at 2019-03-18 06:25:45 +0000 UTC (1 container statuses recorded)
Mar 19 10:52:45.479: INFO: 	Container kube-proxy ready: true, restart count 0
Mar 19 10:52:45.479: INFO: prometheus-jdmon-69d8fd6b87-sf5hc from jke-system started at 2019-03-18 06:46:24 +0000 UTC (2 container statuses recorded)
Mar 19 10:52:45.479: INFO: 	Container k8s-metrics-to-jdmon ready: true, restart count 0
Mar 19 10:52:45.479: INFO: 	Container refresher ready: true, restart count 0
Mar 19 10:52:45.479: INFO: coredns-6b474698f5-hgplj from kube-system started at 2019-03-18 06:46:24 +0000 UTC (1 container statuses recorded)
Mar 19 10:52:45.479: INFO: 	Container coredns ready: true, restart count 0
Mar 19 10:52:45.479: INFO: jdcloud-k8s-ipamd-tfr8l from kube-system started at 2019-03-18 06:25:27 +0000 UTC (1 container statuses recorded)
Mar 19 10:52:45.479: INFO: 	Container jdcloud-k8s-ipamd ready: true, restart count 0
Mar 19 10:52:45.479: INFO: node-exporter-nx6zb from jke-system started at 2019-03-18 06:25:45 +0000 UTC (1 container statuses recorded)
Mar 19 10:52:45.479: INFO: 	Container node-exporter ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-21fa129d-4a35-11e9-989b-da33bd6188b3 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-21fa129d-4a35-11e9-989b-da33bd6188b3 off the node k8s-node-vm1y1w-lkllt8nnod
STEP: verifying the node doesn't have the label kubernetes.io/e2e-21fa129d-4a35-11e9-989b-da33bd6188b3
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:52:49.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-d4n2c" for this suite.
Mar 19 10:52:57.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:52:57.651: INFO: namespace: e2e-tests-sched-pred-d4n2c, resource: bindings, ignored listing per whitelist
Mar 19 10:52:57.815: INFO: namespace e2e-tests-sched-pred-d4n2c deletion completed in 8.203608876s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:12.487 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:52:57.816: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar 19 10:52:57.920: INFO: Waiting up to 5m0s for pod "pod-2829df1b-4a35-11e9-989b-da33bd6188b3" in namespace "e2e-tests-emptydir-ghj5m" to be "success or failure"
Mar 19 10:52:57.925: INFO: Pod "pod-2829df1b-4a35-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.529021ms
Mar 19 10:52:59.931: INFO: Pod "pod-2829df1b-4a35-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010332472s
STEP: Saw pod success
Mar 19 10:52:59.931: INFO: Pod "pod-2829df1b-4a35-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:52:59.935: INFO: Trying to get logs from node k8s-node-vmwvcc-lkllt8nnod pod pod-2829df1b-4a35-11e9-989b-da33bd6188b3 container test-container: <nil>
STEP: delete the pod
Mar 19 10:52:59.974: INFO: Waiting for pod pod-2829df1b-4a35-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:52:59.979: INFO: Pod pod-2829df1b-4a35-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:52:59.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ghj5m" for this suite.
Mar 19 10:53:06.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:53:06.181: INFO: namespace: e2e-tests-emptydir-ghj5m, resource: bindings, ignored listing per whitelist
Mar 19 10:53:06.193: INFO: namespace e2e-tests-emptydir-ghj5m deletion completed in 6.204491233s

• [SLOW TEST:8.378 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:53:06.193: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar 19 10:53:06.289: INFO: Waiting up to 5m0s for pod "pod-2d26feb3-4a35-11e9-989b-da33bd6188b3" in namespace "e2e-tests-emptydir-7bv8n" to be "success or failure"
Mar 19 10:53:06.295: INFO: Pod "pod-2d26feb3-4a35-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.164959ms
Mar 19 10:53:08.301: INFO: Pod "pod-2d26feb3-4a35-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012246051s
STEP: Saw pod success
Mar 19 10:53:08.301: INFO: Pod "pod-2d26feb3-4a35-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:53:08.306: INFO: Trying to get logs from node k8s-node-vm1y1w-lkllt8nnod pod pod-2d26feb3-4a35-11e9-989b-da33bd6188b3 container test-container: <nil>
STEP: delete the pod
Mar 19 10:53:08.342: INFO: Waiting for pod pod-2d26feb3-4a35-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:53:08.346: INFO: Pod pod-2d26feb3-4a35-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:53:08.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7bv8n" for this suite.
Mar 19 10:53:14.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:53:14.487: INFO: namespace: e2e-tests-emptydir-7bv8n, resource: bindings, ignored listing per whitelist
Mar 19 10:53:14.561: INFO: namespace e2e-tests-emptydir-7bv8n deletion completed in 6.204458527s

• [SLOW TEST:8.367 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:53:14.561: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-l2jx
STEP: Creating a pod to test atomic-volume-subpath
Mar 19 10:53:14.675: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-l2jx" in namespace "e2e-tests-subpath-sd6lv" to be "success or failure"
Mar 19 10:53:14.680: INFO: Pod "pod-subpath-test-projected-l2jx": Phase="Pending", Reason="", readiness=false. Elapsed: 4.748246ms
Mar 19 10:53:16.686: INFO: Pod "pod-subpath-test-projected-l2jx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010608421s
Mar 19 10:53:18.692: INFO: Pod "pod-subpath-test-projected-l2jx": Phase="Running", Reason="", readiness=false. Elapsed: 4.016227528s
Mar 19 10:53:20.698: INFO: Pod "pod-subpath-test-projected-l2jx": Phase="Running", Reason="", readiness=false. Elapsed: 6.022140763s
Mar 19 10:53:22.703: INFO: Pod "pod-subpath-test-projected-l2jx": Phase="Running", Reason="", readiness=false. Elapsed: 8.027994198s
Mar 19 10:53:24.709: INFO: Pod "pod-subpath-test-projected-l2jx": Phase="Running", Reason="", readiness=false. Elapsed: 10.033734077s
Mar 19 10:53:26.715: INFO: Pod "pod-subpath-test-projected-l2jx": Phase="Running", Reason="", readiness=false. Elapsed: 12.039806741s
Mar 19 10:53:28.721: INFO: Pod "pod-subpath-test-projected-l2jx": Phase="Running", Reason="", readiness=false. Elapsed: 14.045661365s
Mar 19 10:53:30.727: INFO: Pod "pod-subpath-test-projected-l2jx": Phase="Running", Reason="", readiness=false. Elapsed: 16.051588796s
Mar 19 10:53:32.733: INFO: Pod "pod-subpath-test-projected-l2jx": Phase="Running", Reason="", readiness=false. Elapsed: 18.057601634s
Mar 19 10:53:34.739: INFO: Pod "pod-subpath-test-projected-l2jx": Phase="Running", Reason="", readiness=false. Elapsed: 20.063211766s
Mar 19 10:53:36.745: INFO: Pod "pod-subpath-test-projected-l2jx": Phase="Running", Reason="", readiness=false. Elapsed: 22.069365223s
Mar 19 10:53:38.751: INFO: Pod "pod-subpath-test-projected-l2jx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.075584459s
STEP: Saw pod success
Mar 19 10:53:38.751: INFO: Pod "pod-subpath-test-projected-l2jx" satisfied condition "success or failure"
Mar 19 10:53:38.756: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod pod-subpath-test-projected-l2jx container test-container-subpath-projected-l2jx: <nil>
STEP: delete the pod
Mar 19 10:53:38.792: INFO: Waiting for pod pod-subpath-test-projected-l2jx to disappear
Mar 19 10:53:38.797: INFO: Pod pod-subpath-test-projected-l2jx no longer exists
STEP: Deleting pod pod-subpath-test-projected-l2jx
Mar 19 10:53:38.797: INFO: Deleting pod "pod-subpath-test-projected-l2jx" in namespace "e2e-tests-subpath-sd6lv"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:53:38.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-sd6lv" for this suite.
Mar 19 10:53:44.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:53:45.009: INFO: namespace: e2e-tests-subpath-sd6lv, resource: bindings, ignored listing per whitelist
Mar 19 10:53:45.017: INFO: namespace e2e-tests-subpath-sd6lv deletion completed in 6.207362497s

• [SLOW TEST:30.457 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:53:45.018: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-zf4t
STEP: Creating a pod to test atomic-volume-subpath
Mar 19 10:53:45.131: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-zf4t" in namespace "e2e-tests-subpath-6jfq7" to be "success or failure"
Mar 19 10:53:45.137: INFO: Pod "pod-subpath-test-configmap-zf4t": Phase="Pending", Reason="", readiness=false. Elapsed: 5.608832ms
Mar 19 10:53:47.142: INFO: Pod "pod-subpath-test-configmap-zf4t": Phase="Running", Reason="", readiness=false. Elapsed: 2.011420972s
Mar 19 10:53:49.149: INFO: Pod "pod-subpath-test-configmap-zf4t": Phase="Running", Reason="", readiness=false. Elapsed: 4.017981794s
Mar 19 10:53:51.155: INFO: Pod "pod-subpath-test-configmap-zf4t": Phase="Running", Reason="", readiness=false. Elapsed: 6.023747561s
Mar 19 10:53:53.161: INFO: Pod "pod-subpath-test-configmap-zf4t": Phase="Running", Reason="", readiness=false. Elapsed: 8.029659042s
Mar 19 10:53:55.167: INFO: Pod "pod-subpath-test-configmap-zf4t": Phase="Running", Reason="", readiness=false. Elapsed: 10.035683087s
Mar 19 10:53:57.173: INFO: Pod "pod-subpath-test-configmap-zf4t": Phase="Running", Reason="", readiness=false. Elapsed: 12.041633769s
Mar 19 10:53:59.179: INFO: Pod "pod-subpath-test-configmap-zf4t": Phase="Running", Reason="", readiness=false. Elapsed: 14.047541837s
Mar 19 10:54:01.184: INFO: Pod "pod-subpath-test-configmap-zf4t": Phase="Running", Reason="", readiness=false. Elapsed: 16.05343108s
Mar 19 10:54:03.190: INFO: Pod "pod-subpath-test-configmap-zf4t": Phase="Running", Reason="", readiness=false. Elapsed: 18.059368953s
Mar 19 10:54:05.196: INFO: Pod "pod-subpath-test-configmap-zf4t": Phase="Running", Reason="", readiness=false. Elapsed: 20.065122109s
Mar 19 10:54:07.202: INFO: Pod "pod-subpath-test-configmap-zf4t": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.070828361s
STEP: Saw pod success
Mar 19 10:54:07.202: INFO: Pod "pod-subpath-test-configmap-zf4t" satisfied condition "success or failure"
Mar 19 10:54:07.207: INFO: Trying to get logs from node k8s-node-vmwvcc-lkllt8nnod pod pod-subpath-test-configmap-zf4t container test-container-subpath-configmap-zf4t: <nil>
STEP: delete the pod
Mar 19 10:54:07.253: INFO: Waiting for pod pod-subpath-test-configmap-zf4t to disappear
Mar 19 10:54:07.264: INFO: Pod pod-subpath-test-configmap-zf4t no longer exists
STEP: Deleting pod pod-subpath-test-configmap-zf4t
Mar 19 10:54:07.264: INFO: Deleting pod "pod-subpath-test-configmap-zf4t" in namespace "e2e-tests-subpath-6jfq7"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:54:07.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-6jfq7" for this suite.
Mar 19 10:54:13.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:54:13.357: INFO: namespace: e2e-tests-subpath-6jfq7, resource: bindings, ignored listing per whitelist
Mar 19 10:54:13.480: INFO: namespace e2e-tests-subpath-6jfq7 deletion completed in 6.201740288s

• [SLOW TEST:28.463 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:54:13.480: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-55427ea5-4a35-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume secrets
Mar 19 10:54:13.585: INFO: Waiting up to 5m0s for pod "pod-secrets-55437580-4a35-11e9-989b-da33bd6188b3" in namespace "e2e-tests-secrets-frxns" to be "success or failure"
Mar 19 10:54:13.591: INFO: Pod "pod-secrets-55437580-4a35-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.631088ms
Mar 19 10:54:15.597: INFO: Pod "pod-secrets-55437580-4a35-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012191693s
STEP: Saw pod success
Mar 19 10:54:15.597: INFO: Pod "pod-secrets-55437580-4a35-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:54:15.602: INFO: Trying to get logs from node k8s-node-vm1y1w-lkllt8nnod pod pod-secrets-55437580-4a35-11e9-989b-da33bd6188b3 container secret-volume-test: <nil>
STEP: delete the pod
Mar 19 10:54:15.639: INFO: Waiting for pod pod-secrets-55437580-4a35-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:54:15.644: INFO: Pod pod-secrets-55437580-4a35-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:54:15.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-frxns" for this suite.
Mar 19 10:54:21.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:54:21.858: INFO: namespace: e2e-tests-secrets-frxns, resource: bindings, ignored listing per whitelist
Mar 19 10:54:21.860: INFO: namespace e2e-tests-secrets-frxns deletion completed in 6.207067657s

• [SLOW TEST:8.380 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:54:21.860: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Mar 19 10:54:21.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 cluster-info'
Mar 19 10:54:22.168: INFO: stderr: ""
Mar 19 10:54:22.168: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.16.224.1:443\x1b[0m\n\x1b[0;32mHeapster\x1b[0m is running at \x1b[0;33mhttps://172.16.224.1:443/api/v1/namespaces/kube-system/services/heapster/proxy\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://172.16.224.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:54:22.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4thpk" for this suite.
Mar 19 10:54:28.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:54:28.250: INFO: namespace: e2e-tests-kubectl-4thpk, resource: bindings, ignored listing per whitelist
Mar 19 10:54:28.380: INFO: namespace e2e-tests-kubectl-4thpk deletion completed in 6.203265188s

• [SLOW TEST:6.520 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:54:28.380: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-5e23d5cd-4a35-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume configMaps
Mar 19 10:54:28.486: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5e251e90-4a35-11e9-989b-da33bd6188b3" in namespace "e2e-tests-projected-5j62f" to be "success or failure"
Mar 19 10:54:28.491: INFO: Pod "pod-projected-configmaps-5e251e90-4a35-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.754196ms
Mar 19 10:54:30.497: INFO: Pod "pod-projected-configmaps-5e251e90-4a35-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010660816s
STEP: Saw pod success
Mar 19 10:54:30.497: INFO: Pod "pod-projected-configmaps-5e251e90-4a35-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:54:30.502: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod pod-projected-configmaps-5e251e90-4a35-11e9-989b-da33bd6188b3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 19 10:54:30.538: INFO: Waiting for pod pod-projected-configmaps-5e251e90-4a35-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:54:30.543: INFO: Pod pod-projected-configmaps-5e251e90-4a35-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:54:30.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5j62f" for this suite.
Mar 19 10:54:36.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:54:36.650: INFO: namespace: e2e-tests-projected-5j62f, resource: bindings, ignored listing per whitelist
Mar 19 10:54:36.758: INFO: namespace e2e-tests-projected-5j62f deletion completed in 6.205278174s

• [SLOW TEST:8.378 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:54:36.758: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar 19 10:54:36.853: INFO: Waiting up to 5m0s for pod "pod-6321afeb-4a35-11e9-989b-da33bd6188b3" in namespace "e2e-tests-emptydir-fwvm7" to be "success or failure"
Mar 19 10:54:36.858: INFO: Pod "pod-6321afeb-4a35-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.865383ms
Mar 19 10:54:38.863: INFO: Pod "pod-6321afeb-4a35-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010630886s
STEP: Saw pod success
Mar 19 10:54:38.863: INFO: Pod "pod-6321afeb-4a35-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:54:38.868: INFO: Trying to get logs from node k8s-node-vmwvcc-lkllt8nnod pod pod-6321afeb-4a35-11e9-989b-da33bd6188b3 container test-container: <nil>
STEP: delete the pod
Mar 19 10:54:38.904: INFO: Waiting for pod pod-6321afeb-4a35-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:54:38.909: INFO: Pod pod-6321afeb-4a35-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:54:38.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-fwvm7" for this suite.
Mar 19 10:54:44.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:54:44.955: INFO: namespace: e2e-tests-emptydir-fwvm7, resource: bindings, ignored listing per whitelist
Mar 19 10:54:45.126: INFO: namespace e2e-tests-emptydir-fwvm7 deletion completed in 6.207280291s

• [SLOW TEST:8.368 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:54:45.127: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 10:54:45.227: INFO: Waiting up to 5m0s for pod "downwardapi-volume-681fadb2-4a35-11e9-989b-da33bd6188b3" in namespace "e2e-tests-downward-api-fxdtm" to be "success or failure"
Mar 19 10:54:45.232: INFO: Pod "downwardapi-volume-681fadb2-4a35-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.71683ms
Mar 19 10:54:47.238: INFO: Pod "downwardapi-volume-681fadb2-4a35-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0106371s
STEP: Saw pod success
Mar 19 10:54:47.238: INFO: Pod "downwardapi-volume-681fadb2-4a35-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:54:47.243: INFO: Trying to get logs from node k8s-node-vm1y1w-lkllt8nnod pod downwardapi-volume-681fadb2-4a35-11e9-989b-da33bd6188b3 container client-container: <nil>
STEP: delete the pod
Mar 19 10:54:47.281: INFO: Waiting for pod downwardapi-volume-681fadb2-4a35-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:54:47.286: INFO: Pod downwardapi-volume-681fadb2-4a35-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:54:47.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fxdtm" for this suite.
Mar 19 10:54:53.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:54:53.411: INFO: namespace: e2e-tests-downward-api-fxdtm, resource: bindings, ignored listing per whitelist
Mar 19 10:54:53.498: INFO: namespace e2e-tests-downward-api-fxdtm deletion completed in 6.203231696s

• [SLOW TEST:8.372 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:54:53.498: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Mar 19 10:54:53.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 create -f - --namespace=e2e-tests-kubectl-przdq'
Mar 19 10:54:53.738: INFO: stderr: ""
Mar 19 10:54:53.738: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 19 10:54:53.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-przdq'
Mar 19 10:54:53.833: INFO: stderr: ""
Mar 19 10:54:53.833: INFO: stdout: "update-demo-nautilus-g7hpk update-demo-nautilus-pdg9s "
Mar 19 10:54:53.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods update-demo-nautilus-g7hpk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-przdq'
Mar 19 10:54:53.905: INFO: stderr: ""
Mar 19 10:54:53.905: INFO: stdout: ""
Mar 19 10:54:53.905: INFO: update-demo-nautilus-g7hpk is created but not running
Mar 19 10:54:58.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-przdq'
Mar 19 10:54:58.974: INFO: stderr: ""
Mar 19 10:54:58.974: INFO: stdout: "update-demo-nautilus-g7hpk update-demo-nautilus-pdg9s "
Mar 19 10:54:58.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods update-demo-nautilus-g7hpk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-przdq'
Mar 19 10:54:59.046: INFO: stderr: ""
Mar 19 10:54:59.046: INFO: stdout: "true"
Mar 19 10:54:59.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods update-demo-nautilus-g7hpk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-przdq'
Mar 19 10:54:59.158: INFO: stderr: ""
Mar 19 10:54:59.158: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 19 10:54:59.158: INFO: validating pod update-demo-nautilus-g7hpk
Mar 19 10:54:59.164: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 19 10:54:59.164: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 19 10:54:59.164: INFO: update-demo-nautilus-g7hpk is verified up and running
Mar 19 10:54:59.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods update-demo-nautilus-pdg9s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-przdq'
Mar 19 10:54:59.227: INFO: stderr: ""
Mar 19 10:54:59.227: INFO: stdout: "true"
Mar 19 10:54:59.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods update-demo-nautilus-pdg9s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-przdq'
Mar 19 10:54:59.298: INFO: stderr: ""
Mar 19 10:54:59.298: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 19 10:54:59.298: INFO: validating pod update-demo-nautilus-pdg9s
Mar 19 10:54:59.306: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 19 10:54:59.306: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 19 10:54:59.306: INFO: update-demo-nautilus-pdg9s is verified up and running
STEP: rolling-update to new replication controller
Mar 19 10:54:59.307: INFO: scanned /root for discovery docs: <nil>
Mar 19 10:54:59.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-przdq'
Mar 19 10:55:21.844: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar 19 10:55:21.844: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 19 10:55:21.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-przdq'
Mar 19 10:55:21.913: INFO: stderr: ""
Mar 19 10:55:21.913: INFO: stdout: "update-demo-kitten-mznd9 update-demo-kitten-p69b4 "
Mar 19 10:55:21.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods update-demo-kitten-mznd9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-przdq'
Mar 19 10:55:21.994: INFO: stderr: ""
Mar 19 10:55:21.994: INFO: stdout: "true"
Mar 19 10:55:21.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods update-demo-kitten-mznd9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-przdq'
Mar 19 10:55:22.060: INFO: stderr: ""
Mar 19 10:55:22.060: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar 19 10:55:22.060: INFO: validating pod update-demo-kitten-mznd9
Mar 19 10:55:22.071: INFO: got data: {
  "image": "kitten.jpg"
}

Mar 19 10:55:22.071: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar 19 10:55:22.071: INFO: update-demo-kitten-mznd9 is verified up and running
Mar 19 10:55:22.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods update-demo-kitten-p69b4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-przdq'
Mar 19 10:55:22.133: INFO: stderr: ""
Mar 19 10:55:22.133: INFO: stdout: "true"
Mar 19 10:55:22.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods update-demo-kitten-p69b4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-przdq'
Mar 19 10:55:22.204: INFO: stderr: ""
Mar 19 10:55:22.204: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar 19 10:55:22.204: INFO: validating pod update-demo-kitten-p69b4
Mar 19 10:55:22.211: INFO: got data: {
  "image": "kitten.jpg"
}

Mar 19 10:55:22.211: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar 19 10:55:22.211: INFO: update-demo-kitten-p69b4 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:55:22.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-przdq" for this suite.
Mar 19 10:55:44.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:55:44.366: INFO: namespace: e2e-tests-kubectl-przdq, resource: bindings, ignored listing per whitelist
Mar 19 10:55:44.435: INFO: namespace e2e-tests-kubectl-przdq deletion completed in 22.214492418s

• [SLOW TEST:50.937 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:55:44.435: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar 19 10:55:48.588: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 19 10:55:48.593: INFO: Pod pod-with-prestop-http-hook still exists
Mar 19 10:55:50.593: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 19 10:55:50.599: INFO: Pod pod-with-prestop-http-hook still exists
Mar 19 10:55:52.593: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 19 10:55:52.599: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:55:52.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-rqpxk" for this suite.
Mar 19 10:56:14.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:56:14.667: INFO: namespace: e2e-tests-container-lifecycle-hook-rqpxk, resource: bindings, ignored listing per whitelist
Mar 19 10:56:14.834: INFO: namespace e2e-tests-container-lifecycle-hook-rqpxk deletion completed in 22.208150665s

• [SLOW TEST:30.399 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:56:14.834: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 19 10:56:14.919: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:56:17.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-dwqgb" for this suite.
Mar 19 10:56:39.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:56:39.987: INFO: namespace: e2e-tests-init-container-dwqgb, resource: bindings, ignored listing per whitelist
Mar 19 10:56:40.076: INFO: namespace e2e-tests-init-container-dwqgb deletion completed in 22.20331409s

• [SLOW TEST:25.242 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:56:40.076: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 19 10:56:40.177: INFO: Waiting up to 5m0s for pod "downward-api-aca3b0ab-4a35-11e9-989b-da33bd6188b3" in namespace "e2e-tests-downward-api-42pnr" to be "success or failure"
Mar 19 10:56:40.181: INFO: Pod "downward-api-aca3b0ab-4a35-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.590937ms
Mar 19 10:56:42.187: INFO: Pod "downward-api-aca3b0ab-4a35-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010343175s
STEP: Saw pod success
Mar 19 10:56:42.187: INFO: Pod "downward-api-aca3b0ab-4a35-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:56:42.192: INFO: Trying to get logs from node k8s-node-vm1y1w-lkllt8nnod pod downward-api-aca3b0ab-4a35-11e9-989b-da33bd6188b3 container dapi-container: <nil>
STEP: delete the pod
Mar 19 10:56:42.235: INFO: Waiting for pod downward-api-aca3b0ab-4a35-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:56:42.242: INFO: Pod downward-api-aca3b0ab-4a35-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:56:42.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-42pnr" for this suite.
Mar 19 10:56:48.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:56:48.338: INFO: namespace: e2e-tests-downward-api-42pnr, resource: bindings, ignored listing per whitelist
Mar 19 10:56:48.465: INFO: namespace e2e-tests-downward-api-42pnr deletion completed in 6.214207007s

• [SLOW TEST:8.389 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:56:48.465: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Mar 19 10:56:48.585: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-pt2qm,SelfLink:/api/v1/namespaces/e2e-tests-watch-pt2qm/configmaps/e2e-watch-test-label-changed,UID:930f23de-4a35-11e9-b857-fa163eaabeb9,ResourceVersion:1203823,Generation:0,CreationTimestamp:2019-03-19 10:55:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 19 10:56:48.585: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-pt2qm,SelfLink:/api/v1/namespaces/e2e-tests-watch-pt2qm/configmaps/e2e-watch-test-label-changed,UID:930f23de-4a35-11e9-b857-fa163eaabeb9,ResourceVersion:1203824,Generation:0,CreationTimestamp:2019-03-19 10:55:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar 19 10:56:48.585: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-pt2qm,SelfLink:/api/v1/namespaces/e2e-tests-watch-pt2qm/configmaps/e2e-watch-test-label-changed,UID:930f23de-4a35-11e9-b857-fa163eaabeb9,ResourceVersion:1203825,Generation:0,CreationTimestamp:2019-03-19 10:55:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Mar 19 10:56:58.655: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-pt2qm,SelfLink:/api/v1/namespaces/e2e-tests-watch-pt2qm/configmaps/e2e-watch-test-label-changed,UID:930f23de-4a35-11e9-b857-fa163eaabeb9,ResourceVersion:1203844,Generation:0,CreationTimestamp:2019-03-19 10:55:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 19 10:56:58.655: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-pt2qm,SelfLink:/api/v1/namespaces/e2e-tests-watch-pt2qm/configmaps/e2e-watch-test-label-changed,UID:930f23de-4a35-11e9-b857-fa163eaabeb9,ResourceVersion:1203845,Generation:0,CreationTimestamp:2019-03-19 10:55:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Mar 19 10:56:58.655: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-pt2qm,SelfLink:/api/v1/namespaces/e2e-tests-watch-pt2qm/configmaps/e2e-watch-test-label-changed,UID:930f23de-4a35-11e9-b857-fa163eaabeb9,ResourceVersion:1203846,Generation:0,CreationTimestamp:2019-03-19 10:55:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:56:58.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-pt2qm" for this suite.
Mar 19 10:57:04.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:57:04.799: INFO: namespace: e2e-tests-watch-pt2qm, resource: bindings, ignored listing per whitelist
Mar 19 10:57:04.871: INFO: namespace e2e-tests-watch-pt2qm deletion completed in 6.207616204s

• [SLOW TEST:16.405 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:57:04.871: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-bb6afb13-4a35-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume configMaps
Mar 19 10:57:04.981: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bb6c7453-4a35-11e9-989b-da33bd6188b3" in namespace "e2e-tests-projected-cj5fw" to be "success or failure"
Mar 19 10:57:04.985: INFO: Pod "pod-projected-configmaps-bb6c7453-4a35-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.704094ms
Mar 19 10:57:06.991: INFO: Pod "pod-projected-configmaps-bb6c7453-4a35-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010631471s
STEP: Saw pod success
Mar 19 10:57:06.991: INFO: Pod "pod-projected-configmaps-bb6c7453-4a35-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:57:06.996: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod pod-projected-configmaps-bb6c7453-4a35-11e9-989b-da33bd6188b3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 19 10:57:07.039: INFO: Waiting for pod pod-projected-configmaps-bb6c7453-4a35-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:57:07.043: INFO: Pod pod-projected-configmaps-bb6c7453-4a35-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:57:07.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cj5fw" for this suite.
Mar 19 10:57:13.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:57:13.256: INFO: namespace: e2e-tests-projected-cj5fw, resource: bindings, ignored listing per whitelist
Mar 19 10:57:13.263: INFO: namespace e2e-tests-projected-cj5fw deletion completed in 6.211735306s

• [SLOW TEST:8.392 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:57:13.263: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 10:57:13.380: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Mar 19 10:57:13.389: INFO: Number of nodes with available pods: 0
Mar 19 10:57:13.389: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Mar 19 10:57:13.424: INFO: Number of nodes with available pods: 0
Mar 19 10:57:13.424: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:14.430: INFO: Number of nodes with available pods: 0
Mar 19 10:57:14.430: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:15.430: INFO: Number of nodes with available pods: 1
Mar 19 10:57:15.430: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Mar 19 10:57:15.461: INFO: Number of nodes with available pods: 1
Mar 19 10:57:15.461: INFO: Number of running nodes: 0, number of available pods: 1
Mar 19 10:57:16.466: INFO: Number of nodes with available pods: 0
Mar 19 10:57:16.466: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Mar 19 10:57:16.478: INFO: Number of nodes with available pods: 0
Mar 19 10:57:16.478: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:17.483: INFO: Number of nodes with available pods: 0
Mar 19 10:57:17.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:18.485: INFO: Number of nodes with available pods: 0
Mar 19 10:57:18.485: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:19.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:19.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:20.496: INFO: Number of nodes with available pods: 0
Mar 19 10:57:20.496: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:21.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:21.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:22.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:22.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:23.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:23.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:24.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:24.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:25.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:25.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:26.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:26.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:27.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:27.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:28.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:28.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:29.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:29.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:30.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:30.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:31.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:31.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:32.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:32.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:33.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:33.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:34.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:34.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:35.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:35.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:36.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:36.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:37.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:37.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:38.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:38.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:39.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:39.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:40.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:40.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:41.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:41.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:42.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:42.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:43.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:43.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:44.485: INFO: Number of nodes with available pods: 0
Mar 19 10:57:44.485: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:45.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:45.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:46.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:46.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:47.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:47.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:48.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:48.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:49.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:49.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:50.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:50.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:51.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:51.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:52.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:52.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:53.484: INFO: Number of nodes with available pods: 0
Mar 19 10:57:53.484: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 10:57:54.484: INFO: Number of nodes with available pods: 1
Mar 19 10:57:54.484: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-6kqr6, will wait for the garbage collector to delete the pods
Mar 19 10:57:54.569: INFO: Deleting {extensions DaemonSet} daemon-set took: 22.119101ms
Mar 19 10:57:54.669: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.127712ms
Mar 19 10:58:27.374: INFO: Number of nodes with available pods: 0
Mar 19 10:58:27.374: INFO: Number of running nodes: 0, number of available pods: 0
Mar 19 10:58:27.377: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-6kqr6/daemonsets","resourceVersion":"1204072"},"items":null}

Mar 19 10:58:27.382: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-6kqr6/pods","resourceVersion":"1204072"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:58:27.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-6kqr6" for this suite.
Mar 19 10:58:33.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:58:33.549: INFO: namespace: e2e-tests-daemonsets-6kqr6, resource: bindings, ignored listing per whitelist
Mar 19 10:58:33.640: INFO: namespace e2e-tests-daemonsets-6kqr6 deletion completed in 6.202650215s

• [SLOW TEST:80.377 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:58:33.640: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 10:58:33.739: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f053c328-4a35-11e9-989b-da33bd6188b3" in namespace "e2e-tests-projected-sh9vm" to be "success or failure"
Mar 19 10:58:33.745: INFO: Pod "downwardapi-volume-f053c328-4a35-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.885833ms
Mar 19 10:58:35.751: INFO: Pod "downwardapi-volume-f053c328-4a35-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012749277s
STEP: Saw pod success
Mar 19 10:58:35.751: INFO: Pod "downwardapi-volume-f053c328-4a35-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:58:35.756: INFO: Trying to get logs from node k8s-node-vmwvcc-lkllt8nnod pod downwardapi-volume-f053c328-4a35-11e9-989b-da33bd6188b3 container client-container: <nil>
STEP: delete the pod
Mar 19 10:58:35.791: INFO: Waiting for pod downwardapi-volume-f053c328-4a35-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:58:35.796: INFO: Pod downwardapi-volume-f053c328-4a35-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:58:35.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sh9vm" for this suite.
Mar 19 10:58:41.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:58:41.914: INFO: namespace: e2e-tests-projected-sh9vm, resource: bindings, ignored listing per whitelist
Mar 19 10:58:42.008: INFO: namespace e2e-tests-projected-sh9vm deletion completed in 6.202391877s

• [SLOW TEST:8.368 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:58:42.008: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 19 10:58:42.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-97t78'
Mar 19 10:58:42.201: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar 19 10:58:42.201: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Mar 19 10:58:42.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-97t78'
Mar 19 10:58:42.299: INFO: stderr: ""
Mar 19 10:58:42.299: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:58:42.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-97t78" for this suite.
Mar 19 10:58:48.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:58:48.410: INFO: namespace: e2e-tests-kubectl-97t78, resource: bindings, ignored listing per whitelist
Mar 19 10:58:48.522: INFO: namespace e2e-tests-kubectl-97t78 deletion completed in 6.208982459s

• [SLOW TEST:6.514 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:58:48.522: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-f932f059-4a35-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume configMaps
Mar 19 10:58:48.631: INFO: Waiting up to 5m0s for pod "pod-configmaps-f9343353-4a35-11e9-989b-da33bd6188b3" in namespace "e2e-tests-configmap-sqfp6" to be "success or failure"
Mar 19 10:58:48.636: INFO: Pod "pod-configmaps-f9343353-4a35-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.450214ms
Mar 19 10:58:50.642: INFO: Pod "pod-configmaps-f9343353-4a35-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011320097s
STEP: Saw pod success
Mar 19 10:58:50.642: INFO: Pod "pod-configmaps-f9343353-4a35-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:58:50.647: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod pod-configmaps-f9343353-4a35-11e9-989b-da33bd6188b3 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 19 10:58:50.684: INFO: Waiting for pod pod-configmaps-f9343353-4a35-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:58:50.688: INFO: Pod pod-configmaps-f9343353-4a35-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:58:50.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-sqfp6" for this suite.
Mar 19 10:58:56.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:58:56.739: INFO: namespace: e2e-tests-configmap-sqfp6, resource: bindings, ignored listing per whitelist
Mar 19 10:58:56.912: INFO: namespace e2e-tests-configmap-sqfp6 deletion completed in 6.21424377s

• [SLOW TEST:8.390 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:58:56.912: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-fe32bc75-4a35-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume secrets
Mar 19 10:58:57.016: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fe33acfe-4a35-11e9-989b-da33bd6188b3" in namespace "e2e-tests-projected-ttkbs" to be "success or failure"
Mar 19 10:58:57.021: INFO: Pod "pod-projected-secrets-fe33acfe-4a35-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.786886ms
Mar 19 10:58:59.026: INFO: Pod "pod-projected-secrets-fe33acfe-4a35-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010446156s
STEP: Saw pod success
Mar 19 10:58:59.026: INFO: Pod "pod-projected-secrets-fe33acfe-4a35-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:58:59.032: INFO: Trying to get logs from node k8s-node-vmwvcc-lkllt8nnod pod pod-projected-secrets-fe33acfe-4a35-11e9-989b-da33bd6188b3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 19 10:58:59.081: INFO: Waiting for pod pod-projected-secrets-fe33acfe-4a35-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:58:59.086: INFO: Pod pod-projected-secrets-fe33acfe-4a35-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:58:59.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ttkbs" for this suite.
Mar 19 10:59:05.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:59:05.207: INFO: namespace: e2e-tests-projected-ttkbs, resource: bindings, ignored listing per whitelist
Mar 19 10:59:05.298: INFO: namespace e2e-tests-projected-ttkbs deletion completed in 6.202118565s

• [SLOW TEST:8.385 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:59:05.298: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:59:05.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-qbqwr" for this suite.
Mar 19 10:59:27.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:59:27.518: INFO: namespace: e2e-tests-pods-qbqwr, resource: bindings, ignored listing per whitelist
Mar 19 10:59:27.634: INFO: namespace e2e-tests-pods-qbqwr deletion completed in 22.219715416s

• [SLOW TEST:22.336 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:59:27.634: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar 19 10:59:27.733: INFO: Waiting up to 5m0s for pod "pod-1082b9df-4a36-11e9-989b-da33bd6188b3" in namespace "e2e-tests-emptydir-pzqrg" to be "success or failure"
Mar 19 10:59:27.738: INFO: Pod "pod-1082b9df-4a36-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.042552ms
Mar 19 10:59:29.744: INFO: Pod "pod-1082b9df-4a36-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0107255s
STEP: Saw pod success
Mar 19 10:59:29.744: INFO: Pod "pod-1082b9df-4a36-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:59:29.749: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod pod-1082b9df-4a36-11e9-989b-da33bd6188b3 container test-container: <nil>
STEP: delete the pod
Mar 19 10:59:29.783: INFO: Waiting for pod pod-1082b9df-4a36-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:59:29.788: INFO: Pod pod-1082b9df-4a36-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:59:29.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pzqrg" for this suite.
Mar 19 10:59:35.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:59:35.859: INFO: namespace: e2e-tests-emptydir-pzqrg, resource: bindings, ignored listing per whitelist
Mar 19 10:59:36.003: INFO: namespace e2e-tests-emptydir-pzqrg deletion completed in 6.205950451s

• [SLOW TEST:8.369 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:59:36.004: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-157f3eef-4a36-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume configMaps
Mar 19 10:59:36.108: INFO: Waiting up to 5m0s for pod "pod-configmaps-15808407-4a36-11e9-989b-da33bd6188b3" in namespace "e2e-tests-configmap-rdv8s" to be "success or failure"
Mar 19 10:59:36.113: INFO: Pod "pod-configmaps-15808407-4a36-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.727551ms
Mar 19 10:59:38.119: INFO: Pod "pod-configmaps-15808407-4a36-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010403232s
Mar 19 10:59:40.125: INFO: Pod "pod-configmaps-15808407-4a36-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016170963s
STEP: Saw pod success
Mar 19 10:59:40.125: INFO: Pod "pod-configmaps-15808407-4a36-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:59:40.130: INFO: Trying to get logs from node k8s-node-vmwvcc-lkllt8nnod pod pod-configmaps-15808407-4a36-11e9-989b-da33bd6188b3 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 19 10:59:40.170: INFO: Waiting for pod pod-configmaps-15808407-4a36-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:59:40.177: INFO: Pod pod-configmaps-15808407-4a36-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:59:40.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-rdv8s" for this suite.
Mar 19 10:59:46.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:59:46.303: INFO: namespace: e2e-tests-configmap-rdv8s, resource: bindings, ignored listing per whitelist
Mar 19 10:59:46.396: INFO: namespace e2e-tests-configmap-rdv8s deletion completed in 6.209030942s

• [SLOW TEST:10.392 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:59:46.396: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Mar 19 10:59:46.509: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-tzgmz,SelfLink:/api/v1/namespaces/e2e-tests-watch-tzgmz/configmaps/e2e-watch-test-watch-closed,UID:fd1c5098-4a35-11e9-b857-fa163eaabeb9,ResourceVersion:1204395,Generation:0,CreationTimestamp:2019-03-19 10:58:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 19 10:59:46.509: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-tzgmz,SelfLink:/api/v1/namespaces/e2e-tests-watch-tzgmz/configmaps/e2e-watch-test-watch-closed,UID:fd1c5098-4a35-11e9-b857-fa163eaabeb9,ResourceVersion:1204396,Generation:0,CreationTimestamp:2019-03-19 10:58:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Mar 19 10:59:46.545: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-tzgmz,SelfLink:/api/v1/namespaces/e2e-tests-watch-tzgmz/configmaps/e2e-watch-test-watch-closed,UID:fd1c5098-4a35-11e9-b857-fa163eaabeb9,ResourceVersion:1204397,Generation:0,CreationTimestamp:2019-03-19 10:58:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 19 10:59:46.546: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-tzgmz,SelfLink:/api/v1/namespaces/e2e-tests-watch-tzgmz/configmaps/e2e-watch-test-watch-closed,UID:fd1c5098-4a35-11e9-b857-fa163eaabeb9,ResourceVersion:1204398,Generation:0,CreationTimestamp:2019-03-19 10:58:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:59:46.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-tzgmz" for this suite.
Mar 19 10:59:52.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 10:59:52.742: INFO: namespace: e2e-tests-watch-tzgmz, resource: bindings, ignored listing per whitelist
Mar 19 10:59:52.764: INFO: namespace e2e-tests-watch-tzgmz deletion completed in 6.208538727s

• [SLOW TEST:6.368 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 10:59:52.764: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-1f7cad5f-4a36-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume secrets
Mar 19 10:59:52.868: INFO: Waiting up to 5m0s for pod "pod-secrets-1f7dbea5-4a36-11e9-989b-da33bd6188b3" in namespace "e2e-tests-secrets-dp8wx" to be "success or failure"
Mar 19 10:59:52.873: INFO: Pod "pod-secrets-1f7dbea5-4a36-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.839314ms
Mar 19 10:59:54.878: INFO: Pod "pod-secrets-1f7dbea5-4a36-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010399195s
Mar 19 10:59:56.884: INFO: Pod "pod-secrets-1f7dbea5-4a36-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016377045s
STEP: Saw pod success
Mar 19 10:59:56.884: INFO: Pod "pod-secrets-1f7dbea5-4a36-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 10:59:56.889: INFO: Trying to get logs from node k8s-node-vm1y1w-lkllt8nnod pod pod-secrets-1f7dbea5-4a36-11e9-989b-da33bd6188b3 container secret-volume-test: <nil>
STEP: delete the pod
Mar 19 10:59:56.924: INFO: Waiting for pod pod-secrets-1f7dbea5-4a36-11e9-989b-da33bd6188b3 to disappear
Mar 19 10:59:56.929: INFO: Pod pod-secrets-1f7dbea5-4a36-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 10:59:56.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-dp8wx" for this suite.
Mar 19 11:00:02.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:00:02.982: INFO: namespace: e2e-tests-secrets-dp8wx, resource: bindings, ignored listing per whitelist
Mar 19 11:00:03.143: INFO: namespace e2e-tests-secrets-dp8wx deletion completed in 6.206459131s

• [SLOW TEST:10.380 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:00:03.144: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Mar 19 11:00:05.268: INFO: Pod pod-hostip-25adc933-4a36-11e9-989b-da33bd6188b3 has hostIP: 172.16.128.14
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:00:05.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-6dgx4" for this suite.
Mar 19 11:00:27.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:00:27.425: INFO: namespace: e2e-tests-pods-6dgx4, resource: bindings, ignored listing per whitelist
Mar 19 11:00:27.499: INFO: namespace e2e-tests-pods-6dgx4 deletion completed in 22.221359419s

• [SLOW TEST:24.356 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:00:27.499: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 19 11:00:27.590: INFO: PodSpec: initContainers in spec.initContainers
Mar 19 11:01:12.371: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-34323d2d-4a36-11e9-989b-da33bd6188b3", GenerateName:"", Namespace:"e2e-tests-init-container-hgtld", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-hgtld/pods/pod-init-34323d2d-4a36-11e9-989b-da33bd6188b3", UID:"159d0172-4a36-11e9-b857-fa163eaabeb9", ResourceVersion:"1204663", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63688589976, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"590798710"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-xtg8q", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc421c5c540), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-xtg8q", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-xtg8q", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-xtg8q", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc42225fe68), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k8s-node-vmwvcc-lkllt8nnod", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc421e68b40), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc42123e060)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc42123e080)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590027, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590027, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590027, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688589974, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.16.128.13", PodIP:"172.16.0.4", StartTime:(*v1.Time)(0xc4206ea260), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc422c97c00)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc422c97c70)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://ad8eae5c7877f81c569db0d65a46cf2383b3add2f612692b587ac3cbb14f797b"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc4206ea8e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc4206ea7e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:01:12.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-hgtld" for this suite.
Mar 19 11:01:34.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:01:34.558: INFO: namespace: e2e-tests-init-container-hgtld, resource: bindings, ignored listing per whitelist
Mar 19 11:01:34.588: INFO: namespace e2e-tests-init-container-hgtld deletion completed in 22.206270237s

• [SLOW TEST:67.089 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:01:34.589: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-jds9h
Mar 19 11:01:36.700: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-jds9h
STEP: checking the pod's current state and verifying that restartCount is present
Mar 19 11:01:36.705: INFO: Initial restart count of pod liveness-http is 0
Mar 19 11:01:52.757: INFO: Restart count of pod e2e-tests-container-probe-jds9h/liveness-http is now 1 (16.052218594s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:01:52.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-jds9h" for this suite.
Mar 19 11:01:58.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:01:58.950: INFO: namespace: e2e-tests-container-probe-jds9h, resource: bindings, ignored listing per whitelist
Mar 19 11:01:59.007: INFO: namespace e2e-tests-container-probe-jds9h deletion completed in 6.217803768s

• [SLOW TEST:24.418 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:01:59.007: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Mar 19 11:01:59.095: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 19 11:01:59.112: INFO: Waiting for terminating namespaces to be deleted...
Mar 19 11:01:59.118: INFO: 
Logging pods the kubelet thinks is on node k8s-node-vm1y1w-lkllt8nnod before test
Mar 19 11:01:59.134: INFO: jdcloud-k8s-ipamd-9pz6x from kube-system started at 2019-03-18 06:26:18 +0000 UTC (1 container statuses recorded)
Mar 19 11:01:59.134: INFO: 	Container jdcloud-k8s-ipamd ready: true, restart count 0
Mar 19 11:01:59.134: INFO: kube-proxy-89266 from kube-system started at 2019-03-18 06:26:37 +0000 UTC (1 container statuses recorded)
Mar 19 11:01:59.134: INFO: 	Container kube-proxy ready: true, restart count 0
Mar 19 11:01:59.134: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-19 09:59:45 +0000 UTC (1 container statuses recorded)
Mar 19 11:01:59.134: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 19 11:01:59.134: INFO: sonobuoy-systemd-logs-daemon-set-421c51583ba54221-jfpn4 from heptio-sonobuoy started at 2019-03-19 09:59:46 +0000 UTC (2 container statuses recorded)
Mar 19 11:01:59.134: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Mar 19 11:01:59.134: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar 19 11:01:59.134: INFO: node-exporter-lm4pq from jke-system started at 2019-03-18 06:26:37 +0000 UTC (1 container statuses recorded)
Mar 19 11:01:59.134: INFO: 	Container node-exporter ready: true, restart count 0
Mar 19 11:01:59.134: INFO: kube-state-metrics-c866955d-j29vx from jke-system started at 2019-03-18 06:26:56 +0000 UTC (2 container statuses recorded)
Mar 19 11:01:59.134: INFO: 	Container addon-resizer ready: true, restart count 0
Mar 19 11:01:59.134: INFO: 	Container kube-state-metrics ready: true, restart count 0
Mar 19 11:01:59.134: INFO: prometheus-6f5dfd9fcd-zxm4n from jke-system started at 2019-03-18 06:46:24 +0000 UTC (1 container statuses recorded)
Mar 19 11:01:59.134: INFO: 	Container prometheus ready: true, restart count 0
Mar 19 11:01:59.134: INFO: 
Logging pods the kubelet thinks is on node k8s-node-vmepd8-lkllt8nnod before test
Mar 19 11:01:59.143: INFO: jdcloud-k8s-ipamd-9lcf8 from kube-system started at 2019-03-18 06:26:51 +0000 UTC (1 container statuses recorded)
Mar 19 11:01:59.143: INFO: 	Container jdcloud-k8s-ipamd ready: true, restart count 0
Mar 19 11:01:59.143: INFO: node-exporter-s8d56 from jke-system started at 2019-03-18 06:27:10 +0000 UTC (1 container statuses recorded)
Mar 19 11:01:59.143: INFO: 	Container node-exporter ready: true, restart count 0
Mar 19 11:01:59.143: INFO: heapster-5899f7978c-f6x7x from kube-system started at 2019-03-18 06:46:24 +0000 UTC (1 container statuses recorded)
Mar 19 11:01:59.143: INFO: 	Container heapster ready: true, restart count 0
Mar 19 11:01:59.143: INFO: sonobuoy-e2e-job-7e66631fb61c4f2f from heptio-sonobuoy started at 2019-03-19 09:59:46 +0000 UTC (2 container statuses recorded)
Mar 19 11:01:59.143: INFO: 	Container e2e ready: true, restart count 0
Mar 19 11:01:59.143: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 19 11:01:59.143: INFO: kube-proxy-h74kb from kube-system started at 2019-03-18 06:26:51 +0000 UTC (1 container statuses recorded)
Mar 19 11:01:59.143: INFO: 	Container kube-proxy ready: true, restart count 0
Mar 19 11:01:59.143: INFO: coredns-6b474698f5-6qcd7 from kube-system started at 2019-03-18 06:46:24 +0000 UTC (1 container statuses recorded)
Mar 19 11:01:59.143: INFO: 	Container coredns ready: true, restart count 0
Mar 19 11:01:59.143: INFO: sonobuoy-systemd-logs-daemon-set-421c51583ba54221-wk6bb from heptio-sonobuoy started at 2019-03-19 09:59:46 +0000 UTC (2 container statuses recorded)
Mar 19 11:01:59.143: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Mar 19 11:01:59.143: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar 19 11:01:59.143: INFO: 
Logging pods the kubelet thinks is on node k8s-node-vmwvcc-lkllt8nnod before test
Mar 19 11:01:59.155: INFO: node-exporter-nx6zb from jke-system started at 2019-03-18 06:25:45 +0000 UTC (1 container statuses recorded)
Mar 19 11:01:59.155: INFO: 	Container node-exporter ready: true, restart count 0
Mar 19 11:01:59.155: INFO: sonobuoy-systemd-logs-daemon-set-421c51583ba54221-86srx from heptio-sonobuoy started at 2019-03-19 09:59:46 +0000 UTC (2 container statuses recorded)
Mar 19 11:01:59.155: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Mar 19 11:01:59.155: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar 19 11:01:59.155: INFO: coredns-6b474698f5-hgplj from kube-system started at 2019-03-18 06:46:24 +0000 UTC (1 container statuses recorded)
Mar 19 11:01:59.155: INFO: 	Container coredns ready: true, restart count 0
Mar 19 11:01:59.155: INFO: kube-proxy-n5vt5 from kube-system started at 2019-03-18 06:25:45 +0000 UTC (1 container statuses recorded)
Mar 19 11:01:59.155: INFO: 	Container kube-proxy ready: true, restart count 0
Mar 19 11:01:59.155: INFO: prometheus-jdmon-69d8fd6b87-sf5hc from jke-system started at 2019-03-18 06:46:24 +0000 UTC (2 container statuses recorded)
Mar 19 11:01:59.155: INFO: 	Container k8s-metrics-to-jdmon ready: true, restart count 0
Mar 19 11:01:59.155: INFO: 	Container refresher ready: true, restart count 0
Mar 19 11:01:59.155: INFO: jdcloud-k8s-ipamd-tfr8l from kube-system started at 2019-03-18 06:25:27 +0000 UTC (1 container statuses recorded)
Mar 19 11:01:59.155: INFO: 	Container jdcloud-k8s-ipamd ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node k8s-node-vm1y1w-lkllt8nnod
STEP: verifying the node has the label node k8s-node-vmepd8-lkllt8nnod
STEP: verifying the node has the label node k8s-node-vmwvcc-lkllt8nnod
Mar 19 11:01:59.249: INFO: Pod sonobuoy requesting resource cpu=0m on Node k8s-node-vm1y1w-lkllt8nnod
Mar 19 11:01:59.249: INFO: Pod sonobuoy-e2e-job-7e66631fb61c4f2f requesting resource cpu=0m on Node k8s-node-vmepd8-lkllt8nnod
Mar 19 11:01:59.249: INFO: Pod sonobuoy-systemd-logs-daemon-set-421c51583ba54221-86srx requesting resource cpu=0m on Node k8s-node-vmwvcc-lkllt8nnod
Mar 19 11:01:59.249: INFO: Pod sonobuoy-systemd-logs-daemon-set-421c51583ba54221-jfpn4 requesting resource cpu=0m on Node k8s-node-vm1y1w-lkllt8nnod
Mar 19 11:01:59.249: INFO: Pod sonobuoy-systemd-logs-daemon-set-421c51583ba54221-wk6bb requesting resource cpu=0m on Node k8s-node-vmepd8-lkllt8nnod
Mar 19 11:01:59.249: INFO: Pod kube-state-metrics-c866955d-j29vx requesting resource cpu=204m on Node k8s-node-vm1y1w-lkllt8nnod
Mar 19 11:01:59.249: INFO: Pod node-exporter-lm4pq requesting resource cpu=0m on Node k8s-node-vm1y1w-lkllt8nnod
Mar 19 11:01:59.249: INFO: Pod node-exporter-nx6zb requesting resource cpu=0m on Node k8s-node-vmwvcc-lkllt8nnod
Mar 19 11:01:59.249: INFO: Pod node-exporter-s8d56 requesting resource cpu=0m on Node k8s-node-vmepd8-lkllt8nnod
Mar 19 11:01:59.249: INFO: Pod prometheus-6f5dfd9fcd-zxm4n requesting resource cpu=0m on Node k8s-node-vm1y1w-lkllt8nnod
Mar 19 11:01:59.249: INFO: Pod prometheus-jdmon-69d8fd6b87-sf5hc requesting resource cpu=0m on Node k8s-node-vmwvcc-lkllt8nnod
Mar 19 11:01:59.249: INFO: Pod coredns-6b474698f5-6qcd7 requesting resource cpu=100m on Node k8s-node-vmepd8-lkllt8nnod
Mar 19 11:01:59.249: INFO: Pod coredns-6b474698f5-hgplj requesting resource cpu=100m on Node k8s-node-vmwvcc-lkllt8nnod
Mar 19 11:01:59.249: INFO: Pod heapster-5899f7978c-f6x7x requesting resource cpu=0m on Node k8s-node-vmepd8-lkllt8nnod
Mar 19 11:01:59.249: INFO: Pod jdcloud-k8s-ipamd-9lcf8 requesting resource cpu=0m on Node k8s-node-vmepd8-lkllt8nnod
Mar 19 11:01:59.249: INFO: Pod jdcloud-k8s-ipamd-9pz6x requesting resource cpu=0m on Node k8s-node-vm1y1w-lkllt8nnod
Mar 19 11:01:59.249: INFO: Pod jdcloud-k8s-ipamd-tfr8l requesting resource cpu=0m on Node k8s-node-vmwvcc-lkllt8nnod
Mar 19 11:01:59.249: INFO: Pod kube-proxy-89266 requesting resource cpu=0m on Node k8s-node-vm1y1w-lkllt8nnod
Mar 19 11:01:59.249: INFO: Pod kube-proxy-h74kb requesting resource cpu=0m on Node k8s-node-vmepd8-lkllt8nnod
Mar 19 11:01:59.249: INFO: Pod kube-proxy-n5vt5 requesting resource cpu=0m on Node k8s-node-vmwvcc-lkllt8nnod
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6ad451d7-4a36-11e9-989b-da33bd6188b3.158d572794926917], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-phqvs/filler-pod-6ad451d7-4a36-11e9-989b-da33bd6188b3 to k8s-node-vm1y1w-lkllt8nnod]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6ad451d7-4a36-11e9-989b-da33bd6188b3.158d57323c17199e], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6ad451d7-4a36-11e9-989b-da33bd6188b3.158d57323e976dc2], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6ad451d7-4a36-11e9-989b-da33bd6188b3.158d573242515ecc], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6ad6746f-4a36-11e9-989b-da33bd6188b3.158d57279540472e], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-phqvs/filler-pod-6ad6746f-4a36-11e9-989b-da33bd6188b3 to k8s-node-vmepd8-lkllt8nnod]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6ad6746f-4a36-11e9-989b-da33bd6188b3.158d57323a1f9540], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6ad6746f-4a36-11e9-989b-da33bd6188b3.158d57323c0b08be], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6ad6746f-4a36-11e9-989b-da33bd6188b3.158d573240011183], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6ad7e139-4a36-11e9-989b-da33bd6188b3.158d5727956b6a48], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-phqvs/filler-pod-6ad7e139-4a36-11e9-989b-da33bd6188b3 to k8s-node-vmwvcc-lkllt8nnod]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6ad7e139-4a36-11e9-989b-da33bd6188b3.158d57323ae660c9], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6ad7e139-4a36-11e9-989b-da33bd6188b3.158d57323d116c11], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6ad7e139-4a36-11e9-989b-da33bd6188b3.158d5732410c680f], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.158d57280e7d328a], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node k8s-node-vm1y1w-lkllt8nnod
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node k8s-node-vmepd8-lkllt8nnod
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node k8s-node-vmwvcc-lkllt8nnod
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:02:02.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-phqvs" for this suite.
Mar 19 11:02:08.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:02:08.622: INFO: namespace: e2e-tests-sched-pred-phqvs, resource: bindings, ignored listing per whitelist
Mar 19 11:02:08.670: INFO: namespace e2e-tests-sched-pred-phqvs deletion completed in 6.226239453s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:9.663 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:02:08.670: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar 19 11:02:12.817: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 19 11:02:12.823: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 19 11:02:14.823: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 19 11:02:14.829: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 19 11:02:16.823: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 19 11:02:16.829: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 19 11:02:18.823: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 19 11:02:18.831: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 19 11:02:20.823: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 19 11:02:20.828: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 19 11:02:22.823: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 19 11:02:22.828: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 19 11:02:24.823: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 19 11:02:24.829: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 19 11:02:26.823: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 19 11:02:26.828: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 19 11:02:28.823: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 19 11:02:28.829: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 19 11:02:30.823: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 19 11:02:30.829: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 19 11:02:32.823: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 19 11:02:32.828: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 19 11:02:34.823: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 19 11:02:34.829: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 19 11:02:36.823: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 19 11:02:36.829: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 19 11:02:38.823: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 19 11:02:38.829: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 19 11:02:40.823: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 19 11:02:40.829: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 19 11:02:42.823: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 19 11:02:42.829: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:02:42.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-dkvnr" for this suite.
Mar 19 11:03:04.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:03:04.955: INFO: namespace: e2e-tests-container-lifecycle-hook-dkvnr, resource: bindings, ignored listing per whitelist
Mar 19 11:03:05.059: INFO: namespace e2e-tests-container-lifecycle-hook-dkvnr deletion completed in 22.205241971s

• [SLOW TEST:56.389 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:03:05.059: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-bnzl
STEP: Creating a pod to test atomic-volume-subpath
Mar 19 11:03:05.176: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-bnzl" in namespace "e2e-tests-subpath-4hkbq" to be "success or failure"
Mar 19 11:03:05.184: INFO: Pod "pod-subpath-test-secret-bnzl": Phase="Pending", Reason="", readiness=false. Elapsed: 7.761006ms
Mar 19 11:03:07.194: INFO: Pod "pod-subpath-test-secret-bnzl": Phase="Running", Reason="", readiness=false. Elapsed: 2.017063398s
Mar 19 11:03:09.199: INFO: Pod "pod-subpath-test-secret-bnzl": Phase="Running", Reason="", readiness=false. Elapsed: 4.02281761s
Mar 19 11:03:11.205: INFO: Pod "pod-subpath-test-secret-bnzl": Phase="Running", Reason="", readiness=false. Elapsed: 6.028914076s
Mar 19 11:03:13.211: INFO: Pod "pod-subpath-test-secret-bnzl": Phase="Running", Reason="", readiness=false. Elapsed: 8.034579004s
Mar 19 11:03:15.217: INFO: Pod "pod-subpath-test-secret-bnzl": Phase="Running", Reason="", readiness=false. Elapsed: 10.040735469s
Mar 19 11:03:17.223: INFO: Pod "pod-subpath-test-secret-bnzl": Phase="Running", Reason="", readiness=false. Elapsed: 12.046662959s
Mar 19 11:03:19.229: INFO: Pod "pod-subpath-test-secret-bnzl": Phase="Running", Reason="", readiness=false. Elapsed: 14.052545868s
Mar 19 11:03:21.235: INFO: Pod "pod-subpath-test-secret-bnzl": Phase="Running", Reason="", readiness=false. Elapsed: 16.058544056s
Mar 19 11:03:23.240: INFO: Pod "pod-subpath-test-secret-bnzl": Phase="Running", Reason="", readiness=false. Elapsed: 18.063869278s
Mar 19 11:03:25.246: INFO: Pod "pod-subpath-test-secret-bnzl": Phase="Running", Reason="", readiness=false. Elapsed: 20.0699462s
Mar 19 11:03:27.252: INFO: Pod "pod-subpath-test-secret-bnzl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.075812824s
STEP: Saw pod success
Mar 19 11:03:27.252: INFO: Pod "pod-subpath-test-secret-bnzl" satisfied condition "success or failure"
Mar 19 11:03:27.257: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod pod-subpath-test-secret-bnzl container test-container-subpath-secret-bnzl: <nil>
STEP: delete the pod
Mar 19 11:03:27.293: INFO: Waiting for pod pod-subpath-test-secret-bnzl to disappear
Mar 19 11:03:27.299: INFO: Pod pod-subpath-test-secret-bnzl no longer exists
STEP: Deleting pod pod-subpath-test-secret-bnzl
Mar 19 11:03:27.299: INFO: Deleting pod "pod-subpath-test-secret-bnzl" in namespace "e2e-tests-subpath-4hkbq"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:03:27.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-4hkbq" for this suite.
Mar 19 11:03:33.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:03:33.360: INFO: namespace: e2e-tests-subpath-4hkbq, resource: bindings, ignored listing per whitelist
Mar 19 11:03:33.522: INFO: namespace e2e-tests-subpath-4hkbq deletion completed in 6.207606923s

• [SLOW TEST:28.462 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:03:33.522: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-ffp6
STEP: Creating a pod to test atomic-volume-subpath
Mar 19 11:03:33.638: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-ffp6" in namespace "e2e-tests-subpath-wqcpx" to be "success or failure"
Mar 19 11:03:33.643: INFO: Pod "pod-subpath-test-downwardapi-ffp6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.641552ms
Mar 19 11:03:35.648: INFO: Pod "pod-subpath-test-downwardapi-ffp6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010324971s
Mar 19 11:03:37.654: INFO: Pod "pod-subpath-test-downwardapi-ffp6": Phase="Running", Reason="", readiness=false. Elapsed: 4.016417631s
Mar 19 11:03:39.661: INFO: Pod "pod-subpath-test-downwardapi-ffp6": Phase="Running", Reason="", readiness=false. Elapsed: 6.022494839s
Mar 19 11:03:41.666: INFO: Pod "pod-subpath-test-downwardapi-ffp6": Phase="Running", Reason="", readiness=false. Elapsed: 8.028434684s
Mar 19 11:03:43.672: INFO: Pod "pod-subpath-test-downwardapi-ffp6": Phase="Running", Reason="", readiness=false. Elapsed: 10.034384487s
Mar 19 11:03:45.679: INFO: Pod "pod-subpath-test-downwardapi-ffp6": Phase="Running", Reason="", readiness=false. Elapsed: 12.040685543s
Mar 19 11:03:47.685: INFO: Pod "pod-subpath-test-downwardapi-ffp6": Phase="Running", Reason="", readiness=false. Elapsed: 14.046684165s
Mar 19 11:03:49.691: INFO: Pod "pod-subpath-test-downwardapi-ffp6": Phase="Running", Reason="", readiness=false. Elapsed: 16.052760414s
Mar 19 11:03:51.697: INFO: Pod "pod-subpath-test-downwardapi-ffp6": Phase="Running", Reason="", readiness=false. Elapsed: 18.058618876s
Mar 19 11:03:53.703: INFO: Pod "pod-subpath-test-downwardapi-ffp6": Phase="Running", Reason="", readiness=false. Elapsed: 20.06446721s
Mar 19 11:03:55.708: INFO: Pod "pod-subpath-test-downwardapi-ffp6": Phase="Running", Reason="", readiness=false. Elapsed: 22.070005481s
Mar 19 11:03:57.716: INFO: Pod "pod-subpath-test-downwardapi-ffp6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.077806962s
STEP: Saw pod success
Mar 19 11:03:57.716: INFO: Pod "pod-subpath-test-downwardapi-ffp6" satisfied condition "success or failure"
Mar 19 11:03:57.721: INFO: Trying to get logs from node k8s-node-vmwvcc-lkllt8nnod pod pod-subpath-test-downwardapi-ffp6 container test-container-subpath-downwardapi-ffp6: <nil>
STEP: delete the pod
Mar 19 11:03:57.765: INFO: Waiting for pod pod-subpath-test-downwardapi-ffp6 to disappear
Mar 19 11:03:57.783: INFO: Pod pod-subpath-test-downwardapi-ffp6 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-ffp6
Mar 19 11:03:57.783: INFO: Deleting pod "pod-subpath-test-downwardapi-ffp6" in namespace "e2e-tests-subpath-wqcpx"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:03:57.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-wqcpx" for this suite.
Mar 19 11:04:03.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:04:03.928: INFO: namespace: e2e-tests-subpath-wqcpx, resource: bindings, ignored listing per whitelist
Mar 19 11:04:04.003: INFO: namespace e2e-tests-subpath-wqcpx deletion completed in 6.204953603s

• [SLOW TEST:30.481 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:04:04.003: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 11:04:04.089: INFO: Creating deployment "nginx-deployment"
Mar 19 11:04:04.094: INFO: Waiting for observed generation 1
Mar 19 11:04:06.100: INFO: Waiting for all required pods to come up
Mar 19 11:04:06.107: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Mar 19 11:04:08.120: INFO: Waiting for deployment "nginx-deployment" to complete
Mar 19 11:04:08.125: INFO: Updating deployment "nginx-deployment" with a non-existent image
Mar 19 11:04:08.133: INFO: Updating deployment nginx-deployment
Mar 19 11:04:08.133: INFO: Waiting for observed generation 2
Mar 19 11:04:10.139: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Mar 19 11:04:10.142: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Mar 19 11:04:10.144: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar 19 11:04:10.153: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Mar 19 11:04:10.153: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Mar 19 11:04:10.155: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar 19 11:04:10.160: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Mar 19 11:04:10.160: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Mar 19 11:04:10.167: INFO: Updating deployment nginx-deployment
Mar 19 11:04:10.167: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Mar 19 11:04:10.180: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Mar 19 11:04:10.184: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 19 11:04:10.194: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-ft29z,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ft29z/deployments/nginx-deployment,UID:96a43d27-4a36-11e9-b857-fa163eaabeb9,ResourceVersion:1205381,Generation:3,CreationTimestamp:2019-03-19 11:03:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Available True 2019-03-19 11:03:21 +0000 UTC 2019-03-19 11:03:21 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-19 11:03:22 +0000 UTC 2019-03-19 11:03:18 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Mar 19 11:04:10.198: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-ft29z,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ft29z/replicasets/nginx-deployment-7dc8f79789,UID:9cab8544-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205383,Generation:3,CreationTimestamp:2019-03-19 11:03:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 96a43d27-4a36-11e9-b857-fa163eaabeb9 0xc4228219b7 0xc4228219b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 19 11:04:10.198: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Mar 19 11:04:10.199: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-ft29z,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ft29z/replicasets/nginx-deployment-7f9675fb8b,UID:9a4469b2-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205382,Generation:3,CreationTimestamp:2019-03-19 11:03:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 96a43d27-4a36-11e9-b857-fa163eaabeb9 0xc422821a77 0xc422821a78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Mar 19 11:04:10.233: INFO: Pod "nginx-deployment-7dc8f79789-7rxj7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-7rxj7,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7dc8f79789-7rxj7,UID:9cb5392e-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205372,Generation:0,CreationTimestamp:2019-03-19 11:03:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9cab8544-4a36-11e9-8b0a-fa163ecd2a50 0xc421f38377 0xc421f38378}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm1y1w-lkllt8nnod,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f383e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f38400}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:03:14 +0000 UTC  }],Message:,Reason:,HostIP:172.16.128.12,PodIP:,StartTime:2019-03-19 11:04:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.233: INFO: Pod "nginx-deployment-7dc8f79789-8h79r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-8h79r,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7dc8f79789-8h79r,UID:9de824c0-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205401,Generation:0,CreationTimestamp:2019-03-19 11:03:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9cab8544-4a36-11e9-8b0a-fa163ecd2a50 0xc421f384b7 0xc421f384b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f38520} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f38540}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.234: INFO: Pod "nginx-deployment-7dc8f79789-crwnf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-crwnf,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7dc8f79789-crwnf,UID:9de9a2ba-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205408,Generation:0,CreationTimestamp:2019-03-19 11:03:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9cab8544-4a36-11e9-8b0a-fa163ecd2a50 0xc421f385a7 0xc421f385a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f38610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f38630}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.234: INFO: Pod "nginx-deployment-7dc8f79789-dttdk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-dttdk,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7dc8f79789-dttdk,UID:9cad9db9-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205362,Generation:0,CreationTimestamp:2019-03-19 11:03:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9cab8544-4a36-11e9-8b0a-fa163ecd2a50 0xc421f38697 0xc421f38698}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vmwvcc-lkllt8nnod,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f38ee0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f38f00}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:03:14 +0000 UTC  }],Message:,Reason:,HostIP:172.16.128.13,PodIP:,StartTime:2019-03-19 11:04:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.234: INFO: Pod "nginx-deployment-7dc8f79789-fwnp7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-fwnp7,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7dc8f79789-fwnp7,UID:9de63954-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205392,Generation:0,CreationTimestamp:2019-03-19 11:03:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9cab8544-4a36-11e9-8b0a-fa163ecd2a50 0xc421f38fb7 0xc421f38fb8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f39340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f39360}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.234: INFO: Pod "nginx-deployment-7dc8f79789-hmw6j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-hmw6j,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7dc8f79789-hmw6j,UID:9de7ed58-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205398,Generation:0,CreationTimestamp:2019-03-19 11:03:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9cab8544-4a36-11e9-8b0a-fa163ecd2a50 0xc421f393b7 0xc421f393b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f39430} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f39450}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.234: INFO: Pod "nginx-deployment-7dc8f79789-lz4bp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-lz4bp,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7dc8f79789-lz4bp,UID:9cadc4b7-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205365,Generation:0,CreationTimestamp:2019-03-19 11:03:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9cab8544-4a36-11e9-8b0a-fa163ecd2a50 0xc421f394c7 0xc421f394c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm1y1w-lkllt8nnod,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f396f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f39710}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:03:14 +0000 UTC  }],Message:,Reason:,HostIP:172.16.128.12,PodIP:,StartTime:2019-03-19 11:04:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.234: INFO: Pod "nginx-deployment-7dc8f79789-m7dg5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-m7dg5,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7dc8f79789-m7dg5,UID:9de80be5-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205399,Generation:0,CreationTimestamp:2019-03-19 11:03:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9cab8544-4a36-11e9-8b0a-fa163ecd2a50 0xc421f39817 0xc421f39818}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f39880} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f398b0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.234: INFO: Pod "nginx-deployment-7dc8f79789-qj2q9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-qj2q9,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7dc8f79789-qj2q9,UID:9de81924-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205400,Generation:0,CreationTimestamp:2019-03-19 11:03:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9cab8544-4a36-11e9-8b0a-fa163ecd2a50 0xc421f39907 0xc421f39908}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f399c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f399f0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.234: INFO: Pod "nginx-deployment-7dc8f79789-qtjxs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-qtjxs,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7dc8f79789-qtjxs,UID:9de6539e-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205391,Generation:0,CreationTimestamp:2019-03-19 11:03:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9cab8544-4a36-11e9-8b0a-fa163ecd2a50 0xc421f39b07 0xc421f39b08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f39bb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f39bd0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.234: INFO: Pod "nginx-deployment-7dc8f79789-sd98z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-sd98z,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7dc8f79789-sd98z,UID:9de4bd94-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205386,Generation:0,CreationTimestamp:2019-03-19 11:03:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9cab8544-4a36-11e9-8b0a-fa163ecd2a50 0xc421f39c37 0xc421f39c38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f39f60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f39f90}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.234: INFO: Pod "nginx-deployment-7dc8f79789-v6j5q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-v6j5q,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7dc8f79789-v6j5q,UID:9cac9dd3-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205350,Generation:0,CreationTimestamp:2019-03-19 11:03:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9cab8544-4a36-11e9-8b0a-fa163ecd2a50 0xc421bfc047 0xc421bfc048}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vmepd8-lkllt8nnod,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421bfc0b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421bfc0d0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:03:14 +0000 UTC  }],Message:,Reason:,HostIP:172.16.128.14,PodIP:,StartTime:2019-03-19 11:04:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.235: INFO: Pod "nginx-deployment-7dc8f79789-zvtqm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-zvtqm,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7dc8f79789-zvtqm,UID:9cb6ef9b-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205371,Generation:0,CreationTimestamp:2019-03-19 11:03:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 9cab8544-4a36-11e9-8b0a-fa163ecd2a50 0xc421bfc187 0xc421bfc188}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vmwvcc-lkllt8nnod,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421bfc1f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421bfc210}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:03:14 +0000 UTC  }],Message:,Reason:,HostIP:172.16.128.13,PodIP:,StartTime:2019-03-19 11:04:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.235: INFO: Pod "nginx-deployment-7f9675fb8b-47ck2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-47ck2,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7f9675fb8b-47ck2,UID:9a48afa8-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205281,Generation:0,CreationTimestamp:2019-03-19 11:03:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 9a4469b2-4a36-11e9-8b0a-fa163ecd2a50 0xc421bfc2c7 0xc421bfc2c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vmwvcc-lkllt8nnod,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421bfc330} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421bfc350}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:03:10 +0000 UTC  }],Message:,Reason:,HostIP:172.16.128.13,PodIP:172.16.0.7,StartTime:2019-03-19 11:04:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-19 11:04:04 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://0890dc8033be332986f44b729e47242a142cec17b613c1352aa43a010cd0af23}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.235: INFO: Pod "nginx-deployment-7f9675fb8b-48x4r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-48x4r,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7f9675fb8b-48x4r,UID:9de3ef73-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205384,Generation:0,CreationTimestamp:2019-03-19 11:03:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 9a4469b2-4a36-11e9-8b0a-fa163ecd2a50 0xc421bfc407 0xc421bfc408}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421bfc470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421bfc500}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.235: INFO: Pod "nginx-deployment-7f9675fb8b-752lv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-752lv,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7f9675fb8b-752lv,UID:9de6fa97-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205396,Generation:0,CreationTimestamp:2019-03-19 11:03:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 9a4469b2-4a36-11e9-8b0a-fa163ecd2a50 0xc421bfc557 0xc421bfc558}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421bfc5c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421bfc5e0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.235: INFO: Pod "nginx-deployment-7f9675fb8b-7cbbc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-7cbbc,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7f9675fb8b-7cbbc,UID:9a4a3e91-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205278,Generation:0,CreationTimestamp:2019-03-19 11:03:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 9a4469b2-4a36-11e9-8b0a-fa163ecd2a50 0xc421bfc6d7 0xc421bfc6d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vmepd8-lkllt8nnod,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421bfc750} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421bfc770}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:03:10 +0000 UTC  }],Message:,Reason:,HostIP:172.16.128.14,PodIP:172.16.0.41,StartTime:2019-03-19 11:04:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-19 11:04:04 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://5b70c2b148555d30b55e79673b84a713e28ad5a8fc2ffd7cf10c1819cce2d43a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.235: INFO: Pod "nginx-deployment-7f9675fb8b-7lkpm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-7lkpm,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7f9675fb8b-7lkpm,UID:9de8e809-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205406,Generation:0,CreationTimestamp:2019-03-19 11:03:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 9a4469b2-4a36-11e9-8b0a-fa163ecd2a50 0xc421bfc827 0xc421bfc828}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421bfc890} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421bfc920}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.235: INFO: Pod "nginx-deployment-7f9675fb8b-89sfs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-89sfs,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7f9675fb8b-89sfs,UID:9de8b6e6-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205404,Generation:0,CreationTimestamp:2019-03-19 11:03:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 9a4469b2-4a36-11e9-8b0a-fa163ecd2a50 0xc421bfc977 0xc421bfc978}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421bfc9e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421bfca10}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.235: INFO: Pod "nginx-deployment-7f9675fb8b-bhpdc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-bhpdc,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7f9675fb8b-bhpdc,UID:9de53d1b-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205388,Generation:0,CreationTimestamp:2019-03-19 11:03:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 9a4469b2-4a36-11e9-8b0a-fa163ecd2a50 0xc421bfca67 0xc421bfca68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421bfcad0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421bfcaf0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.235: INFO: Pod "nginx-deployment-7f9675fb8b-cb2m9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-cb2m9,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7f9675fb8b-cb2m9,UID:9a4bc5ef-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205276,Generation:0,CreationTimestamp:2019-03-19 11:03:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 9a4469b2-4a36-11e9-8b0a-fa163ecd2a50 0xc421bfcb47 0xc421bfcb48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vmwvcc-lkllt8nnod,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421bfcbb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421bfcbd0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:03:10 +0000 UTC  }],Message:,Reason:,HostIP:172.16.128.13,PodIP:172.16.0.9,StartTime:2019-03-19 11:04:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-19 11:04:05 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://f11de50d041854096f46e35faccba27538f0e6018c1dad7fc3c2a66ba5e21a5b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.236: INFO: Pod "nginx-deployment-7f9675fb8b-czzjw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-czzjw,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7f9675fb8b-czzjw,UID:9a4a2d8f-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205293,Generation:0,CreationTimestamp:2019-03-19 11:03:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 9a4469b2-4a36-11e9-8b0a-fa163ecd2a50 0xc421bfcc87 0xc421bfcc88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm1y1w-lkllt8nnod,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421bfccf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421bfcd10}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:03:11 +0000 UTC  }],Message:,Reason:,HostIP:172.16.128.12,PodIP:172.16.0.56,StartTime:2019-03-19 11:04:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-19 11:04:05 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://6d09ecc6465e5d5f02c5cc50ea2fac220bf198254308750e308083c954ec6b0d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.236: INFO: Pod "nginx-deployment-7f9675fb8b-hnrzn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-hnrzn,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7f9675fb8b-hnrzn,UID:9a49ff6f-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205303,Generation:0,CreationTimestamp:2019-03-19 11:03:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 9a4469b2-4a36-11e9-8b0a-fa163ecd2a50 0xc421bfcdc7 0xc421bfcdc8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vmepd8-lkllt8nnod,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421bfce30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421bfce50}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:03:12 +0000 UTC  }],Message:,Reason:,HostIP:172.16.128.14,PodIP:172.16.0.40,StartTime:2019-03-19 11:04:05 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-19 11:04:06 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://7842e87344e3c12c76621c83029c927f33ed582775d6f123f111057a48444f0f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.236: INFO: Pod "nginx-deployment-7f9675fb8b-kxtq6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-kxtq6,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7f9675fb8b-kxtq6,UID:9de8c528-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205405,Generation:0,CreationTimestamp:2019-03-19 11:03:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 9a4469b2-4a36-11e9-8b0a-fa163ecd2a50 0xc421bfcf17 0xc421bfcf18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421bfcf80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421bfcfa0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.236: INFO: Pod "nginx-deployment-7f9675fb8b-lld9t" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-lld9t,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7f9675fb8b-lld9t,UID:9a4bd188-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205265,Generation:0,CreationTimestamp:2019-03-19 11:03:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 9a4469b2-4a36-11e9-8b0a-fa163ecd2a50 0xc421bfcff7 0xc421bfcff8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm1y1w-lkllt8nnod,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421bfd060} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421bfd080}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:03:10 +0000 UTC  }],Message:,Reason:,HostIP:172.16.128.12,PodIP:172.16.0.61,StartTime:2019-03-19 11:04:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-19 11:04:04 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://277f7970fa677c30883f9e6ce6410f3f6350d4d0bd96075ba98994e980d10d68}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.236: INFO: Pod "nginx-deployment-7f9675fb8b-mgp5d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-mgp5d,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7f9675fb8b-mgp5d,UID:9de6c298-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205394,Generation:0,CreationTimestamp:2019-03-19 11:03:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 9a4469b2-4a36-11e9-8b0a-fa163ecd2a50 0xc421bfd137 0xc421bfd138}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421bfd1a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421bfd1c0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.236: INFO: Pod "nginx-deployment-7f9675fb8b-nh8kx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-nh8kx,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7f9675fb8b-nh8kx,UID:9de6dc22-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205397,Generation:0,CreationTimestamp:2019-03-19 11:03:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 9a4469b2-4a36-11e9-8b0a-fa163ecd2a50 0xc421bfd217 0xc421bfd218}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421bfd280} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421bfd2a0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.236: INFO: Pod "nginx-deployment-7f9675fb8b-rkrn7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-rkrn7,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7f9675fb8b-rkrn7,UID:9a4bccbd-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205275,Generation:0,CreationTimestamp:2019-03-19 11:03:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 9a4469b2-4a36-11e9-8b0a-fa163ecd2a50 0xc421bfd2f7 0xc421bfd2f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vmepd8-lkllt8nnod,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421bfd360} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421bfd380}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:03:10 +0000 UTC  }],Message:,Reason:,HostIP:172.16.128.14,PodIP:172.16.0.30,StartTime:2019-03-19 11:04:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-19 11:04:04 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://79cce89e5244734ae6d9b6f0d1ef5a63a05d2ececa618a48eb45799865eb1d7a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.236: INFO: Pod "nginx-deployment-7f9675fb8b-rqrmc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-rqrmc,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7f9675fb8b-rqrmc,UID:9de87b1e-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205402,Generation:0,CreationTimestamp:2019-03-19 11:03:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 9a4469b2-4a36-11e9-8b0a-fa163ecd2a50 0xc421bfd437 0xc421bfd438}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421bfd4a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421bfd4c0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.236: INFO: Pod "nginx-deployment-7f9675fb8b-t7pns" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-t7pns,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7f9675fb8b-t7pns,UID:9a476012-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205262,Generation:0,CreationTimestamp:2019-03-19 11:03:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 9a4469b2-4a36-11e9-8b0a-fa163ecd2a50 0xc421bfd517 0xc421bfd518}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm1y1w-lkllt8nnod,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421bfd580} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421bfd5a0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:04:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:03:10 +0000 UTC  }],Message:,Reason:,HostIP:172.16.128.12,PodIP:172.16.0.12,StartTime:2019-03-19 11:04:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-19 11:04:04 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://a2908318ef18ff2f386a2bb1c059e43a328e30ff73716070c269f5338c08f84e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.237: INFO: Pod "nginx-deployment-7f9675fb8b-v728p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-v728p,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7f9675fb8b-v728p,UID:9de69711-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205393,Generation:0,CreationTimestamp:2019-03-19 11:03:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 9a4469b2-4a36-11e9-8b0a-fa163ecd2a50 0xc421bfd657 0xc421bfd658}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421bfd6c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421bfd6e0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.237: INFO: Pod "nginx-deployment-7f9675fb8b-xpc7f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-xpc7f,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7f9675fb8b-xpc7f,UID:9de89ea9-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205403,Generation:0,CreationTimestamp:2019-03-19 11:03:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 9a4469b2-4a36-11e9-8b0a-fa163ecd2a50 0xc421bfd737 0xc421bfd738}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421bfd7a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421bfd7c0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 11:04:10.237: INFO: Pod "nginx-deployment-7f9675fb8b-z6qdv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-z6qdv,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ft29z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ft29z/pods/nginx-deployment-7f9675fb8b-z6qdv,UID:9de53214-4a36-11e9-8b0a-fa163ecd2a50,ResourceVersion:1205387,Generation:0,CreationTimestamp:2019-03-19 11:03:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 9a4469b2-4a36-11e9-8b0a-fa163ecd2a50 0xc421bfd817 0xc421bfd818}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-547vg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-547vg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-547vg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421bfd880} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421bfd8a0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:04:10.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-ft29z" for this suite.
Mar 19 11:04:18.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:04:18.349: INFO: namespace: e2e-tests-deployment-ft29z, resource: bindings, ignored listing per whitelist
Mar 19 11:04:18.461: INFO: namespace e2e-tests-deployment-ft29z deletion completed in 8.211612103s

• [SLOW TEST:14.458 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:04:18.461: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 11:04:18.564: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bddbbf07-4a36-11e9-989b-da33bd6188b3" in namespace "e2e-tests-projected-b6485" to be "success or failure"
Mar 19 11:04:18.569: INFO: Pod "downwardapi-volume-bddbbf07-4a36-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.909554ms
Mar 19 11:04:20.575: INFO: Pod "downwardapi-volume-bddbbf07-4a36-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010904539s
STEP: Saw pod success
Mar 19 11:04:20.575: INFO: Pod "downwardapi-volume-bddbbf07-4a36-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 11:04:20.580: INFO: Trying to get logs from node k8s-node-vmwvcc-lkllt8nnod pod downwardapi-volume-bddbbf07-4a36-11e9-989b-da33bd6188b3 container client-container: <nil>
STEP: delete the pod
Mar 19 11:04:20.617: INFO: Waiting for pod downwardapi-volume-bddbbf07-4a36-11e9-989b-da33bd6188b3 to disappear
Mar 19 11:04:20.622: INFO: Pod downwardapi-volume-bddbbf07-4a36-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:04:20.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-b6485" for this suite.
Mar 19 11:04:26.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:04:26.754: INFO: namespace: e2e-tests-projected-b6485, resource: bindings, ignored listing per whitelist
Mar 19 11:04:26.835: INFO: namespace e2e-tests-projected-b6485 deletion completed in 6.203076235s

• [SLOW TEST:8.374 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:04:26.835: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-c2d80811-4a36-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume secrets
Mar 19 11:04:26.935: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c2d8ff87-4a36-11e9-989b-da33bd6188b3" in namespace "e2e-tests-projected-lggpt" to be "success or failure"
Mar 19 11:04:26.940: INFO: Pod "pod-projected-secrets-c2d8ff87-4a36-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.678425ms
Mar 19 11:04:28.946: INFO: Pod "pod-projected-secrets-c2d8ff87-4a36-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010428006s
STEP: Saw pod success
Mar 19 11:04:28.946: INFO: Pod "pod-projected-secrets-c2d8ff87-4a36-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 11:04:28.950: INFO: Trying to get logs from node k8s-node-vm1y1w-lkllt8nnod pod pod-projected-secrets-c2d8ff87-4a36-11e9-989b-da33bd6188b3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 19 11:04:28.991: INFO: Waiting for pod pod-projected-secrets-c2d8ff87-4a36-11e9-989b-da33bd6188b3 to disappear
Mar 19 11:04:28.996: INFO: Pod pod-projected-secrets-c2d8ff87-4a36-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:04:28.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lggpt" for this suite.
Mar 19 11:04:35.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:04:35.100: INFO: namespace: e2e-tests-projected-lggpt, resource: bindings, ignored listing per whitelist
Mar 19 11:04:35.209: INFO: namespace e2e-tests-projected-lggpt deletion completed in 6.203683655s

• [SLOW TEST:8.375 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:04:35.210: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Mar 19 11:04:35.295: INFO: namespace e2e-tests-kubectl-tzptc
Mar 19 11:04:35.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 create -f - --namespace=e2e-tests-kubectl-tzptc'
Mar 19 11:04:35.626: INFO: stderr: ""
Mar 19 11:04:35.626: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar 19 11:04:36.632: INFO: Selector matched 1 pods for map[app:redis]
Mar 19 11:04:36.632: INFO: Found 1 / 1
Mar 19 11:04:36.632: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 19 11:04:36.637: INFO: Selector matched 1 pods for map[app:redis]
Mar 19 11:04:36.637: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 19 11:04:36.637: INFO: wait on redis-master startup in e2e-tests-kubectl-tzptc 
Mar 19 11:04:36.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 logs redis-master-rds7t redis-master --namespace=e2e-tests-kubectl-tzptc'
Mar 19 11:04:36.748: INFO: stderr: ""
Mar 19 11:04:36.748: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 19 Mar 11:04:36.232 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 19 Mar 11:04:36.232 # Server started, Redis version 3.2.12\n1:M 19 Mar 11:04:36.232 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 19 Mar 11:04:36.232 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Mar 19 11:04:36.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-tzptc'
Mar 19 11:04:36.848: INFO: stderr: ""
Mar 19 11:04:36.848: INFO: stdout: "service/rm2 exposed\n"
Mar 19 11:04:36.856: INFO: Service rm2 in namespace e2e-tests-kubectl-tzptc found.
STEP: exposing service
Mar 19 11:04:38.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-tzptc'
Mar 19 11:04:38.959: INFO: stderr: ""
Mar 19 11:04:38.959: INFO: stdout: "service/rm3 exposed\n"
Mar 19 11:04:38.973: INFO: Service rm3 in namespace e2e-tests-kubectl-tzptc found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:04:40.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tzptc" for this suite.
Mar 19 11:05:03.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:05:03.140: INFO: namespace: e2e-tests-kubectl-tzptc, resource: bindings, ignored listing per whitelist
Mar 19 11:05:03.204: INFO: namespace e2e-tests-kubectl-tzptc deletion completed in 22.208098498s

• [SLOW TEST:27.994 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:05:03.204: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-d8868ed2-4a36-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume configMaps
Mar 19 11:05:03.314: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d88839e3-4a36-11e9-989b-da33bd6188b3" in namespace "e2e-tests-projected-cvgvc" to be "success or failure"
Mar 19 11:05:03.319: INFO: Pod "pod-projected-configmaps-d88839e3-4a36-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.661894ms
Mar 19 11:05:05.325: INFO: Pod "pod-projected-configmaps-d88839e3-4a36-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010477194s
STEP: Saw pod success
Mar 19 11:05:05.325: INFO: Pod "pod-projected-configmaps-d88839e3-4a36-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 11:05:05.330: INFO: Trying to get logs from node k8s-node-vmwvcc-lkllt8nnod pod pod-projected-configmaps-d88839e3-4a36-11e9-989b-da33bd6188b3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 19 11:05:05.366: INFO: Waiting for pod pod-projected-configmaps-d88839e3-4a36-11e9-989b-da33bd6188b3 to disappear
Mar 19 11:05:05.371: INFO: Pod pod-projected-configmaps-d88839e3-4a36-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:05:05.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cvgvc" for this suite.
Mar 19 11:05:11.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:05:11.568: INFO: namespace: e2e-tests-projected-cvgvc, resource: bindings, ignored listing per whitelist
Mar 19 11:05:11.587: INFO: namespace e2e-tests-projected-cvgvc deletion completed in 6.205873409s

• [SLOW TEST:8.383 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:05:11.587: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 19 11:05:11.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-2g94j'
Mar 19 11:05:11.757: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar 19 11:05:11.757: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Mar 19 11:05:15.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-2g94j'
Mar 19 11:05:15.874: INFO: stderr: ""
Mar 19 11:05:15.874: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:05:15.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2g94j" for this suite.
Mar 19 11:05:21.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:05:21.942: INFO: namespace: e2e-tests-kubectl-2g94j, resource: bindings, ignored listing per whitelist
Mar 19 11:05:22.093: INFO: namespace e2e-tests-kubectl-2g94j deletion completed in 6.205398308s

• [SLOW TEST:10.506 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:05:22.093: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-e3c8c3c6-4a36-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume configMaps
Mar 19 11:05:22.200: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e3ca069a-4a36-11e9-989b-da33bd6188b3" in namespace "e2e-tests-projected-qrjvb" to be "success or failure"
Mar 19 11:05:22.205: INFO: Pod "pod-projected-configmaps-e3ca069a-4a36-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.707329ms
Mar 19 11:05:24.210: INFO: Pod "pod-projected-configmaps-e3ca069a-4a36-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010228521s
STEP: Saw pod success
Mar 19 11:05:24.210: INFO: Pod "pod-projected-configmaps-e3ca069a-4a36-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 11:05:24.215: INFO: Trying to get logs from node k8s-node-vm1y1w-lkllt8nnod pod pod-projected-configmaps-e3ca069a-4a36-11e9-989b-da33bd6188b3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 19 11:05:24.253: INFO: Waiting for pod pod-projected-configmaps-e3ca069a-4a36-11e9-989b-da33bd6188b3 to disappear
Mar 19 11:05:24.259: INFO: Pod pod-projected-configmaps-e3ca069a-4a36-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:05:24.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qrjvb" for this suite.
Mar 19 11:05:30.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:05:30.351: INFO: namespace: e2e-tests-projected-qrjvb, resource: bindings, ignored listing per whitelist
Mar 19 11:05:30.469: INFO: namespace e2e-tests-projected-qrjvb deletion completed in 6.201062835s

• [SLOW TEST:8.376 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:05:30.469: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 19 11:05:30.547: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:05:33.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-nqljz" for this suite.
Mar 19 11:05:39.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:05:39.180: INFO: namespace: e2e-tests-init-container-nqljz, resource: bindings, ignored listing per whitelist
Mar 19 11:05:39.313: INFO: namespace e2e-tests-init-container-nqljz deletion completed in 6.215583747s

• [SLOW TEST:8.843 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:05:39.313: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Mar 19 11:05:39.926: INFO: Waiting up to 5m0s for pod "pod-service-account-ee5adeb7-4a36-11e9-989b-da33bd6188b3-48qxn" in namespace "e2e-tests-svcaccounts-rd2jq" to be "success or failure"
Mar 19 11:05:39.934: INFO: Pod "pod-service-account-ee5adeb7-4a36-11e9-989b-da33bd6188b3-48qxn": Phase="Pending", Reason="", readiness=false. Elapsed: 8.411529ms
Mar 19 11:05:41.940: INFO: Pod "pod-service-account-ee5adeb7-4a36-11e9-989b-da33bd6188b3-48qxn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014247295s
STEP: Saw pod success
Mar 19 11:05:41.940: INFO: Pod "pod-service-account-ee5adeb7-4a36-11e9-989b-da33bd6188b3-48qxn" satisfied condition "success or failure"
Mar 19 11:05:41.945: INFO: Trying to get logs from node k8s-node-vm1y1w-lkllt8nnod pod pod-service-account-ee5adeb7-4a36-11e9-989b-da33bd6188b3-48qxn container token-test: <nil>
STEP: delete the pod
Mar 19 11:05:41.982: INFO: Waiting for pod pod-service-account-ee5adeb7-4a36-11e9-989b-da33bd6188b3-48qxn to disappear
Mar 19 11:05:41.986: INFO: Pod pod-service-account-ee5adeb7-4a36-11e9-989b-da33bd6188b3-48qxn no longer exists
STEP: Creating a pod to test consume service account root CA
Mar 19 11:05:41.995: INFO: Waiting up to 5m0s for pod "pod-service-account-ee5adeb7-4a36-11e9-989b-da33bd6188b3-rwvqg" in namespace "e2e-tests-svcaccounts-rd2jq" to be "success or failure"
Mar 19 11:05:42.001: INFO: Pod "pod-service-account-ee5adeb7-4a36-11e9-989b-da33bd6188b3-rwvqg": Phase="Pending", Reason="", readiness=false. Elapsed: 5.842665ms
Mar 19 11:05:44.006: INFO: Pod "pod-service-account-ee5adeb7-4a36-11e9-989b-da33bd6188b3-rwvqg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011261933s
STEP: Saw pod success
Mar 19 11:05:44.006: INFO: Pod "pod-service-account-ee5adeb7-4a36-11e9-989b-da33bd6188b3-rwvqg" satisfied condition "success or failure"
Mar 19 11:05:44.011: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod pod-service-account-ee5adeb7-4a36-11e9-989b-da33bd6188b3-rwvqg container root-ca-test: <nil>
STEP: delete the pod
Mar 19 11:05:44.047: INFO: Waiting for pod pod-service-account-ee5adeb7-4a36-11e9-989b-da33bd6188b3-rwvqg to disappear
Mar 19 11:05:44.052: INFO: Pod pod-service-account-ee5adeb7-4a36-11e9-989b-da33bd6188b3-rwvqg no longer exists
STEP: Creating a pod to test consume service account namespace
Mar 19 11:05:44.059: INFO: Waiting up to 5m0s for pod "pod-service-account-ee5adeb7-4a36-11e9-989b-da33bd6188b3-6x7db" in namespace "e2e-tests-svcaccounts-rd2jq" to be "success or failure"
Mar 19 11:05:44.067: INFO: Pod "pod-service-account-ee5adeb7-4a36-11e9-989b-da33bd6188b3-6x7db": Phase="Pending", Reason="", readiness=false. Elapsed: 8.505244ms
Mar 19 11:05:46.073: INFO: Pod "pod-service-account-ee5adeb7-4a36-11e9-989b-da33bd6188b3-6x7db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014279348s
STEP: Saw pod success
Mar 19 11:05:46.073: INFO: Pod "pod-service-account-ee5adeb7-4a36-11e9-989b-da33bd6188b3-6x7db" satisfied condition "success or failure"
Mar 19 11:05:46.078: INFO: Trying to get logs from node k8s-node-vmwvcc-lkllt8nnod pod pod-service-account-ee5adeb7-4a36-11e9-989b-da33bd6188b3-6x7db container namespace-test: <nil>
STEP: delete the pod
Mar 19 11:05:46.115: INFO: Waiting for pod pod-service-account-ee5adeb7-4a36-11e9-989b-da33bd6188b3-6x7db to disappear
Mar 19 11:05:46.119: INFO: Pod pod-service-account-ee5adeb7-4a36-11e9-989b-da33bd6188b3-6x7db no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:05:46.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-rd2jq" for this suite.
Mar 19 11:05:52.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:05:52.234: INFO: namespace: e2e-tests-svcaccounts-rd2jq, resource: bindings, ignored listing per whitelist
Mar 19 11:05:52.329: INFO: namespace e2e-tests-svcaccounts-rd2jq deletion completed in 6.202116198s

• [SLOW TEST:13.017 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:05:52.329: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-qqr94
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 19 11:05:52.412: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 19 11:06:12.553: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.16.0.37 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-qqr94 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 11:06:12.553: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
Mar 19 11:06:13.645: INFO: Found all expected endpoints: [netserver-0]
Mar 19 11:06:13.650: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.16.0.56 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-qqr94 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 11:06:13.650: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
Mar 19 11:06:14.713: INFO: Found all expected endpoints: [netserver-1]
Mar 19 11:06:14.719: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.16.0.51 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-qqr94 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 11:06:14.719: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
Mar 19 11:06:15.820: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:06:15.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-qqr94" for this suite.
Mar 19 11:06:37.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:06:37.959: INFO: namespace: e2e-tests-pod-network-test-qqr94, resource: bindings, ignored listing per whitelist
Mar 19 11:06:38.039: INFO: namespace e2e-tests-pod-network-test-qqr94 deletion completed in 22.208725708s

• [SLOW TEST:45.710 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:06:38.039: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 11:06:38.143: INFO: Waiting up to 5m0s for pod "downwardapi-volume-110ddb6a-4a37-11e9-989b-da33bd6188b3" in namespace "e2e-tests-downward-api-pt9gz" to be "success or failure"
Mar 19 11:06:38.150: INFO: Pod "downwardapi-volume-110ddb6a-4a37-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.908677ms
Mar 19 11:06:40.156: INFO: Pod "downwardapi-volume-110ddb6a-4a37-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012848581s
STEP: Saw pod success
Mar 19 11:06:40.156: INFO: Pod "downwardapi-volume-110ddb6a-4a37-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 11:06:40.161: INFO: Trying to get logs from node k8s-node-vmwvcc-lkllt8nnod pod downwardapi-volume-110ddb6a-4a37-11e9-989b-da33bd6188b3 container client-container: <nil>
STEP: delete the pod
Mar 19 11:06:40.200: INFO: Waiting for pod downwardapi-volume-110ddb6a-4a37-11e9-989b-da33bd6188b3 to disappear
Mar 19 11:06:40.205: INFO: Pod downwardapi-volume-110ddb6a-4a37-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:06:40.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pt9gz" for this suite.
Mar 19 11:06:46.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:06:46.374: INFO: namespace: e2e-tests-downward-api-pt9gz, resource: bindings, ignored listing per whitelist
Mar 19 11:06:46.419: INFO: namespace e2e-tests-downward-api-pt9gz deletion completed in 6.203896822s

• [SLOW TEST:8.380 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:06:46.419: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 11:06:46.508: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Mar 19 11:06:51.514: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 19 11:06:51.514: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 19 11:06:51.534: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-h5rxd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-h5rxd/deployments/test-cleanup-deployment,UID:fa6e1c01-4a36-11e9-b857-fa163eaabeb9,ResourceVersion:1206314,Generation:1,CreationTimestamp:2019-03-19 11:06:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Mar 19 11:06:51.537: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:06:51.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-h5rxd" for this suite.
Mar 19 11:06:57.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:06:57.739: INFO: namespace: e2e-tests-deployment-h5rxd, resource: bindings, ignored listing per whitelist
Mar 19 11:06:57.769: INFO: namespace e2e-tests-deployment-h5rxd deletion completed in 6.213292487s

• [SLOW TEST:11.350 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:06:57.769: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 11:06:57.863: INFO: Pod name rollover-pod: Found 0 pods out of 1
Mar 19 11:07:02.869: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 19 11:07:02.869: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Mar 19 11:07:04.873: INFO: Creating deployment "test-rollover-deployment"
Mar 19 11:07:04.885: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Mar 19 11:07:06.891: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Mar 19 11:07:06.897: INFO: Ensure that both replica sets have 1 created replica
Mar 19 11:07:06.902: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Mar 19 11:07:06.910: INFO: Updating deployment test-rollover-deployment
Mar 19 11:07:06.910: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Mar 19 11:07:08.917: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Mar 19 11:07:08.922: INFO: Make sure deployment "test-rollover-deployment" is complete
Mar 19 11:07:08.928: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 11:07:08.928: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 11:07:10.935: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 11:07:10.935: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 11:07:12.935: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 11:07:12.935: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 11:07:14.935: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 11:07:14.935: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 11:07:16.935: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 11:07:16.935: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 11:07:18.935: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 11:07:18.935: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 11:07:20.995: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 11:07:20.995: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 11:07:22.934: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 11:07:22.934: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 11:07:24.935: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 11:07:24.935: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 11:07:26.935: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 11:07:26.935: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 11:07:28.934: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 11:07:28.934: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 11:07:30.935: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 11:07:30.935: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 11:07:32.935: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 11:07:32.935: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 11:07:34.935: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 11:07:34.935: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 11:07:36.935: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 11:07:36.935: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 11:07:38.935: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 11:07:38.935: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 11:07:40.935: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 11:07:40.935: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 11:07:42.935: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 11:07:42.935: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 11:07:44.935: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 11:07:44.935: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 11:07:46.935: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 11:07:46.935: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 11:07:48.935: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 11:07:48.935: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 11:07:50.935: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 11:07:50.935: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 11:07:52.935: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 11:07:52.935: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 11:07:54.935: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 11:07:54.935: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 11:07:56.935: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 11:07:56.935: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 11:07:58.934: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 11:07:58.934: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 11:08:00.935: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 11:08:00.935: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 11:08:02.934: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 11:08:02.934: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 11:08:04.935: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 11:08:04.935: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 11:08:06.935: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 11:08:06.935: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688590379, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 11:08:08.935: INFO: 
Mar 19 11:08:08.935: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 19 11:08:08.943: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-qshhh,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qshhh/deployments/test-rollover-deployment,UID:02638348-4a37-11e9-b857-fa163eaabeb9,ResourceVersion:1206559,Generation:2,CreationTimestamp:2019-03-19 11:06:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-19 11:06:19 +0000 UTC 2019-03-19 11:06:19 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-19 11:07:22 +0000 UTC 2019-03-19 11:06:19 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar 19 11:08:08.946: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-qshhh,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qshhh/replicasets/test-rollover-deployment-5b76ff8c4,UID:0738f2bf-4a37-11e9-8b0a-fa163ecd2a50,ResourceVersion:1206550,Generation:2,CreationTimestamp:2019-03-19 11:06:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 02638348-4a37-11e9-b857-fa163eaabeb9 0xc420e229f7 0xc420e229f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 19 11:08:08.946: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Mar 19 11:08:08.946: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-qshhh,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qshhh/replicasets/test-rollover-controller,UID:fe3482cd-4a36-11e9-b857-fa163eaabeb9,ResourceVersion:1206558,Generation:2,CreationTimestamp:2019-03-19 11:06:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 02638348-4a37-11e9-b857-fa163eaabeb9 0xc420e22717 0xc420e22718}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 19 11:08:08.946: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-qshhh,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qshhh/replicasets/test-rollover-deployment-6975f4fb87,UID:0605f676-4a37-11e9-8b0a-fa163ecd2a50,ResourceVersion:1206424,Generation:2,CreationTimestamp:2019-03-19 11:06:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 02638348-4a37-11e9-b857-fa163eaabeb9 0xc420e22ac7 0xc420e22ac8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 19 11:08:08.951: INFO: Pod "test-rollover-deployment-5b76ff8c4-qfqn4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-qfqn4,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-qshhh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qshhh/pods/test-rollover-deployment-5b76ff8c4-qfqn4,UID:073f6710-4a37-11e9-8b0a-fa163ecd2a50,ResourceVersion:1206436,Generation:0,CreationTimestamp:2019-03-19 11:06:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 0738f2bf-4a37-11e9-8b0a-fa163ecd2a50 0xc420e23bd0 0xc420e23bd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mv7ld {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mv7ld,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-mv7ld true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm1y1w-lkllt8nnod,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420e23c30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420e23c50}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:07:07 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:07:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:07:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 11:06:13 +0000 UTC  }],Message:,Reason:,HostIP:172.16.128.12,PodIP:172.16.0.14,StartTime:2019-03-19 11:07:07 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-19 11:07:07 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker://sha256:e4423e943a205fe1d81768e60603c8f2c5821576bad0801c1e91b8ba586124a0 docker://9dd6aaa5fe48d73d8f50370b3002d32567dde9c60f4a7c6fa7b8d5832762894a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:08:08.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-qshhh" for this suite.
Mar 19 11:08:14.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:08:15.002: INFO: namespace: e2e-tests-deployment-qshhh, resource: bindings, ignored listing per whitelist
Mar 19 11:08:15.165: INFO: namespace e2e-tests-deployment-qshhh deletion completed in 6.204169606s

• [SLOW TEST:77.396 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:08:15.165: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 19 11:08:15.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-khb27'
Mar 19 11:08:15.351: INFO: stderr: ""
Mar 19 11:08:15.351: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Mar 19 11:08:20.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-khb27 -o json'
Mar 19 11:08:20.475: INFO: stderr: ""
Mar 19 11:08:20.475: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-03-19T11:07:21Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-khb27\",\n        \"resourceVersion\": \"1206622\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-khb27/pods/e2e-test-nginx-pod\",\n        \"uid\": \"2b0a58c5-4a37-11e9-90e9-fa163eae055d\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-hnk9c\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"k8s-node-vmwvcc-lkllt8nnod\",\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-hnk9c\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-hnk9c\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-19T11:08:15Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-19T11:08:15Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-19T11:08:15Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-19T11:07:21Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://2be839fae3bca120d416a75a0db6220cde4adb07c2244d421f1213eac7dd636f\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-03-19T11:08:15Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.16.128.13\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.16.0.51\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-03-19T11:08:15Z\"\n    }\n}\n"
STEP: replace the image in the pod
Mar 19 11:08:20.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 replace -f - --namespace=e2e-tests-kubectl-khb27'
Mar 19 11:08:20.632: INFO: stderr: ""
Mar 19 11:08:20.632: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Mar 19 11:08:20.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-khb27'
Mar 19 11:08:22.018: INFO: stderr: ""
Mar 19 11:08:22.018: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:08:22.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-khb27" for this suite.
Mar 19 11:08:28.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:08:28.143: INFO: namespace: e2e-tests-kubectl-khb27, resource: bindings, ignored listing per whitelist
Mar 19 11:08:28.233: INFO: namespace e2e-tests-kubectl-khb27 deletion completed in 6.205210511s

• [SLOW TEST:13.068 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:08:28.233: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-52bbcd0a-4a37-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume secrets
Mar 19 11:08:28.343: INFO: Waiting up to 5m0s for pod "pod-secrets-52bd22bf-4a37-11e9-989b-da33bd6188b3" in namespace "e2e-tests-secrets-lnbt8" to be "success or failure"
Mar 19 11:08:28.348: INFO: Pod "pod-secrets-52bd22bf-4a37-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.776558ms
Mar 19 11:08:30.353: INFO: Pod "pod-secrets-52bd22bf-4a37-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010303208s
STEP: Saw pod success
Mar 19 11:08:30.353: INFO: Pod "pod-secrets-52bd22bf-4a37-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 11:08:30.360: INFO: Trying to get logs from node k8s-node-vm1y1w-lkllt8nnod pod pod-secrets-52bd22bf-4a37-11e9-989b-da33bd6188b3 container secret-volume-test: <nil>
STEP: delete the pod
Mar 19 11:08:30.396: INFO: Waiting for pod pod-secrets-52bd22bf-4a37-11e9-989b-da33bd6188b3 to disappear
Mar 19 11:08:30.404: INFO: Pod pod-secrets-52bd22bf-4a37-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:08:30.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-lnbt8" for this suite.
Mar 19 11:08:36.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:08:36.486: INFO: namespace: e2e-tests-secrets-lnbt8, resource: bindings, ignored listing per whitelist
Mar 19 11:08:36.619: INFO: namespace e2e-tests-secrets-lnbt8 deletion completed in 6.205412169s

• [SLOW TEST:8.386 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:08:36.619: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Mar 19 11:08:36.711: INFO: Waiting up to 5m0s for pod "var-expansion-57ba2508-4a37-11e9-989b-da33bd6188b3" in namespace "e2e-tests-var-expansion-l7jd8" to be "success or failure"
Mar 19 11:08:36.716: INFO: Pod "var-expansion-57ba2508-4a37-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.730404ms
Mar 19 11:08:38.721: INFO: Pod "var-expansion-57ba2508-4a37-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010035287s
STEP: Saw pod success
Mar 19 11:08:38.721: INFO: Pod "var-expansion-57ba2508-4a37-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 11:08:38.727: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod var-expansion-57ba2508-4a37-11e9-989b-da33bd6188b3 container dapi-container: <nil>
STEP: delete the pod
Mar 19 11:08:38.765: INFO: Waiting for pod var-expansion-57ba2508-4a37-11e9-989b-da33bd6188b3 to disappear
Mar 19 11:08:38.770: INFO: Pod var-expansion-57ba2508-4a37-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:08:38.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-l7jd8" for this suite.
Mar 19 11:08:44.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:08:44.882: INFO: namespace: e2e-tests-var-expansion-l7jd8, resource: bindings, ignored listing per whitelist
Mar 19 11:08:44.982: INFO: namespace e2e-tests-var-expansion-l7jd8 deletion completed in 6.203636645s

• [SLOW TEST:8.363 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:08:44.982: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-5cb6e0a6-4a37-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume secrets
Mar 19 11:08:45.089: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5cb7fec2-4a37-11e9-989b-da33bd6188b3" in namespace "e2e-tests-projected-b2q48" to be "success or failure"
Mar 19 11:08:45.093: INFO: Pod "pod-projected-secrets-5cb7fec2-4a37-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.711197ms
Mar 19 11:08:47.099: INFO: Pod "pod-projected-secrets-5cb7fec2-4a37-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010283826s
STEP: Saw pod success
Mar 19 11:08:47.099: INFO: Pod "pod-projected-secrets-5cb7fec2-4a37-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 11:08:47.104: INFO: Trying to get logs from node k8s-node-vmwvcc-lkllt8nnod pod pod-projected-secrets-5cb7fec2-4a37-11e9-989b-da33bd6188b3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 19 11:08:47.141: INFO: Waiting for pod pod-projected-secrets-5cb7fec2-4a37-11e9-989b-da33bd6188b3 to disappear
Mar 19 11:08:47.146: INFO: Pod pod-projected-secrets-5cb7fec2-4a37-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:08:47.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-b2q48" for this suite.
Mar 19 11:08:53.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:08:53.235: INFO: namespace: e2e-tests-projected-b2q48, resource: bindings, ignored listing per whitelist
Mar 19 11:08:53.356: INFO: namespace e2e-tests-projected-b2q48 deletion completed in 6.20127501s

• [SLOW TEST:8.375 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:08:53.357: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 11:09:11.468: INFO: Container started at 2019-03-19 11:08:54 +0000 UTC, pod became ready at 2019-03-19 11:09:10 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:09:11.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-ztkc6" for this suite.
Mar 19 11:09:31.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:09:31.637: INFO: namespace: e2e-tests-container-probe-ztkc6, resource: bindings, ignored listing per whitelist
Mar 19 11:09:31.688: INFO: namespace e2e-tests-container-probe-ztkc6 deletion completed in 20.209517146s

• [SLOW TEST:38.331 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:09:31.688: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 11:09:31.791: INFO: Waiting up to 5m0s for pod "downwardapi-volume-788e8a5f-4a37-11e9-989b-da33bd6188b3" in namespace "e2e-tests-downward-api-k8h4s" to be "success or failure"
Mar 19 11:09:31.798: INFO: Pod "downwardapi-volume-788e8a5f-4a37-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.380045ms
Mar 19 11:09:33.804: INFO: Pod "downwardapi-volume-788e8a5f-4a37-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012237406s
STEP: Saw pod success
Mar 19 11:09:33.804: INFO: Pod "downwardapi-volume-788e8a5f-4a37-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 11:09:33.809: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod downwardapi-volume-788e8a5f-4a37-11e9-989b-da33bd6188b3 container client-container: <nil>
STEP: delete the pod
Mar 19 11:09:33.845: INFO: Waiting for pod downwardapi-volume-788e8a5f-4a37-11e9-989b-da33bd6188b3 to disappear
Mar 19 11:09:33.850: INFO: Pod downwardapi-volume-788e8a5f-4a37-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:09:33.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-k8h4s" for this suite.
Mar 19 11:09:39.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:09:40.055: INFO: namespace: e2e-tests-downward-api-k8h4s, resource: bindings, ignored listing per whitelist
Mar 19 11:09:40.068: INFO: namespace e2e-tests-downward-api-k8h4s deletion completed in 6.207451699s

• [SLOW TEST:8.380 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:09:40.068: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar 19 11:09:40.159: INFO: Waiting up to 5m0s for pod "pod-7d8b8d2c-4a37-11e9-989b-da33bd6188b3" in namespace "e2e-tests-emptydir-w2892" to be "success or failure"
Mar 19 11:09:40.164: INFO: Pod "pod-7d8b8d2c-4a37-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.902268ms
Mar 19 11:09:42.170: INFO: Pod "pod-7d8b8d2c-4a37-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010716393s
STEP: Saw pod success
Mar 19 11:09:42.170: INFO: Pod "pod-7d8b8d2c-4a37-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 11:09:42.175: INFO: Trying to get logs from node k8s-node-vmwvcc-lkllt8nnod pod pod-7d8b8d2c-4a37-11e9-989b-da33bd6188b3 container test-container: <nil>
STEP: delete the pod
Mar 19 11:09:42.213: INFO: Waiting for pod pod-7d8b8d2c-4a37-11e9-989b-da33bd6188b3 to disappear
Mar 19 11:09:42.217: INFO: Pod pod-7d8b8d2c-4a37-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:09:42.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-w2892" for this suite.
Mar 19 11:09:48.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:09:48.281: INFO: namespace: e2e-tests-emptydir-w2892, resource: bindings, ignored listing per whitelist
Mar 19 11:09:48.434: INFO: namespace e2e-tests-emptydir-w2892 deletion completed in 6.207030951s

• [SLOW TEST:8.366 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:09:48.434: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Mar 19 11:09:48.523: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-715664315 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:09:48.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d8lwj" for this suite.
Mar 19 11:09:54.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:09:54.675: INFO: namespace: e2e-tests-kubectl-d8lwj, resource: bindings, ignored listing per whitelist
Mar 19 11:09:54.796: INFO: namespace e2e-tests-kubectl-d8lwj deletion completed in 6.209213041s

• [SLOW TEST:6.362 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:09:54.796: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 19 11:09:57.440: INFO: Successfully updated pod "annotationupdate8652aa66-4a37-11e9-989b-da33bd6188b3"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:10:01.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-s8qzd" for this suite.
Mar 19 11:10:23.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:10:23.581: INFO: namespace: e2e-tests-projected-s8qzd, resource: bindings, ignored listing per whitelist
Mar 19 11:10:23.703: INFO: namespace e2e-tests-projected-s8qzd deletion completed in 22.204381139s

• [SLOW TEST:28.907 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:10:23.704: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 11:10:23.821: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Mar 19 11:10:23.827: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-26kbd/daemonsets","resourceVersion":"1207039"},"items":null}

Mar 19 11:10:23.832: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-26kbd/pods","resourceVersion":"1207039"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:10:23.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-26kbd" for this suite.
Mar 19 11:10:29.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:10:30.034: INFO: namespace: e2e-tests-daemonsets-26kbd, resource: bindings, ignored listing per whitelist
Mar 19 11:10:30.074: INFO: namespace e2e-tests-daemonsets-26kbd deletion completed in 6.205851503s

S [SKIPPING] [6.370 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Mar 19 11:10:23.821: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:10:30.074: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar 19 11:10:30.181: INFO: Waiting up to 5m0s for pod "pod-9b5c1f1a-4a37-11e9-989b-da33bd6188b3" in namespace "e2e-tests-emptydir-h6n9f" to be "success or failure"
Mar 19 11:10:30.186: INFO: Pod "pod-9b5c1f1a-4a37-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.67681ms
Mar 19 11:10:32.192: INFO: Pod "pod-9b5c1f1a-4a37-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010747125s
STEP: Saw pod success
Mar 19 11:10:32.192: INFO: Pod "pod-9b5c1f1a-4a37-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 11:10:32.197: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod pod-9b5c1f1a-4a37-11e9-989b-da33bd6188b3 container test-container: <nil>
STEP: delete the pod
Mar 19 11:10:32.234: INFO: Waiting for pod pod-9b5c1f1a-4a37-11e9-989b-da33bd6188b3 to disappear
Mar 19 11:10:32.238: INFO: Pod pod-9b5c1f1a-4a37-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:10:32.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-h6n9f" for this suite.
Mar 19 11:10:38.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:10:38.335: INFO: namespace: e2e-tests-emptydir-h6n9f, resource: bindings, ignored listing per whitelist
Mar 19 11:10:38.448: INFO: namespace e2e-tests-emptydir-h6n9f deletion completed in 6.199526846s

• [SLOW TEST:8.374 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:10:38.448: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:11:38.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-mjl8m" for this suite.
Mar 19 11:12:00.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:12:00.688: INFO: namespace: e2e-tests-container-probe-mjl8m, resource: bindings, ignored listing per whitelist
Mar 19 11:12:00.768: INFO: namespace e2e-tests-container-probe-mjl8m deletion completed in 22.203570225s

• [SLOW TEST:82.320 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:12:00.768: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-d16ab14f-4a37-11e9-989b-da33bd6188b3
STEP: Creating a pod to test consume configMaps
Mar 19 11:12:00.882: INFO: Waiting up to 5m0s for pod "pod-configmaps-d16bf3b2-4a37-11e9-989b-da33bd6188b3" in namespace "e2e-tests-configmap-7lccz" to be "success or failure"
Mar 19 11:12:00.887: INFO: Pod "pod-configmaps-d16bf3b2-4a37-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.955643ms
Mar 19 11:12:02.893: INFO: Pod "pod-configmaps-d16bf3b2-4a37-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010601956s
STEP: Saw pod success
Mar 19 11:12:02.893: INFO: Pod "pod-configmaps-d16bf3b2-4a37-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 11:12:02.898: INFO: Trying to get logs from node k8s-node-vm1y1w-lkllt8nnod pod pod-configmaps-d16bf3b2-4a37-11e9-989b-da33bd6188b3 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 19 11:12:02.935: INFO: Waiting for pod pod-configmaps-d16bf3b2-4a37-11e9-989b-da33bd6188b3 to disappear
Mar 19 11:12:02.939: INFO: Pod pod-configmaps-d16bf3b2-4a37-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:12:02.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-7lccz" for this suite.
Mar 19 11:12:08.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:12:08.986: INFO: namespace: e2e-tests-configmap-7lccz, resource: bindings, ignored listing per whitelist
Mar 19 11:12:09.155: INFO: namespace e2e-tests-configmap-7lccz deletion completed in 6.20616625s

• [SLOW TEST:8.387 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:12:09.155: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Mar 19 11:12:09.249: INFO: Waiting up to 5m0s for pod "pod-d668e184-4a37-11e9-989b-da33bd6188b3" in namespace "e2e-tests-emptydir-8zbnd" to be "success or failure"
Mar 19 11:12:09.254: INFO: Pod "pod-d668e184-4a37-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.630485ms
Mar 19 11:12:11.259: INFO: Pod "pod-d668e184-4a37-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010374328s
STEP: Saw pod success
Mar 19 11:12:11.259: INFO: Pod "pod-d668e184-4a37-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 11:12:11.264: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod pod-d668e184-4a37-11e9-989b-da33bd6188b3 container test-container: <nil>
STEP: delete the pod
Mar 19 11:12:11.300: INFO: Waiting for pod pod-d668e184-4a37-11e9-989b-da33bd6188b3 to disappear
Mar 19 11:12:11.305: INFO: Pod pod-d668e184-4a37-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:12:11.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8zbnd" for this suite.
Mar 19 11:12:17.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:12:17.403: INFO: namespace: e2e-tests-emptydir-8zbnd, resource: bindings, ignored listing per whitelist
Mar 19 11:12:17.517: INFO: namespace e2e-tests-emptydir-8zbnd deletion completed in 6.202924147s

• [SLOW TEST:8.362 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:12:17.518: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Mar 19 11:12:17.618: INFO: Waiting up to 5m0s for pod "client-containers-db65d1e3-4a37-11e9-989b-da33bd6188b3" in namespace "e2e-tests-containers-bsgk4" to be "success or failure"
Mar 19 11:12:17.623: INFO: Pod "client-containers-db65d1e3-4a37-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.719908ms
Mar 19 11:12:19.628: INFO: Pod "client-containers-db65d1e3-4a37-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010424092s
STEP: Saw pod success
Mar 19 11:12:19.628: INFO: Pod "client-containers-db65d1e3-4a37-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 11:12:19.633: INFO: Trying to get logs from node k8s-node-vmwvcc-lkllt8nnod pod client-containers-db65d1e3-4a37-11e9-989b-da33bd6188b3 container test-container: <nil>
STEP: delete the pod
Mar 19 11:12:19.668: INFO: Waiting for pod client-containers-db65d1e3-4a37-11e9-989b-da33bd6188b3 to disappear
Mar 19 11:12:19.673: INFO: Pod client-containers-db65d1e3-4a37-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:12:19.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-bsgk4" for this suite.
Mar 19 11:12:25.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:12:25.872: INFO: namespace: e2e-tests-containers-bsgk4, resource: bindings, ignored listing per whitelist
Mar 19 11:12:25.889: INFO: namespace e2e-tests-containers-bsgk4 deletion completed in 6.203879189s

• [SLOW TEST:8.371 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:12:25.889: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 11:12:26.001: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Mar 19 11:12:26.018: INFO: Number of nodes with available pods: 0
Mar 19 11:12:26.018: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 11:12:27.033: INFO: Number of nodes with available pods: 1
Mar 19 11:12:27.033: INFO: Node k8s-node-vm1y1w-lkllt8nnod is running more than one daemon pod
Mar 19 11:12:28.034: INFO: Number of nodes with available pods: 3
Mar 19 11:12:28.034: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Mar 19 11:12:28.062: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:28.062: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:28.062: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:29.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:29.077: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:29.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:30.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:30.077: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:30.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:31.078: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:31.078: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:31.078: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:32.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:32.077: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:32.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:33.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:33.077: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:33.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:34.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:34.077: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:34.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:35.076: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:35.076: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:35.076: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:36.076: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:36.076: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:36.076: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:37.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:37.077: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:37.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:38.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:38.077: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:38.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:39.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:39.077: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:39.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:40.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:40.077: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:40.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:41.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:41.077: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:41.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:42.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:42.077: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:42.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:43.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:43.077: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:43.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:44.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:44.077: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:44.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:45.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:45.077: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:45.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:46.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:46.077: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:46.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:47.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:47.077: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:47.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:48.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:48.077: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:48.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:49.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:49.077: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:49.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:50.076: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:50.076: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:50.076: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:51.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:51.077: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:51.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:52.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:52.077: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:52.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:53.076: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:53.076: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:53.076: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:54.076: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:54.076: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:54.076: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:55.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:55.077: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:55.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:56.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:56.077: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:56.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:57.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:57.077: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:57.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:58.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:58.077: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:58.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:59.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:59.077: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:12:59.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:00.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:00.077: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:00.077: INFO: Pod daemon-set-78lnz is not available
Mar 19 11:13:00.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:01.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:01.077: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:01.077: INFO: Pod daemon-set-78lnz is not available
Mar 19 11:13:01.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:02.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:02.077: INFO: Wrong image for pod: daemon-set-78lnz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:02.077: INFO: Pod daemon-set-78lnz is not available
Mar 19 11:13:02.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:03.076: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:03.076: INFO: Pod daemon-set-pn2gt is not available
Mar 19 11:13:03.076: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:04.076: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:04.076: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:05.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:05.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:06.076: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:06.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:07.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:07.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:08.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:08.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:09.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:09.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:10.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:10.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:11.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:11.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:12.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:12.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:13.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:13.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:14.076: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:14.076: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:15.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:15.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:16.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:16.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:17.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:17.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:18.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:18.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:19.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:19.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:20.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:20.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:21.076: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:21.076: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:22.076: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:22.076: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:23.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:23.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:24.076: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:24.076: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:25.076: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:25.076: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:26.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:26.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:27.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:27.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:28.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:28.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:29.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:29.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:30.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:30.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:31.076: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:31.076: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:32.076: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:32.076: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:33.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:33.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:34.076: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:34.076: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:35.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:35.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:35.077: INFO: Pod daemon-set-qzfjf is not available
Mar 19 11:13:36.076: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:36.076: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:36.076: INFO: Pod daemon-set-qzfjf is not available
Mar 19 11:13:37.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:37.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:37.077: INFO: Pod daemon-set-qzfjf is not available
Mar 19 11:13:38.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:38.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:38.077: INFO: Pod daemon-set-qzfjf is not available
Mar 19 11:13:39.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:39.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:39.077: INFO: Pod daemon-set-qzfjf is not available
Mar 19 11:13:40.076: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:40.076: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:40.076: INFO: Pod daemon-set-qzfjf is not available
Mar 19 11:13:41.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:41.077: INFO: Wrong image for pod: daemon-set-qzfjf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:41.077: INFO: Pod daemon-set-qzfjf is not available
Mar 19 11:13:42.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:42.077: INFO: Pod daemon-set-q6vr6 is not available
Mar 19 11:13:43.076: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:44.076: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:45.076: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:46.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:47.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:48.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:49.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:50.076: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:51.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:52.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:53.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:54.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:55.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:56.078: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:57.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:58.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:13:59.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:14:00.076: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:14:01.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:14:02.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:14:03.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:14:04.076: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:14:05.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:14:06.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:14:07.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:14:08.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:14:09.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:14:10.076: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:14:11.076: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:14:12.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:14:13.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:14:14.077: INFO: Wrong image for pod: daemon-set-4qpr4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 11:14:14.077: INFO: Pod daemon-set-4qpr4 is not available
Mar 19 11:14:15.076: INFO: Pod daemon-set-5rqfx is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Mar 19 11:14:15.100: INFO: Number of nodes with available pods: 2
Mar 19 11:14:15.100: INFO: Node k8s-node-vmepd8-lkllt8nnod is running more than one daemon pod
Mar 19 11:14:16.116: INFO: Number of nodes with available pods: 3
Mar 19 11:14:16.116: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-fr9jw, will wait for the garbage collector to delete the pods
Mar 19 11:14:16.212: INFO: Deleting {extensions DaemonSet} daemon-set took: 21.674622ms
Mar 19 11:14:16.312: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.183004ms
Mar 19 11:14:25.818: INFO: Number of nodes with available pods: 0
Mar 19 11:14:25.818: INFO: Number of running nodes: 0, number of available pods: 0
Mar 19 11:14:25.821: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-fr9jw/daemonsets","resourceVersion":"1207694"},"items":null}

Mar 19 11:14:25.826: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-fr9jw/pods","resourceVersion":"1207694"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:14:25.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-fr9jw" for this suite.
Mar 19 11:14:31.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:14:31.957: INFO: namespace: e2e-tests-daemonsets-fr9jw, resource: bindings, ignored listing per whitelist
Mar 19 11:14:32.071: INFO: namespace e2e-tests-daemonsets-fr9jw deletion completed in 6.206696479s

• [SLOW TEST:126.182 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:14:32.071: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-6vq5s
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 19 11:14:32.162: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 19 11:14:52.293: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.16.0.3:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-6vq5s PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 11:14:52.293: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
Mar 19 11:14:52.370: INFO: Found all expected endpoints: [netserver-0]
Mar 19 11:14:52.375: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.16.0.41:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-6vq5s PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 11:14:52.375: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
Mar 19 11:14:52.464: INFO: Found all expected endpoints: [netserver-1]
Mar 19 11:14:52.469: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.16.0.22:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-6vq5s PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 11:14:52.469: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
Mar 19 11:14:52.547: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:14:52.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-6vq5s" for this suite.
Mar 19 11:15:14.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:15:14.657: INFO: namespace: e2e-tests-pod-network-test-6vq5s, resource: bindings, ignored listing per whitelist
Mar 19 11:15:14.766: INFO: namespace e2e-tests-pod-network-test-6vq5s deletion completed in 22.20889838s

• [SLOW TEST:42.695 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:15:14.766: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0319 11:15:54.922011      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 19 11:15:54.922: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:15:54.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-m8wzc" for this suite.
Mar 19 11:16:02.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:16:03.031: INFO: namespace: e2e-tests-gc-m8wzc, resource: bindings, ignored listing per whitelist
Mar 19 11:16:03.133: INFO: namespace e2e-tests-gc-m8wzc deletion completed in 8.204293469s

• [SLOW TEST:48.367 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:16:03.134: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Mar 19 11:16:03.239: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-nvbjx" to be "success or failure"
Mar 19 11:16:03.244: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.499949ms
Mar 19 11:16:05.250: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010601968s
STEP: Saw pod success
Mar 19 11:16:05.250: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Mar 19 11:16:05.255: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Mar 19 11:16:05.291: INFO: Waiting for pod pod-host-path-test to disappear
Mar 19 11:16:05.295: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:16:05.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-nvbjx" for this suite.
Mar 19 11:16:11.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:16:11.476: INFO: namespace: e2e-tests-hostpath-nvbjx, resource: bindings, ignored listing per whitelist
Mar 19 11:16:11.521: INFO: namespace e2e-tests-hostpath-nvbjx deletion completed in 6.215534388s

• [SLOW TEST:8.387 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:16:11.521: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 11:16:11.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 version --client'
Mar 19 11:16:11.649: INFO: stderr: ""
Mar 19 11:16:11.649: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Mar 19 11:16:11.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 create -f - --namespace=e2e-tests-kubectl-stjh2'
Mar 19 11:16:12.004: INFO: stderr: ""
Mar 19 11:16:12.004: INFO: stdout: "replicationcontroller/redis-master created\n"
Mar 19 11:16:12.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 create -f - --namespace=e2e-tests-kubectl-stjh2'
Mar 19 11:16:12.206: INFO: stderr: ""
Mar 19 11:16:12.206: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar 19 11:16:13.212: INFO: Selector matched 1 pods for map[app:redis]
Mar 19 11:16:13.212: INFO: Found 0 / 1
Mar 19 11:16:14.212: INFO: Selector matched 1 pods for map[app:redis]
Mar 19 11:16:14.212: INFO: Found 1 / 1
Mar 19 11:16:14.212: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 19 11:16:14.217: INFO: Selector matched 1 pods for map[app:redis]
Mar 19 11:16:14.217: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 19 11:16:14.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 describe pod redis-master-qz2s8 --namespace=e2e-tests-kubectl-stjh2'
Mar 19 11:16:14.310: INFO: stderr: ""
Mar 19 11:16:14.310: INFO: stdout: "Name:           redis-master-qz2s8\nNamespace:      e2e-tests-kubectl-stjh2\nNode:           k8s-node-vmwvcc-lkllt8nnod/172.16.128.13\nStart Time:     Tue, 19 Mar 2019 11:16:12 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    <none>\nStatus:         Running\nIP:             172.16.0.51\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://2977b58c29dc3a5eaa7b1990c3e5da54152672a6fe0f633aea5a027015ff1216\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker://sha256:e4423e943a205fe1d81768e60603c8f2c5821576bad0801c1e91b8ba586124a0\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 19 Mar 2019 11:16:12 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-8tgvj (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-8tgvj:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-8tgvj\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                 Message\n  ----    ------     ----  ----                                 -------\n  Normal  Scheduled  48s   default-scheduler                    Successfully assigned e2e-tests-kubectl-stjh2/redis-master-qz2s8 to k8s-node-vmwvcc-lkllt8nnod\n  Normal  Pulled     2s    kubelet, k8s-node-vmwvcc-lkllt8nnod  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, k8s-node-vmwvcc-lkllt8nnod  Created container\n  Normal  Started    2s    kubelet, k8s-node-vmwvcc-lkllt8nnod  Started container\n"
Mar 19 11:16:14.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 describe rc redis-master --namespace=e2e-tests-kubectl-stjh2'
Mar 19 11:16:14.408: INFO: stderr: ""
Mar 19 11:16:14.408: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-stjh2\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  48s   replication-controller  Created pod: redis-master-qz2s8\n"
Mar 19 11:16:14.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 describe service redis-master --namespace=e2e-tests-kubectl-stjh2'
Mar 19 11:16:14.504: INFO: stderr: ""
Mar 19 11:16:14.504: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-stjh2\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.16.238.244\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.16.0.51:6379\nSession Affinity:  None\nEvents:            <none>\n"
Mar 19 11:16:14.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 describe node k8s-node-vm1y1w-lkllt8nnod'
Mar 19 11:16:14.619: INFO: stderr: ""
Mar 19 11:16:14.619: INFO: stdout: "Name:               k8s-node-vm1y1w-lkllt8nnod\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=g.n2.xlarge\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/jke-fd=1\n                    failure-domain.beta.kubernetes.io/jke-nodegroup=ng-lkllt8nnod\n                    failure-domain.beta.kubernetes.io/region=cn-north-1\n                    failure-domain.beta.kubernetes.io/zone=cn-north-1a\n                    group=default\n                    kubernetes.io/hostname=k8s-node-vm1y1w-lkllt8nnod\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\nCreationTimestamp:  Mon, 18 Mar 2019 06:25:33 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Tue, 19 Mar 2019 11:16:10 +0000   Mon, 18 Mar 2019 06:26:17 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Tue, 19 Mar 2019 11:16:10 +0000   Mon, 18 Mar 2019 06:26:17 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Tue, 19 Mar 2019 11:16:10 +0000   Mon, 18 Mar 2019 06:26:17 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Tue, 19 Mar 2019 11:16:10 +0000   Mon, 18 Mar 2019 06:26:17 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Tue, 19 Mar 2019 11:16:10 +0000   Mon, 18 Mar 2019 06:26:37 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  172.16.128.12\nCapacity:\n cpu:                4\n ephemeral-storage:  103079844Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16267708Ki\n pods:               110\nAllocatable:\n cpu:                3920m\n ephemeral-storage:  94998384074\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             13541820Ki\n pods:               110\nSystem Info:\n Machine ID:                 64639b6a8b6c437a898763164b0a0d2b\n System UUID:                46FB3D61-830A-4AA2-ACA2-F9C581A89301\n Boot ID:                    f31a3979-8da3-41c9-a6ef-e7db9b6f23d9\n Kernel Version:             3.10.0-693.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://17.6.2\n Kubelet Version:            v1.12.3-23.56f6f14\n Kube-Proxy Version:         v1.12.3-23.56f6f14\nProviderID:                  jdcloud:///cn-north-1a/i-b3y73tibwm\nNon-terminated Pods:         (7 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-421c51583ba54221-jfpn4    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  jke-system                 kube-state-metrics-c866955d-j29vx                          204m (5%)     204m (5%)   138Mi (1%)       138Mi (1%)\n  jke-system                 node-exporter-lm4pq                                        0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  jke-system                 prometheus-6f5dfd9fcd-zxm4n                                0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                jdcloud-k8s-ipamd-9pz6x                                    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-proxy-89266                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource  Requests    Limits\n  --------  --------    ------\n  cpu       204m (5%)   204m (5%)\n  memory    138Mi (1%)  138Mi (1%)\nEvents:     <none>\n"
Mar 19 11:16:14.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 describe namespace e2e-tests-kubectl-stjh2'
Mar 19 11:16:14.706: INFO: stderr: ""
Mar 19 11:16:14.706: INFO: stdout: "Name:         e2e-tests-kubectl-stjh2\nLabels:       e2e-framework=kubectl\n              e2e-run=ba44dd46-4a2d-11e9-989b-da33bd6188b3\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:16:14.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-stjh2" for this suite.
Mar 19 11:16:36.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:16:36.754: INFO: namespace: e2e-tests-kubectl-stjh2, resource: bindings, ignored listing per whitelist
Mar 19 11:16:36.922: INFO: namespace e2e-tests-kubectl-stjh2 deletion completed in 22.208661098s

• [SLOW TEST:25.401 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:16:36.922: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 11:16:37.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 version'
Mar 19 11:16:37.095: INFO: stderr: ""
Mar 19 11:16:37.095: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12+\", GitVersion:\"v1.12.3-23.56f6f14\", GitCommit:\"56f6f141d48b68f7d812af96d25b248b9e4b3053\", GitTreeState:\"clean\", BuildDate:\"2019-02-20T02:00:35Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:16:37.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-n5zth" for this suite.
Mar 19 11:16:43.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:16:43.185: INFO: namespace: e2e-tests-kubectl-n5zth, resource: bindings, ignored listing per whitelist
Mar 19 11:16:43.307: INFO: namespace e2e-tests-kubectl-n5zth deletion completed in 6.201816167s

• [SLOW TEST:6.385 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:16:43.307: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 11:16:43.407: INFO: Waiting up to 5m0s for pod "downwardapi-volume-79d20502-4a38-11e9-989b-da33bd6188b3" in namespace "e2e-tests-downward-api-kq924" to be "success or failure"
Mar 19 11:16:43.412: INFO: Pod "downwardapi-volume-79d20502-4a38-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.878161ms
Mar 19 11:16:45.418: INFO: Pod "downwardapi-volume-79d20502-4a38-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010741249s
STEP: Saw pod success
Mar 19 11:16:45.418: INFO: Pod "downwardapi-volume-79d20502-4a38-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 11:16:45.423: INFO: Trying to get logs from node k8s-node-vm1y1w-lkllt8nnod pod downwardapi-volume-79d20502-4a38-11e9-989b-da33bd6188b3 container client-container: <nil>
STEP: delete the pod
Mar 19 11:16:45.459: INFO: Waiting for pod downwardapi-volume-79d20502-4a38-11e9-989b-da33bd6188b3 to disappear
Mar 19 11:16:45.464: INFO: Pod downwardapi-volume-79d20502-4a38-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:16:45.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kq924" for this suite.
Mar 19 11:16:51.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:16:51.516: INFO: namespace: e2e-tests-downward-api-kq924, resource: bindings, ignored listing per whitelist
Mar 19 11:16:51.681: INFO: namespace e2e-tests-downward-api-kq924 deletion completed in 6.207874934s

• [SLOW TEST:8.374 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:16:51.682: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-7ed18c0e-4a38-11e9-989b-da33bd6188b3
STEP: Creating secret with name s-test-opt-upd-7ed18c3d-4a38-11e9-989b-da33bd6188b3
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-7ed18c0e-4a38-11e9-989b-da33bd6188b3
STEP: Updating secret s-test-opt-upd-7ed18c3d-4a38-11e9-989b-da33bd6188b3
STEP: Creating secret with name s-test-opt-create-7ed18c4d-4a38-11e9-989b-da33bd6188b3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:16:55.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-ggh44" for this suite.
Mar 19 11:17:17.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:17:18.081: INFO: namespace: e2e-tests-secrets-ggh44, resource: bindings, ignored listing per whitelist
Mar 19 11:17:18.157: INFO: namespace e2e-tests-secrets-ggh44 deletion completed in 22.204538372s

• [SLOW TEST:26.476 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:17:18.157: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Mar 19 11:17:18.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 create -f - --namespace=e2e-tests-kubectl-z9zjp'
Mar 19 11:17:18.411: INFO: stderr: ""
Mar 19 11:17:18.411: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 19 11:17:18.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-z9zjp'
Mar 19 11:17:18.484: INFO: stderr: ""
Mar 19 11:17:18.484: INFO: stdout: "update-demo-nautilus-2p6ld update-demo-nautilus-46428 "
Mar 19 11:17:18.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods update-demo-nautilus-2p6ld -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-z9zjp'
Mar 19 11:17:18.562: INFO: stderr: ""
Mar 19 11:17:18.562: INFO: stdout: ""
Mar 19 11:17:18.562: INFO: update-demo-nautilus-2p6ld is created but not running
Mar 19 11:17:23.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-z9zjp'
Mar 19 11:17:23.634: INFO: stderr: ""
Mar 19 11:17:23.634: INFO: stdout: "update-demo-nautilus-2p6ld update-demo-nautilus-46428 "
Mar 19 11:17:23.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods update-demo-nautilus-2p6ld -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-z9zjp'
Mar 19 11:17:23.697: INFO: stderr: ""
Mar 19 11:17:23.697: INFO: stdout: "true"
Mar 19 11:17:23.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods update-demo-nautilus-2p6ld -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-z9zjp'
Mar 19 11:17:23.771: INFO: stderr: ""
Mar 19 11:17:23.771: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 19 11:17:23.771: INFO: validating pod update-demo-nautilus-2p6ld
Mar 19 11:17:23.780: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 19 11:17:23.780: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 19 11:17:23.780: INFO: update-demo-nautilus-2p6ld is verified up and running
Mar 19 11:17:23.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods update-demo-nautilus-46428 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-z9zjp'
Mar 19 11:17:23.844: INFO: stderr: ""
Mar 19 11:17:23.844: INFO: stdout: "true"
Mar 19 11:17:23.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods update-demo-nautilus-46428 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-z9zjp'
Mar 19 11:17:23.907: INFO: stderr: ""
Mar 19 11:17:23.907: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 19 11:17:23.907: INFO: validating pod update-demo-nautilus-46428
Mar 19 11:17:23.913: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 19 11:17:23.913: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 19 11:17:23.913: INFO: update-demo-nautilus-46428 is verified up and running
STEP: using delete to clean up resources
Mar 19 11:17:23.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-z9zjp'
Mar 19 11:17:23.999: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 19 11:17:23.999: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar 19 11:17:23.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-z9zjp'
Mar 19 11:17:24.087: INFO: stderr: "No resources found.\n"
Mar 19 11:17:24.087: INFO: stdout: ""
Mar 19 11:17:24.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-715664315 get pods -l name=update-demo --namespace=e2e-tests-kubectl-z9zjp -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 19 11:17:24.165: INFO: stderr: ""
Mar 19 11:17:24.165: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:17:24.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-z9zjp" for this suite.
Mar 19 11:17:46.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:17:46.249: INFO: namespace: e2e-tests-kubectl-z9zjp, resource: bindings, ignored listing per whitelist
Mar 19 11:17:46.377: INFO: namespace e2e-tests-kubectl-z9zjp deletion completed in 22.201609204s

• [SLOW TEST:28.220 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:17:46.377: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 11:17:46.476: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9f69914e-4a38-11e9-989b-da33bd6188b3" in namespace "e2e-tests-downward-api-gq982" to be "success or failure"
Mar 19 11:17:46.481: INFO: Pod "downwardapi-volume-9f69914e-4a38-11e9-989b-da33bd6188b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.846314ms
Mar 19 11:17:48.487: INFO: Pod "downwardapi-volume-9f69914e-4a38-11e9-989b-da33bd6188b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010844857s
STEP: Saw pod success
Mar 19 11:17:48.487: INFO: Pod "downwardapi-volume-9f69914e-4a38-11e9-989b-da33bd6188b3" satisfied condition "success or failure"
Mar 19 11:17:48.491: INFO: Trying to get logs from node k8s-node-vmepd8-lkllt8nnod pod downwardapi-volume-9f69914e-4a38-11e9-989b-da33bd6188b3 container client-container: <nil>
STEP: delete the pod
Mar 19 11:17:48.526: INFO: Waiting for pod downwardapi-volume-9f69914e-4a38-11e9-989b-da33bd6188b3 to disappear
Mar 19 11:17:48.531: INFO: Pod downwardapi-volume-9f69914e-4a38-11e9-989b-da33bd6188b3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:17:48.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-gq982" for this suite.
Mar 19 11:17:54.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:17:54.662: INFO: namespace: e2e-tests-downward-api-gq982, resource: bindings, ignored listing per whitelist
Mar 19 11:17:54.757: INFO: namespace e2e-tests-downward-api-gq982 deletion completed in 6.216392618s

• [SLOW TEST:8.380 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:17:54.757: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-a468d121-4a38-11e9-989b-da33bd6188b3
STEP: Creating configMap with name cm-test-opt-upd-a468d1d4-4a38-11e9-989b-da33bd6188b3
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-a468d121-4a38-11e9-989b-da33bd6188b3
STEP: Updating configmap cm-test-opt-upd-a468d1d4-4a38-11e9-989b-da33bd6188b3
STEP: Creating configMap with name cm-test-opt-create-a468d1ee-4a38-11e9-989b-da33bd6188b3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:17:59.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tqtd5" for this suite.
Mar 19 11:18:21.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:18:21.219: INFO: namespace: e2e-tests-projected-tqtd5, resource: bindings, ignored listing per whitelist
Mar 19 11:18:21.253: INFO: namespace e2e-tests-projected-tqtd5 deletion completed in 22.20574246s

• [SLOW TEST:26.496 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 19 11:18:21.253: INFO: >>> kubeConfig: /tmp/kubeconfig-715664315
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-b434d3b1-4a38-11e9-989b-da33bd6188b3
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-b434d3b1-4a38-11e9-989b-da33bd6188b3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 19 11:19:50.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-j6qqx" for this suite.
Mar 19 11:20:12.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 11:20:12.298: INFO: namespace: e2e-tests-configmap-j6qqx, resource: bindings, ignored listing per whitelist
Mar 19 11:20:12.466: INFO: namespace e2e-tests-configmap-j6qqx deletion completed in 22.208801243s

• [SLOW TEST:111.213 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSMar 19 11:20:12.467: INFO: Running AfterSuite actions on all node
Mar 19 11:20:12.467: INFO: Running AfterSuite actions on node 1
Mar 19 11:20:12.467: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 4824.904 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 1h20m25.523270922s
Test Suite Passed
