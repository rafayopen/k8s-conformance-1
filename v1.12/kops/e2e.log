Client Version: version.Info{Major:"1", Minor:"12", GitVersion:"v1.12.0", GitCommit:"0ed33881dc4355495f623c6f22e7dd0b7632b7c0", GitTreeState:"clean", BuildDate:"2019-03-27T00:13:01Z", GoVersion:"go1.12.1", Compiler:"gc", Platform:"linux/amd64"}
Server Version: version.Info{Major:"1", Minor:"12", GitVersion:"v1.12.7", GitCommit:"6f482974b76db3f1e0f5d24605a9d1d38fad9a2b", GitTreeState:"clean", BuildDate:"2019-03-25T02:41:57Z", GoVersion:"go1.10.8", Compiler:"gc", Platform:"linux/amd64"}
Conformance test: not doing test setup.
Mar 26 21:50:22.780: INFO: Overriding default scale value of zero to 1
Mar 26 21:50:22.780: INFO: Overriding default milliseconds value of zero to 5000
I0326 21:50:23.045453    2026 e2e.go:304] Starting e2e run "af136a82-5032-11e9-9bdd-d050998677c2" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: [1m1553651422[0m - Will randomize all specs
Will run [1m189[0m of [1m1813[0m specs

Mar 26 21:50:23.071: INFO: >>> kubeConfig: /home/justinsb/.kube/config
Mar 26 21:50:23.074: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Mar 26 21:50:23.232: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Mar 26 21:50:23.358: INFO: 12 / 12 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Mar 26 21:50:23.358: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Mar 26 21:50:23.358: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Mar 26 21:50:23.389: INFO: e2e test version: v1.12.0
Mar 26 21:50:23.413: INFO: kube-apiserver version: v1.12.7
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Networking[0m [90mGranular Checks: Pods[0m 
  [1mshould function for node-pod communication: http [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-network] Networking
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 21:50:23.414: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename pod-network-test
Mar 26 21:50:24.249: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Performing setup for networking test in namespace e2e-tests-pod-network-test-9trd9
[1mSTEP[0m: creating a selector
[1mSTEP[0m: Creating the service pods in kubernetes
Mar 26 21:50:24.274: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[1mSTEP[0m: Creating test pods
Mar 26 21:50:44.730: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://100.96.2.21:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-9trd9 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 21:50:44.730: INFO: >>> kubeConfig: /home/justinsb/.kube/config
Mar 26 21:50:45.034: INFO: Found all expected endpoints: [netserver-0]
Mar 26 21:50:45.060: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://100.96.1.81:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-9trd9 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 21:50:45.060: INFO: >>> kubeConfig: /home/justinsb/.kube/config
Mar 26 21:50:45.358: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 21:50:45.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pod-network-test-9trd9" for this suite.
Mar 26 21:51:07.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 21:51:08.183: INFO: namespace: e2e-tests-pod-network-test-9trd9, resource: bindings, ignored listing per whitelist
Mar 26 21:51:08.466: INFO: namespace e2e-tests-pod-network-test-9trd9 deletion completed in 23.071993546s

[32mâ€¢ [SLOW TEST:45.052 seconds][0m
[sig-network] Networking
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25[0m
  Granular Checks: Pods
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28[0m
    should function for node-pod communication: http [NodeConformance] [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Secrets[0m 
  [1mshould be consumable from pods in env vars [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Secrets
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 21:51:08.466: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating secret with name secret-test-cad46b9e-5032-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume secrets
Mar 26 21:51:09.357: INFO: Waiting up to 5m0s for pod "pod-secrets-cad8674d-5032-11e9-9bdd-d050998677c2" in namespace "e2e-tests-secrets-tpphj" to be "success or failure"
Mar 26 21:51:09.383: INFO: Pod "pod-secrets-cad8674d-5032-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 26.022315ms
Mar 26 21:51:11.409: INFO: Pod "pod-secrets-cad8674d-5032-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.052209942s
[1mSTEP[0m: Saw pod success
Mar 26 21:51:11.409: INFO: Pod "pod-secrets-cad8674d-5032-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 21:51:11.435: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-secrets-cad8674d-5032-11e9-9bdd-d050998677c2 container secret-env-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 21:51:11.496: INFO: Waiting for pod pod-secrets-cad8674d-5032-11e9-9bdd-d050998677c2 to disappear
Mar 26 21:51:11.521: INFO: Pod pod-secrets-cad8674d-5032-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 21:51:11.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-secrets-tpphj" for this suite.
Mar 26 21:51:17.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 21:51:18.559: INFO: namespace: e2e-tests-secrets-tpphj, resource: bindings, ignored listing per whitelist
Mar 26 21:51:18.637: INFO: namespace e2e-tests-secrets-tpphj deletion completed in 7.089302516s

[32mâ€¢ [SLOW TEST:10.172 seconds][0m
[sig-api-machinery] Secrets
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31[0m
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 21:51:18.638: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating projection with secret that has name projected-secret-test-d0f74d88-5032-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume secrets
Mar 26 21:51:19.651: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d0fb660a-5032-11e9-9bdd-d050998677c2" in namespace "e2e-tests-projected-w9blw" to be "success or failure"
Mar 26 21:51:19.677: INFO: Pod "pod-projected-secrets-d0fb660a-5032-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.725288ms
Mar 26 21:51:21.706: INFO: Pod "pod-projected-secrets-d0fb660a-5032-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.054549376s
[1mSTEP[0m: Saw pod success
Mar 26 21:51:21.706: INFO: Pod "pod-projected-secrets-d0fb660a-5032-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 21:51:21.732: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-projected-secrets-d0fb660a-5032-11e9-9bdd-d050998677c2 container projected-secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 21:51:21.795: INFO: Waiting for pod pod-projected-secrets-d0fb660a-5032-11e9-9bdd-d050998677c2 to disappear
Mar 26 21:51:21.821: INFO: Pod pod-projected-secrets-d0fb660a-5032-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 21:51:21.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-w9blw" for this suite.
Mar 26 21:51:27.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 21:51:28.696: INFO: namespace: e2e-tests-projected-w9blw, resource: bindings, ignored listing per whitelist
Mar 26 21:51:28.873: INFO: namespace e2e-tests-projected-w9blw deletion completed in 7.025830111s

[32mâ€¢ [SLOW TEST:10.236 seconds][0m
[sig-storage] Projected
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35[0m
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould be updated [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Pods
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 21:51:28.874: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating the pod
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: verifying the pod is in kubernetes
[1mSTEP[0m: updating the pod
Mar 26 21:51:32.409: INFO: Successfully updated pod "pod-update-d70069b3-5032-11e9-9bdd-d050998677c2"
[1mSTEP[0m: verifying the updated pod is in kubernetes
Mar 26 21:51:32.461: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 21:51:32.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pods-xrcks" for this suite.
Mar 26 21:51:54.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 21:51:55.455: INFO: namespace: e2e-tests-pods-xrcks, resource: bindings, ignored listing per whitelist
Mar 26 21:51:55.532: INFO: namespace e2e-tests-pods-xrcks deletion completed in 23.044241135s

[32mâ€¢ [SLOW TEST:26.658 seconds][0m
[k8s.io] Pods
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should be updated [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Daemon set [Serial][0m 
  [1mshould update pod when spec was updated and update strategy is RollingUpdate [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] Daemon set [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 21:51:55.532: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename daemonsets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 21:51:56.465: INFO: Creating simple daemon set daemon-set
[1mSTEP[0m: Check that daemon pods launch on every node of the cluster.
Mar 26 21:51:56.529: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:51:56.555: INFO: Number of nodes with available pods: 0
Mar 26 21:51:56.555: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:51:57.582: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:51:57.609: INFO: Number of nodes with available pods: 0
Mar 26 21:51:57.609: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:51:58.582: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:51:58.608: INFO: Number of nodes with available pods: 2
Mar 26 21:51:58.608: INFO: Number of running nodes: 2, number of available pods: 2
[1mSTEP[0m: Update daemon pods image.
[1mSTEP[0m: Check that daemon pods images are updated.
Mar 26 21:51:58.774: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:51:58.774: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:51:58.801: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:51:59.828: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:51:59.828: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:51:59.854: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:00.827: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:00.827: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:00.854: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:01.828: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:01.828: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:01.855: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:02.827: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:02.827: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:02.855: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:03.837: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:03.837: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:03.875: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:04.828: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:04.828: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:04.854: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:05.827: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:05.827: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:05.854: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:06.828: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:06.828: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:06.855: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:07.827: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:07.827: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:07.858: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:08.827: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:08.827: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:08.853: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:09.831: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:09.831: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:09.860: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:10.828: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:10.828: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:10.855: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:11.827: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:11.827: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:11.854: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:12.827: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:12.827: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:12.853: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:13.827: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:13.827: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:13.854: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:14.828: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:14.828: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:14.855: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:15.829: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:15.829: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:15.858: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:16.828: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:16.828: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:16.862: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:17.827: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:17.827: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:17.854: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:18.828: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:18.828: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:18.855: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:19.827: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:19.827: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:19.854: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:20.827: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:20.827: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:20.853: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:21.832: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:21.832: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:21.858: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:22.828: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:22.828: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:22.855: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:23.828: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:23.828: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:23.855: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:24.827: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:24.827: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:24.854: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:25.827: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:25.827: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:25.854: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:26.827: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:26.827: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:26.854: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:27.830: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:27.830: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:27.856: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:28.827: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:28.827: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:28.854: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:29.835: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:29.835: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:29.862: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:30.827: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:30.827: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:30.859: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:31.827: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:31.827: INFO: Pod daemon-set-8q9xj is not available
Mar 26 21:52:31.827: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:31.855: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:32.829: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:32.829: INFO: Pod daemon-set-8q9xj is not available
Mar 26 21:52:32.829: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:32.856: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:33.827: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:33.827: INFO: Pod daemon-set-8q9xj is not available
Mar 26 21:52:33.827: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:33.853: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:34.828: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:34.828: INFO: Pod daemon-set-8q9xj is not available
Mar 26 21:52:34.828: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:34.855: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:35.827: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:35.827: INFO: Pod daemon-set-8q9xj is not available
Mar 26 21:52:35.827: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:35.854: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:36.827: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:36.827: INFO: Pod daemon-set-8q9xj is not available
Mar 26 21:52:36.827: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:36.857: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:37.832: INFO: Wrong image for pod: daemon-set-8q9xj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:37.832: INFO: Pod daemon-set-8q9xj is not available
Mar 26 21:52:37.832: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:37.865: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:38.828: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:38.828: INFO: Pod daemon-set-kt8kc is not available
Mar 26 21:52:38.854: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:39.827: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:39.854: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:40.827: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:40.853: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:41.827: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:41.854: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:42.828: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:42.855: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:43.832: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:43.859: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:44.828: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:44.854: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:45.834: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:45.860: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:46.831: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:46.860: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:47.827: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:47.854: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:48.828: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:48.855: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:49.827: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:49.854: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:50.828: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:50.855: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:51.827: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:51.854: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:52.831: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:52.857: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:53.827: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:53.854: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:54.828: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:54.854: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:55.827: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:55.853: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:56.828: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:56.855: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:57.827: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:57.854: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:58.828: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:58.855: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:52:59.830: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:52:59.857: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:53:00.837: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:53:00.882: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:53:01.839: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:53:01.880: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:53:02.832: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:53:02.859: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:53:03.828: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:53:03.854: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:53:04.828: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:53:04.855: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:53:05.827: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:53:05.854: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:53:06.828: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:53:06.857: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:53:07.832: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:53:07.858: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:53:08.833: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:53:08.861: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:53:09.828: INFO: Wrong image for pod: daemon-set-gfg2n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 21:53:09.828: INFO: Pod daemon-set-gfg2n is not available
Mar 26 21:53:09.855: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:53:10.828: INFO: Pod daemon-set-77j7v is not available
Mar 26 21:53:10.855: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[1mSTEP[0m: Check that daemon pods are still running on every node of the cluster.
Mar 26 21:53:10.882: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:53:10.908: INFO: Number of nodes with available pods: 1
Mar 26 21:53:10.908: INFO: Node ip-172-20-56-226.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:53:11.935: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 21:53:11.963: INFO: Number of nodes with available pods: 2
Mar 26 21:53:11.963: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
[1mSTEP[0m: Deleting DaemonSet "daemon-set"
[1mSTEP[0m: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-htcc8, will wait for the garbage collector to delete the pods
Mar 26 21:53:12.212: INFO: Deleting {extensions DaemonSet} daemon-set took: 28.513579ms
Mar 26 21:53:12.312: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.252415ms
Mar 26 21:53:20.638: INFO: Number of nodes with available pods: 0
Mar 26 21:53:20.638: INFO: Number of running nodes: 0, number of available pods: 0
Mar 26 21:53:20.663: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-htcc8/daemonsets","resourceVersion":"15348"},"items":null}

Mar 26 21:53:20.689: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-htcc8/pods","resourceVersion":"15348"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 21:53:20.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-daemonsets-htcc8" for this suite.
Mar 26 21:53:26.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 21:53:27.950: INFO: namespace: e2e-tests-daemonsets-htcc8, resource: bindings, ignored listing per whitelist
Mar 26 21:53:28.085: INFO: namespace e2e-tests-daemonsets-htcc8 deletion completed in 7.290109374s

[32mâ€¢ [SLOW TEST:92.552 seconds][0m
[sig-apps] Daemon set [Serial]
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl expose[0m 
  [1mshould create services for rc  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 21:53:28.085: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating Redis RC
Mar 26 21:53:28.968: INFO: namespace e2e-tests-kubectl-pcvgf
Mar 26 21:53:28.968: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config create -f - --namespace=e2e-tests-kubectl-pcvgf'
Mar 26 21:53:31.059: INFO: stderr: ""
Mar 26 21:53:31.059: INFO: stdout: "replicationcontroller/redis-master created\n"
[1mSTEP[0m: Waiting for Redis master to start.
Mar 26 21:53:32.086: INFO: Selector matched 1 pods for map[app:redis]
Mar 26 21:53:32.086: INFO: Found 0 / 1
Mar 26 21:53:33.086: INFO: Selector matched 1 pods for map[app:redis]
Mar 26 21:53:33.086: INFO: Found 1 / 1
Mar 26 21:53:33.086: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 26 21:53:33.112: INFO: Selector matched 1 pods for map[app:redis]
Mar 26 21:53:33.112: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 26 21:53:33.112: INFO: wait on redis-master startup in e2e-tests-kubectl-pcvgf 
Mar 26 21:53:33.112: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config logs redis-master-jtfpl redis-master --namespace=e2e-tests-kubectl-pcvgf'
Mar 26 21:53:33.405: INFO: stderr: ""
Mar 26 21:53:33.405: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 27 Mar 01:53:31.845 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 27 Mar 01:53:31.845 # Server started, Redis version 3.2.12\n1:M 27 Mar 01:53:31.845 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 27 Mar 01:53:31.845 * The server is now ready to accept connections on port 6379\n"
[1mSTEP[0m: exposing RC
Mar 26 21:53:33.405: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-pcvgf'
Mar 26 21:53:33.698: INFO: stderr: ""
Mar 26 21:53:33.698: INFO: stdout: "service/rm2 exposed\n"
Mar 26 21:53:33.724: INFO: Service rm2 in namespace e2e-tests-kubectl-pcvgf found.
[1mSTEP[0m: exposing service
Mar 26 21:53:35.778: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-pcvgf'
Mar 26 21:53:36.072: INFO: stderr: ""
Mar 26 21:53:36.072: INFO: stdout: "service/rm3 exposed\n"
Mar 26 21:53:36.098: INFO: Service rm3 in namespace e2e-tests-kubectl-pcvgf found.
[AfterEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 21:53:38.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-pcvgf" for this suite.
Mar 26 21:54:00.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 21:54:00.947: INFO: namespace: e2e-tests-kubectl-pcvgf, resource: bindings, ignored listing per whitelist
Mar 26 21:54:01.512: INFO: namespace e2e-tests-kubectl-pcvgf deletion completed in 23.33331986s

[32mâ€¢ [SLOW TEST:33.427 seconds][0m
[sig-cli] Kubectl client
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl expose
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should create services for rc  [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (non-root,0644,default) [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 21:54:01.512: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test emptydir 0644 on node default medium
Mar 26 21:54:02.494: INFO: Waiting up to 5m0s for pod "pod-320b28c5-5033-11e9-9bdd-d050998677c2" in namespace "e2e-tests-emptydir-hlkbh" to be "success or failure"
Mar 26 21:54:02.520: INFO: Pod "pod-320b28c5-5033-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.939945ms
Mar 26 21:54:04.548: INFO: Pod "pod-320b28c5-5033-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.054030866s
[1mSTEP[0m: Saw pod success
Mar 26 21:54:04.548: INFO: Pod "pod-320b28c5-5033-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 21:54:04.575: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-320b28c5-5033-11e9-9bdd-d050998677c2 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 21:54:04.639: INFO: Waiting for pod pod-320b28c5-5033-11e9-9bdd-d050998677c2 to disappear
Mar 26 21:54:04.665: INFO: Pod pod-320b28c5-5033-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 21:54:04.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-hlkbh" for this suite.
Mar 26 21:54:10.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 21:54:11.027: INFO: namespace: e2e-tests-emptydir-hlkbh, resource: bindings, ignored listing per whitelist
Mar 26 21:54:11.728: INFO: namespace e2e-tests-emptydir-hlkbh deletion completed in 7.036747068s

[32mâ€¢ [SLOW TEST:10.216 seconds][0m
[sig-storage] EmptyDir volumes
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 21:54:11.728: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename gc
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: create the rc1
[1mSTEP[0m: create the rc2
[1mSTEP[0m: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
[1mSTEP[0m: delete the rc simpletest-rc-to-be-deleted
[1mSTEP[0m: wait for the rc to be deleted
[1mSTEP[0m: Gathering metrics
W0326 21:54:22.984338    2026 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 26 21:54:22.984: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 21:54:22.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-gc-x5l9p" for this suite.
Mar 26 21:54:29.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 21:54:29.580: INFO: namespace: e2e-tests-gc-x5l9p, resource: bindings, ignored listing per whitelist
Mar 26 21:54:30.457: INFO: namespace e2e-tests-gc-x5l9p deletion completed in 7.446280196s

[32mâ€¢ [SLOW TEST:18.729 seconds][0m
[sig-api-machinery] Garbage collector
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable from pods in volume with mappings [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] ConfigMap
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 21:54:30.457: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name configmap-test-volume-map-433a4297-5033-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 26 21:54:31.349: INFO: Waiting up to 5m0s for pod "pod-configmaps-433e5054-5033-11e9-9bdd-d050998677c2" in namespace "e2e-tests-configmap-hrl47" to be "success or failure"
Mar 26 21:54:31.375: INFO: Pod "pod-configmaps-433e5054-5033-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.605302ms
Mar 26 21:54:33.402: INFO: Pod "pod-configmaps-433e5054-5033-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.053008772s
[1mSTEP[0m: Saw pod success
Mar 26 21:54:33.402: INFO: Pod "pod-configmaps-433e5054-5033-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 21:54:33.432: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-configmaps-433e5054-5033-11e9-9bdd-d050998677c2 container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 21:54:33.499: INFO: Waiting for pod pod-configmaps-433e5054-5033-11e9-9bdd-d050998677c2 to disappear
Mar 26 21:54:33.525: INFO: Pod pod-configmaps-433e5054-5033-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 21:54:33.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-hrl47" for this suite.
Mar 26 21:54:39.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 21:54:40.395: INFO: namespace: e2e-tests-configmap-hrl47, resource: bindings, ignored listing per whitelist
Mar 26 21:54:40.660: INFO: namespace e2e-tests-configmap-hrl47 deletion completed in 7.107538695s

[32mâ€¢ [SLOW TEST:10.203 seconds][0m
[sig-storage] ConfigMap
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33[0m
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-auth] ServiceAccounts[0m 
  [1mshould allow opting out of API token automount  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-auth] ServiceAccounts
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 21:54:40.661: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename svcaccounts
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: getting the auto-created API token
Mar 26 21:54:42.316: INFO: created pod pod-service-account-defaultsa
Mar 26 21:54:42.316: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Mar 26 21:54:42.343: INFO: created pod pod-service-account-mountsa
Mar 26 21:54:42.343: INFO: pod pod-service-account-mountsa service account token volume mount: true
Mar 26 21:54:42.369: INFO: created pod pod-service-account-nomountsa
Mar 26 21:54:42.369: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Mar 26 21:54:42.399: INFO: created pod pod-service-account-defaultsa-mountspec
Mar 26 21:54:42.399: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Mar 26 21:54:42.431: INFO: created pod pod-service-account-mountsa-mountspec
Mar 26 21:54:42.431: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Mar 26 21:54:42.460: INFO: created pod pod-service-account-nomountsa-mountspec
Mar 26 21:54:42.460: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Mar 26 21:54:42.491: INFO: created pod pod-service-account-defaultsa-nomountspec
Mar 26 21:54:42.491: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Mar 26 21:54:42.522: INFO: created pod pod-service-account-mountsa-nomountspec
Mar 26 21:54:42.522: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Mar 26 21:54:42.557: INFO: created pod pod-service-account-nomountsa-nomountspec
Mar 26 21:54:42.557: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 21:54:42.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-svcaccounts-4pgdc" for this suite.
Mar 26 21:54:48.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 21:54:49.551: INFO: namespace: e2e-tests-svcaccounts-4pgdc, resource: bindings, ignored listing per whitelist
Mar 26 21:54:49.653: INFO: namespace e2e-tests-svcaccounts-4pgdc deletion completed in 7.061947021s

[32mâ€¢ [SLOW TEST:8.993 seconds][0m
[sig-auth] ServiceAccounts
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22[0m
  should allow opting out of API token automount  [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Deployment[0m 
  [1mRollingUpdateDeployment should delete old pods and create new ones [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] Deployment
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 21:54:49.653: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename deployment
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 21:54:50.622: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Mar 26 21:54:50.676: INFO: Pod name sample-pod: Found 1 pods out of 1
[1mSTEP[0m: ensuring each pod is running
Mar 26 21:54:52.731: INFO: Creating deployment "test-rolling-update-deployment"
Mar 26 21:54:52.759: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Mar 26 21:54:52.822: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Mar 26 21:54:52.852: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689248492, loc:(*time.Location)(0x835fd00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689248492, loc:(*time.Location)(0x835fd00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689248492, loc:(*time.Location)(0x835fd00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689248492, loc:(*time.Location)(0x835fd00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 26 21:54:54.893: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 26 21:54:54.991: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-4k5mq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4k5mq/deployments/test-rolling-update-deployment,UID:50036cc8-5033-11e9-8eb3-023bf32bf132,ResourceVersion:15763,Generation:1,CreationTimestamp:2019-03-26 21:54:52 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-26 21:54:52 -0400 EDT 2019-03-26 21:54:52 -0400 EDT MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-26 21:54:54 -0400 EDT 2019-03-26 21:54:52 -0400 EDT NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar 26 21:54:55.017: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-4k5mq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4k5mq/replicasets/test-rolling-update-deployment-65b7695dcf,UID:50053a1f-5033-11e9-8eb3-023bf32bf132,ResourceVersion:15756,Generation:1,CreationTimestamp:2019-03-26 21:54:52 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 50036cc8-5033-11e9-8eb3-023bf32bf132 0xc0020ded27 0xc0020ded28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 26 21:54:55.017: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Mar 26 21:54:55.018: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-4k5mq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4k5mq/replicasets/test-rolling-update-controller,UID:4ec19404-5033-11e9-8eb3-023bf32bf132,ResourceVersion:15762,Generation:2,CreationTimestamp:2019-03-26 21:54:50 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 50036cc8-5033-11e9-8eb3-023bf32bf132 0xc0020dec67 0xc0020dec68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 26 21:54:55.044: INFO: Pod "test-rolling-update-deployment-65b7695dcf-m44g4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-m44g4,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-4k5mq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4k5mq/pods/test-rolling-update-deployment-65b7695dcf-m44g4,UID:5005eb49-5033-11e9-8eb3-023bf32bf132,ResourceVersion:15755,Generation:0,CreationTimestamp:2019-03-26 21:54:52 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf 50053a1f-5033-11e9-8eb3-023bf32bf132 0xc00209bd67 0xc00209bd68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zcn8v {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zcn8v,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-zcn8v true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-56-226.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00209bdd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00209bdf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 21:54:52 -0400 EDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 21:54:54 -0400 EDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 21:54:54 -0400 EDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 21:54:52 -0400 EDT  }],Message:,Reason:,HostIP:172.20.56.226,PodIP:100.96.2.49,StartTime:2019-03-26 21:54:52 -0400 EDT,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-26 21:54:53 -0400 EDT,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://6020f126d6340ca9410ff3bdcc346f3b7868035819e05a9f406302babe1cc905}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 21:54:55.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-deployment-4k5mq" for this suite.
Mar 26 21:55:01.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 21:55:01.705: INFO: namespace: e2e-tests-deployment-4k5mq, resource: bindings, ignored listing per whitelist
Mar 26 21:55:02.346: INFO: namespace e2e-tests-deployment-4k5mq deletion completed in 7.274954728s

[32mâ€¢ [SLOW TEST:12.693 seconds][0m
[sig-apps] Deployment
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (root,0777,tmpfs) [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 21:55:02.347: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test emptydir 0777 on tmpfs
Mar 26 21:55:03.836: INFO: Waiting up to 5m0s for pod "pod-5697d043-5033-11e9-9bdd-d050998677c2" in namespace "e2e-tests-emptydir-n69mj" to be "success or failure"
Mar 26 21:55:03.882: INFO: Pod "pod-5697d043-5033-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 46.070046ms
Mar 26 21:55:05.916: INFO: Pod "pod-5697d043-5033-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.080468827s
[1mSTEP[0m: Saw pod success
Mar 26 21:55:05.916: INFO: Pod "pod-5697d043-5033-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 21:55:05.958: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-5697d043-5033-11e9-9bdd-d050998677c2 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 21:55:06.055: INFO: Waiting for pod pod-5697d043-5033-11e9-9bdd-d050998677c2 to disappear
Mar 26 21:55:06.109: INFO: Pod pod-5697d043-5033-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 21:55:06.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-n69mj" for this suite.
Mar 26 21:55:12.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 21:55:13.104: INFO: namespace: e2e-tests-emptydir-n69mj, resource: bindings, ignored listing per whitelist
Mar 26 21:55:13.901: INFO: namespace e2e-tests-emptydir-n69mj deletion completed in 7.742554512s

[32mâ€¢ [SLOW TEST:11.554 seconds][0m
[sig-storage] EmptyDir volumes
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] ReplicationController[0m 
  [1mshould serve a basic image on each replica with a public image  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] ReplicationController
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 21:55:13.901: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename replication-controller
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating replication controller my-hostname-basic-5d7131cb-5033-11e9-9bdd-d050998677c2
Mar 26 21:55:15.353: INFO: Pod name my-hostname-basic-5d7131cb-5033-11e9-9bdd-d050998677c2: Found 1 pods out of 1
Mar 26 21:55:15.353: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-5d7131cb-5033-11e9-9bdd-d050998677c2" are running
Mar 26 21:55:17.416: INFO: Pod "my-hostname-basic-5d7131cb-5033-11e9-9bdd-d050998677c2-g6fdm" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-26 21:55:15 -0400 EDT Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-26 21:55:15 -0400 EDT Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-5d7131cb-5033-11e9-9bdd-d050998677c2]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-26 21:55:15 -0400 EDT Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-5d7131cb-5033-11e9-9bdd-d050998677c2]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-26 21:55:15 -0400 EDT Reason: Message:}])
Mar 26 21:55:17.416: INFO: Trying to dial the pod
Mar 26 21:55:22.566: INFO: Controller my-hostname-basic-5d7131cb-5033-11e9-9bdd-d050998677c2: Got expected result from replica 1 [my-hostname-basic-5d7131cb-5033-11e9-9bdd-d050998677c2-g6fdm]: "my-hostname-basic-5d7131cb-5033-11e9-9bdd-d050998677c2-g6fdm", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 21:55:22.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-replication-controller-2th2k" for this suite.
Mar 26 21:55:28.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 21:55:28.788: INFO: namespace: e2e-tests-replication-controller-2th2k, resource: bindings, ignored listing per whitelist
Mar 26 21:55:29.965: INFO: namespace e2e-tests-replication-controller-2th2k deletion completed in 7.3640775s

[32mâ€¢ [SLOW TEST:16.064 seconds][0m
[sig-apps] ReplicationController
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  should serve a basic image on each replica with a public image  [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mvolume on tmpfs should have the correct mode [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 21:55:29.966: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test emptydir volume type on tmpfs
Mar 26 21:55:31.220: INFO: Waiting up to 5m0s for pod "pod-66edada0-5033-11e9-9bdd-d050998677c2" in namespace "e2e-tests-emptydir-xr6n7" to be "success or failure"
Mar 26 21:55:31.246: INFO: Pod "pod-66edada0-5033-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.864394ms
Mar 26 21:55:33.275: INFO: Pod "pod-66edada0-5033-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.055422972s
[1mSTEP[0m: Saw pod success
Mar 26 21:55:33.275: INFO: Pod "pod-66edada0-5033-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 21:55:33.301: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-66edada0-5033-11e9-9bdd-d050998677c2 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 21:55:33.368: INFO: Waiting for pod pod-66edada0-5033-11e9-9bdd-d050998677c2 to disappear
Mar 26 21:55:33.395: INFO: Pod pod-66edada0-5033-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 21:55:33.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-xr6n7" for this suite.
Mar 26 21:55:39.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 21:55:40.540: INFO: namespace: e2e-tests-emptydir-xr6n7, resource: bindings, ignored listing per whitelist
Mar 26 21:55:40.591: INFO: namespace e2e-tests-emptydir-xr6n7 deletion completed in 7.16835182s

[32mâ€¢ [SLOW TEST:10.625 seconds][0m
[sig-storage] EmptyDir volumes
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mshould be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Probing container
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 21:55:40.591: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename container-probe
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating pod liveness-exec in namespace e2e-tests-container-probe-nzd68
Mar 26 21:55:43.761: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-nzd68
[1mSTEP[0m: checking the pod's current state and verifying that restartCount is present
Mar 26 21:55:43.796: INFO: Initial restart count of pod liveness-exec is 0
Mar 26 21:56:34.666: INFO: Restart count of pod e2e-tests-container-probe-nzd68/liveness-exec is now 1 (50.869437909s elapsed)
[1mSTEP[0m: deleting the pod
[AfterEach] [k8s.io] Probing container
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 21:56:34.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-container-probe-nzd68" for this suite.
Mar 26 21:56:40.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 21:56:41.665: INFO: namespace: e2e-tests-container-probe-nzd68, resource: bindings, ignored listing per whitelist
Mar 26 21:56:41.772: INFO: namespace e2e-tests-container-probe-nzd68 deletion completed in 7.049779938s

[32mâ€¢ [SLOW TEST:61.181 seconds][0m
[k8s.io] Probing container
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Downward API[0m 
  [1mshould provide pod UID as env vars [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Downward API
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 21:56:41.772: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward api env vars
Mar 26 21:56:42.762: INFO: Waiting up to 5m0s for pod "downward-api-919241f1-5033-11e9-9bdd-d050998677c2" in namespace "e2e-tests-downward-api-b2gm9" to be "success or failure"
Mar 26 21:56:42.788: INFO: Pod "downward-api-919241f1-5033-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.826637ms
Mar 26 21:56:44.815: INFO: Pod "downward-api-919241f1-5033-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.052406477s
[1mSTEP[0m: Saw pod success
Mar 26 21:56:44.815: INFO: Pod "downward-api-919241f1-5033-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 21:56:44.842: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod downward-api-919241f1-5033-11e9-9bdd-d050998677c2 container dapi-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 21:56:44.906: INFO: Waiting for pod downward-api-919241f1-5033-11e9-9bdd-d050998677c2 to disappear
Mar 26 21:56:44.932: INFO: Pod downward-api-919241f1-5033-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 21:56:44.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-b2gm9" for this suite.
Mar 26 21:56:51.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 21:56:51.504: INFO: namespace: e2e-tests-downward-api-b2gm9, resource: bindings, ignored listing per whitelist
Mar 26 21:56:51.993: INFO: namespace e2e-tests-downward-api-b2gm9 deletion completed in 7.034512466s

[32mâ€¢ [SLOW TEST:10.221 seconds][0m
[sig-api-machinery] Downward API
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38[0m
  should provide pod UID as env vars [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Daemon set [Serial][0m 
  [1mshould run and stop complex daemon [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] Daemon set [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 21:56:51.994: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename daemonsets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 21:56:53.003: INFO: Creating daemon "daemon-set" with a node selector
[1mSTEP[0m: Initially, daemon pods should not be running on any nodes.
Mar 26 21:56:53.056: INFO: Number of nodes with available pods: 0
Mar 26 21:56:53.056: INFO: Number of running nodes: 0, number of available pods: 0
[1mSTEP[0m: Change node label to blue, check that daemon pod is launched.
Mar 26 21:56:53.165: INFO: Number of nodes with available pods: 0
Mar 26 21:56:53.165: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:56:54.191: INFO: Number of nodes with available pods: 1
Mar 26 21:56:54.191: INFO: Number of running nodes: 1, number of available pods: 1
[1mSTEP[0m: Update the node label to green, and wait for daemons to be unscheduled
Mar 26 21:56:54.296: INFO: Number of nodes with available pods: 0
Mar 26 21:56:54.296: INFO: Number of running nodes: 0, number of available pods: 0
[1mSTEP[0m: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Mar 26 21:56:54.350: INFO: Number of nodes with available pods: 0
Mar 26 21:56:54.350: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:56:55.376: INFO: Number of nodes with available pods: 0
Mar 26 21:56:55.376: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:56:56.376: INFO: Number of nodes with available pods: 0
Mar 26 21:56:56.376: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:56:57.376: INFO: Number of nodes with available pods: 0
Mar 26 21:56:57.376: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:56:58.376: INFO: Number of nodes with available pods: 0
Mar 26 21:56:58.376: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:56:59.377: INFO: Number of nodes with available pods: 0
Mar 26 21:56:59.377: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:57:00.376: INFO: Number of nodes with available pods: 0
Mar 26 21:57:00.376: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:57:01.376: INFO: Number of nodes with available pods: 0
Mar 26 21:57:01.376: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:57:02.376: INFO: Number of nodes with available pods: 0
Mar 26 21:57:02.376: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:57:03.384: INFO: Number of nodes with available pods: 0
Mar 26 21:57:03.384: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:57:04.376: INFO: Number of nodes with available pods: 0
Mar 26 21:57:04.376: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:57:05.376: INFO: Number of nodes with available pods: 0
Mar 26 21:57:05.376: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:57:06.376: INFO: Number of nodes with available pods: 0
Mar 26 21:57:06.376: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:57:07.376: INFO: Number of nodes with available pods: 0
Mar 26 21:57:07.376: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:57:08.376: INFO: Number of nodes with available pods: 0
Mar 26 21:57:08.376: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:57:09.376: INFO: Number of nodes with available pods: 0
Mar 26 21:57:09.376: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:57:10.377: INFO: Number of nodes with available pods: 0
Mar 26 21:57:10.377: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:57:11.376: INFO: Number of nodes with available pods: 0
Mar 26 21:57:11.376: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:57:12.376: INFO: Number of nodes with available pods: 0
Mar 26 21:57:12.376: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:57:13.377: INFO: Number of nodes with available pods: 0
Mar 26 21:57:13.377: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:57:14.376: INFO: Number of nodes with available pods: 0
Mar 26 21:57:14.376: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:57:15.376: INFO: Number of nodes with available pods: 0
Mar 26 21:57:15.376: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:57:16.377: INFO: Number of nodes with available pods: 0
Mar 26 21:57:16.377: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:57:17.376: INFO: Number of nodes with available pods: 0
Mar 26 21:57:17.376: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:57:18.376: INFO: Number of nodes with available pods: 0
Mar 26 21:57:18.376: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:57:19.376: INFO: Number of nodes with available pods: 0
Mar 26 21:57:19.376: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:57:20.376: INFO: Number of nodes with available pods: 0
Mar 26 21:57:20.376: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:57:21.376: INFO: Number of nodes with available pods: 0
Mar 26 21:57:21.376: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:57:22.376: INFO: Number of nodes with available pods: 0
Mar 26 21:57:22.376: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:57:23.377: INFO: Number of nodes with available pods: 0
Mar 26 21:57:23.377: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:57:24.376: INFO: Number of nodes with available pods: 0
Mar 26 21:57:24.376: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:57:25.376: INFO: Number of nodes with available pods: 0
Mar 26 21:57:25.376: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:57:26.380: INFO: Number of nodes with available pods: 0
Mar 26 21:57:26.380: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:57:27.377: INFO: Number of nodes with available pods: 0
Mar 26 21:57:27.377: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:57:28.376: INFO: Number of nodes with available pods: 0
Mar 26 21:57:28.376: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 21:57:29.376: INFO: Number of nodes with available pods: 1
Mar 26 21:57:29.376: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
[1mSTEP[0m: Deleting DaemonSet "daemon-set"
[1mSTEP[0m: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-8snpn, will wait for the garbage collector to delete the pods
Mar 26 21:57:29.535: INFO: Deleting {extensions DaemonSet} daemon-set took: 29.119255ms
Mar 26 21:57:29.635: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.239997ms
Mar 26 21:58:08.161: INFO: Number of nodes with available pods: 0
Mar 26 21:58:08.161: INFO: Number of running nodes: 0, number of available pods: 0
Mar 26 21:58:08.187: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-8snpn/daemonsets","resourceVersion":"16166"},"items":null}

Mar 26 21:58:08.213: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-8snpn/pods","resourceVersion":"16166"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 21:58:08.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-daemonsets-8snpn" for this suite.
Mar 26 21:58:14.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 21:58:15.182: INFO: namespace: e2e-tests-daemonsets-8snpn, resource: bindings, ignored listing per whitelist
Mar 26 21:58:15.396: INFO: namespace e2e-tests-daemonsets-8snpn deletion completed in 7.04767422s

[32mâ€¢ [SLOW TEST:83.402 seconds][0m
[sig-apps] Daemon set [Serial]
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  should run and stop complex daemon [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide container's memory limit [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 21:58:15.396: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 26 21:58:16.261: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c94cd8bc-5033-11e9-9bdd-d050998677c2" in namespace "e2e-tests-downward-api-4zzd5" to be "success or failure"
Mar 26 21:58:16.286: INFO: Pod "downwardapi-volume-c94cd8bc-5033-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.662025ms
Mar 26 21:58:18.313: INFO: Pod "downwardapi-volume-c94cd8bc-5033-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.052223609s
[1mSTEP[0m: Saw pod success
Mar 26 21:58:18.313: INFO: Pod "downwardapi-volume-c94cd8bc-5033-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 21:58:18.339: INFO: Trying to get logs from node ip-172-20-53-156.us-east-2.compute.internal pod downwardapi-volume-c94cd8bc-5033-11e9-9bdd-d050998677c2 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 21:58:18.403: INFO: Waiting for pod downwardapi-volume-c94cd8bc-5033-11e9-9bdd-d050998677c2 to disappear
Mar 26 21:58:18.429: INFO: Pod downwardapi-volume-c94cd8bc-5033-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 21:58:18.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-4zzd5" for this suite.
Mar 26 21:58:24.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 21:58:25.031: INFO: namespace: e2e-tests-downward-api-4zzd5, resource: bindings, ignored listing per whitelist
Mar 26 21:58:25.500: INFO: namespace e2e-tests-downward-api-4zzd5 deletion completed in 7.043605285s

[32mâ€¢ [SLOW TEST:10.104 seconds][0m
[sig-storage] Downward API volume
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34[0m
  should provide container's memory limit [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Subpath[0m [90mAtomic writer volumes[0m 
  [1mshould support subpaths with configmap pod [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Subpath
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 21:58:25.500: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename subpath
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
[1mSTEP[0m: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating pod pod-subpath-test-configmap-wdpm
[1mSTEP[0m: Creating a pod to test atomic-volume-subpath
Mar 26 21:58:26.497: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-wdpm" in namespace "e2e-tests-subpath-rttfj" to be "success or failure"
Mar 26 21:58:26.523: INFO: Pod "pod-subpath-test-configmap-wdpm": Phase="Pending", Reason="", readiness=false. Elapsed: 26.161021ms
Mar 26 21:58:28.550: INFO: Pod "pod-subpath-test-configmap-wdpm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053007736s
Mar 26 21:58:30.577: INFO: Pod "pod-subpath-test-configmap-wdpm": Phase="Running", Reason="", readiness=false. Elapsed: 4.079700068s
Mar 26 21:58:32.603: INFO: Pod "pod-subpath-test-configmap-wdpm": Phase="Running", Reason="", readiness=false. Elapsed: 6.106204874s
Mar 26 21:58:34.632: INFO: Pod "pod-subpath-test-configmap-wdpm": Phase="Running", Reason="", readiness=false. Elapsed: 8.13518279s
Mar 26 21:58:36.658: INFO: Pod "pod-subpath-test-configmap-wdpm": Phase="Running", Reason="", readiness=false. Elapsed: 10.161315126s
Mar 26 21:58:38.685: INFO: Pod "pod-subpath-test-configmap-wdpm": Phase="Running", Reason="", readiness=false. Elapsed: 12.187874468s
Mar 26 21:58:40.711: INFO: Pod "pod-subpath-test-configmap-wdpm": Phase="Running", Reason="", readiness=false. Elapsed: 14.214133324s
Mar 26 21:58:42.738: INFO: Pod "pod-subpath-test-configmap-wdpm": Phase="Running", Reason="", readiness=false. Elapsed: 16.240796046s
Mar 26 21:58:44.764: INFO: Pod "pod-subpath-test-configmap-wdpm": Phase="Running", Reason="", readiness=false. Elapsed: 18.266940881s
Mar 26 21:58:46.790: INFO: Pod "pod-subpath-test-configmap-wdpm": Phase="Running", Reason="", readiness=false. Elapsed: 20.293345837s
Mar 26 21:58:48.817: INFO: Pod "pod-subpath-test-configmap-wdpm": Phase="Running", Reason="", readiness=false. Elapsed: 22.320256084s
Mar 26 21:58:50.844: INFO: Pod "pod-subpath-test-configmap-wdpm": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.347077146s
[1mSTEP[0m: Saw pod success
Mar 26 21:58:50.844: INFO: Pod "pod-subpath-test-configmap-wdpm" satisfied condition "success or failure"
Mar 26 21:58:50.870: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-subpath-test-configmap-wdpm container test-container-subpath-configmap-wdpm: <nil>
[1mSTEP[0m: delete the pod
Mar 26 21:58:50.934: INFO: Waiting for pod pod-subpath-test-configmap-wdpm to disappear
Mar 26 21:58:50.961: INFO: Pod pod-subpath-test-configmap-wdpm no longer exists
[1mSTEP[0m: Deleting pod pod-subpath-test-configmap-wdpm
Mar 26 21:58:50.961: INFO: Deleting pod "pod-subpath-test-configmap-wdpm" in namespace "e2e-tests-subpath-rttfj"
[AfterEach] [sig-storage] Subpath
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 21:58:50.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-subpath-rttfj" for this suite.
Mar 26 21:58:57.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 21:58:57.456: INFO: namespace: e2e-tests-subpath-rttfj, resource: bindings, ignored listing per whitelist
Mar 26 21:58:58.149: INFO: namespace e2e-tests-subpath-rttfj deletion completed in 7.135973471s

[32mâ€¢ [SLOW TEST:32.649 seconds][0m
[sig-storage] Subpath
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  Atomic writer volumes
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34[0m
    should support subpaths with configmap pod [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] [sig-node] Pods Extended[0m [90m[k8s.io] Delete Grace Period[0m 
  [1mshould be submitted and removed  [Flaky] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 21:58:58.150: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:46
[It] should be submitted and removed  [Flaky] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating the pod
[1mSTEP[0m: setting up watch
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: verifying the pod is in kubernetes
[1mSTEP[0m: verifying pod creation was observed
Mar 26 21:59:01.191: INFO: Asynchronously running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config proxy -p 0'
[1mSTEP[0m: deleting the pod gracefully
[1mSTEP[0m: verifying the kubelet observed the termination notice
[1mSTEP[0m: verifying pod deletion was observed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 21:59:10.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pods-7b4dg" for this suite.
Mar 26 21:59:16.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 21:59:17.535: INFO: namespace: e2e-tests-pods-7b4dg, resource: bindings, ignored listing per whitelist
Mar 26 21:59:17.720: INFO: namespace e2e-tests-pods-7b4dg deletion completed in 7.058606809s

[32mâ€¢ [SLOW TEST:19.571 seconds][0m
[k8s.io] [sig-node] Pods Extended
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  [k8s.io] Delete Grace Period
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should be submitted and removed  [Flaky] [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide container's memory request [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 21:59:17.721: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 26 21:59:18.602: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ee758ea8-5033-11e9-9bdd-d050998677c2" in namespace "e2e-tests-downward-api-v6z7r" to be "success or failure"
Mar 26 21:59:18.630: INFO: Pod "downwardapi-volume-ee758ea8-5033-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 27.376968ms
Mar 26 21:59:20.658: INFO: Pod "downwardapi-volume-ee758ea8-5033-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.055821708s
[1mSTEP[0m: Saw pod success
Mar 26 21:59:20.658: INFO: Pod "downwardapi-volume-ee758ea8-5033-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 21:59:20.685: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod downwardapi-volume-ee758ea8-5033-11e9-9bdd-d050998677c2 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 21:59:20.749: INFO: Waiting for pod downwardapi-volume-ee758ea8-5033-11e9-9bdd-d050998677c2 to disappear
Mar 26 21:59:20.779: INFO: Pod downwardapi-volume-ee758ea8-5033-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 21:59:20.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-v6z7r" for this suite.
Mar 26 21:59:26.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 21:59:27.035: INFO: namespace: e2e-tests-downward-api-v6z7r, resource: bindings, ignored listing per whitelist
Mar 26 21:59:27.883: INFO: namespace e2e-tests-downward-api-v6z7r deletion completed in 7.075863645s

[32mâ€¢ [SLOW TEST:10.162 seconds][0m
[sig-storage] Downward API volume
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34[0m
  should provide container's memory request [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl rolling-update[0m 
  [1mshould support rolling-update to same image  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 21:59:27.883: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: running the image docker.io/library/nginx:1.14-alpine
Mar 26 21:59:28.785: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-wvqcv'
Mar 26 21:59:29.071: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar 26 21:59:29.071: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
[1mSTEP[0m: verifying the rc e2e-test-nginx-rc was created
[1mSTEP[0m: rolling-update to same image controller
Mar 26 21:59:29.248: INFO: scanned /home/justinsb for discovery docs: <nil>
Mar 26 21:59:29.248: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-wvqcv'
Mar 26 21:59:40.618: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar 26 21:59:40.618: INFO: stdout: "Created e2e-test-nginx-rc-9719dbb286e641c486c337bed449d1c9\nScaling up e2e-test-nginx-rc-9719dbb286e641c486c337bed449d1c9 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-9719dbb286e641c486c337bed449d1c9 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-9719dbb286e641c486c337bed449d1c9 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Mar 26 21:59:40.618: INFO: stdout: "Created e2e-test-nginx-rc-9719dbb286e641c486c337bed449d1c9\nScaling up e2e-test-nginx-rc-9719dbb286e641c486c337bed449d1c9 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-9719dbb286e641c486c337bed449d1c9 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-9719dbb286e641c486c337bed449d1c9 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
[1mSTEP[0m: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Mar 26 21:59:40.618: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-wvqcv'
Mar 26 21:59:40.918: INFO: stderr: ""
Mar 26 21:59:40.918: INFO: stdout: "e2e-test-nginx-rc-9719dbb286e641c486c337bed449d1c9-msckt "
Mar 26 21:59:40.918: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods e2e-test-nginx-rc-9719dbb286e641c486c337bed449d1c9-msckt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wvqcv'
Mar 26 21:59:41.150: INFO: stderr: ""
Mar 26 21:59:41.150: INFO: stdout: "true"
Mar 26 21:59:41.151: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods e2e-test-nginx-rc-9719dbb286e641c486c337bed449d1c9-msckt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wvqcv'
Mar 26 21:59:41.420: INFO: stderr: ""
Mar 26 21:59:41.420: INFO: stdout: "nginx:1.14-alpine"
Mar 26 21:59:41.420: INFO: e2e-test-nginx-rc-9719dbb286e641c486c337bed449d1c9-msckt is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Mar 26 21:59:41.420: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-wvqcv'
Mar 26 21:59:41.718: INFO: stderr: ""
Mar 26 21:59:41.718: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 21:59:41.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-wvqcv" for this suite.
Mar 26 22:00:03.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:00:04.492: INFO: namespace: e2e-tests-kubectl-wvqcv, resource: bindings, ignored listing per whitelist
Mar 26 22:00:04.773: INFO: namespace e2e-tests-kubectl-wvqcv deletion completed in 23.027460178s

[32mâ€¢ [SLOW TEST:36.890 seconds][0m
[sig-cli] Kubectl client
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl rolling-update
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should support rolling-update to same image  [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Daemon set [Serial][0m 
  [1mshould retry creating failed daemon pods [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] Daemon set [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:00:04.773: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename daemonsets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a simple DaemonSet "daemon-set"
[1mSTEP[0m: Check that daemon pods launch on every node of the cluster.
Mar 26 22:00:05.754: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:00:05.780: INFO: Number of nodes with available pods: 0
Mar 26 22:00:05.780: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:00:06.807: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:00:06.833: INFO: Number of nodes with available pods: 0
Mar 26 22:00:06.833: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:00:07.809: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:00:07.835: INFO: Number of nodes with available pods: 2
Mar 26 22:00:07.835: INFO: Number of running nodes: 2, number of available pods: 2
[1mSTEP[0m: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Mar 26 22:00:07.943: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:00:07.969: INFO: Number of nodes with available pods: 1
Mar 26 22:00:07.969: INFO: Node ip-172-20-56-226.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:00:08.997: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:00:09.024: INFO: Number of nodes with available pods: 2
Mar 26 22:00:09.024: INFO: Number of running nodes: 2, number of available pods: 2
[1mSTEP[0m: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
[1mSTEP[0m: Deleting DaemonSet "daemon-set"
[1mSTEP[0m: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-ckplz, will wait for the garbage collector to delete the pods
Mar 26 22:00:09.189: INFO: Deleting {extensions DaemonSet} daemon-set took: 31.093156ms
Mar 26 22:00:09.289: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.215032ms
Mar 26 22:00:48.116: INFO: Number of nodes with available pods: 0
Mar 26 22:00:48.116: INFO: Number of running nodes: 0, number of available pods: 0
Mar 26 22:00:48.141: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-ckplz/daemonsets","resourceVersion":"16564"},"items":null}

Mar 26 22:00:48.168: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-ckplz/pods","resourceVersion":"16564"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:00:48.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-daemonsets-ckplz" for this suite.
Mar 26 22:00:54.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:00:54.956: INFO: namespace: e2e-tests-daemonsets-ckplz, resource: bindings, ignored listing per whitelist
Mar 26 22:00:55.322: INFO: namespace e2e-tests-daemonsets-ckplz deletion completed in 7.04437609s

[32mâ€¢ [SLOW TEST:50.549 seconds][0m
[sig-apps] Daemon set [Serial]
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  should retry creating failed daemon pods [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[k8s.io] Docker Containers[0m 
  [1mshould use the image defaults if command and args are blank [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Docker Containers
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:00:55.322: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename containers
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test use defaults
Mar 26 22:00:56.188: INFO: Waiting up to 5m0s for pod "client-containers-289fd5c5-5034-11e9-9bdd-d050998677c2" in namespace "e2e-tests-containers-2lthx" to be "success or failure"
Mar 26 22:00:56.214: INFO: Pod "client-containers-289fd5c5-5034-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.768457ms
Mar 26 22:00:58.240: INFO: Pod "client-containers-289fd5c5-5034-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.052370635s
[1mSTEP[0m: Saw pod success
Mar 26 22:00:58.240: INFO: Pod "client-containers-289fd5c5-5034-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:00:58.266: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod client-containers-289fd5c5-5034-11e9-9bdd-d050998677c2 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:00:58.328: INFO: Waiting for pod client-containers-289fd5c5-5034-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:00:58.354: INFO: Pod client-containers-289fd5c5-5034-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:00:58.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-containers-2lthx" for this suite.
Mar 26 22:01:04.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:01:05.311: INFO: namespace: e2e-tests-containers-2lthx, resource: bindings, ignored listing per whitelist
Mar 26 22:01:05.415: INFO: namespace e2e-tests-containers-2lthx deletion completed in 7.033610324s

[32mâ€¢ [SLOW TEST:10.093 seconds][0m
[k8s.io] Docker Containers
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould be consumable from pods in volume with mappings [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:01:05.415: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating projection with secret that has name projected-secret-test-map-2eb06d90-5034-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume secrets
Mar 26 22:01:06.388: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2eb46eca-5034-11e9-9bdd-d050998677c2" in namespace "e2e-tests-projected-46n97" to be "success or failure"
Mar 26 22:01:06.415: INFO: Pod "pod-projected-secrets-2eb46eca-5034-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 26.376985ms
Mar 26 22:01:08.440: INFO: Pod "pod-projected-secrets-2eb46eca-5034-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.052318486s
[1mSTEP[0m: Saw pod success
Mar 26 22:01:08.441: INFO: Pod "pod-projected-secrets-2eb46eca-5034-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:01:08.466: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-projected-secrets-2eb46eca-5034-11e9-9bdd-d050998677c2 container projected-secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:01:08.525: INFO: Waiting for pod pod-projected-secrets-2eb46eca-5034-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:01:08.550: INFO: Pod pod-projected-secrets-2eb46eca-5034-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:01:08.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-46n97" for this suite.
Mar 26 22:01:14.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:01:15.410: INFO: namespace: e2e-tests-projected-46n97, resource: bindings, ignored listing per whitelist
Mar 26 22:01:15.644: INFO: namespace e2e-tests-projected-46n97 deletion completed in 7.066141231s

[32mâ€¢ [SLOW TEST:10.229 seconds][0m
[sig-storage] Projected
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35[0m
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould be consumable from pods in volume [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:01:15.644: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-34bc5d90-5034-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 26 22:01:16.532: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-34c0569c-5034-11e9-9bdd-d050998677c2" in namespace "e2e-tests-projected-d7ww7" to be "success or failure"
Mar 26 22:01:16.558: INFO: Pod "pod-projected-configmaps-34c0569c-5034-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.955172ms
Mar 26 22:01:18.585: INFO: Pod "pod-projected-configmaps-34c0569c-5034-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.052053807s
[1mSTEP[0m: Saw pod success
Mar 26 22:01:18.585: INFO: Pod "pod-projected-configmaps-34c0569c-5034-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:01:18.610: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-projected-configmaps-34c0569c-5034-11e9-9bdd-d050998677c2 container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:01:18.672: INFO: Waiting for pod pod-projected-configmaps-34c0569c-5034-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:01:18.698: INFO: Pod pod-projected-configmaps-34c0569c-5034-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:01:18.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-d7ww7" for this suite.
Mar 26 22:01:24.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:01:25.717: INFO: namespace: e2e-tests-projected-d7ww7, resource: bindings, ignored listing per whitelist
Mar 26 22:01:25.769: INFO: namespace e2e-tests-projected-d7ww7 deletion completed in 7.044679377s

[32mâ€¢ [SLOW TEST:10.125 seconds][0m
[sig-storage] Projected
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35[0m
  should be consumable from pods in volume [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] ConfigMap
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:01:25.769: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name configmap-test-volume-3ac7decd-5034-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 26 22:01:26.677: INFO: Waiting up to 5m0s for pod "pod-configmaps-3acbd474-5034-11e9-9bdd-d050998677c2" in namespace "e2e-tests-configmap-c9l4n" to be "success or failure"
Mar 26 22:01:26.703: INFO: Pod "pod-configmaps-3acbd474-5034-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.829646ms
Mar 26 22:01:28.729: INFO: Pod "pod-configmaps-3acbd474-5034-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.052008645s
[1mSTEP[0m: Saw pod success
Mar 26 22:01:28.729: INFO: Pod "pod-configmaps-3acbd474-5034-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:01:28.755: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-configmaps-3acbd474-5034-11e9-9bdd-d050998677c2 container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:01:28.817: INFO: Waiting for pod pod-configmaps-3acbd474-5034-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:01:28.843: INFO: Pod pod-configmaps-3acbd474-5034-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:01:28.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-c9l4n" for this suite.
Mar 26 22:01:34.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:01:35.511: INFO: namespace: e2e-tests-configmap-c9l4n, resource: bindings, ignored listing per whitelist
Mar 26 22:01:35.936: INFO: namespace e2e-tests-configmap-c9l4n deletion completed in 7.066295679s

[32mâ€¢ [SLOW TEST:10.167 seconds][0m
[sig-storage] ConfigMap
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33[0m
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Secrets
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:01:35.937: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating secret with name secret-test-40d57cd9-5034-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume secrets
Mar 26 22:01:36.832: INFO: Waiting up to 5m0s for pod "pod-secrets-40d98f1e-5034-11e9-9bdd-d050998677c2" in namespace "e2e-tests-secrets-92jpt" to be "success or failure"
Mar 26 22:01:36.858: INFO: Pod "pod-secrets-40d98f1e-5034-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 26.178927ms
Mar 26 22:01:38.885: INFO: Pod "pod-secrets-40d98f1e-5034-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.053088335s
[1mSTEP[0m: Saw pod success
Mar 26 22:01:38.885: INFO: Pod "pod-secrets-40d98f1e-5034-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:01:38.911: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-secrets-40d98f1e-5034-11e9-9bdd-d050998677c2 container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:01:38.975: INFO: Waiting for pod pod-secrets-40d98f1e-5034-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:01:39.001: INFO: Pod pod-secrets-40d98f1e-5034-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Secrets
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:01:39.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-secrets-92jpt" for this suite.
Mar 26 22:01:45.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:01:45.525: INFO: namespace: e2e-tests-secrets-92jpt, resource: bindings, ignored listing per whitelist
Mar 26 22:01:46.080: INFO: namespace e2e-tests-secrets-92jpt deletion completed in 7.051201327s

[32mâ€¢ [SLOW TEST:10.143 seconds][0m
[sig-storage] Secrets
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34[0m
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[k8s.io] [sig-node] Pods Extended[0m [90m[k8s.io] Pods Set QOS Class[0m 
  [1mshould be submitted and removed  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:01:46.080: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating the pod
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:01:46.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pods-fs9js" for this suite.
Mar 26 22:02:09.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:02:09.741: INFO: namespace: e2e-tests-pods-fs9js, resource: bindings, ignored listing per whitelist
Mar 26 22:02:10.022: INFO: namespace e2e-tests-pods-fs9js deletion completed in 23.023027282s

[32mâ€¢ [SLOW TEST:23.942 seconds][0m
[k8s.io] [sig-node] Pods Extended
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  [k8s.io] Pods Set QOS Class
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should be submitted and removed  [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-apps] Deployment[0m 
  [1mRecreateDeployment should delete old pods and create new ones [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] Deployment
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:02:10.022: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename deployment
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 22:02:10.866: INFO: Creating deployment "test-recreate-deployment"
Mar 26 22:02:10.894: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Mar 26 22:02:10.952: INFO: Waiting deployment "test-recreate-deployment" to complete
Mar 26 22:02:10.977: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689248930, loc:(*time.Location)(0x835fd00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689248930, loc:(*time.Location)(0x835fd00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689248930, loc:(*time.Location)(0x835fd00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689248930, loc:(*time.Location)(0x835fd00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 26 22:02:13.004: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Mar 26 22:02:13.058: INFO: Updating deployment test-recreate-deployment
Mar 26 22:02:13.058: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 26 22:02:13.134: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-cmx8l,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-cmx8l/deployments/test-recreate-deployment,UID:5529a51f-5034-11e9-8eb3-023bf32bf132,ResourceVersion:16828,Generation:2,CreationTimestamp:2019-03-26 22:02:10 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-03-26 22:02:13 -0400 EDT 2019-03-26 22:02:13 -0400 EDT MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-03-26 22:02:13 -0400 EDT 2019-03-26 22:02:10 -0400 EDT ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Mar 26 22:02:13.162: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-cmx8l,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-cmx8l/replicasets/test-recreate-deployment-7cf749666b,UID:5677931c-5034-11e9-8eb3-023bf32bf132,ResourceVersion:16827,Generation:1,CreationTimestamp:2019-03-26 22:02:13 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 5529a51f-5034-11e9-8eb3-023bf32bf132 0xc002230a47 0xc002230a48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 26 22:02:13.162: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Mar 26 22:02:13.162: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-cmx8l,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-cmx8l/replicasets/test-recreate-deployment-79f694ff59,UID:552a81c3-5034-11e9-8eb3-023bf32bf132,ResourceVersion:16820,Generation:2,CreationTimestamp:2019-03-26 22:02:10 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 5529a51f-5034-11e9-8eb3-023bf32bf132 0xc0022308b7 0xc0022308b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 26 22:02:13.193: INFO: Pod "test-recreate-deployment-7cf749666b-2nnrv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-2nnrv,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-cmx8l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cmx8l/pods/test-recreate-deployment-7cf749666b-2nnrv,UID:56784f3f-5034-11e9-8eb3-023bf32bf132,ResourceVersion:16829,Generation:0,CreationTimestamp:2019-03-26 22:02:13 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b 5677931c-5034-11e9-8eb3-023bf32bf132 0xc0022313d7 0xc0022313d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g56lj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g56lj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-g56lj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-56-226.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002231440} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002231460}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 22:02:13 -0400 EDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 22:02:13 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 22:02:13 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 22:02:13 -0400 EDT  }],Message:,Reason:,HostIP:172.20.56.226,PodIP:,StartTime:2019-03-26 22:02:13 -0400 EDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:02:13.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-deployment-cmx8l" for this suite.
Mar 26 22:02:19.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:02:20.115: INFO: namespace: e2e-tests-deployment-cmx8l, resource: bindings, ignored listing per whitelist
Mar 26 22:02:20.270: INFO: namespace e2e-tests-deployment-cmx8l deletion completed in 7.042722397s

[32mâ€¢ [SLOW TEST:10.248 seconds][0m
[sig-apps] Deployment
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  RecreateDeployment should delete old pods and create new ones [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Downward API[0m 
  [1mshould provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Downward API
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:02:20.270: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward api env vars
Mar 26 22:02:21.140: INFO: Waiting up to 5m0s for pod "downward-api-5b428a5e-5034-11e9-9bdd-d050998677c2" in namespace "e2e-tests-downward-api-97bbs" to be "success or failure"
Mar 26 22:02:21.167: INFO: Pod "downward-api-5b428a5e-5034-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 26.649152ms
Mar 26 22:02:23.206: INFO: Pod "downward-api-5b428a5e-5034-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.065922804s
[1mSTEP[0m: Saw pod success
Mar 26 22:02:23.206: INFO: Pod "downward-api-5b428a5e-5034-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:02:23.247: INFO: Trying to get logs from node ip-172-20-53-156.us-east-2.compute.internal pod downward-api-5b428a5e-5034-11e9-9bdd-d050998677c2 container dapi-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:02:23.341: INFO: Waiting for pod downward-api-5b428a5e-5034-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:02:23.382: INFO: Pod downward-api-5b428a5e-5034-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:02:23.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-97bbs" for this suite.
Mar 26 22:02:29.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:02:30.431: INFO: namespace: e2e-tests-downward-api-97bbs, resource: bindings, ignored listing per whitelist
Mar 26 22:02:30.457: INFO: namespace e2e-tests-downward-api-97bbs deletion completed in 7.041001602s

[32mâ€¢ [SLOW TEST:10.187 seconds][0m
[sig-api-machinery] Downward API
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38[0m
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be consumable in multiple volumes in a pod [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Secrets
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:02:30.458: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating secret with name secret-test-6154dd07-5034-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume secrets
Mar 26 22:02:31.353: INFO: Waiting up to 5m0s for pod "pod-secrets-6158db8b-5034-11e9-9bdd-d050998677c2" in namespace "e2e-tests-secrets-mff9j" to be "success or failure"
Mar 26 22:02:31.379: INFO: Pod "pod-secrets-6158db8b-5034-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 26.007377ms
Mar 26 22:02:33.405: INFO: Pod "pod-secrets-6158db8b-5034-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.052331525s
[1mSTEP[0m: Saw pod success
Mar 26 22:02:33.405: INFO: Pod "pod-secrets-6158db8b-5034-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:02:33.431: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-secrets-6158db8b-5034-11e9-9bdd-d050998677c2 container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:02:33.492: INFO: Waiting for pod pod-secrets-6158db8b-5034-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:02:33.518: INFO: Pod pod-secrets-6158db8b-5034-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Secrets
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:02:33.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-secrets-mff9j" for this suite.
Mar 26 22:02:39.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:02:40.243: INFO: namespace: e2e-tests-secrets-mff9j, resource: bindings, ignored listing per whitelist
Mar 26 22:02:40.578: INFO: namespace e2e-tests-secrets-mff9j deletion completed in 7.033793949s

[32mâ€¢ [SLOW TEST:10.121 seconds][0m
[sig-storage] Secrets
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34[0m
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Watchers[0m 
  [1mshould be able to restart watching from the last resource version observed by the previous watch [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Watchers
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:02:40.578: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename watch
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating a watch on configmaps
[1mSTEP[0m: creating a new configmap
[1mSTEP[0m: modifying the configmap once
[1mSTEP[0m: closing the watch once it receives two notifications
Mar 26 22:02:41.520: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-vbx7q,SelfLink:/api/v1/namespaces/e2e-tests-watch-vbx7q/configmaps/e2e-watch-test-watch-closed,UID:6762c9ca-5034-11e9-8eb3-023bf32bf132,ResourceVersion:16919,Generation:0,CreationTimestamp:2019-03-26 22:02:41 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 26 22:02:41.520: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-vbx7q,SelfLink:/api/v1/namespaces/e2e-tests-watch-vbx7q/configmaps/e2e-watch-test-watch-closed,UID:6762c9ca-5034-11e9-8eb3-023bf32bf132,ResourceVersion:16920,Generation:0,CreationTimestamp:2019-03-26 22:02:41 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
[1mSTEP[0m: modifying the configmap a second time, while the watch is closed
[1mSTEP[0m: creating a new watch on configmaps from the last resource version observed by the first watch
[1mSTEP[0m: deleting the configmap
[1mSTEP[0m: Expecting to observe notifications for all changes to the configmap since the first watch closed
Mar 26 22:02:41.624: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-vbx7q,SelfLink:/api/v1/namespaces/e2e-tests-watch-vbx7q/configmaps/e2e-watch-test-watch-closed,UID:6762c9ca-5034-11e9-8eb3-023bf32bf132,ResourceVersion:16922,Generation:0,CreationTimestamp:2019-03-26 22:02:41 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 26 22:02:41.625: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-vbx7q,SelfLink:/api/v1/namespaces/e2e-tests-watch-vbx7q/configmaps/e2e-watch-test-watch-closed,UID:6762c9ca-5034-11e9-8eb3-023bf32bf132,ResourceVersion:16923,Generation:0,CreationTimestamp:2019-03-26 22:02:41 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:02:41.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-watch-vbx7q" for this suite.
Mar 26 22:02:47.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:02:47.935: INFO: namespace: e2e-tests-watch-vbx7q, resource: bindings, ignored listing per whitelist
Mar 26 22:02:48.686: INFO: namespace e2e-tests-watch-vbx7q deletion completed in 7.034308301s

[32mâ€¢ [SLOW TEST:8.107 seconds][0m
[sig-api-machinery] Watchers
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable from pods in volume as non-root [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] ConfigMap
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:02:48.686: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name configmap-test-volume-6c325252-5034-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 26 22:02:49.584: INFO: Waiting up to 5m0s for pod "pod-configmaps-6c366970-5034-11e9-9bdd-d050998677c2" in namespace "e2e-tests-configmap-6nhv7" to be "success or failure"
Mar 26 22:02:49.610: INFO: Pod "pod-configmaps-6c366970-5034-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.818389ms
Mar 26 22:02:51.637: INFO: Pod "pod-configmaps-6c366970-5034-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.052391871s
[1mSTEP[0m: Saw pod success
Mar 26 22:02:51.637: INFO: Pod "pod-configmaps-6c366970-5034-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:02:51.662: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-configmaps-6c366970-5034-11e9-9bdd-d050998677c2 container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:02:51.727: INFO: Waiting for pod pod-configmaps-6c366970-5034-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:02:51.753: INFO: Pod pod-configmaps-6c366970-5034-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:02:51.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-6nhv7" for this suite.
Mar 26 22:02:57.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:02:58.505: INFO: namespace: e2e-tests-configmap-6nhv7, resource: bindings, ignored listing per whitelist
Mar 26 22:02:58.815: INFO: namespace e2e-tests-configmap-6nhv7 deletion completed in 7.0359423s

[32mâ€¢ [SLOW TEST:10.129 seconds][0m
[sig-storage] ConfigMap
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33[0m
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:02:58.815: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-map-723b0808-5034-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 26 22:02:59.705: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-723f1bbf-5034-11e9-9bdd-d050998677c2" in namespace "e2e-tests-projected-rd7j7" to be "success or failure"
Mar 26 22:02:59.731: INFO: Pod "pod-projected-configmaps-723f1bbf-5034-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.832402ms
Mar 26 22:03:01.760: INFO: Pod "pod-projected-configmaps-723f1bbf-5034-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.054751216s
[1mSTEP[0m: Saw pod success
Mar 26 22:03:01.760: INFO: Pod "pod-projected-configmaps-723f1bbf-5034-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:03:01.786: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-projected-configmaps-723f1bbf-5034-11e9-9bdd-d050998677c2 container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:03:01.850: INFO: Waiting for pod pod-projected-configmaps-723f1bbf-5034-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:03:01.876: INFO: Pod pod-projected-configmaps-723f1bbf-5034-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:03:01.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-rd7j7" for this suite.
Mar 26 22:03:07.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:03:08.294: INFO: namespace: e2e-tests-projected-rd7j7, resource: bindings, ignored listing per whitelist
Mar 26 22:03:08.934: INFO: namespace e2e-tests-projected-rd7j7 deletion completed in 7.031789955s

[32mâ€¢ [SLOW TEST:10.119 seconds][0m
[sig-storage] Projected
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35[0m
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould update labels on modification [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:03:08.935: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating the pod
Mar 26 22:03:12.467: INFO: Successfully updated pod "labelsupdate7843b036-5034-11e9-9bdd-d050998677c2"
[AfterEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:03:16.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-7rdmj" for this suite.
Mar 26 22:03:38.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:03:39.094: INFO: namespace: e2e-tests-downward-api-7rdmj, resource: bindings, ignored listing per whitelist
Mar 26 22:03:39.685: INFO: namespace e2e-tests-downward-api-7rdmj deletion completed in 23.097798191s

[32mâ€¢ [SLOW TEST:30.751 seconds][0m
[sig-storage] Downward API volume
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34[0m
  should update labels on modification [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-scheduling] SchedulerPredicates [Serial][0m 
  [1mvalidates resource limits of pods that are allowed to run  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:03:39.686: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename sched-pred
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Mar 26 22:03:40.533: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 26 22:03:40.586: INFO: Waiting for terminating namespaces to be deleted...
Mar 26 22:03:40.612: INFO: 
Logging pods the kubelet thinks is on node ip-172-20-53-156.us-east-2.compute.internal before test
Mar 26 22:03:40.640: INFO: kube-dns-autoscaler-867b9fd49d-s8grz from kube-system started at 2019-03-26 20:06:02 -0400 EDT (1 container statuses recorded)
Mar 26 22:03:40.640: INFO: 	Container autoscaler ready: true, restart count 0
Mar 26 22:03:40.640: INFO: kube-proxy-ip-172-20-53-156.us-east-2.compute.internal from kube-system started at <nil> (0 container statuses recorded)
Mar 26 22:03:40.640: INFO: kube-dns-7cfc48d44b-5z9lj from kube-system started at 2019-03-26 20:06:02 -0400 EDT (3 container statuses recorded)
Mar 26 22:03:40.640: INFO: 	Container dnsmasq ready: true, restart count 0
Mar 26 22:03:40.640: INFO: 	Container kubedns ready: true, restart count 0
Mar 26 22:03:40.640: INFO: 	Container sidecar ready: true, restart count 0
Mar 26 22:03:40.640: INFO: 
Logging pods the kubelet thinks is on node ip-172-20-56-226.us-east-2.compute.internal before test
Mar 26 22:03:40.667: INFO: kube-dns-7cfc48d44b-x4t9q from kube-system started at 2019-03-26 20:06:07 -0400 EDT (3 container statuses recorded)
Mar 26 22:03:40.668: INFO: 	Container dnsmasq ready: true, restart count 0
Mar 26 22:03:40.668: INFO: 	Container kubedns ready: true, restart count 0
Mar 26 22:03:40.668: INFO: 	Container sidecar ready: true, restart count 0
Mar 26 22:03:40.668: INFO: kube-proxy-ip-172-20-56-226.us-east-2.compute.internal from kube-system started at <nil> (0 container statuses recorded)
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: verifying the node has the label node ip-172-20-53-156.us-east-2.compute.internal
[1mSTEP[0m: verifying the node has the label node ip-172-20-56-226.us-east-2.compute.internal
Mar 26 22:03:40.832: INFO: Pod kube-dns-7cfc48d44b-5z9lj requesting resource cpu=260m on Node ip-172-20-53-156.us-east-2.compute.internal
Mar 26 22:03:40.832: INFO: Pod kube-dns-7cfc48d44b-x4t9q requesting resource cpu=260m on Node ip-172-20-56-226.us-east-2.compute.internal
Mar 26 22:03:40.832: INFO: Pod kube-dns-autoscaler-867b9fd49d-s8grz requesting resource cpu=20m on Node ip-172-20-53-156.us-east-2.compute.internal
Mar 26 22:03:40.832: INFO: Pod kube-proxy-ip-172-20-53-156.us-east-2.compute.internal requesting resource cpu=100m on Node ip-172-20-53-156.us-east-2.compute.internal
Mar 26 22:03:40.832: INFO: Pod kube-proxy-ip-172-20-56-226.us-east-2.compute.internal requesting resource cpu=100m on Node ip-172-20-56-226.us-east-2.compute.internal
[1mSTEP[0m: Starting Pods to consume most of the cluster CPU.
[1mSTEP[0m: Creating another pod that requires unavailable amount of CPU.
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-8ac6e818-5034-11e9-9bdd-d050998677c2.158fae769879831b], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-zv4dq/filler-pod-8ac6e818-5034-11e9-9bdd-d050998677c2 to ip-172-20-53-156.us-east-2.compute.internal]
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-8ac6e818-5034-11e9-9bdd-d050998677c2.158fae76c49b49a8], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-8ac6e818-5034-11e9-9bdd-d050998677c2.158fae76c75e0027], Reason = [Created], Message = [Created container]
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-8ac6e818-5034-11e9-9bdd-d050998677c2.158fae76d2f84929], Reason = [Started], Message = [Started container]
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-8acb2694-5034-11e9-9bdd-d050998677c2.158fae769a1604ef], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-zv4dq/filler-pod-8acb2694-5034-11e9-9bdd-d050998677c2 to ip-172-20-56-226.us-east-2.compute.internal]
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-8acb2694-5034-11e9-9bdd-d050998677c2.158fae76c05a81f4], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-8acb2694-5034-11e9-9bdd-d050998677c2.158fae76c365fc06], Reason = [Created], Message = [Created container]
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-8acb2694-5034-11e9-9bdd-d050998677c2.158fae76cf113670], Reason = [Started], Message = [Started container]
[1mSTEP[0m: Considering event: 
Type = [Warning], Name = [additional-pod.158fae771a7d6e1d], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
[1mSTEP[0m: removing the label node off the node ip-172-20-53-156.us-east-2.compute.internal
[1mSTEP[0m: verifying the node doesn't have the label node
[1mSTEP[0m: removing the label node off the node ip-172-20-56-226.us-east-2.compute.internal
[1mSTEP[0m: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:03:44.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-sched-pred-zv4dq" for this suite.
Mar 26 22:03:50.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:03:50.815: INFO: namespace: e2e-tests-sched-pred-zv4dq, resource: bindings, ignored listing per whitelist
Mar 26 22:03:51.330: INFO: namespace e2e-tests-sched-pred-zv4dq deletion completed in 7.065943575s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

[32mâ€¢ [SLOW TEST:11.645 seconds][0m
[sig-scheduling] SchedulerPredicates [Serial]
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22[0m
  validates resource limits of pods that are allowed to run  [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable from pods in volume [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] ConfigMap
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:03:51.331: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name configmap-test-volume-91886e6c-5034-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 26 22:03:52.222: INFO: Waiting up to 5m0s for pod "pod-configmaps-918c8a0a-5034-11e9-9bdd-d050998677c2" in namespace "e2e-tests-configmap-fgh7m" to be "success or failure"
Mar 26 22:03:52.247: INFO: Pod "pod-configmaps-918c8a0a-5034-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.168464ms
Mar 26 22:03:54.275: INFO: Pod "pod-configmaps-918c8a0a-5034-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.053818084s
[1mSTEP[0m: Saw pod success
Mar 26 22:03:54.275: INFO: Pod "pod-configmaps-918c8a0a-5034-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:03:54.302: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-configmaps-918c8a0a-5034-11e9-9bdd-d050998677c2 container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:03:54.364: INFO: Waiting for pod pod-configmaps-918c8a0a-5034-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:03:54.390: INFO: Pod pod-configmaps-918c8a0a-5034-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:03:54.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-fgh7m" for this suite.
Mar 26 22:04:00.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:04:00.938: INFO: namespace: e2e-tests-configmap-fgh7m, resource: bindings, ignored listing per whitelist
Mar 26 22:04:01.464: INFO: namespace e2e-tests-configmap-fgh7m deletion completed in 7.044383906s

[32mâ€¢ [SLOW TEST:10.133 seconds][0m
[sig-storage] ConfigMap
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33[0m
  should be consumable from pods in volume [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:04:01.464: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 26 22:04:02.346: INFO: Waiting up to 5m0s for pod "downwardapi-volume-97955bd1-5034-11e9-9bdd-d050998677c2" in namespace "e2e-tests-projected-kh8t8" to be "success or failure"
Mar 26 22:04:02.372: INFO: Pod "downwardapi-volume-97955bd1-5034-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.980105ms
Mar 26 22:04:04.399: INFO: Pod "downwardapi-volume-97955bd1-5034-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.052589229s
[1mSTEP[0m: Saw pod success
Mar 26 22:04:04.399: INFO: Pod "downwardapi-volume-97955bd1-5034-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:04:04.428: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod downwardapi-volume-97955bd1-5034-11e9-9bdd-d050998677c2 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:04:04.511: INFO: Waiting for pod downwardapi-volume-97955bd1-5034-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:04:04.539: INFO: Pod downwardapi-volume-97955bd1-5034-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:04:04.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-kh8t8" for this suite.
Mar 26 22:04:10.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:04:11.001: INFO: namespace: e2e-tests-projected-kh8t8, resource: bindings, ignored listing per whitelist
Mar 26 22:04:11.622: INFO: namespace e2e-tests-projected-kh8t8 deletion completed in 7.047735286s

[32mâ€¢ [SLOW TEST:10.158 seconds][0m
[sig-storage] Projected
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35[0m
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl patch[0m 
  [1mshould add annotations for pods in rc  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:04:11.622: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating Redis RC
Mar 26 22:04:12.476: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config create -f - --namespace=e2e-tests-kubectl-2t6fp'
Mar 26 22:04:14.257: INFO: stderr: ""
Mar 26 22:04:14.257: INFO: stdout: "replicationcontroller/redis-master created\n"
[1mSTEP[0m: Waiting for Redis master to start.
Mar 26 22:04:15.302: INFO: Selector matched 1 pods for map[app:redis]
Mar 26 22:04:15.302: INFO: Found 0 / 1
Mar 26 22:04:16.285: INFO: Selector matched 1 pods for map[app:redis]
Mar 26 22:04:16.285: INFO: Found 1 / 1
Mar 26 22:04:16.285: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
[1mSTEP[0m: patching all pods
Mar 26 22:04:16.311: INFO: Selector matched 1 pods for map[app:redis]
Mar 26 22:04:16.311: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 26 22:04:16.311: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config patch pod redis-master-vxkcq --namespace=e2e-tests-kubectl-2t6fp -p {"metadata":{"annotations":{"x":"y"}}}'
Mar 26 22:04:16.595: INFO: stderr: ""
Mar 26 22:04:16.595: INFO: stdout: "pod/redis-master-vxkcq patched\n"
[1mSTEP[0m: checking annotations
Mar 26 22:04:16.622: INFO: Selector matched 1 pods for map[app:redis]
Mar 26 22:04:16.622: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:04:16.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-2t6fp" for this suite.
Mar 26 22:04:38.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:04:39.434: INFO: namespace: e2e-tests-kubectl-2t6fp, resource: bindings, ignored listing per whitelist
Mar 26 22:04:39.718: INFO: namespace e2e-tests-kubectl-2t6fp deletion completed in 23.068627219s

[32mâ€¢ [SLOW TEST:28.095 seconds][0m
[sig-cli] Kubectl client
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl patch
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should add annotations for pods in rc  [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Subpath[0m [90mAtomic writer volumes[0m 
  [1mshould support subpaths with downward pod [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Subpath
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:04:39.718: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename subpath
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
[1mSTEP[0m: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating pod pod-subpath-test-downwardapi-c4gc
[1mSTEP[0m: Creating a pod to test atomic-volume-subpath
Mar 26 22:04:40.682: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-c4gc" in namespace "e2e-tests-subpath-v45gf" to be "success or failure"
Mar 26 22:04:40.707: INFO: Pod "pod-subpath-test-downwardapi-c4gc": Phase="Pending", Reason="", readiness=false. Elapsed: 25.787288ms
Mar 26 22:04:42.734: INFO: Pod "pod-subpath-test-downwardapi-c4gc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052257933s
Mar 26 22:04:44.760: INFO: Pod "pod-subpath-test-downwardapi-c4gc": Phase="Running", Reason="", readiness=false. Elapsed: 4.078807818s
Mar 26 22:04:46.787: INFO: Pod "pod-subpath-test-downwardapi-c4gc": Phase="Running", Reason="", readiness=false. Elapsed: 6.105427618s
Mar 26 22:04:48.814: INFO: Pod "pod-subpath-test-downwardapi-c4gc": Phase="Running", Reason="", readiness=false. Elapsed: 8.132353529s
Mar 26 22:04:50.841: INFO: Pod "pod-subpath-test-downwardapi-c4gc": Phase="Running", Reason="", readiness=false. Elapsed: 10.159034506s
Mar 26 22:04:52.868: INFO: Pod "pod-subpath-test-downwardapi-c4gc": Phase="Running", Reason="", readiness=false. Elapsed: 12.186149796s
Mar 26 22:04:54.896: INFO: Pod "pod-subpath-test-downwardapi-c4gc": Phase="Running", Reason="", readiness=false. Elapsed: 14.214718257s
Mar 26 22:04:56.925: INFO: Pod "pod-subpath-test-downwardapi-c4gc": Phase="Running", Reason="", readiness=false. Elapsed: 16.243456139s
Mar 26 22:04:58.952: INFO: Pod "pod-subpath-test-downwardapi-c4gc": Phase="Running", Reason="", readiness=false. Elapsed: 18.269991324s
Mar 26 22:05:00.979: INFO: Pod "pod-subpath-test-downwardapi-c4gc": Phase="Running", Reason="", readiness=false. Elapsed: 20.297003456s
Mar 26 22:05:03.006: INFO: Pod "pod-subpath-test-downwardapi-c4gc": Phase="Running", Reason="", readiness=false. Elapsed: 22.324103117s
Mar 26 22:05:05.032: INFO: Pod "pod-subpath-test-downwardapi-c4gc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.350874519s
[1mSTEP[0m: Saw pod success
Mar 26 22:05:05.032: INFO: Pod "pod-subpath-test-downwardapi-c4gc" satisfied condition "success or failure"
Mar 26 22:05:05.058: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-subpath-test-downwardapi-c4gc container test-container-subpath-downwardapi-c4gc: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:05:05.119: INFO: Waiting for pod pod-subpath-test-downwardapi-c4gc to disappear
Mar 26 22:05:05.145: INFO: Pod pod-subpath-test-downwardapi-c4gc no longer exists
[1mSTEP[0m: Deleting pod pod-subpath-test-downwardapi-c4gc
Mar 26 22:05:05.145: INFO: Deleting pod "pod-subpath-test-downwardapi-c4gc" in namespace "e2e-tests-subpath-v45gf"
[AfterEach] [sig-storage] Subpath
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:05:05.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-subpath-v45gf" for this suite.
Mar 26 22:05:11.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:05:12.145: INFO: namespace: e2e-tests-subpath-v45gf, resource: bindings, ignored listing per whitelist
Mar 26 22:05:12.256: INFO: namespace e2e-tests-subpath-v45gf deletion completed in 7.057936311s

[32mâ€¢ [SLOW TEST:32.539 seconds][0m
[sig-storage] Subpath
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  Atomic writer volumes
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34[0m
    should support subpaths with downward pod [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Update Demo[0m 
  [1mshould create and stop a replication controller  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:05:12.256: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating a replication controller
Mar 26 22:05:13.108: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config create -f - --namespace=e2e-tests-kubectl-5jjrd'
Mar 26 22:05:13.605: INFO: stderr: ""
Mar 26 22:05:13.605: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
[1mSTEP[0m: waiting for all containers in name=update-demo pods to come up.
Mar 26 22:05:13.605: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-5jjrd'
Mar 26 22:05:14.023: INFO: stderr: ""
Mar 26 22:05:14.023: INFO: stdout: "update-demo-nautilus-5c9jk update-demo-nautilus-mq6mf "
Mar 26 22:05:14.024: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods update-demo-nautilus-5c9jk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5jjrd'
Mar 26 22:05:14.304: INFO: stderr: ""
Mar 26 22:05:14.304: INFO: stdout: ""
Mar 26 22:05:14.304: INFO: update-demo-nautilus-5c9jk is created but not running
Mar 26 22:05:19.304: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-5jjrd'
Mar 26 22:05:19.589: INFO: stderr: ""
Mar 26 22:05:19.590: INFO: stdout: "update-demo-nautilus-5c9jk update-demo-nautilus-mq6mf "
Mar 26 22:05:19.590: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods update-demo-nautilus-5c9jk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5jjrd'
Mar 26 22:05:19.836: INFO: stderr: ""
Mar 26 22:05:19.836: INFO: stdout: "true"
Mar 26 22:05:19.836: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods update-demo-nautilus-5c9jk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5jjrd'
Mar 26 22:05:20.213: INFO: stderr: ""
Mar 26 22:05:20.213: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 26 22:05:20.213: INFO: validating pod update-demo-nautilus-5c9jk
Mar 26 22:05:20.241: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 26 22:05:20.241: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 26 22:05:20.241: INFO: update-demo-nautilus-5c9jk is verified up and running
Mar 26 22:05:20.241: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods update-demo-nautilus-mq6mf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5jjrd'
Mar 26 22:05:20.496: INFO: stderr: ""
Mar 26 22:05:20.496: INFO: stdout: "true"
Mar 26 22:05:20.496: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods update-demo-nautilus-mq6mf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5jjrd'
Mar 26 22:05:20.727: INFO: stderr: ""
Mar 26 22:05:20.727: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 26 22:05:20.727: INFO: validating pod update-demo-nautilus-mq6mf
Mar 26 22:05:20.754: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 26 22:05:20.754: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 26 22:05:20.754: INFO: update-demo-nautilus-mq6mf is verified up and running
[1mSTEP[0m: using delete to clean up resources
Mar 26 22:05:20.754: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-5jjrd'
Mar 26 22:05:21.004: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 26 22:05:21.004: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar 26 22:05:21.004: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-5jjrd'
Mar 26 22:05:21.274: INFO: stderr: "No resources found.\n"
Mar 26 22:05:21.274: INFO: stdout: ""
Mar 26 22:05:21.274: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods -l name=update-demo --namespace=e2e-tests-kubectl-5jjrd -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 26 22:05:21.616: INFO: stderr: ""
Mar 26 22:05:21.616: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:05:21.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-5jjrd" for this suite.
Mar 26 22:05:43.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:05:44.291: INFO: namespace: e2e-tests-kubectl-5jjrd, resource: bindings, ignored listing per whitelist
Mar 26 22:05:44.993: INFO: namespace e2e-tests-kubectl-5jjrd deletion completed in 23.348113575s

[32mâ€¢ [SLOW TEST:32.737 seconds][0m
[sig-cli] Kubectl client
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Update Demo
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should create and stop a replication controller  [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] ConfigMap[0m 
  [1mshould be consumable via environment variable [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] ConfigMap
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:05:44.994: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap e2e-tests-configmap-zmfwt/configmap-test-d580bfb0-5034-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 26 22:05:46.255: INFO: Waiting up to 5m0s for pod "pod-configmaps-d584b576-5034-11e9-9bdd-d050998677c2" in namespace "e2e-tests-configmap-zmfwt" to be "success or failure"
Mar 26 22:05:46.281: INFO: Pod "pod-configmaps-d584b576-5034-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 26.06869ms
Mar 26 22:05:48.317: INFO: Pod "pod-configmaps-d584b576-5034-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.061833712s
[1mSTEP[0m: Saw pod success
Mar 26 22:05:48.317: INFO: Pod "pod-configmaps-d584b576-5034-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:05:48.347: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-configmaps-d584b576-5034-11e9-9bdd-d050998677c2 container env-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:05:48.420: INFO: Waiting for pod pod-configmaps-d584b576-5034-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:05:48.455: INFO: Pod pod-configmaps-d584b576-5034-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:05:48.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-zmfwt" for this suite.
Mar 26 22:05:54.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:05:55.152: INFO: namespace: e2e-tests-configmap-zmfwt, resource: bindings, ignored listing per whitelist
Mar 26 22:05:55.542: INFO: namespace e2e-tests-configmap-zmfwt deletion completed in 7.056573022s

[32mâ€¢ [SLOW TEST:10.549 seconds][0m
[sig-api-machinery] ConfigMap
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30[0m
  should be consumable via environment variable [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mshould have monotonically increasing restart count [Slow][NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Probing container
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:05:55.542: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename container-probe
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating pod liveness-http in namespace e2e-tests-container-probe-556lm
Mar 26 22:05:58.651: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-556lm
[1mSTEP[0m: checking the pod's current state and verifying that restartCount is present
Mar 26 22:05:58.690: INFO: Initial restart count of pod liveness-http is 0
Mar 26 22:06:12.946: INFO: Restart count of pod e2e-tests-container-probe-556lm/liveness-http is now 1 (14.255726436s elapsed)
Mar 26 22:06:33.326: INFO: Restart count of pod e2e-tests-container-probe-556lm/liveness-http is now 2 (34.635535256s elapsed)
Mar 26 22:06:53.790: INFO: Restart count of pod e2e-tests-container-probe-556lm/liveness-http is now 3 (55.099889009s elapsed)
Mar 26 22:07:12.173: INFO: Restart count of pod e2e-tests-container-probe-556lm/liveness-http is now 4 (1m13.482421698s elapsed)
Mar 26 22:08:24.339: INFO: Restart count of pod e2e-tests-container-probe-556lm/liveness-http is now 5 (2m25.648537288s elapsed)
[1mSTEP[0m: deleting the pod
[AfterEach] [k8s.io] Probing container
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:08:24.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-container-probe-556lm" for this suite.
Mar 26 22:08:30.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:08:31.603: INFO: namespace: e2e-tests-container-probe-556lm, resource: bindings, ignored listing per whitelist
Mar 26 22:08:31.653: INFO: namespace e2e-tests-container-probe-556lm deletion completed in 7.257935281s

[32mâ€¢ [SLOW TEST:156.111 seconds][0m
[k8s.io] Probing container
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Update Demo[0m 
  [1mshould scale a replication controller  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:08:31.654: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating a replication controller
Mar 26 22:08:32.484: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config create -f - --namespace=e2e-tests-kubectl-42whf'
Mar 26 22:08:33.007: INFO: stderr: ""
Mar 26 22:08:33.007: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
[1mSTEP[0m: waiting for all containers in name=update-demo pods to come up.
Mar 26 22:08:33.007: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-42whf'
Mar 26 22:08:33.288: INFO: stderr: ""
Mar 26 22:08:33.288: INFO: stdout: "update-demo-nautilus-kr6zl update-demo-nautilus-rrpc6 "
Mar 26 22:08:33.288: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods update-demo-nautilus-kr6zl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-42whf'
Mar 26 22:08:33.912: INFO: stderr: ""
Mar 26 22:08:33.912: INFO: stdout: ""
Mar 26 22:08:33.912: INFO: update-demo-nautilus-kr6zl is created but not running
Mar 26 22:08:38.912: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-42whf'
Mar 26 22:08:39.166: INFO: stderr: ""
Mar 26 22:08:39.166: INFO: stdout: "update-demo-nautilus-kr6zl update-demo-nautilus-rrpc6 "
Mar 26 22:08:39.166: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods update-demo-nautilus-kr6zl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-42whf'
Mar 26 22:08:39.410: INFO: stderr: ""
Mar 26 22:08:39.410: INFO: stdout: "true"
Mar 26 22:08:39.410: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods update-demo-nautilus-kr6zl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-42whf'
Mar 26 22:08:40.181: INFO: stderr: ""
Mar 26 22:08:40.181: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 26 22:08:40.181: INFO: validating pod update-demo-nautilus-kr6zl
Mar 26 22:08:40.209: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 26 22:08:40.209: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 26 22:08:40.209: INFO: update-demo-nautilus-kr6zl is verified up and running
Mar 26 22:08:40.209: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods update-demo-nautilus-rrpc6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-42whf'
Mar 26 22:08:40.462: INFO: stderr: ""
Mar 26 22:08:40.462: INFO: stdout: "true"
Mar 26 22:08:40.462: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods update-demo-nautilus-rrpc6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-42whf'
Mar 26 22:08:40.691: INFO: stderr: ""
Mar 26 22:08:40.691: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 26 22:08:40.691: INFO: validating pod update-demo-nautilus-rrpc6
Mar 26 22:08:40.718: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 26 22:08:40.718: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 26 22:08:40.718: INFO: update-demo-nautilus-rrpc6 is verified up and running
[1mSTEP[0m: scaling down the replication controller
Mar 26 22:08:40.802: INFO: scanned /home/justinsb for discovery docs: <nil>
Mar 26 22:08:40.802: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-42whf'
Mar 26 22:08:41.145: INFO: stderr: ""
Mar 26 22:08:41.145: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
[1mSTEP[0m: waiting for all containers in name=update-demo pods to come up.
Mar 26 22:08:41.145: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-42whf'
Mar 26 22:08:41.385: INFO: stderr: ""
Mar 26 22:08:41.385: INFO: stdout: "update-demo-nautilus-kr6zl update-demo-nautilus-rrpc6 "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
Mar 26 22:08:46.386: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-42whf'
Mar 26 22:08:46.636: INFO: stderr: ""
Mar 26 22:08:46.636: INFO: stdout: "update-demo-nautilus-kr6zl "
Mar 26 22:08:46.637: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods update-demo-nautilus-kr6zl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-42whf'
Mar 26 22:08:46.870: INFO: stderr: ""
Mar 26 22:08:46.870: INFO: stdout: "true"
Mar 26 22:08:46.870: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods update-demo-nautilus-kr6zl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-42whf'
Mar 26 22:08:47.102: INFO: stderr: ""
Mar 26 22:08:47.102: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 26 22:08:47.102: INFO: validating pod update-demo-nautilus-kr6zl
Mar 26 22:08:47.131: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 26 22:08:47.131: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 26 22:08:47.131: INFO: update-demo-nautilus-kr6zl is verified up and running
[1mSTEP[0m: scaling up the replication controller
Mar 26 22:08:47.220: INFO: scanned /home/justinsb for discovery docs: <nil>
Mar 26 22:08:47.220: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-42whf'
Mar 26 22:08:47.530: INFO: stderr: ""
Mar 26 22:08:47.530: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
[1mSTEP[0m: waiting for all containers in name=update-demo pods to come up.
Mar 26 22:08:47.530: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-42whf'
Mar 26 22:08:48.096: INFO: stderr: ""
Mar 26 22:08:48.097: INFO: stdout: "update-demo-nautilus-kr6zl update-demo-nautilus-qzqjt "
Mar 26 22:08:48.097: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods update-demo-nautilus-kr6zl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-42whf'
Mar 26 22:08:48.877: INFO: stderr: ""
Mar 26 22:08:48.877: INFO: stdout: "true"
Mar 26 22:08:48.877: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods update-demo-nautilus-kr6zl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-42whf'
Mar 26 22:08:49.424: INFO: stderr: ""
Mar 26 22:08:49.424: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 26 22:08:49.424: INFO: validating pod update-demo-nautilus-kr6zl
Mar 26 22:08:49.463: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 26 22:08:49.463: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 26 22:08:49.463: INFO: update-demo-nautilus-kr6zl is verified up and running
Mar 26 22:08:49.463: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods update-demo-nautilus-qzqjt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-42whf'
Mar 26 22:08:50.040: INFO: stderr: ""
Mar 26 22:08:50.041: INFO: stdout: "true"
Mar 26 22:08:50.041: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods update-demo-nautilus-qzqjt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-42whf'
Mar 26 22:08:50.739: INFO: stderr: ""
Mar 26 22:08:50.739: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 26 22:08:50.739: INFO: validating pod update-demo-nautilus-qzqjt
Mar 26 22:08:50.782: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 26 22:08:50.782: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 26 22:08:50.782: INFO: update-demo-nautilus-qzqjt is verified up and running
[1mSTEP[0m: using delete to clean up resources
Mar 26 22:08:50.782: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-42whf'
Mar 26 22:08:51.273: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 26 22:08:51.273: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar 26 22:08:51.273: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-42whf'
Mar 26 22:08:51.546: INFO: stderr: "No resources found.\n"
Mar 26 22:08:51.546: INFO: stdout: ""
Mar 26 22:08:51.546: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods -l name=update-demo --namespace=e2e-tests-kubectl-42whf -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 26 22:08:51.957: INFO: stderr: ""
Mar 26 22:08:51.958: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:08:51.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-42whf" for this suite.
Mar 26 22:09:14.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:09:14.863: INFO: namespace: e2e-tests-kubectl-42whf, resource: bindings, ignored listing per whitelist
Mar 26 22:09:15.185: INFO: namespace e2e-tests-kubectl-42whf deletion completed in 23.19141234s

[32mâ€¢ [SLOW TEST:43.531 seconds][0m
[sig-cli] Kubectl client
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Update Demo
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should scale a replication controller  [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:09:15.185: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-5297b971-5035-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 26 22:09:16.127: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-529bed72-5035-11e9-9bdd-d050998677c2" in namespace "e2e-tests-projected-fs4dx" to be "success or failure"
Mar 26 22:09:16.153: INFO: Pod "pod-projected-configmaps-529bed72-5035-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 26.137478ms
Mar 26 22:09:18.190: INFO: Pod "pod-projected-configmaps-529bed72-5035-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.062997747s
[1mSTEP[0m: Saw pod success
Mar 26 22:09:18.190: INFO: Pod "pod-projected-configmaps-529bed72-5035-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:09:18.227: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-projected-configmaps-529bed72-5035-11e9-9bdd-d050998677c2 container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:09:18.303: INFO: Waiting for pod pod-projected-configmaps-529bed72-5035-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:09:18.331: INFO: Pod pod-projected-configmaps-529bed72-5035-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:09:18.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-fs4dx" for this suite.
Mar 26 22:09:24.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:09:25.933: INFO: namespace: e2e-tests-projected-fs4dx, resource: bindings, ignored listing per whitelist
Mar 26 22:09:25.933: INFO: namespace e2e-tests-projected-fs4dx deletion completed in 7.574319754s

[32mâ€¢ [SLOW TEST:10.748 seconds][0m
[sig-storage] Projected
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35[0m
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould be consumable from pods in volume with mappings [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:09:25.933: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-map-5947e94f-5035-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 26 22:09:27.359: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-594c66e5-5035-11e9-9bdd-d050998677c2" in namespace "e2e-tests-projected-sxcq9" to be "success or failure"
Mar 26 22:09:27.395: INFO: Pod "pod-projected-configmaps-594c66e5-5035-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 36.659256ms
Mar 26 22:09:29.471: INFO: Pod "pod-projected-configmaps-594c66e5-5035-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.111871594s
[1mSTEP[0m: Saw pod success
Mar 26 22:09:29.471: INFO: Pod "pod-projected-configmaps-594c66e5-5035-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:09:29.543: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-projected-configmaps-594c66e5-5035-11e9-9bdd-d050998677c2 container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:09:29.693: INFO: Waiting for pod pod-projected-configmaps-594c66e5-5035-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:09:29.749: INFO: Pod pod-projected-configmaps-594c66e5-5035-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:09:29.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-sxcq9" for this suite.
Mar 26 22:09:36.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:09:37.110: INFO: namespace: e2e-tests-projected-sxcq9, resource: bindings, ignored listing per whitelist
Mar 26 22:09:37.808: INFO: namespace e2e-tests-projected-sxcq9 deletion completed in 7.993620004s

[32mâ€¢ [SLOW TEST:11.875 seconds][0m
[sig-storage] Projected
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35[0m
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-network] DNS[0m 
  [1mshould provide DNS for services  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-network] DNS
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:09:37.808: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename dns
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a test headless service
[1mSTEP[0m: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-9tv5h A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-9tv5h;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-9tv5h A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-9tv5h;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-9tv5h.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-9tv5h.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-9tv5h.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-9tv5h.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-9tv5h.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-9tv5h.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-9tv5h.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9tv5h.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-9tv5h.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-9tv5h.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-9tv5h.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-9tv5h.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-9tv5h.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 160.204.68.100.in-addr.arpa. PTR)" && echo OK > /results/100.68.204.160_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 160.204.68.100.in-addr.arpa. PTR)" && echo OK > /results/100.68.204.160_tcp@PTR;sleep 1; done

[1mSTEP[0m: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-9tv5h A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-9tv5h;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-9tv5h A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-9tv5h;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-9tv5h.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-9tv5h.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-9tv5h.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-9tv5h.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-9tv5h.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-9tv5h.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-9tv5h.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9tv5h.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-9tv5h.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-9tv5h.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-9tv5h.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-9tv5h.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-9tv5h.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 160.204.68.100.in-addr.arpa. PTR)" && echo OK > /results/100.68.204.160_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 160.204.68.100.in-addr.arpa. PTR)" && echo OK > /results/100.68.204.160_tcp@PTR;sleep 1; done

[1mSTEP[0m: creating a pod to probe DNS
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: retrieving the pod
[1mSTEP[0m: looking for the results for each expected name from probers
Mar 26 22:09:51.684: INFO: DNS probes using e2e-tests-dns-9tv5h/dns-test-601cab67-5035-11e9-9bdd-d050998677c2 succeeded

[1mSTEP[0m: deleting the pod
[1mSTEP[0m: deleting the test service
[1mSTEP[0m: deleting the test headless service
[AfterEach] [sig-network] DNS
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:09:51.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-dns-9tv5h" for this suite.
Mar 26 22:09:57.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:09:58.546: INFO: namespace: e2e-tests-dns-9tv5h, resource: bindings, ignored listing per whitelist
Mar 26 22:10:00.082: INFO: namespace e2e-tests-dns-9tv5h deletion completed in 8.267422311s

[32mâ€¢ [SLOW TEST:22.274 seconds][0m
[sig-network] DNS
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22[0m
  should provide DNS for services  [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould set mode on item file [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:10:00.082: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 26 22:10:01.892: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6de3dabc-5035-11e9-9bdd-d050998677c2" in namespace "e2e-tests-projected-mqc9r" to be "success or failure"
Mar 26 22:10:01.918: INFO: Pod "downwardapi-volume-6de3dabc-5035-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.471586ms
Mar 26 22:10:03.992: INFO: Pod "downwardapi-volume-6de3dabc-5035-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.100236257s
[1mSTEP[0m: Saw pod success
Mar 26 22:10:03.993: INFO: Pod "downwardapi-volume-6de3dabc-5035-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:10:04.072: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod downwardapi-volume-6de3dabc-5035-11e9-9bdd-d050998677c2 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:10:04.224: INFO: Waiting for pod downwardapi-volume-6de3dabc-5035-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:10:04.285: INFO: Pod downwardapi-volume-6de3dabc-5035-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:10:04.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-mqc9r" for this suite.
Mar 26 22:10:10.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:10:12.935: INFO: namespace: e2e-tests-projected-mqc9r, resource: bindings, ignored listing per whitelist
Mar 26 22:10:14.488: INFO: namespace e2e-tests-projected-mqc9r deletion completed in 10.155639871s

[32mâ€¢ [SLOW TEST:14.406 seconds][0m
[sig-storage] Projected
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35[0m
  should set mode on item file [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Docker Containers[0m 
  [1mshould be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Docker Containers
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:10:14.489: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename containers
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test override arguments
Mar 26 22:10:17.270: INFO: Waiting up to 5m0s for pod "client-containers-7704a1b4-5035-11e9-9bdd-d050998677c2" in namespace "e2e-tests-containers-hmxfc" to be "success or failure"
Mar 26 22:10:17.361: INFO: Pod "client-containers-7704a1b4-5035-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 90.503667ms
Mar 26 22:10:19.454: INFO: Pod "client-containers-7704a1b4-5035-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.183877421s
[1mSTEP[0m: Saw pod success
Mar 26 22:10:19.454: INFO: Pod "client-containers-7704a1b4-5035-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:10:19.557: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod client-containers-7704a1b4-5035-11e9-9bdd-d050998677c2 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:10:19.791: INFO: Waiting for pod client-containers-7704a1b4-5035-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:10:19.906: INFO: Pod client-containers-7704a1b4-5035-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:10:19.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-containers-hmxfc" for this suite.
Mar 26 22:10:26.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:10:27.952: INFO: namespace: e2e-tests-containers-hmxfc, resource: bindings, ignored listing per whitelist
Mar 26 22:10:29.846: INFO: namespace e2e-tests-containers-hmxfc deletion completed in 9.811971901s

[32mâ€¢ [SLOW TEST:15.357 seconds][0m
[k8s.io] Docker Containers
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Networking[0m [90mGranular Checks: Pods[0m 
  [1mshould function for node-pod communication: udp [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-network] Networking
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:10:29.846: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename pod-network-test
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Performing setup for networking test in namespace e2e-tests-pod-network-test-csjhr
[1mSTEP[0m: creating a selector
[1mSTEP[0m: Creating the service pods in kubernetes
Mar 26 22:10:33.785: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[1mSTEP[0m: Creating test pods
Mar 26 22:10:56.545: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 100.96.2.102 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-csjhr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 22:10:56.545: INFO: >>> kubeConfig: /home/justinsb/.kube/config
Mar 26 22:10:57.862: INFO: Found all expected endpoints: [netserver-0]
Mar 26 22:10:57.911: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 100.96.1.104 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-csjhr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 22:10:57.911: INFO: >>> kubeConfig: /home/justinsb/.kube/config
Mar 26 22:10:59.416: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:10:59.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pod-network-test-csjhr" for this suite.
Mar 26 22:11:21.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:11:22.003: INFO: namespace: e2e-tests-pod-network-test-csjhr, resource: bindings, ignored listing per whitelist
Mar 26 22:11:22.991: INFO: namespace e2e-tests-pod-network-test-csjhr deletion completed in 23.536600526s

[32mâ€¢ [SLOW TEST:53.145 seconds][0m
[sig-network] Networking
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25[0m
  Granular Checks: Pods
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28[0m
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Variable Expansion[0m 
  [1mshould allow composing env vars into new env vars [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Variable Expansion
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:11:22.991: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename var-expansion
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test env composition
Mar 26 22:11:24.074: INFO: Waiting up to 5m0s for pod "var-expansion-9edfbf65-5035-11e9-9bdd-d050998677c2" in namespace "e2e-tests-var-expansion-8gw42" to be "success or failure"
Mar 26 22:11:24.100: INFO: Pod "var-expansion-9edfbf65-5035-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.637961ms
Mar 26 22:11:26.209: INFO: Pod "var-expansion-9edfbf65-5035-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.13406767s
[1mSTEP[0m: Saw pod success
Mar 26 22:11:26.209: INFO: Pod "var-expansion-9edfbf65-5035-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:11:26.333: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod var-expansion-9edfbf65-5035-11e9-9bdd-d050998677c2 container dapi-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:11:26.587: INFO: Waiting for pod var-expansion-9edfbf65-5035-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:11:26.734: INFO: Pod var-expansion-9edfbf65-5035-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:11:26.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-var-expansion-8gw42" for this suite.
Mar 26 22:11:33.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:11:35.626: INFO: namespace: e2e-tests-var-expansion-8gw42, resource: bindings, ignored listing per whitelist
Mar 26 22:11:36.315: INFO: namespace e2e-tests-var-expansion-8gw42 deletion completed in 9.461004911s

[32mâ€¢ [SLOW TEST:13.324 seconds][0m
[k8s.io] Variable Expansion
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl replace[0m 
  [1mshould update a single-container pod's image  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:11:36.315: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: running the image docker.io/library/nginx:1.14-alpine
Mar 26 22:11:39.215: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-b86kt'
Mar 26 22:11:39.842: INFO: stderr: ""
Mar 26 22:11:39.842: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
[1mSTEP[0m: verifying the pod e2e-test-nginx-pod is running
[1mSTEP[0m: verifying the pod e2e-test-nginx-pod was created
Mar 26 22:11:44.943: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-b86kt -o json'
Mar 26 22:11:45.182: INFO: stderr: ""
Mar 26 22:11:45.182: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-03-27T02:11:39Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-b86kt\",\n        \"resourceVersion\": \"18118\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-b86kt/pods/e2e-test-nginx-pod\",\n        \"uid\": \"a83ba4d5-5035-11e9-8eb3-023bf32bf132\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-9r24v\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"ip-172-20-56-226.us-east-2.compute.internal\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-9r24v\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-9r24v\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-27T02:11:39Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-27T02:11:40Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-27T02:11:40Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-27T02:11:39Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://aa18961c3a11c1b767db94ef959eceb7aedb972ca8e64338b61fb6b7e17d2ec8\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-03-27T02:11:40Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.20.56.226\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.96.2.106\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-03-27T02:11:39Z\"\n    }\n}\n"
[1mSTEP[0m: replace the image in the pod
Mar 26 22:11:45.182: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config replace -f - --namespace=e2e-tests-kubectl-b86kt'
Mar 26 22:11:45.763: INFO: stderr: ""
Mar 26 22:11:45.763: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
[1mSTEP[0m: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Mar 26 22:11:45.832: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-b86kt'
Mar 26 22:11:49.059: INFO: stderr: ""
Mar 26 22:11:49.059: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:11:49.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-b86kt" for this suite.
Mar 26 22:11:55.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:11:57.209: INFO: namespace: e2e-tests-kubectl-b86kt, resource: bindings, ignored listing per whitelist
Mar 26 22:11:58.170: INFO: namespace e2e-tests-kubectl-b86kt deletion completed in 9.049593595s

[32mâ€¢ [SLOW TEST:21.855 seconds][0m
[sig-cli] Kubectl client
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl replace
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should update a single-container pod's image  [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould contain environment variables for services [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Pods
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:11:58.171: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 22:12:03.742: INFO: Waiting up to 5m0s for pod "client-envvars-b6809b36-5035-11e9-9bdd-d050998677c2" in namespace "e2e-tests-pods-7pqch" to be "success or failure"
Mar 26 22:12:03.796: INFO: Pod "client-envvars-b6809b36-5035-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 53.651659ms
Mar 26 22:12:05.877: INFO: Pod "client-envvars-b6809b36-5035-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.134593078s
[1mSTEP[0m: Saw pod success
Mar 26 22:12:05.877: INFO: Pod "client-envvars-b6809b36-5035-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:12:05.946: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod client-envvars-b6809b36-5035-11e9-9bdd-d050998677c2 container env3cont: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:12:06.100: INFO: Waiting for pod client-envvars-b6809b36-5035-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:12:06.165: INFO: Pod client-envvars-b6809b36-5035-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [k8s.io] Pods
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:12:06.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pods-7pqch" for this suite.
Mar 26 22:12:56.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:12:57.467: INFO: namespace: e2e-tests-pods-7pqch, resource: bindings, ignored listing per whitelist
Mar 26 22:12:57.559: INFO: namespace e2e-tests-pods-7pqch deletion completed in 51.334033182s

[32mâ€¢ [SLOW TEST:59.389 seconds][0m
[k8s.io] Pods
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should contain environment variables for services [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl label[0m 
  [1mshould update the label on a resource  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:12:57.559: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
[1mSTEP[0m: creating the pod
Mar 26 22:12:58.594: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config create -f - --namespace=e2e-tests-kubectl-27xjm'
Mar 26 22:12:59.131: INFO: stderr: ""
Mar 26 22:12:59.131: INFO: stdout: "pod/pause created\n"
Mar 26 22:12:59.131: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Mar 26 22:12:59.131: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-27xjm" to be "running and ready"
Mar 26 22:12:59.157: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 25.50177ms
Mar 26 22:13:01.183: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.051710378s
Mar 26 22:13:01.183: INFO: Pod "pause" satisfied condition "running and ready"
Mar 26 22:13:01.183: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: adding the label testing-label with value testing-label-value to a pod
Mar 26 22:13:01.183: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-27xjm'
Mar 26 22:13:01.879: INFO: stderr: ""
Mar 26 22:13:01.879: INFO: stdout: "pod/pause labeled\n"
[1mSTEP[0m: verifying the pod has the label testing-label with the value testing-label-value
Mar 26 22:13:01.879: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pod pause -L testing-label --namespace=e2e-tests-kubectl-27xjm'
Mar 26 22:13:02.133: INFO: stderr: ""
Mar 26 22:13:02.133: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
[1mSTEP[0m: removing the label testing-label of a pod
Mar 26 22:13:02.133: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config label pods pause testing-label- --namespace=e2e-tests-kubectl-27xjm'
Mar 26 22:13:02.409: INFO: stderr: ""
Mar 26 22:13:02.409: INFO: stdout: "pod/pause labeled\n"
[1mSTEP[0m: verifying the pod doesn't have the label testing-label
Mar 26 22:13:02.409: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pod pause -L testing-label --namespace=e2e-tests-kubectl-27xjm'
Mar 26 22:13:02.697: INFO: stderr: ""
Mar 26 22:13:02.697: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
[1mSTEP[0m: using delete to clean up resources
Mar 26 22:13:02.697: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-27xjm'
Mar 26 22:13:03.143: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 26 22:13:03.143: INFO: stdout: "pod \"pause\" force deleted\n"
Mar 26 22:13:03.143: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-27xjm'
Mar 26 22:13:03.770: INFO: stderr: "No resources found.\n"
Mar 26 22:13:03.770: INFO: stdout: ""
Mar 26 22:13:03.770: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods -l name=pause --namespace=e2e-tests-kubectl-27xjm -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 26 22:13:04.016: INFO: stderr: ""
Mar 26 22:13:04.016: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:13:04.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-27xjm" for this suite.
Mar 26 22:13:10.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:13:10.472: INFO: namespace: e2e-tests-kubectl-27xjm, resource: bindings, ignored listing per whitelist
Mar 26 22:13:11.133: INFO: namespace e2e-tests-kubectl-27xjm deletion completed in 7.090500224s

[32mâ€¢ [SLOW TEST:13.574 seconds][0m
[sig-cli] Kubectl client
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl label
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should update the label on a resource  [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:13:11.133: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename gc
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: create the rc
[1mSTEP[0m: delete the rc
[1mSTEP[0m: wait for the rc to be deleted
[1mSTEP[0m: Gathering metrics
W0326 22:13:18.235664    2026 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 26 22:13:18.235: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:13:18.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-gc-czqj7" for this suite.
Mar 26 22:13:24.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:13:25.092: INFO: namespace: e2e-tests-gc-czqj7, resource: bindings, ignored listing per whitelist
Mar 26 22:13:25.454: INFO: namespace e2e-tests-gc-czqj7 deletion completed in 7.191879627s

[32mâ€¢ [SLOW TEST:14.321 seconds][0m
[sig-api-machinery] Garbage collector
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Secrets
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:13:25.454: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating secret with name secret-test-map-e803b4b3-5035-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume secrets
Mar 26 22:13:26.971: INFO: Waiting up to 5m0s for pod "pod-secrets-e815c2b2-5035-11e9-9bdd-d050998677c2" in namespace "e2e-tests-secrets-qsdl6" to be "success or failure"
Mar 26 22:13:27.046: INFO: Pod "pod-secrets-e815c2b2-5035-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 75.341856ms
Mar 26 22:13:29.097: INFO: Pod "pod-secrets-e815c2b2-5035-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.125436848s
[1mSTEP[0m: Saw pod success
Mar 26 22:13:29.097: INFO: Pod "pod-secrets-e815c2b2-5035-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:13:29.131: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-secrets-e815c2b2-5035-11e9-9bdd-d050998677c2 container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:13:29.195: INFO: Waiting for pod pod-secrets-e815c2b2-5035-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:13:29.223: INFO: Pod pod-secrets-e815c2b2-5035-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Secrets
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:13:29.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-secrets-qsdl6" for this suite.
Mar 26 22:13:35.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:13:36.344: INFO: namespace: e2e-tests-secrets-qsdl6, resource: bindings, ignored listing per whitelist
Mar 26 22:13:36.344: INFO: namespace e2e-tests-secrets-qsdl6 deletion completed in 7.090938482s

[32mâ€¢ [SLOW TEST:10.890 seconds][0m
[sig-storage] Secrets
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34[0m
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl run --rm job[0m 
  [1mshould create a job from an image, then delete the job  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:13:36.344: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: executing a command with run --rm and attach with stdin
Mar 26 22:13:37.504: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config --namespace=e2e-tests-kubectl-7db7v run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Mar 26 22:13:40.252: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Mar 26 22:13:40.252: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
[1mSTEP[0m: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:13:42.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-7db7v" for this suite.
Mar 26 22:13:48.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:13:49.703: INFO: namespace: e2e-tests-kubectl-7db7v, resource: bindings, ignored listing per whitelist
Mar 26 22:13:49.736: INFO: namespace e2e-tests-kubectl-7db7v deletion completed in 7.405904861s

[32mâ€¢ [SLOW TEST:13.392 seconds][0m
[sig-cli] Kubectl client
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl run --rm job
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should create a job from an image, then delete the job  [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould set DefaultMode on files [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:13:49.737: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 26 22:13:50.871: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f65e986f-5035-11e9-9bdd-d050998677c2" in namespace "e2e-tests-projected-r8pvz" to be "success or failure"
Mar 26 22:13:50.897: INFO: Pod "downwardapi-volume-f65e986f-5035-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 26.309244ms
Mar 26 22:13:52.927: INFO: Pod "downwardapi-volume-f65e986f-5035-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.056188226s
[1mSTEP[0m: Saw pod success
Mar 26 22:13:52.927: INFO: Pod "downwardapi-volume-f65e986f-5035-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:13:52.953: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod downwardapi-volume-f65e986f-5035-11e9-9bdd-d050998677c2 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:13:53.015: INFO: Waiting for pod downwardapi-volume-f65e986f-5035-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:13:53.041: INFO: Pod downwardapi-volume-f65e986f-5035-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:13:53.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-r8pvz" for this suite.
Mar 26 22:13:59.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:14:00.030: INFO: namespace: e2e-tests-projected-r8pvz, resource: bindings, ignored listing per whitelist
Mar 26 22:14:00.632: INFO: namespace e2e-tests-projected-r8pvz deletion completed in 7.564638317s

[32mâ€¢ [SLOW TEST:10.895 seconds][0m
[sig-storage] Projected
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35[0m
  should set DefaultMode on files [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Networking[0m [90mGranular Checks: Pods[0m 
  [1mshould function for intra-pod communication: http [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-network] Networking
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:14:00.632: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename pod-network-test
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Performing setup for networking test in namespace e2e-tests-pod-network-test-4g9dd
[1mSTEP[0m: creating a selector
[1mSTEP[0m: Creating the service pods in kubernetes
Mar 26 22:14:01.900: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[1mSTEP[0m: Creating test pods
Mar 26 22:14:24.705: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.2.122:8080/dial?request=hostName&protocol=http&host=100.96.1.110&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-4g9dd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 22:14:24.705: INFO: >>> kubeConfig: /home/justinsb/.kube/config
Mar 26 22:14:25.120: INFO: Waiting for endpoints: map[]
Mar 26 22:14:25.169: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.2.122:8080/dial?request=hostName&protocol=http&host=100.96.2.121&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-4g9dd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 22:14:25.169: INFO: >>> kubeConfig: /home/justinsb/.kube/config
Mar 26 22:14:25.475: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:14:25.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pod-network-test-4g9dd" for this suite.
Mar 26 22:14:47.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:14:49.075: INFO: namespace: e2e-tests-pod-network-test-4g9dd, resource: bindings, ignored listing per whitelist
Mar 26 22:14:52.935: INFO: namespace e2e-tests-pod-network-test-4g9dd deletion completed in 27.412468196s

[32mâ€¢ [SLOW TEST:52.303 seconds][0m
[sig-network] Networking
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25[0m
  Granular Checks: Pods
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28[0m
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Proxy[0m [90mversion v1[0m 
  [1mshould proxy through a service and a pod  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] version v1
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:14:52.935: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename proxy
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: starting an echo server on multiple ports
[1mSTEP[0m: creating replication controller proxy-service-nnvch in namespace e2e-tests-proxy-dqkhc
I0326 22:14:55.524788    2026 runners.go:180] Created replication controller with name: proxy-service-nnvch, namespace: e2e-tests-proxy-dqkhc, replica count: 1
I0326 22:14:56.625131    2026 runners.go:180] proxy-service-nnvch Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0326 22:14:57.625264    2026 runners.go:180] proxy-service-nnvch Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 26 22:14:57.764: INFO: setup took 2.381283718s, starting test cases
[1mSTEP[0m: running 16 cases, 20 attempts per case, 320 total attempts
Mar 26 22:14:57.919: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:162/proxy/: bar (200; 154.922064ms)
Mar 26 22:14:57.923: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname1/proxy/: foo (200; 158.686038ms)
Mar 26 22:14:57.923: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname2/proxy/: bar (200; 158.711366ms)
Mar 26 22:14:57.927: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/... (200; 162.925843ms)
Mar 26 22:14:57.928: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:160/proxy/: foo (200; 163.680308ms)
Mar 26 22:14:57.928: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname1/proxy/: foo (200; 163.659839ms)
Mar 26 22:14:57.928: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:160/proxy/: foo (200; 163.764583ms)
Mar 26 22:14:57.928: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:162/proxy/: bar (200; 163.763522ms)
Mar 26 22:14:57.933: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/rewriteme"... (200; 168.665667ms)
Mar 26 22:14:57.933: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/rewri... (200; 168.716036ms)
Mar 26 22:14:57.934: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname2/proxy/: bar (200; 169.589763ms)
Mar 26 22:14:57.934: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:460/proxy/: tls baz (200; 169.758443ms)
Mar 26 22:14:57.934: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname1/proxy/: tls baz (200; 169.803995ms)
Mar 26 22:14:57.934: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:462/proxy/: tls qux (200; 170.273238ms)
Mar 26 22:14:57.934: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname2/proxy/: tls qux (200; 170.277867ms)
Mar 26 22:14:57.934: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/... (200; 170.289255ms)
Mar 26 22:14:58.107: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:460/proxy/: tls baz (200; 172.534555ms)
Mar 26 22:14:58.108: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/rewri... (200; 173.44571ms)
Mar 26 22:14:58.108: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:162/proxy/: bar (200; 173.72578ms)
Mar 26 22:14:58.111: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/rewriteme"... (200; 176.686364ms)
Mar 26 22:14:58.111: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/... (200; 176.901965ms)
Mar 26 22:14:58.112: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:160/proxy/: foo (200; 177.107735ms)
Mar 26 22:14:58.113: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:162/proxy/: bar (200; 178.459255ms)
Mar 26 22:14:58.113: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/... (200; 178.632068ms)
Mar 26 22:14:58.114: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname2/proxy/: bar (200; 179.363415ms)
Mar 26 22:14:58.115: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname1/proxy/: tls baz (200; 180.616261ms)
Mar 26 22:14:58.115: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname1/proxy/: foo (200; 180.835128ms)
Mar 26 22:14:58.116: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname2/proxy/: bar (200; 181.140196ms)
Mar 26 22:14:58.116: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname1/proxy/: foo (200; 181.285166ms)
Mar 26 22:14:58.117: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname2/proxy/: tls qux (200; 182.148693ms)
Mar 26 22:14:58.117: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:462/proxy/: tls qux (200; 182.243569ms)
Mar 26 22:14:58.117: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:160/proxy/: foo (200; 182.513781ms)
Mar 26 22:14:58.285: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:162/proxy/: bar (200; 168.060248ms)
Mar 26 22:14:58.286: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:160/proxy/: foo (200; 168.377596ms)
Mar 26 22:14:58.286: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/... (200; 168.408896ms)
Mar 26 22:14:58.286: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:460/proxy/: tls baz (200; 169.119371ms)
Mar 26 22:14:58.287: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:162/proxy/: bar (200; 169.456391ms)
Mar 26 22:14:58.290: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/... (200; 172.800165ms)
Mar 26 22:14:58.294: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname1/proxy/: foo (200; 176.637823ms)
Mar 26 22:14:58.295: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/rewri... (200; 178.117158ms)
Mar 26 22:14:58.296: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname1/proxy/: tls baz (200; 178.711466ms)
Mar 26 22:14:58.296: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname2/proxy/: bar (200; 178.817098ms)
Mar 26 22:14:58.296: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:160/proxy/: foo (200; 178.80475ms)
Mar 26 22:14:58.296: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname2/proxy/: bar (200; 179.054094ms)
Mar 26 22:14:58.297: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:462/proxy/: tls qux (200; 179.682013ms)
Mar 26 22:14:58.297: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/rewriteme"... (200; 179.668889ms)
Mar 26 22:14:58.297: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname2/proxy/: tls qux (200; 179.72845ms)
Mar 26 22:14:58.297: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname1/proxy/: foo (200; 179.851894ms)
Mar 26 22:14:58.467: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:462/proxy/: tls qux (200; 170.252016ms)
Mar 26 22:14:58.470: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/... (200; 172.898715ms)
Mar 26 22:14:58.470: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:162/proxy/: bar (200; 173.101317ms)
Mar 26 22:14:58.471: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/rewriteme"... (200; 173.494548ms)
Mar 26 22:14:58.471: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:162/proxy/: bar (200; 173.630126ms)
Mar 26 22:14:58.471: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:460/proxy/: tls baz (200; 173.619783ms)
Mar 26 22:14:58.471: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname2/proxy/: bar (200; 174.107462ms)
Mar 26 22:14:58.471: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:160/proxy/: foo (200; 174.267828ms)
Mar 26 22:14:58.471: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname1/proxy/: foo (200; 174.314514ms)
Mar 26 22:14:58.472: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname2/proxy/: tls qux (200; 174.46081ms)
Mar 26 22:14:58.472: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname2/proxy/: bar (200; 175.09123ms)
Mar 26 22:14:58.472: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname1/proxy/: foo (200; 175.121556ms)
Mar 26 22:14:58.472: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:160/proxy/: foo (200; 175.415074ms)
Mar 26 22:14:58.473: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/rewri... (200; 175.65772ms)
Mar 26 22:14:58.473: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/... (200; 175.737311ms)
Mar 26 22:14:58.473: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname1/proxy/: tls baz (200; 175.906064ms)
Mar 26 22:14:58.654: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/... (200; 180.528655ms)
Mar 26 22:14:58.654: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:160/proxy/: foo (200; 180.511451ms)
Mar 26 22:14:58.654: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:460/proxy/: tls baz (200; 180.745814ms)
Mar 26 22:14:58.654: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/rewri... (200; 181.263419ms)
Mar 26 22:14:58.655: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:160/proxy/: foo (200; 181.283329ms)
Mar 26 22:14:58.655: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname2/proxy/: bar (200; 181.656442ms)
Mar 26 22:14:58.656: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:462/proxy/: tls qux (200; 182.416635ms)
Mar 26 22:14:58.656: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:162/proxy/: bar (200; 182.65475ms)
Mar 26 22:14:58.656: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname2/proxy/: tls qux (200; 182.944623ms)
Mar 26 22:14:58.656: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname1/proxy/: tls baz (200; 183.11584ms)
Mar 26 22:14:58.657: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/... (200; 183.466085ms)
Mar 26 22:14:58.657: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/rewriteme"... (200; 183.627894ms)
Mar 26 22:14:58.657: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname1/proxy/: foo (200; 183.925994ms)
Mar 26 22:14:58.657: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:162/proxy/: bar (200; 184.150692ms)
Mar 26 22:14:58.658: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname2/proxy/: bar (200; 184.419459ms)
Mar 26 22:14:58.658: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname1/proxy/: foo (200; 184.659577ms)
Mar 26 22:14:58.817: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/... (200; 158.744879ms)
Mar 26 22:14:58.819: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/... (200; 161.37868ms)
Mar 26 22:14:58.819: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:160/proxy/: foo (200; 161.417781ms)
Mar 26 22:14:58.819: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:162/proxy/: bar (200; 161.456494ms)
Mar 26 22:14:58.820: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:462/proxy/: tls qux (200; 161.782589ms)
Mar 26 22:14:58.820: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/rewri... (200; 161.764557ms)
Mar 26 22:14:58.820: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:160/proxy/: foo (200; 162.273933ms)
Mar 26 22:14:58.821: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/rewriteme"... (200; 163.102791ms)
Mar 26 22:14:58.821: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:162/proxy/: bar (200; 163.353437ms)
Mar 26 22:14:58.821: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:460/proxy/: tls baz (200; 163.422031ms)
Mar 26 22:14:58.822: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname1/proxy/: tls baz (200; 163.726458ms)
Mar 26 22:14:58.822: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname1/proxy/: foo (200; 164.264041ms)
Mar 26 22:14:58.822: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname2/proxy/: bar (200; 164.388014ms)
Mar 26 22:14:58.822: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname2/proxy/: tls qux (200; 164.500227ms)
Mar 26 22:14:58.823: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname2/proxy/: bar (200; 164.74705ms)
Mar 26 22:14:58.823: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname1/proxy/: foo (200; 164.777404ms)
Mar 26 22:14:58.970: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/... (200; 147.396346ms)
Mar 26 22:14:58.971: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:160/proxy/: foo (200; 147.909274ms)
Mar 26 22:14:58.971: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname1/proxy/: foo (200; 148.028166ms)
Mar 26 22:14:58.972: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:162/proxy/: bar (200; 148.904143ms)
Mar 26 22:14:58.972: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:460/proxy/: tls baz (200; 148.978413ms)
Mar 26 22:14:58.972: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/rewriteme"... (200; 149.316729ms)
Mar 26 22:14:58.972: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:462/proxy/: tls qux (200; 149.388283ms)
Mar 26 22:14:58.972: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/... (200; 149.669602ms)
Mar 26 22:14:58.973: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/rewri... (200; 150.152178ms)
Mar 26 22:14:58.973: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:160/proxy/: foo (200; 150.422616ms)
Mar 26 22:14:58.974: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:162/proxy/: bar (200; 150.735631ms)
Mar 26 22:14:58.976: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname2/proxy/: bar (200; 153.123244ms)
Mar 26 22:14:58.976: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname2/proxy/: tls qux (200; 153.160689ms)
Mar 26 22:14:58.976: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname2/proxy/: bar (200; 153.23422ms)
Mar 26 22:14:58.976: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname1/proxy/: foo (200; 153.342869ms)
Mar 26 22:14:58.976: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname1/proxy/: tls baz (200; 153.464479ms)
Mar 26 22:14:59.100: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:462/proxy/: tls qux (200; 123.836247ms)
Mar 26 22:14:59.101: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/rewriteme"... (200; 124.400401ms)
Mar 26 22:14:59.101: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/... (200; 124.601643ms)
Mar 26 22:14:59.101: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:162/proxy/: bar (200; 124.849044ms)
Mar 26 22:14:59.102: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/rewri... (200; 125.922204ms)
Mar 26 22:14:59.102: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:160/proxy/: foo (200; 126.040845ms)
Mar 26 22:14:59.103: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:162/proxy/: bar (200; 126.309599ms)
Mar 26 22:14:59.103: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname2/proxy/: tls qux (200; 127.063483ms)
Mar 26 22:14:59.104: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname2/proxy/: bar (200; 127.366253ms)
Mar 26 22:14:59.106: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname1/proxy/: foo (200; 129.172948ms)
Mar 26 22:14:59.106: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:160/proxy/: foo (200; 129.526141ms)
Mar 26 22:14:59.106: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/... (200; 129.54611ms)
Mar 26 22:14:59.106: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname2/proxy/: bar (200; 130.057391ms)
Mar 26 22:14:59.106: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname1/proxy/: foo (200; 130.090942ms)
Mar 26 22:14:59.107: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname1/proxy/: tls baz (200; 130.288136ms)
Mar 26 22:14:59.107: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:460/proxy/: tls baz (200; 130.291231ms)
Mar 26 22:14:59.222: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:160/proxy/: foo (200; 114.943137ms)
Mar 26 22:14:59.222: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:160/proxy/: foo (200; 115.181715ms)
Mar 26 22:14:59.222: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/... (200; 115.794011ms)
Mar 26 22:14:59.222: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/rewri... (200; 115.777402ms)
Mar 26 22:14:59.223: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname2/proxy/: bar (200; 115.898386ms)
Mar 26 22:14:59.223: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:462/proxy/: tls qux (200; 116.352402ms)
Mar 26 22:14:59.224: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/rewriteme"... (200; 116.937141ms)
Mar 26 22:14:59.224: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:162/proxy/: bar (200; 117.110868ms)
Mar 26 22:14:59.224: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname2/proxy/: bar (200; 117.458305ms)
Mar 26 22:14:59.225: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname1/proxy/: foo (200; 118.112057ms)
Mar 26 22:14:59.225: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname1/proxy/: foo (200; 118.808226ms)
Mar 26 22:14:59.227: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:460/proxy/: tls baz (200; 120.326199ms)
Mar 26 22:14:59.228: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/... (200; 121.235259ms)
Mar 26 22:14:59.228: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:162/proxy/: bar (200; 121.246426ms)
Mar 26 22:14:59.228: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname2/proxy/: tls qux (200; 121.504455ms)
Mar 26 22:14:59.233: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname1/proxy/: tls baz (200; 125.913978ms)
Mar 26 22:14:59.335: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:162/proxy/: bar (200; 102.730976ms)
Mar 26 22:14:59.335: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:160/proxy/: foo (200; 102.761724ms)
Mar 26 22:14:59.336: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/rewriteme"... (200; 102.935546ms)
Mar 26 22:14:59.336: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/... (200; 103.154936ms)
Mar 26 22:14:59.336: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname1/proxy/: foo (200; 103.642103ms)
Mar 26 22:14:59.336: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname1/proxy/: foo (200; 103.720478ms)
Mar 26 22:14:59.337: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname2/proxy/: tls qux (200; 103.863843ms)
Mar 26 22:14:59.338: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:460/proxy/: tls baz (200; 105.247165ms)
Mar 26 22:14:59.338: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:160/proxy/: foo (200; 105.218449ms)
Mar 26 22:14:59.338: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:462/proxy/: tls qux (200; 105.370723ms)
Mar 26 22:14:59.338: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname1/proxy/: tls baz (200; 105.391126ms)
Mar 26 22:14:59.338: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname2/proxy/: bar (200; 105.445492ms)
Mar 26 22:14:59.338: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:162/proxy/: bar (200; 105.555314ms)
Mar 26 22:14:59.339: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/rewri... (200; 105.688014ms)
Mar 26 22:14:59.339: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname2/proxy/: bar (200; 105.798515ms)
Mar 26 22:14:59.339: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/... (200; 105.843211ms)
Mar 26 22:14:59.443: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:160/proxy/: foo (200; 104.606004ms)
Mar 26 22:14:59.444: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:162/proxy/: bar (200; 105.472765ms)
Mar 26 22:14:59.445: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/... (200; 106.125166ms)
Mar 26 22:14:59.445: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/rewriteme"... (200; 106.238852ms)
Mar 26 22:14:59.445: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:160/proxy/: foo (200; 106.467001ms)
Mar 26 22:14:59.445: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/rewri... (200; 106.567219ms)
Mar 26 22:14:59.446: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:462/proxy/: tls qux (200; 106.956312ms)
Mar 26 22:14:59.446: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/... (200; 107.430281ms)
Mar 26 22:14:59.446: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:460/proxy/: tls baz (200; 107.452165ms)
Mar 26 22:14:59.446: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:162/proxy/: bar (200; 107.499128ms)
Mar 26 22:14:59.446: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname1/proxy/: foo (200; 107.770463ms)
Mar 26 22:14:59.447: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname1/proxy/: foo (200; 108.100204ms)
Mar 26 22:14:59.447: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname2/proxy/: tls qux (200; 108.169944ms)
Mar 26 22:14:59.447: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname2/proxy/: bar (200; 108.169971ms)
Mar 26 22:14:59.447: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname1/proxy/: tls baz (200; 108.501071ms)
Mar 26 22:14:59.447: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname2/proxy/: bar (200; 108.54532ms)
Mar 26 22:14:59.565: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:462/proxy/: tls qux (200; 117.28407ms)
Mar 26 22:14:59.565: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:460/proxy/: tls baz (200; 117.282673ms)
Mar 26 22:14:59.566: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/rewriteme"... (200; 118.750773ms)
Mar 26 22:14:59.573: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/rewri... (200; 126.028883ms)
Mar 26 22:14:59.574: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname1/proxy/: foo (200; 126.522509ms)
Mar 26 22:14:59.574: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname2/proxy/: bar (200; 126.543745ms)
Mar 26 22:14:59.574: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname1/proxy/: foo (200; 126.491122ms)
Mar 26 22:14:59.574: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/... (200; 126.698068ms)
Mar 26 22:14:59.575: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname2/proxy/: bar (200; 127.331187ms)
Mar 26 22:14:59.575: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:160/proxy/: foo (200; 127.875429ms)
Mar 26 22:14:59.576: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:162/proxy/: bar (200; 128.175413ms)
Mar 26 22:14:59.576: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:162/proxy/: bar (200; 129.153063ms)
Mar 26 22:14:59.577: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:160/proxy/: foo (200; 129.894351ms)
Mar 26 22:14:59.577: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/... (200; 129.947659ms)
Mar 26 22:14:59.578: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname2/proxy/: tls qux (200; 130.741391ms)
Mar 26 22:14:59.578: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname1/proxy/: tls baz (200; 130.697043ms)
Mar 26 22:14:59.707: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:162/proxy/: bar (200; 129.251507ms)
Mar 26 22:14:59.707: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:162/proxy/: bar (200; 129.256939ms)
Mar 26 22:14:59.712: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:160/proxy/: foo (200; 133.402574ms)
Mar 26 22:14:59.712: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/rewri... (200; 133.580528ms)
Mar 26 22:14:59.712: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:160/proxy/: foo (200; 134.067945ms)
Mar 26 22:14:59.713: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname1/proxy/: tls baz (200; 134.426417ms)
Mar 26 22:14:59.713: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname1/proxy/: foo (200; 134.512482ms)
Mar 26 22:14:59.713: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:462/proxy/: tls qux (200; 134.584777ms)
Mar 26 22:14:59.713: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:460/proxy/: tls baz (200; 134.921278ms)
Mar 26 22:14:59.713: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/rewriteme"... (200; 135.214446ms)
Mar 26 22:14:59.713: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/... (200; 135.159609ms)
Mar 26 22:14:59.713: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname2/proxy/: tls qux (200; 135.228267ms)
Mar 26 22:14:59.714: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname1/proxy/: foo (200; 136.041009ms)
Mar 26 22:14:59.714: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/... (200; 136.115525ms)
Mar 26 22:14:59.716: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname2/proxy/: bar (200; 138.314178ms)
Mar 26 22:14:59.717: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname2/proxy/: bar (200; 138.822455ms)
Mar 26 22:14:59.854: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:162/proxy/: bar (200; 136.761753ms)
Mar 26 22:14:59.855: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:460/proxy/: tls baz (200; 137.571682ms)
Mar 26 22:14:59.855: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:160/proxy/: foo (200; 137.670173ms)
Mar 26 22:14:59.855: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/... (200; 137.685381ms)
Mar 26 22:14:59.858: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:160/proxy/: foo (200; 140.636902ms)
Mar 26 22:14:59.858: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:462/proxy/: tls qux (200; 140.927289ms)
Mar 26 22:14:59.859: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/... (200; 141.464393ms)
Mar 26 22:14:59.859: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/rewriteme"... (200; 141.987319ms)
Mar 26 22:14:59.860: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:162/proxy/: bar (200; 142.983216ms)
Mar 26 22:14:59.862: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname2/proxy/: bar (200; 145.422194ms)
Mar 26 22:14:59.862: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname1/proxy/: foo (200; 145.417744ms)
Mar 26 22:14:59.863: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname1/proxy/: tls baz (200; 145.766807ms)
Mar 26 22:14:59.863: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname1/proxy/: foo (200; 145.833393ms)
Mar 26 22:14:59.863: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname2/proxy/: bar (200; 145.960874ms)
Mar 26 22:14:59.863: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/rewri... (200; 146.312183ms)
Mar 26 22:14:59.864: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname2/proxy/: tls qux (200; 146.529642ms)
Mar 26 22:14:59.992: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:162/proxy/: bar (200; 127.789922ms)
Mar 26 22:14:59.998: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/rewriteme"... (200; 133.973021ms)
Mar 26 22:14:59.998: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/... (200; 134.155666ms)
Mar 26 22:14:59.998: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname1/proxy/: foo (200; 134.501874ms)
Mar 26 22:14:59.998: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname2/proxy/: bar (200; 134.597822ms)
Mar 26 22:14:59.999: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/... (200; 134.937689ms)
Mar 26 22:14:59.999: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname1/proxy/: tls baz (200; 135.021221ms)
Mar 26 22:14:59.999: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:460/proxy/: tls baz (200; 134.986433ms)
Mar 26 22:14:59.999: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname2/proxy/: bar (200; 134.935995ms)
Mar 26 22:14:59.999: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/rewri... (200; 134.93558ms)
Mar 26 22:14:59.999: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:162/proxy/: bar (200; 135.058333ms)
Mar 26 22:14:59.999: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname2/proxy/: tls qux (200; 135.374271ms)
Mar 26 22:14:59.999: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:462/proxy/: tls qux (200; 135.514336ms)
Mar 26 22:14:59.999: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:160/proxy/: foo (200; 135.373295ms)
Mar 26 22:14:59.999: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:160/proxy/: foo (200; 135.369457ms)
Mar 26 22:14:59.999: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname1/proxy/: foo (200; 135.432583ms)
Mar 26 22:15:00.152: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:460/proxy/: tls baz (200; 152.769056ms)
Mar 26 22:15:00.152: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:160/proxy/: foo (200; 152.810207ms)
Mar 26 22:15:00.158: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/rewriteme"... (200; 158.510351ms)
Mar 26 22:15:00.158: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/rewri... (200; 158.5478ms)
Mar 26 22:15:00.158: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:162/proxy/: bar (200; 158.534482ms)
Mar 26 22:15:00.158: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:160/proxy/: foo (200; 158.609971ms)
Mar 26 22:15:00.158: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:462/proxy/: tls qux (200; 158.613265ms)
Mar 26 22:15:00.158: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/... (200; 158.554437ms)
Mar 26 22:15:00.158: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:162/proxy/: bar (200; 158.553288ms)
Mar 26 22:15:00.158: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/... (200; 158.560483ms)
Mar 26 22:15:00.158: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname2/proxy/: bar (200; 158.592457ms)
Mar 26 22:15:00.158: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname2/proxy/: tls qux (200; 158.559989ms)
Mar 26 22:15:00.158: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname1/proxy/: tls baz (200; 158.612265ms)
Mar 26 22:15:00.158: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname1/proxy/: foo (200; 158.660967ms)
Mar 26 22:15:00.158: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname1/proxy/: foo (200; 158.647807ms)
Mar 26 22:15:00.158: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname2/proxy/: bar (200; 158.655157ms)
Mar 26 22:15:00.306: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:160/proxy/: foo (200; 148.44831ms)
Mar 26 22:15:00.307: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:162/proxy/: bar (200; 149.279231ms)
Mar 26 22:15:00.308: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/rewriteme"... (200; 149.529346ms)
Mar 26 22:15:00.308: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/... (200; 149.878503ms)
Mar 26 22:15:00.308: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/... (200; 149.945316ms)
Mar 26 22:15:00.308: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:160/proxy/: foo (200; 149.922472ms)
Mar 26 22:15:00.308: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/rewri... (200; 149.902937ms)
Mar 26 22:15:00.308: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:162/proxy/: bar (200; 149.940888ms)
Mar 26 22:15:00.308: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:462/proxy/: tls qux (200; 150.045948ms)
Mar 26 22:15:00.309: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname1/proxy/: foo (200; 150.899127ms)
Mar 26 22:15:00.309: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:460/proxy/: tls baz (200; 150.952268ms)
Mar 26 22:15:00.309: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname2/proxy/: bar (200; 151.268041ms)
Mar 26 22:15:00.309: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname2/proxy/: bar (200; 151.296455ms)
Mar 26 22:15:00.309: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname1/proxy/: foo (200; 151.267871ms)
Mar 26 22:15:00.310: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname2/proxy/: tls qux (200; 152.34836ms)
Mar 26 22:15:00.311: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname1/proxy/: tls baz (200; 152.449166ms)
Mar 26 22:15:00.459: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:162/proxy/: bar (200; 148.080249ms)
Mar 26 22:15:00.459: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/rewriteme"... (200; 148.002292ms)
Mar 26 22:15:00.459: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/... (200; 148.149046ms)
Mar 26 22:15:00.459: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/rewri... (200; 148.18286ms)
Mar 26 22:15:00.459: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:460/proxy/: tls baz (200; 148.312235ms)
Mar 26 22:15:00.459: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:160/proxy/: foo (200; 148.364159ms)
Mar 26 22:15:00.459: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:160/proxy/: foo (200; 148.460581ms)
Mar 26 22:15:00.459: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:162/proxy/: bar (200; 148.557832ms)
Mar 26 22:15:00.459: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/... (200; 148.534432ms)
Mar 26 22:15:00.459: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:462/proxy/: tls qux (200; 148.53384ms)
Mar 26 22:15:00.463: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname1/proxy/: foo (200; 152.795698ms)
Mar 26 22:15:00.463: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname2/proxy/: bar (200; 152.850034ms)
Mar 26 22:15:00.463: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname2/proxy/: tls qux (200; 152.807128ms)
Mar 26 22:15:00.464: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname2/proxy/: bar (200; 152.968269ms)
Mar 26 22:15:00.464: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname1/proxy/: foo (200; 153.073357ms)
Mar 26 22:15:00.464: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname1/proxy/: tls baz (200; 153.084381ms)
Mar 26 22:15:00.596: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:160/proxy/: foo (200; 132.138758ms)
Mar 26 22:15:00.596: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/... (200; 132.259848ms)
Mar 26 22:15:00.596: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:162/proxy/: bar (200; 132.379388ms)
Mar 26 22:15:00.596: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/rewri... (200; 132.338952ms)
Mar 26 22:15:00.597: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/... (200; 132.797547ms)
Mar 26 22:15:00.597: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:460/proxy/: tls baz (200; 132.894978ms)
Mar 26 22:15:00.597: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:162/proxy/: bar (200; 132.958783ms)
Mar 26 22:15:00.597: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:462/proxy/: tls qux (200; 133.026234ms)
Mar 26 22:15:00.598: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:160/proxy/: foo (200; 134.621291ms)
Mar 26 22:15:00.598: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/rewriteme"... (200; 134.719156ms)
Mar 26 22:15:00.599: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname1/proxy/: foo (200; 135.456691ms)
Mar 26 22:15:00.599: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname1/proxy/: foo (200; 135.575405ms)
Mar 26 22:15:00.599: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname2/proxy/: bar (200; 135.524397ms)
Mar 26 22:15:00.600: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname2/proxy/: tls qux (200; 135.798285ms)
Mar 26 22:15:00.600: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname2/proxy/: bar (200; 135.853261ms)
Mar 26 22:15:00.600: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname1/proxy/: tls baz (200; 136.008094ms)
Mar 26 22:15:00.734: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:462/proxy/: tls qux (200; 134.19784ms)
Mar 26 22:15:00.734: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:1080/proxy/... (200; 134.252078ms)
Mar 26 22:15:00.734: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l/proxy/rewriteme"... (200; 134.528138ms)
Mar 26 22:15:00.735: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:443/proxy/... (200; 135.223683ms)
Mar 26 22:15:00.735: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:162/proxy/: bar (200; 135.331066ms)
Mar 26 22:15:00.735: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:160/proxy/: foo (200; 135.372489ms)
Mar 26 22:15:00.735: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:160/proxy/: foo (200; 135.365267ms)
Mar 26 22:15:00.735: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/http:proxy-service-nnvch-2f84l:162/proxy/: bar (200; 135.390898ms)
Mar 26 22:15:00.735: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/https:proxy-service-nnvch-2f84l:460/proxy/: tls baz (200; 135.41266ms)
Mar 26 22:15:00.735: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-dqkhc/pods/proxy-service-nnvch-2f84l:1080/proxy/rewri... (200; 135.368196ms)
Mar 26 22:15:00.737: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname1/proxy/: tls baz (200; 137.202307ms)
Mar 26 22:15:00.737: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname1/proxy/: foo (200; 137.403843ms)
Mar 26 22:15:00.737: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/proxy-service-nnvch:portname2/proxy/: bar (200; 137.457491ms)
Mar 26 22:15:00.738: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname2/proxy/: bar (200; 138.35689ms)
Mar 26 22:15:00.738: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/http:proxy-service-nnvch:portname1/proxy/: foo (200; 138.361149ms)
Mar 26 22:15:00.738: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-dqkhc/services/https:proxy-service-nnvch:tlsportname2/proxy/: tls qux (200; 138.351846ms)
[1mSTEP[0m: deleting { ReplicationController} proxy-service-nnvch in namespace e2e-tests-proxy-dqkhc, will wait for the garbage collector to delete the pods
Mar 26 22:15:01.159: INFO: Deleting { ReplicationController} proxy-service-nnvch took: 140.809542ms
Mar 26 22:15:01.260: INFO: Terminating { ReplicationController} proxy-service-nnvch pods took: 100.252975ms
[AfterEach] version v1
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:15:03.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-proxy-dqkhc" for this suite.
Mar 26 22:15:09.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:15:14.212: INFO: namespace: e2e-tests-proxy-dqkhc, resource: bindings, ignored listing per whitelist
Mar 26 22:15:15.475: INFO: namespace e2e-tests-proxy-dqkhc deletion completed in 12.057925545s

[32mâ€¢ [SLOW TEST:22.539 seconds][0m
[sig-network] Proxy
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22[0m
  version v1
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56[0m
    should proxy through a service and a pod  [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould project all components that make up the projection API [Projection][NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:15:15.475: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name configmap-projected-all-test-volume-2b345639-5036-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating secret with name secret-projected-all-test-volume-2b34562a-5036-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test Check all projections for projected volume plugin
Mar 26 22:15:19.812: INFO: Waiting up to 5m0s for pod "projected-volume-2b3455f7-5036-11e9-9bdd-d050998677c2" in namespace "e2e-tests-projected-568r9" to be "success or failure"
Mar 26 22:15:19.921: INFO: Pod "projected-volume-2b3455f7-5036-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 108.371481ms
Mar 26 22:15:22.037: INFO: Pod "projected-volume-2b3455f7-5036-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.224614738s
[1mSTEP[0m: Saw pod success
Mar 26 22:15:22.037: INFO: Pod "projected-volume-2b3455f7-5036-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:15:22.150: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod projected-volume-2b3455f7-5036-11e9-9bdd-d050998677c2 container projected-all-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:15:22.399: INFO: Waiting for pod projected-volume-2b3455f7-5036-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:15:22.507: INFO: Pod projected-volume-2b3455f7-5036-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:15:22.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-568r9" for this suite.
Mar 26 22:15:28.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:15:30.328: INFO: namespace: e2e-tests-projected-568r9, resource: bindings, ignored listing per whitelist
Mar 26 22:15:31.156: INFO: namespace e2e-tests-projected-568r9 deletion completed in 8.550479606s

[32mâ€¢ [SLOW TEST:15.681 seconds][0m
[sig-storage] Projected
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35[0m
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Services[0m 
  [1mshould serve a basic endpoint from pods  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-network] Services
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:15:31.156: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename services
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating service endpoint-test2 in namespace e2e-tests-services-vtjnt
[1mSTEP[0m: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-vtjnt to expose endpoints map[]
Mar 26 22:15:34.746: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-vtjnt exposes endpoints map[] (116.251622ms elapsed)
[1mSTEP[0m: Creating pod pod1 in namespace e2e-tests-services-vtjnt
[1mSTEP[0m: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-vtjnt to expose endpoints map[pod1:[80]]
Mar 26 22:15:37.308: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-vtjnt exposes endpoints map[pod1:[80]] (2.449708744s elapsed)
[1mSTEP[0m: Creating pod pod2 in namespace e2e-tests-services-vtjnt
[1mSTEP[0m: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-vtjnt to expose endpoints map[pod1:[80] pod2:[80]]
Mar 26 22:15:39.698: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-vtjnt exposes endpoints map[pod1:[80] pod2:[80]] (2.351124534s elapsed)
[1mSTEP[0m: Deleting pod pod1 in namespace e2e-tests-services-vtjnt
[1mSTEP[0m: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-vtjnt to expose endpoints map[pod2:[80]]
Mar 26 22:15:39.793: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-vtjnt exposes endpoints map[pod2:[80]] (67.870785ms elapsed)
[1mSTEP[0m: Deleting pod pod2 in namespace e2e-tests-services-vtjnt
[1mSTEP[0m: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-vtjnt to expose endpoints map[]
Mar 26 22:15:39.891: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-vtjnt exposes endpoints map[] (58.227793ms elapsed)
[AfterEach] [sig-network] Services
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:15:39.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-services-vtjnt" for this suite.
Mar 26 22:16:02.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:16:03.522: INFO: namespace: e2e-tests-services-vtjnt, resource: bindings, ignored listing per whitelist
Mar 26 22:16:04.881: INFO: namespace e2e-tests-services-vtjnt deletion completed in 24.877209867s
[AfterEach] [sig-network] Services
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

[32mâ€¢ [SLOW TEST:33.725 seconds][0m
[sig-network] Services
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22[0m
  should serve a basic endpoint from pods  [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] InitContainer [NodeConformance][0m 
  [1mshould invoke init containers on a RestartAlways pod [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:16:04.881: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename init-container
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating the pod
Mar 26 22:16:06.653: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:16:10.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-init-container-b5dc5" for this suite.
Mar 26 22:16:32.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:16:35.167: INFO: namespace: e2e-tests-init-container-b5dc5, resource: bindings, ignored listing per whitelist
Mar 26 22:16:35.238: INFO: namespace e2e-tests-init-container-b5dc5 deletion completed in 24.422918603s

[32mâ€¢ [SLOW TEST:30.357 seconds][0m
[k8s.io] InitContainer [NodeConformance]
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should invoke init containers on a RestartAlways pod [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] HostPath[0m 
  [1mshould give a volume the correct mode [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] HostPath
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:16:35.238: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename hostpath
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test hostPath mode
Mar 26 22:16:37.662: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-mjbsf" to be "success or failure"
Mar 26 22:16:37.712: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 50.376265ms
Mar 26 22:16:39.759: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.096875833s
[1mSTEP[0m: Saw pod success
Mar 26 22:16:39.759: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Mar 26 22:16:39.804: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-host-path-test container test-container-1: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:16:39.909: INFO: Waiting for pod pod-host-path-test to disappear
Mar 26 22:16:39.956: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:16:39.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-hostpath-mjbsf" for this suite.
Mar 26 22:16:46.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:16:47.112: INFO: namespace: e2e-tests-hostpath-mjbsf, resource: bindings, ignored listing per whitelist
Mar 26 22:16:47.298: INFO: namespace e2e-tests-hostpath-mjbsf deletion completed in 7.292504566s

[32mâ€¢ [SLOW TEST:12.060 seconds][0m
[sig-storage] HostPath
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34[0m
  should give a volume the correct mode [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mupdates should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:16:47.298: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating projection with configMap that has name projected-configmap-test-upd-600f54ca-5036-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Updating configmap projected-configmap-test-upd-600f54ca-5036-11e9-9bdd-d050998677c2
[1mSTEP[0m: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:16:54.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-x4rfw" for this suite.
Mar 26 22:17:16.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:17:18.044: INFO: namespace: e2e-tests-projected-x4rfw, resource: bindings, ignored listing per whitelist
Mar 26 22:17:18.712: INFO: namespace e2e-tests-projected-x4rfw deletion completed in 24.220550165s

[32mâ€¢ [SLOW TEST:31.414 seconds][0m
[sig-storage] Projected
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35[0m
  updates should be reflected in volume [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould provide container's memory limit [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:17:18.713: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 26 22:17:19.761: INFO: Waiting up to 5m0s for pod "downwardapi-volume-72e14496-5036-11e9-9bdd-d050998677c2" in namespace "e2e-tests-projected-4pmqn" to be "success or failure"
Mar 26 22:17:19.792: INFO: Pod "downwardapi-volume-72e14496-5036-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 31.221772ms
Mar 26 22:17:21.846: INFO: Pod "downwardapi-volume-72e14496-5036-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.08500033s
[1mSTEP[0m: Saw pod success
Mar 26 22:17:21.846: INFO: Pod "downwardapi-volume-72e14496-5036-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:17:21.885: INFO: Trying to get logs from node ip-172-20-53-156.us-east-2.compute.internal pod downwardapi-volume-72e14496-5036-11e9-9bdd-d050998677c2 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:17:22.014: INFO: Waiting for pod downwardapi-volume-72e14496-5036-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:17:22.105: INFO: Pod downwardapi-volume-72e14496-5036-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:17:22.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-4pmqn" for this suite.
Mar 26 22:17:28.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:17:28.670: INFO: namespace: e2e-tests-projected-4pmqn, resource: bindings, ignored listing per whitelist
Mar 26 22:17:29.897: INFO: namespace e2e-tests-projected-4pmqn deletion completed in 7.682962346s

[32mâ€¢ [SLOW TEST:11.184 seconds][0m
[sig-storage] Projected
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35[0m
  should provide container's memory limit [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Namespaces [Serial][0m 
  [1mshould ensure that all services are removed when a namespace is deleted [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:17:29.897: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename namespaces
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a test namespace
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[1mSTEP[0m: Creating a service in the namespace
[1mSTEP[0m: Deleting the namespace
[1mSTEP[0m: Waiting for the namespace to be removed.
[1mSTEP[0m: Recreating the namespace
[1mSTEP[0m: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:17:37.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-namespaces-t7qpt" for this suite.
Mar 26 22:17:43.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:17:43.779: INFO: namespace: e2e-tests-namespaces-t7qpt, resource: bindings, ignored listing per whitelist
Mar 26 22:17:44.793: INFO: namespace e2e-tests-namespaces-t7qpt deletion completed in 7.315494281s
[1mSTEP[0m: Destroying namespace "e2e-tests-nsdeletetest-xx8tq" for this suite.
Mar 26 22:17:44.822: INFO: Namespace e2e-tests-nsdeletetest-xx8tq was already deleted
[1mSTEP[0m: Destroying namespace "e2e-tests-nsdeletetest-bfkrs" for this suite.
Mar 26 22:17:50.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:17:51.340: INFO: namespace: e2e-tests-nsdeletetest-bfkrs, resource: bindings, ignored listing per whitelist
Mar 26 22:17:52.427: INFO: namespace e2e-tests-nsdeletetest-bfkrs deletion completed in 7.60483971s

[32mâ€¢ [SLOW TEST:22.530 seconds][0m
[sig-api-machinery] Namespaces [Serial]
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should ensure that all services are removed when a namespace is deleted [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] ConfigMap[0m 
  [1mshould be consumable via the environment [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] ConfigMap
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:17:52.427: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap e2e-tests-configmap-rw7vv/configmap-test-86f32837-5036-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 26 22:17:53.459: INFO: Waiting up to 5m0s for pod "pod-configmaps-86f72b3a-5036-11e9-9bdd-d050998677c2" in namespace "e2e-tests-configmap-rw7vv" to be "success or failure"
Mar 26 22:17:53.484: INFO: Pod "pod-configmaps-86f72b3a-5036-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.389763ms
Mar 26 22:17:55.518: INFO: Pod "pod-configmaps-86f72b3a-5036-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.059217558s
[1mSTEP[0m: Saw pod success
Mar 26 22:17:55.518: INFO: Pod "pod-configmaps-86f72b3a-5036-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:17:55.556: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-configmaps-86f72b3a-5036-11e9-9bdd-d050998677c2 container env-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:17:55.631: INFO: Waiting for pod pod-configmaps-86f72b3a-5036-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:17:55.659: INFO: Pod pod-configmaps-86f72b3a-5036-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:17:55.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-rw7vv" for this suite.
Mar 26 22:18:01.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:18:02.708: INFO: namespace: e2e-tests-configmap-rw7vv, resource: bindings, ignored listing per whitelist
Mar 26 22:18:02.788: INFO: namespace e2e-tests-configmap-rw7vv deletion completed in 7.099481366s

[32mâ€¢ [SLOW TEST:10.362 seconds][0m
[sig-api-machinery] ConfigMap
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30[0m
  should be consumable via the environment [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] InitContainer [NodeConformance][0m 
  [1mshould invoke init containers on a RestartNever pod [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:18:02.789: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename init-container
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating the pod
Mar 26 22:18:03.713: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:18:07.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-init-container-5db7g" for this suite.
Mar 26 22:18:13.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:18:13.765: INFO: namespace: e2e-tests-init-container-5db7g, resource: bindings, ignored listing per whitelist
Mar 26 22:18:14.595: INFO: namespace e2e-tests-init-container-5db7g deletion completed in 7.154042332s

[32mâ€¢ [SLOW TEST:11.806 seconds][0m
[k8s.io] InitContainer [NodeConformance]
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should invoke init containers on a RestartNever pod [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] [sig-node] PreStop[0m 
  [1mshould call prestop when killing a pod  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] [sig-node] PreStop
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:18:14.595: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename prestop
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating server pod server in namespace e2e-tests-prestop-xcllm
[1mSTEP[0m: Waiting for pods to come up.
[1mSTEP[0m: Creating tester pod tester in namespace e2e-tests-prestop-xcllm
[1mSTEP[0m: Deleting pre-stop pod
Mar 26 22:18:25.056: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
[1mSTEP[0m: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:18:25.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-prestop-xcllm" for this suite.
Mar 26 22:19:03.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:19:03.840: INFO: namespace: e2e-tests-prestop-xcllm, resource: bindings, ignored listing per whitelist
Mar 26 22:19:04.485: INFO: namespace e2e-tests-prestop-xcllm deletion completed in 39.318842001s

[32mâ€¢ [SLOW TEST:49.890 seconds][0m
[k8s.io] [sig-node] PreStop
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should call prestop when killing a pod  [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould provide container's cpu limit [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:19:04.485: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 26 22:19:05.363: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b1d2e2ad-5036-11e9-9bdd-d050998677c2" in namespace "e2e-tests-projected-gdfbx" to be "success or failure"
Mar 26 22:19:05.390: INFO: Pod "downwardapi-volume-b1d2e2ad-5036-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 26.322849ms
Mar 26 22:19:07.419: INFO: Pod "downwardapi-volume-b1d2e2ad-5036-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.055478756s
[1mSTEP[0m: Saw pod success
Mar 26 22:19:07.419: INFO: Pod "downwardapi-volume-b1d2e2ad-5036-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:19:07.451: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod downwardapi-volume-b1d2e2ad-5036-11e9-9bdd-d050998677c2 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:19:07.517: INFO: Waiting for pod downwardapi-volume-b1d2e2ad-5036-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:19:07.543: INFO: Pod downwardapi-volume-b1d2e2ad-5036-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:19:07.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-gdfbx" for this suite.
Mar 26 22:19:13.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:19:13.827: INFO: namespace: e2e-tests-projected-gdfbx, resource: bindings, ignored listing per whitelist
Mar 26 22:19:14.649: INFO: namespace e2e-tests-projected-gdfbx deletion completed in 7.078941612s

[32mâ€¢ [SLOW TEST:10.164 seconds][0m
[sig-storage] Projected
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35[0m
  should provide container's cpu limit [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (non-root,0666,default) [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:19:14.649: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test emptydir 0666 on node default medium
Mar 26 22:19:15.527: INFO: Waiting up to 5m0s for pod "pod-b7e1cbf8-5036-11e9-9bdd-d050998677c2" in namespace "e2e-tests-emptydir-b7z9p" to be "success or failure"
Mar 26 22:19:15.552: INFO: Pod "pod-b7e1cbf8-5036-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.426585ms
Mar 26 22:19:17.578: INFO: Pod "pod-b7e1cbf8-5036-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.051710035s
[1mSTEP[0m: Saw pod success
Mar 26 22:19:17.579: INFO: Pod "pod-b7e1cbf8-5036-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:19:17.604: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-b7e1cbf8-5036-11e9-9bdd-d050998677c2 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:19:17.665: INFO: Waiting for pod pod-b7e1cbf8-5036-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:19:17.694: INFO: Pod pod-b7e1cbf8-5036-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:19:17.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-b7z9p" for this suite.
Mar 26 22:19:23.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:19:23.901: INFO: namespace: e2e-tests-emptydir-b7z9p, resource: bindings, ignored listing per whitelist
Mar 26 22:19:24.982: INFO: namespace e2e-tests-emptydir-b7z9p deletion completed in 7.26180109s

[32mâ€¢ [SLOW TEST:10.333 seconds][0m
[sig-storage] EmptyDir volumes
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1moptional updates should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:19:24.983: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name cm-test-opt-del-bebba778-5036-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating configMap with name cm-test-opt-upd-bebba7ce-5036-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Deleting configmap cm-test-opt-del-bebba778-5036-11e9-9bdd-d050998677c2
[1mSTEP[0m: Updating configmap cm-test-opt-upd-bebba7ce-5036-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating configMap with name cm-test-opt-create-bebba7ef-5036-11e9-9bdd-d050998677c2
[1mSTEP[0m: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:20:47.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-s694k" for this suite.
Mar 26 22:21:09.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:21:09.809: INFO: namespace: e2e-tests-projected-s694k, resource: bindings, ignored listing per whitelist
Mar 26 22:21:10.903: INFO: namespace e2e-tests-projected-s694k deletion completed in 23.639059711s

[32mâ€¢ [SLOW TEST:105.921 seconds][0m
[sig-storage] Projected
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35[0m
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] ConfigMap
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:21:10.904: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name configmap-test-volume-map-fd5e6a34-5036-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 26 22:21:12.136: INFO: Waiting up to 5m0s for pod "pod-configmaps-fd62ebac-5036-11e9-9bdd-d050998677c2" in namespace "e2e-tests-configmap-n4kj6" to be "success or failure"
Mar 26 22:21:12.162: INFO: Pod "pod-configmaps-fd62ebac-5036-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.916201ms
Mar 26 22:21:14.203: INFO: Pod "pod-configmaps-fd62ebac-5036-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.067431757s
[1mSTEP[0m: Saw pod success
Mar 26 22:21:14.203: INFO: Pod "pod-configmaps-fd62ebac-5036-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:21:14.241: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-configmaps-fd62ebac-5036-11e9-9bdd-d050998677c2 container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:21:14.331: INFO: Waiting for pod pod-configmaps-fd62ebac-5036-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:21:14.366: INFO: Pod pod-configmaps-fd62ebac-5036-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:21:14.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-n4kj6" for this suite.
Mar 26 22:21:20.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:21:21.133: INFO: namespace: e2e-tests-configmap-n4kj6, resource: bindings, ignored listing per whitelist
Mar 26 22:21:21.716: INFO: namespace e2e-tests-configmap-n4kj6 deletion completed in 7.315453505s

[32mâ€¢ [SLOW TEST:10.813 seconds][0m
[sig-storage] ConfigMap
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33[0m
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould be submitted and removed [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Pods
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:21:21.717: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating the pod
[1mSTEP[0m: setting up watch
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: verifying the pod is in kubernetes
[1mSTEP[0m: verifying pod creation was observed
Mar 26 22:21:25.290: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-03eee181-5037-11e9-9bdd-d050998677c2", GenerateName:"", Namespace:"e2e-tests-pods-txvp8", SelfLink:"/api/v1/namespaces/e2e-tests-pods-txvp8/pods/pod-submit-remove-03eee181-5037-11e9-9bdd-d050998677c2", UID:"03fb7460-5037-11e9-8eb3-023bf32bf132", ResourceVersion:"19514", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63689250083, loc:(*time.Location)(0x835fd00)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"92118553"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-sj9qw", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0026d0000), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-sj9qw", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001bd7418), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-20-56-226.us-east-2.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001a58c00), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001bd7450)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001bd7470)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001bd7478), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689250083, loc:(*time.Location)(0x835fd00)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689250084, loc:(*time.Location)(0x835fd00)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689250084, loc:(*time.Location)(0x835fd00)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689250083, loc:(*time.Location)(0x835fd00)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.20.56.226", PodIP:"100.96.2.142", StartTime:(*v1.Time)(0xc0027b5d20), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc0027b5dc0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d", ContainerID:"docker://46e80cfd148f14a7d3833aab77fc657c7f22fc0c432a5442c2ca41afd6abeefd"}}, QOSClass:"BestEffort"}}
[1mSTEP[0m: deleting the pod gracefully
[1mSTEP[0m: verifying the kubelet observed the termination notice
Mar 26 22:21:30.349: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[1mSTEP[0m: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:21:30.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pods-txvp8" for this suite.
Mar 26 22:21:36.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:21:37.146: INFO: namespace: e2e-tests-pods-txvp8, resource: bindings, ignored listing per whitelist
Mar 26 22:21:37.544: INFO: namespace e2e-tests-pods-txvp8 deletion completed in 7.141377684s

[32mâ€¢ [SLOW TEST:15.827 seconds][0m
[k8s.io] Pods
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should be submitted and removed [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (root,0666,tmpfs) [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:21:37.544: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test emptydir 0666 on tmpfs
Mar 26 22:21:38.482: INFO: Waiting up to 5m0s for pod "pod-0d170b2e-5037-11e9-9bdd-d050998677c2" in namespace "e2e-tests-emptydir-dgcpt" to be "success or failure"
Mar 26 22:21:38.507: INFO: Pod "pod-0d170b2e-5037-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.078608ms
Mar 26 22:21:40.538: INFO: Pod "pod-0d170b2e-5037-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.055683571s
[1mSTEP[0m: Saw pod success
Mar 26 22:21:40.538: INFO: Pod "pod-0d170b2e-5037-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:21:40.563: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-0d170b2e-5037-11e9-9bdd-d050998677c2 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:21:40.625: INFO: Waiting for pod pod-0d170b2e-5037-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:21:40.657: INFO: Pod pod-0d170b2e-5037-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:21:40.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-dgcpt" for this suite.
Mar 26 22:21:46.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:21:47.908: INFO: namespace: e2e-tests-emptydir-dgcpt, resource: bindings, ignored listing per whitelist
Mar 26 22:21:47.933: INFO: namespace e2e-tests-emptydir-dgcpt deletion completed in 7.239906396s

[32mâ€¢ [SLOW TEST:10.389 seconds][0m
[sig-storage] EmptyDir volumes
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Container Lifecycle Hook[0m [90mwhen create a pod with lifecycle hook[0m 
  [1mshould execute poststart http hook properly [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:21:47.933: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename container-lifecycle-hook
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
[1mSTEP[0m: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: create the pod with lifecycle hook
[1mSTEP[0m: check poststart hook
[1mSTEP[0m: delete the pod with lifecycle hook
Mar 26 22:21:53.078: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 26 22:21:53.113: INFO: Pod pod-with-poststart-http-hook still exists
Mar 26 22:21:55.113: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 26 22:21:55.147: INFO: Pod pod-with-poststart-http-hook still exists
Mar 26 22:21:57.113: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 26 22:21:57.168: INFO: Pod pod-with-poststart-http-hook still exists
Mar 26 22:21:59.113: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 26 22:21:59.139: INFO: Pod pod-with-poststart-http-hook still exists
Mar 26 22:22:01.113: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 26 22:22:01.139: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:22:01.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-container-lifecycle-hook-dt4zg" for this suite.
Mar 26 22:22:23.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:22:23.567: INFO: namespace: e2e-tests-container-lifecycle-hook-dt4zg, resource: bindings, ignored listing per whitelist
Mar 26 22:22:24.216: INFO: namespace e2e-tests-container-lifecycle-hook-dt4zg deletion completed in 23.048619314s

[32mâ€¢ [SLOW TEST:36.283 seconds][0m
[k8s.io] Container Lifecycle Hook
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  when create a pod with lifecycle hook
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40[0m
    should execute poststart http hook properly [NodeConformance] [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Namespaces [Serial][0m 
  [1mshould ensure that all pods are removed when a namespace is deleted [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:22:24.216: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename namespaces
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a test namespace
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[1mSTEP[0m: Creating a pod in the namespace
[1mSTEP[0m: Waiting for the pod to have running status
[1mSTEP[0m: Creating an uninitialized pod in the namespace
Mar 26 22:22:27.218: INFO: error from create uninitialized namespace: <nil>
[1mSTEP[0m: Deleting the namespace
[1mSTEP[0m: Waiting for the namespace to be removed.
[1mSTEP[0m: Recreating the namespace
[1mSTEP[0m: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:22:51.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-namespaces-lppbc" for this suite.
Mar 26 22:22:57.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:22:58.288: INFO: namespace: e2e-tests-namespaces-lppbc, resource: bindings, ignored listing per whitelist
Mar 26 22:22:58.572: INFO: namespace e2e-tests-namespaces-lppbc deletion completed in 7.147366022s
[1mSTEP[0m: Destroying namespace "e2e-tests-nsdeletetest-h77b6" for this suite.
Mar 26 22:22:58.602: INFO: Namespace e2e-tests-nsdeletetest-h77b6 was already deleted
[1mSTEP[0m: Destroying namespace "e2e-tests-nsdeletetest-pqjvg" for this suite.
Mar 26 22:23:04.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:23:05.207: INFO: namespace: e2e-tests-nsdeletetest-pqjvg, resource: bindings, ignored listing per whitelist
Mar 26 22:23:05.910: INFO: namespace e2e-tests-nsdeletetest-pqjvg deletion completed in 7.30812067s

[32mâ€¢ [SLOW TEST:41.695 seconds][0m
[sig-api-machinery] Namespaces [Serial]
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Downward API[0m 
  [1mshould provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Downward API
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:23:05.911: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward api env vars
Mar 26 22:23:06.825: INFO: Waiting up to 5m0s for pod "downward-api-41bf101c-5037-11e9-9bdd-d050998677c2" in namespace "e2e-tests-downward-api-gsrbh" to be "success or failure"
Mar 26 22:23:06.853: INFO: Pod "downward-api-41bf101c-5037-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 27.828065ms
Mar 26 22:23:08.883: INFO: Pod "downward-api-41bf101c-5037-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.057679203s
[1mSTEP[0m: Saw pod success
Mar 26 22:23:08.883: INFO: Pod "downward-api-41bf101c-5037-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:23:08.908: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod downward-api-41bf101c-5037-11e9-9bdd-d050998677c2 container dapi-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:23:08.971: INFO: Waiting for pod downward-api-41bf101c-5037-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:23:08.996: INFO: Pod downward-api-41bf101c-5037-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:23:08.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-gsrbh" for this suite.
Mar 26 22:23:15.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:23:15.511: INFO: namespace: e2e-tests-downward-api-gsrbh, resource: bindings, ignored listing per whitelist
Mar 26 22:23:16.080: INFO: namespace e2e-tests-downward-api-gsrbh deletion completed in 7.05748075s

[32mâ€¢ [SLOW TEST:10.170 seconds][0m
[sig-api-machinery] Downward API
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38[0m
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Subpath[0m [90mAtomic writer volumes[0m 
  [1mshould support subpaths with configmap pod with mountPath of existing file [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Subpath
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:23:16.080: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename subpath
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
[1mSTEP[0m: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating pod pod-subpath-test-configmap-xlxf
[1mSTEP[0m: Creating a pod to test atomic-volume-subpath
Mar 26 22:23:17.327: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-xlxf" in namespace "e2e-tests-subpath-qslz5" to be "success or failure"
Mar 26 22:23:17.360: INFO: Pod "pod-subpath-test-configmap-xlxf": Phase="Pending", Reason="", readiness=false. Elapsed: 32.537375ms
Mar 26 22:23:19.386: INFO: Pod "pod-subpath-test-configmap-xlxf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.058510412s
Mar 26 22:23:21.411: INFO: Pod "pod-subpath-test-configmap-xlxf": Phase="Running", Reason="", readiness=false. Elapsed: 4.084190847s
Mar 26 22:23:23.458: INFO: Pod "pod-subpath-test-configmap-xlxf": Phase="Running", Reason="", readiness=false. Elapsed: 6.130755125s
Mar 26 22:23:25.504: INFO: Pod "pod-subpath-test-configmap-xlxf": Phase="Running", Reason="", readiness=false. Elapsed: 8.177153819s
Mar 26 22:23:27.532: INFO: Pod "pod-subpath-test-configmap-xlxf": Phase="Running", Reason="", readiness=false. Elapsed: 10.205352191s
Mar 26 22:23:29.561: INFO: Pod "pod-subpath-test-configmap-xlxf": Phase="Running", Reason="", readiness=false. Elapsed: 12.234110154s
Mar 26 22:23:31.587: INFO: Pod "pod-subpath-test-configmap-xlxf": Phase="Running", Reason="", readiness=false. Elapsed: 14.260268196s
Mar 26 22:23:33.614: INFO: Pod "pod-subpath-test-configmap-xlxf": Phase="Running", Reason="", readiness=false. Elapsed: 16.28690069s
Mar 26 22:23:35.640: INFO: Pod "pod-subpath-test-configmap-xlxf": Phase="Running", Reason="", readiness=false. Elapsed: 18.313345003s
Mar 26 22:23:37.668: INFO: Pod "pod-subpath-test-configmap-xlxf": Phase="Running", Reason="", readiness=false. Elapsed: 20.3404276s
Mar 26 22:23:39.696: INFO: Pod "pod-subpath-test-configmap-xlxf": Phase="Running", Reason="", readiness=false. Elapsed: 22.369349861s
Mar 26 22:23:41.726: INFO: Pod "pod-subpath-test-configmap-xlxf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.398959976s
[1mSTEP[0m: Saw pod success
Mar 26 22:23:41.726: INFO: Pod "pod-subpath-test-configmap-xlxf" satisfied condition "success or failure"
Mar 26 22:23:41.751: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-subpath-test-configmap-xlxf container test-container-subpath-configmap-xlxf: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:23:41.822: INFO: Waiting for pod pod-subpath-test-configmap-xlxf to disappear
Mar 26 22:23:41.850: INFO: Pod pod-subpath-test-configmap-xlxf no longer exists
[1mSTEP[0m: Deleting pod pod-subpath-test-configmap-xlxf
Mar 26 22:23:41.850: INFO: Deleting pod "pod-subpath-test-configmap-xlxf" in namespace "e2e-tests-subpath-qslz5"
[AfterEach] [sig-storage] Subpath
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:23:41.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-subpath-qslz5" for this suite.
Mar 26 22:23:47.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:23:48.826: INFO: namespace: e2e-tests-subpath-qslz5, resource: bindings, ignored listing per whitelist
Mar 26 22:23:48.953: INFO: namespace e2e-tests-subpath-qslz5 deletion completed in 7.047198969s

[32mâ€¢ [SLOW TEST:32.873 seconds][0m
[sig-storage] Subpath
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  Atomic writer volumes
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34[0m
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mwith readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Probing container
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:23:48.953: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename container-probe
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:24:49.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-container-probe-9zb7t" for this suite.
Mar 26 22:25:08.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:25:08.811: INFO: namespace: e2e-tests-container-probe-9zb7t, resource: bindings, ignored listing per whitelist
Mar 26 22:25:09.488: INFO: namespace e2e-tests-container-probe-9zb7t deletion completed in 19.569073314s

[32mâ€¢ [SLOW TEST:80.535 seconds][0m
[k8s.io] Probing container
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Downward API[0m 
  [1mshould provide host IP as an env var [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Downward API
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:25:09.488: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward api env vars
Mar 26 22:25:10.709: INFO: Waiting up to 5m0s for pod "downward-api-8b966027-5037-11e9-9bdd-d050998677c2" in namespace "e2e-tests-downward-api-7csng" to be "success or failure"
Mar 26 22:25:10.736: INFO: Pod "downward-api-8b966027-5037-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 26.894315ms
Mar 26 22:25:12.774: INFO: Pod "downward-api-8b966027-5037-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.065059181s
[1mSTEP[0m: Saw pod success
Mar 26 22:25:12.775: INFO: Pod "downward-api-8b966027-5037-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:25:12.812: INFO: Trying to get logs from node ip-172-20-53-156.us-east-2.compute.internal pod downward-api-8b966027-5037-11e9-9bdd-d050998677c2 container dapi-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:25:12.882: INFO: Waiting for pod downward-api-8b966027-5037-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:25:12.909: INFO: Pod downward-api-8b966027-5037-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:25:12.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-7csng" for this suite.
Mar 26 22:25:19.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:25:19.649: INFO: namespace: e2e-tests-downward-api-7csng, resource: bindings, ignored listing per whitelist
Mar 26 22:25:20.066: INFO: namespace e2e-tests-downward-api-7csng deletion completed in 7.130320019s

[32mâ€¢ [SLOW TEST:10.578 seconds][0m
[sig-api-machinery] Downward API
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38[0m
  should provide host IP as an env var [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] InitContainer [NodeConformance][0m 
  [1mshould not start app containers if init containers fail on a RestartAlways pod [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:25:20.066: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename init-container
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating the pod
Mar 26 22:25:21.611: INFO: PodSpec: initContainers in spec.initContainers
Mar 26 22:26:05.581: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-921a1b0e-5037-11e9-9bdd-d050998677c2", GenerateName:"", Namespace:"e2e-tests-init-container-bdgfh", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-bdgfh/pods/pod-init-921a1b0e-5037-11e9-9bdd-d050998677c2", UID:"921cc26c-5037-11e9-8eb3-023bf32bf132", ResourceVersion:"20086", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63689250321, loc:(*time.Location)(0x835fd00)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"611861139"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-pwz6w", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0021ee180), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-pwz6w", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-pwz6w", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-pwz6w", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0025f7298), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-20-56-226.us-east-2.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0017dc960), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0025f73a0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0025f73c0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0025f73c8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689250321, loc:(*time.Location)(0x835fd00)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689250321, loc:(*time.Location)(0x835fd00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689250321, loc:(*time.Location)(0x835fd00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689250321, loc:(*time.Location)(0x835fd00)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.20.56.226", PodIP:"100.96.2.152", StartTime:(*v1.Time)(0xc002ed5ba0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000173260)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0001732d0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://bbaa6dbbc0066c17e48a9e94dd7ed7cd761f22066451280c8bcc14c1db8d1b33"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002ed5be0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002ed5bc0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:26:05.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-init-container-bdgfh" for this suite.
Mar 26 22:26:27.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:26:27.822: INFO: namespace: e2e-tests-init-container-bdgfh, resource: bindings, ignored listing per whitelist
Mar 26 22:26:28.666: INFO: namespace e2e-tests-init-container-bdgfh deletion completed in 23.057977127s

[32mâ€¢ [SLOW TEST:68.600 seconds][0m
[k8s.io] InitContainer [NodeConformance]
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mshould be restarted with a /healthz http liveness probe [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Probing container
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:26:28.667: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename container-probe
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating pod liveness-http in namespace e2e-tests-container-probe-8qfzd
Mar 26 22:26:32.001: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-8qfzd
[1mSTEP[0m: checking the pod's current state and verifying that restartCount is present
Mar 26 22:26:32.026: INFO: Initial restart count of pod liveness-http is 0
Mar 26 22:26:56.580: INFO: Restart count of pod e2e-tests-container-probe-8qfzd/liveness-http is now 1 (24.553509725s elapsed)
[1mSTEP[0m: deleting the pod
[AfterEach] [k8s.io] Probing container
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:26:56.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-container-probe-8qfzd" for this suite.
Mar 26 22:27:02.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:27:03.280: INFO: namespace: e2e-tests-container-probe-8qfzd, resource: bindings, ignored listing per whitelist
Mar 26 22:27:04.585: INFO: namespace e2e-tests-container-probe-8qfzd deletion completed in 7.924355835s

[32mâ€¢ [SLOW TEST:35.919 seconds][0m
[k8s.io] Probing container
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (root,0666,default) [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:27:04.585: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test emptydir 0666 on node default medium
Mar 26 22:27:06.071: INFO: Waiting up to 5m0s for pod "pod-d057e674-5037-11e9-9bdd-d050998677c2" in namespace "e2e-tests-emptydir-l5xzt" to be "success or failure"
Mar 26 22:27:06.104: INFO: Pod "pod-d057e674-5037-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 32.871432ms
Mar 26 22:27:08.163: INFO: Pod "pod-d057e674-5037-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.091946825s
[1mSTEP[0m: Saw pod success
Mar 26 22:27:08.163: INFO: Pod "pod-d057e674-5037-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:27:08.227: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-d057e674-5037-11e9-9bdd-d050998677c2 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:27:08.348: INFO: Waiting for pod pod-d057e674-5037-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:27:08.408: INFO: Pod pod-d057e674-5037-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:27:08.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-l5xzt" for this suite.
Mar 26 22:27:14.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:27:15.754: INFO: namespace: e2e-tests-emptydir-l5xzt, resource: bindings, ignored listing per whitelist
Mar 26 22:27:15.842: INFO: namespace e2e-tests-emptydir-l5xzt deletion completed in 7.375920001s

[32mâ€¢ [SLOW TEST:11.257 seconds][0m
[sig-storage] EmptyDir volumes
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (root,0666,default) [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl describe[0m 
  [1mshould check if kubectl describe prints relevant information for rc and pods  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:27:15.843: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 22:27:16.706: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config version --client'
Mar 26 22:27:16.770: INFO: stderr: ""
Mar 26 22:27:16.770: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.0\", GitCommit:\"0ed33881dc4355495f623c6f22e7dd0b7632b7c0\", GitTreeState:\"clean\", BuildDate:\"2019-03-27T00:13:01Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Mar 26 22:27:16.798: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config create -f - --namespace=e2e-tests-kubectl-fhn62'
Mar 26 22:27:18.522: INFO: stderr: ""
Mar 26 22:27:18.522: INFO: stdout: "replicationcontroller/redis-master created\n"
Mar 26 22:27:18.522: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config create -f - --namespace=e2e-tests-kubectl-fhn62'
Mar 26 22:27:18.986: INFO: stderr: ""
Mar 26 22:27:18.986: INFO: stdout: "service/redis-master created\n"
[1mSTEP[0m: Waiting for Redis master to start.
Mar 26 22:27:20.025: INFO: Selector matched 1 pods for map[app:redis]
Mar 26 22:27:20.025: INFO: Found 0 / 1
Mar 26 22:27:21.013: INFO: Selector matched 1 pods for map[app:redis]
Mar 26 22:27:21.013: INFO: Found 1 / 1
Mar 26 22:27:21.013: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 26 22:27:21.041: INFO: Selector matched 1 pods for map[app:redis]
Mar 26 22:27:21.041: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 26 22:27:21.041: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config describe pod redis-master-ls5cp --namespace=e2e-tests-kubectl-fhn62'
Mar 26 22:27:21.459: INFO: stderr: ""
Mar 26 22:27:21.459: INFO: stdout: "Name:               redis-master-ls5cp\nNamespace:          e2e-tests-kubectl-fhn62\nPriority:           0\nPriorityClassName:  <none>\nNode:               ip-172-20-56-226.us-east-2.compute.internal/172.20.56.226\nStart Time:         Tue, 26 Mar 2019 22:27:18 -0400\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 100.96.2.156\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://f2ab2b3dc76adb1a3fd642e75d151dd9eb48778602761c9127cb7c3b98ce0eea\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 26 Mar 2019 22:27:19 -0400\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-vdhrq (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-vdhrq:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-vdhrq\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                  Message\n  ----    ------     ----  ----                                                  -------\n  Normal  Scheduled  3s    default-scheduler                                     Successfully assigned e2e-tests-kubectl-fhn62/redis-master-ls5cp to ip-172-20-56-226.us-east-2.compute.internal\n  Normal  Pulled     2s    kubelet, ip-172-20-56-226.us-east-2.compute.internal  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, ip-172-20-56-226.us-east-2.compute.internal  Created container\n  Normal  Started    2s    kubelet, ip-172-20-56-226.us-east-2.compute.internal  Started container\n"
Mar 26 22:27:21.459: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config describe rc redis-master --namespace=e2e-tests-kubectl-fhn62'
Mar 26 22:27:21.801: INFO: stderr: ""
Mar 26 22:27:21.801: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-fhn62\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-ls5cp\n"
Mar 26 22:27:21.801: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config describe service redis-master --namespace=e2e-tests-kubectl-fhn62'
Mar 26 22:27:22.136: INFO: stderr: ""
Mar 26 22:27:22.136: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-fhn62\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                100.66.70.80\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         100.96.2.156:6379\nSession Affinity:  None\nEvents:            <none>\n"
Mar 26 22:27:22.162: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config describe node ip-172-20-51-114.us-east-2.compute.internal'
Mar 26 22:27:22.538: INFO: stderr: ""
Mar 26 22:27:22.538: INFO: stdout: "Name:               ip-172-20-51-114.us-east-2.compute.internal\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=c4.large\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-east-2\n                    failure-domain.beta.kubernetes.io/zone=us-east-2a\n                    kops.k8s.io/instancegroup=master-us-east-2a\n                    kubernetes.io/hostname=ip-172-20-51-114.us-east-2.compute.internal\n                    kubernetes.io/role=master\n                    node-role.kubernetes.io/master=\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 26 Mar 2019 20:05:39 -0400\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Tue, 26 Mar 2019 20:05:43 -0400   Tue, 26 Mar 2019 20:05:43 -0400   RouteCreated                 RouteController created a route\n  OutOfDisk            False   Tue, 26 Mar 2019 22:27:16 -0400   Tue, 26 Mar 2019 20:05:39 -0400   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure       False   Tue, 26 Mar 2019 22:27:16 -0400   Tue, 26 Mar 2019 20:05:39 -0400   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 26 Mar 2019 22:27:16 -0400   Tue, 26 Mar 2019 20:05:39 -0400   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 26 Mar 2019 22:27:16 -0400   Tue, 26 Mar 2019 20:05:39 -0400   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 26 Mar 2019 22:27:16 -0400   Tue, 26 Mar 2019 20:05:39 -0400   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:   172.20.51.114\n  ExternalIP:   18.191.212.66\n  InternalDNS:  ip-172-20-51-114.us-east-2.compute.internal\n  Hostname:     ip-172-20-51-114.us-east-2.compute.internal\n  ExternalDNS:  ec2-18-191-212-66.us-east-2.compute.amazonaws.com\nCapacity:\n attachable-volumes-aws-ebs:  39\n cpu:                         2\n ephemeral-storage:           62843416Ki\n hugepages-1Gi:               0\n hugepages-2Mi:               0\n memory:                      3857012Ki\n pods:                        110\nAllocatable:\n attachable-volumes-aws-ebs:  39\n cpu:                         2\n ephemeral-storage:           57916492090\n hugepages-1Gi:               0\n hugepages-2Mi:               0\n memory:                      3754612Ki\n pods:                        110\nSystem Info:\n Machine ID:                 ce311ca7a2554036990bfd78e131abd1\n System UUID:                EC269718-5ABB-5317-9740-537A387062E7\n Boot ID:                    7bdecb9c-d7de-4984-809c-705945d5f002\n Kernel Version:             4.9.0-7-amd64\n OS Image:                   Debian GNU/Linux 9 (stretch)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.3\n Kubelet Version:            v1.12.7\n Kube-Proxy Version:         v1.12.7\nPodCIDR:                     100.96.0.0/24\nProviderID:                  aws:///us-east-2a/i-0aeab5d0ebbefecd5\nNon-terminated Pods:         (7 in total)\n  Namespace                  Name                                                                   CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                                   ------------  ----------  ---------------  -------------\n  kube-system                dns-controller-7cd56b9f88-s9shb                                        50m (2%)      0 (0%)      50Mi (1%)        0 (0%)\n  kube-system                etcd-manager-events-ip-172-20-51-114.us-east-2.compute.internal        100m (5%)     0 (0%)      100Mi (2%)       0 (0%)\n  kube-system                etcd-manager-main-ip-172-20-51-114.us-east-2.compute.internal          200m (10%)    0 (0%)      100Mi (2%)       0 (0%)\n  kube-system                kube-apiserver-ip-172-20-51-114.us-east-2.compute.internal             150m (7%)     0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-controller-manager-ip-172-20-51-114.us-east-2.compute.internal    100m (5%)     0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-proxy-ip-172-20-51-114.us-east-2.compute.internal                 100m (5%)     0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-scheduler-ip-172-20-51-114.us-east-2.compute.internal             100m (5%)     0 (0%)      0 (0%)           0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                    Requests    Limits\n  --------                    --------    ------\n  cpu                         800m (40%)  0 (0%)\n  memory                      250Mi (6%)  0 (0%)\n  attachable-volumes-aws-ebs  0           0\nEvents:                       <none>\n"
Mar 26 22:27:22.539: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config describe namespace e2e-tests-kubectl-fhn62'
Mar 26 22:27:22.880: INFO: stderr: ""
Mar 26 22:27:22.880: INFO: stdout: "Name:         e2e-tests-kubectl-fhn62\nLabels:       e2e-framework=kubectl\n              e2e-run=af136a82-5032-11e9-9bdd-d050998677c2\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:27:22.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-fhn62" for this suite.
Mar 26 22:27:44.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:27:45.452: INFO: namespace: e2e-tests-kubectl-fhn62, resource: bindings, ignored listing per whitelist
Mar 26 22:27:45.936: INFO: namespace e2e-tests-kubectl-fhn62 deletion completed in 23.028588577s

[32mâ€¢ [SLOW TEST:30.093 seconds][0m
[sig-cli] Kubectl client
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl describe
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Daemon set [Serial][0m 
  [1mshould run and stop simple daemon [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] Daemon set [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:27:45.936: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename daemonsets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating simple DaemonSet "daemon-set"
[1mSTEP[0m: Check that daemon pods launch on every node of the cluster.
Mar 26 22:27:46.915: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:27:46.941: INFO: Number of nodes with available pods: 0
Mar 26 22:27:46.941: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:27:47.967: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:27:47.994: INFO: Number of nodes with available pods: 0
Mar 26 22:27:47.994: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:27:48.968: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:27:48.995: INFO: Number of nodes with available pods: 2
Mar 26 22:27:48.995: INFO: Number of running nodes: 2, number of available pods: 2
[1mSTEP[0m: Stop a daemon pod, check that the daemon pod is revived.
Mar 26 22:27:49.107: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:27:49.133: INFO: Number of nodes with available pods: 1
Mar 26 22:27:49.133: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:27:50.160: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:27:50.186: INFO: Number of nodes with available pods: 1
Mar 26 22:27:50.186: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:27:51.160: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:27:51.185: INFO: Number of nodes with available pods: 1
Mar 26 22:27:51.185: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:27:52.159: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:27:52.185: INFO: Number of nodes with available pods: 1
Mar 26 22:27:52.185: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:27:53.160: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:27:53.186: INFO: Number of nodes with available pods: 1
Mar 26 22:27:53.186: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:27:54.160: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:27:54.185: INFO: Number of nodes with available pods: 1
Mar 26 22:27:54.185: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:27:55.160: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:27:55.187: INFO: Number of nodes with available pods: 1
Mar 26 22:27:55.187: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:27:56.160: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:27:56.185: INFO: Number of nodes with available pods: 1
Mar 26 22:27:56.185: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:27:57.160: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:27:57.194: INFO: Number of nodes with available pods: 1
Mar 26 22:27:57.194: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:27:58.160: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:27:58.185: INFO: Number of nodes with available pods: 1
Mar 26 22:27:58.185: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:27:59.167: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:27:59.197: INFO: Number of nodes with available pods: 1
Mar 26 22:27:59.197: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:28:00.159: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:28:00.185: INFO: Number of nodes with available pods: 1
Mar 26 22:28:00.185: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:28:01.160: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:28:01.185: INFO: Number of nodes with available pods: 1
Mar 26 22:28:01.185: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:28:02.160: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:28:02.186: INFO: Number of nodes with available pods: 1
Mar 26 22:28:02.186: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:28:03.160: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:28:03.187: INFO: Number of nodes with available pods: 1
Mar 26 22:28:03.187: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:28:04.161: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:28:04.187: INFO: Number of nodes with available pods: 1
Mar 26 22:28:04.187: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:28:05.163: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:28:05.192: INFO: Number of nodes with available pods: 1
Mar 26 22:28:05.192: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:28:06.160: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:28:06.186: INFO: Number of nodes with available pods: 1
Mar 26 22:28:06.186: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:28:07.160: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:28:07.186: INFO: Number of nodes with available pods: 1
Mar 26 22:28:07.186: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:28:08.160: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:28:08.185: INFO: Number of nodes with available pods: 1
Mar 26 22:28:08.185: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:28:09.160: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:28:09.187: INFO: Number of nodes with available pods: 1
Mar 26 22:28:09.187: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:28:10.159: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:28:10.185: INFO: Number of nodes with available pods: 1
Mar 26 22:28:10.185: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:28:11.159: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:28:11.185: INFO: Number of nodes with available pods: 1
Mar 26 22:28:11.185: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:28:12.160: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:28:12.186: INFO: Number of nodes with available pods: 1
Mar 26 22:28:12.186: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:28:13.160: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:28:13.191: INFO: Number of nodes with available pods: 1
Mar 26 22:28:13.191: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:28:14.160: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:28:14.186: INFO: Number of nodes with available pods: 1
Mar 26 22:28:14.186: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:28:15.160: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:28:15.186: INFO: Number of nodes with available pods: 1
Mar 26 22:28:15.186: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:28:16.159: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:28:16.185: INFO: Number of nodes with available pods: 1
Mar 26 22:28:16.185: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:28:17.160: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:28:17.186: INFO: Number of nodes with available pods: 1
Mar 26 22:28:17.186: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:28:18.166: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:28:18.194: INFO: Number of nodes with available pods: 1
Mar 26 22:28:18.194: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:28:19.160: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:28:19.189: INFO: Number of nodes with available pods: 1
Mar 26 22:28:19.189: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:28:20.161: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:28:20.190: INFO: Number of nodes with available pods: 1
Mar 26 22:28:20.190: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:28:21.160: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:28:21.186: INFO: Number of nodes with available pods: 1
Mar 26 22:28:21.186: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:28:22.160: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:28:22.186: INFO: Number of nodes with available pods: 1
Mar 26 22:28:22.186: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:28:23.162: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:28:23.192: INFO: Number of nodes with available pods: 1
Mar 26 22:28:23.192: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:28:24.163: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:28:24.189: INFO: Number of nodes with available pods: 2
Mar 26 22:28:24.189: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
[1mSTEP[0m: Deleting DaemonSet "daemon-set"
[1mSTEP[0m: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-srg9r, will wait for the garbage collector to delete the pods
Mar 26 22:28:24.319: INFO: Deleting {extensions DaemonSet} daemon-set took: 28.36563ms
Mar 26 22:28:24.419: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.23624ms
Mar 26 22:29:08.146: INFO: Number of nodes with available pods: 0
Mar 26 22:29:08.146: INFO: Number of running nodes: 0, number of available pods: 0
Mar 26 22:29:08.174: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-srg9r/daemonsets","resourceVersion":"20454"},"items":null}

Mar 26 22:29:08.202: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-srg9r/pods","resourceVersion":"20454"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:29:08.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-daemonsets-srg9r" for this suite.
Mar 26 22:29:14.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:29:15.035: INFO: namespace: e2e-tests-daemonsets-srg9r, resource: bindings, ignored listing per whitelist
Mar 26 22:29:15.342: INFO: namespace e2e-tests-daemonsets-srg9r deletion completed in 7.035730636s

[32mâ€¢ [SLOW TEST:89.406 seconds][0m
[sig-apps] Daemon set [Serial]
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  should run and stop simple daemon [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould update annotations on modification [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:29:15.343: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating the pod
Mar 26 22:29:18.891: INFO: Successfully updated pod "annotationupdate1de9b232-5038-11e9-9bdd-d050998677c2"
[AfterEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:29:22.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-smt4q" for this suite.
Mar 26 22:29:45.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:29:45.941: INFO: namespace: e2e-tests-projected-smt4q, resource: bindings, ignored listing per whitelist
Mar 26 22:29:46.070: INFO: namespace e2e-tests-projected-smt4q deletion completed in 23.049445806s

[32mâ€¢ [SLOW TEST:30.727 seconds][0m
[sig-storage] Projected
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35[0m
  should update annotations on modification [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould provide podname only [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:29:46.070: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 26 22:29:46.933: INFO: Waiting up to 5m0s for pod "downwardapi-volume-303a5a8d-5038-11e9-9bdd-d050998677c2" in namespace "e2e-tests-projected-wxkmb" to be "success or failure"
Mar 26 22:29:46.959: INFO: Pod "downwardapi-volume-303a5a8d-5038-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.572954ms
Mar 26 22:29:48.984: INFO: Pod "downwardapi-volume-303a5a8d-5038-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.051375388s
[1mSTEP[0m: Saw pod success
Mar 26 22:29:48.984: INFO: Pod "downwardapi-volume-303a5a8d-5038-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:29:49.010: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod downwardapi-volume-303a5a8d-5038-11e9-9bdd-d050998677c2 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:29:49.077: INFO: Waiting for pod downwardapi-volume-303a5a8d-5038-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:29:49.102: INFO: Pod downwardapi-volume-303a5a8d-5038-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:29:49.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-wxkmb" for this suite.
Mar 26 22:29:55.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:29:55.468: INFO: namespace: e2e-tests-projected-wxkmb, resource: bindings, ignored listing per whitelist
Mar 26 22:29:56.308: INFO: namespace e2e-tests-projected-wxkmb deletion completed in 7.17948473s

[32mâ€¢ [SLOW TEST:10.238 seconds][0m
[sig-storage] Projected
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35[0m
  should provide podname only [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mshould *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Probing container
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:29:56.309: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename container-probe
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating pod liveness-exec in namespace e2e-tests-container-probe-gsxp5
Mar 26 22:29:59.347: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-gsxp5
[1mSTEP[0m: checking the pod's current state and verifying that restartCount is present
Mar 26 22:29:59.372: INFO: Initial restart count of pod liveness-exec is 0
[1mSTEP[0m: deleting the pod
[AfterEach] [k8s.io] Probing container
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:34:00.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-container-probe-gsxp5" for this suite.
Mar 26 22:34:06.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:34:07.696: INFO: namespace: e2e-tests-container-probe-gsxp5, resource: bindings, ignored listing per whitelist
Mar 26 22:34:07.746: INFO: namespace e2e-tests-container-probe-gsxp5 deletion completed in 7.005835713s

[32mâ€¢ [SLOW TEST:251.438 seconds][0m
[k8s.io] Probing container
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Guestbook application[0m 
  [1mshould create and stop a working application  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:34:07.746: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating all guestbook components
Mar 26 22:34:08.572: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Mar 26 22:34:08.572: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config create -f - --namespace=e2e-tests-kubectl-sgscd'
Mar 26 22:34:09.040: INFO: stderr: ""
Mar 26 22:34:09.040: INFO: stdout: "service/redis-slave created\n"
Mar 26 22:34:09.040: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Mar 26 22:34:09.040: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config create -f - --namespace=e2e-tests-kubectl-sgscd'
Mar 26 22:34:09.491: INFO: stderr: ""
Mar 26 22:34:09.492: INFO: stdout: "service/redis-master created\n"
Mar 26 22:34:09.492: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Mar 26 22:34:09.492: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config create -f - --namespace=e2e-tests-kubectl-sgscd'
Mar 26 22:34:09.945: INFO: stderr: ""
Mar 26 22:34:09.945: INFO: stdout: "service/frontend created\n"
Mar 26 22:34:09.945: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Mar 26 22:34:09.945: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config create -f - --namespace=e2e-tests-kubectl-sgscd'
Mar 26 22:34:10.409: INFO: stderr: ""
Mar 26 22:34:10.409: INFO: stdout: "deployment.extensions/frontend created\n"
Mar 26 22:34:10.409: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Mar 26 22:34:10.409: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config create -f - --namespace=e2e-tests-kubectl-sgscd'
Mar 26 22:34:10.878: INFO: stderr: ""
Mar 26 22:34:10.878: INFO: stdout: "deployment.extensions/redis-master created\n"
Mar 26 22:34:10.878: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Mar 26 22:34:10.878: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config create -f - --namespace=e2e-tests-kubectl-sgscd'
Mar 26 22:34:11.339: INFO: stderr: ""
Mar 26 22:34:11.339: INFO: stdout: "deployment.extensions/redis-slave created\n"
[1mSTEP[0m: validating guestbook app
Mar 26 22:34:11.339: INFO: Waiting for all frontend pods to be Running.
Mar 26 22:34:26.389: INFO: Waiting for frontend to serve content.
Mar 26 22:34:31.428: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Mar 26 22:34:36.463: INFO: Trying to add a new entry to the guestbook.
Mar 26 22:34:36.499: INFO: Verifying that added entry can be retrieved.
[1mSTEP[0m: using delete to clean up resources
Mar 26 22:34:36.534: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-sgscd'
Mar 26 22:34:36.822: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 26 22:34:36.822: INFO: stdout: "service \"redis-slave\" force deleted\n"
[1mSTEP[0m: using delete to clean up resources
Mar 26 22:34:36.822: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-sgscd'
Mar 26 22:34:37.081: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 26 22:34:37.081: INFO: stdout: "service \"redis-master\" force deleted\n"
[1mSTEP[0m: using delete to clean up resources
Mar 26 22:34:37.081: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-sgscd'
Mar 26 22:34:37.354: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 26 22:34:37.354: INFO: stdout: "service \"frontend\" force deleted\n"
[1mSTEP[0m: using delete to clean up resources
Mar 26 22:34:37.354: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-sgscd'
Mar 26 22:34:37.604: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 26 22:34:37.604: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
[1mSTEP[0m: using delete to clean up resources
Mar 26 22:34:37.604: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-sgscd'
Mar 26 22:34:37.856: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 26 22:34:37.856: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
[1mSTEP[0m: using delete to clean up resources
Mar 26 22:34:37.856: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-sgscd'
Mar 26 22:34:38.117: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 26 22:34:38.117: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:34:38.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-sgscd" for this suite.
Mar 26 22:35:24.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:35:24.752: INFO: namespace: e2e-tests-kubectl-sgscd, resource: bindings, ignored listing per whitelist
Mar 26 22:35:25.185: INFO: namespace e2e-tests-kubectl-sgscd deletion completed in 47.041716356s

[32mâ€¢ [SLOW TEST:77.438 seconds][0m
[sig-cli] Kubectl client
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Guestbook application
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should create and stop a working application  [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Watchers[0m 
  [1mshould be able to start watching from a specific resource version [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Watchers
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:35:25.185: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename watch
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating a new configmap
[1mSTEP[0m: modifying the configmap once
[1mSTEP[0m: modifying the configmap a second time
[1mSTEP[0m: deleting the configmap
[1mSTEP[0m: creating a watch on configmaps from the resource version returned by the first update
[1mSTEP[0m: Expecting to observe notifications for all changes to the configmap after the first update
Mar 26 22:35:26.196: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-swr9p,SelfLink:/api/v1/namespaces/e2e-tests-watch-swr9p/configmaps/e2e-watch-test-resource-version,UID:fa5d5695-5038-11e9-8eb3-023bf32bf132,ResourceVersion:21167,Generation:0,CreationTimestamp:2019-03-26 22:35:26 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 26 22:35:26.197: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-swr9p,SelfLink:/api/v1/namespaces/e2e-tests-watch-swr9p/configmaps/e2e-watch-test-resource-version,UID:fa5d5695-5038-11e9-8eb3-023bf32bf132,ResourceVersion:21168,Generation:0,CreationTimestamp:2019-03-26 22:35:26 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:35:26.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-watch-swr9p" for this suite.
Mar 26 22:35:32.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:35:32.628: INFO: namespace: e2e-tests-watch-swr9p, resource: bindings, ignored listing per whitelist
Mar 26 22:35:33.238: INFO: namespace e2e-tests-watch-swr9p deletion completed in 7.014350429s

[32mâ€¢ [SLOW TEST:8.053 seconds][0m
[sig-api-machinery] Watchers
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should be able to start watching from a specific resource version [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Deployment[0m 
  [1mdeployment should delete old replica sets [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] Deployment
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:35:33.238: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename deployment
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 22:35:34.119: INFO: Pod name cleanup-pod: Found 1 pods out of 1
[1mSTEP[0m: ensuring each pod is running
Mar 26 22:35:36.171: INFO: Creating deployment test-cleanup-deployment
[1mSTEP[0m: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 26 22:35:38.380: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-xvrrf,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xvrrf/deployments/test-cleanup-deployment,UID:00728390-5039-11e9-8eb3-023bf32bf132,ResourceVersion:21223,Generation:1,CreationTimestamp:2019-03-26 22:35:36 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-26 22:35:36 -0400 EDT 2019-03-26 22:35:36 -0400 EDT MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-26 22:35:37 -0400 EDT 2019-03-26 22:35:36 -0400 EDT NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-755f6b95cc" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar 26 22:35:38.406: INFO: New ReplicaSet "test-cleanup-deployment-755f6b95cc" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-755f6b95cc,GenerateName:,Namespace:e2e-tests-deployment-xvrrf,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xvrrf/replicasets/test-cleanup-deployment-755f6b95cc,UID:00748965-5039-11e9-8eb3-023bf32bf132,ResourceVersion:21216,Generation:1,CreationTimestamp:2019-03-26 22:35:36 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 00728390-5039-11e9-8eb3-023bf32bf132 0xc002fbdd17 0xc002fbdd18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 26 22:35:38.432: INFO: Pod "test-cleanup-deployment-755f6b95cc-vss52" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-755f6b95cc-vss52,GenerateName:test-cleanup-deployment-755f6b95cc-,Namespace:e2e-tests-deployment-xvrrf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xvrrf/pods/test-cleanup-deployment-755f6b95cc-vss52,UID:007509ce-5039-11e9-8eb3-023bf32bf132,ResourceVersion:21215,Generation:0,CreationTimestamp:2019-03-26 22:35:36 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-755f6b95cc 00748965-5039-11e9-8eb3-023bf32bf132 0xc001977d77 0xc001977d78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g2tfg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g2tfg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-g2tfg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-56-226.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001977de0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001977e00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 22:35:36 -0400 EDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 22:35:37 -0400 EDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 22:35:37 -0400 EDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 22:35:36 -0400 EDT  }],Message:,Reason:,HostIP:172.20.56.226,PodIP:100.96.2.166,StartTime:2019-03-26 22:35:36 -0400 EDT,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-26 22:35:37 -0400 EDT,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://791b97be97c414fe85259968ff19a46d6e659e0ea14ce02a197767826ecb9721}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:35:38.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-deployment-xvrrf" for this suite.
Mar 26 22:35:44.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:35:45.381: INFO: namespace: e2e-tests-deployment-xvrrf, resource: bindings, ignored listing per whitelist
Mar 26 22:35:45.622: INFO: namespace e2e-tests-deployment-xvrrf deletion completed in 7.163177817s

[32mâ€¢ [SLOW TEST:12.384 seconds][0m
[sig-apps] Deployment
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  deployment should delete old replica sets [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl run rc[0m 
  [1mshould create an rc from an image  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:35:45.622: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: running the image docker.io/library/nginx:1.14-alpine
Mar 26 22:35:46.467: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-dngth'
Mar 26 22:35:46.740: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar 26 22:35:46.740: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
[1mSTEP[0m: verifying the rc e2e-test-nginx-rc was created
[1mSTEP[0m: verifying the pod controlled by rc e2e-test-nginx-rc was created
[1mSTEP[0m: confirm that you can get logs from an rc
Mar 26 22:35:46.791: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-blcmj]
Mar 26 22:35:46.791: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-blcmj" in namespace "e2e-tests-kubectl-dngth" to be "running and ready"
Mar 26 22:35:46.819: INFO: Pod "e2e-test-nginx-rc-blcmj": Phase="Pending", Reason="", readiness=false. Elapsed: 27.628936ms
Mar 26 22:35:48.849: INFO: Pod "e2e-test-nginx-rc-blcmj": Phase="Running", Reason="", readiness=true. Elapsed: 2.058295357s
Mar 26 22:35:48.849: INFO: Pod "e2e-test-nginx-rc-blcmj" satisfied condition "running and ready"
Mar 26 22:35:48.849: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-blcmj]
Mar 26 22:35:48.850: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-dngth'
Mar 26 22:35:49.176: INFO: stderr: ""
Mar 26 22:35:49.176: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Mar 26 22:35:49.176: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-dngth'
Mar 26 22:35:49.461: INFO: stderr: ""
Mar 26 22:35:49.461: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:35:49.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-dngth" for this suite.
Mar 26 22:36:11.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:36:12.593: INFO: namespace: e2e-tests-kubectl-dngth, resource: bindings, ignored listing per whitelist
Mar 26 22:36:12.644: INFO: namespace e2e-tests-kubectl-dngth deletion completed in 23.155375895s

[32mâ€¢ [SLOW TEST:27.022 seconds][0m
[sig-cli] Kubectl client
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl run rc
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should create an rc from an image  [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl cluster-info[0m 
  [1mshould check if Kubernetes master services is included in cluster-info  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:36:12.644: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: validating cluster-info
Mar 26 22:36:13.498: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config cluster-info'
Mar 26 22:36:13.761: INFO: stderr: ""
Mar 26 22:36:13.761: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:36:13.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-z22bf" for this suite.
Mar 26 22:36:19.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:36:20.595: INFO: namespace: e2e-tests-kubectl-z22bf, resource: bindings, ignored listing per whitelist
Mar 26 22:36:20.847: INFO: namespace e2e-tests-kubectl-z22bf deletion completed in 7.042604821s

[32mâ€¢ [SLOW TEST:8.203 seconds][0m
[sig-cli] Kubectl client
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl cluster-info
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Daemon set [Serial][0m 
  [1mshould rollback without unnecessary restarts [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] Daemon set [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:36:20.847: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename daemonsets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 22:36:21.746: INFO: Create a RollingUpdate DaemonSet
Mar 26 22:36:21.776: INFO: Check that daemon pods launch on every node of the cluster
Mar 26 22:36:21.804: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:36:21.829: INFO: Number of nodes with available pods: 0
Mar 26 22:36:21.829: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:36:22.856: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:36:22.881: INFO: Number of nodes with available pods: 0
Mar 26 22:36:22.881: INFO: Node ip-172-20-53-156.us-east-2.compute.internal is running more than one daemon pod
Mar 26 22:36:23.860: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:36:23.887: INFO: Number of nodes with available pods: 2
Mar 26 22:36:23.887: INFO: Number of running nodes: 2, number of available pods: 2
Mar 26 22:36:23.887: INFO: Update the DaemonSet to trigger a rollout
Mar 26 22:36:23.939: INFO: Updating DaemonSet daemon-set
Mar 26 22:37:09.018: INFO: Roll back the DaemonSet before rollout is complete
Mar 26 22:37:09.071: INFO: Updating DaemonSet daemon-set
Mar 26 22:37:09.071: INFO: Make sure DaemonSet rollback is complete
Mar 26 22:37:09.096: INFO: Wrong image for pod: daemon-set-6vhcc. Expected: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1, got: foo:non-existent.
Mar 26 22:37:09.096: INFO: Pod daemon-set-6vhcc is not available
Mar 26 22:37:09.126: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:37:10.152: INFO: Wrong image for pod: daemon-set-6vhcc. Expected: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1, got: foo:non-existent.
Mar 26 22:37:10.152: INFO: Pod daemon-set-6vhcc is not available
Mar 26 22:37:10.179: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 26 22:37:11.154: INFO: Pod daemon-set-v954d is not available
Mar 26 22:37:11.180: INFO: DaemonSet pods can't tolerate node ip-172-20-51-114.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
[1mSTEP[0m: Deleting DaemonSet "daemon-set"
[1mSTEP[0m: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-fg7nj, will wait for the garbage collector to delete the pods
Mar 26 22:37:11.336: INFO: Deleting {extensions DaemonSet} daemon-set took: 27.142513ms
Mar 26 22:37:11.436: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.238181ms
Mar 26 22:37:50.661: INFO: Number of nodes with available pods: 0
Mar 26 22:37:50.662: INFO: Number of running nodes: 0, number of available pods: 0
Mar 26 22:37:50.686: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-fg7nj/daemonsets","resourceVersion":"21512"},"items":null}

Mar 26 22:37:50.712: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-fg7nj/pods","resourceVersion":"21512"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:37:50.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-daemonsets-fg7nj" for this suite.
Mar 26 22:37:56.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:37:57.476: INFO: namespace: e2e-tests-daemonsets-fg7nj, resource: bindings, ignored listing per whitelist
Mar 26 22:37:57.883: INFO: namespace e2e-tests-daemonsets-fg7nj deletion completed in 7.062325638s

[32mâ€¢ [SLOW TEST:97.036 seconds][0m
[sig-apps] Daemon set [Serial]
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  should rollback without unnecessary restarts [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Service endpoints latency[0m 
  [1mshould not be very high  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-network] Service endpoints latency
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:37:57.884: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename svc-latency
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-9bq8p
I0326 22:37:58.739271    2026 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-9bq8p, replica count: 1
I0326 22:37:59.789626    2026 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 26 22:37:59.921: INFO: Created: latency-svc-hwx5b
Mar 26 22:37:59.935: INFO: Got endpoints: latency-svc-hwx5b [45.523595ms]
Mar 26 22:37:59.970: INFO: Created: latency-svc-fzfgs
Mar 26 22:37:59.977: INFO: Got endpoints: latency-svc-fzfgs [42.19182ms]
Mar 26 22:37:59.982: INFO: Created: latency-svc-2bjlq
Mar 26 22:37:59.987: INFO: Got endpoints: latency-svc-2bjlq [51.898343ms]
Mar 26 22:37:59.991: INFO: Created: latency-svc-4pw6f
Mar 26 22:37:59.999: INFO: Created: latency-svc-qcn9v
Mar 26 22:38:00.001: INFO: Got endpoints: latency-svc-4pw6f [65.78569ms]
Mar 26 22:38:00.006: INFO: Got endpoints: latency-svc-qcn9v [71.028482ms]
Mar 26 22:38:00.006: INFO: Created: latency-svc-ktkck
Mar 26 22:38:00.021: INFO: Created: latency-svc-pnzl4
Mar 26 22:38:00.021: INFO: Got endpoints: latency-svc-ktkck [86.209176ms]
Mar 26 22:38:00.028: INFO: Created: latency-svc-zwklx
Mar 26 22:38:00.028: INFO: Got endpoints: latency-svc-pnzl4 [93.465141ms]
Mar 26 22:38:00.037: INFO: Created: latency-svc-ccl7c
Mar 26 22:38:00.037: INFO: Got endpoints: latency-svc-zwklx [102.284055ms]
Mar 26 22:38:00.041: INFO: Got endpoints: latency-svc-ccl7c [106.479833ms]
Mar 26 22:38:00.047: INFO: Created: latency-svc-xhgpz
Mar 26 22:38:00.051: INFO: Got endpoints: latency-svc-xhgpz [115.844726ms]
Mar 26 22:38:00.056: INFO: Created: latency-svc-jqgk5
Mar 26 22:38:00.059: INFO: Got endpoints: latency-svc-jqgk5 [124.195122ms]
Mar 26 22:38:00.061: INFO: Created: latency-svc-jt4tk
Mar 26 22:38:00.076: INFO: Created: latency-svc-hwk5x
Mar 26 22:38:00.077: INFO: Got endpoints: latency-svc-jt4tk [141.471805ms]
Mar 26 22:38:00.078: INFO: Got endpoints: latency-svc-hwk5x [142.798583ms]
Mar 26 22:38:00.087: INFO: Created: latency-svc-2v85l
Mar 26 22:38:00.091: INFO: Created: latency-svc-qf7hf
Mar 26 22:38:00.092: INFO: Got endpoints: latency-svc-2v85l [156.539728ms]
Mar 26 22:38:00.096: INFO: Got endpoints: latency-svc-qf7hf [161.066207ms]
Mar 26 22:38:00.100: INFO: Created: latency-svc-9zlw6
Mar 26 22:38:00.104: INFO: Got endpoints: latency-svc-9zlw6 [169.384086ms]
Mar 26 22:38:00.110: INFO: Created: latency-svc-6xj88
Mar 26 22:38:00.115: INFO: Got endpoints: latency-svc-6xj88 [137.619756ms]
Mar 26 22:38:00.116: INFO: Created: latency-svc-hjwtb
Mar 26 22:38:00.120: INFO: Got endpoints: latency-svc-hjwtb [133.335556ms]
Mar 26 22:38:00.126: INFO: Created: latency-svc-vnt8p
Mar 26 22:38:00.134: INFO: Got endpoints: latency-svc-vnt8p [133.634839ms]
Mar 26 22:38:00.135: INFO: Created: latency-svc-ml4vd
Mar 26 22:38:00.146: INFO: Got endpoints: latency-svc-ml4vd [140.318267ms]
Mar 26 22:38:00.151: INFO: Created: latency-svc-c9mww
Mar 26 22:38:00.157: INFO: Got endpoints: latency-svc-c9mww [135.243632ms]
Mar 26 22:38:00.162: INFO: Created: latency-svc-cg68t
Mar 26 22:38:00.162: INFO: Got endpoints: latency-svc-cg68t [134.000452ms]
Mar 26 22:38:00.167: INFO: Created: latency-svc-pvqvq
Mar 26 22:38:00.173: INFO: Got endpoints: latency-svc-pvqvq [135.66407ms]
Mar 26 22:38:00.174: INFO: Created: latency-svc-fb745
Mar 26 22:38:00.180: INFO: Got endpoints: latency-svc-fb745 [138.871388ms]
Mar 26 22:38:00.183: INFO: Created: latency-svc-nk2vk
Mar 26 22:38:00.190: INFO: Got endpoints: latency-svc-nk2vk [138.940406ms]
Mar 26 22:38:00.191: INFO: Created: latency-svc-hdvrg
Mar 26 22:38:00.198: INFO: Got endpoints: latency-svc-hdvrg [139.123902ms]
Mar 26 22:38:00.200: INFO: Created: latency-svc-52nk7
Mar 26 22:38:00.207: INFO: Got endpoints: latency-svc-52nk7 [130.894623ms]
Mar 26 22:38:00.210: INFO: Created: latency-svc-xv4xg
Mar 26 22:38:00.218: INFO: Created: latency-svc-gtmbl
Mar 26 22:38:00.219: INFO: Got endpoints: latency-svc-xv4xg [141.304325ms]
Mar 26 22:38:00.222: INFO: Got endpoints: latency-svc-gtmbl [130.800131ms]
Mar 26 22:38:00.229: INFO: Created: latency-svc-ftslm
Mar 26 22:38:00.237: INFO: Got endpoints: latency-svc-ftslm [140.800957ms]
Mar 26 22:38:00.239: INFO: Created: latency-svc-9qdb4
Mar 26 22:38:00.248: INFO: Created: latency-svc-mbf5g
Mar 26 22:38:00.252: INFO: Got endpoints: latency-svc-9qdb4 [147.074713ms]
Mar 26 22:38:00.253: INFO: Got endpoints: latency-svc-mbf5g [138.541071ms]
Mar 26 22:38:00.261: INFO: Created: latency-svc-rc6q8
Mar 26 22:38:00.271: INFO: Got endpoints: latency-svc-rc6q8 [150.860321ms]
Mar 26 22:38:00.277: INFO: Created: latency-svc-rxnk7
Mar 26 22:38:00.290: INFO: Created: latency-svc-qv6dl
Mar 26 22:38:00.291: INFO: Got endpoints: latency-svc-rxnk7 [156.914999ms]
Mar 26 22:38:00.295: INFO: Got endpoints: latency-svc-qv6dl [148.795751ms]
Mar 26 22:38:00.300: INFO: Created: latency-svc-7nq5d
Mar 26 22:38:00.306: INFO: Got endpoints: latency-svc-7nq5d [148.953964ms]
Mar 26 22:38:00.310: INFO: Created: latency-svc-ln62b
Mar 26 22:38:00.313: INFO: Created: latency-svc-hkfx7
Mar 26 22:38:00.325: INFO: Created: latency-svc-jn7xx
Mar 26 22:38:00.331: INFO: Got endpoints: latency-svc-ln62b [168.83928ms]
Mar 26 22:38:00.337: INFO: Got endpoints: latency-svc-hkfx7 [164.032764ms]
Mar 26 22:38:00.337: INFO: Created: latency-svc-h8lb6
Mar 26 22:38:00.343: INFO: Created: latency-svc-r4zvq
Mar 26 22:38:00.354: INFO: Created: latency-svc-k566w
Mar 26 22:38:00.363: INFO: Created: latency-svc-mtlz2
Mar 26 22:38:00.373: INFO: Created: latency-svc-xrr8w
Mar 26 22:38:00.378: INFO: Created: latency-svc-w5bnx
Mar 26 22:38:00.384: INFO: Got endpoints: latency-svc-jn7xx [203.316796ms]
Mar 26 22:38:00.391: INFO: Created: latency-svc-ls2js
Mar 26 22:38:00.408: INFO: Created: latency-svc-dcwcm
Mar 26 22:38:00.420: INFO: Created: latency-svc-f9wgd
Mar 26 22:38:00.428: INFO: Created: latency-svc-zj4vz
Mar 26 22:38:00.431: INFO: Got endpoints: latency-svc-h8lb6 [241.571509ms]
Mar 26 22:38:00.434: INFO: Created: latency-svc-2h5vx
Mar 26 22:38:00.444: INFO: Created: latency-svc-kg47r
Mar 26 22:38:00.449: INFO: Created: latency-svc-c25kr
Mar 26 22:38:00.461: INFO: Created: latency-svc-r7mx7
Mar 26 22:38:00.464: INFO: Created: latency-svc-m55sw
Mar 26 22:38:00.473: INFO: Created: latency-svc-tfv7s
Mar 26 22:38:00.476: INFO: Got endpoints: latency-svc-r4zvq [277.474433ms]
Mar 26 22:38:00.510: INFO: Created: latency-svc-kcnkx
Mar 26 22:38:00.525: INFO: Got endpoints: latency-svc-k566w [317.407657ms]
Mar 26 22:38:00.566: INFO: Created: latency-svc-ggdks
Mar 26 22:38:00.576: INFO: Got endpoints: latency-svc-mtlz2 [356.956871ms]
Mar 26 22:38:00.612: INFO: Created: latency-svc-zzdr7
Mar 26 22:38:00.625: INFO: Got endpoints: latency-svc-xrr8w [402.405283ms]
Mar 26 22:38:00.661: INFO: Created: latency-svc-tjv8w
Mar 26 22:38:00.676: INFO: Got endpoints: latency-svc-w5bnx [438.536982ms]
Mar 26 22:38:00.708: INFO: Created: latency-svc-nqtfl
Mar 26 22:38:00.726: INFO: Got endpoints: latency-svc-ls2js [474.488777ms]
Mar 26 22:38:00.759: INFO: Created: latency-svc-ddzp6
Mar 26 22:38:00.776: INFO: Got endpoints: latency-svc-dcwcm [522.667265ms]
Mar 26 22:38:00.814: INFO: Created: latency-svc-c98z8
Mar 26 22:38:00.836: INFO: Got endpoints: latency-svc-f9wgd [565.23302ms]
Mar 26 22:38:00.876: INFO: Created: latency-svc-tpppl
Mar 26 22:38:00.879: INFO: Got endpoints: latency-svc-zj4vz [587.497959ms]
Mar 26 22:38:00.923: INFO: Created: latency-svc-m5ck9
Mar 26 22:38:00.932: INFO: Got endpoints: latency-svc-2h5vx [637.204007ms]
Mar 26 22:38:00.969: INFO: Created: latency-svc-8n4sj
Mar 26 22:38:00.979: INFO: Got endpoints: latency-svc-kg47r [673.885887ms]
Mar 26 22:38:01.028: INFO: Created: latency-svc-tf5bg
Mar 26 22:38:01.047: INFO: Got endpoints: latency-svc-c25kr [715.410889ms]
Mar 26 22:38:01.104: INFO: Got endpoints: latency-svc-r7mx7 [767.25946ms]
Mar 26 22:38:01.109: INFO: Created: latency-svc-7kqft
Mar 26 22:38:01.143: INFO: Got endpoints: latency-svc-m55sw [759.137281ms]
Mar 26 22:38:01.162: INFO: Created: latency-svc-nx79d
Mar 26 22:38:01.211: INFO: Created: latency-svc-mgcvk
Mar 26 22:38:01.212: INFO: Got endpoints: latency-svc-tfv7s [780.041021ms]
Mar 26 22:38:01.248: INFO: Got endpoints: latency-svc-kcnkx [771.821047ms]
Mar 26 22:38:01.261: INFO: Created: latency-svc-zf726
Mar 26 22:38:01.297: INFO: Got endpoints: latency-svc-ggdks [771.687646ms]
Mar 26 22:38:01.299: INFO: Created: latency-svc-5d4bl
Mar 26 22:38:01.336: INFO: Got endpoints: latency-svc-zzdr7 [760.305484ms]
Mar 26 22:38:01.342: INFO: Created: latency-svc-v9v9d
Mar 26 22:38:01.374: INFO: Created: latency-svc-skdm6
Mar 26 22:38:01.382: INFO: Got endpoints: latency-svc-tjv8w [757.510058ms]
Mar 26 22:38:01.423: INFO: Created: latency-svc-n87k8
Mar 26 22:38:01.434: INFO: Got endpoints: latency-svc-nqtfl [758.642322ms]
Mar 26 22:38:01.469: INFO: Created: latency-svc-45qdw
Mar 26 22:38:01.476: INFO: Got endpoints: latency-svc-ddzp6 [749.420412ms]
Mar 26 22:38:01.507: INFO: Created: latency-svc-9wfb4
Mar 26 22:38:01.529: INFO: Got endpoints: latency-svc-c98z8 [752.630637ms]
Mar 26 22:38:01.561: INFO: Created: latency-svc-mm5mf
Mar 26 22:38:01.577: INFO: Got endpoints: latency-svc-tpppl [739.973719ms]
Mar 26 22:38:01.610: INFO: Created: latency-svc-rjvhw
Mar 26 22:38:01.625: INFO: Got endpoints: latency-svc-m5ck9 [746.06087ms]
Mar 26 22:38:01.658: INFO: Created: latency-svc-4swj7
Mar 26 22:38:01.675: INFO: Got endpoints: latency-svc-8n4sj [743.008096ms]
Mar 26 22:38:01.715: INFO: Created: latency-svc-jrqjw
Mar 26 22:38:01.725: INFO: Got endpoints: latency-svc-tf5bg [745.376007ms]
Mar 26 22:38:01.759: INFO: Created: latency-svc-pmcgb
Mar 26 22:38:01.775: INFO: Got endpoints: latency-svc-7kqft [727.907547ms]
Mar 26 22:38:01.808: INFO: Created: latency-svc-zs4cq
Mar 26 22:38:01.826: INFO: Got endpoints: latency-svc-nx79d [721.136717ms]
Mar 26 22:38:01.857: INFO: Created: latency-svc-cwnjg
Mar 26 22:38:01.876: INFO: Got endpoints: latency-svc-mgcvk [732.668949ms]
Mar 26 22:38:01.911: INFO: Created: latency-svc-zhhq9
Mar 26 22:38:01.925: INFO: Got endpoints: latency-svc-zf726 [713.499601ms]
Mar 26 22:38:01.956: INFO: Created: latency-svc-ljpsv
Mar 26 22:38:01.975: INFO: Got endpoints: latency-svc-5d4bl [727.681944ms]
Mar 26 22:38:02.008: INFO: Created: latency-svc-r6zlp
Mar 26 22:38:02.025: INFO: Got endpoints: latency-svc-v9v9d [728.331601ms]
Mar 26 22:38:02.058: INFO: Created: latency-svc-t4rdm
Mar 26 22:38:02.080: INFO: Got endpoints: latency-svc-skdm6 [743.340595ms]
Mar 26 22:38:02.112: INFO: Created: latency-svc-7x9vw
Mar 26 22:38:02.126: INFO: Got endpoints: latency-svc-n87k8 [743.342882ms]
Mar 26 22:38:02.161: INFO: Created: latency-svc-djrv8
Mar 26 22:38:02.175: INFO: Got endpoints: latency-svc-45qdw [741.026146ms]
Mar 26 22:38:02.208: INFO: Created: latency-svc-drk2c
Mar 26 22:38:02.225: INFO: Got endpoints: latency-svc-9wfb4 [749.507015ms]
Mar 26 22:38:02.258: INFO: Created: latency-svc-tp8pv
Mar 26 22:38:02.275: INFO: Got endpoints: latency-svc-mm5mf [746.498265ms]
Mar 26 22:38:02.330: INFO: Created: latency-svc-f59vc
Mar 26 22:38:02.333: INFO: Got endpoints: latency-svc-rjvhw [756.50504ms]
Mar 26 22:38:02.376: INFO: Created: latency-svc-6zc4s
Mar 26 22:38:02.384: INFO: Got endpoints: latency-svc-4swj7 [758.545591ms]
Mar 26 22:38:02.430: INFO: Created: latency-svc-dv94k
Mar 26 22:38:02.431: INFO: Got endpoints: latency-svc-jrqjw [755.676325ms]
Mar 26 22:38:02.472: INFO: Created: latency-svc-8spzk
Mar 26 22:38:02.480: INFO: Got endpoints: latency-svc-pmcgb [755.235147ms]
Mar 26 22:38:02.514: INFO: Created: latency-svc-bbxs5
Mar 26 22:38:02.527: INFO: Got endpoints: latency-svc-zs4cq [751.863038ms]
Mar 26 22:38:02.560: INFO: Created: latency-svc-bwnqj
Mar 26 22:38:02.578: INFO: Got endpoints: latency-svc-cwnjg [752.14925ms]
Mar 26 22:38:02.611: INFO: Created: latency-svc-pf6kv
Mar 26 22:38:02.626: INFO: Got endpoints: latency-svc-zhhq9 [750.194814ms]
Mar 26 22:38:02.659: INFO: Created: latency-svc-64plq
Mar 26 22:38:02.676: INFO: Got endpoints: latency-svc-ljpsv [750.796836ms]
Mar 26 22:38:02.709: INFO: Created: latency-svc-j9dzq
Mar 26 22:38:02.725: INFO: Got endpoints: latency-svc-r6zlp [749.625485ms]
Mar 26 22:38:02.758: INFO: Created: latency-svc-jxzqk
Mar 26 22:38:02.775: INFO: Got endpoints: latency-svc-t4rdm [750.336678ms]
Mar 26 22:38:02.810: INFO: Created: latency-svc-5k9db
Mar 26 22:38:02.826: INFO: Got endpoints: latency-svc-7x9vw [745.908159ms]
Mar 26 22:38:02.856: INFO: Created: latency-svc-vg7zr
Mar 26 22:38:02.879: INFO: Got endpoints: latency-svc-djrv8 [752.804981ms]
Mar 26 22:38:02.915: INFO: Created: latency-svc-pkmvq
Mar 26 22:38:02.925: INFO: Got endpoints: latency-svc-drk2c [749.605598ms]
Mar 26 22:38:02.961: INFO: Created: latency-svc-2wrwm
Mar 26 22:38:02.976: INFO: Got endpoints: latency-svc-tp8pv [750.469177ms]
Mar 26 22:38:03.008: INFO: Created: latency-svc-p7rwp
Mar 26 22:38:03.025: INFO: Got endpoints: latency-svc-f59vc [750.141874ms]
Mar 26 22:38:03.057: INFO: Created: latency-svc-d4hrf
Mar 26 22:38:03.076: INFO: Got endpoints: latency-svc-6zc4s [742.480613ms]
Mar 26 22:38:03.108: INFO: Created: latency-svc-9qbnj
Mar 26 22:38:03.126: INFO: Got endpoints: latency-svc-dv94k [741.954989ms]
Mar 26 22:38:03.159: INFO: Created: latency-svc-nrbxd
Mar 26 22:38:03.175: INFO: Got endpoints: latency-svc-8spzk [743.652545ms]
Mar 26 22:38:03.207: INFO: Created: latency-svc-jl5p9
Mar 26 22:38:03.225: INFO: Got endpoints: latency-svc-bbxs5 [745.227894ms]
Mar 26 22:38:03.264: INFO: Created: latency-svc-2wbcl
Mar 26 22:38:03.276: INFO: Got endpoints: latency-svc-bwnqj [749.061787ms]
Mar 26 22:38:03.308: INFO: Created: latency-svc-bn76g
Mar 26 22:38:03.327: INFO: Got endpoints: latency-svc-pf6kv [749.151984ms]
Mar 26 22:38:03.357: INFO: Created: latency-svc-nqfhs
Mar 26 22:38:03.375: INFO: Got endpoints: latency-svc-64plq [749.224605ms]
Mar 26 22:38:03.411: INFO: Created: latency-svc-bd7tz
Mar 26 22:38:03.426: INFO: Got endpoints: latency-svc-j9dzq [750.073206ms]
Mar 26 22:38:03.463: INFO: Created: latency-svc-l455q
Mar 26 22:38:03.475: INFO: Got endpoints: latency-svc-jxzqk [749.744426ms]
Mar 26 22:38:03.512: INFO: Created: latency-svc-m5cc4
Mar 26 22:38:03.539: INFO: Got endpoints: latency-svc-5k9db [763.152116ms]
Mar 26 22:38:03.586: INFO: Created: latency-svc-chtrt
Mar 26 22:38:03.589: INFO: Got endpoints: latency-svc-vg7zr [763.057067ms]
Mar 26 22:38:03.630: INFO: Created: latency-svc-4xlcr
Mar 26 22:38:03.634: INFO: Got endpoints: latency-svc-pkmvq [755.17861ms]
Mar 26 22:38:03.667: INFO: Created: latency-svc-58ftx
Mar 26 22:38:03.675: INFO: Got endpoints: latency-svc-2wrwm [750.297436ms]
Mar 26 22:38:03.707: INFO: Created: latency-svc-572m2
Mar 26 22:38:03.726: INFO: Got endpoints: latency-svc-p7rwp [750.197901ms]
Mar 26 22:38:03.758: INFO: Created: latency-svc-vdnml
Mar 26 22:38:03.783: INFO: Got endpoints: latency-svc-d4hrf [757.229149ms]
Mar 26 22:38:03.815: INFO: Created: latency-svc-jkndt
Mar 26 22:38:03.829: INFO: Got endpoints: latency-svc-9qbnj [753.740826ms]
Mar 26 22:38:03.863: INFO: Created: latency-svc-vznsz
Mar 26 22:38:03.876: INFO: Got endpoints: latency-svc-nrbxd [749.936208ms]
Mar 26 22:38:03.908: INFO: Created: latency-svc-gx88k
Mar 26 22:38:03.925: INFO: Got endpoints: latency-svc-jl5p9 [750.410514ms]
Mar 26 22:38:03.958: INFO: Created: latency-svc-mrgvs
Mar 26 22:38:03.975: INFO: Got endpoints: latency-svc-2wbcl [750.023826ms]
Mar 26 22:38:04.007: INFO: Created: latency-svc-p76gt
Mar 26 22:38:04.026: INFO: Got endpoints: latency-svc-bn76g [749.8582ms]
Mar 26 22:38:04.057: INFO: Created: latency-svc-42xd6
Mar 26 22:38:04.075: INFO: Got endpoints: latency-svc-nqfhs [747.811687ms]
Mar 26 22:38:04.108: INFO: Created: latency-svc-zxrdk
Mar 26 22:38:04.126: INFO: Got endpoints: latency-svc-bd7tz [750.583691ms]
Mar 26 22:38:04.159: INFO: Created: latency-svc-fmhzx
Mar 26 22:38:04.175: INFO: Got endpoints: latency-svc-l455q [748.462416ms]
Mar 26 22:38:04.209: INFO: Created: latency-svc-lqsf4
Mar 26 22:38:04.225: INFO: Got endpoints: latency-svc-m5cc4 [750.537459ms]
Mar 26 22:38:04.258: INFO: Created: latency-svc-dpmpz
Mar 26 22:38:04.275: INFO: Got endpoints: latency-svc-chtrt [736.796295ms]
Mar 26 22:38:04.307: INFO: Created: latency-svc-nc9v2
Mar 26 22:38:04.325: INFO: Got endpoints: latency-svc-4xlcr [736.247995ms]
Mar 26 22:38:04.357: INFO: Created: latency-svc-7ll4x
Mar 26 22:38:04.381: INFO: Got endpoints: latency-svc-58ftx [746.951118ms]
Mar 26 22:38:04.415: INFO: Created: latency-svc-hqhld
Mar 26 22:38:04.430: INFO: Got endpoints: latency-svc-572m2 [754.825737ms]
Mar 26 22:38:04.463: INFO: Created: latency-svc-5td8x
Mar 26 22:38:04.475: INFO: Got endpoints: latency-svc-vdnml [748.96465ms]
Mar 26 22:38:04.507: INFO: Created: latency-svc-skhcp
Mar 26 22:38:04.526: INFO: Got endpoints: latency-svc-jkndt [743.027243ms]
Mar 26 22:38:04.566: INFO: Created: latency-svc-prc6q
Mar 26 22:38:04.592: INFO: Got endpoints: latency-svc-vznsz [762.396986ms]
Mar 26 22:38:04.634: INFO: Created: latency-svc-pn8qb
Mar 26 22:38:04.637: INFO: Got endpoints: latency-svc-gx88k [761.599032ms]
Mar 26 22:38:04.669: INFO: Created: latency-svc-kxwgf
Mar 26 22:38:04.676: INFO: Got endpoints: latency-svc-mrgvs [750.850784ms]
Mar 26 22:38:04.708: INFO: Created: latency-svc-v9nhh
Mar 26 22:38:04.724: INFO: Got endpoints: latency-svc-p76gt [748.94364ms]
Mar 26 22:38:04.758: INFO: Created: latency-svc-7847r
Mar 26 22:38:04.775: INFO: Got endpoints: latency-svc-42xd6 [749.542925ms]
Mar 26 22:38:04.811: INFO: Created: latency-svc-cx8pq
Mar 26 22:38:04.825: INFO: Got endpoints: latency-svc-zxrdk [750.293571ms]
Mar 26 22:38:04.858: INFO: Created: latency-svc-jmc6k
Mar 26 22:38:04.875: INFO: Got endpoints: latency-svc-fmhzx [749.048446ms]
Mar 26 22:38:04.910: INFO: Created: latency-svc-sms5h
Mar 26 22:38:04.928: INFO: Got endpoints: latency-svc-lqsf4 [753.018718ms]
Mar 26 22:38:04.960: INFO: Created: latency-svc-7cp4p
Mar 26 22:38:04.976: INFO: Got endpoints: latency-svc-dpmpz [750.353481ms]
Mar 26 22:38:05.010: INFO: Created: latency-svc-dq9n5
Mar 26 22:38:05.026: INFO: Got endpoints: latency-svc-nc9v2 [750.705199ms]
Mar 26 22:38:05.059: INFO: Created: latency-svc-pl75c
Mar 26 22:38:05.075: INFO: Got endpoints: latency-svc-7ll4x [750.145381ms]
Mar 26 22:38:05.108: INFO: Created: latency-svc-fr9xt
Mar 26 22:38:05.126: INFO: Got endpoints: latency-svc-hqhld [745.079735ms]
Mar 26 22:38:05.159: INFO: Created: latency-svc-gmjlb
Mar 26 22:38:05.176: INFO: Got endpoints: latency-svc-5td8x [745.664373ms]
Mar 26 22:38:05.207: INFO: Created: latency-svc-h8gxw
Mar 26 22:38:05.226: INFO: Got endpoints: latency-svc-skhcp [750.765616ms]
Mar 26 22:38:05.258: INFO: Created: latency-svc-dwvfh
Mar 26 22:38:05.275: INFO: Got endpoints: latency-svc-prc6q [749.459181ms]
Mar 26 22:38:05.308: INFO: Created: latency-svc-26gz2
Mar 26 22:38:05.326: INFO: Got endpoints: latency-svc-pn8qb [734.568865ms]
Mar 26 22:38:05.358: INFO: Created: latency-svc-6bbh8
Mar 26 22:38:05.375: INFO: Got endpoints: latency-svc-kxwgf [738.176105ms]
Mar 26 22:38:05.409: INFO: Created: latency-svc-v95rh
Mar 26 22:38:05.425: INFO: Got endpoints: latency-svc-v9nhh [748.75939ms]
Mar 26 22:38:05.456: INFO: Created: latency-svc-58bfm
Mar 26 22:38:05.475: INFO: Got endpoints: latency-svc-7847r [750.24391ms]
Mar 26 22:38:05.508: INFO: Created: latency-svc-fh5vq
Mar 26 22:38:05.525: INFO: Got endpoints: latency-svc-cx8pq [749.579625ms]
Mar 26 22:38:05.556: INFO: Created: latency-svc-df7k9
Mar 26 22:38:05.575: INFO: Got endpoints: latency-svc-jmc6k [749.358714ms]
Mar 26 22:38:05.611: INFO: Created: latency-svc-mq5tl
Mar 26 22:38:05.625: INFO: Got endpoints: latency-svc-sms5h [750.148867ms]
Mar 26 22:38:05.658: INFO: Created: latency-svc-wj4gn
Mar 26 22:38:05.680: INFO: Got endpoints: latency-svc-7cp4p [752.074218ms]
Mar 26 22:38:05.713: INFO: Created: latency-svc-f7zxs
Mar 26 22:38:05.725: INFO: Got endpoints: latency-svc-dq9n5 [748.950342ms]
Mar 26 22:38:05.757: INFO: Created: latency-svc-sv2kk
Mar 26 22:38:05.777: INFO: Got endpoints: latency-svc-pl75c [751.139271ms]
Mar 26 22:38:05.813: INFO: Created: latency-svc-7vcjc
Mar 26 22:38:05.826: INFO: Got endpoints: latency-svc-fr9xt [750.547943ms]
Mar 26 22:38:05.857: INFO: Created: latency-svc-tx5c6
Mar 26 22:38:05.876: INFO: Got endpoints: latency-svc-gmjlb [750.489427ms]
Mar 26 22:38:05.911: INFO: Created: latency-svc-rcm6f
Mar 26 22:38:05.926: INFO: Got endpoints: latency-svc-h8gxw [750.313513ms]
Mar 26 22:38:05.958: INFO: Created: latency-svc-kct62
Mar 26 22:38:05.976: INFO: Got endpoints: latency-svc-dwvfh [750.229865ms]
Mar 26 22:38:06.008: INFO: Created: latency-svc-mq5kt
Mar 26 22:38:06.029: INFO: Got endpoints: latency-svc-26gz2 [753.331935ms]
Mar 26 22:38:06.062: INFO: Created: latency-svc-ntctn
Mar 26 22:38:06.077: INFO: Got endpoints: latency-svc-6bbh8 [750.354318ms]
Mar 26 22:38:06.109: INFO: Created: latency-svc-kg5j9
Mar 26 22:38:06.126: INFO: Got endpoints: latency-svc-v95rh [750.978087ms]
Mar 26 22:38:06.161: INFO: Created: latency-svc-c9h52
Mar 26 22:38:06.175: INFO: Got endpoints: latency-svc-58bfm [749.76103ms]
Mar 26 22:38:06.207: INFO: Created: latency-svc-7ds2n
Mar 26 22:38:06.226: INFO: Got endpoints: latency-svc-fh5vq [750.854482ms]
Mar 26 22:38:06.259: INFO: Created: latency-svc-v4smt
Mar 26 22:38:06.275: INFO: Got endpoints: latency-svc-df7k9 [749.81505ms]
Mar 26 22:38:06.306: INFO: Created: latency-svc-7wrxc
Mar 26 22:38:06.325: INFO: Got endpoints: latency-svc-mq5tl [750.491429ms]
Mar 26 22:38:06.358: INFO: Created: latency-svc-5k796
Mar 26 22:38:06.375: INFO: Got endpoints: latency-svc-wj4gn [750.196656ms]
Mar 26 22:38:06.408: INFO: Created: latency-svc-9vv48
Mar 26 22:38:06.425: INFO: Got endpoints: latency-svc-f7zxs [745.304674ms]
Mar 26 22:38:06.457: INFO: Created: latency-svc-j8hrp
Mar 26 22:38:06.475: INFO: Got endpoints: latency-svc-sv2kk [749.997582ms]
Mar 26 22:38:06.506: INFO: Created: latency-svc-zhtgp
Mar 26 22:38:06.524: INFO: Got endpoints: latency-svc-7vcjc [747.042585ms]
Mar 26 22:38:06.555: INFO: Created: latency-svc-cqd9b
Mar 26 22:38:06.576: INFO: Got endpoints: latency-svc-tx5c6 [749.853805ms]
Mar 26 22:38:06.610: INFO: Created: latency-svc-h5cs2
Mar 26 22:38:06.628: INFO: Got endpoints: latency-svc-rcm6f [751.372047ms]
Mar 26 22:38:06.665: INFO: Created: latency-svc-xb5rg
Mar 26 22:38:06.675: INFO: Got endpoints: latency-svc-kct62 [748.724256ms]
Mar 26 22:38:06.711: INFO: Created: latency-svc-xkwfw
Mar 26 22:38:06.725: INFO: Got endpoints: latency-svc-mq5kt [748.932726ms]
Mar 26 22:38:06.761: INFO: Created: latency-svc-pc2j9
Mar 26 22:38:06.782: INFO: Got endpoints: latency-svc-ntctn [753.206378ms]
Mar 26 22:38:06.815: INFO: Created: latency-svc-bftcd
Mar 26 22:38:06.825: INFO: Got endpoints: latency-svc-kg5j9 [748.005373ms]
Mar 26 22:38:06.857: INFO: Created: latency-svc-znbzn
Mar 26 22:38:06.875: INFO: Got endpoints: latency-svc-c9h52 [748.972487ms]
Mar 26 22:38:06.912: INFO: Created: latency-svc-7djbh
Mar 26 22:38:06.926: INFO: Got endpoints: latency-svc-7ds2n [750.713593ms]
Mar 26 22:38:06.958: INFO: Created: latency-svc-qctv8
Mar 26 22:38:06.975: INFO: Got endpoints: latency-svc-v4smt [749.25116ms]
Mar 26 22:38:07.005: INFO: Created: latency-svc-82b5k
Mar 26 22:38:07.028: INFO: Got endpoints: latency-svc-7wrxc [753.172542ms]
Mar 26 22:38:07.060: INFO: Created: latency-svc-cxrqn
Mar 26 22:38:07.075: INFO: Got endpoints: latency-svc-5k796 [749.901965ms]
Mar 26 22:38:07.109: INFO: Created: latency-svc-4krdb
Mar 26 22:38:07.127: INFO: Got endpoints: latency-svc-9vv48 [751.739555ms]
Mar 26 22:38:07.157: INFO: Created: latency-svc-fs7rp
Mar 26 22:38:07.175: INFO: Got endpoints: latency-svc-j8hrp [749.658877ms]
Mar 26 22:38:07.206: INFO: Created: latency-svc-sd4rz
Mar 26 22:38:07.225: INFO: Got endpoints: latency-svc-zhtgp [750.350656ms]
Mar 26 22:38:07.258: INFO: Created: latency-svc-vxlnx
Mar 26 22:38:07.275: INFO: Got endpoints: latency-svc-cqd9b [750.462223ms]
Mar 26 22:38:07.309: INFO: Created: latency-svc-lhlst
Mar 26 22:38:07.325: INFO: Got endpoints: latency-svc-h5cs2 [749.111588ms]
Mar 26 22:38:07.356: INFO: Created: latency-svc-gsjfp
Mar 26 22:38:07.375: INFO: Got endpoints: latency-svc-xb5rg [747.509378ms]
Mar 26 22:38:07.410: INFO: Created: latency-svc-qw796
Mar 26 22:38:07.425: INFO: Got endpoints: latency-svc-xkwfw [750.484088ms]
Mar 26 22:38:07.458: INFO: Created: latency-svc-7nrr6
Mar 26 22:38:07.475: INFO: Got endpoints: latency-svc-pc2j9 [750.0374ms]
Mar 26 22:38:07.521: INFO: Created: latency-svc-z4zh7
Mar 26 22:38:07.526: INFO: Got endpoints: latency-svc-bftcd [743.68318ms]
Mar 26 22:38:07.557: INFO: Created: latency-svc-5gpfv
Mar 26 22:38:07.576: INFO: Got endpoints: latency-svc-znbzn [751.282494ms]
Mar 26 22:38:07.611: INFO: Created: latency-svc-clp57
Mar 26 22:38:07.625: INFO: Got endpoints: latency-svc-7djbh [749.63999ms]
Mar 26 22:38:07.658: INFO: Created: latency-svc-dprn5
Mar 26 22:38:07.676: INFO: Got endpoints: latency-svc-qctv8 [749.918604ms]
Mar 26 22:38:07.714: INFO: Created: latency-svc-nbr8s
Mar 26 22:38:07.726: INFO: Got endpoints: latency-svc-82b5k [750.858485ms]
Mar 26 22:38:07.766: INFO: Created: latency-svc-dkzkl
Mar 26 22:38:07.775: INFO: Got endpoints: latency-svc-cxrqn [747.222056ms]
Mar 26 22:38:07.825: INFO: Got endpoints: latency-svc-4krdb [749.756086ms]
Mar 26 22:38:07.875: INFO: Got endpoints: latency-svc-fs7rp [747.825792ms]
Mar 26 22:38:07.928: INFO: Got endpoints: latency-svc-sd4rz [753.701818ms]
Mar 26 22:38:07.977: INFO: Got endpoints: latency-svc-vxlnx [751.901375ms]
Mar 26 22:38:08.027: INFO: Got endpoints: latency-svc-lhlst [751.825087ms]
Mar 26 22:38:08.075: INFO: Got endpoints: latency-svc-gsjfp [749.599195ms]
Mar 26 22:38:08.125: INFO: Got endpoints: latency-svc-qw796 [749.074148ms]
Mar 26 22:38:08.175: INFO: Got endpoints: latency-svc-7nrr6 [749.66261ms]
Mar 26 22:38:08.226: INFO: Got endpoints: latency-svc-z4zh7 [750.801844ms]
Mar 26 22:38:08.275: INFO: Got endpoints: latency-svc-5gpfv [749.599387ms]
Mar 26 22:38:08.325: INFO: Got endpoints: latency-svc-clp57 [748.995786ms]
Mar 26 22:38:08.375: INFO: Got endpoints: latency-svc-dprn5 [750.193156ms]
Mar 26 22:38:08.425: INFO: Got endpoints: latency-svc-nbr8s [749.345022ms]
Mar 26 22:38:08.474: INFO: Got endpoints: latency-svc-dkzkl [748.692914ms]
Mar 26 22:38:08.475: INFO: Latencies: [42.19182ms 51.898343ms 65.78569ms 71.028482ms 86.209176ms 93.465141ms 102.284055ms 106.479833ms 115.844726ms 124.195122ms 130.800131ms 130.894623ms 133.335556ms 133.634839ms 134.000452ms 135.243632ms 135.66407ms 137.619756ms 138.541071ms 138.871388ms 138.940406ms 139.123902ms 140.318267ms 140.800957ms 141.304325ms 141.471805ms 142.798583ms 147.074713ms 148.795751ms 148.953964ms 150.860321ms 156.539728ms 156.914999ms 161.066207ms 164.032764ms 168.83928ms 169.384086ms 203.316796ms 241.571509ms 277.474433ms 317.407657ms 356.956871ms 402.405283ms 438.536982ms 474.488777ms 522.667265ms 565.23302ms 587.497959ms 637.204007ms 673.885887ms 713.499601ms 715.410889ms 721.136717ms 727.681944ms 727.907547ms 728.331601ms 732.668949ms 734.568865ms 736.247995ms 736.796295ms 738.176105ms 739.973719ms 741.026146ms 741.954989ms 742.480613ms 743.008096ms 743.027243ms 743.340595ms 743.342882ms 743.652545ms 743.68318ms 745.079735ms 745.227894ms 745.304674ms 745.376007ms 745.664373ms 745.908159ms 746.06087ms 746.498265ms 746.951118ms 747.042585ms 747.222056ms 747.509378ms 747.811687ms 747.825792ms 748.005373ms 748.462416ms 748.692914ms 748.724256ms 748.75939ms 748.932726ms 748.94364ms 748.950342ms 748.96465ms 748.972487ms 748.995786ms 749.048446ms 749.061787ms 749.074148ms 749.111588ms 749.151984ms 749.224605ms 749.25116ms 749.345022ms 749.358714ms 749.420412ms 749.459181ms 749.507015ms 749.542925ms 749.579625ms 749.599195ms 749.599387ms 749.605598ms 749.625485ms 749.63999ms 749.658877ms 749.66261ms 749.744426ms 749.756086ms 749.76103ms 749.81505ms 749.853805ms 749.8582ms 749.901965ms 749.918604ms 749.936208ms 749.997582ms 750.023826ms 750.0374ms 750.073206ms 750.141874ms 750.145381ms 750.148867ms 750.193156ms 750.194814ms 750.196656ms 750.197901ms 750.229865ms 750.24391ms 750.293571ms 750.297436ms 750.313513ms 750.336678ms 750.350656ms 750.353481ms 750.354318ms 750.410514ms 750.462223ms 750.469177ms 750.484088ms 750.489427ms 750.491429ms 750.537459ms 750.547943ms 750.583691ms 750.705199ms 750.713593ms 750.765616ms 750.796836ms 750.801844ms 750.850784ms 750.854482ms 750.858485ms 750.978087ms 751.139271ms 751.282494ms 751.372047ms 751.739555ms 751.825087ms 751.863038ms 751.901375ms 752.074218ms 752.14925ms 752.630637ms 752.804981ms 753.018718ms 753.172542ms 753.206378ms 753.331935ms 753.701818ms 753.740826ms 754.825737ms 755.17861ms 755.235147ms 755.676325ms 756.50504ms 757.229149ms 757.510058ms 758.545591ms 758.642322ms 759.137281ms 760.305484ms 761.599032ms 762.396986ms 763.057067ms 763.152116ms 767.25946ms 771.687646ms 771.821047ms 780.041021ms]
Mar 26 22:38:08.475: INFO: 50 %ile: 749.151984ms
Mar 26 22:38:08.475: INFO: 90 %ile: 753.740826ms
Mar 26 22:38:08.475: INFO: 99 %ile: 771.821047ms
Mar 26 22:38:08.475: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:38:08.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-svc-latency-9bq8p" for this suite.
Mar 26 22:38:22.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:38:23.149: INFO: namespace: e2e-tests-svc-latency-9bq8p, resource: bindings, ignored listing per whitelist
Mar 26 22:38:23.528: INFO: namespace e2e-tests-svc-latency-9bq8p deletion completed in 15.024513546s

[32mâ€¢ [SLOW TEST:25.645 seconds][0m
[sig-network] Service endpoints latency
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22[0m
  should not be very high  [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould set mode on item file [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:38:23.528: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 26 22:38:24.376: INFO: Waiting up to 5m0s for pod "downwardapi-volume-64a639bf-5039-11e9-9bdd-d050998677c2" in namespace "e2e-tests-downward-api-5r8sg" to be "success or failure"
Mar 26 22:38:24.401: INFO: Pod "downwardapi-volume-64a639bf-5039-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.471426ms
Mar 26 22:38:26.427: INFO: Pod "downwardapi-volume-64a639bf-5039-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.051547363s
[1mSTEP[0m: Saw pod success
Mar 26 22:38:26.427: INFO: Pod "downwardapi-volume-64a639bf-5039-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:38:26.453: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod downwardapi-volume-64a639bf-5039-11e9-9bdd-d050998677c2 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:38:26.512: INFO: Waiting for pod downwardapi-volume-64a639bf-5039-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:38:26.538: INFO: Pod downwardapi-volume-64a639bf-5039-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:38:26.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-5r8sg" for this suite.
Mar 26 22:38:32.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:38:33.624: INFO: namespace: e2e-tests-downward-api-5r8sg, resource: bindings, ignored listing per whitelist
Mar 26 22:38:33.701: INFO: namespace e2e-tests-downward-api-5r8sg deletion completed in 7.136384738s

[32mâ€¢ [SLOW TEST:10.172 seconds][0m
[sig-storage] Downward API volume
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34[0m
  should set mode on item file [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould delete pods created by rc when not orphaning [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:38:33.701: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename gc
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: create the rc
[1mSTEP[0m: delete the rc
[1mSTEP[0m: wait for all pods to be garbage collected
[1mSTEP[0m: Gathering metrics
W0326 22:38:44.713002    2026 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 26 22:38:44.713: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:38:44.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-gc-9ndzk" for this suite.
Mar 26 22:38:50.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:38:51.375: INFO: namespace: e2e-tests-gc-9ndzk, resource: bindings, ignored listing per whitelist
Mar 26 22:38:51.778: INFO: namespace e2e-tests-gc-9ndzk deletion completed in 7.037203658s

[32mâ€¢ [SLOW TEST:18.077 seconds][0m
[sig-api-machinery] Garbage collector
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should delete pods created by rc when not orphaning [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Variable Expansion[0m 
  [1mshould allow substituting values in a container's args [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Variable Expansion
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:38:51.778: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename var-expansion
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test substitution in container's args
Mar 26 22:38:52.629: INFO: Waiting up to 5m0s for pod "var-expansion-757d4ce9-5039-11e9-9bdd-d050998677c2" in namespace "e2e-tests-var-expansion-lcvlw" to be "success or failure"
Mar 26 22:38:52.654: INFO: Pod "var-expansion-757d4ce9-5039-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.281585ms
Mar 26 22:38:54.681: INFO: Pod "var-expansion-757d4ce9-5039-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.051407926s
[1mSTEP[0m: Saw pod success
Mar 26 22:38:54.681: INFO: Pod "var-expansion-757d4ce9-5039-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:38:54.706: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod var-expansion-757d4ce9-5039-11e9-9bdd-d050998677c2 container dapi-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:38:54.768: INFO: Waiting for pod var-expansion-757d4ce9-5039-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:38:54.792: INFO: Pod var-expansion-757d4ce9-5039-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:38:54.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-var-expansion-lcvlw" for this suite.
Mar 26 22:39:00.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:39:01.609: INFO: namespace: e2e-tests-var-expansion-lcvlw, resource: bindings, ignored listing per whitelist
Mar 26 22:39:01.844: INFO: namespace e2e-tests-var-expansion-lcvlw deletion completed in 7.025135573s

[32mâ€¢ [SLOW TEST:10.066 seconds][0m
[k8s.io] Variable Expansion
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl run default[0m 
  [1mshould create an rc or deployment from an image  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:39:01.844: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: running the image docker.io/library/nginx:1.14-alpine
Mar 26 22:39:02.681: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-pqzjk'
Mar 26 22:39:04.196: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar 26 22:39:04.196: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
[1mSTEP[0m: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Mar 26 22:39:04.224: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-pqzjk'
Mar 26 22:39:04.491: INFO: stderr: ""
Mar 26 22:39:04.491: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:39:04.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-pqzjk" for this suite.
Mar 26 22:39:10.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:39:10.825: INFO: namespace: e2e-tests-kubectl-pqzjk, resource: bindings, ignored listing per whitelist
Mar 26 22:39:11.539: INFO: namespace e2e-tests-kubectl-pqzjk deletion completed in 7.020973614s

[32mâ€¢ [SLOW TEST:9.695 seconds][0m
[sig-cli] Kubectl client
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl run default
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should create an rc or deployment from an image  [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Docker Containers[0m 
  [1mshould be able to override the image's default command and arguments [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Docker Containers
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:39:11.540: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename containers
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test override all
Mar 26 22:39:12.392: INFO: Waiting up to 5m0s for pod "client-containers-8144ddb8-5039-11e9-9bdd-d050998677c2" in namespace "e2e-tests-containers-kkdcp" to be "success or failure"
Mar 26 22:39:12.417: INFO: Pod "client-containers-8144ddb8-5039-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.155005ms
Mar 26 22:39:14.443: INFO: Pod "client-containers-8144ddb8-5039-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.050871083s
[1mSTEP[0m: Saw pod success
Mar 26 22:39:14.443: INFO: Pod "client-containers-8144ddb8-5039-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:39:14.468: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod client-containers-8144ddb8-5039-11e9-9bdd-d050998677c2 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:39:14.531: INFO: Waiting for pod client-containers-8144ddb8-5039-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:39:14.557: INFO: Pod client-containers-8144ddb8-5039-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:39:14.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-containers-kkdcp" for this suite.
Mar 26 22:39:20.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:39:21.339: INFO: namespace: e2e-tests-containers-kkdcp, resource: bindings, ignored listing per whitelist
Mar 26 22:39:21.594: INFO: namespace e2e-tests-containers-kkdcp deletion completed in 7.011101497s

[32mâ€¢ [SLOW TEST:10.055 seconds][0m
[k8s.io] Docker Containers
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mvolume on default medium should have the correct mode [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:39:21.594: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test emptydir volume type on node default medium
Mar 26 22:39:22.438: INFO: Waiting up to 5m0s for pod "pod-8741e788-5039-11e9-9bdd-d050998677c2" in namespace "e2e-tests-emptydir-5bbnt" to be "success or failure"
Mar 26 22:39:22.463: INFO: Pod "pod-8741e788-5039-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 24.913583ms
Mar 26 22:39:24.489: INFO: Pod "pod-8741e788-5039-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.05075118s
[1mSTEP[0m: Saw pod success
Mar 26 22:39:24.489: INFO: Pod "pod-8741e788-5039-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:39:24.514: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-8741e788-5039-11e9-9bdd-d050998677c2 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:39:24.573: INFO: Waiting for pod pod-8741e788-5039-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:39:24.601: INFO: Pod pod-8741e788-5039-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:39:24.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-5bbnt" for this suite.
Mar 26 22:39:30.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:39:31.331: INFO: namespace: e2e-tests-emptydir-5bbnt, resource: bindings, ignored listing per whitelist
Mar 26 22:39:31.632: INFO: namespace e2e-tests-emptydir-5bbnt deletion completed in 7.003781856s

[32mâ€¢ [SLOW TEST:10.037 seconds][0m
[sig-storage] EmptyDir volumes
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mwith readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Probing container
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:39:31.632: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename container-probe
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 22:39:52.558: INFO: Container started at 2019-03-26 22:39:33 -0400 EDT, pod became ready at 2019-03-26 22:39:51 -0400 EDT
[AfterEach] [k8s.io] Probing container
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:39:52.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-container-probe-n6mtj" for this suite.
Mar 26 22:40:08.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:40:09.221: INFO: namespace: e2e-tests-container-probe-n6mtj, resource: bindings, ignored listing per whitelist
Mar 26 22:40:09.600: INFO: namespace e2e-tests-container-probe-n6mtj deletion completed in 17.0146987s

[32mâ€¢ [SLOW TEST:37.968 seconds][0m
[k8s.io] Probing container
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl run job[0m 
  [1mshould create a job from an image when restart is OnFailure  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:40:09.600: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: running the image docker.io/library/nginx:1.14-alpine
Mar 26 22:40:10.432: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-c5g2q'
Mar 26 22:40:10.651: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar 26 22:40:10.651: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
[1mSTEP[0m: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Mar 26 22:40:10.676: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-c5g2q'
Mar 26 22:40:10.912: INFO: stderr: ""
Mar 26 22:40:10.912: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:40:10.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-c5g2q" for this suite.
Mar 26 22:40:17.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:40:17.303: INFO: namespace: e2e-tests-kubectl-c5g2q, resource: bindings, ignored listing per whitelist
Mar 26 22:40:18.110: INFO: namespace e2e-tests-kubectl-c5g2q deletion completed in 7.173125387s

[32mâ€¢ [SLOW TEST:8.511 seconds][0m
[sig-cli] Kubectl client
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl run job
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should create a job from an image when restart is OnFailure  [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:40:18.111: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating projection with secret that has name projected-secret-test-a8f2ac5b-5039-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume secrets
Mar 26 22:40:18.990: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a8f6a75c-5039-11e9-9bdd-d050998677c2" in namespace "e2e-tests-projected-pnr25" to be "success or failure"
Mar 26 22:40:19.015: INFO: Pod "pod-projected-secrets-a8f6a75c-5039-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.67464ms
Mar 26 22:40:21.044: INFO: Pod "pod-projected-secrets-a8f6a75c-5039-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0545484s
[1mSTEP[0m: Saw pod success
Mar 26 22:40:21.044: INFO: Pod "pod-projected-secrets-a8f6a75c-5039-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:40:21.071: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-projected-secrets-a8f6a75c-5039-11e9-9bdd-d050998677c2 container projected-secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:40:21.132: INFO: Waiting for pod pod-projected-secrets-a8f6a75c-5039-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:40:21.157: INFO: Pod pod-projected-secrets-a8f6a75c-5039-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:40:21.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-pnr25" for this suite.
Mar 26 22:40:27.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:40:27.664: INFO: namespace: e2e-tests-projected-pnr25, resource: bindings, ignored listing per whitelist
Mar 26 22:40:28.304: INFO: namespace e2e-tests-projected-pnr25 deletion completed in 7.120145375s

[32mâ€¢ [SLOW TEST:10.193 seconds][0m
[sig-storage] Projected
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35[0m
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould set DefaultMode on files [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:40:28.304: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 26 22:40:29.156: INFO: Waiting up to 5m0s for pod "downwardapi-volume-af064161-5039-11e9-9bdd-d050998677c2" in namespace "e2e-tests-downward-api-hhh2x" to be "success or failure"
Mar 26 22:40:29.182: INFO: Pod "downwardapi-volume-af064161-5039-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.62232ms
Mar 26 22:40:31.208: INFO: Pod "downwardapi-volume-af064161-5039-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.051561569s
[1mSTEP[0m: Saw pod success
Mar 26 22:40:31.208: INFO: Pod "downwardapi-volume-af064161-5039-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:40:31.234: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod downwardapi-volume-af064161-5039-11e9-9bdd-d050998677c2 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:40:31.297: INFO: Waiting for pod downwardapi-volume-af064161-5039-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:40:31.325: INFO: Pod downwardapi-volume-af064161-5039-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:40:31.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-hhh2x" for this suite.
Mar 26 22:40:37.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:40:37.797: INFO: namespace: e2e-tests-downward-api-hhh2x, resource: bindings, ignored listing per whitelist
Mar 26 22:40:38.412: INFO: namespace e2e-tests-downward-api-hhh2x deletion completed in 7.05585495s

[32mâ€¢ [SLOW TEST:10.108 seconds][0m
[sig-storage] Downward API volume
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34[0m
  should set DefaultMode on files [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-scheduling] SchedulerPredicates [Serial][0m 
  [1mvalidates that NodeSelector is respected if not matching  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:40:38.412: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename sched-pred
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Mar 26 22:40:39.239: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 26 22:40:39.292: INFO: Waiting for terminating namespaces to be deleted...
Mar 26 22:40:39.320: INFO: 
Logging pods the kubelet thinks is on node ip-172-20-53-156.us-east-2.compute.internal before test
Mar 26 22:40:39.349: INFO: kube-dns-7cfc48d44b-5z9lj from kube-system started at 2019-03-26 20:06:02 -0400 EDT (3 container statuses recorded)
Mar 26 22:40:39.349: INFO: 	Container dnsmasq ready: true, restart count 0
Mar 26 22:40:39.349: INFO: 	Container kubedns ready: true, restart count 0
Mar 26 22:40:39.349: INFO: 	Container sidecar ready: true, restart count 0
Mar 26 22:40:39.349: INFO: kube-proxy-ip-172-20-53-156.us-east-2.compute.internal from kube-system started at <nil> (0 container statuses recorded)
Mar 26 22:40:39.349: INFO: kube-dns-autoscaler-867b9fd49d-s8grz from kube-system started at 2019-03-26 20:06:02 -0400 EDT (1 container statuses recorded)
Mar 26 22:40:39.349: INFO: 	Container autoscaler ready: true, restart count 0
Mar 26 22:40:39.349: INFO: 
Logging pods the kubelet thinks is on node ip-172-20-56-226.us-east-2.compute.internal before test
Mar 26 22:40:39.377: INFO: kube-dns-7cfc48d44b-x4t9q from kube-system started at 2019-03-26 20:06:07 -0400 EDT (3 container statuses recorded)
Mar 26 22:40:39.377: INFO: 	Container dnsmasq ready: true, restart count 0
Mar 26 22:40:39.377: INFO: 	Container kubedns ready: true, restart count 0
Mar 26 22:40:39.377: INFO: 	Container sidecar ready: true, restart count 0
Mar 26 22:40:39.377: INFO: kube-proxy-ip-172-20-56-226.us-east-2.compute.internal from kube-system started at <nil> (0 container statuses recorded)
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Trying to schedule Pod with nonempty NodeSelector.
[1mSTEP[0m: Considering event: 
Type = [Warning], Name = [restricted-pod.158fb07b288047bf], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:40:40.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-sched-pred-z6jjt" for this suite.
Mar 26 22:40:46.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:40:47.180: INFO: namespace: e2e-tests-sched-pred-z6jjt, resource: bindings, ignored listing per whitelist
Mar 26 22:40:47.626: INFO: namespace e2e-tests-sched-pred-z6jjt deletion completed in 7.093054506s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

[32mâ€¢ [SLOW TEST:9.214 seconds][0m
[sig-scheduling] SchedulerPredicates [Serial]
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22[0m
  validates that NodeSelector is respected if not matching  [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Subpath[0m [90mAtomic writer volumes[0m 
  [1mshould support subpaths with secret pod [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Subpath
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:40:47.626: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename subpath
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
[1mSTEP[0m: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating pod pod-subpath-test-secret-px92
[1mSTEP[0m: Creating a pod to test atomic-volume-subpath
Mar 26 22:40:48.540: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-px92" in namespace "e2e-tests-subpath-g7jbd" to be "success or failure"
Mar 26 22:40:48.565: INFO: Pod "pod-subpath-test-secret-px92": Phase="Pending", Reason="", readiness=false. Elapsed: 25.569828ms
Mar 26 22:40:50.591: INFO: Pod "pod-subpath-test-secret-px92": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05157349s
Mar 26 22:40:52.617: INFO: Pod "pod-subpath-test-secret-px92": Phase="Running", Reason="", readiness=false. Elapsed: 4.077505832s
Mar 26 22:40:54.644: INFO: Pod "pod-subpath-test-secret-px92": Phase="Running", Reason="", readiness=false. Elapsed: 6.103964963s
Mar 26 22:40:56.670: INFO: Pod "pod-subpath-test-secret-px92": Phase="Running", Reason="", readiness=false. Elapsed: 8.129947806s
Mar 26 22:40:58.696: INFO: Pod "pod-subpath-test-secret-px92": Phase="Running", Reason="", readiness=false. Elapsed: 10.156129195s
Mar 26 22:41:00.722: INFO: Pod "pod-subpath-test-secret-px92": Phase="Running", Reason="", readiness=false. Elapsed: 12.181949212s
Mar 26 22:41:02.748: INFO: Pod "pod-subpath-test-secret-px92": Phase="Running", Reason="", readiness=false. Elapsed: 14.208006817s
Mar 26 22:41:04.774: INFO: Pod "pod-subpath-test-secret-px92": Phase="Running", Reason="", readiness=false. Elapsed: 16.234313076s
Mar 26 22:41:06.803: INFO: Pod "pod-subpath-test-secret-px92": Phase="Running", Reason="", readiness=false. Elapsed: 18.263182817s
Mar 26 22:41:08.829: INFO: Pod "pod-subpath-test-secret-px92": Phase="Running", Reason="", readiness=false. Elapsed: 20.288848409s
Mar 26 22:41:10.859: INFO: Pod "pod-subpath-test-secret-px92": Phase="Running", Reason="", readiness=false. Elapsed: 22.318649138s
Mar 26 22:41:12.884: INFO: Pod "pod-subpath-test-secret-px92": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.344543571s
[1mSTEP[0m: Saw pod success
Mar 26 22:41:12.884: INFO: Pod "pod-subpath-test-secret-px92" satisfied condition "success or failure"
Mar 26 22:41:12.914: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-subpath-test-secret-px92 container test-container-subpath-secret-px92: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:41:12.976: INFO: Waiting for pod pod-subpath-test-secret-px92 to disappear
Mar 26 22:41:13.001: INFO: Pod pod-subpath-test-secret-px92 no longer exists
[1mSTEP[0m: Deleting pod pod-subpath-test-secret-px92
Mar 26 22:41:13.001: INFO: Deleting pod "pod-subpath-test-secret-px92" in namespace "e2e-tests-subpath-g7jbd"
[AfterEach] [sig-storage] Subpath
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:41:13.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-subpath-g7jbd" for this suite.
Mar 26 22:41:19.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:41:20.044: INFO: namespace: e2e-tests-subpath-g7jbd, resource: bindings, ignored listing per whitelist
Mar 26 22:41:20.095: INFO: namespace e2e-tests-subpath-g7jbd deletion completed in 7.040964235s

[32mâ€¢ [SLOW TEST:32.469 seconds][0m
[sig-storage] Subpath
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  Atomic writer volumes
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34[0m
    should support subpaths with secret pod [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould update annotations on modification [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:41:20.095: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating the pod
Mar 26 22:41:23.645: INFO: Successfully updated pod "annotationupdatecde68962-5039-11e9-9bdd-d050998677c2"
[AfterEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:41:27.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-mzvfw" for this suite.
Mar 26 22:41:49.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:41:50.654: INFO: namespace: e2e-tests-downward-api-mzvfw, resource: bindings, ignored listing per whitelist
Mar 26 22:41:50.780: INFO: namespace e2e-tests-downward-api-mzvfw deletion completed in 23.018160328s

[32mâ€¢ [SLOW TEST:30.684 seconds][0m
[sig-storage] Downward API volume
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34[0m
  should update annotations on modification [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Services[0m 
  [1mshould provide secure master service  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-network] Services
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:41:50.780: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename services
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:41:51.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-services-qpdjp" for this suite.
Mar 26 22:41:57.724: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:41:58.004: INFO: namespace: e2e-tests-services-qpdjp, resource: bindings, ignored listing per whitelist
Mar 26 22:41:58.663: INFO: namespace e2e-tests-services-qpdjp deletion completed in 7.015634295s
[AfterEach] [sig-network] Services
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

[32mâ€¢ [SLOW TEST:7.883 seconds][0m
[sig-network] Services
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22[0m
  should provide secure master service  [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl logs[0m 
  [1mshould be able to retrieve and filter logs  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:41:58.663: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
[1mSTEP[0m: creating an rc
Mar 26 22:41:59.527: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config create -f - --namespace=e2e-tests-kubectl-c4jq4'
Mar 26 22:41:59.859: INFO: stderr: ""
Mar 26 22:41:59.859: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Waiting for Redis master to start.
Mar 26 22:42:00.885: INFO: Selector matched 1 pods for map[app:redis]
Mar 26 22:42:00.885: INFO: Found 0 / 1
Mar 26 22:42:01.886: INFO: Selector matched 1 pods for map[app:redis]
Mar 26 22:42:01.886: INFO: Found 1 / 1
Mar 26 22:42:01.886: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 26 22:42:01.912: INFO: Selector matched 1 pods for map[app:redis]
Mar 26 22:42:01.912: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[1mSTEP[0m: checking for a matching strings
Mar 26 22:42:01.912: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config logs redis-master-7jfhm redis-master --namespace=e2e-tests-kubectl-c4jq4'
Mar 26 22:42:02.157: INFO: stderr: ""
Mar 26 22:42:02.157: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 27 Mar 02:42:00.677 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 27 Mar 02:42:00.677 # Server started, Redis version 3.2.12\n1:M 27 Mar 02:42:00.677 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 27 Mar 02:42:00.677 * The server is now ready to accept connections on port 6379\n"
[1mSTEP[0m: limiting log lines
Mar 26 22:42:02.157: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config log redis-master-7jfhm redis-master --namespace=e2e-tests-kubectl-c4jq4 --tail=1'
Mar 26 22:42:02.392: INFO: stderr: ""
Mar 26 22:42:02.392: INFO: stdout: "1:M 27 Mar 02:42:00.677 * The server is now ready to accept connections on port 6379\n"
[1mSTEP[0m: limiting log bytes
Mar 26 22:42:02.392: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config log redis-master-7jfhm redis-master --namespace=e2e-tests-kubectl-c4jq4 --limit-bytes=1'
Mar 26 22:42:02.607: INFO: stderr: ""
Mar 26 22:42:02.607: INFO: stdout: " "
[1mSTEP[0m: exposing timestamps
Mar 26 22:42:02.607: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config log redis-master-7jfhm redis-master --namespace=e2e-tests-kubectl-c4jq4 --tail=1 --timestamps'
Mar 26 22:42:02.833: INFO: stderr: ""
Mar 26 22:42:02.833: INFO: stdout: "2019-03-27T02:42:00.677666544Z 1:M 27 Mar 02:42:00.677 * The server is now ready to accept connections on port 6379\n"
[1mSTEP[0m: restricting to a time range
Mar 26 22:42:05.333: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config log redis-master-7jfhm redis-master --namespace=e2e-tests-kubectl-c4jq4 --since=1s'
Mar 26 22:42:05.569: INFO: stderr: ""
Mar 26 22:42:05.569: INFO: stdout: ""
Mar 26 22:42:05.569: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config log redis-master-7jfhm redis-master --namespace=e2e-tests-kubectl-c4jq4 --since=24h'
Mar 26 22:42:05.778: INFO: stderr: ""
Mar 26 22:42:05.778: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 27 Mar 02:42:00.677 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 27 Mar 02:42:00.677 # Server started, Redis version 3.2.12\n1:M 27 Mar 02:42:00.677 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 27 Mar 02:42:00.677 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
[1mSTEP[0m: using delete to clean up resources
Mar 26 22:42:05.779: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-c4jq4'
Mar 26 22:42:05.987: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 26 22:42:05.987: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Mar 26 22:42:05.987: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-c4jq4'
Mar 26 22:42:06.208: INFO: stderr: "No resources found.\n"
Mar 26 22:42:06.208: INFO: stdout: ""
Mar 26 22:42:06.208: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods -l name=nginx --namespace=e2e-tests-kubectl-c4jq4 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 26 22:42:06.391: INFO: stderr: ""
Mar 26 22:42:06.391: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:42:06.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-c4jq4" for this suite.
Mar 26 22:42:12.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:42:13.379: INFO: namespace: e2e-tests-kubectl-c4jq4, resource: bindings, ignored listing per whitelist
Mar 26 22:42:13.404: INFO: namespace e2e-tests-kubectl-c4jq4 deletion completed in 6.986084418s

[32mâ€¢ [SLOW TEST:14.741 seconds][0m
[sig-cli] Kubectl client
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl logs
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should be able to retrieve and filter logs  [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (non-root,0777,default) [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:42:13.404: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test emptydir 0777 on node default medium
Mar 26 22:42:14.248: INFO: Waiting up to 5m0s for pod "pod-eda9d5ff-5039-11e9-9bdd-d050998677c2" in namespace "e2e-tests-emptydir-vv2cs" to be "success or failure"
Mar 26 22:42:14.273: INFO: Pod "pod-eda9d5ff-5039-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.205763ms
Mar 26 22:42:16.300: INFO: Pod "pod-eda9d5ff-5039-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.052113749s
[1mSTEP[0m: Saw pod success
Mar 26 22:42:16.300: INFO: Pod "pod-eda9d5ff-5039-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:42:16.326: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-eda9d5ff-5039-11e9-9bdd-d050998677c2 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:42:16.385: INFO: Waiting for pod pod-eda9d5ff-5039-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:42:16.410: INFO: Pod pod-eda9d5ff-5039-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:42:16.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-vv2cs" for this suite.
Mar 26 22:42:22.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:42:22.916: INFO: namespace: e2e-tests-emptydir-vv2cs, resource: bindings, ignored listing per whitelist
Mar 26 22:42:23.447: INFO: namespace e2e-tests-emptydir-vv2cs deletion completed in 7.009375687s

[32mâ€¢ [SLOW TEST:10.043 seconds][0m
[sig-storage] EmptyDir volumes
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[k8s.io] Docker Containers[0m 
  [1mshould be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Docker Containers
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:42:23.447: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename containers
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test override command
Mar 26 22:42:24.293: INFO: Waiting up to 5m0s for pod "client-containers-f3a6893a-5039-11e9-9bdd-d050998677c2" in namespace "e2e-tests-containers-rj6qw" to be "success or failure"
Mar 26 22:42:24.319: INFO: Pod "client-containers-f3a6893a-5039-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 26.066544ms
Mar 26 22:42:26.346: INFO: Pod "client-containers-f3a6893a-5039-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.052740784s
[1mSTEP[0m: Saw pod success
Mar 26 22:42:26.346: INFO: Pod "client-containers-f3a6893a-5039-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:42:26.372: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod client-containers-f3a6893a-5039-11e9-9bdd-d050998677c2 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:42:26.434: INFO: Waiting for pod client-containers-f3a6893a-5039-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:42:26.459: INFO: Pod client-containers-f3a6893a-5039-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:42:26.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-containers-rj6qw" for this suite.
Mar 26 22:42:32.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:42:33.561: INFO: namespace: e2e-tests-containers-rj6qw, resource: bindings, ignored listing per whitelist
Mar 26 22:42:33.561: INFO: namespace e2e-tests-containers-rj6qw deletion completed in 7.075416625s

[32mâ€¢ [SLOW TEST:10.114 seconds][0m
[k8s.io] Docker Containers
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide container's cpu request [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:42:33.561: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 26 22:42:34.452: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f9b48eb7-5039-11e9-9bdd-d050998677c2" in namespace "e2e-tests-downward-api-ctl4w" to be "success or failure"
Mar 26 22:42:34.477: INFO: Pod "downwardapi-volume-f9b48eb7-5039-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 24.95635ms
Mar 26 22:42:36.503: INFO: Pod "downwardapi-volume-f9b48eb7-5039-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0509677s
[1mSTEP[0m: Saw pod success
Mar 26 22:42:36.503: INFO: Pod "downwardapi-volume-f9b48eb7-5039-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:42:36.531: INFO: Trying to get logs from node ip-172-20-53-156.us-east-2.compute.internal pod downwardapi-volume-f9b48eb7-5039-11e9-9bdd-d050998677c2 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:42:36.600: INFO: Waiting for pod downwardapi-volume-f9b48eb7-5039-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:42:36.629: INFO: Pod downwardapi-volume-f9b48eb7-5039-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:42:36.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-ctl4w" for this suite.
Mar 26 22:42:42.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:42:43.263: INFO: namespace: e2e-tests-downward-api-ctl4w, resource: bindings, ignored listing per whitelist
Mar 26 22:42:43.665: INFO: namespace e2e-tests-downward-api-ctl4w deletion completed in 7.009378346s

[32mâ€¢ [SLOW TEST:10.104 seconds][0m
[sig-storage] Downward API volume
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34[0m
  should provide container's cpu request [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Container Lifecycle Hook[0m [90mwhen create a pod with lifecycle hook[0m 
  [1mshould execute prestop exec hook properly [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:42:43.665: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename container-lifecycle-hook
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
[1mSTEP[0m: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: create the pod with lifecycle hook
[1mSTEP[0m: delete the pod with lifecycle hook
Mar 26 22:42:48.710: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 26 22:42:48.736: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 26 22:42:50.737: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 26 22:42:50.763: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 26 22:42:52.737: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 26 22:42:52.763: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 26 22:42:54.737: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 26 22:42:54.766: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 26 22:42:56.737: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 26 22:42:56.762: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 26 22:42:58.737: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 26 22:42:58.763: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 26 22:43:00.737: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 26 22:43:00.762: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 26 22:43:02.737: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 26 22:43:02.763: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 26 22:43:04.737: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 26 22:43:04.762: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 26 22:43:06.737: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 26 22:43:06.763: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 26 22:43:08.737: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 26 22:43:08.762: INFO: Pod pod-with-prestop-exec-hook no longer exists
[1mSTEP[0m: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:43:08.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-container-lifecycle-hook-g5v2d" for this suite.
Mar 26 22:43:30.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:43:31.674: INFO: namespace: e2e-tests-container-lifecycle-hook-g5v2d, resource: bindings, ignored listing per whitelist
Mar 26 22:43:31.826: INFO: namespace e2e-tests-container-lifecycle-hook-g5v2d deletion completed in 23.009001548s

[32mâ€¢ [SLOW TEST:48.161 seconds][0m
[k8s.io] Container Lifecycle Hook
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  when create a pod with lifecycle hook
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40[0m
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (root,0777,default) [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:43:31.826: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test emptydir 0777 on node default medium
Mar 26 22:43:32.669: INFO: Waiting up to 5m0s for pod "pod-1c6821c5-503a-11e9-9bdd-d050998677c2" in namespace "e2e-tests-emptydir-br4vx" to be "success or failure"
Mar 26 22:43:32.694: INFO: Pod "pod-1c6821c5-503a-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.603918ms
Mar 26 22:43:34.720: INFO: Pod "pod-1c6821c5-503a-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.051545428s
[1mSTEP[0m: Saw pod success
Mar 26 22:43:34.720: INFO: Pod "pod-1c6821c5-503a-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:43:34.746: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-1c6821c5-503a-11e9-9bdd-d050998677c2 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:43:34.805: INFO: Waiting for pod pod-1c6821c5-503a-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:43:34.831: INFO: Pod pod-1c6821c5-503a-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:43:34.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-br4vx" for this suite.
Mar 26 22:43:40.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:43:41.110: INFO: namespace: e2e-tests-emptydir-br4vx, resource: bindings, ignored listing per whitelist
Mar 26 22:43:41.865: INFO: namespace e2e-tests-emptydir-br4vx deletion completed in 7.007975077s

[32mâ€¢ [SLOW TEST:10.039 seconds][0m
[sig-storage] EmptyDir volumes
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (root,0777,default) [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould get a host IP [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Pods
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:43:41.865: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating pod
Mar 26 22:43:44.813: INFO: Pod pod-hostip-226465c6-503a-11e9-9bdd-d050998677c2 has hostIP: 172.20.56.226
[AfterEach] [k8s.io] Pods
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:43:44.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pods-ztkc8" for this suite.
Mar 26 22:44:06.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:44:07.240: INFO: namespace: e2e-tests-pods-ztkc8, resource: bindings, ignored listing per whitelist
Mar 26 22:44:07.842: INFO: namespace e2e-tests-pods-ztkc8 deletion completed in 23.002282864s

[32mâ€¢ [SLOW TEST:25.977 seconds][0m
[k8s.io] Pods
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should get a host IP [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Pods
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:44:07.842: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating the pod
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: verifying the pod is in kubernetes
[1mSTEP[0m: updating the pod
Mar 26 22:44:11.344: INFO: Successfully updated pod "pod-update-activedeadlineseconds-31e00da1-503a-11e9-9bdd-d050998677c2"
Mar 26 22:44:11.344: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-31e00da1-503a-11e9-9bdd-d050998677c2" in namespace "e2e-tests-pods-558pq" to be "terminated due to deadline exceeded"
Mar 26 22:44:11.370: INFO: Pod "pod-update-activedeadlineseconds-31e00da1-503a-11e9-9bdd-d050998677c2": Phase="Running", Reason="", readiness=true. Elapsed: 25.554657ms
Mar 26 22:44:13.396: INFO: Pod "pod-update-activedeadlineseconds-31e00da1-503a-11e9-9bdd-d050998677c2": Phase="Running", Reason="", readiness=true. Elapsed: 2.051221139s
Mar 26 22:44:15.422: INFO: Pod "pod-update-activedeadlineseconds-31e00da1-503a-11e9-9bdd-d050998677c2": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.077413864s
Mar 26 22:44:15.422: INFO: Pod "pod-update-activedeadlineseconds-31e00da1-503a-11e9-9bdd-d050998677c2" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:44:15.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pods-558pq" for this suite.
Mar 26 22:44:21.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:44:21.654: INFO: namespace: e2e-tests-pods-558pq, resource: bindings, ignored listing per whitelist
Mar 26 22:44:22.470: INFO: namespace e2e-tests-pods-558pq deletion completed in 7.020914825s

[32mâ€¢ [SLOW TEST:14.628 seconds][0m
[k8s.io] Pods
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Watchers[0m 
  [1mshould observe add, update, and delete watch notifications on configmaps [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Watchers
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:44:22.470: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename watch
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating a watch on configmaps with label A
[1mSTEP[0m: creating a watch on configmaps with label B
[1mSTEP[0m: creating a watch on configmaps with label A or B
[1mSTEP[0m: creating a configmap with label A and ensuring the correct watchers observe the notification
Mar 26 22:44:23.382: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-jlnbx,SelfLink:/api/v1/namespaces/e2e-tests-watch-jlnbx/configmaps/e2e-watch-test-configmap-a,UID:3aa5045a-503a-11e9-8eb3-023bf32bf132,ResourceVersion:23764,Generation:0,CreationTimestamp:2019-03-26 22:44:23 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 26 22:44:23.383: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-jlnbx,SelfLink:/api/v1/namespaces/e2e-tests-watch-jlnbx/configmaps/e2e-watch-test-configmap-a,UID:3aa5045a-503a-11e9-8eb3-023bf32bf132,ResourceVersion:23764,Generation:0,CreationTimestamp:2019-03-26 22:44:23 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[1mSTEP[0m: modifying configmap A and ensuring the correct watchers observe the notification
Mar 26 22:44:33.434: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-jlnbx,SelfLink:/api/v1/namespaces/e2e-tests-watch-jlnbx/configmaps/e2e-watch-test-configmap-a,UID:3aa5045a-503a-11e9-8eb3-023bf32bf132,ResourceVersion:23779,Generation:0,CreationTimestamp:2019-03-26 22:44:23 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar 26 22:44:33.434: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-jlnbx,SelfLink:/api/v1/namespaces/e2e-tests-watch-jlnbx/configmaps/e2e-watch-test-configmap-a,UID:3aa5045a-503a-11e9-8eb3-023bf32bf132,ResourceVersion:23779,Generation:0,CreationTimestamp:2019-03-26 22:44:23 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
[1mSTEP[0m: modifying configmap A again and ensuring the correct watchers observe the notification
Mar 26 22:44:43.486: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-jlnbx,SelfLink:/api/v1/namespaces/e2e-tests-watch-jlnbx/configmaps/e2e-watch-test-configmap-a,UID:3aa5045a-503a-11e9-8eb3-023bf32bf132,ResourceVersion:23795,Generation:0,CreationTimestamp:2019-03-26 22:44:23 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 26 22:44:43.486: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-jlnbx,SelfLink:/api/v1/namespaces/e2e-tests-watch-jlnbx/configmaps/e2e-watch-test-configmap-a,UID:3aa5045a-503a-11e9-8eb3-023bf32bf132,ResourceVersion:23795,Generation:0,CreationTimestamp:2019-03-26 22:44:23 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[1mSTEP[0m: deleting configmap A and ensuring the correct watchers observe the notification
Mar 26 22:44:53.513: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-jlnbx,SelfLink:/api/v1/namespaces/e2e-tests-watch-jlnbx/configmaps/e2e-watch-test-configmap-a,UID:3aa5045a-503a-11e9-8eb3-023bf32bf132,ResourceVersion:23810,Generation:0,CreationTimestamp:2019-03-26 22:44:23 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 26 22:44:53.513: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-jlnbx,SelfLink:/api/v1/namespaces/e2e-tests-watch-jlnbx/configmaps/e2e-watch-test-configmap-a,UID:3aa5045a-503a-11e9-8eb3-023bf32bf132,ResourceVersion:23810,Generation:0,CreationTimestamp:2019-03-26 22:44:23 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[1mSTEP[0m: creating a configmap with label B and ensuring the correct watchers observe the notification
Mar 26 22:45:03.541: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-jlnbx,SelfLink:/api/v1/namespaces/e2e-tests-watch-jlnbx/configmaps/e2e-watch-test-configmap-b,UID:52947257-503a-11e9-8eb3-023bf32bf132,ResourceVersion:23825,Generation:0,CreationTimestamp:2019-03-26 22:45:03 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 26 22:45:03.541: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-jlnbx,SelfLink:/api/v1/namespaces/e2e-tests-watch-jlnbx/configmaps/e2e-watch-test-configmap-b,UID:52947257-503a-11e9-8eb3-023bf32bf132,ResourceVersion:23825,Generation:0,CreationTimestamp:2019-03-26 22:45:03 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[1mSTEP[0m: deleting configmap B and ensuring the correct watchers observe the notification
Mar 26 22:45:13.568: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-jlnbx,SelfLink:/api/v1/namespaces/e2e-tests-watch-jlnbx/configmaps/e2e-watch-test-configmap-b,UID:52947257-503a-11e9-8eb3-023bf32bf132,ResourceVersion:23840,Generation:0,CreationTimestamp:2019-03-26 22:45:03 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 26 22:45:13.568: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-jlnbx,SelfLink:/api/v1/namespaces/e2e-tests-watch-jlnbx/configmaps/e2e-watch-test-configmap-b,UID:52947257-503a-11e9-8eb3-023bf32bf132,ResourceVersion:23840,Generation:0,CreationTimestamp:2019-03-26 22:45:03 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:45:23.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-watch-jlnbx" for this suite.
Mar 26 22:45:29.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:45:29.823: INFO: namespace: e2e-tests-watch-jlnbx, resource: bindings, ignored listing per whitelist
Mar 26 22:45:30.613: INFO: namespace e2e-tests-watch-jlnbx deletion completed in 7.017428195s

[32mâ€¢ [SLOW TEST:68.143 seconds][0m
[sig-api-machinery] Watchers
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide container's cpu limit [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:45:30.613: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 26 22:45:31.448: INFO: Waiting up to 5m0s for pod "downwardapi-volume-63346cbc-503a-11e9-9bdd-d050998677c2" in namespace "e2e-tests-downward-api-d2jp4" to be "success or failure"
Mar 26 22:45:31.474: INFO: Pod "downwardapi-volume-63346cbc-503a-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.346243ms
Mar 26 22:45:33.500: INFO: Pod "downwardapi-volume-63346cbc-503a-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.05144634s
[1mSTEP[0m: Saw pod success
Mar 26 22:45:33.500: INFO: Pod "downwardapi-volume-63346cbc-503a-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:45:33.525: INFO: Trying to get logs from node ip-172-20-53-156.us-east-2.compute.internal pod downwardapi-volume-63346cbc-503a-11e9-9bdd-d050998677c2 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:45:33.588: INFO: Waiting for pod downwardapi-volume-63346cbc-503a-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:45:33.613: INFO: Pod downwardapi-volume-63346cbc-503a-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:45:33.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-d2jp4" for this suite.
Mar 26 22:45:39.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:45:40.395: INFO: namespace: e2e-tests-downward-api-d2jp4, resource: bindings, ignored listing per whitelist
Mar 26 22:45:40.645: INFO: namespace e2e-tests-downward-api-d2jp4 deletion completed in 7.004496928s

[32mâ€¢ [SLOW TEST:10.032 seconds][0m
[sig-storage] Downward API volume
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34[0m
  should provide container's cpu limit [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:45:40.645: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 26 22:45:41.491: INFO: Waiting up to 5m0s for pod "downwardapi-volume-693090c2-503a-11e9-9bdd-d050998677c2" in namespace "e2e-tests-projected-dwdcs" to be "success or failure"
Mar 26 22:45:41.517: INFO: Pod "downwardapi-volume-693090c2-503a-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.421852ms
Mar 26 22:45:43.546: INFO: Pod "downwardapi-volume-693090c2-503a-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.054735796s
[1mSTEP[0m: Saw pod success
Mar 26 22:45:43.546: INFO: Pod "downwardapi-volume-693090c2-503a-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:45:43.571: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod downwardapi-volume-693090c2-503a-11e9-9bdd-d050998677c2 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:45:43.634: INFO: Waiting for pod downwardapi-volume-693090c2-503a-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:45:43.659: INFO: Pod downwardapi-volume-693090c2-503a-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:45:43.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-dwdcs" for this suite.
Mar 26 22:45:49.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:45:50.319: INFO: namespace: e2e-tests-projected-dwdcs, resource: bindings, ignored listing per whitelist
Mar 26 22:45:50.702: INFO: namespace e2e-tests-projected-dwdcs deletion completed in 7.016651185s

[32mâ€¢ [SLOW TEST:10.057 seconds][0m
[sig-storage] Projected
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35[0m
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:45:50.702: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename gc
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: create the deployment
[1mSTEP[0m: Wait for the Deployment to create new ReplicaSet
[1mSTEP[0m: delete the deployment
[1mSTEP[0m: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
[1mSTEP[0m: Gathering metrics
W0326 22:46:21.732149    2026 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 26 22:46:21.732: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:46:21.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-gc-h7tx4" for this suite.
Mar 26 22:46:27.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:46:28.445: INFO: namespace: e2e-tests-gc-h7tx4, resource: bindings, ignored listing per whitelist
Mar 26 22:46:28.774: INFO: namespace e2e-tests-gc-h7tx4 deletion completed in 7.015058486s

[32mâ€¢ [SLOW TEST:38.072 seconds][0m
[sig-api-machinery] Garbage collector
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[k8s.io] [sig-node] Events[0m 
  [1mshould be sent by kubelets and the scheduler about pods scheduling and running  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] [sig-node] Events
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:46:28.774: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename events
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating the pod
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: verifying the pod is in kubernetes
[1mSTEP[0m: retrieving the pod
Mar 26 22:46:31.724: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-85e0e0be-503a-11e9-9bdd-d050998677c2,GenerateName:,Namespace:e2e-tests-events-gjdr9,SelfLink:/api/v1/namespaces/e2e-tests-events-gjdr9/pods/send-events-85e0e0be-503a-11e9-9bdd-d050998677c2,UID:85e381a4-503a-11e9-8eb3-023bf32bf132,ResourceVersion:24032,Generation:0,CreationTimestamp:2019-03-26 22:46:29 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 594342482,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wfjtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wfjtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-wfjtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-56-226.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001977400} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001977420}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 22:46:29 -0400 EDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 22:46:30 -0400 EDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 22:46:30 -0400 EDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 22:46:29 -0400 EDT  }],Message:,Reason:,HostIP:172.20.56.226,PodIP:100.96.2.200,StartTime:2019-03-26 22:46:29 -0400 EDT,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-03-26 22:46:30 -0400 EDT,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://2dd2112fed77aa6b2b46b79505be651ce6b0b917a02854a28c3d8074e36d6a61}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

[1mSTEP[0m: checking for scheduler event about the pod
Mar 26 22:46:33.750: INFO: Saw scheduler event for our pod.
[1mSTEP[0m: checking for kubelet event about the pod
Mar 26 22:46:35.777: INFO: Saw kubelet event for our pod.
[1mSTEP[0m: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:46:35.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-events-gjdr9" for this suite.
Mar 26 22:47:13.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:47:14.419: INFO: namespace: e2e-tests-events-gjdr9, resource: bindings, ignored listing per whitelist
Mar 26 22:47:14.852: INFO: namespace e2e-tests-events-gjdr9 deletion completed in 39.020316722s

[32mâ€¢ [SLOW TEST:46.079 seconds][0m
[k8s.io] [sig-node] Events
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-apps] StatefulSet[0m [90m[k8s.io] Basic StatefulSet functionality [StatefulSetBasic][0m 
  [1mshould perform rolling updates and roll backs of template modifications [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] StatefulSet
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:47:14.853: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename statefulset
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
[1mSTEP[0m: Creating service test in namespace e2e-tests-statefulset-4dsxf
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a new StatefulSet
Mar 26 22:47:15.767: INFO: Found 1 stateful pods, waiting for 3
Mar 26 22:47:25.796: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 26 22:47:25.796: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 26 22:47:25.796: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Mar 26 22:47:25.874: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-4dsxf ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 26 22:47:26.394: INFO: stderr: ""
Mar 26 22:47:26.394: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 26 22:47:26.394: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

[1mSTEP[0m: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar 26 22:47:36.560: INFO: Updating stateful set ss2
[1mSTEP[0m: Creating a new revision
[1mSTEP[0m: Updating Pods in reverse ordinal order
Mar 26 22:47:36.636: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-4dsxf ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:47:37.117: INFO: stderr: ""
Mar 26 22:47:37.117: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 26 22:47:37.117: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 26 22:47:47.274: INFO: Waiting for StatefulSet e2e-tests-statefulset-4dsxf/ss2 to complete update
Mar 26 22:47:47.274: INFO: Waiting for Pod e2e-tests-statefulset-4dsxf/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 26 22:47:47.274: INFO: Waiting for Pod e2e-tests-statefulset-4dsxf/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 26 22:47:47.274: INFO: Waiting for Pod e2e-tests-statefulset-4dsxf/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 26 22:47:57.326: INFO: Waiting for StatefulSet e2e-tests-statefulset-4dsxf/ss2 to complete update
Mar 26 22:47:57.326: INFO: Waiting for Pod e2e-tests-statefulset-4dsxf/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 26 22:47:57.326: INFO: Waiting for Pod e2e-tests-statefulset-4dsxf/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
[1mSTEP[0m: Rolling back to a previous revision
Mar 26 22:48:07.326: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-4dsxf ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 26 22:48:07.818: INFO: stderr: ""
Mar 26 22:48:07.818: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 26 22:48:07.818: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 26 22:48:17.983: INFO: Updating stateful set ss2
[1mSTEP[0m: Rolling back update in reverse ordinal order
Mar 26 22:48:18.060: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-4dsxf ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:48:18.540: INFO: stderr: ""
Mar 26 22:48:18.540: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 26 22:48:18.540: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 26 22:48:28.693: INFO: Waiting for StatefulSet e2e-tests-statefulset-4dsxf/ss2 to complete update
Mar 26 22:48:28.693: INFO: Waiting for Pod e2e-tests-statefulset-4dsxf/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 26 22:48:38.744: INFO: Deleting all statefulset in ns e2e-tests-statefulset-4dsxf
Mar 26 22:48:38.769: INFO: Scaling statefulset ss2 to 0
Mar 26 22:49:08.875: INFO: Waiting for statefulset status.replicas updated to 0
Mar 26 22:49:08.902: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:49:08.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-statefulset-4dsxf" for this suite.
Mar 26 22:49:15.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:49:15.362: INFO: namespace: e2e-tests-statefulset-4dsxf, resource: bindings, ignored listing per whitelist
Mar 26 22:49:16.022: INFO: namespace e2e-tests-statefulset-4dsxf deletion completed in 7.015256632s

[32mâ€¢ [SLOW TEST:121.170 seconds][0m
[sig-apps] StatefulSet
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should perform rolling updates and roll backs of template modifications [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] CustomResourceDefinition resources[0m [90mSimple CustomResourceDefinition[0m 
  [1mcreating/deleting custom resource definition objects works  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:49:16.023: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename custom-resource-definition
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 22:49:16.861: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:49:17.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-custom-resource-definition-5cfk9" for this suite.
Mar 26 22:49:23.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:49:23.257: INFO: namespace: e2e-tests-custom-resource-definition-5cfk9, resource: bindings, ignored listing per whitelist
Mar 26 22:49:24.092: INFO: namespace e2e-tests-custom-resource-definition-5cfk9 deletion completed in 7.011404044s

[32mâ€¢ [SLOW TEST:8.069 seconds][0m
[sig-api-machinery] CustomResourceDefinition resources
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  Simple CustomResourceDefinition
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35[0m
    creating/deleting custom resource definition objects works  [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Watchers[0m 
  [1mshould observe an object deletion if it stops meeting the requirements of the selector [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Watchers
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:49:24.092: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename watch
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating a watch on configmaps with a certain label
[1mSTEP[0m: creating a new configmap
[1mSTEP[0m: modifying the configmap once
[1mSTEP[0m: changing the label value of the configmap
[1mSTEP[0m: Expecting to observe a delete notification for the watched object
Mar 26 22:49:25.062: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-8dxbb,SelfLink:/api/v1/namespaces/e2e-tests-watch-8dxbb/configmaps/e2e-watch-test-label-changed,UID:ee65ede3-503a-11e9-8eb3-023bf32bf132,ResourceVersion:24488,Generation:0,CreationTimestamp:2019-03-26 22:49:24 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 26 22:49:25.062: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-8dxbb,SelfLink:/api/v1/namespaces/e2e-tests-watch-8dxbb/configmaps/e2e-watch-test-label-changed,UID:ee65ede3-503a-11e9-8eb3-023bf32bf132,ResourceVersion:24489,Generation:0,CreationTimestamp:2019-03-26 22:49:24 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar 26 22:49:25.062: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-8dxbb,SelfLink:/api/v1/namespaces/e2e-tests-watch-8dxbb/configmaps/e2e-watch-test-label-changed,UID:ee65ede3-503a-11e9-8eb3-023bf32bf132,ResourceVersion:24490,Generation:0,CreationTimestamp:2019-03-26 22:49:24 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
[1mSTEP[0m: modifying the configmap a second time
[1mSTEP[0m: Expecting not to observe a notification because the object no longer meets the selector's requirements
[1mSTEP[0m: changing the label value of the configmap back
[1mSTEP[0m: modifying the configmap a third time
[1mSTEP[0m: deleting the configmap
[1mSTEP[0m: Expecting to observe an add notification for the watched object when the label value was restored
Mar 26 22:49:35.246: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-8dxbb,SelfLink:/api/v1/namespaces/e2e-tests-watch-8dxbb/configmaps/e2e-watch-test-label-changed,UID:ee65ede3-503a-11e9-8eb3-023bf32bf132,ResourceVersion:24507,Generation:0,CreationTimestamp:2019-03-26 22:49:24 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 26 22:49:35.246: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-8dxbb,SelfLink:/api/v1/namespaces/e2e-tests-watch-8dxbb/configmaps/e2e-watch-test-label-changed,UID:ee65ede3-503a-11e9-8eb3-023bf32bf132,ResourceVersion:24508,Generation:0,CreationTimestamp:2019-03-26 22:49:24 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Mar 26 22:49:35.246: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-8dxbb,SelfLink:/api/v1/namespaces/e2e-tests-watch-8dxbb/configmaps/e2e-watch-test-label-changed,UID:ee65ede3-503a-11e9-8eb3-023bf32bf132,ResourceVersion:24509,Generation:0,CreationTimestamp:2019-03-26 22:49:24 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:49:35.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-watch-8dxbb" for this suite.
Mar 26 22:49:41.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:49:42.107: INFO: namespace: e2e-tests-watch-8dxbb, resource: bindings, ignored listing per whitelist
Mar 26 22:49:42.284: INFO: namespace e2e-tests-watch-8dxbb deletion completed in 7.010758271s

[32mâ€¢ [SLOW TEST:18.192 seconds][0m
[sig-api-machinery] Watchers
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Update Demo[0m 
  [1mshould do a rolling update of a replication controller  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:49:42.284: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating the initial replication controller
Mar 26 22:49:43.105: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config create -f - --namespace=e2e-tests-kubectl-rzw75'
Mar 26 22:49:44.742: INFO: stderr: ""
Mar 26 22:49:44.742: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
[1mSTEP[0m: waiting for all containers in name=update-demo pods to come up.
Mar 26 22:49:44.742: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rzw75'
Mar 26 22:49:44.944: INFO: stderr: ""
Mar 26 22:49:44.944: INFO: stdout: "update-demo-nautilus-75r8j update-demo-nautilus-g262w "
Mar 26 22:49:44.944: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods update-demo-nautilus-75r8j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rzw75'
Mar 26 22:49:45.147: INFO: stderr: ""
Mar 26 22:49:45.147: INFO: stdout: ""
Mar 26 22:49:45.147: INFO: update-demo-nautilus-75r8j is created but not running
Mar 26 22:49:50.147: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rzw75'
Mar 26 22:49:50.369: INFO: stderr: ""
Mar 26 22:49:50.369: INFO: stdout: "update-demo-nautilus-75r8j update-demo-nautilus-g262w "
Mar 26 22:49:50.369: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods update-demo-nautilus-75r8j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rzw75'
Mar 26 22:49:50.584: INFO: stderr: ""
Mar 26 22:49:50.584: INFO: stdout: "true"
Mar 26 22:49:50.584: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods update-demo-nautilus-75r8j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rzw75'
Mar 26 22:49:50.775: INFO: stderr: ""
Mar 26 22:49:50.775: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 26 22:49:50.775: INFO: validating pod update-demo-nautilus-75r8j
Mar 26 22:49:50.802: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 26 22:49:50.802: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 26 22:49:50.802: INFO: update-demo-nautilus-75r8j is verified up and running
Mar 26 22:49:50.802: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods update-demo-nautilus-g262w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rzw75'
Mar 26 22:49:51.010: INFO: stderr: ""
Mar 26 22:49:51.010: INFO: stdout: "true"
Mar 26 22:49:51.010: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods update-demo-nautilus-g262w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rzw75'
Mar 26 22:49:51.221: INFO: stderr: ""
Mar 26 22:49:51.221: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 26 22:49:51.221: INFO: validating pod update-demo-nautilus-g262w
Mar 26 22:49:51.247: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 26 22:49:51.247: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 26 22:49:51.247: INFO: update-demo-nautilus-g262w is verified up and running
[1mSTEP[0m: rolling-update to new replication controller
Mar 26 22:49:51.300: INFO: scanned /home/justinsb for discovery docs: <nil>
Mar 26 22:49:51.300: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-rzw75'
Mar 26 22:50:06.943: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar 26 22:50:06.943: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
[1mSTEP[0m: waiting for all containers in name=update-demo pods to come up.
Mar 26 22:50:06.943: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rzw75'
Mar 26 22:50:07.145: INFO: stderr: ""
Mar 26 22:50:07.145: INFO: stdout: "update-demo-kitten-8z82p update-demo-kitten-f5pn2 "
Mar 26 22:50:07.145: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods update-demo-kitten-8z82p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rzw75'
Mar 26 22:50:07.339: INFO: stderr: ""
Mar 26 22:50:07.339: INFO: stdout: "true"
Mar 26 22:50:07.339: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods update-demo-kitten-8z82p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rzw75'
Mar 26 22:50:07.524: INFO: stderr: ""
Mar 26 22:50:07.524: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar 26 22:50:07.524: INFO: validating pod update-demo-kitten-8z82p
Mar 26 22:50:07.551: INFO: got data: {
  "image": "kitten.jpg"
}

Mar 26 22:50:07.552: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar 26 22:50:07.552: INFO: update-demo-kitten-8z82p is verified up and running
Mar 26 22:50:07.552: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods update-demo-kitten-f5pn2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rzw75'
Mar 26 22:50:07.729: INFO: stderr: ""
Mar 26 22:50:07.729: INFO: stdout: "true"
Mar 26 22:50:07.729: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config get pods update-demo-kitten-f5pn2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rzw75'
Mar 26 22:50:07.921: INFO: stderr: ""
Mar 26 22:50:07.921: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar 26 22:50:07.921: INFO: validating pod update-demo-kitten-f5pn2
Mar 26 22:50:07.947: INFO: got data: {
  "image": "kitten.jpg"
}

Mar 26 22:50:07.947: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar 26 22:50:07.947: INFO: update-demo-kitten-f5pn2 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:50:07.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-rzw75" for this suite.
Mar 26 22:50:30.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:50:30.273: INFO: namespace: e2e-tests-kubectl-rzw75, resource: bindings, ignored listing per whitelist
Mar 26 22:50:30.976: INFO: namespace e2e-tests-kubectl-rzw75 deletion completed in 23.002010084s

[32mâ€¢ [SLOW TEST:48.692 seconds][0m
[sig-cli] Kubectl client
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Update Demo
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should do a rolling update of a replication controller  [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl api-versions[0m 
  [1mshould check if v1 is in available api versions  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:50:30.976: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: validating api versions
Mar 26 22:50:31.788: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config api-versions'
Mar 26 22:50:31.995: INFO: stderr: ""
Mar 26 22:50:31.995: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:50:31.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-lvzn4" for this suite.
Mar 26 22:50:38.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:50:38.651: INFO: namespace: e2e-tests-kubectl-lvzn4, resource: bindings, ignored listing per whitelist
Mar 26 22:50:39.024: INFO: namespace e2e-tests-kubectl-lvzn4 deletion completed in 7.002446257s

[32mâ€¢ [SLOW TEST:8.048 seconds][0m
[sig-cli] Kubectl client
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl api-versions
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should check if v1 is in available api versions  [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Deployment[0m 
  [1mdeployment should support rollover [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] Deployment
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:50:39.025: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename deployment
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 22:50:39.887: INFO: Pod name rollover-pod: Found 1 pods out of 1
[1mSTEP[0m: ensuring each pod is running
Mar 26 22:50:41.938: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Mar 26 22:50:43.964: INFO: Creating deployment "test-rollover-deployment"
Mar 26 22:50:44.023: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Mar 26 22:50:44.048: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Mar 26 22:50:44.099: INFO: Ensure that both replica sets have 1 created replica
Mar 26 22:50:44.150: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Mar 26 22:50:44.202: INFO: Updating deployment test-rollover-deployment
Mar 26 22:50:44.202: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Mar 26 22:50:44.234: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Mar 26 22:50:44.284: INFO: Make sure deployment "test-rollover-deployment" is complete
Mar 26 22:50:44.336: INFO: all replica sets need to contain the pod-template-hash label
Mar 26 22:50:44.336: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689251844, loc:(*time.Location)(0x835fd00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689251844, loc:(*time.Location)(0x835fd00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689251844, loc:(*time.Location)(0x835fd00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689251843, loc:(*time.Location)(0x835fd00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 26 22:50:46.387: INFO: all replica sets need to contain the pod-template-hash label
Mar 26 22:50:46.387: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689251844, loc:(*time.Location)(0x835fd00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689251844, loc:(*time.Location)(0x835fd00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689251845, loc:(*time.Location)(0x835fd00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689251843, loc:(*time.Location)(0x835fd00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 26 22:50:48.389: INFO: all replica sets need to contain the pod-template-hash label
Mar 26 22:50:48.389: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689251844, loc:(*time.Location)(0x835fd00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689251844, loc:(*time.Location)(0x835fd00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689251845, loc:(*time.Location)(0x835fd00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689251843, loc:(*time.Location)(0x835fd00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 26 22:50:50.387: INFO: all replica sets need to contain the pod-template-hash label
Mar 26 22:50:50.387: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689251844, loc:(*time.Location)(0x835fd00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689251844, loc:(*time.Location)(0x835fd00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689251845, loc:(*time.Location)(0x835fd00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689251843, loc:(*time.Location)(0x835fd00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 26 22:50:52.387: INFO: all replica sets need to contain the pod-template-hash label
Mar 26 22:50:52.387: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689251844, loc:(*time.Location)(0x835fd00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689251844, loc:(*time.Location)(0x835fd00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689251845, loc:(*time.Location)(0x835fd00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689251843, loc:(*time.Location)(0x835fd00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 26 22:50:54.387: INFO: all replica sets need to contain the pod-template-hash label
Mar 26 22:50:54.387: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689251844, loc:(*time.Location)(0x835fd00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689251844, loc:(*time.Location)(0x835fd00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689251845, loc:(*time.Location)(0x835fd00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689251843, loc:(*time.Location)(0x835fd00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 26 22:50:56.387: INFO: 
Mar 26 22:50:56.387: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 26 22:50:56.464: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-pqr85,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-pqr85/deployments/test-rollover-deployment,UID:1d811c0b-503b-11e9-8eb3-023bf32bf132,ResourceVersion:24766,Generation:2,CreationTimestamp:2019-03-26 22:50:43 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-26 22:50:44 -0400 EDT 2019-03-26 22:50:44 -0400 EDT MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-26 22:50:55 -0400 EDT 2019-03-26 22:50:43 -0400 EDT NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar 26 22:50:56.490: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-pqr85,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-pqr85/replicasets/test-rollover-deployment-5b76ff8c4,UID:1da1dce3-503b-11e9-8eb3-023bf32bf132,ResourceVersion:24759,Generation:2,CreationTimestamp:2019-03-26 22:50:44 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 1d811c0b-503b-11e9-8eb3-023bf32bf132 0xc0029861c0 0xc0029861c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 26 22:50:56.490: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Mar 26 22:50:56.490: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-pqr85,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-pqr85/replicasets/test-rollover-controller,UID:1b0af3f5-503b-11e9-8eb3-023bf32bf132,ResourceVersion:24765,Generation:2,CreationTimestamp:2019-03-26 22:50:39 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 1d811c0b-503b-11e9-8eb3-023bf32bf132 0xc002986107 0xc002986108}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 26 22:50:56.490: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-pqr85,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-pqr85/replicasets/test-rollover-deployment-6975f4fb87,UID:1d82ae78-503b-11e9-8eb3-023bf32bf132,ResourceVersion:24735,Generation:2,CreationTimestamp:2019-03-26 22:50:43 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 1d811c0b-503b-11e9-8eb3-023bf32bf132 0xc002986287 0xc002986288}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 26 22:50:56.516: INFO: Pod "test-rollover-deployment-5b76ff8c4-5czj4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-5czj4,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-pqr85,SelfLink:/api/v1/namespaces/e2e-tests-deployment-pqr85/pods/test-rollover-deployment-5b76ff8c4-5czj4,UID:1da53bec-503b-11e9-8eb3-023bf32bf132,ResourceVersion:24742,Generation:0,CreationTimestamp:2019-03-26 22:50:44 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 1da1dce3-503b-11e9-8eb3-023bf32bf132 0xc002986f80 0xc002986f81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vq27c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vq27c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-vq27c true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-56-226.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002986fe0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002987000}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 22:50:44 -0400 EDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 22:50:45 -0400 EDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 22:50:45 -0400 EDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 22:50:44 -0400 EDT  }],Message:,Reason:,HostIP:172.20.56.226,PodIP:100.96.2.211,StartTime:2019-03-26 22:50:44 -0400 EDT,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-26 22:50:45 -0400 EDT,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://7a249a803769f5c615d2a877ae55d37527d23154f212a3af823e7163527ebe99}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:50:56.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-deployment-pqr85" for this suite.
Mar 26 22:51:02.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:51:03.348: INFO: namespace: e2e-tests-deployment-pqr85, resource: bindings, ignored listing per whitelist
Mar 26 22:51:03.549: INFO: namespace e2e-tests-deployment-pqr85 deletion completed in 7.006979063s

[32mâ€¢ [SLOW TEST:24.524 seconds][0m
[sig-apps] Deployment
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  deployment should support rollover [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-auth] ServiceAccounts[0m 
  [1mshould mount an API token into pods  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-auth] ServiceAccounts
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:51:03.549: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename svcaccounts
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: getting the auto-created API token
[1mSTEP[0m: Creating a pod to test consume service account token
Mar 26 22:51:04.942: INFO: Waiting up to 5m0s for pod "pod-service-account-29fb88ff-503b-11e9-9bdd-d050998677c2-j76rs" in namespace "e2e-tests-svcaccounts-bxzpj" to be "success or failure"
Mar 26 22:51:04.967: INFO: Pod "pod-service-account-29fb88ff-503b-11e9-9bdd-d050998677c2-j76rs": Phase="Pending", Reason="", readiness=false. Elapsed: 24.936534ms
Mar 26 22:51:06.993: INFO: Pod "pod-service-account-29fb88ff-503b-11e9-9bdd-d050998677c2-j76rs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.050342879s
[1mSTEP[0m: Saw pod success
Mar 26 22:51:06.993: INFO: Pod "pod-service-account-29fb88ff-503b-11e9-9bdd-d050998677c2-j76rs" satisfied condition "success or failure"
Mar 26 22:51:07.018: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-service-account-29fb88ff-503b-11e9-9bdd-d050998677c2-j76rs container token-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:51:07.078: INFO: Waiting for pod pod-service-account-29fb88ff-503b-11e9-9bdd-d050998677c2-j76rs to disappear
Mar 26 22:51:07.103: INFO: Pod pod-service-account-29fb88ff-503b-11e9-9bdd-d050998677c2-j76rs no longer exists
[1mSTEP[0m: Creating a pod to test consume service account root CA
Mar 26 22:51:07.130: INFO: Waiting up to 5m0s for pod "pod-service-account-29fb88ff-503b-11e9-9bdd-d050998677c2-h6fmw" in namespace "e2e-tests-svcaccounts-bxzpj" to be "success or failure"
Mar 26 22:51:07.155: INFO: Pod "pod-service-account-29fb88ff-503b-11e9-9bdd-d050998677c2-h6fmw": Phase="Pending", Reason="", readiness=false. Elapsed: 25.219542ms
Mar 26 22:51:09.183: INFO: Pod "pod-service-account-29fb88ff-503b-11e9-9bdd-d050998677c2-h6fmw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.052794846s
[1mSTEP[0m: Saw pod success
Mar 26 22:51:09.183: INFO: Pod "pod-service-account-29fb88ff-503b-11e9-9bdd-d050998677c2-h6fmw" satisfied condition "success or failure"
Mar 26 22:51:09.208: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-service-account-29fb88ff-503b-11e9-9bdd-d050998677c2-h6fmw container root-ca-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:51:09.270: INFO: Waiting for pod pod-service-account-29fb88ff-503b-11e9-9bdd-d050998677c2-h6fmw to disappear
Mar 26 22:51:09.295: INFO: Pod pod-service-account-29fb88ff-503b-11e9-9bdd-d050998677c2-h6fmw no longer exists
[1mSTEP[0m: Creating a pod to test consume service account namespace
Mar 26 22:51:09.321: INFO: Waiting up to 5m0s for pod "pod-service-account-29fb88ff-503b-11e9-9bdd-d050998677c2-zswsg" in namespace "e2e-tests-svcaccounts-bxzpj" to be "success or failure"
Mar 26 22:51:09.346: INFO: Pod "pod-service-account-29fb88ff-503b-11e9-9bdd-d050998677c2-zswsg": Phase="Pending", Reason="", readiness=false. Elapsed: 24.957187ms
Mar 26 22:51:11.371: INFO: Pod "pod-service-account-29fb88ff-503b-11e9-9bdd-d050998677c2-zswsg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.050691298s
[1mSTEP[0m: Saw pod success
Mar 26 22:51:11.371: INFO: Pod "pod-service-account-29fb88ff-503b-11e9-9bdd-d050998677c2-zswsg" satisfied condition "success or failure"
Mar 26 22:51:11.397: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-service-account-29fb88ff-503b-11e9-9bdd-d050998677c2-zswsg container namespace-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:51:11.458: INFO: Waiting for pod pod-service-account-29fb88ff-503b-11e9-9bdd-d050998677c2-zswsg to disappear
Mar 26 22:51:11.482: INFO: Pod pod-service-account-29fb88ff-503b-11e9-9bdd-d050998677c2-zswsg no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:51:11.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-svcaccounts-bxzpj" for this suite.
Mar 26 22:51:17.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:51:17.758: INFO: namespace: e2e-tests-svcaccounts-bxzpj, resource: bindings, ignored listing per whitelist
Mar 26 22:51:18.509: INFO: namespace e2e-tests-svcaccounts-bxzpj deletion completed in 7.000732539s

[32mâ€¢ [SLOW TEST:14.960 seconds][0m
[sig-auth] ServiceAccounts
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22[0m
  should mount an API token into pods  [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould be consumable in multiple volumes in the same pod [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:51:18.510: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-32921ce0-503b-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 26 22:51:19.376: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-32960487-503b-11e9-9bdd-d050998677c2" in namespace "e2e-tests-projected-9qk94" to be "success or failure"
Mar 26 22:51:19.401: INFO: Pod "pod-projected-configmaps-32960487-503b-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.223522ms
Mar 26 22:51:21.427: INFO: Pod "pod-projected-configmaps-32960487-503b-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.051019262s
[1mSTEP[0m: Saw pod success
Mar 26 22:51:21.427: INFO: Pod "pod-projected-configmaps-32960487-503b-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:51:21.453: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-projected-configmaps-32960487-503b-11e9-9bdd-d050998677c2 container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:51:21.512: INFO: Waiting for pod pod-projected-configmaps-32960487-503b-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:51:21.537: INFO: Pod pod-projected-configmaps-32960487-503b-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:51:21.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-9qk94" for this suite.
Mar 26 22:51:27.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:51:28.291: INFO: namespace: e2e-tests-projected-9qk94, resource: bindings, ignored listing per whitelist
Mar 26 22:51:28.567: INFO: namespace e2e-tests-projected-9qk94 deletion completed in 7.003528407s

[32mâ€¢ [SLOW TEST:10.058 seconds][0m
[sig-storage] Projected
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35[0m
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (non-root,0644,tmpfs) [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:51:28.567: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test emptydir 0644 on tmpfs
Mar 26 22:51:29.409: INFO: Waiting up to 5m0s for pod "pod-3890f9cf-503b-11e9-9bdd-d050998677c2" in namespace "e2e-tests-emptydir-5d2bq" to be "success or failure"
Mar 26 22:51:29.434: INFO: Pod "pod-3890f9cf-503b-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 24.891831ms
Mar 26 22:51:31.460: INFO: Pod "pod-3890f9cf-503b-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.050547499s
[1mSTEP[0m: Saw pod success
Mar 26 22:51:31.460: INFO: Pod "pod-3890f9cf-503b-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:51:31.485: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-3890f9cf-503b-11e9-9bdd-d050998677c2 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:51:31.543: INFO: Waiting for pod pod-3890f9cf-503b-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:51:31.568: INFO: Pod pod-3890f9cf-503b-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:51:31.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-5d2bq" for this suite.
Mar 26 22:51:37.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:51:38.249: INFO: namespace: e2e-tests-emptydir-5d2bq, resource: bindings, ignored listing per whitelist
Mar 26 22:51:38.603: INFO: namespace e2e-tests-emptydir-5d2bq deletion completed in 7.008247362s

[32mâ€¢ [SLOW TEST:10.035 seconds][0m
[sig-storage] EmptyDir volumes
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Secrets
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:51:38.603: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating secret with name secret-test-3e8d4837-503b-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume secrets
Mar 26 22:51:39.479: INFO: Waiting up to 5m0s for pod "pod-secrets-3e913a27-503b-11e9-9bdd-d050998677c2" in namespace "e2e-tests-secrets-dkvkg" to be "success or failure"
Mar 26 22:51:39.505: INFO: Pod "pod-secrets-3e913a27-503b-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.722951ms
Mar 26 22:51:41.531: INFO: Pod "pod-secrets-3e913a27-503b-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.051778887s
[1mSTEP[0m: Saw pod success
Mar 26 22:51:41.531: INFO: Pod "pod-secrets-3e913a27-503b-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:51:41.556: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-secrets-3e913a27-503b-11e9-9bdd-d050998677c2 container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:51:41.617: INFO: Waiting for pod pod-secrets-3e913a27-503b-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:51:41.642: INFO: Pod pod-secrets-3e913a27-503b-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Secrets
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:51:41.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-secrets-dkvkg" for this suite.
Mar 26 22:51:47.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:51:47.847: INFO: namespace: e2e-tests-secrets-dkvkg, resource: bindings, ignored listing per whitelist
Mar 26 22:51:48.681: INFO: namespace e2e-tests-secrets-dkvkg deletion completed in 7.012308893s

[32mâ€¢ [SLOW TEST:10.078 seconds][0m
[sig-storage] Secrets
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34[0m
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould be consumable from pods in volume [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:51:48.681: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating projection with secret that has name projected-secret-test-448e33a3-503b-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume secrets
Mar 26 22:51:49.550: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-44921f07-503b-11e9-9bdd-d050998677c2" in namespace "e2e-tests-projected-9n7s2" to be "success or failure"
Mar 26 22:51:49.575: INFO: Pod "pod-projected-secrets-44921f07-503b-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.198182ms
Mar 26 22:51:51.601: INFO: Pod "pod-projected-secrets-44921f07-503b-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.051361057s
[1mSTEP[0m: Saw pod success
Mar 26 22:51:51.601: INFO: Pod "pod-projected-secrets-44921f07-503b-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:51:51.627: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-projected-secrets-44921f07-503b-11e9-9bdd-d050998677c2 container projected-secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:51:51.688: INFO: Waiting for pod pod-projected-secrets-44921f07-503b-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:51:51.714: INFO: Pod pod-projected-secrets-44921f07-503b-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:51:51.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-9n7s2" for this suite.
Mar 26 22:51:57.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:51:58.278: INFO: namespace: e2e-tests-projected-9n7s2, resource: bindings, ignored listing per whitelist
Mar 26 22:51:58.762: INFO: namespace e2e-tests-projected-9n7s2 deletion completed in 7.021448324s

[32mâ€¢ [SLOW TEST:10.081 seconds][0m
[sig-storage] Projected
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35[0m
  should be consumable from pods in volume [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] ConfigMap
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:51:58.762: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name configmap-test-volume-map-4a90c624-503b-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 26 22:51:59.633: INFO: Waiting up to 5m0s for pod "pod-configmaps-4a94aa07-503b-11e9-9bdd-d050998677c2" in namespace "e2e-tests-configmap-6sh6g" to be "success or failure"
Mar 26 22:51:59.658: INFO: Pod "pod-configmaps-4a94aa07-503b-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.26675ms
Mar 26 22:52:01.687: INFO: Pod "pod-configmaps-4a94aa07-503b-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.054190333s
[1mSTEP[0m: Saw pod success
Mar 26 22:52:01.687: INFO: Pod "pod-configmaps-4a94aa07-503b-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:52:01.717: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-configmaps-4a94aa07-503b-11e9-9bdd-d050998677c2 container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:52:01.789: INFO: Waiting for pod pod-configmaps-4a94aa07-503b-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:52:01.818: INFO: Pod pod-configmaps-4a94aa07-503b-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:52:01.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-6sh6g" for this suite.
Mar 26 22:52:07.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:52:08.241: INFO: namespace: e2e-tests-configmap-6sh6g, resource: bindings, ignored listing per whitelist
Mar 26 22:52:08.868: INFO: namespace e2e-tests-configmap-6sh6g deletion completed in 7.009799388s

[32mâ€¢ [SLOW TEST:10.105 seconds][0m
[sig-storage] ConfigMap
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33[0m
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-scheduling] SchedulerPredicates [Serial][0m 
  [1mvalidates that NodeSelector is respected if matching  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:52:08.868: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename sched-pred
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Mar 26 22:52:09.684: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 26 22:52:09.737: INFO: Waiting for terminating namespaces to be deleted...
Mar 26 22:52:09.762: INFO: 
Logging pods the kubelet thinks is on node ip-172-20-53-156.us-east-2.compute.internal before test
Mar 26 22:52:09.790: INFO: kube-dns-autoscaler-867b9fd49d-s8grz from kube-system started at 2019-03-26 20:06:02 -0400 EDT (1 container statuses recorded)
Mar 26 22:52:09.790: INFO: 	Container autoscaler ready: true, restart count 0
Mar 26 22:52:09.790: INFO: kube-proxy-ip-172-20-53-156.us-east-2.compute.internal from kube-system started at <nil> (0 container statuses recorded)
Mar 26 22:52:09.790: INFO: kube-dns-7cfc48d44b-5z9lj from kube-system started at 2019-03-26 20:06:02 -0400 EDT (3 container statuses recorded)
Mar 26 22:52:09.790: INFO: 	Container dnsmasq ready: true, restart count 0
Mar 26 22:52:09.790: INFO: 	Container kubedns ready: true, restart count 0
Mar 26 22:52:09.790: INFO: 	Container sidecar ready: true, restart count 0
Mar 26 22:52:09.790: INFO: 
Logging pods the kubelet thinks is on node ip-172-20-56-226.us-east-2.compute.internal before test
Mar 26 22:52:09.818: INFO: kube-dns-7cfc48d44b-x4t9q from kube-system started at 2019-03-26 20:06:07 -0400 EDT (3 container statuses recorded)
Mar 26 22:52:09.818: INFO: 	Container dnsmasq ready: true, restart count 0
Mar 26 22:52:09.818: INFO: 	Container kubedns ready: true, restart count 0
Mar 26 22:52:09.818: INFO: 	Container sidecar ready: true, restart count 0
Mar 26 22:52:09.818: INFO: kube-proxy-ip-172-20-56-226.us-east-2.compute.internal from kube-system started at <nil> (0 container statuses recorded)
[It] validates that NodeSelector is respected if matching  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Trying to launch a pod without a label to get a node which can launch it.
[1mSTEP[0m: Explicitly delete pod here to free the resource it takes.
[1mSTEP[0m: Trying to apply a random label on the found node.
[1mSTEP[0m: verifying the node has the label kubernetes.io/e2e-51f099aa-503b-11e9-9bdd-d050998677c2 42
[1mSTEP[0m: Trying to relaunch the pod, now with labels.
[1mSTEP[0m: removing the label kubernetes.io/e2e-51f099aa-503b-11e9-9bdd-d050998677c2 off the node ip-172-20-56-226.us-east-2.compute.internal
[1mSTEP[0m: verifying the node doesn't have the label kubernetes.io/e2e-51f099aa-503b-11e9-9bdd-d050998677c2
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:52:14.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-sched-pred-2n5bw" for this suite.
Mar 26 22:52:32.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:52:32.967: INFO: namespace: e2e-tests-sched-pred-2n5bw, resource: bindings, ignored listing per whitelist
Mar 26 22:52:33.217: INFO: namespace e2e-tests-sched-pred-2n5bw deletion completed in 19.005087006s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

[32mâ€¢ [SLOW TEST:24.350 seconds][0m
[sig-scheduling] SchedulerPredicates [Serial]
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22[0m
  validates that NodeSelector is respected if matching  [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Downward API[0m 
  [1mshould provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Downward API
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:52:33.218: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward api env vars
Mar 26 22:52:34.061: INFO: Waiting up to 5m0s for pod "downward-api-5f19dc9f-503b-11e9-9bdd-d050998677c2" in namespace "e2e-tests-downward-api-fbns5" to be "success or failure"
Mar 26 22:52:34.086: INFO: Pod "downward-api-5f19dc9f-503b-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.707679ms
Mar 26 22:52:36.112: INFO: Pod "downward-api-5f19dc9f-503b-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.051417815s
[1mSTEP[0m: Saw pod success
Mar 26 22:52:36.112: INFO: Pod "downward-api-5f19dc9f-503b-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:52:36.138: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod downward-api-5f19dc9f-503b-11e9-9bdd-d050998677c2 container dapi-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:52:36.200: INFO: Waiting for pod downward-api-5f19dc9f-503b-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:52:36.225: INFO: Pod downward-api-5f19dc9f-503b-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:52:36.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-fbns5" for this suite.
Mar 26 22:52:42.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:52:43.254: INFO: namespace: e2e-tests-downward-api-fbns5, resource: bindings, ignored listing per whitelist
Mar 26 22:52:43.255: INFO: namespace e2e-tests-downward-api-fbns5 deletion completed in 7.002209159s

[32mâ€¢ [SLOW TEST:10.037 seconds][0m
[sig-api-machinery] Downward API
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38[0m
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Subpath[0m [90mAtomic writer volumes[0m 
  [1mshould support subpaths with projected pod [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Subpath
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:52:43.255: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename subpath
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
[1mSTEP[0m: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating pod pod-subpath-test-projected-r4tb
[1mSTEP[0m: Creating a pod to test atomic-volume-subpath
Mar 26 22:52:44.152: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-r4tb" in namespace "e2e-tests-subpath-6jh6k" to be "success or failure"
Mar 26 22:52:44.177: INFO: Pod "pod-subpath-test-projected-r4tb": Phase="Pending", Reason="", readiness=false. Elapsed: 25.015036ms
Mar 26 22:52:46.202: INFO: Pod "pod-subpath-test-projected-r4tb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050428058s
Mar 26 22:52:48.228: INFO: Pod "pod-subpath-test-projected-r4tb": Phase="Running", Reason="", readiness=false. Elapsed: 4.076648094s
Mar 26 22:52:50.254: INFO: Pod "pod-subpath-test-projected-r4tb": Phase="Running", Reason="", readiness=false. Elapsed: 6.102611102s
Mar 26 22:52:52.280: INFO: Pod "pod-subpath-test-projected-r4tb": Phase="Running", Reason="", readiness=false. Elapsed: 8.128417516s
Mar 26 22:52:54.306: INFO: Pod "pod-subpath-test-projected-r4tb": Phase="Running", Reason="", readiness=false. Elapsed: 10.154157409s
Mar 26 22:52:56.332: INFO: Pod "pod-subpath-test-projected-r4tb": Phase="Running", Reason="", readiness=false. Elapsed: 12.180101534s
Mar 26 22:52:58.358: INFO: Pod "pod-subpath-test-projected-r4tb": Phase="Running", Reason="", readiness=false. Elapsed: 14.206074261s
Mar 26 22:53:00.383: INFO: Pod "pod-subpath-test-projected-r4tb": Phase="Running", Reason="", readiness=false. Elapsed: 16.231681681s
Mar 26 22:53:02.409: INFO: Pod "pod-subpath-test-projected-r4tb": Phase="Running", Reason="", readiness=false. Elapsed: 18.257462767s
Mar 26 22:53:04.435: INFO: Pod "pod-subpath-test-projected-r4tb": Phase="Running", Reason="", readiness=false. Elapsed: 20.283056036s
Mar 26 22:53:06.461: INFO: Pod "pod-subpath-test-projected-r4tb": Phase="Running", Reason="", readiness=false. Elapsed: 22.309029519s
Mar 26 22:53:08.486: INFO: Pod "pod-subpath-test-projected-r4tb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.334711604s
[1mSTEP[0m: Saw pod success
Mar 26 22:53:08.486: INFO: Pod "pod-subpath-test-projected-r4tb" satisfied condition "success or failure"
Mar 26 22:53:08.511: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-subpath-test-projected-r4tb container test-container-subpath-projected-r4tb: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:53:08.574: INFO: Waiting for pod pod-subpath-test-projected-r4tb to disappear
Mar 26 22:53:08.599: INFO: Pod pod-subpath-test-projected-r4tb no longer exists
[1mSTEP[0m: Deleting pod pod-subpath-test-projected-r4tb
Mar 26 22:53:08.599: INFO: Deleting pod "pod-subpath-test-projected-r4tb" in namespace "e2e-tests-subpath-6jh6k"
[AfterEach] [sig-storage] Subpath
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:53:08.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-subpath-6jh6k" for this suite.
Mar 26 22:53:14.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:53:15.308: INFO: namespace: e2e-tests-subpath-6jh6k, resource: bindings, ignored listing per whitelist
Mar 26 22:53:15.660: INFO: namespace e2e-tests-subpath-6jh6k deletion completed in 7.009904651s

[32mâ€¢ [SLOW TEST:32.405 seconds][0m
[sig-storage] Subpath
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  Atomic writer volumes
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34[0m
    should support subpaths with projected pod [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Secrets[0m 
  [1mshould be consumable via the environment [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Secrets
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:53:15.660: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating secret e2e-tests-secrets-ptzgl/secret-test-78668104-503b-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume secrets
Mar 26 22:53:16.551: INFO: Waiting up to 5m0s for pod "pod-configmaps-786b720b-503b-11e9-9bdd-d050998677c2" in namespace "e2e-tests-secrets-ptzgl" to be "success or failure"
Mar 26 22:53:16.590: INFO: Pod "pod-configmaps-786b720b-503b-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 38.945994ms
Mar 26 22:53:18.616: INFO: Pod "pod-configmaps-786b720b-503b-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.064744786s
[1mSTEP[0m: Saw pod success
Mar 26 22:53:18.616: INFO: Pod "pod-configmaps-786b720b-503b-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 22:53:18.641: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-configmaps-786b720b-503b-11e9-9bdd-d050998677c2 container env-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 22:53:18.707: INFO: Waiting for pod pod-configmaps-786b720b-503b-11e9-9bdd-d050998677c2 to disappear
Mar 26 22:53:18.732: INFO: Pod pod-configmaps-786b720b-503b-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:53:18.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-secrets-ptzgl" for this suite.
Mar 26 22:53:24.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:53:25.538: INFO: namespace: e2e-tests-secrets-ptzgl, resource: bindings, ignored listing per whitelist
Mar 26 22:53:25.764: INFO: namespace e2e-tests-secrets-ptzgl deletion completed in 7.005895277s

[32mâ€¢ [SLOW TEST:10.104 seconds][0m
[sig-api-machinery] Secrets
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31[0m
  should be consumable via the environment [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] StatefulSet[0m [90m[k8s.io] Basic StatefulSet functionality [StatefulSetBasic][0m 
  [1mScaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] StatefulSet
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:53:25.765: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename statefulset
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
[1mSTEP[0m: Creating service test in namespace e2e-tests-statefulset-h7wd9
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Initializing watcher for selector baz=blah,foo=bar
[1mSTEP[0m: Creating stateful set ss in namespace e2e-tests-statefulset-h7wd9
[1mSTEP[0m: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-h7wd9
Mar 26 22:53:26.686: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Mar 26 22:53:36.712: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
[1mSTEP[0m: Confirming that stateful set scale up will halt with unhealthy stateful pod
Mar 26 22:53:36.738: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 26 22:53:37.236: INFO: stderr: ""
Mar 26 22:53:37.236: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 26 22:53:37.236: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 26 22:53:37.261: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar 26 22:53:47.288: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 26 22:53:47.288: INFO: Waiting for statefulset status.replicas updated to 0
Mar 26 22:53:47.392: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999668s
Mar 26 22:53:48.418: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.974027754s
Mar 26 22:53:49.445: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.947956337s
Mar 26 22:53:50.471: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.921466895s
Mar 26 22:53:51.497: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.895453841s
Mar 26 22:53:52.524: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.869520122s
Mar 26 22:53:53.550: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.842391603s
Mar 26 22:53:54.576: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.81626095s
Mar 26 22:53:55.603: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.790054064s
Mar 26 22:53:56.629: INFO: Verifying statefulset ss doesn't scale past 1 for another 763.42849ms
[1mSTEP[0m: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-h7wd9
Mar 26 22:53:57.656: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:53:58.143: INFO: stderr: ""
Mar 26 22:53:58.143: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 26 22:53:58.143: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 26 22:53:58.169: INFO: Found 1 stateful pods, waiting for 3
Mar 26 22:54:08.196: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 26 22:54:08.196: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 26 22:54:08.196: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
[1mSTEP[0m: Verifying that stateful set ss was scaled up in order
[1mSTEP[0m: Scale down will halt with unhealthy stateful pod
Mar 26 22:54:08.248: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 26 22:54:08.723: INFO: stderr: ""
Mar 26 22:54:08.723: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 26 22:54:08.723: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 26 22:54:08.723: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 26 22:54:09.220: INFO: stderr: ""
Mar 26 22:54:09.220: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 26 22:54:09.220: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 26 22:54:09.220: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 26 22:54:09.666: INFO: stderr: ""
Mar 26 22:54:09.666: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 26 22:54:09.666: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 26 22:54:09.666: INFO: Waiting for statefulset status.replicas updated to 0
Mar 26 22:54:09.692: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Mar 26 22:54:19.743: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 26 22:54:19.743: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar 26 22:54:19.743: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar 26 22:54:19.819: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999672s
Mar 26 22:54:20.846: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.974308495s
Mar 26 22:54:21.872: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.947888111s
Mar 26 22:54:22.904: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.921362799s
Mar 26 22:54:23.930: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.889798526s
Mar 26 22:54:24.956: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.863580322s
Mar 26 22:54:25.983: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.837219051s
Mar 26 22:54:27.009: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.810925756s
Mar 26 22:54:28.035: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.784895728s
Mar 26 22:54:29.062: INFO: Verifying statefulset ss doesn't scale past 3 for another 758.282844ms
[1mSTEP[0m: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-h7wd9
Mar 26 22:54:30.088: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:54:30.532: INFO: stderr: ""
Mar 26 22:54:30.532: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 26 22:54:30.532: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 26 22:54:30.532: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:54:31.018: INFO: stderr: ""
Mar 26 22:54:31.018: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 26 22:54:31.018: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 26 22:54:31.018: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:54:31.499: INFO: rc: 126
Mar 26 22:54:31.499: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl [kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil> cannot exec in a stopped state: unknown
 command terminated with exit code 126
 [] <nil> 0xc001b396e0 exit status 126 <nil> <nil> true [0xc000db26c8 0xc000db26e0 0xc000db26f8] [0xc000db26c8 0xc000db26e0 0xc000db26f8] [0xc000db26d8 0xc000db26f0] [0x96f2f0 0x96f2f0] 0xc00102b7a0 <nil>}:
Command stdout:
cannot exec in a stopped state: unknown

stderr:
command terminated with exit code 126

error:
exit status 126

Mar 26 22:54:41.500: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:54:41.714: INFO: rc: 1
Mar 26 22:54:41.714: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl [kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0014c2b70 exit status 1 <nil> <nil> true [0xc00175e228 0xc00175e240 0xc00175e258] [0xc00175e228 0xc00175e240 0xc00175e258] [0xc00175e238 0xc00175e250] [0x96f2f0 0x96f2f0] 0xc0030756e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar 26 22:54:51.714: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:54:51.957: INFO: rc: 1
Mar 26 22:54:51.957: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl [kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002398210 exit status 1 <nil> <nil> true [0xc000a53a90 0xc000a53ad8 0xc000a53b00] [0xc000a53a90 0xc000a53ad8 0xc000a53b00] [0xc000a53ab8 0xc000a53af8] [0x96f2f0 0x96f2f0] 0xc001429f20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar 26 22:55:01.957: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:55:02.209: INFO: rc: 1
Mar 26 22:55:02.209: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl [kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001b39aa0 exit status 1 <nil> <nil> true [0xc000db2700 0xc000db2718 0xc000db2730] [0xc000db2700 0xc000db2718 0xc000db2730] [0xc000db2710 0xc000db2728] [0x96f2f0 0x96f2f0] 0xc00102bb00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar 26 22:55:12.210: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:55:12.427: INFO: rc: 1
Mar 26 22:55:12.427: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl [kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0014c2f60 exit status 1 <nil> <nil> true [0xc00175e260 0xc00175e278 0xc00175e290] [0xc00175e260 0xc00175e278 0xc00175e290] [0xc00175e270 0xc00175e288] [0x96f2f0 0x96f2f0] 0xc003075b60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar 26 22:55:22.427: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:55:22.631: INFO: rc: 1
Mar 26 22:55:22.631: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl [kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0010fe300 exit status 1 <nil> <nil> true [0xc00083c088 0xc00083c150 0xc00083c198] [0xc00083c088 0xc00083c150 0xc00083c198] [0xc00083c130 0xc00083c180] [0x96f2f0 0x96f2f0] 0xc001afc720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar 26 22:55:32.631: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:55:32.828: INFO: rc: 1
Mar 26 22:55:32.828: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl [kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0010fe8d0 exit status 1 <nil> <nil> true [0xc00083c1c0 0xc00083c238 0xc00083c260] [0xc00083c1c0 0xc00083c238 0xc00083c260] [0xc00083c230 0xc00083c258] [0x96f2f0 0x96f2f0] 0xc001afd0e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar 26 22:55:42.828: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:55:43.036: INFO: rc: 1
Mar 26 22:55:43.036: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl [kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0021f83c0 exit status 1 <nil> <nil> true [0xc0000e0178 0xc0000e0238 0xc0000e02c8] [0xc0000e0178 0xc0000e0238 0xc0000e02c8] [0xc0000e0218 0xc0000e02b8] [0x96f2f0 0x96f2f0] 0xc0020142a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar 26 22:55:53.036: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:55:53.246: INFO: rc: 1
Mar 26 22:55:53.246: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl [kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0021f86c0 exit status 1 <nil> <nil> true [0xc0000e02e8 0xc0000e18d8 0xc0000e1938] [0xc0000e02e8 0xc0000e18d8 0xc0000e1938] [0xc0000e18d0 0xc0000e1930] [0x96f2f0 0x96f2f0] 0xc002014de0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar 26 22:56:03.246: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:56:03.443: INFO: rc: 1
Mar 26 22:56:03.443: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl [kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0007d10b0 exit status 1 <nil> <nil> true [0xc000010010 0xc000011638 0xc000011678] [0xc000010010 0xc000011638 0xc000011678] [0xc000011628 0xc000011670] [0x96f2f0 0x96f2f0] 0xc0020d46c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar 26 22:56:13.443: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:56:13.633: INFO: rc: 1
Mar 26 22:56:13.633: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl [kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000eca420 exit status 1 <nil> <nil> true [0xc000b0c000 0xc000b0c018 0xc000b0c030] [0xc000b0c000 0xc000b0c018 0xc000b0c030] [0xc000b0c010 0xc000b0c028] [0x96f2f0 0x96f2f0] 0xc0027fa240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar 26 22:56:23.633: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:56:23.820: INFO: rc: 1
Mar 26 22:56:23.820: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl [kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000eca7e0 exit status 1 <nil> <nil> true [0xc000b0c038 0xc000b0c050 0xc000b0c068] [0xc000b0c038 0xc000b0c050 0xc000b0c068] [0xc000b0c048 0xc000b0c060] [0x96f2f0 0x96f2f0] 0xc0027fa540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar 26 22:56:33.820: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:56:34.043: INFO: rc: 1
Mar 26 22:56:34.043: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl [kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0010fec60 exit status 1 <nil> <nil> true [0xc00083c268 0xc00083c2c8 0xc00083c300] [0xc00083c268 0xc00083c2c8 0xc00083c300] [0xc00083c2a8 0xc00083c2f8] [0x96f2f0 0x96f2f0] 0xc002f75440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar 26 22:56:44.044: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:56:44.245: INFO: rc: 1
Mar 26 22:56:44.245: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl [kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0021f89f0 exit status 1 <nil> <nil> true [0xc0000e1960 0xc0000e19b8 0xc0000e19f8] [0xc0000e1960 0xc0000e19b8 0xc0000e19f8] [0xc0000e19a8 0xc0000e19e8] [0x96f2f0 0x96f2f0] 0xc0020153e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar 26 22:56:54.245: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:56:54.452: INFO: rc: 1
Mar 26 22:56:54.452: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl [kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0021f8d20 exit status 1 <nil> <nil> true [0xc0000e1a08 0xc0000e1a28 0xc0000e1a48] [0xc0000e1a08 0xc0000e1a28 0xc0000e1a48] [0xc0000e1a18 0xc0000e1a40] [0x96f2f0 0x96f2f0] 0xc002015740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar 26 22:57:04.453: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:57:04.663: INFO: rc: 1
Mar 26 22:57:04.663: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl [kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0010fefc0 exit status 1 <nil> <nil> true [0xc00083c330 0xc00083c380 0xc00083c410] [0xc00083c330 0xc00083c380 0xc00083c410] [0xc00083c378 0xc00083c3e0] [0x96f2f0 0x96f2f0] 0xc002f757a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar 26 22:57:14.663: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:57:14.871: INFO: rc: 1
Mar 26 22:57:14.871: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl [kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0010ff2f0 exit status 1 <nil> <nil> true [0xc00083c420 0xc00083c498 0xc00083c558] [0xc00083c420 0xc00083c498 0xc00083c558] [0xc00083c460 0xc00083c538] [0x96f2f0 0x96f2f0] 0xc002f75aa0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar 26 22:57:24.872: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:57:25.061: INFO: rc: 1
Mar 26 22:57:25.062: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl [kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0007d10e0 exit status 1 <nil> <nil> true [0xc000011600 0xc000011658 0xc000011680] [0xc000011600 0xc000011658 0xc000011680] [0xc000011638 0xc000011678] [0x96f2f0 0x96f2f0] 0xc002f755c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar 26 22:57:35.062: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:57:35.263: INFO: rc: 1
Mar 26 22:57:35.263: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl [kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0007d1470 exit status 1 <nil> <nil> true [0xc000011698 0xc0000116c0 0xc0000e0218] [0xc000011698 0xc0000116c0 0xc0000e0218] [0xc0000116b8 0xc0000e01e8] [0x96f2f0 0x96f2f0] 0xc002f75920 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar 26 22:57:45.263: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:57:45.450: INFO: rc: 1
Mar 26 22:57:45.450: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl [kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0007d18c0 exit status 1 <nil> <nil> true [0xc0000e0238 0xc0000e02c8 0xc0000e18d0] [0xc0000e0238 0xc0000e02c8 0xc0000e18d0] [0xc0000e02b8 0xc0000e18c8] [0x96f2f0 0x96f2f0] 0xc001afc4e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar 26 22:57:55.450: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:57:55.621: INFO: rc: 1
Mar 26 22:57:55.621: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl [kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000eca450 exit status 1 <nil> <nil> true [0xc000b0c000 0xc000b0c018 0xc000b0c030] [0xc000b0c000 0xc000b0c018 0xc000b0c030] [0xc000b0c010 0xc000b0c028] [0x96f2f0 0x96f2f0] 0xc0020d4660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar 26 22:58:05.621: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:58:05.842: INFO: rc: 1
Mar 26 22:58:05.842: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl [kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0007d1ec0 exit status 1 <nil> <nil> true [0xc0000e18d8 0xc0000e1938 0xc0000e19a8] [0xc0000e18d8 0xc0000e1938 0xc0000e19a8] [0xc0000e1930 0xc0000e1998] [0x96f2f0 0x96f2f0] 0xc001afcf00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar 26 22:58:15.842: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:58:16.017: INFO: rc: 1
Mar 26 22:58:16.017: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl [kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001430330 exit status 1 <nil> <nil> true [0xc0000e19b8 0xc0000e19f8 0xc0000e1a18] [0xc0000e19b8 0xc0000e19f8 0xc0000e1a18] [0xc0000e19e8 0xc0000e1a10] [0x96f2f0 0x96f2f0] 0xc002014000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar 26 22:58:26.017: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:58:26.230: INFO: rc: 1
Mar 26 22:58:26.230: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl [kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0014306c0 exit status 1 <nil> <nil> true [0xc0000e1a28 0xc0000e1a48 0xc0000e1a70] [0xc0000e1a28 0xc0000e1a48 0xc0000e1a70] [0xc0000e1a40 0xc0000e1a68] [0x96f2f0 0x96f2f0] 0xc0020143c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar 26 22:58:36.230: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:58:36.426: INFO: rc: 1
Mar 26 22:58:36.426: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl [kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001430a50 exit status 1 <nil> <nil> true [0xc0000e1a78 0xc0000e1a90 0xc0000e1aa8] [0xc0000e1a78 0xc0000e1a90 0xc0000e1aa8] [0xc0000e1a88 0xc0000e1aa0] [0x96f2f0 0x96f2f0] 0xc002014ea0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar 26 22:58:46.426: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:58:46.635: INFO: rc: 1
Mar 26 22:58:46.635: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl [kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000eca840 exit status 1 <nil> <nil> true [0xc000b0c038 0xc000b0c050 0xc000b0c068] [0xc000b0c038 0xc000b0c050 0xc000b0c068] [0xc000b0c048 0xc000b0c060] [0x96f2f0 0x96f2f0] 0xc0020d4de0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar 26 22:58:56.635: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:58:56.824: INFO: rc: 1
Mar 26 22:58:56.824: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl [kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0021f83f0 exit status 1 <nil> <nil> true [0xc00083c038 0xc00083c130 0xc00083c180] [0xc00083c038 0xc00083c130 0xc00083c180] [0xc00083c0a0 0xc00083c168] [0x96f2f0 0x96f2f0] 0xc0027fa240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar 26 22:59:06.825: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:59:07.020: INFO: rc: 1
Mar 26 22:59:07.020: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl [kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0010fe390 exit status 1 <nil> <nil> true [0xc000a52018 0xc000a52040 0xc000a52090] [0xc000a52018 0xc000a52040 0xc000a52090] [0xc000a52038 0xc000a52050] [0x96f2f0 0x96f2f0] 0xc001f6c360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar 26 22:59:17.020: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:59:17.232: INFO: rc: 1
Mar 26 22:59:17.232: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl [kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0010fe990 exit status 1 <nil> <nil> true [0xc000a520a0 0xc000a520d0 0xc000a52148] [0xc000a520a0 0xc000a520d0 0xc000a52148] [0xc000a520c0 0xc000a52100] [0x96f2f0 0x96f2f0] 0xc001f6cd80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar 26 22:59:27.232: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:59:27.439: INFO: rc: 1
Mar 26 22:59:27.439: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl [kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0007d10b0 exit status 1 <nil> <nil> true [0xc000011600 0xc000011658 0xc000011680] [0xc000011600 0xc000011658 0xc000011680] [0xc000011638 0xc000011678] [0x96f2f0 0x96f2f0] 0xc001afc720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar 26 22:59:37.439: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-h7wd9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 22:59:37.629: INFO: rc: 1
Mar 26 22:59:37.629: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Mar 26 22:59:37.629: INFO: Scaling statefulset ss to 0
[1mSTEP[0m: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 26 22:59:37.707: INFO: Deleting all statefulset in ns e2e-tests-statefulset-h7wd9
Mar 26 22:59:37.733: INFO: Scaling statefulset ss to 0
Mar 26 22:59:37.809: INFO: Waiting for statefulset status.replicas updated to 0
Mar 26 22:59:37.835: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 22:59:37.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-statefulset-h7wd9" for this suite.
Mar 26 22:59:44.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 22:59:44.191: INFO: namespace: e2e-tests-statefulset-h7wd9, resource: bindings, ignored listing per whitelist
Mar 26 22:59:44.946: INFO: namespace e2e-tests-statefulset-h7wd9 deletion completed in 7.00732215s

[32mâ€¢ [SLOW TEST:379.181 seconds][0m
[sig-apps] StatefulSet
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Networking[0m [90mGranular Checks: Pods[0m 
  [1mshould function for intra-pod communication: udp [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-network] Networking
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 22:59:44.946: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename pod-network-test
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Performing setup for networking test in namespace e2e-tests-pod-network-test-dbxph
[1mSTEP[0m: creating a selector
[1mSTEP[0m: Creating the service pods in kubernetes
Mar 26 22:59:45.759: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[1mSTEP[0m: Creating test pods
Mar 26 23:00:04.293: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.2.232:8080/dial?request=hostName&protocol=udp&host=100.96.2.231&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-dbxph PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 23:00:04.293: INFO: >>> kubeConfig: /home/justinsb/.kube/config
Mar 26 23:00:04.578: INFO: Waiting for endpoints: map[]
Mar 26 23:00:04.604: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.2.232:8080/dial?request=hostName&protocol=udp&host=100.96.1.135&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-dbxph PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 23:00:04.604: INFO: >>> kubeConfig: /home/justinsb/.kube/config
Mar 26 23:00:04.892: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:00:04.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pod-network-test-dbxph" for this suite.
Mar 26 23:00:26.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:00:27.591: INFO: namespace: e2e-tests-pod-network-test-dbxph, resource: bindings, ignored listing per whitelist
Mar 26 23:00:27.924: INFO: namespace e2e-tests-pod-network-test-dbxph deletion completed in 23.005238969s

[32mâ€¢ [SLOW TEST:42.978 seconds][0m
[sig-network] Networking
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25[0m
  Granular Checks: Pods
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28[0m
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Secrets
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:00:27.924: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating secret with name secret-test-7a0c247d-503c-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume secrets
Mar 26 23:00:28.867: INFO: Waiting up to 5m0s for pod "pod-secrets-7a1bc18b-503c-11e9-9bdd-d050998677c2" in namespace "e2e-tests-secrets-rvpkg" to be "success or failure"
Mar 26 23:00:28.893: INFO: Pod "pod-secrets-7a1bc18b-503c-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.714582ms
Mar 26 23:00:30.919: INFO: Pod "pod-secrets-7a1bc18b-503c-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.051578889s
[1mSTEP[0m: Saw pod success
Mar 26 23:00:30.919: INFO: Pod "pod-secrets-7a1bc18b-503c-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 23:00:30.946: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-secrets-7a1bc18b-503c-11e9-9bdd-d050998677c2 container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 23:00:31.004: INFO: Waiting for pod pod-secrets-7a1bc18b-503c-11e9-9bdd-d050998677c2 to disappear
Mar 26 23:00:31.030: INFO: Pod pod-secrets-7a1bc18b-503c-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Secrets
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:00:31.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-secrets-rvpkg" for this suite.
Mar 26 23:00:37.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:00:37.384: INFO: namespace: e2e-tests-secrets-rvpkg, resource: bindings, ignored listing per whitelist
Mar 26 23:00:38.072: INFO: namespace e2e-tests-secrets-rvpkg deletion completed in 7.015770605s
[1mSTEP[0m: Destroying namespace "e2e-tests-secret-namespace-6t4kz" for this suite.
Mar 26 23:00:44.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:00:44.750: INFO: namespace: e2e-tests-secret-namespace-6t4kz, resource: bindings, ignored listing per whitelist
Mar 26 23:00:45.081: INFO: namespace e2e-tests-secret-namespace-6t4kz deletion completed in 7.00899597s

[32mâ€¢ [SLOW TEST:17.157 seconds][0m
[sig-storage] Secrets
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34[0m
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould be consumable in multiple volumes in a pod [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:00:45.081: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating secret with name projected-secret-test-84454544-503c-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume secrets
Mar 26 23:00:45.943: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-844935c2-503c-11e9-9bdd-d050998677c2" in namespace "e2e-tests-projected-55tgf" to be "success or failure"
Mar 26 23:00:45.968: INFO: Pod "pod-projected-secrets-844935c2-503c-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.15285ms
Mar 26 23:00:47.994: INFO: Pod "pod-projected-secrets-844935c2-503c-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.05114732s
[1mSTEP[0m: Saw pod success
Mar 26 23:00:47.994: INFO: Pod "pod-projected-secrets-844935c2-503c-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 23:00:48.020: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-projected-secrets-844935c2-503c-11e9-9bdd-d050998677c2 container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 23:00:48.078: INFO: Waiting for pod pod-projected-secrets-844935c2-503c-11e9-9bdd-d050998677c2 to disappear
Mar 26 23:00:48.103: INFO: Pod pod-projected-secrets-844935c2-503c-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:00:48.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-55tgf" for this suite.
Mar 26 23:00:54.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:00:54.787: INFO: namespace: e2e-tests-projected-55tgf, resource: bindings, ignored listing per whitelist
Mar 26 23:00:55.146: INFO: namespace e2e-tests-projected-55tgf deletion completed in 7.016413962s

[32mâ€¢ [SLOW TEST:10.066 seconds][0m
[sig-storage] Projected
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35[0m
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Proxy server[0m 
  [1mshould support proxy with --port 0  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:00:55.147: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: starting the proxy server
Mar 26 23:00:55.964: INFO: Asynchronously running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config proxy -p 0 --disable-filter'
[1mSTEP[0m: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:00:56.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-lcdtl" for this suite.
Mar 26 23:01:02.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:01:02.840: INFO: namespace: e2e-tests-kubectl-lcdtl, resource: bindings, ignored listing per whitelist
Mar 26 23:01:03.192: INFO: namespace e2e-tests-kubectl-lcdtl deletion completed in 7.007081213s

[32mâ€¢ [SLOW TEST:8.046 seconds][0m
[sig-cli] Kubectl client
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Proxy server
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should support proxy with --port 0  [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mshould *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Probing container
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:01:03.192: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename container-probe
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating pod liveness-http in namespace e2e-tests-container-probe-8cstz
Mar 26 23:01:06.084: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-8cstz
[1mSTEP[0m: checking the pod's current state and verifying that restartCount is present
Mar 26 23:01:06.110: INFO: Initial restart count of pod liveness-http is 0
[1mSTEP[0m: deleting the pod
[AfterEach] [k8s.io] Probing container
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:05:07.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-container-probe-8cstz" for this suite.
Mar 26 23:05:13.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:05:13.398: INFO: namespace: e2e-tests-container-probe-8cstz, resource: bindings, ignored listing per whitelist
Mar 26 23:05:14.134: INFO: namespace e2e-tests-container-probe-8cstz deletion completed in 7.014356907s

[32mâ€¢ [SLOW TEST:250.942 seconds][0m
[k8s.io] Probing container
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl version[0m 
  [1mshould check is all data is printed  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:05:14.135: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 23:05:14.954: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config version'
Mar 26 23:05:15.177: INFO: stderr: ""
Mar 26 23:05:15.177: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.0\", GitCommit:\"0ed33881dc4355495f623c6f22e7dd0b7632b7c0\", GitTreeState:\"clean\", BuildDate:\"2019-03-27T00:13:01Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.7\", GitCommit:\"6f482974b76db3f1e0f5d24605a9d1d38fad9a2b\", GitTreeState:\"clean\", BuildDate:\"2019-03-25T02:41:57Z\", GoVersion:\"go1.10.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:05:15.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-ftsbs" for this suite.
Mar 26 23:05:21.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:05:21.785: INFO: namespace: e2e-tests-kubectl-ftsbs, resource: bindings, ignored listing per whitelist
Mar 26 23:05:22.214: INFO: namespace e2e-tests-kubectl-ftsbs deletion completed in 7.010146906s

[32mâ€¢ [SLOW TEST:8.079 seconds][0m
[sig-cli] Kubectl client
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl version
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should check is all data is printed  [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] KubeletManagedEtcHosts[0m 
  [1mshould test kubelet managed /etc/hosts file [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:05:22.214: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename e2e-kubelet-etc-hosts
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Setting up the test
[1mSTEP[0m: Creating hostNetwork=false pod
[1mSTEP[0m: Creating hostNetwork=true pod
[1mSTEP[0m: Running the test
[1mSTEP[0m: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Mar 26 23:05:27.242: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-87qww PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 23:05:27.242: INFO: >>> kubeConfig: /home/justinsb/.kube/config
Mar 26 23:05:27.529: INFO: Exec stderr: ""
Mar 26 23:05:27.529: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-87qww PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 23:05:27.529: INFO: >>> kubeConfig: /home/justinsb/.kube/config
Mar 26 23:05:27.806: INFO: Exec stderr: ""
Mar 26 23:05:27.806: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-87qww PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 23:05:27.806: INFO: >>> kubeConfig: /home/justinsb/.kube/config
Mar 26 23:05:28.123: INFO: Exec stderr: ""
Mar 26 23:05:28.123: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-87qww PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 23:05:28.123: INFO: >>> kubeConfig: /home/justinsb/.kube/config
Mar 26 23:05:28.396: INFO: Exec stderr: ""
[1mSTEP[0m: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Mar 26 23:05:28.396: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-87qww PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 23:05:28.396: INFO: >>> kubeConfig: /home/justinsb/.kube/config
Mar 26 23:05:28.674: INFO: Exec stderr: ""
Mar 26 23:05:28.674: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-87qww PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 23:05:28.674: INFO: >>> kubeConfig: /home/justinsb/.kube/config
Mar 26 23:05:28.969: INFO: Exec stderr: ""
[1mSTEP[0m: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Mar 26 23:05:28.969: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-87qww PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 23:05:28.969: INFO: >>> kubeConfig: /home/justinsb/.kube/config
Mar 26 23:05:29.245: INFO: Exec stderr: ""
Mar 26 23:05:29.245: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-87qww PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 23:05:29.245: INFO: >>> kubeConfig: /home/justinsb/.kube/config
Mar 26 23:05:29.518: INFO: Exec stderr: ""
Mar 26 23:05:29.518: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-87qww PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 23:05:29.518: INFO: >>> kubeConfig: /home/justinsb/.kube/config
Mar 26 23:05:29.813: INFO: Exec stderr: ""
Mar 26 23:05:29.813: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-87qww PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 23:05:29.813: INFO: >>> kubeConfig: /home/justinsb/.kube/config
Mar 26 23:05:30.086: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:05:30.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-87qww" for this suite.
Mar 26 23:06:20.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:06:20.748: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-87qww, resource: bindings, ignored listing per whitelist
Mar 26 23:06:21.127: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-87qww deletion completed in 51.014322125s

[32mâ€¢ [SLOW TEST:58.914 seconds][0m
[k8s.io] KubeletManagedEtcHosts
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould orphan pods created by rc if delete options say so [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:06:21.128: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename gc
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: create the rc
[1mSTEP[0m: delete the rc
[1mSTEP[0m: wait for the rc to be deleted
[1mSTEP[0m: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
[1mSTEP[0m: Gathering metrics
W0326 23:07:02.135416    2026 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 26 23:07:02.135: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:07:02.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-gc-np4rp" for this suite.
Mar 26 23:07:08.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:07:08.976: INFO: namespace: e2e-tests-gc-np4rp, resource: bindings, ignored listing per whitelist
Mar 26 23:07:09.178: INFO: namespace e2e-tests-gc-np4rp deletion completed in 7.017374874s

[32mâ€¢ [SLOW TEST:48.051 seconds][0m
[sig-api-machinery] Garbage collector
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should orphan pods created by rc if delete options say so [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide podname only [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:07:09.179: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 26 23:07:10.035: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6938d5e4-503d-11e9-9bdd-d050998677c2" in namespace "e2e-tests-downward-api-s8x6r" to be "success or failure"
Mar 26 23:07:10.060: INFO: Pod "downwardapi-volume-6938d5e4-503d-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.607681ms
Mar 26 23:07:12.086: INFO: Pod "downwardapi-volume-6938d5e4-503d-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.051441433s
[1mSTEP[0m: Saw pod success
Mar 26 23:07:12.086: INFO: Pod "downwardapi-volume-6938d5e4-503d-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 23:07:12.111: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod downwardapi-volume-6938d5e4-503d-11e9-9bdd-d050998677c2 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 23:07:12.171: INFO: Waiting for pod downwardapi-volume-6938d5e4-503d-11e9-9bdd-d050998677c2 to disappear
Mar 26 23:07:12.196: INFO: Pod downwardapi-volume-6938d5e4-503d-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:07:12.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-s8x6r" for this suite.
Mar 26 23:07:18.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:07:18.423: INFO: namespace: e2e-tests-downward-api-s8x6r, resource: bindings, ignored listing per whitelist
Mar 26 23:07:19.244: INFO: namespace e2e-tests-downward-api-s8x6r deletion completed in 7.02120568s

[32mâ€¢ [SLOW TEST:10.065 seconds][0m
[sig-storage] Downward API volume
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34[0m
  should provide podname only [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould provide container's memory request [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:07:19.244: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 26 23:07:20.097: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6f383743-503d-11e9-9bdd-d050998677c2" in namespace "e2e-tests-projected-9zrwv" to be "success or failure"
Mar 26 23:07:20.123: INFO: Pod "downwardapi-volume-6f383743-503d-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.868941ms
Mar 26 23:07:22.150: INFO: Pod "downwardapi-volume-6f383743-503d-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.052614473s
[1mSTEP[0m: Saw pod success
Mar 26 23:07:22.150: INFO: Pod "downwardapi-volume-6f383743-503d-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 23:07:22.175: INFO: Trying to get logs from node ip-172-20-53-156.us-east-2.compute.internal pod downwardapi-volume-6f383743-503d-11e9-9bdd-d050998677c2 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 23:07:22.236: INFO: Waiting for pod downwardapi-volume-6f383743-503d-11e9-9bdd-d050998677c2 to disappear
Mar 26 23:07:22.262: INFO: Pod downwardapi-volume-6f383743-503d-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:07:22.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-9zrwv" for this suite.
Mar 26 23:07:28.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:07:28.818: INFO: namespace: e2e-tests-projected-9zrwv, resource: bindings, ignored listing per whitelist
Mar 26 23:07:29.301: INFO: namespace e2e-tests-projected-9zrwv deletion completed in 7.012562637s

[32mâ€¢ [SLOW TEST:10.057 seconds][0m
[sig-storage] Projected
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35[0m
  should provide container's memory request [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (non-root,0777,tmpfs) [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:07:29.301: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test emptydir 0777 on tmpfs
Mar 26 23:07:30.152: INFO: Waiting up to 5m0s for pod "pod-7536a31c-503d-11e9-9bdd-d050998677c2" in namespace "e2e-tests-emptydir-rg9g8" to be "success or failure"
Mar 26 23:07:30.178: INFO: Pod "pod-7536a31c-503d-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.704832ms
Mar 26 23:07:32.204: INFO: Pod "pod-7536a31c-503d-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.051705328s
[1mSTEP[0m: Saw pod success
Mar 26 23:07:32.204: INFO: Pod "pod-7536a31c-503d-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 23:07:32.229: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-7536a31c-503d-11e9-9bdd-d050998677c2 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 23:07:32.289: INFO: Waiting for pod pod-7536a31c-503d-11e9-9bdd-d050998677c2 to disappear
Mar 26 23:07:32.314: INFO: Pod pod-7536a31c-503d-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:07:32.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-rg9g8" for this suite.
Mar 26 23:07:38.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:07:38.794: INFO: namespace: e2e-tests-emptydir-rg9g8, resource: bindings, ignored listing per whitelist
Mar 26 23:07:39.352: INFO: namespace e2e-tests-emptydir-rg9g8 deletion completed in 7.011712065s

[32mâ€¢ [SLOW TEST:10.051 seconds][0m
[sig-storage] EmptyDir volumes
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (root,0644,default) [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:07:39.352: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test emptydir 0644 on node default medium
Mar 26 23:07:40.199: INFO: Waiting up to 5m0s for pod "pod-7b33ae1d-503d-11e9-9bdd-d050998677c2" in namespace "e2e-tests-emptydir-fqkh9" to be "success or failure"
Mar 26 23:07:40.225: INFO: Pod "pod-7b33ae1d-503d-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.409891ms
Mar 26 23:07:42.251: INFO: Pod "pod-7b33ae1d-503d-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.051672273s
[1mSTEP[0m: Saw pod success
Mar 26 23:07:42.251: INFO: Pod "pod-7b33ae1d-503d-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 23:07:42.277: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-7b33ae1d-503d-11e9-9bdd-d050998677c2 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 23:07:42.343: INFO: Waiting for pod pod-7b33ae1d-503d-11e9-9bdd-d050998677c2 to disappear
Mar 26 23:07:42.368: INFO: Pod pod-7b33ae1d-503d-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:07:42.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-fqkh9" for this suite.
Mar 26 23:07:48.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:07:49.283: INFO: namespace: e2e-tests-emptydir-fqkh9, resource: bindings, ignored listing per whitelist
Mar 26 23:07:49.411: INFO: namespace e2e-tests-emptydir-fqkh9 deletion completed in 7.016526716s

[32mâ€¢ [SLOW TEST:10.059 seconds][0m
[sig-storage] EmptyDir volumes
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (root,0644,default) [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould delete RS created by deployment when not orphaning [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:07:49.411: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename gc
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: create the deployment
[1mSTEP[0m: Wait for the Deployment to create new ReplicaSet
[1mSTEP[0m: delete the deployment
[1mSTEP[0m: wait for all rs to be garbage collected
[1mSTEP[0m: Gathering metrics
W0326 23:07:50.424546    2026 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 26 23:07:50.424: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:07:50.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-gc-jf7bk" for this suite.
Mar 26 23:07:56.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:07:57.205: INFO: namespace: e2e-tests-gc-jf7bk, resource: bindings, ignored listing per whitelist
Mar 26 23:07:57.457: INFO: namespace e2e-tests-gc-jf7bk deletion completed in 7.006457446s

[32mâ€¢ [SLOW TEST:8.046 seconds][0m
[sig-api-machinery] Garbage collector
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should delete RS created by deployment when not orphaning [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould provide container's cpu request [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:07:57.457: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 26 23:07:58.305: INFO: Waiting up to 5m0s for pod "downwardapi-volume-85fe3854-503d-11e9-9bdd-d050998677c2" in namespace "e2e-tests-projected-4r8x4" to be "success or failure"
Mar 26 23:07:58.330: INFO: Pod "downwardapi-volume-85fe3854-503d-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.239892ms
Mar 26 23:08:00.356: INFO: Pod "downwardapi-volume-85fe3854-503d-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.051194286s
[1mSTEP[0m: Saw pod success
Mar 26 23:08:00.356: INFO: Pod "downwardapi-volume-85fe3854-503d-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 23:08:00.381: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod downwardapi-volume-85fe3854-503d-11e9-9bdd-d050998677c2 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 23:08:00.441: INFO: Waiting for pod downwardapi-volume-85fe3854-503d-11e9-9bdd-d050998677c2 to disappear
Mar 26 23:08:00.467: INFO: Pod downwardapi-volume-85fe3854-503d-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:08:00.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-4r8x4" for this suite.
Mar 26 23:08:06.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:08:07.178: INFO: namespace: e2e-tests-projected-4r8x4, resource: bindings, ignored listing per whitelist
Mar 26 23:08:07.507: INFO: namespace e2e-tests-projected-4r8x4 deletion completed in 7.012876783s

[32mâ€¢ [SLOW TEST:10.050 seconds][0m
[sig-storage] Projected
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35[0m
  should provide container's cpu request [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-apps] StatefulSet[0m [90m[k8s.io] Basic StatefulSet functionality [StatefulSetBasic][0m 
  [1mShould recreate evicted statefulset [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] StatefulSet
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:08:07.507: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename statefulset
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
[1mSTEP[0m: Creating service test in namespace e2e-tests-statefulset-vj2jp
[It] Should recreate evicted statefulset [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Looking for a node to schedule stateful set and pod
[1mSTEP[0m: Creating pod with conflicting port in namespace e2e-tests-statefulset-vj2jp
[1mSTEP[0m: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-vj2jp
[1mSTEP[0m: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-vj2jp
[1mSTEP[0m: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-vj2jp
Mar 26 23:08:12.512: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-vj2jp, name: ss-0, uid: 8e4588da-503d-11e9-8eb3-023bf32bf132, status phase: Pending. Waiting for statefulset controller to delete.
Mar 26 23:08:12.765: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-vj2jp, name: ss-0, uid: 8e4588da-503d-11e9-8eb3-023bf32bf132, status phase: Failed. Waiting for statefulset controller to delete.
Mar 26 23:08:12.772: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-vj2jp, name: ss-0, uid: 8e4588da-503d-11e9-8eb3-023bf32bf132, status phase: Failed. Waiting for statefulset controller to delete.
Mar 26 23:08:12.774: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-vj2jp
[1mSTEP[0m: Removing pod with conflicting port in namespace e2e-tests-statefulset-vj2jp
[1mSTEP[0m: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-vj2jp and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 26 23:08:14.859: INFO: Deleting all statefulset in ns e2e-tests-statefulset-vj2jp
Mar 26 23:08:14.886: INFO: Scaling statefulset ss to 0
Mar 26 23:08:24.996: INFO: Waiting for statefulset status.replicas updated to 0
Mar 26 23:08:25.023: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:08:25.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-statefulset-vj2jp" for this suite.
Mar 26 23:08:31.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:08:31.611: INFO: namespace: e2e-tests-statefulset-vj2jp, resource: bindings, ignored listing per whitelist
Mar 26 23:08:32.197: INFO: namespace e2e-tests-statefulset-vj2jp deletion completed in 7.062631156s

[32mâ€¢ [SLOW TEST:24.690 seconds][0m
[sig-apps] StatefulSet
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    Should recreate evicted statefulset [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:08:32.197: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 26 23:08:33.090: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9aba0066-503d-11e9-9bdd-d050998677c2" in namespace "e2e-tests-downward-api-sl2st" to be "success or failure"
Mar 26 23:08:33.118: INFO: Pod "downwardapi-volume-9aba0066-503d-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 27.294376ms
Mar 26 23:08:35.145: INFO: Pod "downwardapi-volume-9aba0066-503d-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.054509345s
[1mSTEP[0m: Saw pod success
Mar 26 23:08:35.145: INFO: Pod "downwardapi-volume-9aba0066-503d-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 23:08:35.172: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod downwardapi-volume-9aba0066-503d-11e9-9bdd-d050998677c2 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 23:08:35.235: INFO: Waiting for pod downwardapi-volume-9aba0066-503d-11e9-9bdd-d050998677c2 to disappear
Mar 26 23:08:35.261: INFO: Pod downwardapi-volume-9aba0066-503d-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:08:35.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-sl2st" for this suite.
Mar 26 23:08:41.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:08:41.924: INFO: namespace: e2e-tests-downward-api-sl2st, resource: bindings, ignored listing per whitelist
Mar 26 23:08:42.349: INFO: namespace e2e-tests-downward-api-sl2st deletion completed in 7.059272544s

[32mâ€¢ [SLOW TEST:10.152 seconds][0m
[sig-storage] Downward API volume
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34[0m
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl run deployment[0m 
  [1mshould create a deployment from an image  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:08:42.349: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: running the image docker.io/library/nginx:1.14-alpine
Mar 26 23:08:43.212: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-5jf7z'
Mar 26 23:08:44.621: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar 26 23:08:44.621: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
[1mSTEP[0m: verifying the deployment e2e-test-nginx-deployment was created
[1mSTEP[0m: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Mar 26 23:08:46.679: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-5jf7z'
Mar 26 23:08:46.948: INFO: stderr: ""
Mar 26 23:08:46.948: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:08:46.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-5jf7z" for this suite.
Mar 26 23:09:09.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:09:09.769: INFO: namespace: e2e-tests-kubectl-5jf7z, resource: bindings, ignored listing per whitelist
Mar 26 23:09:10.039: INFO: namespace e2e-tests-kubectl-5jf7z deletion completed in 23.063255448s

[32mâ€¢ [SLOW TEST:27.690 seconds][0m
[sig-cli] Kubectl client
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl run deployment
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should create a deployment from an image  [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] ReplicaSet[0m 
  [1mshould serve a basic image on each replica with a public image  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] ReplicaSet
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:09:10.039: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename replicaset
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 23:09:10.897: INFO: Creating ReplicaSet my-hostname-basic-b1474dd8-503d-11e9-9bdd-d050998677c2
Mar 26 23:09:10.952: INFO: Pod name my-hostname-basic-b1474dd8-503d-11e9-9bdd-d050998677c2: Found 1 pods out of 1
Mar 26 23:09:10.952: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-b1474dd8-503d-11e9-9bdd-d050998677c2" is running
Mar 26 23:09:13.007: INFO: Pod "my-hostname-basic-b1474dd8-503d-11e9-9bdd-d050998677c2-dth46" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-26 23:09:10 -0400 EDT Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-26 23:09:10 -0400 EDT Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-b1474dd8-503d-11e9-9bdd-d050998677c2]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-26 23:09:10 -0400 EDT Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-b1474dd8-503d-11e9-9bdd-d050998677c2]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-26 23:09:10 -0400 EDT Reason: Message:}])
Mar 26 23:09:13.007: INFO: Trying to dial the pod
Mar 26 23:09:18.089: INFO: Controller my-hostname-basic-b1474dd8-503d-11e9-9bdd-d050998677c2: Got expected result from replica 1 [my-hostname-basic-b1474dd8-503d-11e9-9bdd-d050998677c2-dth46]: "my-hostname-basic-b1474dd8-503d-11e9-9bdd-d050998677c2-dth46", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:09:18.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-replicaset-4c27q" for this suite.
Mar 26 23:09:24.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:09:24.889: INFO: namespace: e2e-tests-replicaset-4c27q, resource: bindings, ignored listing per whitelist
Mar 26 23:09:25.183: INFO: namespace e2e-tests-replicaset-4c27q deletion completed in 7.065662524s

[32mâ€¢ [SLOW TEST:15.144 seconds][0m
[sig-apps] ReplicaSet
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  should serve a basic image on each replica with a public image  [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1moptional updates should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] ConfigMap
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:09:25.183: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name cm-test-opt-del-ba524a1e-503d-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating configMap with name cm-test-opt-upd-ba524a6c-503d-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Deleting configmap cm-test-opt-del-ba524a1e-503d-11e9-9bdd-d050998677c2
[1mSTEP[0m: Updating configmap cm-test-opt-upd-ba524a6c-503d-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating configMap with name cm-test-opt-create-ba524a90-503d-11e9-9bdd-d050998677c2
[1mSTEP[0m: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:10:49.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-dsqm4" for this suite.
Mar 26 23:11:11.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:11:12.203: INFO: namespace: e2e-tests-configmap-dsqm4, resource: bindings, ignored listing per whitelist
Mar 26 23:11:12.965: INFO: namespace e2e-tests-configmap-dsqm4 deletion completed in 23.186825664s

[32mâ€¢ [SLOW TEST:107.782 seconds][0m
[sig-storage] ConfigMap
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33[0m
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:11:12.965: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-map-fa931a4b-503d-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 26 23:11:13.926: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fa9751dd-503d-11e9-9bdd-d050998677c2" in namespace "e2e-tests-projected-77l54" to be "success or failure"
Mar 26 23:11:13.954: INFO: Pod "pod-projected-configmaps-fa9751dd-503d-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 28.091359ms
Mar 26 23:11:15.981: INFO: Pod "pod-projected-configmaps-fa9751dd-503d-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.054929018s
[1mSTEP[0m: Saw pod success
Mar 26 23:11:15.981: INFO: Pod "pod-projected-configmaps-fa9751dd-503d-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 23:11:16.008: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-projected-configmaps-fa9751dd-503d-11e9-9bdd-d050998677c2 container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 23:11:16.069: INFO: Waiting for pod pod-projected-configmaps-fa9751dd-503d-11e9-9bdd-d050998677c2 to disappear
Mar 26 23:11:16.095: INFO: Pod pod-projected-configmaps-fa9751dd-503d-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:11:16.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-77l54" for this suite.
Mar 26 23:11:22.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:11:22.333: INFO: namespace: e2e-tests-projected-77l54, resource: bindings, ignored listing per whitelist
Mar 26 23:11:23.194: INFO: namespace e2e-tests-projected-77l54 deletion completed in 7.071109005s

[32mâ€¢ [SLOW TEST:10.229 seconds][0m
[sig-storage] Projected
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35[0m
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Proxy server[0m 
  [1mshould support --unix-socket=/path  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:11:23.194: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Starting the proxy
Mar 26 23:11:24.055: INFO: Asynchronously running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config proxy --unix-socket=/tmp/kubectl-proxy-unix049920563/test'
[1mSTEP[0m: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:11:24.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-v4x6q" for this suite.
Mar 26 23:11:30.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:11:30.616: INFO: namespace: e2e-tests-kubectl-v4x6q, resource: bindings, ignored listing per whitelist
Mar 26 23:11:31.174: INFO: namespace e2e-tests-kubectl-v4x6q deletion completed in 7.035986736s

[32mâ€¢ [SLOW TEST:7.980 seconds][0m
[sig-cli] Kubectl client
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Proxy server
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should support --unix-socket=/path  [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mupdates should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] ConfigMap
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:11:31.174: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name configmap-test-upd-056bd687-503e-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Updating configmap configmap-test-upd-056bd687-503e-11e9-9bdd-d050998677c2
[1mSTEP[0m: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:11:38.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-7ptjj" for this suite.
Mar 26 23:12:00.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:12:00.857: INFO: namespace: e2e-tests-configmap-7ptjj, resource: bindings, ignored listing per whitelist
Mar 26 23:12:01.442: INFO: namespace e2e-tests-configmap-7ptjj deletion completed in 23.062678257s

[32mâ€¢ [SLOW TEST:30.268 seconds][0m
[sig-storage] ConfigMap
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33[0m
  updates should be reflected in volume [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould not be blocked by dependency circle [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:12:01.442: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename gc
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 23:12:02.413: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"177cd0ee-503e-11e9-8eb3-023bf32bf132", Controller:(*bool)(0xc003a6069e), BlockOwnerDeletion:(*bool)(0xc003a6069f)}}
Mar 26 23:12:02.440: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"17747121-503e-11e9-8eb3-023bf32bf132", Controller:(*bool)(0xc0029867ce), BlockOwnerDeletion:(*bool)(0xc0029867cf)}}
Mar 26 23:12:02.468: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"17789e6a-503e-11e9-8eb3-023bf32bf132", Controller:(*bool)(0xc0028ca19e), BlockOwnerDeletion:(*bool)(0xc0028ca19f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:12:07.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-gc-d8rtn" for this suite.
Mar 26 23:12:13.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:12:14.265: INFO: namespace: e2e-tests-gc-d8rtn, resource: bindings, ignored listing per whitelist
Mar 26 23:12:14.611: INFO: namespace e2e-tests-gc-d8rtn deletion completed in 7.061129463s

[32mâ€¢ [SLOW TEST:13.169 seconds][0m
[sig-api-machinery] Garbage collector
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should not be blocked by dependency circle [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mbinary data should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] ConfigMap
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:12:14.611: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name configmap-test-upd-1f4ee8a4-503e-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Waiting for pod with text data
[1mSTEP[0m: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:12:17.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-sp6k6" for this suite.
Mar 26 23:12:39.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:12:40.254: INFO: namespace: e2e-tests-configmap-sp6k6, resource: bindings, ignored listing per whitelist
Mar 26 23:12:40.784: INFO: namespace e2e-tests-configmap-sp6k6 deletion completed in 23.060695781s

[32mâ€¢ [SLOW TEST:26.172 seconds][0m
[sig-storage] ConfigMap
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33[0m
  binary data should be reflected in volume [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:12:40.784: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating projection with secret that has name projected-secret-test-map-2ee39bce-503e-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume secrets
Mar 26 23:12:41.694: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2ee7cb96-503e-11e9-9bdd-d050998677c2" in namespace "e2e-tests-projected-xqsc2" to be "success or failure"
Mar 26 23:12:41.720: INFO: Pod "pod-projected-secrets-2ee7cb96-503e-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 26.404724ms
Mar 26 23:12:43.747: INFO: Pod "pod-projected-secrets-2ee7cb96-503e-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.053750065s
[1mSTEP[0m: Saw pod success
Mar 26 23:12:43.748: INFO: Pod "pod-projected-secrets-2ee7cb96-503e-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 23:12:43.774: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-projected-secrets-2ee7cb96-503e-11e9-9bdd-d050998677c2 container projected-secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 23:12:43.839: INFO: Waiting for pod pod-projected-secrets-2ee7cb96-503e-11e9-9bdd-d050998677c2 to disappear
Mar 26 23:12:43.865: INFO: Pod pod-projected-secrets-2ee7cb96-503e-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:12:43.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-xqsc2" for this suite.
Mar 26 23:12:49.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:12:50.550: INFO: namespace: e2e-tests-projected-xqsc2, resource: bindings, ignored listing per whitelist
Mar 26 23:12:50.951: INFO: namespace e2e-tests-projected-xqsc2 deletion completed in 7.058223678s

[32mâ€¢ [SLOW TEST:10.167 seconds][0m
[sig-storage] Projected
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35[0m
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Proxy[0m [90mversion v1[0m 
  [1mshould proxy logs on node with explicit kubelet port using proxy subresource  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] version v1
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:12:50.951: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename proxy
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 23:12:51.862: INFO: (0) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 27.392389ms)
Mar 26 23:12:51.890: INFO: (1) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 27.794252ms)
Mar 26 23:12:51.917: INFO: (2) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 27.71496ms)
Mar 26 23:12:51.945: INFO: (3) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 27.21276ms)
Mar 26 23:12:51.973: INFO: (4) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 28.518503ms)
Mar 26 23:12:52.001: INFO: (5) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 27.56903ms)
Mar 26 23:12:52.028: INFO: (6) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 27.609349ms)
Mar 26 23:12:52.056: INFO: (7) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 27.816062ms)
Mar 26 23:12:52.084: INFO: (8) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 27.678263ms)
Mar 26 23:12:52.112: INFO: (9) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 27.676589ms)
Mar 26 23:12:52.139: INFO: (10) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 27.646899ms)
Mar 26 23:12:52.167: INFO: (11) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 27.952845ms)
Mar 26 23:12:52.195: INFO: (12) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 27.42559ms)
Mar 26 23:12:52.222: INFO: (13) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 27.366725ms)
Mar 26 23:12:52.250: INFO: (14) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 27.593413ms)
Mar 26 23:12:52.277: INFO: (15) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 27.520545ms)
Mar 26 23:12:52.305: INFO: (16) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 27.376413ms)
Mar 26 23:12:52.332: INFO: (17) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 27.668017ms)
Mar 26 23:12:52.360: INFO: (18) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 27.510889ms)
Mar 26 23:12:52.389: INFO: (19) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 28.831973ms)
[AfterEach] version v1
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:12:52.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-proxy-mnbb2" for this suite.
Mar 26 23:12:58.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:12:58.892: INFO: namespace: e2e-tests-proxy-mnbb2, resource: bindings, ignored listing per whitelist
Mar 26 23:12:59.473: INFO: namespace e2e-tests-proxy-mnbb2 deletion completed in 7.056265303s

[32mâ€¢ [SLOW TEST:8.521 seconds][0m
[sig-network] Proxy
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22[0m
  version v1
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56[0m
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be consumable from pods in volume [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Secrets
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:12:59.473: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating secret with name secret-test-3a08bde8-503e-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume secrets
Mar 26 23:13:00.392: INFO: Waiting up to 5m0s for pod "pod-secrets-3a0cd171-503e-11e9-9bdd-d050998677c2" in namespace "e2e-tests-secrets-c944m" to be "success or failure"
Mar 26 23:13:00.418: INFO: Pod "pod-secrets-3a0cd171-503e-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 26.448348ms
Mar 26 23:13:02.445: INFO: Pod "pod-secrets-3a0cd171-503e-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.053280132s
[1mSTEP[0m: Saw pod success
Mar 26 23:13:02.445: INFO: Pod "pod-secrets-3a0cd171-503e-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 23:13:02.472: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-secrets-3a0cd171-503e-11e9-9bdd-d050998677c2 container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 23:13:02.534: INFO: Waiting for pod pod-secrets-3a0cd171-503e-11e9-9bdd-d050998677c2 to disappear
Mar 26 23:13:02.560: INFO: Pod pod-secrets-3a0cd171-503e-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Secrets
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:13:02.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-secrets-c944m" for this suite.
Mar 26 23:13:08.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:13:09.065: INFO: namespace: e2e-tests-secrets-c944m, resource: bindings, ignored listing per whitelist
Mar 26 23:13:09.645: INFO: namespace e2e-tests-secrets-c944m deletion completed in 7.057626856s

[32mâ€¢ [SLOW TEST:10.173 seconds][0m
[sig-storage] Secrets
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34[0m
  should be consumable from pods in volume [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Container Lifecycle Hook[0m [90mwhen create a pod with lifecycle hook[0m 
  [1mshould execute prestop http hook properly [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:13:09.646: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename container-lifecycle-hook
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
[1mSTEP[0m: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: create the pod with lifecycle hook
[1mSTEP[0m: delete the pod with lifecycle hook
Mar 26 23:13:14.757: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 26 23:13:14.784: INFO: Pod pod-with-prestop-http-hook still exists
Mar 26 23:13:16.784: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 26 23:13:16.811: INFO: Pod pod-with-prestop-http-hook still exists
Mar 26 23:13:18.784: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 26 23:13:18.811: INFO: Pod pod-with-prestop-http-hook still exists
Mar 26 23:13:20.784: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 26 23:13:20.811: INFO: Pod pod-with-prestop-http-hook no longer exists
[1mSTEP[0m: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:13:20.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-container-lifecycle-hook-g7ghp" for this suite.
Mar 26 23:13:42.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:13:43.468: INFO: namespace: e2e-tests-container-lifecycle-hook-g7ghp, resource: bindings, ignored listing per whitelist
Mar 26 23:13:43.905: INFO: namespace e2e-tests-container-lifecycle-hook-g7ghp deletion completed in 23.034416166s

[32mâ€¢ [SLOW TEST:34.259 seconds][0m
[k8s.io] Container Lifecycle Hook
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  when create a pod with lifecycle hook
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40[0m
    should execute prestop http hook properly [NodeConformance] [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Proxy[0m [90mversion v1[0m 
  [1mshould proxy logs on node using proxy subresource  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] version v1
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:13:43.905: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename proxy
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 23:13:44.778: INFO: (0) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 26.517883ms)
Mar 26 23:13:44.805: INFO: (1) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 26.601051ms)
Mar 26 23:13:44.831: INFO: (2) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 26.776728ms)
Mar 26 23:13:44.858: INFO: (3) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 26.162256ms)
Mar 26 23:13:44.884: INFO: (4) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 26.511926ms)
Mar 26 23:13:44.911: INFO: (5) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 26.526338ms)
Mar 26 23:13:44.937: INFO: (6) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 26.177427ms)
Mar 26 23:13:44.963: INFO: (7) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 26.113245ms)
Mar 26 23:13:44.990: INFO: (8) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 26.570495ms)
Mar 26 23:13:45.017: INFO: (9) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 26.964576ms)
Mar 26 23:13:45.043: INFO: (10) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 26.765313ms)
Mar 26 23:13:45.070: INFO: (11) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 26.923519ms)
Mar 26 23:13:45.097: INFO: (12) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 26.557477ms)
Mar 26 23:13:45.124: INFO: (13) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 26.628167ms)
Mar 26 23:13:45.151: INFO: (14) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 27.561418ms)
Mar 26 23:13:45.178: INFO: (15) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 26.702126ms)
Mar 26 23:13:45.205: INFO: (16) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 26.560896ms)
Mar 26 23:13:45.231: INFO: (17) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 26.759046ms)
Mar 26 23:13:45.258: INFO: (18) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 26.693078ms)
Mar 26 23:13:45.284: INFO: (19) /api/v1/nodes/ip-172-20-53-156.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 26.425184ms)
[AfterEach] version v1
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:13:45.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-proxy-f4nq4" for this suite.
Mar 26 23:13:51.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:13:51.525: INFO: namespace: e2e-tests-proxy-f4nq4, resource: bindings, ignored listing per whitelist
Mar 26 23:13:52.346: INFO: namespace e2e-tests-proxy-f4nq4 deletion completed in 7.034645228s

[32mâ€¢ [SLOW TEST:8.441 seconds][0m
[sig-network] Proxy
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22[0m
  version v1
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56[0m
    should proxy logs on node using proxy subresource  [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (non-root,0666,tmpfs) [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:13:52.346: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test emptydir 0666 on tmpfs
Mar 26 23:13:53.197: INFO: Waiting up to 5m0s for pod "pod-59866887-503e-11e9-9bdd-d050998677c2" in namespace "e2e-tests-emptydir-74jjv" to be "success or failure"
Mar 26 23:13:53.224: INFO: Pod "pod-59866887-503e-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 26.519287ms
Mar 26 23:13:55.250: INFO: Pod "pod-59866887-503e-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.052565891s
[1mSTEP[0m: Saw pod success
Mar 26 23:13:55.250: INFO: Pod "pod-59866887-503e-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 23:13:55.275: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-59866887-503e-11e9-9bdd-d050998677c2 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 23:13:55.338: INFO: Waiting for pod pod-59866887-503e-11e9-9bdd-d050998677c2 to disappear
Mar 26 23:13:55.364: INFO: Pod pod-59866887-503e-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:13:55.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-74jjv" for this suite.
Mar 26 23:14:01.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:14:01.696: INFO: namespace: e2e-tests-emptydir-74jjv, resource: bindings, ignored listing per whitelist
Mar 26 23:14:02.406: INFO: namespace e2e-tests-emptydir-74jjv deletion completed in 7.01563676s

[32mâ€¢ [SLOW TEST:10.060 seconds][0m
[sig-storage] EmptyDir volumes
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould update labels on modification [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:14:02.407: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating the pod
Mar 26 23:14:05.925: INFO: Successfully updated pod "labelsupdate5f86e7af-503e-11e9-9bdd-d050998677c2"
[AfterEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:14:10.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-t8rlj" for this suite.
Mar 26 23:14:32.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:14:32.575: INFO: namespace: e2e-tests-projected-t8rlj, resource: bindings, ignored listing per whitelist
Mar 26 23:14:33.059: INFO: namespace e2e-tests-projected-t8rlj deletion completed in 23.018177162s

[32mâ€¢ [SLOW TEST:30.653 seconds][0m
[sig-storage] Projected
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35[0m
  should update labels on modification [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Services[0m 
  [1mshould serve multiport endpoints from pods  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-network] Services
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:14:33.059: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename services
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating service multi-endpoint-test in namespace e2e-tests-services-hcfxc
[1mSTEP[0m: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-hcfxc to expose endpoints map[]
Mar 26 23:14:33.934: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-hcfxc exposes endpoints map[] (25.586307ms elapsed)
[1mSTEP[0m: Creating pod pod1 in namespace e2e-tests-services-hcfxc
[1mSTEP[0m: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-hcfxc to expose endpoints map[pod1:[100]]
Mar 26 23:14:35.064: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-hcfxc exposes endpoints map[pod1:[100]] (1.101975528s elapsed)
[1mSTEP[0m: Creating pod pod2 in namespace e2e-tests-services-hcfxc
[1mSTEP[0m: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-hcfxc to expose endpoints map[pod1:[100] pod2:[101]]
Mar 26 23:14:37.322: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-hcfxc exposes endpoints map[pod1:[100] pod2:[101]] (2.231355142s elapsed)
[1mSTEP[0m: Deleting pod pod1 in namespace e2e-tests-services-hcfxc
[1mSTEP[0m: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-hcfxc to expose endpoints map[pod2:[101]]
Mar 26 23:14:37.402: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-hcfxc exposes endpoints map[pod2:[101]] (50.465725ms elapsed)
[1mSTEP[0m: Deleting pod pod2 in namespace e2e-tests-services-hcfxc
[1mSTEP[0m: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-hcfxc to expose endpoints map[]
Mar 26 23:14:37.455: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-hcfxc exposes endpoints map[] (26.262381ms elapsed)
[AfterEach] [sig-network] Services
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:14:37.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-services-hcfxc" for this suite.
Mar 26 23:14:43.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:14:43.857: INFO: namespace: e2e-tests-services-hcfxc, resource: bindings, ignored listing per whitelist
Mar 26 23:14:44.544: INFO: namespace e2e-tests-services-hcfxc deletion completed in 7.022684528s
[AfterEach] [sig-network] Services
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

[32mâ€¢ [SLOW TEST:11.484 seconds][0m
[sig-network] Services
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22[0m
  should serve multiport endpoints from pods  [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable in multiple volumes in the same pod [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] ConfigMap
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:14:44.544: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name configmap-test-volume-78a1815e-503e-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 26 23:14:45.409: INFO: Waiting up to 5m0s for pod "pod-configmaps-78a57fa5-503e-11e9-9bdd-d050998677c2" in namespace "e2e-tests-configmap-2lvhf" to be "success or failure"
Mar 26 23:14:45.434: INFO: Pod "pod-configmaps-78a57fa5-503e-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.154626ms
Mar 26 23:14:47.460: INFO: Pod "pod-configmaps-78a57fa5-503e-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.051215706s
[1mSTEP[0m: Saw pod success
Mar 26 23:14:47.460: INFO: Pod "pod-configmaps-78a57fa5-503e-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 23:14:47.486: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-configmaps-78a57fa5-503e-11e9-9bdd-d050998677c2 container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 23:14:47.545: INFO: Waiting for pod pod-configmaps-78a57fa5-503e-11e9-9bdd-d050998677c2 to disappear
Mar 26 23:14:47.571: INFO: Pod pod-configmaps-78a57fa5-503e-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:14:47.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-2lvhf" for this suite.
Mar 26 23:14:53.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:14:54.278: INFO: namespace: e2e-tests-configmap-2lvhf, resource: bindings, ignored listing per whitelist
Mar 26 23:14:54.610: INFO: namespace e2e-tests-configmap-2lvhf deletion completed in 7.013273295s

[32mâ€¢ [SLOW TEST:10.067 seconds][0m
[sig-storage] ConfigMap
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33[0m
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be consumable from pods in volume with mappings [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Secrets
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:14:54.610: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating secret with name secret-test-map-7ea26815-503e-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume secrets
Mar 26 23:14:55.488: INFO: Waiting up to 5m0s for pod "pod-secrets-7ea76621-503e-11e9-9bdd-d050998677c2" in namespace "e2e-tests-secrets-lc5g7" to be "success or failure"
Mar 26 23:14:55.514: INFO: Pod "pod-secrets-7ea76621-503e-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 26.25024ms
Mar 26 23:14:57.540: INFO: Pod "pod-secrets-7ea76621-503e-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.052301947s
[1mSTEP[0m: Saw pod success
Mar 26 23:14:57.540: INFO: Pod "pod-secrets-7ea76621-503e-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 23:14:57.566: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-secrets-7ea76621-503e-11e9-9bdd-d050998677c2 container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 23:14:57.627: INFO: Waiting for pod pod-secrets-7ea76621-503e-11e9-9bdd-d050998677c2 to disappear
Mar 26 23:14:57.653: INFO: Pod pod-secrets-7ea76621-503e-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Secrets
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:14:57.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-secrets-lc5g7" for this suite.
Mar 26 23:15:03.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:15:04.617: INFO: namespace: e2e-tests-secrets-lc5g7, resource: bindings, ignored listing per whitelist
Mar 26 23:15:04.693: INFO: namespace e2e-tests-secrets-lc5g7 deletion completed in 7.013594109s

[32mâ€¢ [SLOW TEST:10.082 seconds][0m
[sig-storage] Secrets
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34[0m
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] StatefulSet[0m [90m[k8s.io] Basic StatefulSet functionality [StatefulSetBasic][0m 
  [1mshould perform canary updates and phased rolling updates of template modifications [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] StatefulSet
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:15:04.693: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename statefulset
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
[1mSTEP[0m: Creating service test in namespace e2e-tests-statefulset-bt628
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a new StaefulSet
Mar 26 23:15:05.591: INFO: Found 1 stateful pods, waiting for 3
Mar 26 23:15:15.618: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 26 23:15:15.618: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 26 23:15:15.618: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
[1mSTEP[0m: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar 26 23:15:15.757: INFO: Updating stateful set ss2
[1mSTEP[0m: Creating a new revision
[1mSTEP[0m: Not applying an update when the partition is greater than the number of replicas
[1mSTEP[0m: Performing a canary update
Mar 26 23:15:15.870: INFO: Updating stateful set ss2
Mar 26 23:15:15.921: INFO: Waiting for Pod e2e-tests-statefulset-bt628/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
[1mSTEP[0m: Restoring Pods to the correct revision when they are deleted
Mar 26 23:15:26.072: INFO: Found 2 stateful pods, waiting for 3
Mar 26 23:15:36.098: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 26 23:15:36.098: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 26 23:15:36.098: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
[1mSTEP[0m: Performing a phased rolling update
Mar 26 23:15:36.214: INFO: Updating stateful set ss2
Mar 26 23:15:36.267: INFO: Waiting for Pod e2e-tests-statefulset-bt628/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 26 23:15:46.319: INFO: Waiting for Pod e2e-tests-statefulset-bt628/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 26 23:15:56.381: INFO: Updating stateful set ss2
Mar 26 23:15:56.432: INFO: Waiting for StatefulSet e2e-tests-statefulset-bt628/ss2 to complete update
Mar 26 23:15:56.432: INFO: Waiting for Pod e2e-tests-statefulset-bt628/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 26 23:16:06.485: INFO: Deleting all statefulset in ns e2e-tests-statefulset-bt628
Mar 26 23:16:06.511: INFO: Scaling statefulset ss2 to 0
Mar 26 23:16:36.622: INFO: Waiting for statefulset status.replicas updated to 0
Mar 26 23:16:36.647: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:16:36.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-statefulset-bt628" for this suite.
Mar 26 23:16:42.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:16:43.363: INFO: namespace: e2e-tests-statefulset-bt628, resource: bindings, ignored listing per whitelist
Mar 26 23:16:43.769: INFO: namespace e2e-tests-statefulset-bt628 deletion completed in 7.016879023s

[32mâ€¢ [SLOW TEST:99.077 seconds][0m
[sig-apps] StatefulSet
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Container Lifecycle Hook[0m [90mwhen create a pod with lifecycle hook[0m 
  [1mshould execute poststart exec hook properly [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:16:43.770: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename container-lifecycle-hook
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
[1mSTEP[0m: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: create the pod with lifecycle hook
[1mSTEP[0m: check poststart hook
[1mSTEP[0m: delete the pod with lifecycle hook
Mar 26 23:16:48.859: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 26 23:16:48.885: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 26 23:16:50.885: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 26 23:16:50.911: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 26 23:16:52.885: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 26 23:16:52.911: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 26 23:16:54.885: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 26 23:16:54.911: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 26 23:16:56.885: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 26 23:16:56.911: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 26 23:16:58.885: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 26 23:16:58.911: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 26 23:17:00.885: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 26 23:17:00.911: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 26 23:17:02.885: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 26 23:17:02.911: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 26 23:17:04.885: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 26 23:17:04.912: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 26 23:17:06.885: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 26 23:17:06.911: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 26 23:17:08.885: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 26 23:17:08.911: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:17:08.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-container-lifecycle-hook-tc9w2" for this suite.
Mar 26 23:17:31.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:17:31.191: INFO: namespace: e2e-tests-container-lifecycle-hook-tc9w2, resource: bindings, ignored listing per whitelist
Mar 26 23:17:31.955: INFO: namespace e2e-tests-container-lifecycle-hook-tc9w2 deletion completed in 23.0172375s

[32mâ€¢ [SLOW TEST:48.186 seconds][0m
[k8s.io] Container Lifecycle Hook
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  when create a pod with lifecycle hook
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40[0m
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Variable Expansion[0m 
  [1mshould allow substituting values in a container's command [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Variable Expansion
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:17:31.956: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename var-expansion
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test substitution in container's command
Mar 26 23:17:32.813: INFO: Waiting up to 5m0s for pod "var-expansion-dc6d4b67-503e-11e9-9bdd-d050998677c2" in namespace "e2e-tests-var-expansion-gzrmr" to be "success or failure"
Mar 26 23:17:32.838: INFO: Pod "var-expansion-dc6d4b67-503e-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.799399ms
Mar 26 23:17:34.865: INFO: Pod "var-expansion-dc6d4b67-503e-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.052412s
[1mSTEP[0m: Saw pod success
Mar 26 23:17:34.865: INFO: Pod "var-expansion-dc6d4b67-503e-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 23:17:34.891: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod var-expansion-dc6d4b67-503e-11e9-9bdd-d050998677c2 container dapi-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 23:17:34.950: INFO: Waiting for pod var-expansion-dc6d4b67-503e-11e9-9bdd-d050998677c2 to disappear
Mar 26 23:17:34.976: INFO: Pod var-expansion-dc6d4b67-503e-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:17:34.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-var-expansion-gzrmr" for this suite.
Mar 26 23:17:41.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:17:41.516: INFO: namespace: e2e-tests-var-expansion-gzrmr, resource: bindings, ignored listing per whitelist
Mar 26 23:17:42.033: INFO: namespace e2e-tests-var-expansion-gzrmr deletion completed in 7.028294439s

[32mâ€¢ [SLOW TEST:10.077 seconds][0m
[k8s.io] Variable Expansion
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] DNS[0m 
  [1mshould provide DNS for the cluster  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-network] DNS
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:17:42.033: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename dns
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-scqwl.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-scqwl.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-scqwl.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

[1mSTEP[0m: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-scqwl.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-scqwl.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-scqwl.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

[1mSTEP[0m: creating a pod to probe DNS
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: retrieving the pod
[1mSTEP[0m: looking for the results for each expected name from probers
Mar 26 23:17:55.488: INFO: DNS probes using e2e-tests-dns-scqwl/dns-test-e26dab50-503e-11e9-9bdd-d050998677c2 succeeded

[1mSTEP[0m: deleting the pod
[AfterEach] [sig-network] DNS
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:17:55.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-dns-scqwl" for this suite.
Mar 26 23:18:01.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:18:02.002: INFO: namespace: e2e-tests-dns-scqwl, resource: bindings, ignored listing per whitelist
Mar 26 23:18:02.562: INFO: namespace e2e-tests-dns-scqwl deletion completed in 7.016308708s

[32mâ€¢ [SLOW TEST:20.529 seconds][0m
[sig-network] DNS
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22[0m
  should provide DNS for the cluster  [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:18:02.562: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
Mar 26 23:18:03.407: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eea982de-503e-11e9-9bdd-d050998677c2" in namespace "e2e-tests-downward-api-622fg" to be "success or failure"
Mar 26 23:18:03.432: INFO: Pod "downwardapi-volume-eea982de-503e-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.67443ms
Mar 26 23:18:05.459: INFO: Pod "downwardapi-volume-eea982de-503e-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.052004817s
[1mSTEP[0m: Saw pod success
Mar 26 23:18:05.459: INFO: Pod "downwardapi-volume-eea982de-503e-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 23:18:05.484: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod downwardapi-volume-eea982de-503e-11e9-9bdd-d050998677c2 container client-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 23:18:05.555: INFO: Waiting for pod downwardapi-volume-eea982de-503e-11e9-9bdd-d050998677c2 to disappear
Mar 26 23:18:05.580: INFO: Pod downwardapi-volume-eea982de-503e-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:18:05.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-622fg" for this suite.
Mar 26 23:18:11.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:18:11.782: INFO: namespace: e2e-tests-downward-api-622fg, resource: bindings, ignored listing per whitelist
Mar 26 23:18:12.629: INFO: namespace e2e-tests-downward-api-622fg deletion completed in 7.023036224s

[32mâ€¢ [SLOW TEST:10.067 seconds][0m
[sig-storage] Downward API volume
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34[0m
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Deployment[0m 
  [1mdeployment should support proportional scaling [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] Deployment
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:18:12.630: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename deployment
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 23:18:13.453: INFO: Creating deployment "nginx-deployment"
Mar 26 23:18:13.481: INFO: Waiting for observed generation 1
Mar 26 23:18:13.520: INFO: Waiting for all required pods to come up
Mar 26 23:18:13.555: INFO: Pod name nginx: Found 10 pods out of 10
[1mSTEP[0m: ensuring each pod is running
Mar 26 23:18:19.614: INFO: Waiting for deployment "nginx-deployment" to complete
Mar 26 23:18:19.665: INFO: Updating deployment "nginx-deployment" with a non-existent image
Mar 26 23:18:19.717: INFO: Updating deployment nginx-deployment
Mar 26 23:18:19.717: INFO: Waiting for observed generation 2
Mar 26 23:18:21.775: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Mar 26 23:18:21.800: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Mar 26 23:18:21.825: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar 26 23:18:21.901: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Mar 26 23:18:21.901: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Mar 26 23:18:21.929: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar 26 23:18:21.988: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Mar 26 23:18:21.988: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Mar 26 23:18:22.041: INFO: Updating deployment nginx-deployment
Mar 26 23:18:22.041: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Mar 26 23:18:22.098: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Mar 26 23:18:24.163: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 26 23:18:24.216: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-j6t47,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-j6t47/deployments/nginx-deployment,UID:f4ad89c5-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28539,Generation:3,CreationTimestamp:2019-03-26 23:18:13 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-03-26 23:18:22 -0400 EDT 2019-03-26 23:18:22 -0400 EDT MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-03-26 23:18:22 -0400 EDT 2019-03-26 23:18:13 -0400 EDT ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Mar 26 23:18:24.242: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-j6t47,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-j6t47/replicasets/nginx-deployment-7dc8f79789,UID:f8658c67-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28537,Generation:3,CreationTimestamp:2019-03-26 23:18:19 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment f4ad89c5-503e-11e9-8eb3-023bf32bf132 0xc00269d497 0xc00269d498}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 26 23:18:24.242: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Mar 26 23:18:24.242: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-j6t47,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-j6t47/replicasets/nginx-deployment-7f9675fb8b,UID:f4ae8f3b-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28538,Generation:3,CreationTimestamp:2019-03-26 23:18:13 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment f4ad89c5-503e-11e9-8eb3-023bf32bf132 0xc00269d557 0xc00269d558}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Mar 26 23:18:24.273: INFO: Pod "nginx-deployment-7dc8f79789-2g4gv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-2g4gv,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7dc8f79789-2g4gv,UID:f86d4e28-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28485,Generation:0,CreationTimestamp:2019-03-26 23:18:19 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f8658c67-503e-11e9-8eb3-023bf32bf132 0xc0024ffc17 0xc0024ffc18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-53-156.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024ffc80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024ffca0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:19 -0400 EDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:19 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:19 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:19 -0400 EDT  }],Message:,Reason:,HostIP:172.20.53.156,PodIP:100.96.1.154,StartTime:2019-03-26 23:18:19 -0400 EDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.273: INFO: Pod "nginx-deployment-7dc8f79789-4txvt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-4txvt,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7dc8f79789-4txvt,UID:f9d3a512-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28530,Generation:0,CreationTimestamp:2019-03-26 23:18:22 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f8658c67-503e-11e9-8eb3-023bf32bf132 0xc0024ffd90 0xc0024ffd91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-56-226.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024ffe00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024ffe20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.273: INFO: Pod "nginx-deployment-7dc8f79789-57clw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-57clw,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7dc8f79789-57clw,UID:f8670bd5-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28484,Generation:0,CreationTimestamp:2019-03-26 23:18:19 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f8658c67-503e-11e9-8eb3-023bf32bf132 0xc0024ffe90 0xc0024ffe91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-53-156.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024fff00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bd6000}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:19 -0400 EDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:19 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:19 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:19 -0400 EDT  }],Message:,Reason:,HostIP:172.20.53.156,PodIP:100.96.1.153,StartTime:2019-03-26 23:18:19 -0400 EDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.273: INFO: Pod "nginx-deployment-7dc8f79789-9p28j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-9p28j,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7dc8f79789-9p28j,UID:f9d0bc00-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28524,Generation:0,CreationTimestamp:2019-03-26 23:18:22 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f8658c67-503e-11e9-8eb3-023bf32bf132 0xc001bd6400 0xc001bd6401}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-56-226.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bd6470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bd6490}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.273: INFO: Pod "nginx-deployment-7dc8f79789-bbb77" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-bbb77,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7dc8f79789-bbb77,UID:f9cf4fa7-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28546,Generation:0,CreationTimestamp:2019-03-26 23:18:22 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f8658c67-503e-11e9-8eb3-023bf32bf132 0xc001bd6500 0xc001bd6501}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-53-156.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bd65d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bd65f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT  }],Message:,Reason:,HostIP:172.20.53.156,PodIP:,StartTime:2019-03-26 23:18:22 -0400 EDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.273: INFO: Pod "nginx-deployment-7dc8f79789-cmnxq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-cmnxq,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7dc8f79789-cmnxq,UID:f865e995-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28483,Generation:0,CreationTimestamp:2019-03-26 23:18:19 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f8658c67-503e-11e9-8eb3-023bf32bf132 0xc001bd6740 0xc001bd6741}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-56-226.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bd67b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bd67d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:19 -0400 EDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:19 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:19 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:19 -0400 EDT  }],Message:,Reason:,HostIP:172.20.56.226,PodIP:100.96.2.38,StartTime:2019-03-26 23:18:19 -0400 EDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.273: INFO: Pod "nginx-deployment-7dc8f79789-cwkfv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-cwkfv,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7dc8f79789-cwkfv,UID:f9c95ec3-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28526,Generation:0,CreationTimestamp:2019-03-26 23:18:22 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f8658c67-503e-11e9-8eb3-023bf32bf132 0xc001bd6920 0xc001bd6921}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-53-156.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bd6a00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bd6a20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT  }],Message:,Reason:,HostIP:172.20.53.156,PodIP:,StartTime:2019-03-26 23:18:22 -0400 EDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.273: INFO: Pod "nginx-deployment-7dc8f79789-f6rvb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-f6rvb,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7dc8f79789-f6rvb,UID:f9cc46e8-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28547,Generation:0,CreationTimestamp:2019-03-26 23:18:22 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f8658c67-503e-11e9-8eb3-023bf32bf132 0xc001bd6b90 0xc001bd6b91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-56-226.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bd6c00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bd6d40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT  }],Message:,Reason:,HostIP:172.20.56.226,PodIP:,StartTime:2019-03-26 23:18:22 -0400 EDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.274: INFO: Pod "nginx-deployment-7dc8f79789-fcgzh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-fcgzh,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7dc8f79789-fcgzh,UID:f86f5613-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28480,Generation:0,CreationTimestamp:2019-03-26 23:18:19 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f8658c67-503e-11e9-8eb3-023bf32bf132 0xc001bd6e00 0xc001bd6e01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-56-226.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bd6fc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bd7050}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:19 -0400 EDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:19 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:19 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:19 -0400 EDT  }],Message:,Reason:,HostIP:172.20.56.226,PodIP:,StartTime:2019-03-26 23:18:19 -0400 EDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.274: INFO: Pod "nginx-deployment-7dc8f79789-ll5vt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-ll5vt,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7dc8f79789-ll5vt,UID:f9d03acc-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28517,Generation:0,CreationTimestamp:2019-03-26 23:18:22 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f8658c67-503e-11e9-8eb3-023bf32bf132 0xc001bd7250 0xc001bd7251}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-56-226.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bd72d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bd73f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.274: INFO: Pod "nginx-deployment-7dc8f79789-pw75z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-pw75z,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7dc8f79789-pw75z,UID:f8672ba3-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28486,Generation:0,CreationTimestamp:2019-03-26 23:18:19 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f8658c67-503e-11e9-8eb3-023bf32bf132 0xc001bd7460 0xc001bd7461}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-56-226.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bd74d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bd74f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:19 -0400 EDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:19 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:19 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:19 -0400 EDT  }],Message:,Reason:,HostIP:172.20.56.226,PodIP:100.96.2.39,StartTime:2019-03-26 23:18:19 -0400 EDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.274: INFO: Pod "nginx-deployment-7dc8f79789-qzbfj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-qzbfj,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7dc8f79789-qzbfj,UID:f9d07f2b-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28519,Generation:0,CreationTimestamp:2019-03-26 23:18:22 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f8658c67-503e-11e9-8eb3-023bf32bf132 0xc001bd7660 0xc001bd7661}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-53-156.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bd76d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bd76f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.274: INFO: Pod "nginx-deployment-7dc8f79789-xg7fm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-xg7fm,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7dc8f79789-xg7fm,UID:f9cc421e-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28543,Generation:0,CreationTimestamp:2019-03-26 23:18:22 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f8658c67-503e-11e9-8eb3-023bf32bf132 0xc001bd7760 0xc001bd7761}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-53-156.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bd77d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bd77f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT  }],Message:,Reason:,HostIP:172.20.53.156,PodIP:,StartTime:2019-03-26 23:18:22 -0400 EDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.274: INFO: Pod "nginx-deployment-7f9675fb8b-6826f" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-6826f,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7f9675fb8b-6826f,UID:f4b44b39-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28424,Generation:0,CreationTimestamp:2019-03-26 23:18:13 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4ae8f3b-503e-11e9-8eb3-023bf32bf132 0xc001bd78b0 0xc001bd78b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-56-226.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bd7910} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bd7930}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:13 -0400 EDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:15 -0400 EDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:15 -0400 EDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:13 -0400 EDT  }],Message:,Reason:,HostIP:172.20.56.226,PodIP:100.96.2.36,StartTime:2019-03-26 23:18:13 -0400 EDT,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-26 23:18:15 -0400 EDT,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://2e4e8f9cb7a5dfdd132709bcc8a347e14e0146286143d13d17025ea6ab0944d5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.274: INFO: Pod "nginx-deployment-7f9675fb8b-6r8h4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-6r8h4,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7f9675fb8b-6r8h4,UID:f9cc0e13-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28544,Generation:0,CreationTimestamp:2019-03-26 23:18:22 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4ae8f3b-503e-11e9-8eb3-023bf32bf132 0xc001bd79f0 0xc001bd79f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-56-226.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bd7a50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bd7a70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT  }],Message:,Reason:,HostIP:172.20.56.226,PodIP:,StartTime:2019-03-26 23:18:22 -0400 EDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.274: INFO: Pod "nginx-deployment-7f9675fb8b-ctz79" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-ctz79,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7f9675fb8b-ctz79,UID:f9d39fb7-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28529,Generation:0,CreationTimestamp:2019-03-26 23:18:22 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4ae8f3b-503e-11e9-8eb3-023bf32bf132 0xc001bd7b27 0xc001bd7b28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-53-156.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bd7ba0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bd7bc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.274: INFO: Pod "nginx-deployment-7f9675fb8b-ggwrv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-ggwrv,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7f9675fb8b-ggwrv,UID:f9cf97a1-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28516,Generation:0,CreationTimestamp:2019-03-26 23:18:22 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4ae8f3b-503e-11e9-8eb3-023bf32bf132 0xc001bd7c30 0xc001bd7c31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-56-226.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bd7fa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bd7fc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.274: INFO: Pod "nginx-deployment-7f9675fb8b-gmpc4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-gmpc4,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7f9675fb8b-gmpc4,UID:f4b41390-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28411,Generation:0,CreationTimestamp:2019-03-26 23:18:13 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4ae8f3b-503e-11e9-8eb3-023bf32bf132 0xc0004cb1c0 0xc0004cb1c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-56-226.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0004cb250} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0004cb900}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:13 -0400 EDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:15 -0400 EDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:15 -0400 EDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:13 -0400 EDT  }],Message:,Reason:,HostIP:172.20.56.226,PodIP:100.96.2.33,StartTime:2019-03-26 23:18:13 -0400 EDT,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-26 23:18:14 -0400 EDT,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://8ee3bfdd85f4948a97e038c84321dd47fba9a63b2280b18c87fadab1fe712ee2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.275: INFO: Pod "nginx-deployment-7f9675fb8b-h7dn9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-h7dn9,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7f9675fb8b-h7dn9,UID:f9d0a399-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28523,Generation:0,CreationTimestamp:2019-03-26 23:18:22 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4ae8f3b-503e-11e9-8eb3-023bf32bf132 0xc0004cbb80 0xc0004cbb81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-53-156.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0004cbc00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0004cbc20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.275: INFO: Pod "nginx-deployment-7f9675fb8b-hj5xc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-hj5xc,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7f9675fb8b-hj5xc,UID:f4b3c22e-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28438,Generation:0,CreationTimestamp:2019-03-26 23:18:13 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4ae8f3b-503e-11e9-8eb3-023bf32bf132 0xc0004cbd80 0xc0004cbd81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-53-156.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000058190} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000058260}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:13 -0400 EDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:16 -0400 EDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:16 -0400 EDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:13 -0400 EDT  }],Message:,Reason:,HostIP:172.20.53.156,PodIP:100.96.1.150,StartTime:2019-03-26 23:18:13 -0400 EDT,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-26 23:18:14 -0400 EDT,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://c5e5d75e7aa8b9b92ee07444cf949c83d9cd5bb92c761191e54e8112168b6a9c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.275: INFO: Pod "nginx-deployment-7f9675fb8b-hqgmq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-hqgmq,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7f9675fb8b-hqgmq,UID:f9d4834c-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28536,Generation:0,CreationTimestamp:2019-03-26 23:18:22 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4ae8f3b-503e-11e9-8eb3-023bf32bf132 0xc000058ae7 0xc000058ae8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-56-226.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000058c10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000059000}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.275: INFO: Pod "nginx-deployment-7f9675fb8b-k8ctx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-k8ctx,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7f9675fb8b-k8ctx,UID:f4b0cdb3-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28435,Generation:0,CreationTimestamp:2019-03-26 23:18:13 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4ae8f3b-503e-11e9-8eb3-023bf32bf132 0xc000059560 0xc000059561}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-56-226.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0000595f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000059660}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:13 -0400 EDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:15 -0400 EDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:15 -0400 EDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:13 -0400 EDT  }],Message:,Reason:,HostIP:172.20.56.226,PodIP:100.96.2.34,StartTime:2019-03-26 23:18:13 -0400 EDT,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-26 23:18:14 -0400 EDT,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://9731fc380ac6c9e9e82d957f51b4b1595426416fd62c7a15f1afbe223ee3d235}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.275: INFO: Pod "nginx-deployment-7f9675fb8b-m5pb6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-m5pb6,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7f9675fb8b-m5pb6,UID:f9d4751d-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28535,Generation:0,CreationTimestamp:2019-03-26 23:18:22 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4ae8f3b-503e-11e9-8eb3-023bf32bf132 0xc000059b70 0xc000059b71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-53-156.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00095e000} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00095e020}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.275: INFO: Pod "nginx-deployment-7f9675fb8b-nkf26" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-nkf26,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7f9675fb8b-nkf26,UID:f9d456e5-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28534,Generation:0,CreationTimestamp:2019-03-26 23:18:22 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4ae8f3b-503e-11e9-8eb3-023bf32bf132 0xc00095e0b0 0xc00095e0b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-56-226.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00095e130} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00095e1e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.275: INFO: Pod "nginx-deployment-7f9675fb8b-p8mnz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-p8mnz,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7f9675fb8b-p8mnz,UID:f4b429b1-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28420,Generation:0,CreationTimestamp:2019-03-26 23:18:13 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4ae8f3b-503e-11e9-8eb3-023bf32bf132 0xc00095e440 0xc00095e441}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-53-156.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00095e540} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00095e590}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:13 -0400 EDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:15 -0400 EDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:15 -0400 EDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:13 -0400 EDT  }],Message:,Reason:,HostIP:172.20.53.156,PodIP:100.96.1.149,StartTime:2019-03-26 23:18:13 -0400 EDT,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-26 23:18:14 -0400 EDT,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://80a228b3293bbd5cb52f6669fe955c478886a96b27431411d47f2d05da820625}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.275: INFO: Pod "nginx-deployment-7f9675fb8b-phwpg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-phwpg,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7f9675fb8b-phwpg,UID:f9c8a0b0-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28505,Generation:0,CreationTimestamp:2019-03-26 23:18:22 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4ae8f3b-503e-11e9-8eb3-023bf32bf132 0xc00095e7f7 0xc00095e7f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-53-156.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00095ea00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00095ea40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT  }],Message:,Reason:,HostIP:172.20.53.156,PodIP:,StartTime:2019-03-26 23:18:22 -0400 EDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.275: INFO: Pod "nginx-deployment-7f9675fb8b-pkmbc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-pkmbc,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7f9675fb8b-pkmbc,UID:f4b5eaef-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28431,Generation:0,CreationTimestamp:2019-03-26 23:18:13 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4ae8f3b-503e-11e9-8eb3-023bf32bf132 0xc00095ebd7 0xc00095ebd8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-53-156.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00095ec50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00095eca0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:13 -0400 EDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:16 -0400 EDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:16 -0400 EDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:13 -0400 EDT  }],Message:,Reason:,HostIP:172.20.53.156,PodIP:100.96.1.151,StartTime:2019-03-26 23:18:13 -0400 EDT,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-26 23:18:15 -0400 EDT,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://a567e0637e073ac8661dbc6721ed8fc7460f9a68cd2dc7c7f3efd32ae894b86d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.275: INFO: Pod "nginx-deployment-7f9675fb8b-rnzh4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-rnzh4,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7f9675fb8b-rnzh4,UID:f9d3e8ca-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28531,Generation:0,CreationTimestamp:2019-03-26 23:18:22 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4ae8f3b-503e-11e9-8eb3-023bf32bf132 0xc00095f0c7 0xc00095f0c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-53-156.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00095f1c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00095f320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.275: INFO: Pod "nginx-deployment-7f9675fb8b-sg5d2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-sg5d2,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7f9675fb8b-sg5d2,UID:f4b16e4c-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28414,Generation:0,CreationTimestamp:2019-03-26 23:18:13 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4ae8f3b-503e-11e9-8eb3-023bf32bf132 0xc00095f3e0 0xc00095f3e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-53-156.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020fa030} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020fa060}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:13 -0400 EDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:15 -0400 EDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:15 -0400 EDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:13 -0400 EDT  }],Message:,Reason:,HostIP:172.20.53.156,PodIP:100.96.1.148,StartTime:2019-03-26 23:18:13 -0400 EDT,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-26 23:18:14 -0400 EDT,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://d453712729bf415ee68165281e9f28186c3297ca4894dbd9c26ef8d0e482c7cb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.276: INFO: Pod "nginx-deployment-7f9675fb8b-v4rql" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-v4rql,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7f9675fb8b-v4rql,UID:f9c9fdf1-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28540,Generation:0,CreationTimestamp:2019-03-26 23:18:22 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4ae8f3b-503e-11e9-8eb3-023bf32bf132 0xc0020fa267 0xc0020fa268}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-56-226.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020fa310} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020fa330}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT  }],Message:,Reason:,HostIP:172.20.56.226,PodIP:,StartTime:2019-03-26 23:18:22 -0400 EDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.276: INFO: Pod "nginx-deployment-7f9675fb8b-vgg5n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-vgg5n,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7f9675fb8b-vgg5n,UID:f9cf64cc-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28515,Generation:0,CreationTimestamp:2019-03-26 23:18:22 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4ae8f3b-503e-11e9-8eb3-023bf32bf132 0xc0020fa4f7 0xc0020fa4f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-53-156.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020fa560} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020fa580}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.276: INFO: Pod "nginx-deployment-7f9675fb8b-x8mr4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-x8mr4,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7f9675fb8b-x8mr4,UID:f4b661ac-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28417,Generation:0,CreationTimestamp:2019-03-26 23:18:13 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4ae8f3b-503e-11e9-8eb3-023bf32bf132 0xc0020fa5f0 0xc0020fa5f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-56-226.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020fa980} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020fa9a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:13 -0400 EDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:15 -0400 EDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:15 -0400 EDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:13 -0400 EDT  }],Message:,Reason:,HostIP:172.20.56.226,PodIP:100.96.2.35,StartTime:2019-03-26 23:18:13 -0400 EDT,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-26 23:18:14 -0400 EDT,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://99b3dbc6bed3bc8b96b566e5e423566da0f187b4b4c25be385cdcd5e7262391b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 23:18:24.276: INFO: Pod "nginx-deployment-7f9675fb8b-xlq9x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-xlq9x,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-j6t47,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6t47/pods/nginx-deployment-7f9675fb8b-xlq9x,UID:f9d08e62-503e-11e9-8eb3-023bf32bf132,ResourceVersion:28518,Generation:0,CreationTimestamp:2019-03-26 23:18:22 -0400 EDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4ae8f3b-503e-11e9-8eb3-023bf32bf132 0xc0020faa60 0xc0020faa61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ntg9x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg9x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ntg9x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-56-226.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020fab20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020fab40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:18:22 -0400 EDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:18:24.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-deployment-j6t47" for this suite.
Mar 26 23:18:30.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:18:30.879: INFO: namespace: e2e-tests-deployment-j6t47, resource: bindings, ignored listing per whitelist
Mar 26 23:18:31.307: INFO: namespace e2e-tests-deployment-j6t47 deletion completed in 7.004680168s

[32mâ€¢ [SLOW TEST:18.678 seconds][0m
[sig-apps] Deployment
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  deployment should support proportional scaling [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[k8s.io] InitContainer [NodeConformance][0m 
  [1mshould not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:18:31.307: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename init-container
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating the pod
Mar 26 23:18:32.138: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:18:38.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-init-container-qj9xp" for this suite.
Mar 26 23:18:44.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:18:44.757: INFO: namespace: e2e-tests-init-container-qj9xp, resource: bindings, ignored listing per whitelist
Mar 26 23:18:45.575: INFO: namespace e2e-tests-init-container-qj9xp deletion completed in 7.020561514s

[32mâ€¢ [SLOW TEST:14.268 seconds][0m
[k8s.io] InitContainer [NodeConformance]
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1moptional updates should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:18:45.575: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating secret with name s-test-opt-del-085411af-503f-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating secret with name s-test-opt-upd-085411fd-503f-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Deleting secret s-test-opt-del-085411af-503f-11e9-9bdd-d050998677c2
[1mSTEP[0m: Updating secret s-test-opt-upd-085411fd-503f-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating secret with name s-test-opt-create-08541211-503f-11e9-9bdd-d050998677c2
[1mSTEP[0m: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:18:50.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-68p49" for this suite.
Mar 26 23:19:12.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:19:13.637: INFO: namespace: e2e-tests-projected-68p49, resource: bindings, ignored listing per whitelist
Mar 26 23:19:13.941: INFO: namespace e2e-tests-projected-68p49 deletion completed in 23.020376008s

[32mâ€¢ [SLOW TEST:28.366 seconds][0m
[sig-storage] Projected
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35[0m
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl run pod[0m 
  [1mshould create a pod from an image when restart is Never  [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:19:13.941: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: running the image docker.io/library/nginx:1.14-alpine
Mar 26 23:19:14.758: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-ntkf8'
Mar 26 23:19:16.305: INFO: stderr: ""
Mar 26 23:19:16.305: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
[1mSTEP[0m: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Mar 26 23:19:16.330: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-ntkf8'
Mar 26 23:19:19.056: INFO: stderr: ""
Mar 26 23:19:19.056: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:19:19.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-ntkf8" for this suite.
Mar 26 23:19:25.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:19:26.007: INFO: namespace: e2e-tests-kubectl-ntkf8, resource: bindings, ignored listing per whitelist
Mar 26 23:19:26.108: INFO: namespace e2e-tests-kubectl-ntkf8 deletion completed in 7.026007892s

[32mâ€¢ [SLOW TEST:12.167 seconds][0m
[sig-cli] Kubectl client
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl run pod
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should create a pod from an image when restart is Never  [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected[0m 
  [1mshould be consumable from pods in volume as non-root [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:19:26.108: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-2075953f-503f-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating a pod to test consume configMaps
Mar 26 23:19:26.978: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-207979cf-503f-11e9-9bdd-d050998677c2" in namespace "e2e-tests-projected-q8klp" to be "success or failure"
Mar 26 23:19:27.003: INFO: Pod "pod-projected-configmaps-207979cf-503f-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.346954ms
Mar 26 23:19:29.030: INFO: Pod "pod-projected-configmaps-207979cf-503f-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.051677411s
[1mSTEP[0m: Saw pod success
Mar 26 23:19:29.030: INFO: Pod "pod-projected-configmaps-207979cf-503f-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 23:19:29.055: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-projected-configmaps-207979cf-503f-11e9-9bdd-d050998677c2 container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
Mar 26 23:19:29.117: INFO: Waiting for pod pod-projected-configmaps-207979cf-503f-11e9-9bdd-d050998677c2 to disappear
Mar 26 23:19:29.142: INFO: Pod pod-projected-configmaps-207979cf-503f-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] Projected
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:19:29.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-q8klp" for this suite.
Mar 26 23:19:35.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:19:35.348: INFO: namespace: e2e-tests-projected-q8klp, resource: bindings, ignored listing per whitelist
Mar 26 23:19:36.183: INFO: namespace e2e-tests-projected-q8klp deletion completed in 7.013932259s

[32mâ€¢ [SLOW TEST:10.074 seconds][0m
[sig-storage] Projected
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35[0m
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (root,0644,tmpfs) [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:19:36.183: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test emptydir 0644 on tmpfs
Mar 26 23:19:37.034: INFO: Waiting up to 5m0s for pod "pod-2677eb54-503f-11e9-9bdd-d050998677c2" in namespace "e2e-tests-emptydir-64dld" to be "success or failure"
Mar 26 23:19:37.060: INFO: Pod "pod-2677eb54-503f-11e9-9bdd-d050998677c2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.964241ms
Mar 26 23:19:39.086: INFO: Pod "pod-2677eb54-503f-11e9-9bdd-d050998677c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.051566895s
[1mSTEP[0m: Saw pod success
Mar 26 23:19:39.086: INFO: Pod "pod-2677eb54-503f-11e9-9bdd-d050998677c2" satisfied condition "success or failure"
Mar 26 23:19:39.111: INFO: Trying to get logs from node ip-172-20-56-226.us-east-2.compute.internal pod pod-2677eb54-503f-11e9-9bdd-d050998677c2 container test-container: <nil>
[1mSTEP[0m: delete the pod
Mar 26 23:19:39.173: INFO: Waiting for pod pod-2677eb54-503f-11e9-9bdd-d050998677c2 to disappear
Mar 26 23:19:39.198: INFO: Pod pod-2677eb54-503f-11e9-9bdd-d050998677c2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:19:39.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-64dld" for this suite.
Mar 26 23:19:45.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:19:45.603: INFO: namespace: e2e-tests-emptydir-64dld, resource: bindings, ignored listing per whitelist
Mar 26 23:19:46.243: INFO: namespace e2e-tests-emptydir-64dld deletion completed in 7.017924441s

[32mâ€¢ [SLOW TEST:10.060 seconds][0m
[sig-storage] EmptyDir volumes
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1moptional updates should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Secrets
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:19:46.243: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating secret with name s-test-opt-del-2c7a56c3-503f-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating secret with name s-test-opt-upd-2c7a5701-503f-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Deleting secret s-test-opt-del-2c7a56c3-503f-11e9-9bdd-d050998677c2
[1mSTEP[0m: Updating secret s-test-opt-upd-2c7a5701-503f-11e9-9bdd-d050998677c2
[1mSTEP[0m: Creating secret with name s-test-opt-create-2c7a5711-503f-11e9-9bdd-d050998677c2
[1mSTEP[0m: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:21:08.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-secrets-scjkm" for this suite.
Mar 26 23:21:30.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:21:31.553: INFO: namespace: e2e-tests-secrets-scjkm, resource: bindings, ignored listing per whitelist
Mar 26 23:21:31.708: INFO: namespace e2e-tests-secrets-scjkm deletion completed in 23.019291488s

[32mâ€¢ [SLOW TEST:105.466 seconds][0m
[sig-storage] Secrets
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34[0m
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] StatefulSet[0m [90m[k8s.io] Basic StatefulSet functionality [StatefulSetBasic][0m 
  [1mBurst scaling should run to completion even with unhealthy pods [Conformance][0m
  [37m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] StatefulSet
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
[1mSTEP[0m: Creating a kubernetes client
Mar 26 23:21:31.708: INFO: >>> kubeConfig: /home/justinsb/.kube/config
[1mSTEP[0m: Building a namespace api object, basename statefulset
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
[1mSTEP[0m: Creating service test in namespace e2e-tests-statefulset-88mkt
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating stateful set ss in namespace e2e-tests-statefulset-88mkt
[1mSTEP[0m: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-88mkt
Mar 26 23:21:32.684: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Mar 26 23:21:42.712: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
[1mSTEP[0m: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Mar 26 23:21:42.738: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-88mkt ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 26 23:21:43.230: INFO: stderr: ""
Mar 26 23:21:43.230: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 26 23:21:43.230: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 26 23:21:43.255: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar 26 23:21:53.282: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 26 23:21:53.282: INFO: Waiting for statefulset status.replicas updated to 0
Mar 26 23:21:53.390: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999526s
Mar 26 23:21:54.417: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.971169493s
Mar 26 23:21:55.444: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.944341999s
Mar 26 23:21:56.470: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.917612699s
Mar 26 23:21:57.497: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.891156231s
Mar 26 23:21:58.543: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.8644732s
Mar 26 23:21:59.571: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.81775621s
Mar 26 23:22:00.598: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.790151702s
Mar 26 23:22:01.626: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.763490827s
Mar 26 23:22:02.653: INFO: Verifying statefulset ss doesn't scale past 3 for another 735.198876ms
[1mSTEP[0m: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-88mkt
Mar 26 23:22:03.680: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-88mkt ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 23:22:04.174: INFO: stderr: ""
Mar 26 23:22:04.174: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 26 23:22:04.174: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 26 23:22:04.174: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-88mkt ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 23:22:04.651: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Mar 26 23:22:04.651: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 26 23:22:04.651: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 26 23:22:04.651: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-88mkt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 23:22:05.115: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Mar 26 23:22:05.115: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 26 23:22:05.115: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 26 23:22:05.141: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 26 23:22:05.141: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 26 23:22:05.141: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
[1mSTEP[0m: Scale down will not halt with unhealthy stateful pod
Mar 26 23:22:05.167: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-88mkt ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 26 23:22:05.630: INFO: stderr: ""
Mar 26 23:22:05.630: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 26 23:22:05.630: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 26 23:22:05.630: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-88mkt ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 26 23:22:06.128: INFO: stderr: ""
Mar 26 23:22:06.128: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 26 23:22:06.128: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 26 23:22:06.128: INFO: Running '/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/bin/kubectl --server=https://api-conformance-k8s-local-6bm0v2-1153835568.us-east-2.elb.amazonaws.com --kubeconfig=/home/justinsb/.kube/config exec --namespace=e2e-tests-statefulset-88mkt ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 26 23:22:06.583: INFO: stderr: ""
Mar 26 23:22:06.583: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 26 23:22:06.583: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 26 23:22:06.583: INFO: Waiting for statefulset status.replicas updated to 0
Mar 26 23:22:06.613: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Mar 26 23:22:16.665: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 26 23:22:16.665: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar 26 23:22:16.665: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar 26 23:22:16.755: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Mar 26 23:22:16.755: INFO: ss-0  ip-172-20-56-226.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:21:32 -0400 EDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:22:05 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:22:05 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:21:32 -0400 EDT  }]
Mar 26 23:22:16.755: INFO: ss-1  ip-172-20-53-156.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:21:53 -0400 EDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:22:06 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:22:06 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:21:53 -0400 EDT  }]
Mar 26 23:22:16.755: INFO: ss-2  ip-172-20-56-226.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:21:53 -0400 EDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:22:07 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:22:07 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:21:53 -0400 EDT  }]
Mar 26 23:22:16.755: INFO: 
Mar 26 23:22:16.755: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 26 23:22:17.781: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Mar 26 23:22:17.781: INFO: ss-0  ip-172-20-56-226.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:21:32 -0400 EDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:22:05 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:22:05 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:21:32 -0400 EDT  }]
Mar 26 23:22:17.781: INFO: ss-1  ip-172-20-53-156.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:21:53 -0400 EDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:22:06 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:22:06 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:21:53 -0400 EDT  }]
Mar 26 23:22:17.781: INFO: ss-2  ip-172-20-56-226.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:21:53 -0400 EDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:22:07 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:22:07 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:21:53 -0400 EDT  }]
Mar 26 23:22:17.781: INFO: 
Mar 26 23:22:17.781: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 26 23:22:18.808: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Mar 26 23:22:18.808: INFO: ss-0  ip-172-20-56-226.us-east-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:21:32 -0400 EDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:22:05 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:22:05 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:21:32 -0400 EDT  }]
Mar 26 23:22:18.808: INFO: ss-1  ip-172-20-53-156.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:21:53 -0400 EDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:22:06 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:22:06 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:21:53 -0400 EDT  }]
Mar 26 23:22:18.808: INFO: ss-2  ip-172-20-56-226.us-east-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:21:53 -0400 EDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:22:07 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:22:07 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:21:53 -0400 EDT  }]
Mar 26 23:22:18.808: INFO: 
Mar 26 23:22:18.808: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 26 23:22:19.834: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Mar 26 23:22:19.834: INFO: ss-0  ip-172-20-56-226.us-east-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:21:32 -0400 EDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:22:05 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:22:05 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:21:32 -0400 EDT  }]
Mar 26 23:22:19.834: INFO: ss-2  ip-172-20-56-226.us-east-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:21:53 -0400 EDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:22:07 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:22:07 -0400 EDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 23:21:53 -0400 EDT  }]
Mar 26 23:22:19.834: INFO: 
Mar 26 23:22:19.834: INFO: StatefulSet ss has not reached scale 0, at 2
Mar 26 23:22:20.860: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.883824045s
Mar 26 23:22:21.887: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.857992054s
Mar 26 23:22:22.913: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.83094098s
Mar 26 23:22:23.940: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.804851528s
Mar 26 23:22:24.966: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.778172821s
Mar 26 23:22:25.992: INFO: Verifying statefulset ss doesn't scale past 0 for another 752.247227ms
[1mSTEP[0m: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-88mkt
Mar 26 23:22:27.017: INFO: Scaling statefulset ss to 0
Mar 26 23:22:27.093: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 26 23:22:27.119: INFO: Deleting all statefulset in ns e2e-tests-statefulset-88mkt
Mar 26 23:22:27.144: INFO: Scaling statefulset ss to 0
Mar 26 23:22:27.220: INFO: Waiting for statefulset status.replicas updated to 0
Mar 26 23:22:27.246: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 23:22:27.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-statefulset-88mkt" for this suite.
Mar 26 23:22:33.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 23:22:34.183: INFO: namespace: e2e-tests-statefulset-88mkt, resource: bindings, ignored listing per whitelist
Mar 26 23:22:34.361: INFO: namespace e2e-tests-statefulset-88mkt deletion completed in 7.010589774s

[32mâ€¢ [SLOW TEST:62.652 seconds][0m
[sig-apps] StatefulSet
[90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    [90m/home/justinsb/k8s/src/k8s.io/kops/hack/conformance/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
Mar 26 23:22:34.361: INFO: Running AfterSuite actions on all node
Mar 26 23:22:34.361: INFO: Running AfterSuite actions on node 1
Mar 26 23:22:34.361: INFO: Skipping dumping logs from cluster

[1m[32mRan 189 of 1813 Specs in 5531.290 seconds[0m
[1m[32mSUCCESS![0m -- [32m[1m189 Passed[0m | [91m[1m0 Failed[0m | [33m[1m0 Pending[0m | [36m[1m1624 Skipped[0m PASS

Ginkgo ran 1 suite in 1h32m11.711108373s
Test Suite Passed
