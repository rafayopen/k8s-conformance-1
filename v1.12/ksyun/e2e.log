May 21 09:26:46.171: INFO: Overriding default scale value of zero to 1
May 21 09:26:46.171: INFO: Overriding default milliseconds value of zero to 5000
I0521 09:26:46.640095      15 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-877789554
I0521 09:26:46.640196      15 e2e.go:304] Starting e2e run "8d8261cc-7baa-11e9-be4b-6e6d88bcf118" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1558430805 - Will randomize all specs
Will run 188 of 1814 specs

May 21 09:26:46.796: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
May 21 09:26:46.798: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
May 21 09:26:46.809: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May 21 09:26:46.846: INFO: The status of Pod system-monitor-7d7cc47bc9-r8zcc is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 09:26:46.846: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 21 09:26:46.846: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 09:26:46.846: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 09:26:46.846: INFO: system-monitor-7d7cc47bc9-r8zcc  192.168.5.11  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  }]
May 21 09:26:46.846: INFO: 
May 21 09:26:48.865: INFO: The status of Pod system-monitor-7d7cc47bc9-r8zcc is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 09:26:48.865: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (2 seconds elapsed)
May 21 09:26:48.865: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 09:26:48.865: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 09:26:48.865: INFO: system-monitor-7d7cc47bc9-r8zcc  192.168.5.11  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  }]
May 21 09:26:48.865: INFO: 
May 21 09:26:50.865: INFO: The status of Pod system-monitor-7d7cc47bc9-r8zcc is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 09:26:50.865: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (4 seconds elapsed)
May 21 09:26:50.865: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 09:26:50.865: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 09:26:50.865: INFO: system-monitor-7d7cc47bc9-r8zcc  192.168.5.11  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  }]
May 21 09:26:50.865: INFO: 
May 21 09:26:52.863: INFO: The status of Pod system-monitor-7d7cc47bc9-r8zcc is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 09:26:52.863: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (6 seconds elapsed)
May 21 09:26:52.863: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 09:26:52.863: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 09:26:52.863: INFO: system-monitor-7d7cc47bc9-r8zcc  192.168.5.11  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  }]
May 21 09:26:52.864: INFO: 
May 21 09:26:54.864: INFO: The status of Pod system-monitor-7d7cc47bc9-r8zcc is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 09:26:54.864: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (8 seconds elapsed)
May 21 09:26:54.864: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 09:26:54.864: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 09:26:54.864: INFO: system-monitor-7d7cc47bc9-r8zcc  192.168.5.11  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  }]
May 21 09:26:54.864: INFO: 
May 21 09:26:56.861: INFO: The status of Pod system-monitor-7d7cc47bc9-r8zcc is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 09:26:56.861: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (10 seconds elapsed)
May 21 09:26:56.861: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 09:26:56.861: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 09:26:56.861: INFO: system-monitor-7d7cc47bc9-r8zcc  192.168.5.11  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  }]
May 21 09:26:56.861: INFO: 
May 21 09:26:58.869: INFO: The status of Pod system-monitor-7d7cc47bc9-r8zcc is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 09:26:58.869: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (12 seconds elapsed)
May 21 09:26:58.869: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 09:26:58.869: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 09:26:58.869: INFO: system-monitor-7d7cc47bc9-r8zcc  192.168.5.11  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  }]
May 21 09:26:58.869: INFO: 
May 21 09:27:00.860: INFO: The status of Pod system-monitor-7d7cc47bc9-r8zcc is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 09:27:00.860: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (14 seconds elapsed)
May 21 09:27:00.861: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 09:27:00.861: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 09:27:00.861: INFO: system-monitor-7d7cc47bc9-r8zcc  192.168.5.11  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  }]
May 21 09:27:00.861: INFO: 
May 21 09:27:02.861: INFO: The status of Pod system-monitor-7d7cc47bc9-r8zcc is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 09:27:02.861: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (16 seconds elapsed)
May 21 09:27:02.861: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 09:27:02.861: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 09:27:02.861: INFO: system-monitor-7d7cc47bc9-r8zcc  192.168.5.11  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  }]
May 21 09:27:02.861: INFO: 
May 21 09:27:04.864: INFO: The status of Pod system-monitor-7d7cc47bc9-r8zcc is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 09:27:04.864: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (18 seconds elapsed)
May 21 09:27:04.864: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 09:27:04.864: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 09:27:04.864: INFO: system-monitor-7d7cc47bc9-r8zcc  192.168.5.11  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  }]
May 21 09:27:04.864: INFO: 
May 21 09:27:06.861: INFO: The status of Pod system-monitor-7d7cc47bc9-r8zcc is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 09:27:06.861: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (20 seconds elapsed)
May 21 09:27:06.861: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 09:27:06.861: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 09:27:06.861: INFO: system-monitor-7d7cc47bc9-r8zcc  192.168.5.11  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  }]
May 21 09:27:06.861: INFO: 
May 21 09:27:08.867: INFO: The status of Pod system-monitor-7d7cc47bc9-r8zcc is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 09:27:08.867: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (22 seconds elapsed)
May 21 09:27:08.867: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 09:27:08.867: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 09:27:08.867: INFO: system-monitor-7d7cc47bc9-r8zcc  192.168.5.11  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  }]
May 21 09:27:08.868: INFO: 
May 21 09:27:10.861: INFO: The status of Pod system-monitor-7d7cc47bc9-r8zcc is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 09:27:10.861: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (24 seconds elapsed)
May 21 09:27:10.861: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 09:27:10.861: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 09:27:10.861: INFO: system-monitor-7d7cc47bc9-r8zcc  192.168.5.11  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  }]
May 21 09:27:10.861: INFO: 
May 21 09:27:12.860: INFO: The status of Pod system-monitor-7d7cc47bc9-r8zcc is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 09:27:12.860: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (26 seconds elapsed)
May 21 09:27:12.860: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 09:27:12.860: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 09:27:12.860: INFO: system-monitor-7d7cc47bc9-r8zcc  192.168.5.11  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  }]
May 21 09:27:12.860: INFO: 
May 21 09:27:14.867: INFO: The status of Pod system-monitor-7d7cc47bc9-r8zcc is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 09:27:14.867: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (28 seconds elapsed)
May 21 09:27:14.867: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 09:27:14.867: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 09:27:14.867: INFO: system-monitor-7d7cc47bc9-r8zcc  192.168.5.11  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  }]
May 21 09:27:14.867: INFO: 
May 21 09:27:16.861: INFO: The status of Pod system-monitor-7d7cc47bc9-r8zcc is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 09:27:16.861: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (30 seconds elapsed)
May 21 09:27:16.861: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 09:27:16.861: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 09:27:16.861: INFO: system-monitor-7d7cc47bc9-r8zcc  192.168.5.11  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  }]
May 21 09:27:16.861: INFO: 
May 21 09:27:18.863: INFO: The status of Pod system-monitor-7d7cc47bc9-r8zcc is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 09:27:18.863: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (32 seconds elapsed)
May 21 09:27:18.863: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 09:27:18.863: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 09:27:18.863: INFO: system-monitor-7d7cc47bc9-r8zcc  192.168.5.11  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  }]
May 21 09:27:18.863: INFO: 
May 21 09:27:20.866: INFO: The status of Pod system-monitor-7d7cc47bc9-r8zcc is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 09:27:20.866: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (34 seconds elapsed)
May 21 09:27:20.866: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 09:27:20.866: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 09:27:20.866: INFO: system-monitor-7d7cc47bc9-r8zcc  192.168.5.11  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  }]
May 21 09:27:20.866: INFO: 
May 21 09:27:22.861: INFO: The status of Pod system-monitor-7d7cc47bc9-r8zcc is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 09:27:22.861: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (36 seconds elapsed)
May 21 09:27:22.861: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 09:27:22.861: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 09:27:22.861: INFO: system-monitor-7d7cc47bc9-r8zcc  192.168.5.11  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:22:10 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:15:31 +0000 UTC  }]
May 21 09:27:22.861: INFO: 
May 21 09:27:24.865: INFO: 33 / 33 pods in namespace 'kube-system' are running and ready (38 seconds elapsed)
May 21 09:27:24.865: INFO: expected 8 pod replicas in namespace 'kube-system', 8 are Running and Ready.
May 21 09:27:24.865: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
May 21 09:27:24.872: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'ksc-flexvolume-ds' (0 seconds elapsed)
May 21 09:27:24.872: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'kube-flannel' (0 seconds elapsed)
May 21 09:27:24.872: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
May 21 09:27:24.872: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-device-plugin-daemonset' (0 seconds elapsed)
May 21 09:27:24.872: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'traefik-ingress-controller' (0 seconds elapsed)
May 21 09:27:24.872: INFO: e2e test version: v1.12.1
May 21 09:27:24.872: INFO: kube-apiserver version: v1.12.3
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:27:24.873: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename projected
May 21 09:27:24.924: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-a4b1618e-7baa-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume configMaps
May 21 09:27:24.937: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a4b1f450-7baa-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-projected-mf2n8" to be "success or failure"
May 21 09:27:24.940: INFO: Pod "pod-projected-configmaps-a4b1f450-7baa-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 2.757228ms
May 21 09:27:26.943: INFO: Pod "pod-projected-configmaps-a4b1f450-7baa-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005822627s
May 21 09:27:28.946: INFO: Pod "pod-projected-configmaps-a4b1f450-7baa-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009220768s
STEP: Saw pod success
May 21 09:27:28.946: INFO: Pod "pod-projected-configmaps-a4b1f450-7baa-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 09:27:28.951: INFO: Trying to get logs from node 192.168.5.29 pod pod-projected-configmaps-a4b1f450-7baa-11e9-be4b-6e6d88bcf118 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 09:27:28.981: INFO: Waiting for pod pod-projected-configmaps-a4b1f450-7baa-11e9-be4b-6e6d88bcf118 to disappear
May 21 09:27:28.982: INFO: Pod pod-projected-configmaps-a4b1f450-7baa-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:27:28.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mf2n8" for this suite.
May 21 09:27:34.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:27:35.040: INFO: namespace: e2e-tests-projected-mf2n8, resource: bindings, ignored listing per whitelist
May 21 09:27:35.065: INFO: namespace e2e-tests-projected-mf2n8 deletion completed in 6.079606847s

• [SLOW TEST:10.192 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:27:35.065: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
May 21 09:27:35.115: INFO: Waiting up to 5m0s for pod "var-expansion-aac37c31-7baa-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-var-expansion-9w8vh" to be "success or failure"
May 21 09:27:35.118: INFO: Pod "var-expansion-aac37c31-7baa-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 2.106636ms
May 21 09:27:37.120: INFO: Pod "var-expansion-aac37c31-7baa-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004579623s
May 21 09:27:39.123: INFO: Pod "var-expansion-aac37c31-7baa-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007484856s
May 21 09:27:41.130: INFO: Pod "var-expansion-aac37c31-7baa-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014578516s
May 21 09:27:43.133: INFO: Pod "var-expansion-aac37c31-7baa-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 8.017447019s
May 21 09:27:45.135: INFO: Pod "var-expansion-aac37c31-7baa-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 10.020063102s
May 21 09:27:47.138: INFO: Pod "var-expansion-aac37c31-7baa-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 12.022657462s
May 21 09:27:49.141: INFO: Pod "var-expansion-aac37c31-7baa-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 14.025150231s
May 21 09:27:51.144: INFO: Pod "var-expansion-aac37c31-7baa-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 16.028999867s
May 21 09:27:53.147: INFO: Pod "var-expansion-aac37c31-7baa-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 18.031619808s
May 21 09:27:55.150: INFO: Pod "var-expansion-aac37c31-7baa-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 20.034986577s
STEP: Saw pod success
May 21 09:27:55.150: INFO: Pod "var-expansion-aac37c31-7baa-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 09:27:55.152: INFO: Trying to get logs from node 192.168.5.29 pod var-expansion-aac37c31-7baa-11e9-be4b-6e6d88bcf118 container dapi-container: <nil>
STEP: delete the pod
May 21 09:27:55.164: INFO: Waiting for pod var-expansion-aac37c31-7baa-11e9-be4b-6e6d88bcf118 to disappear
May 21 09:27:55.166: INFO: Pod var-expansion-aac37c31-7baa-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:27:55.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-9w8vh" for this suite.
May 21 09:28:01.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:28:01.221: INFO: namespace: e2e-tests-var-expansion-9w8vh, resource: bindings, ignored listing per whitelist
May 21 09:28:01.236: INFO: namespace e2e-tests-var-expansion-9w8vh deletion completed in 6.067255925s

• [SLOW TEST:26.171 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:28:01.236: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 09:28:01.283: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ba5c4806-7baa-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-projected-cdzmv" to be "success or failure"
May 21 09:28:01.285: INFO: Pod "downwardapi-volume-ba5c4806-7baa-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 2.491629ms
May 21 09:28:03.290: INFO: Pod "downwardapi-volume-ba5c4806-7baa-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007500558s
STEP: Saw pod success
May 21 09:28:03.290: INFO: Pod "downwardapi-volume-ba5c4806-7baa-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 09:28:03.292: INFO: Trying to get logs from node 192.168.5.29 pod downwardapi-volume-ba5c4806-7baa-11e9-be4b-6e6d88bcf118 container client-container: <nil>
STEP: delete the pod
May 21 09:28:03.306: INFO: Waiting for pod downwardapi-volume-ba5c4806-7baa-11e9-be4b-6e6d88bcf118 to disappear
May 21 09:28:03.308: INFO: Pod downwardapi-volume-ba5c4806-7baa-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:28:03.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cdzmv" for this suite.
May 21 09:28:09.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:28:09.357: INFO: namespace: e2e-tests-projected-cdzmv, resource: bindings, ignored listing per whitelist
May 21 09:28:09.375: INFO: namespace e2e-tests-projected-cdzmv deletion completed in 6.064492179s

• [SLOW TEST:8.139 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:28:09.375: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
May 21 09:28:09.418: INFO: Waiting up to 5m0s for pod "pod-bf358cba-7baa-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-emptydir-h2ssq" to be "success or failure"
May 21 09:28:09.419: INFO: Pod "pod-bf358cba-7baa-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 1.491408ms
May 21 09:28:11.422: INFO: Pod "pod-bf358cba-7baa-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004305309s
May 21 09:28:13.425: INFO: Pod "pod-bf358cba-7baa-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006947524s
STEP: Saw pod success
May 21 09:28:13.425: INFO: Pod "pod-bf358cba-7baa-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 09:28:13.426: INFO: Trying to get logs from node 192.168.5.29 pod pod-bf358cba-7baa-11e9-be4b-6e6d88bcf118 container test-container: <nil>
STEP: delete the pod
May 21 09:28:13.441: INFO: Waiting for pod pod-bf358cba-7baa-11e9-be4b-6e6d88bcf118 to disappear
May 21 09:28:13.444: INFO: Pod pod-bf358cba-7baa-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:28:13.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-h2ssq" for this suite.
May 21 09:28:19.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:28:19.482: INFO: namespace: e2e-tests-emptydir-h2ssq, resource: bindings, ignored listing per whitelist
May 21 09:28:19.511: INFO: namespace e2e-tests-emptydir-h2ssq deletion completed in 6.064736001s

• [SLOW TEST:10.136 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:28:19.512: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0521 09:28:29.599400      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 21 09:28:29.599: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:28:29.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-d79mb" for this suite.
May 21 09:28:35.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:28:35.639: INFO: namespace: e2e-tests-gc-d79mb, resource: bindings, ignored listing per whitelist
May 21 09:28:35.674: INFO: namespace e2e-tests-gc-d79mb deletion completed in 6.069344162s

• [SLOW TEST:16.162 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:28:35.674: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
May 21 09:28:35.743: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:28:39.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-dfz2n" for this suite.
May 21 09:28:45.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:28:45.978: INFO: namespace: e2e-tests-init-container-dfz2n, resource: bindings, ignored listing per whitelist
May 21 09:28:46.001: INFO: namespace e2e-tests-init-container-dfz2n deletion completed in 6.074457826s

• [SLOW TEST:10.327 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:28:46.001: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May 21 09:31:24.075: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 21 09:31:24.078: INFO: Pod pod-with-poststart-http-hook still exists
May 21 09:31:26.078: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 21 09:31:26.082: INFO: Pod pod-with-poststart-http-hook still exists
May 21 09:31:28.078: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 21 09:31:28.082: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:31:28.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-vqd4g" for this suite.
May 21 09:31:50.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:31:50.138: INFO: namespace: e2e-tests-container-lifecycle-hook-vqd4g, resource: bindings, ignored listing per whitelist
May 21 09:31:50.169: INFO: namespace e2e-tests-container-lifecycle-hook-vqd4g deletion completed in 22.079386987s

• [SLOW TEST:184.168 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:31:50.169: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-42d066f1-7bab-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume configMaps
May 21 09:31:50.216: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-42d0ef15-7bab-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-projected-f7j7m" to be "success or failure"
May 21 09:31:50.219: INFO: Pod "pod-projected-configmaps-42d0ef15-7bab-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 2.964173ms
May 21 09:31:52.224: INFO: Pod "pod-projected-configmaps-42d0ef15-7bab-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008014813s
STEP: Saw pod success
May 21 09:31:52.224: INFO: Pod "pod-projected-configmaps-42d0ef15-7bab-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 09:31:52.225: INFO: Trying to get logs from node 192.168.5.29 pod pod-projected-configmaps-42d0ef15-7bab-11e9-be4b-6e6d88bcf118 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 09:31:52.237: INFO: Waiting for pod pod-projected-configmaps-42d0ef15-7bab-11e9-be4b-6e6d88bcf118 to disappear
May 21 09:31:52.239: INFO: Pod pod-projected-configmaps-42d0ef15-7bab-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:31:52.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-f7j7m" for this suite.
May 21 09:31:58.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:31:58.287: INFO: namespace: e2e-tests-projected-f7j7m, resource: bindings, ignored listing per whitelist
May 21 09:31:58.308: INFO: namespace e2e-tests-projected-f7j7m deletion completed in 6.066398454s

• [SLOW TEST:8.139 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:31:58.308: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-hglwp
May 21 09:32:02.362: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-hglwp
STEP: checking the pod's current state and verifying that restartCount is present
May 21 09:32:02.364: INFO: Initial restart count of pod liveness-http is 0
May 21 09:32:14.382: INFO: Restart count of pod e2e-tests-container-probe-hglwp/liveness-http is now 1 (12.018285002s elapsed)
May 21 09:32:34.410: INFO: Restart count of pod e2e-tests-container-probe-hglwp/liveness-http is now 2 (32.045895349s elapsed)
May 21 09:32:54.441: INFO: Restart count of pod e2e-tests-container-probe-hglwp/liveness-http is now 3 (52.077242253s elapsed)
May 21 09:33:14.469: INFO: Restart count of pod e2e-tests-container-probe-hglwp/liveness-http is now 4 (1m12.104923364s elapsed)
May 21 09:34:18.574: INFO: Restart count of pod e2e-tests-container-probe-hglwp/liveness-http is now 5 (2m16.209990167s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:34:18.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-hglwp" for this suite.
May 21 09:34:24.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:34:24.615: INFO: namespace: e2e-tests-container-probe-hglwp, resource: bindings, ignored listing per whitelist
May 21 09:34:24.666: INFO: namespace e2e-tests-container-probe-hglwp deletion completed in 6.074979237s

• [SLOW TEST:146.357 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:34:24.666: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
May 21 09:34:24.708: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 21 09:34:24.713: INFO: Waiting for terminating namespaces to be deleted...
May 21 09:34:24.714: INFO: 
Logging pods the kubelet thinks is on node 192.168.5.29 before test
May 21 09:34:24.720: INFO: coredns-57cddf5944-w8t7z from kube-system started at 2019-05-21 09:15:17 +0000 UTC (1 container statuses recorded)
May 21 09:34:24.720: INFO: 	Container coredns ready: true, restart count 0
May 21 09:34:24.720: INFO: coredns-57cddf5944-ggdnt from kube-system started at 2019-05-21 09:15:17 +0000 UTC (1 container statuses recorded)
May 21 09:34:24.720: INFO: 	Container coredns ready: true, restart count 0
May 21 09:34:24.720: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-21 09:25:36 +0000 UTC (1 container statuses recorded)
May 21 09:34:24.720: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 21 09:34:24.720: INFO: sonobuoy-systemd-logs-daemon-set-8150fbd9d34045a3-ddhtz from heptio-sonobuoy started at 2019-05-21 09:25:47 +0000 UTC (2 container statuses recorded)
May 21 09:34:24.720: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 21 09:34:24.720: INFO: 	Container systemd-logs ready: true, restart count 0
May 21 09:34:24.720: INFO: kube-flannel-w6rtw from kube-system started at 2019-05-21 09:14:18 +0000 UTC (2 container statuses recorded)
May 21 09:34:24.720: INFO: 	Container install-cni ready: true, restart count 0
May 21 09:34:24.720: INFO: 	Container kube-flannel ready: true, restart count 3
May 21 09:34:24.720: INFO: cloud-controller-manager-5b95856974-d6bg8 from kube-system started at 2019-05-21 09:15:33 +0000 UTC (1 container statuses recorded)
May 21 09:34:24.720: INFO: 	Container cloud-controller-manager ready: true, restart count 0
May 21 09:34:24.720: INFO: sonobuoy-e2e-job-ed687c3b8a094b84 from heptio-sonobuoy started at 2019-05-21 09:25:47 +0000 UTC (2 container statuses recorded)
May 21 09:34:24.720: INFO: 	Container e2e ready: true, restart count 0
May 21 09:34:24.720: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 21 09:34:24.720: INFO: kube-proxy-pslz8 from kube-system started at 2019-05-21 09:14:12 +0000 UTC (1 container statuses recorded)
May 21 09:34:24.720: INFO: 	Container kube-proxy ready: true, restart count 0
May 21 09:34:24.720: INFO: traefik-ingress-controller-rm4kh from kube-system started at 2019-05-21 09:15:33 +0000 UTC (1 container statuses recorded)
May 21 09:34:24.720: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
May 21 09:34:24.720: INFO: disk-provisioner-7fb7598b96-hxs85 from kube-system started at 2019-05-21 09:15:34 +0000 UTC (1 container statuses recorded)
May 21 09:34:24.720: INFO: 	Container disk-provisioner ready: true, restart count 0
May 21 09:34:24.720: INFO: ksc-flexvolume-ds-5mzbx from kube-system started at 2019-05-21 09:15:31 +0000 UTC (1 container statuses recorded)
May 21 09:34:24.720: INFO: 	Container ksc-flexvolume-ds ready: true, restart count 0
May 21 09:34:24.720: INFO: metrics-server-774c777b9b-xzw2r from kube-system started at 2019-05-21 09:15:33 +0000 UTC (1 container statuses recorded)
May 21 09:34:24.720: INFO: 	Container metrics-server ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15a0a8fa75910bfd], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:34:25.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-6grgz" for this suite.
May 21 09:34:31.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:34:31.801: INFO: namespace: e2e-tests-sched-pred-6grgz, resource: bindings, ignored listing per whitelist
May 21 09:34:31.808: INFO: namespace e2e-tests-sched-pred-6grgz deletion completed in 6.066895239s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:7.143 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:34:31.809: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
May 21 09:34:34.388: INFO: Successfully updated pod "labelsupdatea3293665-7bab-11e9-be4b-6e6d88bcf118"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:34:38.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zxxz6" for this suite.
May 21 09:35:00.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:35:00.444: INFO: namespace: e2e-tests-projected-zxxz6, resource: bindings, ignored listing per whitelist
May 21 09:35:00.478: INFO: namespace e2e-tests-projected-zxxz6 deletion completed in 22.070283702s

• [SLOW TEST:28.669 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:35:00.479: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-b43fc794-7bab-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume configMaps
May 21 09:35:00.529: INFO: Waiting up to 5m0s for pod "pod-configmaps-b4406c66-7bab-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-configmap-ks48z" to be "success or failure"
May 21 09:35:00.532: INFO: Pod "pod-configmaps-b4406c66-7bab-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 2.46549ms
May 21 09:35:02.536: INFO: Pod "pod-configmaps-b4406c66-7bab-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006347296s
STEP: Saw pod success
May 21 09:35:02.536: INFO: Pod "pod-configmaps-b4406c66-7bab-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 09:35:02.538: INFO: Trying to get logs from node 192.168.5.29 pod pod-configmaps-b4406c66-7bab-11e9-be4b-6e6d88bcf118 container configmap-volume-test: <nil>
STEP: delete the pod
May 21 09:35:02.559: INFO: Waiting for pod pod-configmaps-b4406c66-7bab-11e9-be4b-6e6d88bcf118 to disappear
May 21 09:35:02.561: INFO: Pod pod-configmaps-b4406c66-7bab-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:35:02.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ks48z" for this suite.
May 21 09:35:08.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:35:08.619: INFO: namespace: e2e-tests-configmap-ks48z, resource: bindings, ignored listing per whitelist
May 21 09:35:08.625: INFO: namespace e2e-tests-configmap-ks48z deletion completed in 6.061296245s

• [SLOW TEST:8.147 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:35:08.626: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
May 21 09:35:12.682: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-b91ad26b-7bab-11e9-be4b-6e6d88bcf118,GenerateName:,Namespace:e2e-tests-events-f6p68,SelfLink:/api/v1/namespaces/e2e-tests-events-f6p68/pods/send-events-b91ad26b-7bab-11e9-be4b-6e6d88bcf118,UID:b91b4c78-7bab-11e9-acff-fa163e1b1d33,ResourceVersion:3341,Generation:0,CreationTimestamp:2019-05-21 09:35:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 667767465,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cv5nf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cv5nf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-cv5nf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:35:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:35:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:35:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:35:08 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.29,PodIP:10.8.1.38,StartTime:2019-05-21 09:35:08 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-05-21 09:35:11 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://ae7603ce1f59733c72202a6b6cd678fec47cd29d845fff6f06a211a0c0b5d1e0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
May 21 09:35:14.685: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
May 21 09:35:16.689: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:35:16.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-f6p68" for this suite.
May 21 09:35:54.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:35:54.762: INFO: namespace: e2e-tests-events-f6p68, resource: bindings, ignored listing per whitelist
May 21 09:35:54.771: INFO: namespace e2e-tests-events-f6p68 deletion completed in 38.072520142s

• [SLOW TEST:46.145 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:35:54.771: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 21 09:35:54.819: INFO: Waiting up to 5m0s for pod "downward-api-d49bfd85-7bab-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-downward-api-lvdqg" to be "success or failure"
May 21 09:35:54.821: INFO: Pod "downward-api-d49bfd85-7bab-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 1.862961ms
May 21 09:35:56.824: INFO: Pod "downward-api-d49bfd85-7bab-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004761658s
STEP: Saw pod success
May 21 09:35:56.824: INFO: Pod "downward-api-d49bfd85-7bab-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 09:35:56.826: INFO: Trying to get logs from node 192.168.5.29 pod downward-api-d49bfd85-7bab-11e9-be4b-6e6d88bcf118 container dapi-container: <nil>
STEP: delete the pod
May 21 09:35:56.847: INFO: Waiting for pod downward-api-d49bfd85-7bab-11e9-be4b-6e6d88bcf118 to disappear
May 21 09:35:56.849: INFO: Pod downward-api-d49bfd85-7bab-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:35:56.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lvdqg" for this suite.
May 21 09:36:02.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:36:02.915: INFO: namespace: e2e-tests-downward-api-lvdqg, resource: bindings, ignored listing per whitelist
May 21 09:36:02.940: INFO: namespace e2e-tests-downward-api-lvdqg deletion completed in 6.085981381s

• [SLOW TEST:8.169 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:36:02.940: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-zngpk
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
May 21 09:36:03.013: INFO: Found 1 stateful pods, waiting for 3
May 21 09:36:13.018: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 21 09:36:13.018: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 21 09:36:13.018: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
May 21 09:36:13.042: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
May 21 09:36:23.069: INFO: Updating stateful set ss2
May 21 09:36:23.076: INFO: Waiting for Pod e2e-tests-statefulset-zngpk/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
May 21 09:36:33.082: INFO: Waiting for Pod e2e-tests-statefulset-zngpk/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
May 21 09:36:43.111: INFO: Found 2 stateful pods, waiting for 3
May 21 09:36:53.115: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 21 09:36:53.115: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 21 09:36:53.115: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
May 21 09:37:03.115: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 21 09:37:03.115: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 21 09:37:03.115: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
May 21 09:37:13.114: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 21 09:37:13.114: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 21 09:37:13.114: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
May 21 09:37:13.136: INFO: Updating stateful set ss2
May 21 09:37:13.140: INFO: Waiting for Pod e2e-tests-statefulset-zngpk/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
May 21 09:37:23.147: INFO: Waiting for Pod e2e-tests-statefulset-zngpk/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
May 21 09:37:33.163: INFO: Updating stateful set ss2
May 21 09:37:33.180: INFO: Waiting for StatefulSet e2e-tests-statefulset-zngpk/ss2 to complete update
May 21 09:37:33.180: INFO: Waiting for Pod e2e-tests-statefulset-zngpk/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
May 21 09:37:43.186: INFO: Waiting for StatefulSet e2e-tests-statefulset-zngpk/ss2 to complete update
May 21 09:37:43.186: INFO: Waiting for Pod e2e-tests-statefulset-zngpk/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 21 09:37:53.186: INFO: Deleting all statefulset in ns e2e-tests-statefulset-zngpk
May 21 09:37:53.188: INFO: Scaling statefulset ss2 to 0
May 21 09:38:33.199: INFO: Waiting for statefulset status.replicas updated to 0
May 21 09:38:33.201: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:38:33.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-zngpk" for this suite.
May 21 09:38:39.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:38:39.246: INFO: namespace: e2e-tests-statefulset-zngpk, resource: bindings, ignored listing per whitelist
May 21 09:38:39.277: INFO: namespace e2e-tests-statefulset-zngpk deletion completed in 6.06252987s

• [SLOW TEST:156.337 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:38:39.277: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:38:45.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-8b8qw" for this suite.
May 21 09:38:51.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:38:51.399: INFO: namespace: e2e-tests-namespaces-8b8qw, resource: bindings, ignored listing per whitelist
May 21 09:38:51.439: INFO: namespace e2e-tests-namespaces-8b8qw deletion completed in 6.072033608s
STEP: Destroying namespace "e2e-tests-nsdeletetest-b2xw5" for this suite.
May 21 09:38:51.441: INFO: Namespace e2e-tests-nsdeletetest-b2xw5 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-7mpz5" for this suite.
May 21 09:38:57.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:38:57.494: INFO: namespace: e2e-tests-nsdeletetest-7mpz5, resource: bindings, ignored listing per whitelist
May 21 09:38:57.504: INFO: namespace e2e-tests-nsdeletetest-7mpz5 deletion completed in 6.063006847s

• [SLOW TEST:18.226 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:38:57.504: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
May 21 09:39:00.074: INFO: Successfully updated pod "annotationupdate4186f0e6-7bac-11e9-be4b-6e6d88bcf118"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:39:02.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bksz4" for this suite.
May 21 09:39:24.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:39:24.114: INFO: namespace: e2e-tests-projected-bksz4, resource: bindings, ignored listing per whitelist
May 21 09:39:24.161: INFO: namespace e2e-tests-projected-bksz4 deletion completed in 22.07178681s

• [SLOW TEST:26.657 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:39:24.161: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 21 09:39:24.207: INFO: Waiting up to 5m0s for pod "downward-api-516a1d0c-7bac-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-downward-api-s2f7w" to be "success or failure"
May 21 09:39:24.210: INFO: Pod "downward-api-516a1d0c-7bac-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 3.521657ms
May 21 09:39:26.213: INFO: Pod "downward-api-516a1d0c-7bac-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00616135s
STEP: Saw pod success
May 21 09:39:26.213: INFO: Pod "downward-api-516a1d0c-7bac-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 09:39:26.214: INFO: Trying to get logs from node 192.168.5.29 pod downward-api-516a1d0c-7bac-11e9-be4b-6e6d88bcf118 container dapi-container: <nil>
STEP: delete the pod
May 21 09:39:26.228: INFO: Waiting for pod downward-api-516a1d0c-7bac-11e9-be4b-6e6d88bcf118 to disappear
May 21 09:39:26.230: INFO: Pod downward-api-516a1d0c-7bac-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:39:26.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-s2f7w" for this suite.
May 21 09:39:32.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:39:32.285: INFO: namespace: e2e-tests-downward-api-s2f7w, resource: bindings, ignored listing per whitelist
May 21 09:39:32.295: INFO: namespace e2e-tests-downward-api-s2f7w deletion completed in 6.062878396s

• [SLOW TEST:8.134 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:39:32.296: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
May 21 09:39:32.342: INFO: Waiting up to 5m0s for pod "pod-564390f6-7bac-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-emptydir-6qrwj" to be "success or failure"
May 21 09:39:32.344: INFO: Pod "pod-564390f6-7bac-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 1.614586ms
May 21 09:39:34.347: INFO: Pod "pod-564390f6-7bac-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004645858s
STEP: Saw pod success
May 21 09:39:34.347: INFO: Pod "pod-564390f6-7bac-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 09:39:34.348: INFO: Trying to get logs from node 192.168.5.29 pod pod-564390f6-7bac-11e9-be4b-6e6d88bcf118 container test-container: <nil>
STEP: delete the pod
May 21 09:39:34.367: INFO: Waiting for pod pod-564390f6-7bac-11e9-be4b-6e6d88bcf118 to disappear
May 21 09:39:34.368: INFO: Pod pod-564390f6-7bac-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:39:34.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6qrwj" for this suite.
May 21 09:39:40.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:39:40.415: INFO: namespace: e2e-tests-emptydir-6qrwj, resource: bindings, ignored listing per whitelist
May 21 09:39:40.436: INFO: namespace e2e-tests-emptydir-6qrwj deletion completed in 6.064805729s

• [SLOW TEST:8.140 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:39:40.436: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 09:39:40.485: INFO: Pod name rollover-pod: Found 0 pods out of 1
May 21 09:39:45.489: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 21 09:39:45.489: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
May 21 09:39:47.492: INFO: Creating deployment "test-rollover-deployment"
May 21 09:39:47.498: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
May 21 09:39:49.503: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
May 21 09:39:49.507: INFO: Ensure that both replica sets have 1 created replica
May 21 09:39:49.510: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
May 21 09:39:49.514: INFO: Updating deployment test-rollover-deployment
May 21 09:39:49.514: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
May 21 09:39:51.519: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
May 21 09:39:51.523: INFO: Make sure deployment "test-rollover-deployment" is complete
May 21 09:39:51.528: INFO: all replica sets need to contain the pod-template-hash label
May 21 09:39:51.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694028387, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694028387, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694028389, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694028387, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 21 09:39:53.534: INFO: all replica sets need to contain the pod-template-hash label
May 21 09:39:53.534: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694028387, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694028387, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694028392, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694028387, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 21 09:39:55.534: INFO: all replica sets need to contain the pod-template-hash label
May 21 09:39:55.534: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694028387, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694028387, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694028392, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694028387, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 21 09:39:57.533: INFO: all replica sets need to contain the pod-template-hash label
May 21 09:39:57.533: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694028387, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694028387, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694028392, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694028387, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 21 09:39:59.533: INFO: all replica sets need to contain the pod-template-hash label
May 21 09:39:59.533: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694028387, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694028387, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694028392, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694028387, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 21 09:40:01.534: INFO: all replica sets need to contain the pod-template-hash label
May 21 09:40:01.534: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694028387, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694028387, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694028392, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694028387, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 21 09:40:03.534: INFO: 
May 21 09:40:03.534: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 21 09:40:03.539: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-tbk67,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-tbk67/deployments/test-rollover-deployment,UID:5f4ce6dc-7bac-11e9-acff-fa163e1b1d33,ResourceVersion:4221,Generation:2,CreationTimestamp:2019-05-21 09:39:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-21 09:39:47 +0000 UTC 2019-05-21 09:39:47 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-21 09:40:02 +0000 UTC 2019-05-21 09:39:47 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 21 09:40:03.542: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-tbk67,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-tbk67/replicasets/test-rollover-deployment-5b76ff8c4,UID:60814fd2-7bac-11e9-8d66-fa163e76243a,ResourceVersion:4212,Generation:2,CreationTimestamp:2019-05-21 09:39:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 5f4ce6dc-7bac-11e9-acff-fa163e1b1d33 0xc4206c0e57 0xc4206c0e58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 21 09:40:03.542: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
May 21 09:40:03.542: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-tbk67,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-tbk67/replicasets/test-rollover-controller,UID:5b1eb001-7bac-11e9-acff-fa163e1b1d33,ResourceVersion:4220,Generation:2,CreationTimestamp:2019-05-21 09:39:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 5f4ce6dc-7bac-11e9-acff-fa163e1b1d33 0xc4206c0d87 0xc4206c0d88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 21 09:40:03.542: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-tbk67,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-tbk67/replicasets/test-rollover-deployment-6975f4fb87,UID:5f4e5c72-7bac-11e9-8d66-fa163e76243a,ResourceVersion:4181,Generation:2,CreationTimestamp:2019-05-21 09:39:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 5f4ce6dc-7bac-11e9-acff-fa163e1b1d33 0xc4206c0f77 0xc4206c0f78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 21 09:40:03.545: INFO: Pod "test-rollover-deployment-5b76ff8c4-6dr4z" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-6dr4z,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-tbk67,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tbk67/pods/test-rollover-deployment-5b76ff8c4-6dr4z,UID:6083eb19-7bac-11e9-8d66-fa163e76243a,ResourceVersion:4195,Generation:0,CreationTimestamp:2019-05-21 09:39:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 60814fd2-7bac-11e9-8d66-fa163e76243a 0xc4207943c0 0xc4207943c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hf2z2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hf2z2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-hf2z2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:39:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:39:52 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:39:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:39:49 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.29,PodIP:10.8.1.56,StartTime:2019-05-21 09:39:49 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-21 09:39:52 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://916d23099797b652fbce86d6df4e9ab7c2c5f6ff77729324adbf9cddb15acc85}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:40:03.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-tbk67" for this suite.
May 21 09:40:09.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:40:09.584: INFO: namespace: e2e-tests-deployment-tbk67, resource: bindings, ignored listing per whitelist
May 21 09:40:09.612: INFO: namespace e2e-tests-deployment-tbk67 deletion completed in 6.064041811s

• [SLOW TEST:29.176 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:40:09.612: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-6c815c41-7bac-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume configMaps
May 21 09:40:09.659: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6c81e40e-7bac-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-projected-9wwdm" to be "success or failure"
May 21 09:40:09.662: INFO: Pod "pod-projected-configmaps-6c81e40e-7bac-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 3.116023ms
May 21 09:40:11.664: INFO: Pod "pod-projected-configmaps-6c81e40e-7bac-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005586301s
STEP: Saw pod success
May 21 09:40:11.664: INFO: Pod "pod-projected-configmaps-6c81e40e-7bac-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 09:40:11.666: INFO: Trying to get logs from node 192.168.5.29 pod pod-projected-configmaps-6c81e40e-7bac-11e9-be4b-6e6d88bcf118 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 09:40:11.680: INFO: Waiting for pod pod-projected-configmaps-6c81e40e-7bac-11e9-be4b-6e6d88bcf118 to disappear
May 21 09:40:11.681: INFO: Pod pod-projected-configmaps-6c81e40e-7bac-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:40:11.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9wwdm" for this suite.
May 21 09:40:17.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:40:17.717: INFO: namespace: e2e-tests-projected-9wwdm, resource: bindings, ignored listing per whitelist
May 21 09:40:17.743: INFO: namespace e2e-tests-projected-9wwdm deletion completed in 6.058852752s

• [SLOW TEST:8.130 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:40:17.743: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
May 21 09:40:17.786: INFO: Waiting up to 5m0s for pod "var-expansion-7159df6e-7bac-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-var-expansion-p4pkw" to be "success or failure"
May 21 09:40:17.789: INFO: Pod "var-expansion-7159df6e-7bac-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 3.063663ms
May 21 09:40:19.792: INFO: Pod "var-expansion-7159df6e-7bac-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006088945s
STEP: Saw pod success
May 21 09:40:19.792: INFO: Pod "var-expansion-7159df6e-7bac-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 09:40:19.794: INFO: Trying to get logs from node 192.168.5.29 pod var-expansion-7159df6e-7bac-11e9-be4b-6e6d88bcf118 container dapi-container: <nil>
STEP: delete the pod
May 21 09:40:19.804: INFO: Waiting for pod var-expansion-7159df6e-7bac-11e9-be4b-6e6d88bcf118 to disappear
May 21 09:40:19.806: INFO: Pod var-expansion-7159df6e-7bac-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:40:19.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-p4pkw" for this suite.
May 21 09:40:25.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:40:25.868: INFO: namespace: e2e-tests-var-expansion-p4pkw, resource: bindings, ignored listing per whitelist
May 21 09:40:25.871: INFO: namespace e2e-tests-var-expansion-p4pkw deletion completed in 6.061398967s

• [SLOW TEST:8.128 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:40:25.871: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
May 21 09:40:25.913: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 21 09:40:25.920: INFO: Waiting for terminating namespaces to be deleted...
May 21 09:40:25.921: INFO: 
Logging pods the kubelet thinks is on node 192.168.5.29 before test
May 21 09:40:25.926: INFO: kube-proxy-pslz8 from kube-system started at 2019-05-21 09:14:12 +0000 UTC (1 container statuses recorded)
May 21 09:40:25.926: INFO: 	Container kube-proxy ready: true, restart count 0
May 21 09:40:25.926: INFO: traefik-ingress-controller-rm4kh from kube-system started at 2019-05-21 09:15:33 +0000 UTC (1 container statuses recorded)
May 21 09:40:25.926: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
May 21 09:40:25.926: INFO: disk-provisioner-7fb7598b96-hxs85 from kube-system started at 2019-05-21 09:15:34 +0000 UTC (1 container statuses recorded)
May 21 09:40:25.926: INFO: 	Container disk-provisioner ready: true, restart count 0
May 21 09:40:25.926: INFO: ksc-flexvolume-ds-5mzbx from kube-system started at 2019-05-21 09:15:31 +0000 UTC (1 container statuses recorded)
May 21 09:40:25.926: INFO: 	Container ksc-flexvolume-ds ready: true, restart count 0
May 21 09:40:25.926: INFO: metrics-server-774c777b9b-xzw2r from kube-system started at 2019-05-21 09:15:33 +0000 UTC (1 container statuses recorded)
May 21 09:40:25.926: INFO: 	Container metrics-server ready: true, restart count 0
May 21 09:40:25.926: INFO: coredns-57cddf5944-w8t7z from kube-system started at 2019-05-21 09:15:17 +0000 UTC (1 container statuses recorded)
May 21 09:40:25.926: INFO: 	Container coredns ready: true, restart count 0
May 21 09:40:25.926: INFO: coredns-57cddf5944-ggdnt from kube-system started at 2019-05-21 09:15:17 +0000 UTC (1 container statuses recorded)
May 21 09:40:25.926: INFO: 	Container coredns ready: true, restart count 0
May 21 09:40:25.926: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-21 09:25:36 +0000 UTC (1 container statuses recorded)
May 21 09:40:25.926: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 21 09:40:25.926: INFO: sonobuoy-systemd-logs-daemon-set-8150fbd9d34045a3-ddhtz from heptio-sonobuoy started at 2019-05-21 09:25:47 +0000 UTC (2 container statuses recorded)
May 21 09:40:25.926: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 21 09:40:25.926: INFO: 	Container systemd-logs ready: true, restart count 0
May 21 09:40:25.926: INFO: kube-flannel-w6rtw from kube-system started at 2019-05-21 09:14:18 +0000 UTC (2 container statuses recorded)
May 21 09:40:25.926: INFO: 	Container install-cni ready: true, restart count 0
May 21 09:40:25.926: INFO: 	Container kube-flannel ready: true, restart count 3
May 21 09:40:25.926: INFO: cloud-controller-manager-5b95856974-d6bg8 from kube-system started at 2019-05-21 09:15:33 +0000 UTC (1 container statuses recorded)
May 21 09:40:25.926: INFO: 	Container cloud-controller-manager ready: true, restart count 0
May 21 09:40:25.926: INFO: sonobuoy-e2e-job-ed687c3b8a094b84 from heptio-sonobuoy started at 2019-05-21 09:25:47 +0000 UTC (2 container statuses recorded)
May 21 09:40:25.926: INFO: 	Container e2e ready: true, restart count 0
May 21 09:40:25.926: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-77685763-7bac-11e9-be4b-6e6d88bcf118 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-77685763-7bac-11e9-be4b-6e6d88bcf118 off the node 192.168.5.29
STEP: verifying the node doesn't have the label kubernetes.io/e2e-77685763-7bac-11e9-be4b-6e6d88bcf118
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:40:29.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-hqn4r" for this suite.
May 21 09:40:47.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:40:48.038: INFO: namespace: e2e-tests-sched-pred-hqn4r, resource: bindings, ignored listing per whitelist
May 21 09:40:48.040: INFO: namespace e2e-tests-sched-pred-hqn4r deletion completed in 18.064835901s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:22.169 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:40:48.041: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
May 21 09:40:50.100: INFO: Pod pod-hostip-836a023d-7bac-11e9-be4b-6e6d88bcf118 has hostIP: 192.168.5.29
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:40:50.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-9cpdc" for this suite.
May 21 09:41:12.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:41:12.133: INFO: namespace: e2e-tests-pods-9cpdc, resource: bindings, ignored listing per whitelist
May 21 09:41:12.168: INFO: namespace e2e-tests-pods-9cpdc deletion completed in 22.065486852s

• [SLOW TEST:24.127 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:41:12.168: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 09:41:12.220: INFO: Waiting up to 5m0s for pod "downwardapi-volume-91cbb551-7bac-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-projected-4zhnj" to be "success or failure"
May 21 09:41:12.224: INFO: Pod "downwardapi-volume-91cbb551-7bac-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 3.338012ms
May 21 09:41:14.227: INFO: Pod "downwardapi-volume-91cbb551-7bac-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006402651s
STEP: Saw pod success
May 21 09:41:14.227: INFO: Pod "downwardapi-volume-91cbb551-7bac-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 09:41:14.229: INFO: Trying to get logs from node 192.168.5.29 pod downwardapi-volume-91cbb551-7bac-11e9-be4b-6e6d88bcf118 container client-container: <nil>
STEP: delete the pod
May 21 09:41:14.243: INFO: Waiting for pod downwardapi-volume-91cbb551-7bac-11e9-be4b-6e6d88bcf118 to disappear
May 21 09:41:14.245: INFO: Pod downwardapi-volume-91cbb551-7bac-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:41:14.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4zhnj" for this suite.
May 21 09:41:20.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:41:20.269: INFO: namespace: e2e-tests-projected-4zhnj, resource: bindings, ignored listing per whitelist
May 21 09:41:20.312: INFO: namespace e2e-tests-projected-4zhnj deletion completed in 6.064073306s

• [SLOW TEST:8.144 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:41:20.312: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-96a5a279-7bac-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume secrets
May 21 09:41:20.360: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-96a626d4-7bac-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-projected-w6b24" to be "success or failure"
May 21 09:41:20.362: INFO: Pod "pod-projected-secrets-96a626d4-7bac-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 1.600989ms
May 21 09:41:22.365: INFO: Pod "pod-projected-secrets-96a626d4-7bac-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004685881s
STEP: Saw pod success
May 21 09:41:22.365: INFO: Pod "pod-projected-secrets-96a626d4-7bac-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 09:41:22.367: INFO: Trying to get logs from node 192.168.5.29 pod pod-projected-secrets-96a626d4-7bac-11e9-be4b-6e6d88bcf118 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 21 09:41:22.378: INFO: Waiting for pod pod-projected-secrets-96a626d4-7bac-11e9-be4b-6e6d88bcf118 to disappear
May 21 09:41:22.380: INFO: Pod pod-projected-secrets-96a626d4-7bac-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:41:22.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-w6b24" for this suite.
May 21 09:41:28.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:41:28.418: INFO: namespace: e2e-tests-projected-w6b24, resource: bindings, ignored listing per whitelist
May 21 09:41:28.444: INFO: namespace e2e-tests-projected-w6b24 deletion completed in 6.061684237s

• [SLOW TEST:8.132 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:41:28.444: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0521 09:41:29.516669      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 21 09:41:29.516: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:41:29.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-h8qpt" for this suite.
May 21 09:41:35.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:41:35.558: INFO: namespace: e2e-tests-gc-h8qpt, resource: bindings, ignored listing per whitelist
May 21 09:41:35.583: INFO: namespace e2e-tests-gc-h8qpt deletion completed in 6.065028655s

• [SLOW TEST:7.139 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:41:35.584: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-pcl4w
May 21 09:41:37.633: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-pcl4w
STEP: checking the pod's current state and verifying that restartCount is present
May 21 09:41:37.634: INFO: Initial restart count of pod liveness-http is 0
May 21 09:41:59.665: INFO: Restart count of pod e2e-tests-container-probe-pcl4w/liveness-http is now 1 (22.030273983s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:41:59.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-pcl4w" for this suite.
May 21 09:42:05.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:42:05.701: INFO: namespace: e2e-tests-container-probe-pcl4w, resource: bindings, ignored listing per whitelist
May 21 09:42:05.743: INFO: namespace e2e-tests-container-probe-pcl4w deletion completed in 6.064159474s

• [SLOW TEST:30.159 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:42:05.743: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-b1ba13f3-7bac-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume configMaps
May 21 09:42:05.794: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b1bab24b-7bac-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-projected-tdlxg" to be "success or failure"
May 21 09:42:05.797: INFO: Pod "pod-projected-configmaps-b1bab24b-7bac-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 2.758541ms
May 21 09:42:07.799: INFO: Pod "pod-projected-configmaps-b1bab24b-7bac-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005343473s
STEP: Saw pod success
May 21 09:42:07.799: INFO: Pod "pod-projected-configmaps-b1bab24b-7bac-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 09:42:07.802: INFO: Trying to get logs from node 192.168.5.29 pod pod-projected-configmaps-b1bab24b-7bac-11e9-be4b-6e6d88bcf118 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 09:42:07.816: INFO: Waiting for pod pod-projected-configmaps-b1bab24b-7bac-11e9-be4b-6e6d88bcf118 to disappear
May 21 09:42:07.818: INFO: Pod pod-projected-configmaps-b1bab24b-7bac-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:42:07.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tdlxg" for this suite.
May 21 09:42:13.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:42:13.849: INFO: namespace: e2e-tests-projected-tdlxg, resource: bindings, ignored listing per whitelist
May 21 09:42:13.889: INFO: namespace e2e-tests-projected-tdlxg deletion completed in 6.068137617s

• [SLOW TEST:8.146 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:42:13.889: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-b694ccbe-7bac-11e9-be4b-6e6d88bcf118
STEP: Creating secret with name s-test-opt-upd-b694cd00-7bac-11e9-be4b-6e6d88bcf118
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-b694ccbe-7bac-11e9-be4b-6e6d88bcf118
STEP: Updating secret s-test-opt-upd-b694cd00-7bac-11e9-be4b-6e6d88bcf118
STEP: Creating secret with name s-test-opt-create-b694cd10-7bac-11e9-be4b-6e6d88bcf118
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:42:20.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-x6gbt" for this suite.
May 21 09:42:42.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:42:42.033: INFO: namespace: e2e-tests-secrets-x6gbt, resource: bindings, ignored listing per whitelist
May 21 09:42:42.084: INFO: namespace e2e-tests-secrets-x6gbt deletion completed in 22.076069194s

• [SLOW TEST:28.195 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:42:42.084: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-c7623ee9-7bac-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume secrets
May 21 09:42:42.129: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c762fe56-7bac-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-projected-tvjzt" to be "success or failure"
May 21 09:42:42.131: INFO: Pod "pod-projected-secrets-c762fe56-7bac-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 1.630538ms
May 21 09:42:44.133: INFO: Pod "pod-projected-secrets-c762fe56-7bac-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004144844s
STEP: Saw pod success
May 21 09:42:44.133: INFO: Pod "pod-projected-secrets-c762fe56-7bac-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 09:42:44.135: INFO: Trying to get logs from node 192.168.5.29 pod pod-projected-secrets-c762fe56-7bac-11e9-be4b-6e6d88bcf118 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 21 09:42:44.151: INFO: Waiting for pod pod-projected-secrets-c762fe56-7bac-11e9-be4b-6e6d88bcf118 to disappear
May 21 09:42:44.152: INFO: Pod pod-projected-secrets-c762fe56-7bac-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:42:44.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tvjzt" for this suite.
May 21 09:42:50.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:42:50.211: INFO: namespace: e2e-tests-projected-tvjzt, resource: bindings, ignored listing per whitelist
May 21 09:42:50.217: INFO: namespace e2e-tests-projected-tvjzt deletion completed in 6.062103517s

• [SLOW TEST:8.133 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:42:50.218: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 21 09:42:50.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-8ksp9'
May 21 09:42:50.440: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
May 21 09:42:50.441: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
May 21 09:42:50.444: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
May 21 09:42:50.466: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
May 21 09:42:50.495: INFO: scanned /root for discovery docs: <nil>
May 21 09:42:50.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-8ksp9'
May 21 09:43:06.266: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 21 09:43:06.266: INFO: stdout: "Created e2e-test-nginx-rc-bb713e1403c58f282bfaa9ece53d560e\nScaling up e2e-test-nginx-rc-bb713e1403c58f282bfaa9ece53d560e from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-bb713e1403c58f282bfaa9ece53d560e up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-bb713e1403c58f282bfaa9ece53d560e to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
May 21 09:43:06.266: INFO: stdout: "Created e2e-test-nginx-rc-bb713e1403c58f282bfaa9ece53d560e\nScaling up e2e-test-nginx-rc-bb713e1403c58f282bfaa9ece53d560e from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-bb713e1403c58f282bfaa9ece53d560e up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-bb713e1403c58f282bfaa9ece53d560e to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
May 21 09:43:06.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-8ksp9'
May 21 09:43:06.360: INFO: stderr: ""
May 21 09:43:06.360: INFO: stdout: "e2e-test-nginx-rc-bb713e1403c58f282bfaa9ece53d560e-6kvht "
May 21 09:43:06.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods e2e-test-nginx-rc-bb713e1403c58f282bfaa9ece53d560e-6kvht -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8ksp9'
May 21 09:43:06.441: INFO: stderr: ""
May 21 09:43:06.441: INFO: stdout: "true"
May 21 09:43:06.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods e2e-test-nginx-rc-bb713e1403c58f282bfaa9ece53d560e-6kvht -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8ksp9'
May 21 09:43:06.524: INFO: stderr: ""
May 21 09:43:06.524: INFO: stdout: "nginx:1.14-alpine"
May 21 09:43:06.524: INFO: e2e-test-nginx-rc-bb713e1403c58f282bfaa9ece53d560e-6kvht is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
May 21 09:43:06.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-8ksp9'
May 21 09:43:06.608: INFO: stderr: ""
May 21 09:43:06.608: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:43:06.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8ksp9" for this suite.
May 21 09:43:12.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:43:12.656: INFO: namespace: e2e-tests-kubectl-8ksp9, resource: bindings, ignored listing per whitelist
May 21 09:43:12.678: INFO: namespace e2e-tests-kubectl-8ksp9 deletion completed in 6.064201983s

• [SLOW TEST:22.460 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:43:12.678: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 09:43:12.720: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
May 21 09:43:12.726: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-7jbdp/daemonsets","resourceVersion":"4969"},"items":null}

May 21 09:43:12.728: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-7jbdp/pods","resourceVersion":"4969"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:43:12.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-7jbdp" for this suite.
May 21 09:43:18.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:43:18.789: INFO: namespace: e2e-tests-daemonsets-7jbdp, resource: bindings, ignored listing per whitelist
May 21 09:43:18.795: INFO: namespace e2e-tests-daemonsets-7jbdp deletion completed in 6.060931654s

S [SKIPPING] [6.117 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  May 21 09:43:12.720: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:43:18.795: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 21 09:43:18.836: INFO: Waiting up to 5m0s for pod "downward-api-dd43d3fe-7bac-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-downward-api-77nhl" to be "success or failure"
May 21 09:43:18.838: INFO: Pod "downward-api-dd43d3fe-7bac-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 2.142563ms
May 21 09:43:20.841: INFO: Pod "downward-api-dd43d3fe-7bac-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005289409s
STEP: Saw pod success
May 21 09:43:20.841: INFO: Pod "downward-api-dd43d3fe-7bac-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 09:43:20.843: INFO: Trying to get logs from node 192.168.5.29 pod downward-api-dd43d3fe-7bac-11e9-be4b-6e6d88bcf118 container dapi-container: <nil>
STEP: delete the pod
May 21 09:43:20.854: INFO: Waiting for pod downward-api-dd43d3fe-7bac-11e9-be4b-6e6d88bcf118 to disappear
May 21 09:43:20.855: INFO: Pod downward-api-dd43d3fe-7bac-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:43:20.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-77nhl" for this suite.
May 21 09:43:26.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:43:26.887: INFO: namespace: e2e-tests-downward-api-77nhl, resource: bindings, ignored listing per whitelist
May 21 09:43:26.918: INFO: namespace e2e-tests-downward-api-77nhl deletion completed in 6.059819692s

• [SLOW TEST:8.123 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:43:26.918: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 09:43:26.965: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e21c3ed1-7bac-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-downward-api-pm8x5" to be "success or failure"
May 21 09:43:26.970: INFO: Pod "downwardapi-volume-e21c3ed1-7bac-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 5.144173ms
May 21 09:43:28.973: INFO: Pod "downwardapi-volume-e21c3ed1-7bac-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007609563s
STEP: Saw pod success
May 21 09:43:28.973: INFO: Pod "downwardapi-volume-e21c3ed1-7bac-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 09:43:28.974: INFO: Trying to get logs from node 192.168.5.29 pod downwardapi-volume-e21c3ed1-7bac-11e9-be4b-6e6d88bcf118 container client-container: <nil>
STEP: delete the pod
May 21 09:43:28.988: INFO: Waiting for pod downwardapi-volume-e21c3ed1-7bac-11e9-be4b-6e6d88bcf118 to disappear
May 21 09:43:28.990: INFO: Pod downwardapi-volume-e21c3ed1-7bac-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:43:28.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pm8x5" for this suite.
May 21 09:43:35.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:43:35.036: INFO: namespace: e2e-tests-downward-api-pm8x5, resource: bindings, ignored listing per whitelist
May 21 09:43:35.057: INFO: namespace e2e-tests-downward-api-pm8x5 deletion completed in 6.064194185s

• [SLOW TEST:8.139 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:43:35.057: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-e6f6b7c4-7bac-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume secrets
May 21 09:43:35.111: INFO: Waiting up to 5m0s for pod "pod-secrets-e6f762e1-7bac-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-secrets-7xhng" to be "success or failure"
May 21 09:43:35.114: INFO: Pod "pod-secrets-e6f762e1-7bac-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 2.940889ms
May 21 09:43:37.117: INFO: Pod "pod-secrets-e6f762e1-7bac-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005904836s
STEP: Saw pod success
May 21 09:43:37.117: INFO: Pod "pod-secrets-e6f762e1-7bac-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 09:43:37.118: INFO: Trying to get logs from node 192.168.5.29 pod pod-secrets-e6f762e1-7bac-11e9-be4b-6e6d88bcf118 container secret-volume-test: <nil>
STEP: delete the pod
May 21 09:43:37.131: INFO: Waiting for pod pod-secrets-e6f762e1-7bac-11e9-be4b-6e6d88bcf118 to disappear
May 21 09:43:37.133: INFO: Pod pod-secrets-e6f762e1-7bac-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:43:37.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-7xhng" for this suite.
May 21 09:43:43.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:43:43.173: INFO: namespace: e2e-tests-secrets-7xhng, resource: bindings, ignored listing per whitelist
May 21 09:43:43.201: INFO: namespace e2e-tests-secrets-7xhng deletion completed in 6.064370387s

• [SLOW TEST:8.144 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:43:43.201: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-ebd02902-7bac-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume secrets
May 21 09:43:43.246: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ebd0ab6c-7bac-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-projected-wztr4" to be "success or failure"
May 21 09:43:43.247: INFO: Pod "pod-projected-secrets-ebd0ab6c-7bac-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 1.91341ms
May 21 09:43:45.250: INFO: Pod "pod-projected-secrets-ebd0ab6c-7bac-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004210442s
STEP: Saw pod success
May 21 09:43:45.250: INFO: Pod "pod-projected-secrets-ebd0ab6c-7bac-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 09:43:45.251: INFO: Trying to get logs from node 192.168.5.29 pod pod-projected-secrets-ebd0ab6c-7bac-11e9-be4b-6e6d88bcf118 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 21 09:43:45.265: INFO: Waiting for pod pod-projected-secrets-ebd0ab6c-7bac-11e9-be4b-6e6d88bcf118 to disappear
May 21 09:43:45.267: INFO: Pod pod-projected-secrets-ebd0ab6c-7bac-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:43:45.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wztr4" for this suite.
May 21 09:43:51.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:43:51.295: INFO: namespace: e2e-tests-projected-wztr4, resource: bindings, ignored listing per whitelist
May 21 09:43:51.323: INFO: namespace e2e-tests-projected-wztr4 deletion completed in 6.053749581s

• [SLOW TEST:8.122 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:43:51.323: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-5tqq7 in namespace e2e-tests-proxy-pg292
I0521 09:43:51.368974      15 runners.go:180] Created replication controller with name: proxy-service-5tqq7, namespace: e2e-tests-proxy-pg292, replica count: 1
I0521 09:43:52.419334      15 runners.go:180] proxy-service-5tqq7 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0521 09:43:53.419515      15 runners.go:180] proxy-service-5tqq7 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0521 09:43:54.419684      15 runners.go:180] proxy-service-5tqq7 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0521 09:43:55.419833      15 runners.go:180] proxy-service-5tqq7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0521 09:43:56.419973      15 runners.go:180] proxy-service-5tqq7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0521 09:43:57.420124      15 runners.go:180] proxy-service-5tqq7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0521 09:43:58.420264      15 runners.go:180] proxy-service-5tqq7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0521 09:43:59.420418      15 runners.go:180] proxy-service-5tqq7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0521 09:44:00.420560      15 runners.go:180] proxy-service-5tqq7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0521 09:44:01.420732      15 runners.go:180] proxy-service-5tqq7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0521 09:44:02.420884      15 runners.go:180] proxy-service-5tqq7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0521 09:44:03.421176      15 runners.go:180] proxy-service-5tqq7 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 21 09:44:03.423: INFO: setup took 12.066012449s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
May 21 09:44:03.437: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/rewriteme"... (200; 13.486763ms)
May 21 09:44:03.437: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 13.867342ms)
May 21 09:44:03.441: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname2/proxy/: tls qux (200; 17.373034ms)
May 21 09:44:03.441: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:460/proxy/: tls baz (200; 17.555197ms)
May 21 09:44:03.441: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/... (200; 16.851528ms)
May 21 09:44:03.441: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname2/proxy/: bar (200; 17.154386ms)
May 21 09:44:03.441: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname2/proxy/: bar (200; 17.104211ms)
May 21 09:44:03.441: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 17.051484ms)
May 21 09:44:03.441: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/... (200; 17.732382ms)
May 21 09:44:03.441: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/rewri... (200; 17.017269ms)
May 21 09:44:03.441: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname1/proxy/: foo (200; 17.300725ms)
May 21 09:44:03.441: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname1/proxy/: foo (200; 17.380997ms)
May 21 09:44:03.441: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 17.463068ms)
May 21 09:44:03.441: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 16.93295ms)
May 21 09:44:03.441: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:462/proxy/: tls qux (200; 18.015345ms)
May 21 09:44:03.443: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname1/proxy/: tls baz (200; 19.364638ms)
May 21 09:44:03.446: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:460/proxy/: tls baz (200; 2.407434ms)
May 21 09:44:03.446: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 2.853164ms)
May 21 09:44:03.447: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/... (200; 3.321062ms)
May 21 09:44:03.447: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname1/proxy/: foo (200; 3.369726ms)
May 21 09:44:03.447: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/rewriteme"... (200; 3.231876ms)
May 21 09:44:03.447: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 3.646793ms)
May 21 09:44:03.447: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname2/proxy/: bar (200; 4.022638ms)
May 21 09:44:03.448: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname2/proxy/: bar (200; 4.692369ms)
May 21 09:44:03.448: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 4.401473ms)
May 21 09:44:03.448: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname1/proxy/: tls baz (200; 4.737843ms)
May 21 09:44:03.448: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 4.362858ms)
May 21 09:44:03.448: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/... (200; 4.519698ms)
May 21 09:44:03.448: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname1/proxy/: foo (200; 4.630726ms)
May 21 09:44:03.448: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname2/proxy/: tls qux (200; 4.837438ms)
May 21 09:44:03.449: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/rewri... (200; 4.803892ms)
May 21 09:44:03.449: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:462/proxy/: tls qux (200; 4.931747ms)
May 21 09:44:03.451: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/rewri... (200; 1.970874ms)
May 21 09:44:03.451: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 2.192328ms)
May 21 09:44:03.452: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/... (200; 2.889986ms)
May 21 09:44:03.453: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:460/proxy/: tls baz (200; 3.37282ms)
May 21 09:44:03.453: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/... (200; 3.738716ms)
May 21 09:44:03.453: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/rewriteme"... (200; 3.950283ms)
May 21 09:44:03.454: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:462/proxy/: tls qux (200; 4.517174ms)
May 21 09:44:03.454: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 4.622147ms)
May 21 09:44:03.454: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 4.392379ms)
May 21 09:44:03.454: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 4.89046ms)
May 21 09:44:03.455: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname2/proxy/: tls qux (200; 5.719132ms)
May 21 09:44:03.456: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname1/proxy/: tls baz (200; 6.691372ms)
May 21 09:44:03.456: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname2/proxy/: bar (200; 6.841804ms)
May 21 09:44:03.456: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname1/proxy/: foo (200; 6.917783ms)
May 21 09:44:03.456: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname1/proxy/: foo (200; 6.983606ms)
May 21 09:44:03.457: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname2/proxy/: bar (200; 6.827112ms)
May 21 09:44:03.460: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:460/proxy/: tls baz (200; 2.984871ms)
May 21 09:44:03.460: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 3.435813ms)
May 21 09:44:03.460: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/rewri... (200; 3.390712ms)
May 21 09:44:03.460: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:462/proxy/: tls qux (200; 3.614776ms)
May 21 09:44:03.460: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 3.69473ms)
May 21 09:44:03.460: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/... (200; 3.776934ms)
May 21 09:44:03.461: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 3.905187ms)
May 21 09:44:03.461: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/... (200; 3.901975ms)
May 21 09:44:03.461: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 3.636691ms)
May 21 09:44:03.461: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname2/proxy/: bar (200; 4.192511ms)
May 21 09:44:03.461: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/rewriteme"... (200; 4.259473ms)
May 21 09:44:03.461: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname1/proxy/: foo (200; 4.382919ms)
May 21 09:44:03.462: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname1/proxy/: foo (200; 4.5918ms)
May 21 09:44:03.462: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname2/proxy/: bar (200; 4.944604ms)
May 21 09:44:03.462: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname1/proxy/: tls baz (200; 5.083706ms)
May 21 09:44:03.462: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname2/proxy/: tls qux (200; 5.169525ms)
May 21 09:44:03.466: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/... (200; 3.123597ms)
May 21 09:44:03.466: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 3.689793ms)
May 21 09:44:03.466: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:460/proxy/: tls baz (200; 3.810495ms)
May 21 09:44:03.467: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname2/proxy/: tls qux (200; 4.461736ms)
May 21 09:44:03.467: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 4.422914ms)
May 21 09:44:03.467: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/rewriteme"... (200; 4.492042ms)
May 21 09:44:03.467: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname1/proxy/: tls baz (200; 4.667559ms)
May 21 09:44:03.468: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname2/proxy/: bar (200; 5.36822ms)
May 21 09:44:03.468: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname1/proxy/: foo (200; 5.49969ms)
May 21 09:44:03.468: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/rewri... (200; 5.269843ms)
May 21 09:44:03.468: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 5.360409ms)
May 21 09:44:03.468: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/... (200; 5.245601ms)
May 21 09:44:03.468: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 5.207115ms)
May 21 09:44:03.468: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:462/proxy/: tls qux (200; 5.166701ms)
May 21 09:44:03.468: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname1/proxy/: foo (200; 5.664107ms)
May 21 09:44:03.468: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname2/proxy/: bar (200; 5.558545ms)
May 21 09:44:03.473: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 4.436564ms)
May 21 09:44:03.474: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 5.181973ms)
May 21 09:44:03.474: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:460/proxy/: tls baz (200; 5.339845ms)
May 21 09:44:03.474: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/rewriteme"... (200; 5.289361ms)
May 21 09:44:03.474: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 4.761154ms)
May 21 09:44:03.475: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname1/proxy/: foo (200; 6.247459ms)
May 21 09:44:03.475: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/... (200; 6.040795ms)
May 21 09:44:03.476: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname2/proxy/: bar (200; 6.753013ms)
May 21 09:44:03.476: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname2/proxy/: tls qux (200; 6.661329ms)
May 21 09:44:03.476: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname1/proxy/: foo (200; 6.924361ms)
May 21 09:44:03.476: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname2/proxy/: bar (200; 6.88179ms)
May 21 09:44:03.476: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:462/proxy/: tls qux (200; 6.486755ms)
May 21 09:44:03.476: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/... (200; 6.626929ms)
May 21 09:44:03.476: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname1/proxy/: tls baz (200; 7.02263ms)
May 21 09:44:03.476: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/rewri... (200; 6.828632ms)
May 21 09:44:03.476: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 6.649431ms)
May 21 09:44:03.478: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/rewri... (200; 2.391059ms)
May 21 09:44:03.479: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/... (200; 2.882625ms)
May 21 09:44:03.479: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 2.960764ms)
May 21 09:44:03.479: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 3.208576ms)
May 21 09:44:03.479: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:462/proxy/: tls qux (200; 3.035821ms)
May 21 09:44:03.480: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:460/proxy/: tls baz (200; 3.108071ms)
May 21 09:44:03.480: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 3.446965ms)
May 21 09:44:03.480: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/... (200; 3.491837ms)
May 21 09:44:03.480: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname1/proxy/: foo (200; 3.602433ms)
May 21 09:44:03.480: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname1/proxy/: foo (200; 3.638971ms)
May 21 09:44:03.480: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname2/proxy/: bar (200; 3.692466ms)
May 21 09:44:03.481: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 3.734855ms)
May 21 09:44:03.481: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/rewriteme"... (200; 3.959785ms)
May 21 09:44:03.481: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname2/proxy/: bar (200; 4.440002ms)
May 21 09:44:03.481: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname1/proxy/: tls baz (200; 4.51473ms)
May 21 09:44:03.481: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname2/proxy/: tls qux (200; 4.581086ms)
May 21 09:44:03.486: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 4.731833ms)
May 21 09:44:03.486: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 4.690402ms)
May 21 09:44:03.487: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 5.210265ms)
May 21 09:44:03.487: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/rewri... (200; 5.703084ms)
May 21 09:44:03.487: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:462/proxy/: tls qux (200; 5.81178ms)
May 21 09:44:03.487: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:460/proxy/: tls baz (200; 5.57663ms)
May 21 09:44:03.488: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/... (200; 6.410291ms)
May 21 09:44:03.488: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/... (200; 6.376698ms)
May 21 09:44:03.488: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname1/proxy/: tls baz (200; 6.211182ms)
May 21 09:44:03.489: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/rewriteme"... (200; 6.492758ms)
May 21 09:44:03.489: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname2/proxy/: bar (200; 6.967089ms)
May 21 09:44:03.489: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname1/proxy/: foo (200; 6.65552ms)
May 21 09:44:03.489: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname1/proxy/: foo (200; 7.074766ms)
May 21 09:44:03.489: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname2/proxy/: tls qux (200; 7.366986ms)
May 21 09:44:03.490: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname2/proxy/: bar (200; 7.697503ms)
May 21 09:44:03.490: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 7.624492ms)
May 21 09:44:03.493: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 2.616103ms)
May 21 09:44:03.493: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:462/proxy/: tls qux (200; 2.821431ms)
May 21 09:44:03.493: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:460/proxy/: tls baz (200; 2.951526ms)
May 21 09:44:03.493: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/... (200; 3.113619ms)
May 21 09:44:03.493: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 2.870148ms)
May 21 09:44:03.494: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/rewriteme"... (200; 3.288157ms)
May 21 09:44:03.494: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 3.030403ms)
May 21 09:44:03.494: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname1/proxy/: foo (200; 3.403101ms)
May 21 09:44:03.494: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname2/proxy/: bar (200; 3.376469ms)
May 21 09:44:03.494: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/rewri... (200; 3.483424ms)
May 21 09:44:03.494: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 3.445716ms)
May 21 09:44:03.494: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/... (200; 3.756101ms)
May 21 09:44:03.494: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname2/proxy/: tls qux (200; 4.296989ms)
May 21 09:44:03.495: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname1/proxy/: tls baz (200; 4.449139ms)
May 21 09:44:03.495: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname2/proxy/: bar (200; 4.128475ms)
May 21 09:44:03.495: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname1/proxy/: foo (200; 4.418002ms)
May 21 09:44:03.498: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:460/proxy/: tls baz (200; 3.173993ms)
May 21 09:44:03.498: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/... (200; 3.552315ms)
May 21 09:44:03.498: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 3.513858ms)
May 21 09:44:03.498: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/... (200; 3.518674ms)
May 21 09:44:03.499: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 3.396808ms)
May 21 09:44:03.499: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:462/proxy/: tls qux (200; 3.508549ms)
May 21 09:44:03.500: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 4.185381ms)
May 21 09:44:03.500: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname1/proxy/: tls baz (200; 4.404569ms)
May 21 09:44:03.500: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 4.076849ms)
May 21 09:44:03.500: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname2/proxy/: bar (200; 4.582179ms)
May 21 09:44:03.500: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname1/proxy/: foo (200; 4.388134ms)
May 21 09:44:03.500: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname2/proxy/: tls qux (200; 4.697727ms)
May 21 09:44:03.500: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/rewri... (200; 4.458745ms)
May 21 09:44:03.500: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname1/proxy/: foo (200; 4.781198ms)
May 21 09:44:03.500: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/rewriteme"... (200; 4.922569ms)
May 21 09:44:03.500: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname2/proxy/: bar (200; 5.18416ms)
May 21 09:44:03.505: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/... (200; 4.514806ms)
May 21 09:44:03.506: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 5.587963ms)
May 21 09:44:03.506: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:460/proxy/: tls baz (200; 5.52338ms)
May 21 09:44:03.506: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname2/proxy/: tls qux (200; 5.710374ms)
May 21 09:44:03.506: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 5.708907ms)
May 21 09:44:03.506: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/rewriteme"... (200; 5.78611ms)
May 21 09:44:03.507: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/... (200; 6.000268ms)
May 21 09:44:03.507: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname1/proxy/: tls baz (200; 6.510836ms)
May 21 09:44:03.508: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname1/proxy/: foo (200; 7.034435ms)
May 21 09:44:03.508: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname1/proxy/: foo (200; 7.162985ms)
May 21 09:44:03.508: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname2/proxy/: bar (200; 7.204151ms)
May 21 09:44:03.508: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname2/proxy/: bar (200; 7.228023ms)
May 21 09:44:03.508: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 7.30413ms)
May 21 09:44:03.508: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 7.516947ms)
May 21 09:44:03.509: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:462/proxy/: tls qux (200; 7.493029ms)
May 21 09:44:03.509: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/rewri... (200; 7.869033ms)
May 21 09:44:03.513: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 4.047448ms)
May 21 09:44:03.514: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 4.921529ms)
May 21 09:44:03.514: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 4.824319ms)
May 21 09:44:03.514: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/... (200; 5.44972ms)
May 21 09:44:03.514: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:460/proxy/: tls baz (200; 5.402155ms)
May 21 09:44:03.515: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/... (200; 5.365221ms)
May 21 09:44:03.515: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:462/proxy/: tls qux (200; 5.567181ms)
May 21 09:44:03.516: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/rewriteme"... (200; 6.336665ms)
May 21 09:44:03.516: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname2/proxy/: bar (200; 6.680452ms)
May 21 09:44:03.516: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname1/proxy/: tls baz (200; 6.86371ms)
May 21 09:44:03.516: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname1/proxy/: foo (200; 7.14232ms)
May 21 09:44:03.516: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname2/proxy/: bar (200; 7.007175ms)
May 21 09:44:03.517: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/rewri... (200; 7.04765ms)
May 21 09:44:03.517: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname2/proxy/: tls qux (200; 7.239426ms)
May 21 09:44:03.517: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 6.991828ms)
May 21 09:44:03.517: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname1/proxy/: foo (200; 7.751649ms)
May 21 09:44:03.522: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/rewriteme"... (200; 4.731503ms)
May 21 09:44:03.522: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 5.289198ms)
May 21 09:44:03.523: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/... (200; 5.57815ms)
May 21 09:44:03.523: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/rewri... (200; 5.783948ms)
May 21 09:44:03.523: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:462/proxy/: tls qux (200; 5.625304ms)
May 21 09:44:03.523: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 5.639384ms)
May 21 09:44:03.523: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 5.759933ms)
May 21 09:44:03.523: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 5.463991ms)
May 21 09:44:03.524: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname1/proxy/: foo (200; 6.024152ms)
May 21 09:44:03.524: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname1/proxy/: foo (200; 6.439372ms)
May 21 09:44:03.524: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/... (200; 6.719726ms)
May 21 09:44:03.524: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:460/proxy/: tls baz (200; 6.66356ms)
May 21 09:44:03.525: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname2/proxy/: tls qux (200; 6.746306ms)
May 21 09:44:03.525: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname2/proxy/: bar (200; 7.28005ms)
May 21 09:44:03.525: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname1/proxy/: tls baz (200; 7.350214ms)
May 21 09:44:03.525: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname2/proxy/: bar (200; 7.506065ms)
May 21 09:44:03.530: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 4.293709ms)
May 21 09:44:03.530: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/... (200; 4.510708ms)
May 21 09:44:03.531: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 5.274268ms)
May 21 09:44:03.531: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/rewri... (200; 5.34608ms)
May 21 09:44:03.532: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 5.409399ms)
May 21 09:44:03.532: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/... (200; 5.63605ms)
May 21 09:44:03.532: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:462/proxy/: tls qux (200; 6.371704ms)
May 21 09:44:03.533: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname2/proxy/: tls qux (200; 6.932336ms)
May 21 09:44:03.533: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname1/proxy/: foo (200; 6.839124ms)
May 21 09:44:03.533: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname2/proxy/: bar (200; 6.871747ms)
May 21 09:44:03.533: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname1/proxy/: foo (200; 7.034808ms)
May 21 09:44:03.533: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/rewriteme"... (200; 7.482144ms)
May 21 09:44:03.533: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname2/proxy/: bar (200; 7.721072ms)
May 21 09:44:03.533: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname1/proxy/: tls baz (200; 7.821238ms)
May 21 09:44:03.533: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:460/proxy/: tls baz (200; 7.959185ms)
May 21 09:44:03.534: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 7.802868ms)
May 21 09:44:03.536: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/... (200; 2.337779ms)
May 21 09:44:03.536: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:460/proxy/: tls baz (200; 2.752708ms)
May 21 09:44:03.537: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 3.607494ms)
May 21 09:44:03.538: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname1/proxy/: foo (200; 3.89143ms)
May 21 09:44:03.538: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/rewriteme"... (200; 3.77977ms)
May 21 09:44:03.538: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 3.946069ms)
May 21 09:44:03.538: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname2/proxy/: bar (200; 4.242531ms)
May 21 09:44:03.538: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/... (200; 4.031688ms)
May 21 09:44:03.538: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname2/proxy/: tls qux (200; 4.370198ms)
May 21 09:44:03.538: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname2/proxy/: bar (200; 4.570581ms)
May 21 09:44:03.539: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname1/proxy/: tls baz (200; 4.736923ms)
May 21 09:44:03.539: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:462/proxy/: tls qux (200; 4.319848ms)
May 21 09:44:03.539: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/rewri... (200; 4.372155ms)
May 21 09:44:03.539: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 4.527295ms)
May 21 09:44:03.539: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 4.656ms)
May 21 09:44:03.539: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname1/proxy/: foo (200; 5.1208ms)
May 21 09:44:03.543: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 3.972173ms)
May 21 09:44:03.544: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:462/proxy/: tls qux (200; 4.268267ms)
May 21 09:44:03.545: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 4.837868ms)
May 21 09:44:03.545: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/... (200; 5.882113ms)
May 21 09:44:03.545: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/rewriteme"... (200; 5.7992ms)
May 21 09:44:03.545: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:460/proxy/: tls baz (200; 5.916641ms)
May 21 09:44:03.545: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 5.879067ms)
May 21 09:44:03.545: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/... (200; 5.40706ms)
May 21 09:44:03.546: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname2/proxy/: tls qux (200; 6.436306ms)
May 21 09:44:03.547: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname1/proxy/: foo (200; 6.988116ms)
May 21 09:44:03.547: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/rewri... (200; 6.674458ms)
May 21 09:44:03.547: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname1/proxy/: foo (200; 7.297433ms)
May 21 09:44:03.547: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname2/proxy/: bar (200; 7.43449ms)
May 21 09:44:03.547: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname2/proxy/: bar (200; 7.389221ms)
May 21 09:44:03.547: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname1/proxy/: tls baz (200; 7.397905ms)
May 21 09:44:03.547: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 7.213102ms)
May 21 09:44:03.552: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:460/proxy/: tls baz (200; 4.157973ms)
May 21 09:44:03.554: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 6.056966ms)
May 21 09:44:03.554: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/rewriteme"... (200; 6.23058ms)
May 21 09:44:03.560: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/... (200; 12.345787ms)
May 21 09:44:03.561: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname1/proxy/: tls baz (200; 12.794554ms)
May 21 09:44:03.561: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/rewri... (200; 12.629436ms)
May 21 09:44:03.562: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/... (200; 13.398649ms)
May 21 09:44:03.562: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname1/proxy/: foo (200; 14.212236ms)
May 21 09:44:03.562: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname2/proxy/: bar (200; 14.130233ms)
May 21 09:44:03.562: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 13.913628ms)
May 21 09:44:03.562: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname2/proxy/: bar (200; 14.109733ms)
May 21 09:44:03.562: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 13.768996ms)
May 21 09:44:03.562: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:462/proxy/: tls qux (200; 13.722701ms)
May 21 09:44:03.562: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 14.242127ms)
May 21 09:44:03.566: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname2/proxy/: tls qux (200; 18.157407ms)
May 21 09:44:03.566: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname1/proxy/: foo (200; 18.640003ms)
May 21 09:44:03.572: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 5.442826ms)
May 21 09:44:03.572: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:462/proxy/: tls qux (200; 5.392909ms)
May 21 09:44:03.572: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/rewri... (200; 5.691366ms)
May 21 09:44:03.572: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:460/proxy/: tls baz (200; 5.677003ms)
May 21 09:44:03.572: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 5.778441ms)
May 21 09:44:03.572: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/... (200; 5.68879ms)
May 21 09:44:03.572: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/... (200; 6.141104ms)
May 21 09:44:03.573: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 6.230236ms)
May 21 09:44:03.578: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/rewriteme"... (200; 11.18203ms)
May 21 09:44:03.584: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 17.232656ms)
May 21 09:44:03.584: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname2/proxy/: bar (200; 17.502876ms)
May 21 09:44:03.584: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname2/proxy/: bar (200; 17.67264ms)
May 21 09:44:03.585: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname2/proxy/: tls qux (200; 17.616952ms)
May 21 09:44:03.589: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname1/proxy/: foo (200; 22.337288ms)
May 21 09:44:03.589: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname1/proxy/: foo (200; 22.061135ms)
May 21 09:44:03.589: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname1/proxy/: tls baz (200; 22.390868ms)
May 21 09:44:03.597: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 7.88893ms)
May 21 09:44:03.601: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/... (200; 11.504857ms)
May 21 09:44:03.601: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 11.586291ms)
May 21 09:44:03.601: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 11.677593ms)
May 21 09:44:03.601: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:462/proxy/: tls qux (200; 11.915026ms)
May 21 09:44:03.601: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/... (200; 11.823899ms)
May 21 09:44:03.602: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:460/proxy/: tls baz (200; 12.141526ms)
May 21 09:44:03.602: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/rewriteme"... (200; 11.720154ms)
May 21 09:44:03.602: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/rewri... (200; 12.626087ms)
May 21 09:44:03.602: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 12.514268ms)
May 21 09:44:03.607: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname2/proxy/: tls qux (200; 16.964847ms)
May 21 09:44:03.607: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname1/proxy/: foo (200; 17.416759ms)
May 21 09:44:03.607: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname1/proxy/: tls baz (200; 17.280736ms)
May 21 09:44:03.615: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname2/proxy/: bar (200; 25.09075ms)
May 21 09:44:03.615: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname1/proxy/: foo (200; 25.262733ms)
May 21 09:44:03.615: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname2/proxy/: bar (200; 25.235273ms)
May 21 09:44:03.622: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:462/proxy/: tls qux (200; 7.005173ms)
May 21 09:44:03.628: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:460/proxy/: tls baz (200; 12.695118ms)
May 21 09:44:03.629: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 12.635465ms)
May 21 09:44:03.629: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:1080/proxy/rewri... (200; 13.019933ms)
May 21 09:44:03.629: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm/proxy/rewriteme"... (200; 13.489147ms)
May 21 09:44:03.629: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 13.224882ms)
May 21 09:44:03.629: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:160/proxy/: foo (200; 13.591823ms)
May 21 09:44:03.629: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/http:proxy-service-5tqq7-kqgnm:1080/proxy/... (200; 13.233518ms)
May 21 09:44:03.630: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/proxy-service-5tqq7-kqgnm:162/proxy/: bar (200; 14.187707ms)
May 21 09:44:03.630: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pg292/pods/https:proxy-service-5tqq7-kqgnm:443/proxy/... (200; 14.151092ms)
May 21 09:44:03.633: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname2/proxy/: bar (200; 17.540494ms)
May 21 09:44:03.633: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname2/proxy/: tls qux (200; 17.968166ms)
May 21 09:44:03.634: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pg292/services/proxy-service-5tqq7:portname1/proxy/: foo (200; 17.860933ms)
May 21 09:44:03.634: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname2/proxy/: bar (200; 17.745843ms)
May 21 09:44:03.634: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pg292/services/http:proxy-service-5tqq7:portname1/proxy/: foo (200; 17.98218ms)
May 21 09:44:03.634: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pg292/services/https:proxy-service-5tqq7:tlsportname1/proxy/: tls baz (200; 17.9867ms)
STEP: deleting { ReplicationController} proxy-service-5tqq7 in namespace e2e-tests-proxy-pg292, will wait for the garbage collector to delete the pods
May 21 09:44:03.696: INFO: Deleting { ReplicationController} proxy-service-5tqq7 took: 4.670102ms
May 21 09:44:03.796: INFO: Terminating { ReplicationController} proxy-service-5tqq7 pods took: 100.350113ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:44:13.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-pg292" for this suite.
May 21 09:44:19.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:44:19.729: INFO: namespace: e2e-tests-proxy-pg292, resource: bindings, ignored listing per whitelist
May 21 09:44:19.767: INFO: namespace e2e-tests-proxy-pg292 deletion completed in 6.066843787s

• [SLOW TEST:28.444 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:44:19.767: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
May 21 09:44:19.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 --namespace=e2e-tests-kubectl-6zgmz run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
May 21 09:44:21.619: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
May 21 09:44:21.619: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:44:23.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6zgmz" for this suite.
May 21 09:44:35.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:44:35.649: INFO: namespace: e2e-tests-kubectl-6zgmz, resource: bindings, ignored listing per whitelist
May 21 09:44:35.689: INFO: namespace e2e-tests-kubectl-6zgmz deletion completed in 12.06354687s

• [SLOW TEST:15.921 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:44:35.689: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 21 09:44:35.731: INFO: Waiting up to 5m0s for pod "pod-0b191096-7bad-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-emptydir-84bm7" to be "success or failure"
May 21 09:44:35.733: INFO: Pod "pod-0b191096-7bad-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 1.939576ms
May 21 09:44:37.737: INFO: Pod "pod-0b191096-7bad-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006348503s
STEP: Saw pod success
May 21 09:44:37.737: INFO: Pod "pod-0b191096-7bad-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 09:44:37.739: INFO: Trying to get logs from node 192.168.5.29 pod pod-0b191096-7bad-11e9-be4b-6e6d88bcf118 container test-container: <nil>
STEP: delete the pod
May 21 09:44:37.754: INFO: Waiting for pod pod-0b191096-7bad-11e9-be4b-6e6d88bcf118 to disappear
May 21 09:44:37.757: INFO: Pod pod-0b191096-7bad-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:44:37.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-84bm7" for this suite.
May 21 09:44:43.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:44:43.808: INFO: namespace: e2e-tests-emptydir-84bm7, resource: bindings, ignored listing per whitelist
May 21 09:44:43.847: INFO: namespace e2e-tests-emptydir-84bm7 deletion completed in 6.08682905s

• [SLOW TEST:8.158 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:44:43.847: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 09:44:43.898: INFO: (0) /api/v1/nodes/192.168.5.29/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 3.594252ms)
May 21 09:44:43.900: INFO: (1) /api/v1/nodes/192.168.5.29/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.262226ms)
May 21 09:44:43.903: INFO: (2) /api/v1/nodes/192.168.5.29/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.161371ms)
May 21 09:44:43.905: INFO: (3) /api/v1/nodes/192.168.5.29/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.241459ms)
May 21 09:44:43.907: INFO: (4) /api/v1/nodes/192.168.5.29/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.164983ms)
May 21 09:44:43.909: INFO: (5) /api/v1/nodes/192.168.5.29/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.094196ms)
May 21 09:44:43.911: INFO: (6) /api/v1/nodes/192.168.5.29/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.184091ms)
May 21 09:44:43.913: INFO: (7) /api/v1/nodes/192.168.5.29/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.069195ms)
May 21 09:44:43.916: INFO: (8) /api/v1/nodes/192.168.5.29/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.212305ms)
May 21 09:44:43.918: INFO: (9) /api/v1/nodes/192.168.5.29/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.301701ms)
May 21 09:44:43.920: INFO: (10) /api/v1/nodes/192.168.5.29/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.221702ms)
May 21 09:44:43.922: INFO: (11) /api/v1/nodes/192.168.5.29/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.266657ms)
May 21 09:44:43.925: INFO: (12) /api/v1/nodes/192.168.5.29/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.30515ms)
May 21 09:44:43.927: INFO: (13) /api/v1/nodes/192.168.5.29/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.363749ms)
May 21 09:44:43.929: INFO: (14) /api/v1/nodes/192.168.5.29/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.170998ms)
May 21 09:44:43.932: INFO: (15) /api/v1/nodes/192.168.5.29/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.188736ms)
May 21 09:44:43.934: INFO: (16) /api/v1/nodes/192.168.5.29/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.356022ms)
May 21 09:44:43.936: INFO: (17) /api/v1/nodes/192.168.5.29/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.030471ms)
May 21 09:44:43.938: INFO: (18) /api/v1/nodes/192.168.5.29/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.19794ms)
May 21 09:44:43.940: INFO: (19) /api/v1/nodes/192.168.5.29/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 1.973168ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:44:43.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-5nws9" for this suite.
May 21 09:44:49.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:44:49.978: INFO: namespace: e2e-tests-proxy-5nws9, resource: bindings, ignored listing per whitelist
May 21 09:44:50.003: INFO: namespace e2e-tests-proxy-5nws9 deletion completed in 6.060364801s

• [SLOW TEST:6.155 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:44:50.003: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-p6gtm
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-p6gtm
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-p6gtm
May 21 09:44:50.053: INFO: Found 0 stateful pods, waiting for 1
May 21 09:45:00.057: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
May 21 09:45:00.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 21 09:45:00.277: INFO: stderr: ""
May 21 09:45:00.277: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 21 09:45:00.277: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 21 09:45:00.280: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 21 09:45:10.283: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 21 09:45:10.283: INFO: Waiting for statefulset status.replicas updated to 0
May 21 09:45:10.291: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
May 21 09:45:10.291: INFO: ss-0  192.168.5.29  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:44:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:44:50 +0000 UTC  }]
May 21 09:45:10.291: INFO: 
May 21 09:45:10.291: INFO: StatefulSet ss has not reached scale 3, at 1
May 21 09:45:11.294: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997883922s
May 21 09:45:12.297: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.994951529s
May 21 09:45:13.300: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.992140325s
May 21 09:45:14.305: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.98955126s
May 21 09:45:15.308: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.983807055s
May 21 09:45:16.312: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.980855366s
May 21 09:45:17.316: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.977300708s
May 21 09:45:18.320: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.972713268s
May 21 09:45:19.325: INFO: Verifying statefulset ss doesn't scale past 3 for another 969.271864ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-p6gtm
May 21 09:45:20.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:45:20.551: INFO: stderr: ""
May 21 09:45:20.551: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 21 09:45:20.551: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 21 09:45:20.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:45:20.751: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
May 21 09:45:20.751: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 21 09:45:20.751: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 21 09:45:20.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:45:20.939: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
May 21 09:45:20.939: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 21 09:45:20.939: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 21 09:45:20.942: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
May 21 09:45:30.945: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 21 09:45:30.945: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 21 09:45:30.945: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
May 21 09:45:30.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 21 09:45:31.163: INFO: stderr: ""
May 21 09:45:31.163: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 21 09:45:31.163: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 21 09:45:31.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 21 09:45:31.394: INFO: stderr: ""
May 21 09:45:31.394: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 21 09:45:31.394: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 21 09:45:31.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 21 09:45:31.593: INFO: stderr: ""
May 21 09:45:31.593: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 21 09:45:31.593: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 21 09:45:31.594: INFO: Waiting for statefulset status.replicas updated to 0
May 21 09:45:31.596: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
May 21 09:45:41.602: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 21 09:45:41.602: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 21 09:45:41.602: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 21 09:45:41.610: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
May 21 09:45:41.610: INFO: ss-0  192.168.5.29  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:44:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:44:50 +0000 UTC  }]
May 21 09:45:41.610: INFO: ss-1  192.168.5.29  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  }]
May 21 09:45:41.610: INFO: ss-2  192.168.5.29  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  }]
May 21 09:45:41.610: INFO: 
May 21 09:45:41.610: INFO: StatefulSet ss has not reached scale 0, at 3
May 21 09:45:42.613: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
May 21 09:45:42.613: INFO: ss-0  192.168.5.29  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:44:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:44:50 +0000 UTC  }]
May 21 09:45:42.613: INFO: ss-1  192.168.5.29  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  }]
May 21 09:45:42.613: INFO: ss-2  192.168.5.29  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  }]
May 21 09:45:42.613: INFO: 
May 21 09:45:42.613: INFO: StatefulSet ss has not reached scale 0, at 3
May 21 09:45:43.617: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
May 21 09:45:43.617: INFO: ss-0  192.168.5.29  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:44:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:44:50 +0000 UTC  }]
May 21 09:45:43.617: INFO: ss-1  192.168.5.29  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  }]
May 21 09:45:43.617: INFO: ss-2  192.168.5.29  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  }]
May 21 09:45:43.617: INFO: 
May 21 09:45:43.617: INFO: StatefulSet ss has not reached scale 0, at 3
May 21 09:45:44.620: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
May 21 09:45:44.620: INFO: ss-0  192.168.5.29  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:44:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:44:50 +0000 UTC  }]
May 21 09:45:44.620: INFO: ss-1  192.168.5.29  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  }]
May 21 09:45:44.620: INFO: ss-2  192.168.5.29  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  }]
May 21 09:45:44.620: INFO: 
May 21 09:45:44.620: INFO: StatefulSet ss has not reached scale 0, at 3
May 21 09:45:45.623: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
May 21 09:45:45.623: INFO: ss-0  192.168.5.29  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:44:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:44:50 +0000 UTC  }]
May 21 09:45:45.623: INFO: ss-1  192.168.5.29  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  }]
May 21 09:45:45.623: INFO: ss-2  192.168.5.29  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  }]
May 21 09:45:45.624: INFO: 
May 21 09:45:45.624: INFO: StatefulSet ss has not reached scale 0, at 3
May 21 09:45:46.626: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
May 21 09:45:46.626: INFO: ss-0  192.168.5.29  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:44:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:44:50 +0000 UTC  }]
May 21 09:45:46.627: INFO: ss-1  192.168.5.29  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  }]
May 21 09:45:46.627: INFO: ss-2  192.168.5.29  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  }]
May 21 09:45:46.627: INFO: 
May 21 09:45:46.627: INFO: StatefulSet ss has not reached scale 0, at 3
May 21 09:45:47.630: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
May 21 09:45:47.630: INFO: ss-0  192.168.5.29  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:44:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:44:50 +0000 UTC  }]
May 21 09:45:47.630: INFO: ss-1  192.168.5.29  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  }]
May 21 09:45:47.630: INFO: ss-2  192.168.5.29  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  }]
May 21 09:45:47.630: INFO: 
May 21 09:45:47.630: INFO: StatefulSet ss has not reached scale 0, at 3
May 21 09:45:48.632: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
May 21 09:45:48.632: INFO: ss-0  192.168.5.29  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:44:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:44:50 +0000 UTC  }]
May 21 09:45:48.632: INFO: ss-1  192.168.5.29  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  }]
May 21 09:45:48.632: INFO: ss-2  192.168.5.29  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  }]
May 21 09:45:48.632: INFO: 
May 21 09:45:48.632: INFO: StatefulSet ss has not reached scale 0, at 3
May 21 09:45:49.636: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
May 21 09:45:49.636: INFO: ss-0  192.168.5.29  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:44:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:44:50 +0000 UTC  }]
May 21 09:45:49.636: INFO: ss-1  192.168.5.29  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  }]
May 21 09:45:49.636: INFO: ss-2  192.168.5.29  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  }]
May 21 09:45:49.636: INFO: 
May 21 09:45:49.636: INFO: StatefulSet ss has not reached scale 0, at 3
May 21 09:45:50.639: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
May 21 09:45:50.639: INFO: ss-0  192.168.5.29  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:44:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:44:50 +0000 UTC  }]
May 21 09:45:50.639: INFO: ss-1  192.168.5.29  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  }]
May 21 09:45:50.639: INFO: ss-2  192.168.5.29  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 09:45:10 +0000 UTC  }]
May 21 09:45:50.639: INFO: 
May 21 09:45:50.639: INFO: StatefulSet ss has not reached scale 0, at 3
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-p6gtm
May 21 09:45:51.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:45:51.747: INFO: rc: 1
May 21 09:45:51.747: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc421637560 exit status 1 <nil> <nil> true [0xc4212bb478 0xc4212bb490 0xc4212bb4a8] [0xc4212bb478 0xc4212bb490 0xc4212bb4a8] [0xc4212bb488 0xc4212bb4a0] [0x8fd520 0x8fd520] 0xc4210cf8c0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

May 21 09:46:01.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:46:01.824: INFO: rc: 1
May 21 09:46:01.825: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421637980 exit status 1 <nil> <nil> true [0xc4212bb4b0 0xc4212bb4c8 0xc4212bb4e0] [0xc4212bb4b0 0xc4212bb4c8 0xc4212bb4e0] [0xc4212bb4c0 0xc4212bb4d8] [0x8fd520 0x8fd520] 0xc4210cf9e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 21 09:46:11.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:46:11.902: INFO: rc: 1
May 21 09:46:11.902: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421637d40 exit status 1 <nil> <nil> true [0xc4212bb4e8 0xc4212bb500 0xc4212bb518] [0xc4212bb4e8 0xc4212bb500 0xc4212bb518] [0xc4212bb4f8 0xc4212bb510] [0x8fd520 0x8fd520] 0xc4210cfb00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 21 09:46:21.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:46:21.981: INFO: rc: 1
May 21 09:46:21.981: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421878150 exit status 1 <nil> <nil> true [0xc4212bb520 0xc4212bb538 0xc4212bb550] [0xc4212bb520 0xc4212bb538 0xc4212bb550] [0xc4212bb530 0xc4212bb548] [0x8fd520 0x8fd520] 0xc4210cfc20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 21 09:46:31.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:46:32.069: INFO: rc: 1
May 21 09:46:32.069: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4218785d0 exit status 1 <nil> <nil> true [0xc4212bb558 0xc4212bb570 0xc4212bb588] [0xc4212bb558 0xc4212bb570 0xc4212bb588] [0xc4212bb568 0xc4212bb580] [0x8fd520 0x8fd520] 0xc4210cfd40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 21 09:46:42.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:46:42.153: INFO: rc: 1
May 21 09:46:42.153: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4218789c0 exit status 1 <nil> <nil> true [0xc4212bb590 0xc4212bb5a8 0xc4212bb5c0] [0xc4212bb590 0xc4212bb5a8 0xc4212bb5c0] [0xc4212bb5a0 0xc4212bb5b8] [0x8fd520 0x8fd520] 0xc4210cfe60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 21 09:46:52.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:46:52.233: INFO: rc: 1
May 21 09:46:52.233: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc422c94390 exit status 1 <nil> <nil> true [0xc42144e008 0xc42144e020 0xc42144e038] [0xc42144e008 0xc42144e020 0xc42144e038] [0xc42144e018 0xc42144e030] [0x8fd520 0x8fd520] 0xc421e4e0c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 21 09:47:02.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:47:02.312: INFO: rc: 1
May 21 09:47:02.313: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421636450 exit status 1 <nil> <nil> true [0xc4212ba018 0xc4212ba030 0xc4212ba050] [0xc4212ba018 0xc4212ba030 0xc4212ba050] [0xc4212ba028 0xc4212ba040] [0x8fd520 0x8fd520] 0xc4218248a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 21 09:47:12.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:47:12.392: INFO: rc: 1
May 21 09:47:12.392: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4216368a0 exit status 1 <nil> <nil> true [0xc4212ba070 0xc4212ba098 0xc4212ba0b0] [0xc4212ba070 0xc4212ba098 0xc4212ba0b0] [0xc4212ba090 0xc4212ba0a8] [0x8fd520 0x8fd520] 0xc421825740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 21 09:47:22.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:47:22.467: INFO: rc: 1
May 21 09:47:22.467: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc422c94750 exit status 1 <nil> <nil> true [0xc42144e040 0xc42144e058 0xc42144e070] [0xc42144e040 0xc42144e058 0xc42144e070] [0xc42144e050 0xc42144e068] [0x8fd520 0x8fd520] 0xc421e4f020 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 21 09:47:32.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:47:32.555: INFO: rc: 1
May 21 09:47:32.556: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421637230 exit status 1 <nil> <nil> true [0xc4212ba0b8 0xc4212ba0d0 0xc4212ba0e8] [0xc4212ba0b8 0xc4212ba0d0 0xc4212ba0e8] [0xc4212ba0c8 0xc4212ba0e0] [0x8fd520 0x8fd520] 0xc420d8d800 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 21 09:47:42.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:47:42.636: INFO: rc: 1
May 21 09:47:42.636: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421637620 exit status 1 <nil> <nil> true [0xc4212ba0f0 0xc4212ba108 0xc4212ba120] [0xc4212ba0f0 0xc4212ba108 0xc4212ba120] [0xc4212ba100 0xc4212ba118] [0x8fd520 0x8fd520] 0xc4216f5320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 21 09:47:52.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:47:52.719: INFO: rc: 1
May 21 09:47:52.719: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421637a70 exit status 1 <nil> <nil> true [0xc4212ba128 0xc4212ba140 0xc4212ba158] [0xc4212ba128 0xc4212ba140 0xc4212ba158] [0xc4212ba138 0xc4212ba150] [0x8fd520 0x8fd520] 0xc421111e00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 21 09:48:02.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:48:02.790: INFO: rc: 1
May 21 09:48:02.790: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421637e60 exit status 1 <nil> <nil> true [0xc4212ba160 0xc4212ba178 0xc4212ba1a8] [0xc4212ba160 0xc4212ba178 0xc4212ba1a8] [0xc4212ba170 0xc4212ba1a0] [0x8fd520 0x8fd520] 0xc42190e6c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 21 09:48:12.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:48:12.877: INFO: rc: 1
May 21 09:48:12.877: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42195e270 exit status 1 <nil> <nil> true [0xc4212ba1b0 0xc4212ba1c8 0xc4212ba1e0] [0xc4212ba1b0 0xc4212ba1c8 0xc4212ba1e0] [0xc4212ba1c0 0xc4212ba1d8] [0x8fd520 0x8fd520] 0xc420eba960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 21 09:48:22.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:48:22.954: INFO: rc: 1
May 21 09:48:22.954: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc422c94ae0 exit status 1 <nil> <nil> true [0xc42144e078 0xc42144e090 0xc42144e0a8] [0xc42144e078 0xc42144e090 0xc42144e0a8] [0xc42144e088 0xc42144e0a0] [0x8fd520 0x8fd520] 0xc421531bc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 21 09:48:32.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:48:33.035: INFO: rc: 1
May 21 09:48:33.035: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc422c94ea0 exit status 1 <nil> <nil> true [0xc42144e0b0 0xc42144e0c8 0xc42144e0e0] [0xc42144e0b0 0xc42144e0c8 0xc42144e0e0] [0xc42144e0c0 0xc42144e0d8] [0x8fd520 0x8fd520] 0xc4200a0840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 21 09:48:43.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:48:43.113: INFO: rc: 1
May 21 09:48:43.113: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42195e690 exit status 1 <nil> <nil> true [0xc4212ba1e8 0xc4212ba200 0xc4212ba218] [0xc4212ba1e8 0xc4212ba200 0xc4212ba218] [0xc4212ba1f8 0xc4212ba210] [0x8fd520 0x8fd520] 0xc422020720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 21 09:48:53.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:48:53.199: INFO: rc: 1
May 21 09:48:53.199: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421636480 exit status 1 <nil> <nil> true [0xc42144e008 0xc42144e020 0xc42144e038] [0xc42144e008 0xc42144e020 0xc42144e038] [0xc42144e018 0xc42144e030] [0x8fd520 0x8fd520] 0xc4200a0000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 21 09:49:03.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:49:03.286: INFO: rc: 1
May 21 09:49:03.286: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421636900 exit status 1 <nil> <nil> true [0xc42144e040 0xc42144e058 0xc42144e070] [0xc42144e040 0xc42144e058 0xc42144e070] [0xc42144e050 0xc42144e068] [0x8fd520 0x8fd520] 0xc421531bc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 21 09:49:13.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:49:13.363: INFO: rc: 1
May 21 09:49:13.363: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421637290 exit status 1 <nil> <nil> true [0xc42144e078 0xc42144e090 0xc42144e0a8] [0xc42144e078 0xc42144e090 0xc42144e0a8] [0xc42144e088 0xc42144e0a0] [0x8fd520 0x8fd520] 0xc421a16fc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 21 09:49:23.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:49:23.456: INFO: rc: 1
May 21 09:49:23.456: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc422c943c0 exit status 1 <nil> <nil> true [0xc4212ba018 0xc4212ba030 0xc4212ba050] [0xc4212ba018 0xc4212ba030 0xc4212ba050] [0xc4212ba028 0xc4212ba040] [0x8fd520 0x8fd520] 0xc421066900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 21 09:49:33.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:49:33.540: INFO: rc: 1
May 21 09:49:33.540: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421637680 exit status 1 <nil> <nil> true [0xc42144e0b0 0xc42144e0c8 0xc42144e0e0] [0xc42144e0b0 0xc42144e0c8 0xc42144e0e0] [0xc42144e0c0 0xc42144e0d8] [0x8fd520 0x8fd520] 0xc421111080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 21 09:49:43.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:49:43.634: INFO: rc: 1
May 21 09:49:43.634: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc422c947e0 exit status 1 <nil> <nil> true [0xc4212ba070 0xc4212ba098 0xc4212ba0b0] [0xc4212ba070 0xc4212ba098 0xc4212ba0b0] [0xc4212ba090 0xc4212ba0a8] [0x8fd520 0x8fd520] 0xc4216f5320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 21 09:49:53.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:49:53.705: INFO: rc: 1
May 21 09:49:53.705: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc422c94bd0 exit status 1 <nil> <nil> true [0xc4212ba0b8 0xc4212ba0d0 0xc4212ba0e8] [0xc4212ba0b8 0xc4212ba0d0 0xc4212ba0e8] [0xc4212ba0c8 0xc4212ba0e0] [0x8fd520 0x8fd520] 0xc420d8dda0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 21 09:50:03.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:50:03.792: INFO: rc: 1
May 21 09:50:03.792: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421637aa0 exit status 1 <nil> <nil> true [0xc42144e0e8 0xc42144e100 0xc42144e118] [0xc42144e0e8 0xc42144e100 0xc42144e118] [0xc42144e0f8 0xc42144e110] [0x8fd520 0x8fd520] 0xc421e4e420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 21 09:50:13.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:50:13.880: INFO: rc: 1
May 21 09:50:13.880: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421637e90 exit status 1 <nil> <nil> true [0xc42144e120 0xc42144e138 0xc42144e150] [0xc42144e120 0xc42144e138 0xc42144e150] [0xc42144e130 0xc42144e148] [0x8fd520 0x8fd520] 0xc421e4f7a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 21 09:50:23.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:50:23.957: INFO: rc: 1
May 21 09:50:23.957: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42195e2a0 exit status 1 <nil> <nil> true [0xc42144e158 0xc42144e170 0xc42144e188] [0xc42144e158 0xc42144e170 0xc42144e188] [0xc42144e168 0xc42144e180] [0x8fd520 0x8fd520] 0xc4220204e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 21 09:50:33.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:50:34.037: INFO: rc: 1
May 21 09:50:34.037: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42195e6c0 exit status 1 <nil> <nil> true [0xc42144e190 0xc42144e1a8 0xc42144e1c0] [0xc42144e190 0xc42144e1a8 0xc42144e1c0] [0xc42144e1a0 0xc42144e1b8] [0x8fd520 0x8fd520] 0xc422021500 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 21 09:50:44.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:50:44.109: INFO: rc: 1
May 21 09:50:44.109: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc422c95020 exit status 1 <nil> <nil> true [0xc4212ba0f0 0xc4212ba108 0xc4212ba120] [0xc4212ba0f0 0xc4212ba108 0xc4212ba120] [0xc4212ba100 0xc4212ba118] [0x8fd520 0x8fd520] 0xc421824d80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 21 09:50:54.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-p6gtm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 09:50:54.196: INFO: rc: 1
May 21 09:50:54.196: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
May 21 09:50:54.196: INFO: Scaling statefulset ss to 0
May 21 09:50:54.203: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 21 09:50:54.205: INFO: Deleting all statefulset in ns e2e-tests-statefulset-p6gtm
May 21 09:50:54.206: INFO: Scaling statefulset ss to 0
May 21 09:50:54.211: INFO: Waiting for statefulset status.replicas updated to 0
May 21 09:50:54.213: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:50:54.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-p6gtm" for this suite.
May 21 09:51:00.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:51:00.281: INFO: namespace: e2e-tests-statefulset-p6gtm, resource: bindings, ignored listing per whitelist
May 21 09:51:00.299: INFO: namespace e2e-tests-statefulset-p6gtm deletion completed in 6.065946011s

• [SLOW TEST:370.296 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:51:00.299: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 21 09:51:00.342: INFO: Waiting up to 5m0s for pod "pod-f05800c5-7bad-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-emptydir-xzrw9" to be "success or failure"
May 21 09:51:00.345: INFO: Pod "pod-f05800c5-7bad-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 3.398966ms
May 21 09:51:02.348: INFO: Pod "pod-f05800c5-7bad-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006255436s
STEP: Saw pod success
May 21 09:51:02.348: INFO: Pod "pod-f05800c5-7bad-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 09:51:02.350: INFO: Trying to get logs from node 192.168.5.29 pod pod-f05800c5-7bad-11e9-be4b-6e6d88bcf118 container test-container: <nil>
STEP: delete the pod
May 21 09:51:02.366: INFO: Waiting for pod pod-f05800c5-7bad-11e9-be4b-6e6d88bcf118 to disappear
May 21 09:51:02.368: INFO: Pod pod-f05800c5-7bad-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:51:02.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-xzrw9" for this suite.
May 21 09:51:08.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:51:08.421: INFO: namespace: e2e-tests-emptydir-xzrw9, resource: bindings, ignored listing per whitelist
May 21 09:51:08.434: INFO: namespace e2e-tests-emptydir-xzrw9 deletion completed in 6.06336282s

• [SLOW TEST:8.135 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:51:08.434: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
May 21 09:51:08.475: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:51:12.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-nrcnp" for this suite.
May 21 09:51:34.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:51:34.193: INFO: namespace: e2e-tests-init-container-nrcnp, resource: bindings, ignored listing per whitelist
May 21 09:51:34.248: INFO: namespace e2e-tests-init-container-nrcnp deletion completed in 22.075141352s

• [SLOW TEST:25.814 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:51:34.248: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 09:51:34.297: INFO: Waiting up to 5m0s for pod "downwardapi-volume-04951e3d-7bae-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-projected-4p6t6" to be "success or failure"
May 21 09:51:34.302: INFO: Pod "downwardapi-volume-04951e3d-7bae-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 4.584214ms
May 21 09:51:36.304: INFO: Pod "downwardapi-volume-04951e3d-7bae-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007146801s
STEP: Saw pod success
May 21 09:51:36.304: INFO: Pod "downwardapi-volume-04951e3d-7bae-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 09:51:36.306: INFO: Trying to get logs from node 192.168.5.29 pod downwardapi-volume-04951e3d-7bae-11e9-be4b-6e6d88bcf118 container client-container: <nil>
STEP: delete the pod
May 21 09:51:36.317: INFO: Waiting for pod downwardapi-volume-04951e3d-7bae-11e9-be4b-6e6d88bcf118 to disappear
May 21 09:51:36.320: INFO: Pod downwardapi-volume-04951e3d-7bae-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:51:36.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4p6t6" for this suite.
May 21 09:51:42.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:51:42.373: INFO: namespace: e2e-tests-projected-4p6t6, resource: bindings, ignored listing per whitelist
May 21 09:51:42.383: INFO: namespace e2e-tests-projected-4p6t6 deletion completed in 6.058386229s

• [SLOW TEST:8.135 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:51:42.383: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
May 21 09:51:42.474: INFO: Waiting up to 5m0s for pod "client-containers-0974ec30-7bae-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-containers-98d4c" to be "success or failure"
May 21 09:51:42.478: INFO: Pod "client-containers-0974ec30-7bae-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 4.65436ms
May 21 09:51:44.481: INFO: Pod "client-containers-0974ec30-7bae-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007624035s
May 21 09:51:46.485: INFO: Pod "client-containers-0974ec30-7bae-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010937028s
STEP: Saw pod success
May 21 09:51:46.485: INFO: Pod "client-containers-0974ec30-7bae-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 09:51:46.486: INFO: Trying to get logs from node 192.168.5.29 pod client-containers-0974ec30-7bae-11e9-be4b-6e6d88bcf118 container test-container: <nil>
STEP: delete the pod
May 21 09:51:46.498: INFO: Waiting for pod client-containers-0974ec30-7bae-11e9-be4b-6e6d88bcf118 to disappear
May 21 09:51:46.500: INFO: Pod client-containers-0974ec30-7bae-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:51:46.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-98d4c" for this suite.
May 21 09:51:52.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:51:52.539: INFO: namespace: e2e-tests-containers-98d4c, resource: bindings, ignored listing per whitelist
May 21 09:51:52.570: INFO: namespace e2e-tests-containers-98d4c deletion completed in 6.065815944s

• [SLOW TEST:10.187 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:51:52.571: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-vvjmv
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 21 09:51:52.607: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 21 09:52:16.644: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.8.1.100:8080/dial?request=hostName&protocol=http&host=10.8.1.99&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-vvjmv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 09:52:16.644: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
May 21 09:52:16.781: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:52:16.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-vvjmv" for this suite.
May 21 09:52:38.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:52:38.823: INFO: namespace: e2e-tests-pod-network-test-vvjmv, resource: bindings, ignored listing per whitelist
May 21 09:52:38.867: INFO: namespace e2e-tests-pod-network-test-vvjmv deletion completed in 22.082288004s

• [SLOW TEST:46.297 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:52:38.868: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
May 21 09:52:38.907: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

May 21 09:52:38.907: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 create -f - --namespace=e2e-tests-kubectl-gmwj8'
May 21 09:52:39.101: INFO: stderr: ""
May 21 09:52:39.101: INFO: stdout: "service/redis-slave created\n"
May 21 09:52:39.101: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

May 21 09:52:39.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 create -f - --namespace=e2e-tests-kubectl-gmwj8'
May 21 09:52:39.269: INFO: stderr: ""
May 21 09:52:39.269: INFO: stdout: "service/redis-master created\n"
May 21 09:52:39.269: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

May 21 09:52:39.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 create -f - --namespace=e2e-tests-kubectl-gmwj8'
May 21 09:52:39.434: INFO: stderr: ""
May 21 09:52:39.434: INFO: stdout: "service/frontend created\n"
May 21 09:52:39.435: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

May 21 09:52:39.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 create -f - --namespace=e2e-tests-kubectl-gmwj8'
May 21 09:52:39.590: INFO: stderr: ""
May 21 09:52:39.590: INFO: stdout: "deployment.extensions/frontend created\n"
May 21 09:52:39.590: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

May 21 09:52:39.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 create -f - --namespace=e2e-tests-kubectl-gmwj8'
May 21 09:52:39.766: INFO: stderr: ""
May 21 09:52:39.767: INFO: stdout: "deployment.extensions/redis-master created\n"
May 21 09:52:39.767: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

May 21 09:52:39.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 create -f - --namespace=e2e-tests-kubectl-gmwj8'
May 21 09:52:39.913: INFO: stderr: ""
May 21 09:52:39.913: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
May 21 09:52:39.913: INFO: Waiting for all frontend pods to be Running.
May 21 09:53:29.966: INFO: Waiting for frontend to serve content.
May 21 09:53:29.978: INFO: Trying to add a new entry to the guestbook.
May 21 09:53:29.985: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
May 21 09:53:29.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-gmwj8'
May 21 09:53:30.177: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 09:53:30.177: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
May 21 09:53:30.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-gmwj8'
May 21 09:53:30.273: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 09:53:30.273: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
May 21 09:53:30.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-gmwj8'
May 21 09:53:30.366: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 09:53:30.366: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 21 09:53:30.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-gmwj8'
May 21 09:53:30.454: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 09:53:30.454: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 21 09:53:30.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-gmwj8'
May 21 09:53:30.706: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 09:53:30.706: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
May 21 09:53:30.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-gmwj8'
May 21 09:53:30.848: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 09:53:30.848: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:53:30.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gmwj8" for this suite.
May 21 09:54:14.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:54:14.919: INFO: namespace: e2e-tests-kubectl-gmwj8, resource: bindings, ignored listing per whitelist
May 21 09:54:14.919: INFO: namespace e2e-tests-kubectl-gmwj8 deletion completed in 44.067029344s

• [SLOW TEST:96.051 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:54:14.919: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-9jp78
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-9jp78
STEP: Deleting pre-stop pod
May 21 09:54:27.985: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:54:27.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-9jp78" for this suite.
May 21 09:55:06.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:55:06.065: INFO: namespace: e2e-tests-prestop-9jp78, resource: bindings, ignored listing per whitelist
May 21 09:55:06.065: INFO: namespace e2e-tests-prestop-9jp78 deletion completed in 38.069323545s

• [SLOW TEST:51.146 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:55:06.066: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-82d56918-7bae-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume configMaps
May 21 09:55:06.113: INFO: Waiting up to 5m0s for pod "pod-configmaps-82d5f72f-7bae-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-configmap-fc5vc" to be "success or failure"
May 21 09:55:06.119: INFO: Pod "pod-configmaps-82d5f72f-7bae-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 5.095867ms
May 21 09:55:08.121: INFO: Pod "pod-configmaps-82d5f72f-7bae-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008002223s
STEP: Saw pod success
May 21 09:55:08.122: INFO: Pod "pod-configmaps-82d5f72f-7bae-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 09:55:08.123: INFO: Trying to get logs from node 192.168.5.29 pod pod-configmaps-82d5f72f-7bae-11e9-be4b-6e6d88bcf118 container configmap-volume-test: <nil>
STEP: delete the pod
May 21 09:55:08.144: INFO: Waiting for pod pod-configmaps-82d5f72f-7bae-11e9-be4b-6e6d88bcf118 to disappear
May 21 09:55:08.147: INFO: Pod pod-configmaps-82d5f72f-7bae-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:55:08.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-fc5vc" for this suite.
May 21 09:55:14.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:55:14.192: INFO: namespace: e2e-tests-configmap-fc5vc, resource: bindings, ignored listing per whitelist
May 21 09:55:14.229: INFO: namespace e2e-tests-configmap-fc5vc deletion completed in 6.078899069s

• [SLOW TEST:8.164 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:55:14.229: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-87b2a4c7-7bae-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume configMaps
May 21 09:55:14.278: INFO: Waiting up to 5m0s for pod "pod-configmaps-87b3c3a9-7bae-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-configmap-tjbgm" to be "success or failure"
May 21 09:55:14.281: INFO: Pod "pod-configmaps-87b3c3a9-7bae-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 3.314118ms
May 21 09:55:16.284: INFO: Pod "pod-configmaps-87b3c3a9-7bae-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005860317s
STEP: Saw pod success
May 21 09:55:16.284: INFO: Pod "pod-configmaps-87b3c3a9-7bae-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 09:55:16.286: INFO: Trying to get logs from node 192.168.5.29 pod pod-configmaps-87b3c3a9-7bae-11e9-be4b-6e6d88bcf118 container configmap-volume-test: <nil>
STEP: delete the pod
May 21 09:55:16.303: INFO: Waiting for pod pod-configmaps-87b3c3a9-7bae-11e9-be4b-6e6d88bcf118 to disappear
May 21 09:55:16.305: INFO: Pod pod-configmaps-87b3c3a9-7bae-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:55:16.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tjbgm" for this suite.
May 21 09:55:22.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:55:22.353: INFO: namespace: e2e-tests-configmap-tjbgm, resource: bindings, ignored listing per whitelist
May 21 09:55:22.371: INFO: namespace e2e-tests-configmap-tjbgm deletion completed in 6.063418292s

• [SLOW TEST:8.142 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:55:22.372: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 21 09:55:22.427: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:22.427: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:22.427: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:22.430: INFO: Number of nodes with available pods: 0
May 21 09:55:22.430: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:23.434: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:23.434: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:23.434: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:23.435: INFO: Number of nodes with available pods: 1
May 21 09:55:23.435: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Stop a daemon pod, check that the daemon pod is revived.
May 21 09:55:23.447: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:23.447: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:23.447: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:23.448: INFO: Number of nodes with available pods: 0
May 21 09:55:23.448: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:24.452: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:24.452: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:24.452: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:24.454: INFO: Number of nodes with available pods: 0
May 21 09:55:24.454: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:25.452: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:25.452: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:25.452: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:25.454: INFO: Number of nodes with available pods: 0
May 21 09:55:25.454: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:26.451: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:26.451: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:26.451: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:26.453: INFO: Number of nodes with available pods: 0
May 21 09:55:26.453: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:27.452: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:27.452: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:27.452: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:27.454: INFO: Number of nodes with available pods: 0
May 21 09:55:27.454: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:28.456: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:28.456: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:28.456: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:28.458: INFO: Number of nodes with available pods: 0
May 21 09:55:28.458: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:29.452: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:29.452: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:29.452: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:29.454: INFO: Number of nodes with available pods: 0
May 21 09:55:29.454: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:30.451: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:30.452: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:30.452: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:30.454: INFO: Number of nodes with available pods: 0
May 21 09:55:30.454: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:31.452: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:31.452: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:31.452: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:31.454: INFO: Number of nodes with available pods: 0
May 21 09:55:31.454: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:32.452: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:32.452: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:32.452: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:32.454: INFO: Number of nodes with available pods: 0
May 21 09:55:32.454: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:33.452: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:33.452: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:33.452: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:33.454: INFO: Number of nodes with available pods: 0
May 21 09:55:33.454: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:34.453: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:34.453: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:34.453: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:34.455: INFO: Number of nodes with available pods: 0
May 21 09:55:34.455: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:35.452: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:35.452: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:35.453: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:35.455: INFO: Number of nodes with available pods: 0
May 21 09:55:35.455: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:36.452: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:36.452: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:36.452: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:36.453: INFO: Number of nodes with available pods: 0
May 21 09:55:36.453: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:37.452: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:37.453: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:37.453: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:37.458: INFO: Number of nodes with available pods: 0
May 21 09:55:37.458: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:38.451: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:38.451: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:38.451: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:38.456: INFO: Number of nodes with available pods: 0
May 21 09:55:38.456: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:39.452: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:39.452: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:39.452: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:39.453: INFO: Number of nodes with available pods: 0
May 21 09:55:39.453: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:40.453: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:40.453: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:40.453: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:40.455: INFO: Number of nodes with available pods: 0
May 21 09:55:40.455: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:41.452: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:41.452: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:41.452: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:41.453: INFO: Number of nodes with available pods: 0
May 21 09:55:41.453: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:42.452: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:42.452: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:42.452: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:42.453: INFO: Number of nodes with available pods: 0
May 21 09:55:42.453: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:43.452: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:43.452: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:43.452: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:43.454: INFO: Number of nodes with available pods: 0
May 21 09:55:43.454: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:44.453: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:44.453: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:44.453: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:44.456: INFO: Number of nodes with available pods: 0
May 21 09:55:44.456: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:45.453: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:45.453: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:45.453: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:45.456: INFO: Number of nodes with available pods: 0
May 21 09:55:45.456: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:46.452: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:46.452: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:46.452: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:46.454: INFO: Number of nodes with available pods: 0
May 21 09:55:46.454: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:47.451: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:47.451: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:47.452: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:47.453: INFO: Number of nodes with available pods: 0
May 21 09:55:47.453: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:48.452: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:48.452: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:48.452: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:48.454: INFO: Number of nodes with available pods: 0
May 21 09:55:48.454: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:49.451: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:49.451: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:49.451: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:49.453: INFO: Number of nodes with available pods: 0
May 21 09:55:49.453: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:50.453: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:50.453: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:50.453: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:50.457: INFO: Number of nodes with available pods: 0
May 21 09:55:50.457: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:51.452: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:51.452: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:51.452: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:51.454: INFO: Number of nodes with available pods: 0
May 21 09:55:51.454: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:52.452: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:52.452: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:52.452: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:52.453: INFO: Number of nodes with available pods: 0
May 21 09:55:52.453: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:53.452: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:53.452: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:53.452: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:53.453: INFO: Number of nodes with available pods: 0
May 21 09:55:53.453: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:54.452: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:54.452: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:54.452: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:54.453: INFO: Number of nodes with available pods: 0
May 21 09:55:54.453: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:55.452: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:55.452: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:55.452: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:55.456: INFO: Number of nodes with available pods: 0
May 21 09:55:55.456: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:56.453: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:56.453: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:56.453: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:56.455: INFO: Number of nodes with available pods: 0
May 21 09:55:56.455: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:57.452: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:57.452: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:57.452: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:57.454: INFO: Number of nodes with available pods: 0
May 21 09:55:57.454: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:58.452: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:58.452: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:58.452: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:58.454: INFO: Number of nodes with available pods: 0
May 21 09:55:58.454: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:55:59.452: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:59.452: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:59.452: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:55:59.454: INFO: Number of nodes with available pods: 0
May 21 09:55:59.454: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:56:00.452: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:56:00.452: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:56:00.452: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:56:00.455: INFO: Number of nodes with available pods: 0
May 21 09:56:00.455: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:56:01.452: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:56:01.452: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:56:01.452: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:56:01.454: INFO: Number of nodes with available pods: 0
May 21 09:56:01.454: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:56:02.452: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:56:02.452: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:56:02.452: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:56:02.455: INFO: Number of nodes with available pods: 0
May 21 09:56:02.455: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:56:03.452: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:56:03.452: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:56:03.452: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:56:03.453: INFO: Number of nodes with available pods: 0
May 21 09:56:03.453: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:56:04.452: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:56:04.452: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:56:04.452: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:56:04.453: INFO: Number of nodes with available pods: 0
May 21 09:56:04.453: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 09:56:05.452: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:56:05.452: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:56:05.452: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 09:56:05.454: INFO: Number of nodes with available pods: 1
May 21 09:56:05.454: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-9zjpb, will wait for the garbage collector to delete the pods
May 21 09:56:05.514: INFO: Deleting {extensions DaemonSet} daemon-set took: 5.433492ms
May 21 09:56:05.614: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.119843ms
May 21 09:56:43.718: INFO: Number of nodes with available pods: 0
May 21 09:56:43.718: INFO: Number of running nodes: 0, number of available pods: 0
May 21 09:56:43.719: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-9zjpb/daemonsets","resourceVersion":"7027"},"items":null}

May 21 09:56:43.721: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-9zjpb/pods","resourceVersion":"7027"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:56:43.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-9zjpb" for this suite.
May 21 09:56:49.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:56:49.772: INFO: namespace: e2e-tests-daemonsets-9zjpb, resource: bindings, ignored listing per whitelist
May 21 09:56:49.793: INFO: namespace e2e-tests-daemonsets-9zjpb deletion completed in 6.063289271s

• [SLOW TEST:87.421 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:56:49.793: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
May 21 09:56:49.836: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-6qklc" to be "success or failure"
May 21 09:56:49.839: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 3.374251ms
May 21 09:56:51.842: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005925127s
STEP: Saw pod success
May 21 09:56:51.842: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
May 21 09:56:51.843: INFO: Trying to get logs from node 192.168.5.29 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
May 21 09:56:51.857: INFO: Waiting for pod pod-host-path-test to disappear
May 21 09:56:51.859: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:56:51.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-6qklc" for this suite.
May 21 09:56:57.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:56:57.896: INFO: namespace: e2e-tests-hostpath-6qklc, resource: bindings, ignored listing per whitelist
May 21 09:56:57.928: INFO: namespace e2e-tests-hostpath-6qklc deletion completed in 6.067133815s

• [SLOW TEST:8.135 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:56:57.928: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-c5827fbb-7bae-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume secrets
May 21 09:56:57.977: INFO: Waiting up to 5m0s for pod "pod-secrets-c583107f-7bae-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-secrets-l5cg5" to be "success or failure"
May 21 09:56:57.981: INFO: Pod "pod-secrets-c583107f-7bae-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 3.84858ms
May 21 09:56:59.985: INFO: Pod "pod-secrets-c583107f-7bae-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008247072s
STEP: Saw pod success
May 21 09:56:59.985: INFO: Pod "pod-secrets-c583107f-7bae-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 09:56:59.989: INFO: Trying to get logs from node 192.168.5.29 pod pod-secrets-c583107f-7bae-11e9-be4b-6e6d88bcf118 container secret-env-test: <nil>
STEP: delete the pod
May 21 09:57:00.000: INFO: Waiting for pod pod-secrets-c583107f-7bae-11e9-be4b-6e6d88bcf118 to disappear
May 21 09:57:00.002: INFO: Pod pod-secrets-c583107f-7bae-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:57:00.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-l5cg5" for this suite.
May 21 09:57:06.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:57:06.059: INFO: namespace: e2e-tests-secrets-l5cg5, resource: bindings, ignored listing per whitelist
May 21 09:57:06.074: INFO: namespace e2e-tests-secrets-l5cg5 deletion completed in 6.069285222s

• [SLOW TEST:8.145 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:57:06.074: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-5np2q A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-5np2q;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-5np2q A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-5np2q;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-5np2q.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-5np2q.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-5np2q.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-5np2q.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-5np2q.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-5np2q.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-5np2q.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5np2q.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-5np2q.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-5np2q.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-5np2q.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-5np2q.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-5np2q.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 242.178.254.10.in-addr.arpa. PTR)" && echo OK > /results/10.254.178.242_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 242.178.254.10.in-addr.arpa. PTR)" && echo OK > /results/10.254.178.242_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-5np2q A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-5np2q;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-5np2q A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-5np2q;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-5np2q.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-5np2q.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-5np2q.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-5np2q.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-5np2q.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-5np2q.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-5np2q.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5np2q.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-5np2q.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-5np2q.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-5np2q.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-5np2q.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-5np2q.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 242.178.254.10.in-addr.arpa. PTR)" && echo OK > /results/10.254.178.242_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 242.178.254.10.in-addr.arpa. PTR)" && echo OK > /results/10.254.178.242_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 21 09:57:42.181: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-5np2q/dns-test-ca5f0740-7bae-11e9-be4b-6e6d88bcf118: the server could not find the requested resource (get pods dns-test-ca5f0740-7bae-11e9-be4b-6e6d88bcf118)
May 21 09:57:42.184: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-5np2q/dns-test-ca5f0740-7bae-11e9-be4b-6e6d88bcf118: the server could not find the requested resource (get pods dns-test-ca5f0740-7bae-11e9-be4b-6e6d88bcf118)
May 21 09:57:42.187: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-5np2q from pod e2e-tests-dns-5np2q/dns-test-ca5f0740-7bae-11e9-be4b-6e6d88bcf118: the server could not find the requested resource (get pods dns-test-ca5f0740-7bae-11e9-be4b-6e6d88bcf118)
May 21 09:57:42.191: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-5np2q.svc from pod e2e-tests-dns-5np2q/dns-test-ca5f0740-7bae-11e9-be4b-6e6d88bcf118: the server could not find the requested resource (get pods dns-test-ca5f0740-7bae-11e9-be4b-6e6d88bcf118)
May 21 09:57:42.193: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-5np2q.svc from pod e2e-tests-dns-5np2q/dns-test-ca5f0740-7bae-11e9-be4b-6e6d88bcf118: the server could not find the requested resource (get pods dns-test-ca5f0740-7bae-11e9-be4b-6e6d88bcf118)
May 21 09:57:42.195: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-5np2q.svc from pod e2e-tests-dns-5np2q/dns-test-ca5f0740-7bae-11e9-be4b-6e6d88bcf118: the server could not find the requested resource (get pods dns-test-ca5f0740-7bae-11e9-be4b-6e6d88bcf118)
May 21 09:57:42.197: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5np2q.svc from pod e2e-tests-dns-5np2q/dns-test-ca5f0740-7bae-11e9-be4b-6e6d88bcf118: the server could not find the requested resource (get pods dns-test-ca5f0740-7bae-11e9-be4b-6e6d88bcf118)
May 21 09:57:42.223: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-5np2q/dns-test-ca5f0740-7bae-11e9-be4b-6e6d88bcf118: the server could not find the requested resource (get pods dns-test-ca5f0740-7bae-11e9-be4b-6e6d88bcf118)
May 21 09:57:42.243: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-5np2q.svc from pod e2e-tests-dns-5np2q/dns-test-ca5f0740-7bae-11e9-be4b-6e6d88bcf118: the server could not find the requested resource (get pods dns-test-ca5f0740-7bae-11e9-be4b-6e6d88bcf118)
May 21 09:57:42.247: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5np2q.svc from pod e2e-tests-dns-5np2q/dns-test-ca5f0740-7bae-11e9-be4b-6e6d88bcf118: the server could not find the requested resource (get pods dns-test-ca5f0740-7bae-11e9-be4b-6e6d88bcf118)
May 21 09:57:42.261: INFO: Lookups using e2e-tests-dns-5np2q/dns-test-ca5f0740-7bae-11e9-be4b-6e6d88bcf118 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-5np2q wheezy_udp@dns-test-service.e2e-tests-dns-5np2q.svc wheezy_tcp@dns-test-service.e2e-tests-dns-5np2q.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-5np2q.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5np2q.svc jessie_udp@dns-test-service jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-5np2q.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5np2q.svc]

May 21 09:57:52.218: INFO: DNS probes using e2e-tests-dns-5np2q/dns-test-ca5f0740-7bae-11e9-be4b-6e6d88bcf118 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:57:52.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-5np2q" for this suite.
May 21 09:57:58.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:57:58.348: INFO: namespace: e2e-tests-dns-5np2q, resource: bindings, ignored listing per whitelist
May 21 09:57:58.352: INFO: namespace e2e-tests-dns-5np2q deletion completed in 6.075635974s

• [SLOW TEST:52.278 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:57:58.353: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
May 21 09:57:58.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 create -f - --namespace=e2e-tests-kubectl-p7xd9'
May 21 09:57:58.579: INFO: stderr: ""
May 21 09:57:58.579: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 21 09:57:58.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-p7xd9'
May 21 09:57:58.664: INFO: stderr: ""
May 21 09:57:58.664: INFO: stdout: "update-demo-nautilus-hqmn6 update-demo-nautilus-w27mn "
May 21 09:57:58.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods update-demo-nautilus-hqmn6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p7xd9'
May 21 09:57:58.732: INFO: stderr: ""
May 21 09:57:58.732: INFO: stdout: ""
May 21 09:57:58.732: INFO: update-demo-nautilus-hqmn6 is created but not running
May 21 09:58:03.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-p7xd9'
May 21 09:58:03.816: INFO: stderr: ""
May 21 09:58:03.816: INFO: stdout: "update-demo-nautilus-hqmn6 update-demo-nautilus-w27mn "
May 21 09:58:03.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods update-demo-nautilus-hqmn6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p7xd9'
May 21 09:58:03.894: INFO: stderr: ""
May 21 09:58:03.894: INFO: stdout: "true"
May 21 09:58:03.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods update-demo-nautilus-hqmn6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p7xd9'
May 21 09:58:03.972: INFO: stderr: ""
May 21 09:58:03.972: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 21 09:58:03.972: INFO: validating pod update-demo-nautilus-hqmn6
May 21 09:58:03.975: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 09:58:03.975: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 09:58:03.975: INFO: update-demo-nautilus-hqmn6 is verified up and running
May 21 09:58:03.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods update-demo-nautilus-w27mn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p7xd9'
May 21 09:58:04.055: INFO: stderr: ""
May 21 09:58:04.055: INFO: stdout: "true"
May 21 09:58:04.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods update-demo-nautilus-w27mn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p7xd9'
May 21 09:58:04.128: INFO: stderr: ""
May 21 09:58:04.128: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 21 09:58:04.128: INFO: validating pod update-demo-nautilus-w27mn
May 21 09:58:04.131: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 09:58:04.131: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 09:58:04.131: INFO: update-demo-nautilus-w27mn is verified up and running
STEP: rolling-update to new replication controller
May 21 09:58:04.132: INFO: scanned /root for discovery docs: <nil>
May 21 09:58:04.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-p7xd9'
May 21 09:58:26.457: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 21 09:58:26.457: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 21 09:58:26.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-p7xd9'
May 21 09:58:26.557: INFO: stderr: ""
May 21 09:58:26.557: INFO: stdout: "update-demo-kitten-2cnf5 update-demo-kitten-m5bxw "
May 21 09:58:26.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods update-demo-kitten-2cnf5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p7xd9'
May 21 09:58:26.631: INFO: stderr: ""
May 21 09:58:26.631: INFO: stdout: "true"
May 21 09:58:26.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods update-demo-kitten-2cnf5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p7xd9'
May 21 09:58:26.707: INFO: stderr: ""
May 21 09:58:26.707: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
May 21 09:58:26.707: INFO: validating pod update-demo-kitten-2cnf5
May 21 09:58:26.711: INFO: got data: {
  "image": "kitten.jpg"
}

May 21 09:58:26.711: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 21 09:58:26.711: INFO: update-demo-kitten-2cnf5 is verified up and running
May 21 09:58:26.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods update-demo-kitten-m5bxw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p7xd9'
May 21 09:58:26.795: INFO: stderr: ""
May 21 09:58:26.795: INFO: stdout: "true"
May 21 09:58:26.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods update-demo-kitten-m5bxw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p7xd9'
May 21 09:58:26.874: INFO: stderr: ""
May 21 09:58:26.874: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
May 21 09:58:26.874: INFO: validating pod update-demo-kitten-m5bxw
May 21 09:58:26.878: INFO: got data: {
  "image": "kitten.jpg"
}

May 21 09:58:26.878: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 21 09:58:26.878: INFO: update-demo-kitten-m5bxw is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:58:26.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-p7xd9" for this suite.
May 21 09:58:48.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:58:48.937: INFO: namespace: e2e-tests-kubectl-p7xd9, resource: bindings, ignored listing per whitelist
May 21 09:58:48.944: INFO: namespace e2e-tests-kubectl-p7xd9 deletion completed in 22.062092746s

• [SLOW TEST:50.592 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:58:48.944: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-07ae69f4-7baf-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume configMaps
May 21 09:58:48.994: INFO: Waiting up to 5m0s for pod "pod-configmaps-07aeed3f-7baf-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-configmap-qm6sg" to be "success or failure"
May 21 09:58:48.996: INFO: Pod "pod-configmaps-07aeed3f-7baf-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 1.428ms
May 21 09:58:50.998: INFO: Pod "pod-configmaps-07aeed3f-7baf-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003907591s
STEP: Saw pod success
May 21 09:58:50.998: INFO: Pod "pod-configmaps-07aeed3f-7baf-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 09:58:51.000: INFO: Trying to get logs from node 192.168.5.29 pod pod-configmaps-07aeed3f-7baf-11e9-be4b-6e6d88bcf118 container configmap-volume-test: <nil>
STEP: delete the pod
May 21 09:58:51.014: INFO: Waiting for pod pod-configmaps-07aeed3f-7baf-11e9-be4b-6e6d88bcf118 to disappear
May 21 09:58:51.016: INFO: Pod pod-configmaps-07aeed3f-7baf-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:58:51.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-qm6sg" for this suite.
May 21 09:58:57.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:58:57.045: INFO: namespace: e2e-tests-configmap-qm6sg, resource: bindings, ignored listing per whitelist
May 21 09:58:57.083: INFO: namespace e2e-tests-configmap-qm6sg deletion completed in 6.064231587s

• [SLOW TEST:8.138 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:58:57.083: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 21 09:58:57.134: INFO: Waiting up to 5m0s for pod "pod-0c881314-7baf-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-emptydir-pwkm8" to be "success or failure"
May 21 09:58:57.138: INFO: Pod "pod-0c881314-7baf-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 4.355846ms
May 21 09:58:59.140: INFO: Pod "pod-0c881314-7baf-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006583312s
STEP: Saw pod success
May 21 09:58:59.140: INFO: Pod "pod-0c881314-7baf-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 09:58:59.142: INFO: Trying to get logs from node 192.168.5.29 pod pod-0c881314-7baf-11e9-be4b-6e6d88bcf118 container test-container: <nil>
STEP: delete the pod
May 21 09:58:59.155: INFO: Waiting for pod pod-0c881314-7baf-11e9-be4b-6e6d88bcf118 to disappear
May 21 09:58:59.156: INFO: Pod pod-0c881314-7baf-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:58:59.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pwkm8" for this suite.
May 21 09:59:05.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:59:05.262: INFO: namespace: e2e-tests-emptydir-pwkm8, resource: bindings, ignored listing per whitelist
May 21 09:59:05.291: INFO: namespace e2e-tests-emptydir-pwkm8 deletion completed in 6.133003947s

• [SLOW TEST:8.208 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:59:05.292: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
May 21 09:59:05.377: INFO: Waiting up to 5m0s for pod "var-expansion-116ead12-7baf-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-var-expansion-fggfk" to be "success or failure"
May 21 09:59:05.387: INFO: Pod "var-expansion-116ead12-7baf-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 10.385016ms
May 21 09:59:07.390: INFO: Pod "var-expansion-116ead12-7baf-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013028241s
STEP: Saw pod success
May 21 09:59:07.390: INFO: Pod "var-expansion-116ead12-7baf-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 09:59:07.392: INFO: Trying to get logs from node 192.168.5.29 pod var-expansion-116ead12-7baf-11e9-be4b-6e6d88bcf118 container dapi-container: <nil>
STEP: delete the pod
May 21 09:59:07.405: INFO: Waiting for pod var-expansion-116ead12-7baf-11e9-be4b-6e6d88bcf118 to disappear
May 21 09:59:07.406: INFO: Pod var-expansion-116ead12-7baf-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:59:07.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-fggfk" for this suite.
May 21 09:59:13.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:59:13.423: INFO: namespace: e2e-tests-var-expansion-fggfk, resource: bindings, ignored listing per whitelist
May 21 09:59:13.470: INFO: namespace e2e-tests-var-expansion-fggfk deletion completed in 6.062066548s

• [SLOW TEST:8.179 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:59:13.471: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
May 21 09:59:17.530: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-9xhcb PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 09:59:17.530: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
May 21 09:59:17.653: INFO: Exec stderr: ""
May 21 09:59:17.653: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-9xhcb PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 09:59:17.653: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
May 21 09:59:17.806: INFO: Exec stderr: ""
May 21 09:59:17.806: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-9xhcb PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 09:59:17.806: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
May 21 09:59:17.928: INFO: Exec stderr: ""
May 21 09:59:17.928: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-9xhcb PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 09:59:17.928: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
May 21 09:59:18.079: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
May 21 09:59:18.079: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-9xhcb PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 09:59:18.079: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
May 21 09:59:18.212: INFO: Exec stderr: ""
May 21 09:59:18.212: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-9xhcb PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 09:59:18.212: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
May 21 09:59:18.350: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
May 21 09:59:18.350: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-9xhcb PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 09:59:18.350: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
May 21 09:59:18.473: INFO: Exec stderr: ""
May 21 09:59:18.473: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-9xhcb PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 09:59:18.473: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
May 21 09:59:18.618: INFO: Exec stderr: ""
May 21 09:59:18.618: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-9xhcb PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 09:59:18.619: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
May 21 09:59:18.757: INFO: Exec stderr: ""
May 21 09:59:18.757: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-9xhcb PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 09:59:18.757: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
May 21 09:59:18.898: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:59:18.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-9xhcb" for this suite.
May 21 09:59:56.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 09:59:56.934: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-9xhcb, resource: bindings, ignored listing per whitelist
May 21 09:59:56.965: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-9xhcb deletion completed in 38.063972053s

• [SLOW TEST:43.495 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 09:59:56.965: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 09:59:57.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 version'
May 21 09:59:57.109: INFO: stderr: ""
May 21 09:59:57.109: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.3\", GitCommit:\"435f92c719f279a3a67808c80521ea17d5715c66\", GitTreeState:\"clean\", BuildDate:\"2018-11-26T12:46:57Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 09:59:57.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mvvz9" for this suite.
May 21 10:00:03.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:00:03.179: INFO: namespace: e2e-tests-kubectl-mvvz9, resource: bindings, ignored listing per whitelist
May 21 10:00:03.185: INFO: namespace e2e-tests-kubectl-mvvz9 deletion completed in 6.072409645s

• [SLOW TEST:6.220 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:00:03.185: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 10:00:03.225: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
May 21 10:00:03.236: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:03.236: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:03.236: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:03.238: INFO: Number of nodes with available pods: 0
May 21 10:00:03.238: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:00:04.242: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:04.242: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:04.242: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:04.244: INFO: Number of nodes with available pods: 0
May 21 10:00:04.244: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:00:05.242: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:05.242: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:05.242: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:05.243: INFO: Number of nodes with available pods: 1
May 21 10:00:05.243: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
May 21 10:00:05.259: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:05.262: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:05.262: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:05.262: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:06.264: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:06.267: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:06.267: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:06.267: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:07.264: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:07.267: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:07.267: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:07.267: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:08.264: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:08.268: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:08.268: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:08.268: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:09.264: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:09.270: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:09.270: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:09.270: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:10.264: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:10.266: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:10.266: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:10.266: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:11.264: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:11.266: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:11.267: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:11.267: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:12.264: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:12.269: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:12.269: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:12.269: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:13.264: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:13.267: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:13.267: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:13.267: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:14.265: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:14.268: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:14.268: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:14.268: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:15.266: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:15.269: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:15.269: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:15.269: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:16.264: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:16.267: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:16.267: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:16.267: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:17.264: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:17.267: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:17.267: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:17.267: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:18.265: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:18.268: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:18.268: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:18.268: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:19.265: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:19.267: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:19.267: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:19.267: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:20.264: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:20.267: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:20.267: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:20.267: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:21.264: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:21.267: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:21.267: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:21.267: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:22.265: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:22.268: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:22.268: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:22.268: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:23.265: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:23.268: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:23.268: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:23.268: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:24.265: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:24.268: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:24.268: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:24.268: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:25.271: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:25.276: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:25.276: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:25.276: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:26.264: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:26.267: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:26.267: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:26.267: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:27.264: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:27.271: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:27.271: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:27.271: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:28.264: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:28.267: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:28.267: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:28.267: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:29.264: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:29.267: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:29.267: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:29.267: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:30.270: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:30.277: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:30.277: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:30.277: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:31.264: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:31.267: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:31.267: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:31.267: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:32.265: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:32.268: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:32.268: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:32.268: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:33.264: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:33.267: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:33.267: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:33.267: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:34.265: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:34.273: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:34.273: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:34.273: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:35.267: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:35.270: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:35.270: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:35.270: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:36.266: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:36.269: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:36.269: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:36.269: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:37.264: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:37.268: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:37.268: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:37.268: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:38.265: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:38.265: INFO: Pod daemon-set-r7xl6 is not available
May 21 10:00:38.268: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:38.268: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:38.268: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:39.264: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:39.264: INFO: Pod daemon-set-r7xl6 is not available
May 21 10:00:39.267: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:39.267: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:39.267: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:40.265: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:40.265: INFO: Pod daemon-set-r7xl6 is not available
May 21 10:00:40.267: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:40.267: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:40.267: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:41.264: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:41.264: INFO: Pod daemon-set-r7xl6 is not available
May 21 10:00:41.267: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:41.267: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:41.267: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:42.264: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:42.265: INFO: Pod daemon-set-r7xl6 is not available
May 21 10:00:42.268: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:42.268: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:42.268: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:43.264: INFO: Wrong image for pod: daemon-set-r7xl6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 10:00:43.264: INFO: Pod daemon-set-r7xl6 is not available
May 21 10:00:43.267: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:43.267: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:43.267: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:44.264: INFO: Pod daemon-set-7sxpb is not available
May 21 10:00:44.267: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:44.267: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:44.267: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
May 21 10:00:44.270: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:44.271: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:44.271: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:44.273: INFO: Number of nodes with available pods: 0
May 21 10:00:44.273: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:00:45.279: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:45.279: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:45.279: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:00:45.282: INFO: Number of nodes with available pods: 1
May 21 10:00:45.282: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-kmwhp, will wait for the garbage collector to delete the pods
May 21 10:00:45.348: INFO: Deleting {extensions DaemonSet} daemon-set took: 4.672105ms
May 21 10:00:45.448: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.112611ms
May 21 10:00:53.750: INFO: Number of nodes with available pods: 0
May 21 10:00:53.750: INFO: Number of running nodes: 0, number of available pods: 0
May 21 10:00:53.752: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-kmwhp/daemonsets","resourceVersion":"7846"},"items":null}

May 21 10:00:53.753: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-kmwhp/pods","resourceVersion":"7846"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:00:53.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-kmwhp" for this suite.
May 21 10:00:59.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:00:59.779: INFO: namespace: e2e-tests-daemonsets-kmwhp, resource: bindings, ignored listing per whitelist
May 21 10:00:59.832: INFO: namespace e2e-tests-daemonsets-kmwhp deletion completed in 6.068574208s

• [SLOW TEST:56.647 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:00:59.833: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-hnpnx.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-hnpnx.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-hnpnx.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-hnpnx.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-hnpnx.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-hnpnx.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 21 10:01:11.924: INFO: DNS probes using e2e-tests-dns-hnpnx/dns-test-55b1cf13-7baf-11e9-be4b-6e6d88bcf118 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:01:11.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-hnpnx" for this suite.
May 21 10:01:17.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:01:17.976: INFO: namespace: e2e-tests-dns-hnpnx, resource: bindings, ignored listing per whitelist
May 21 10:01:18.009: INFO: namespace e2e-tests-dns-hnpnx deletion completed in 6.074889439s

• [SLOW TEST:18.177 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:01:18.010: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-6087b0ed-7baf-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume secrets
May 21 10:01:18.060: INFO: Waiting up to 5m0s for pod "pod-secrets-6088820c-7baf-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-secrets-v2mhb" to be "success or failure"
May 21 10:01:18.064: INFO: Pod "pod-secrets-6088820c-7baf-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 3.805278ms
May 21 10:01:20.066: INFO: Pod "pod-secrets-6088820c-7baf-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006446034s
STEP: Saw pod success
May 21 10:01:20.066: INFO: Pod "pod-secrets-6088820c-7baf-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:01:20.068: INFO: Trying to get logs from node 192.168.5.29 pod pod-secrets-6088820c-7baf-11e9-be4b-6e6d88bcf118 container secret-volume-test: <nil>
STEP: delete the pod
May 21 10:01:20.083: INFO: Waiting for pod pod-secrets-6088820c-7baf-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:01:20.087: INFO: Pod pod-secrets-6088820c-7baf-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:01:20.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-v2mhb" for this suite.
May 21 10:01:26.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:01:26.151: INFO: namespace: e2e-tests-secrets-v2mhb, resource: bindings, ignored listing per whitelist
May 21 10:01:26.154: INFO: namespace e2e-tests-secrets-v2mhb deletion completed in 6.06466322s

• [SLOW TEST:8.145 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:01:26.155: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 10:01:26.203: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6562d5ac-7baf-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-downward-api-xqn9v" to be "success or failure"
May 21 10:01:26.206: INFO: Pod "downwardapi-volume-6562d5ac-7baf-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 2.564841ms
May 21 10:01:28.209: INFO: Pod "downwardapi-volume-6562d5ac-7baf-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005417218s
STEP: Saw pod success
May 21 10:01:28.209: INFO: Pod "downwardapi-volume-6562d5ac-7baf-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:01:28.210: INFO: Trying to get logs from node 192.168.5.29 pod downwardapi-volume-6562d5ac-7baf-11e9-be4b-6e6d88bcf118 container client-container: <nil>
STEP: delete the pod
May 21 10:01:28.232: INFO: Waiting for pod downwardapi-volume-6562d5ac-7baf-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:01:28.235: INFO: Pod downwardapi-volume-6562d5ac-7baf-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:01:28.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xqn9v" for this suite.
May 21 10:01:34.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:01:34.261: INFO: namespace: e2e-tests-downward-api-xqn9v, resource: bindings, ignored listing per whitelist
May 21 10:01:34.299: INFO: namespace e2e-tests-downward-api-xqn9v deletion completed in 6.061272376s

• [SLOW TEST:8.144 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:01:34.299: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 10:01:34.342: INFO: Pod name cleanup-pod: Found 0 pods out of 1
May 21 10:01:39.345: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 21 10:01:39.345: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 21 10:01:41.367: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-5dmmw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5dmmw/deployments/test-cleanup-deployment,UID:6d3993f6-7baf-11e9-acff-fa163e1b1d33,ResourceVersion:8061,Generation:1,CreationTimestamp:2019-05-21 10:01:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-21 10:01:39 +0000 UTC 2019-05-21 10:01:39 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-21 10:01:40 +0000 UTC 2019-05-21 10:01:39 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-755f6b95cc" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 21 10:01:41.369: INFO: New ReplicaSet "test-cleanup-deployment-755f6b95cc" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-755f6b95cc,GenerateName:,Namespace:e2e-tests-deployment-5dmmw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5dmmw/replicasets/test-cleanup-deployment-755f6b95cc,UID:6d3b3d96-7baf-11e9-8d66-fa163e76243a,ResourceVersion:8052,Generation:1,CreationTimestamp:2019-05-21 10:01:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 6d3993f6-7baf-11e9-acff-fa163e1b1d33 0xc421830527 0xc421830528}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 21 10:01:41.371: INFO: Pod "test-cleanup-deployment-755f6b95cc-fdlfg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-755f6b95cc-fdlfg,GenerateName:test-cleanup-deployment-755f6b95cc-,Namespace:e2e-tests-deployment-5dmmw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5dmmw/pods/test-cleanup-deployment-755f6b95cc-fdlfg,UID:6d3b9533-7baf-11e9-8d66-fa163e76243a,ResourceVersion:8051,Generation:0,CreationTimestamp:2019-05-21 10:01:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-755f6b95cc 6d3b3d96-7baf-11e9-8d66-fa163e76243a 0xc420dc5097 0xc420dc5098}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-492dn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-492dn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-492dn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:01:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:01:40 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:01:40 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:01:39 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.29,PodIP:10.8.1.136,StartTime:2019-05-21 10:01:39 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-21 10:01:40 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://d3a2a5a8d9191afb565784fcda1cbfec44ef91b0ee29a103170f89736a19405b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:01:41.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-5dmmw" for this suite.
May 21 10:01:47.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:01:47.418: INFO: namespace: e2e-tests-deployment-5dmmw, resource: bindings, ignored listing per whitelist
May 21 10:01:47.443: INFO: namespace e2e-tests-deployment-5dmmw deletion completed in 6.069015889s

• [SLOW TEST:13.144 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:01:47.443: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-p799j
May 21 10:01:49.495: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-p799j
STEP: checking the pod's current state and verifying that restartCount is present
May 21 10:01:49.497: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:05:49.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-p799j" for this suite.
May 21 10:05:55.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:05:55.881: INFO: namespace: e2e-tests-container-probe-p799j, resource: bindings, ignored listing per whitelist
May 21 10:05:55.926: INFO: namespace e2e-tests-container-probe-p799j deletion completed in 6.072231438s

• [SLOW TEST:248.483 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:05:55.926: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
May 21 10:05:55.973: INFO: Waiting up to 5m0s for pod "client-containers-062e6b2a-7bb0-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-containers-vsmm7" to be "success or failure"
May 21 10:05:55.975: INFO: Pod "client-containers-062e6b2a-7bb0-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 1.734973ms
May 21 10:05:57.978: INFO: Pod "client-containers-062e6b2a-7bb0-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004400541s
STEP: Saw pod success
May 21 10:05:57.978: INFO: Pod "client-containers-062e6b2a-7bb0-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:05:57.979: INFO: Trying to get logs from node 192.168.5.29 pod client-containers-062e6b2a-7bb0-11e9-be4b-6e6d88bcf118 container test-container: <nil>
STEP: delete the pod
May 21 10:05:57.992: INFO: Waiting for pod client-containers-062e6b2a-7bb0-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:05:57.994: INFO: Pod client-containers-062e6b2a-7bb0-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:05:57.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-vsmm7" for this suite.
May 21 10:06:04.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:06:04.052: INFO: namespace: e2e-tests-containers-vsmm7, resource: bindings, ignored listing per whitelist
May 21 10:06:04.062: INFO: namespace e2e-tests-containers-vsmm7 deletion completed in 6.064969482s

• [SLOW TEST:8.136 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:06:04.062: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
May 21 10:06:06.627: INFO: Successfully updated pod "annotationupdate0b07aeeb-7bb0-11e9-be4b-6e6d88bcf118"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:06:10.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-c5g5p" for this suite.
May 21 10:06:32.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:06:32.690: INFO: namespace: e2e-tests-downward-api-c5g5p, resource: bindings, ignored listing per whitelist
May 21 10:06:32.711: INFO: namespace e2e-tests-downward-api-c5g5p deletion completed in 22.064470224s

• [SLOW TEST:28.649 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:06:32.711: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0521 10:07:12.772018      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 21 10:07:12.772: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:07:12.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-7gpkg" for this suite.
May 21 10:07:18.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:07:18.837: INFO: namespace: e2e-tests-gc-7gpkg, resource: bindings, ignored listing per whitelist
May 21 10:07:18.856: INFO: namespace e2e-tests-gc-7gpkg deletion completed in 6.081735268s

• [SLOW TEST:46.145 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:07:18.857: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 10:07:18.920: INFO: Waiting up to 5m0s for pod "downwardapi-volume-379e9eb7-7bb0-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-downward-api-m4nqt" to be "success or failure"
May 21 10:07:18.923: INFO: Pod "downwardapi-volume-379e9eb7-7bb0-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 2.727253ms
May 21 10:07:20.926: INFO: Pod "downwardapi-volume-379e9eb7-7bb0-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006020221s
May 21 10:07:22.940: INFO: Pod "downwardapi-volume-379e9eb7-7bb0-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020401777s
May 21 10:07:24.943: INFO: Pod "downwardapi-volume-379e9eb7-7bb0-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023280992s
May 21 10:07:26.947: INFO: Pod "downwardapi-volume-379e9eb7-7bb0-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.026738036s
STEP: Saw pod success
May 21 10:07:26.947: INFO: Pod "downwardapi-volume-379e9eb7-7bb0-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:07:26.948: INFO: Trying to get logs from node 192.168.5.29 pod downwardapi-volume-379e9eb7-7bb0-11e9-be4b-6e6d88bcf118 container client-container: <nil>
STEP: delete the pod
May 21 10:07:26.962: INFO: Waiting for pod downwardapi-volume-379e9eb7-7bb0-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:07:26.965: INFO: Pod downwardapi-volume-379e9eb7-7bb0-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:07:26.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-m4nqt" for this suite.
May 21 10:07:32.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:07:32.993: INFO: namespace: e2e-tests-downward-api-m4nqt, resource: bindings, ignored listing per whitelist
May 21 10:07:33.036: INFO: namespace e2e-tests-downward-api-m4nqt deletion completed in 6.067648682s

• [SLOW TEST:14.180 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:07:33.036: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:07:33.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-mqbkq" for this suite.
May 21 10:07:39.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:07:39.126: INFO: namespace: e2e-tests-services-mqbkq, resource: bindings, ignored listing per whitelist
May 21 10:07:39.144: INFO: namespace e2e-tests-services-mqbkq deletion completed in 6.061991425s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.108 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:07:39.144: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
May 21 10:07:39.185: INFO: PodSpec: initContainers in spec.initContainers
May 21 10:08:24.707: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-43b42325-7bb0-11e9-be4b-6e6d88bcf118", GenerateName:"", Namespace:"e2e-tests-init-container-mwsjm", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-mwsjm/pods/pod-init-43b42325-7bb0-11e9-be4b-6e6d88bcf118", UID:"43b482b5-7bb0-11e9-acff-fa163e1b1d33", ResourceVersion:"8996", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63694030059, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"185058126"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-k8wvc", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc4211f8e00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-k8wvc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-k8wvc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}, "cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-k8wvc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc421831cc8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"192.168.5.29", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc421c33d40), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration(nil), HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694030059, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694030059, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694030059, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694030059, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.5.29", PodIP:"10.8.1.153", StartTime:(*v1.Time)(0xc42187b9e0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc420797570)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc420797810)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://eac4658c75d33febe06f75171bc1801d0b2a04801441893b0d0f614f9cb99de7"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc42187ba20), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc42187ba00), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:08:24.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-mwsjm" for this suite.
May 21 10:08:46.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:08:46.761: INFO: namespace: e2e-tests-init-container-mwsjm, resource: bindings, ignored listing per whitelist
May 21 10:08:46.779: INFO: namespace e2e-tests-init-container-mwsjm deletion completed in 22.067258911s

• [SLOW TEST:67.635 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:08:46.780: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-bbmv
STEP: Creating a pod to test atomic-volume-subpath
May 21 10:08:46.836: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-bbmv" in namespace "e2e-tests-subpath-zk6jf" to be "success or failure"
May 21 10:08:46.840: INFO: Pod "pod-subpath-test-configmap-bbmv": Phase="Pending", Reason="", readiness=false. Elapsed: 3.832281ms
May 21 10:08:48.843: INFO: Pod "pod-subpath-test-configmap-bbmv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006932156s
May 21 10:08:50.846: INFO: Pod "pod-subpath-test-configmap-bbmv": Phase="Running", Reason="", readiness=false. Elapsed: 4.010632339s
May 21 10:08:52.850: INFO: Pod "pod-subpath-test-configmap-bbmv": Phase="Running", Reason="", readiness=false. Elapsed: 6.013724595s
May 21 10:08:54.853: INFO: Pod "pod-subpath-test-configmap-bbmv": Phase="Running", Reason="", readiness=false. Elapsed: 8.017288368s
May 21 10:08:56.857: INFO: Pod "pod-subpath-test-configmap-bbmv": Phase="Running", Reason="", readiness=false. Elapsed: 10.02074946s
May 21 10:08:58.860: INFO: Pod "pod-subpath-test-configmap-bbmv": Phase="Running", Reason="", readiness=false. Elapsed: 12.023934701s
May 21 10:09:00.863: INFO: Pod "pod-subpath-test-configmap-bbmv": Phase="Running", Reason="", readiness=false. Elapsed: 14.027485938s
May 21 10:09:02.868: INFO: Pod "pod-subpath-test-configmap-bbmv": Phase="Running", Reason="", readiness=false. Elapsed: 16.031835329s
May 21 10:09:04.871: INFO: Pod "pod-subpath-test-configmap-bbmv": Phase="Running", Reason="", readiness=false. Elapsed: 18.035137452s
May 21 10:09:06.874: INFO: Pod "pod-subpath-test-configmap-bbmv": Phase="Running", Reason="", readiness=false. Elapsed: 20.038158748s
May 21 10:09:08.877: INFO: Pod "pod-subpath-test-configmap-bbmv": Phase="Running", Reason="", readiness=false. Elapsed: 22.041162761s
May 21 10:09:10.880: INFO: Pod "pod-subpath-test-configmap-bbmv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.044108465s
STEP: Saw pod success
May 21 10:09:10.880: INFO: Pod "pod-subpath-test-configmap-bbmv" satisfied condition "success or failure"
May 21 10:09:10.882: INFO: Trying to get logs from node 192.168.5.29 pod pod-subpath-test-configmap-bbmv container test-container-subpath-configmap-bbmv: <nil>
STEP: delete the pod
May 21 10:09:10.897: INFO: Waiting for pod pod-subpath-test-configmap-bbmv to disappear
May 21 10:09:10.899: INFO: Pod pod-subpath-test-configmap-bbmv no longer exists
STEP: Deleting pod pod-subpath-test-configmap-bbmv
May 21 10:09:10.899: INFO: Deleting pod "pod-subpath-test-configmap-bbmv" in namespace "e2e-tests-subpath-zk6jf"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:09:10.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-zk6jf" for this suite.
May 21 10:09:16.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:09:16.929: INFO: namespace: e2e-tests-subpath-zk6jf, resource: bindings, ignored listing per whitelist
May 21 10:09:16.972: INFO: namespace e2e-tests-subpath-zk6jf deletion completed in 6.068582085s

• [SLOW TEST:30.192 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:09:16.972: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 10:09:17.015: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7e03031d-7bb0-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-downward-api-f94jf" to be "success or failure"
May 21 10:09:17.018: INFO: Pod "downwardapi-volume-7e03031d-7bb0-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 2.547808ms
May 21 10:09:19.023: INFO: Pod "downwardapi-volume-7e03031d-7bb0-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007300493s
STEP: Saw pod success
May 21 10:09:19.023: INFO: Pod "downwardapi-volume-7e03031d-7bb0-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:09:19.024: INFO: Trying to get logs from node 192.168.5.29 pod downwardapi-volume-7e03031d-7bb0-11e9-be4b-6e6d88bcf118 container client-container: <nil>
STEP: delete the pod
May 21 10:09:19.039: INFO: Waiting for pod downwardapi-volume-7e03031d-7bb0-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:09:19.040: INFO: Pod downwardapi-volume-7e03031d-7bb0-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:09:19.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-f94jf" for this suite.
May 21 10:09:25.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:09:25.069: INFO: namespace: e2e-tests-downward-api-f94jf, resource: bindings, ignored listing per whitelist
May 21 10:09:25.113: INFO: namespace e2e-tests-downward-api-f94jf deletion completed in 6.067991368s

• [SLOW TEST:8.141 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:09:25.113: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-7kkcf
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 21 10:09:25.151: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 21 10:09:43.183: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.8.1.158:8080/dial?request=hostName&protocol=udp&host=10.8.1.157&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-7kkcf PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 10:09:43.183: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
May 21 10:09:43.316: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:09:43.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-7kkcf" for this suite.
May 21 10:10:05.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:10:05.387: INFO: namespace: e2e-tests-pod-network-test-7kkcf, resource: bindings, ignored listing per whitelist
May 21 10:10:05.388: INFO: namespace e2e-tests-pod-network-test-7kkcf deletion completed in 22.067725883s

• [SLOW TEST:40.274 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:10:05.388: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-9adec417-7bb0-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume configMaps
May 21 10:10:05.435: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9adf5f3e-7bb0-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-projected-p7nvw" to be "success or failure"
May 21 10:10:05.437: INFO: Pod "pod-projected-configmaps-9adf5f3e-7bb0-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 1.900556ms
May 21 10:10:07.440: INFO: Pod "pod-projected-configmaps-9adf5f3e-7bb0-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005334827s
STEP: Saw pod success
May 21 10:10:07.440: INFO: Pod "pod-projected-configmaps-9adf5f3e-7bb0-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:10:07.442: INFO: Trying to get logs from node 192.168.5.29 pod pod-projected-configmaps-9adf5f3e-7bb0-11e9-be4b-6e6d88bcf118 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 10:10:07.454: INFO: Waiting for pod pod-projected-configmaps-9adf5f3e-7bb0-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:10:07.458: INFO: Pod pod-projected-configmaps-9adf5f3e-7bb0-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:10:07.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-p7nvw" for this suite.
May 21 10:10:13.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:10:13.487: INFO: namespace: e2e-tests-projected-p7nvw, resource: bindings, ignored listing per whitelist
May 21 10:10:13.533: INFO: namespace e2e-tests-projected-p7nvw deletion completed in 6.070541866s

• [SLOW TEST:8.145 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:10:13.533: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-9fba4ec8-7bb0-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume configMaps
May 21 10:10:13.584: INFO: Waiting up to 5m0s for pod "pod-configmaps-9fbae16e-7bb0-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-configmap-n79xm" to be "success or failure"
May 21 10:10:13.586: INFO: Pod "pod-configmaps-9fbae16e-7bb0-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 2.856741ms
May 21 10:10:15.589: INFO: Pod "pod-configmaps-9fbae16e-7bb0-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005791769s
STEP: Saw pod success
May 21 10:10:15.589: INFO: Pod "pod-configmaps-9fbae16e-7bb0-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:10:15.591: INFO: Trying to get logs from node 192.168.5.29 pod pod-configmaps-9fbae16e-7bb0-11e9-be4b-6e6d88bcf118 container configmap-volume-test: <nil>
STEP: delete the pod
May 21 10:10:15.604: INFO: Waiting for pod pod-configmaps-9fbae16e-7bb0-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:10:15.606: INFO: Pod pod-configmaps-9fbae16e-7bb0-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:10:15.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-n79xm" for this suite.
May 21 10:10:21.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:10:21.645: INFO: namespace: e2e-tests-configmap-n79xm, resource: bindings, ignored listing per whitelist
May 21 10:10:21.675: INFO: namespace e2e-tests-configmap-n79xm deletion completed in 6.066040764s

• [SLOW TEST:8.141 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:10:21.675: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
May 21 10:10:21.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 cluster-info'
May 21 10:10:21.870: INFO: stderr: ""
May 21 10:10:21.870: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443\x1b[0m\n\x1b[0;32mHeapster\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443/api/v1/namespaces/kube-system/services/heapster/proxy\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mmonitoring-influxdb\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443/api/v1/namespaces/kube-system/services/monitoring-influxdb/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:10:21.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ngr78" for this suite.
May 21 10:10:27.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:10:27.936: INFO: namespace: e2e-tests-kubectl-ngr78, resource: bindings, ignored listing per whitelist
May 21 10:10:27.944: INFO: namespace e2e-tests-kubectl-ngr78 deletion completed in 6.07089302s

• [SLOW TEST:6.270 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:10:27.945: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-vtvs8
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-vtvs8
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-vtvs8
May 21 10:10:28.000: INFO: Found 0 stateful pods, waiting for 1
May 21 10:10:38.004: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
May 21 10:10:38.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-vtvs8 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 21 10:10:38.239: INFO: stderr: ""
May 21 10:10:38.239: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 21 10:10:38.239: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 21 10:10:38.242: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 21 10:10:48.245: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 21 10:10:48.245: INFO: Waiting for statefulset status.replicas updated to 0
May 21 10:10:48.255: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999739s
May 21 10:10:49.258: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997651219s
May 21 10:10:50.260: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.994929757s
May 21 10:10:51.264: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.992300469s
May 21 10:10:52.267: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.988858479s
May 21 10:10:53.269: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.98616684s
May 21 10:10:54.272: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.983519785s
May 21 10:10:55.275: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.980407033s
May 21 10:10:56.278: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.977652759s
May 21 10:10:57.281: INFO: Verifying statefulset ss doesn't scale past 1 for another 974.965915ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-vtvs8
May 21 10:10:58.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-vtvs8 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:10:58.542: INFO: stderr: ""
May 21 10:10:58.542: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 21 10:10:58.542: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 21 10:10:58.546: INFO: Found 2 stateful pods, waiting for 3
May 21 10:11:08.550: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 21 10:11:08.550: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 21 10:11:08.550: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
May 21 10:11:08.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-vtvs8 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 21 10:11:08.854: INFO: stderr: ""
May 21 10:11:08.854: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 21 10:11:08.854: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 21 10:11:08.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-vtvs8 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 21 10:11:09.119: INFO: stderr: ""
May 21 10:11:09.119: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 21 10:11:09.119: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 21 10:11:09.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-vtvs8 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 21 10:11:09.365: INFO: stderr: ""
May 21 10:11:09.365: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 21 10:11:09.365: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 21 10:11:09.365: INFO: Waiting for statefulset status.replicas updated to 0
May 21 10:11:09.367: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
May 21 10:11:19.373: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 21 10:11:19.373: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 21 10:11:19.373: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 21 10:11:19.383: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999779s
May 21 10:11:20.386: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995927613s
May 21 10:11:21.389: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992731202s
May 21 10:11:22.393: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.989786375s
May 21 10:11:23.402: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.9854877s
May 21 10:11:24.405: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.97700233s
May 21 10:11:25.409: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.973538743s
May 21 10:11:26.412: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.970023359s
May 21 10:11:27.415: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.966823147s
May 21 10:11:28.419: INFO: Verifying statefulset ss doesn't scale past 3 for another 963.261201ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-vtvs8
May 21 10:11:29.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-vtvs8 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:11:29.654: INFO: stderr: ""
May 21 10:11:29.654: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 21 10:11:29.654: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 21 10:11:29.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-vtvs8 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:11:29.889: INFO: stderr: ""
May 21 10:11:29.889: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 21 10:11:29.889: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 21 10:11:29.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-vtvs8 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:11:30.145: INFO: stderr: ""
May 21 10:11:30.145: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 21 10:11:30.145: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 21 10:11:30.145: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 21 10:11:40.170: INFO: Deleting all statefulset in ns e2e-tests-statefulset-vtvs8
May 21 10:11:40.172: INFO: Scaling statefulset ss to 0
May 21 10:11:40.177: INFO: Waiting for statefulset status.replicas updated to 0
May 21 10:11:40.179: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:11:40.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-vtvs8" for this suite.
May 21 10:11:46.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:11:46.226: INFO: namespace: e2e-tests-statefulset-vtvs8, resource: bindings, ignored listing per whitelist
May 21 10:11:46.258: INFO: namespace e2e-tests-statefulset-vtvs8 deletion completed in 6.068494102s

• [SLOW TEST:78.314 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:11:46.259: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 10:11:46.305: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d6fee0f7-7bb0-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-projected-b2vb7" to be "success or failure"
May 21 10:11:46.312: INFO: Pod "downwardapi-volume-d6fee0f7-7bb0-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 7.201509ms
May 21 10:11:48.315: INFO: Pod "downwardapi-volume-d6fee0f7-7bb0-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009411782s
STEP: Saw pod success
May 21 10:11:48.315: INFO: Pod "downwardapi-volume-d6fee0f7-7bb0-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:11:48.318: INFO: Trying to get logs from node 192.168.5.29 pod downwardapi-volume-d6fee0f7-7bb0-11e9-be4b-6e6d88bcf118 container client-container: <nil>
STEP: delete the pod
May 21 10:11:48.335: INFO: Waiting for pod downwardapi-volume-d6fee0f7-7bb0-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:11:48.341: INFO: Pod downwardapi-volume-d6fee0f7-7bb0-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:11:48.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-b2vb7" for this suite.
May 21 10:11:54.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:11:54.399: INFO: namespace: e2e-tests-projected-b2vb7, resource: bindings, ignored listing per whitelist
May 21 10:11:54.413: INFO: namespace e2e-tests-projected-b2vb7 deletion completed in 6.063717637s

• [SLOW TEST:8.154 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:11:54.413: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
May 21 10:11:58.485: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 21 10:11:58.487: INFO: Pod pod-with-prestop-http-hook still exists
May 21 10:12:00.487: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 21 10:12:00.491: INFO: Pod pod-with-prestop-http-hook still exists
May 21 10:12:02.487: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 21 10:12:02.490: INFO: Pod pod-with-prestop-http-hook still exists
May 21 10:12:04.487: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 21 10:12:04.490: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:12:04.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-xthsb" for this suite.
May 21 10:12:26.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:12:26.556: INFO: namespace: e2e-tests-container-lifecycle-hook-xthsb, resource: bindings, ignored listing per whitelist
May 21 10:12:26.566: INFO: namespace e2e-tests-container-lifecycle-hook-xthsb deletion completed in 22.067429147s

• [SLOW TEST:32.153 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:12:26.566: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 21 10:12:26.611: INFO: Waiting up to 5m0s for pod "pod-ef052b40-7bb0-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-emptydir-28k9k" to be "success or failure"
May 21 10:12:26.614: INFO: Pod "pod-ef052b40-7bb0-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 2.29168ms
May 21 10:12:28.619: INFO: Pod "pod-ef052b40-7bb0-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007407991s
STEP: Saw pod success
May 21 10:12:28.619: INFO: Pod "pod-ef052b40-7bb0-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:12:28.624: INFO: Trying to get logs from node 192.168.5.29 pod pod-ef052b40-7bb0-11e9-be4b-6e6d88bcf118 container test-container: <nil>
STEP: delete the pod
May 21 10:12:28.647: INFO: Waiting for pod pod-ef052b40-7bb0-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:12:28.650: INFO: Pod pod-ef052b40-7bb0-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:12:28.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-28k9k" for this suite.
May 21 10:12:34.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:12:34.704: INFO: namespace: e2e-tests-emptydir-28k9k, resource: bindings, ignored listing per whitelist
May 21 10:12:34.723: INFO: namespace e2e-tests-emptydir-28k9k deletion completed in 6.067125494s

• [SLOW TEST:8.157 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:12:34.723: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 10:12:34.786: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"f3e44c42-7bb0-11e9-acff-fa163e1b1d33", Controller:(*bool)(0xc42203b33e), BlockOwnerDeletion:(*bool)(0xc42203b33f)}}
May 21 10:12:34.789: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"f3e2cf0c-7bb0-11e9-acff-fa163e1b1d33", Controller:(*bool)(0xc4220ea466), BlockOwnerDeletion:(*bool)(0xc4220ea467)}}
May 21 10:12:34.793: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"f3e37686-7bb0-11e9-acff-fa163e1b1d33", Controller:(*bool)(0xc42203b4e6), BlockOwnerDeletion:(*bool)(0xc42203b4e7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:12:39.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-2dpr2" for this suite.
May 21 10:12:45.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:12:45.842: INFO: namespace: e2e-tests-gc-2dpr2, resource: bindings, ignored listing per whitelist
May 21 10:12:45.869: INFO: namespace e2e-tests-gc-2dpr2 deletion completed in 6.064278301s

• [SLOW TEST:11.146 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:12:45.869: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 10:12:45.918: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fa871427-7bb0-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-projected-d576z" to be "success or failure"
May 21 10:12:45.919: INFO: Pod "downwardapi-volume-fa871427-7bb0-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 1.51666ms
May 21 10:12:47.922: INFO: Pod "downwardapi-volume-fa871427-7bb0-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004115986s
STEP: Saw pod success
May 21 10:12:47.922: INFO: Pod "downwardapi-volume-fa871427-7bb0-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:12:47.923: INFO: Trying to get logs from node 192.168.5.29 pod downwardapi-volume-fa871427-7bb0-11e9-be4b-6e6d88bcf118 container client-container: <nil>
STEP: delete the pod
May 21 10:12:47.935: INFO: Waiting for pod downwardapi-volume-fa871427-7bb0-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:12:47.936: INFO: Pod downwardapi-volume-fa871427-7bb0-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:12:47.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d576z" for this suite.
May 21 10:12:53.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:12:53.964: INFO: namespace: e2e-tests-projected-d576z, resource: bindings, ignored listing per whitelist
May 21 10:12:54.001: INFO: namespace e2e-tests-projected-d576z deletion completed in 6.061627377s

• [SLOW TEST:8.132 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:12:54.001: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 10:12:54.048: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ff5fbeda-7bb0-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-downward-api-8vn7h" to be "success or failure"
May 21 10:12:54.050: INFO: Pod "downwardapi-volume-ff5fbeda-7bb0-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 1.49022ms
May 21 10:12:56.052: INFO: Pod "downwardapi-volume-ff5fbeda-7bb0-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004043734s
STEP: Saw pod success
May 21 10:12:56.052: INFO: Pod "downwardapi-volume-ff5fbeda-7bb0-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:12:56.055: INFO: Trying to get logs from node 192.168.5.29 pod downwardapi-volume-ff5fbeda-7bb0-11e9-be4b-6e6d88bcf118 container client-container: <nil>
STEP: delete the pod
May 21 10:12:56.072: INFO: Waiting for pod downwardapi-volume-ff5fbeda-7bb0-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:12:56.075: INFO: Pod downwardapi-volume-ff5fbeda-7bb0-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:12:56.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8vn7h" for this suite.
May 21 10:13:02.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:13:02.146: INFO: namespace: e2e-tests-downward-api-8vn7h, resource: bindings, ignored listing per whitelist
May 21 10:13:02.163: INFO: namespace e2e-tests-downward-api-8vn7h deletion completed in 6.079060678s

• [SLOW TEST:8.162 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:13:02.163: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 21 10:13:02.208: INFO: Waiting up to 5m0s for pod "pod-043cd73a-7bb1-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-emptydir-pl65j" to be "success or failure"
May 21 10:13:02.212: INFO: Pod "pod-043cd73a-7bb1-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 3.123185ms
May 21 10:13:04.214: INFO: Pod "pod-043cd73a-7bb1-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005897619s
STEP: Saw pod success
May 21 10:13:04.214: INFO: Pod "pod-043cd73a-7bb1-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:13:04.216: INFO: Trying to get logs from node 192.168.5.29 pod pod-043cd73a-7bb1-11e9-be4b-6e6d88bcf118 container test-container: <nil>
STEP: delete the pod
May 21 10:13:04.238: INFO: Waiting for pod pod-043cd73a-7bb1-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:13:04.241: INFO: Pod pod-043cd73a-7bb1-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:13:04.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pl65j" for this suite.
May 21 10:13:10.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:13:10.286: INFO: namespace: e2e-tests-emptydir-pl65j, resource: bindings, ignored listing per whitelist
May 21 10:13:10.305: INFO: namespace e2e-tests-emptydir-pl65j deletion completed in 6.060878908s

• [SLOW TEST:8.142 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:13:10.305: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 21 10:13:10.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-s7dtk'
May 21 10:13:10.449: INFO: stderr: ""
May 21 10:13:10.449: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
May 21 10:13:15.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-s7dtk -o json'
May 21 10:13:15.584: INFO: stderr: ""
May 21 10:13:15.584: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-05-21T10:13:10Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-s7dtk\",\n        \"resourceVersion\": \"10009\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-s7dtk/pods/e2e-test-nginx-pod\",\n        \"uid\": \"0924f590-7bb1-11e9-8d09-fa163e36b516\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-gxln4\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"192.168.5.29\",\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"volumes\": [\n            {\n                \"name\": \"default-token-gxln4\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-gxln4\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-21T10:13:10Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-21T10:13:11Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-21T10:13:11Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-21T10:13:10Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://32d6ae84a1ccd0ad48f8b6870fdf762255cf8e109fb37dccbedc9d8ff6bc34b3\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-05-21T10:13:11Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.5.29\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.8.1.178\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-05-21T10:13:10Z\"\n    }\n}\n"
STEP: replace the image in the pod
May 21 10:13:15.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 replace -f - --namespace=e2e-tests-kubectl-s7dtk'
May 21 10:13:15.770: INFO: stderr: ""
May 21 10:13:15.770: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
May 21 10:13:15.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-s7dtk'
May 21 10:13:23.695: INFO: stderr: ""
May 21 10:13:23.695: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:13:23.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-s7dtk" for this suite.
May 21 10:13:29.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:13:29.763: INFO: namespace: e2e-tests-kubectl-s7dtk, resource: bindings, ignored listing per whitelist
May 21 10:13:29.767: INFO: namespace e2e-tests-kubectl-s7dtk deletion completed in 6.0685107s

• [SLOW TEST:19.462 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:13:29.768: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-2b8wx
I0521 10:13:29.812625      15 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-2b8wx, replica count: 1
I0521 10:13:30.863134      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0521 10:13:31.863267      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 21 10:13:31.972: INFO: Created: latency-svc-9j5mt
May 21 10:13:31.979: INFO: Got endpoints: latency-svc-9j5mt [15.778046ms]
May 21 10:13:31.989: INFO: Created: latency-svc-wtdnj
May 21 10:13:31.991: INFO: Got endpoints: latency-svc-wtdnj [11.990408ms]
May 21 10:13:32.021: INFO: Created: latency-svc-jnntw
May 21 10:13:32.021: INFO: Created: latency-svc-sbxjn
May 21 10:13:32.024: INFO: Got endpoints: latency-svc-sbxjn [44.756022ms]
May 21 10:13:32.024: INFO: Got endpoints: latency-svc-jnntw [44.857779ms]
May 21 10:13:32.026: INFO: Created: latency-svc-9z2zp
May 21 10:13:32.031: INFO: Got endpoints: latency-svc-9z2zp [52.155242ms]
May 21 10:13:32.032: INFO: Created: latency-svc-kklmg
May 21 10:13:32.034: INFO: Got endpoints: latency-svc-kklmg [54.616812ms]
May 21 10:13:32.036: INFO: Created: latency-svc-p5zfs
May 21 10:13:32.038: INFO: Got endpoints: latency-svc-p5zfs [59.02949ms]
May 21 10:13:32.044: INFO: Created: latency-svc-ctncj
May 21 10:13:32.048: INFO: Got endpoints: latency-svc-ctncj [68.585594ms]
May 21 10:13:32.064: INFO: Created: latency-svc-8czpg
May 21 10:13:32.065: INFO: Got endpoints: latency-svc-8czpg [86.013331ms]
May 21 10:13:32.067: INFO: Created: latency-svc-dcgwd
May 21 10:13:32.069: INFO: Got endpoints: latency-svc-dcgwd [89.271937ms]
May 21 10:13:32.070: INFO: Created: latency-svc-594nk
May 21 10:13:32.073: INFO: Got endpoints: latency-svc-594nk [93.40867ms]
May 21 10:13:32.074: INFO: Created: latency-svc-flt8f
May 21 10:13:32.078: INFO: Got endpoints: latency-svc-flt8f [98.778431ms]
May 21 10:13:32.081: INFO: Created: latency-svc-mc74m
May 21 10:13:32.083: INFO: Got endpoints: latency-svc-mc74m [104.010788ms]
May 21 10:13:32.090: INFO: Created: latency-svc-rdsg5
May 21 10:13:32.093: INFO: Got endpoints: latency-svc-rdsg5 [113.907931ms]
May 21 10:13:32.095: INFO: Created: latency-svc-mg85v
May 21 10:13:32.097: INFO: Got endpoints: latency-svc-mg85v [117.28999ms]
May 21 10:13:32.102: INFO: Created: latency-svc-h7l7n
May 21 10:13:32.105: INFO: Got endpoints: latency-svc-h7l7n [125.629408ms]
May 21 10:13:32.107: INFO: Created: latency-svc-fc6fk
May 21 10:13:32.111: INFO: Got endpoints: latency-svc-fc6fk [120.569078ms]
May 21 10:13:32.120: INFO: Created: latency-svc-qmrzs
May 21 10:13:32.137: INFO: Got endpoints: latency-svc-qmrzs [113.515939ms]
May 21 10:13:32.141: INFO: Created: latency-svc-82wgc
May 21 10:13:32.146: INFO: Got endpoints: latency-svc-82wgc [122.418612ms]
May 21 10:13:32.154: INFO: Created: latency-svc-qwl75
May 21 10:13:32.154: INFO: Got endpoints: latency-svc-qwl75 [122.683624ms]
May 21 10:13:32.163: INFO: Created: latency-svc-m9f7j
May 21 10:13:32.168: INFO: Got endpoints: latency-svc-m9f7j [134.258107ms]
May 21 10:13:32.194: INFO: Created: latency-svc-bwdmc
May 21 10:13:32.194: INFO: Created: latency-svc-4qkmc
May 21 10:13:32.202: INFO: Created: latency-svc-lfmg7
May 21 10:13:32.202: INFO: Got endpoints: latency-svc-bwdmc [154.614397ms]
May 21 10:13:32.203: INFO: Got endpoints: latency-svc-4qkmc [164.543498ms]
May 21 10:13:32.203: INFO: Got endpoints: latency-svc-lfmg7 [138.201604ms]
May 21 10:13:32.213: INFO: Created: latency-svc-4lghn
May 21 10:13:32.217: INFO: Got endpoints: latency-svc-4lghn [147.975445ms]
May 21 10:13:32.229: INFO: Created: latency-svc-xmntz
May 21 10:13:32.231: INFO: Created: latency-svc-kk8rr
May 21 10:13:32.244: INFO: Got endpoints: latency-svc-kk8rr [165.935156ms]
May 21 10:13:32.244: INFO: Got endpoints: latency-svc-xmntz [171.547839ms]
May 21 10:13:32.248: INFO: Created: latency-svc-rkgj5
May 21 10:13:32.251: INFO: Got endpoints: latency-svc-rkgj5 [167.902228ms]
May 21 10:13:32.256: INFO: Created: latency-svc-7rz8x
May 21 10:13:32.259: INFO: Got endpoints: latency-svc-7rz8x [15.236859ms]
May 21 10:13:32.263: INFO: Created: latency-svc-mcz6z
May 21 10:13:32.267: INFO: Got endpoints: latency-svc-mcz6z [174.06675ms]
May 21 10:13:32.281: INFO: Created: latency-svc-pf6m7
May 21 10:13:32.281: INFO: Created: latency-svc-k6bx5
May 21 10:13:32.281: INFO: Created: latency-svc-66hd2
May 21 10:13:32.282: INFO: Created: latency-svc-7rnr4
May 21 10:13:32.288: INFO: Got endpoints: latency-svc-7rnr4 [150.784083ms]
May 21 10:13:32.291: INFO: Got endpoints: latency-svc-66hd2 [186.184739ms]
May 21 10:13:32.291: INFO: Got endpoints: latency-svc-k6bx5 [194.703929ms]
May 21 10:13:32.292: INFO: Got endpoints: latency-svc-pf6m7 [180.187679ms]
May 21 10:13:32.295: INFO: Created: latency-svc-cfg2f
May 21 10:13:32.299: INFO: Got endpoints: latency-svc-cfg2f [152.368951ms]
May 21 10:13:32.301: INFO: Created: latency-svc-l88pl
May 21 10:13:32.305: INFO: Got endpoints: latency-svc-l88pl [150.641138ms]
May 21 10:13:32.312: INFO: Created: latency-svc-j8bl9
May 21 10:13:32.316: INFO: Got endpoints: latency-svc-j8bl9 [147.683258ms]
May 21 10:13:32.324: INFO: Created: latency-svc-jgjm6
May 21 10:13:32.326: INFO: Got endpoints: latency-svc-jgjm6 [123.963963ms]
May 21 10:13:32.330: INFO: Created: latency-svc-v2jvd
May 21 10:13:32.336: INFO: Created: latency-svc-pnpn5
May 21 10:13:32.336: INFO: Created: latency-svc-nzbgl
May 21 10:13:32.336: INFO: Got endpoints: latency-svc-nzbgl [132.232434ms]
May 21 10:13:32.336: INFO: Got endpoints: latency-svc-v2jvd [133.108994ms]
May 21 10:13:32.339: INFO: Got endpoints: latency-svc-pnpn5 [122.469829ms]
May 21 10:13:32.346: INFO: Created: latency-svc-ctps6
May 21 10:13:32.360: INFO: Created: latency-svc-9zcj2
May 21 10:13:32.360: INFO: Got endpoints: latency-svc-ctps6 [116.032903ms]
May 21 10:13:32.361: INFO: Created: latency-svc-jsgvd
May 21 10:13:32.370: INFO: Created: latency-svc-rmwrq
May 21 10:13:32.370: INFO: Got endpoints: latency-svc-9zcj2 [118.430481ms]
May 21 10:13:32.370: INFO: Got endpoints: latency-svc-jsgvd [110.502967ms]
May 21 10:13:32.383: INFO: Got endpoints: latency-svc-rmwrq [115.869947ms]
May 21 10:13:32.384: INFO: Created: latency-svc-l2h8v
May 21 10:13:32.390: INFO: Got endpoints: latency-svc-l2h8v [99.202891ms]
May 21 10:13:32.396: INFO: Created: latency-svc-dbvvm
May 21 10:13:32.398: INFO: Got endpoints: latency-svc-dbvvm [110.221409ms]
May 21 10:13:32.399: INFO: Created: latency-svc-gbptm
May 21 10:13:32.401: INFO: Got endpoints: latency-svc-gbptm [109.818685ms]
May 21 10:13:32.403: INFO: Created: latency-svc-5wqwq
May 21 10:13:32.405: INFO: Got endpoints: latency-svc-5wqwq [113.074917ms]
May 21 10:13:32.408: INFO: Created: latency-svc-l8qfk
May 21 10:13:32.411: INFO: Got endpoints: latency-svc-l8qfk [112.483101ms]
May 21 10:13:32.418: INFO: Created: latency-svc-kz9fk
May 21 10:13:32.418: INFO: Got endpoints: latency-svc-kz9fk [113.392712ms]
May 21 10:13:32.419: INFO: Created: latency-svc-5tk7l
May 21 10:13:32.423: INFO: Got endpoints: latency-svc-5tk7l [107.042806ms]
May 21 10:13:32.425: INFO: Created: latency-svc-cvnb4
May 21 10:13:32.427: INFO: Got endpoints: latency-svc-cvnb4 [101.07592ms]
May 21 10:13:32.430: INFO: Created: latency-svc-5m75j
May 21 10:13:32.435: INFO: Created: latency-svc-rnj58
May 21 10:13:32.440: INFO: Created: latency-svc-bhql4
May 21 10:13:32.452: INFO: Got endpoints: latency-svc-rnj58 [115.763578ms]
May 21 10:13:32.452: INFO: Got endpoints: latency-svc-5m75j [116.10799ms]
May 21 10:13:32.452: INFO: Got endpoints: latency-svc-bhql4 [112.938865ms]
May 21 10:13:32.457: INFO: Created: latency-svc-kspxq
May 21 10:13:32.459: INFO: Got endpoints: latency-svc-kspxq [98.6847ms]
May 21 10:13:32.466: INFO: Created: latency-svc-mdx8k
May 21 10:13:32.468: INFO: Got endpoints: latency-svc-mdx8k [98.138539ms]
May 21 10:13:32.472: INFO: Created: latency-svc-bdklv
May 21 10:13:32.474: INFO: Got endpoints: latency-svc-bdklv [103.768647ms]
May 21 10:13:32.476: INFO: Created: latency-svc-zphwr
May 21 10:13:32.479: INFO: Got endpoints: latency-svc-zphwr [95.676872ms]
May 21 10:13:32.482: INFO: Created: latency-svc-c8t97
May 21 10:13:32.485: INFO: Got endpoints: latency-svc-c8t97 [94.226975ms]
May 21 10:13:32.491: INFO: Created: latency-svc-65d6q
May 21 10:13:32.494: INFO: Got endpoints: latency-svc-65d6q [95.95216ms]
May 21 10:13:32.498: INFO: Created: latency-svc-zz9qc
May 21 10:13:32.501: INFO: Got endpoints: latency-svc-zz9qc [99.499774ms]
May 21 10:13:32.504: INFO: Created: latency-svc-zw6x4
May 21 10:13:32.506: INFO: Got endpoints: latency-svc-zw6x4 [101.203304ms]
May 21 10:13:32.510: INFO: Created: latency-svc-q5cb9
May 21 10:13:32.511: INFO: Got endpoints: latency-svc-q5cb9 [100.15458ms]
May 21 10:13:32.513: INFO: Created: latency-svc-8g6pc
May 21 10:13:32.537: INFO: Created: latency-svc-wb4qg
May 21 10:13:32.540: INFO: Got endpoints: latency-svc-8g6pc [121.685913ms]
May 21 10:13:32.541: INFO: Got endpoints: latency-svc-wb4qg [118.253926ms]
May 21 10:13:32.542: INFO: Created: latency-svc-n9wvf
May 21 10:13:32.542: INFO: Got endpoints: latency-svc-n9wvf [114.279252ms]
May 21 10:13:32.553: INFO: Created: latency-svc-trsk4
May 21 10:13:32.553: INFO: Got endpoints: latency-svc-trsk4 [101.089522ms]
May 21 10:13:32.566: INFO: Created: latency-svc-z2pfx
May 21 10:13:32.568: INFO: Got endpoints: latency-svc-z2pfx [116.28796ms]
May 21 10:13:32.571: INFO: Created: latency-svc-wkrl4
May 21 10:13:32.573: INFO: Got endpoints: latency-svc-wkrl4 [121.487197ms]
May 21 10:13:32.576: INFO: Created: latency-svc-6cnhm
May 21 10:13:32.580: INFO: Got endpoints: latency-svc-6cnhm [121.28339ms]
May 21 10:13:32.587: INFO: Created: latency-svc-qcdxb
May 21 10:13:32.590: INFO: Created: latency-svc-86zzh
May 21 10:13:32.590: INFO: Got endpoints: latency-svc-qcdxb [122.443606ms]
May 21 10:13:32.591: INFO: Got endpoints: latency-svc-86zzh [117.512833ms]
May 21 10:13:32.594: INFO: Created: latency-svc-rw7mn
May 21 10:13:32.611: INFO: Created: latency-svc-xnr85
May 21 10:13:32.611: INFO: Got endpoints: latency-svc-rw7mn [132.331955ms]
May 21 10:13:32.615: INFO: Got endpoints: latency-svc-xnr85 [130.382242ms]
May 21 10:13:32.621: INFO: Created: latency-svc-w62qz
May 21 10:13:32.625: INFO: Got endpoints: latency-svc-w62qz [131.160232ms]
May 21 10:13:32.634: INFO: Created: latency-svc-hd5rk
May 21 10:13:32.634: INFO: Got endpoints: latency-svc-hd5rk [133.511635ms]
May 21 10:13:32.639: INFO: Created: latency-svc-fhxw6
May 21 10:13:32.640: INFO: Got endpoints: latency-svc-fhxw6 [134.118868ms]
May 21 10:13:32.646: INFO: Created: latency-svc-pc28x
May 21 10:13:32.647: INFO: Got endpoints: latency-svc-pc28x [135.896141ms]
May 21 10:13:32.661: INFO: Created: latency-svc-rh4sc
May 21 10:13:32.661: INFO: Created: latency-svc-k7vcf
May 21 10:13:32.661: INFO: Got endpoints: latency-svc-rh4sc [119.63237ms]
May 21 10:13:32.661: INFO: Got endpoints: latency-svc-k7vcf [121.421665ms]
May 21 10:13:32.668: INFO: Created: latency-svc-7b2tn
May 21 10:13:32.668: INFO: Got endpoints: latency-svc-7b2tn [126.57381ms]
May 21 10:13:32.669: INFO: Created: latency-svc-9gs86
May 21 10:13:32.673: INFO: Got endpoints: latency-svc-9gs86 [120.48773ms]
May 21 10:13:32.676: INFO: Created: latency-svc-hb8wv
May 21 10:13:32.681: INFO: Got endpoints: latency-svc-hb8wv [112.554059ms]
May 21 10:13:32.683: INFO: Created: latency-svc-csdd8
May 21 10:13:32.685: INFO: Got endpoints: latency-svc-csdd8 [111.827178ms]
May 21 10:13:32.688: INFO: Created: latency-svc-vmmcx
May 21 10:13:32.690: INFO: Got endpoints: latency-svc-vmmcx [109.710807ms]
May 21 10:13:32.695: INFO: Created: latency-svc-5trgw
May 21 10:13:32.697: INFO: Got endpoints: latency-svc-5trgw [106.445771ms]
May 21 10:13:32.701: INFO: Created: latency-svc-gczwv
May 21 10:13:32.702: INFO: Got endpoints: latency-svc-gczwv [110.998532ms]
May 21 10:13:32.704: INFO: Created: latency-svc-rc8rh
May 21 10:13:32.707: INFO: Got endpoints: latency-svc-rc8rh [95.308506ms]
May 21 10:13:32.710: INFO: Created: latency-svc-fxd8c
May 21 10:13:32.712: INFO: Got endpoints: latency-svc-fxd8c [96.771488ms]
May 21 10:13:32.717: INFO: Created: latency-svc-57r2b
May 21 10:13:32.722: INFO: Got endpoints: latency-svc-57r2b [96.300538ms]
May 21 10:13:32.725: INFO: Created: latency-svc-cvxrq
May 21 10:13:32.736: INFO: Got endpoints: latency-svc-cvxrq [101.861638ms]
May 21 10:13:32.737: INFO: Created: latency-svc-vmljb
May 21 10:13:32.738: INFO: Got endpoints: latency-svc-vmljb [97.793456ms]
May 21 10:13:32.751: INFO: Created: latency-svc-hbb69
May 21 10:13:32.751: INFO: Got endpoints: latency-svc-hbb69 [103.551835ms]
May 21 10:13:32.758: INFO: Created: latency-svc-dbhcg
May 21 10:13:32.758: INFO: Got endpoints: latency-svc-dbhcg [97.398378ms]
May 21 10:13:32.759: INFO: Created: latency-svc-8496t
May 21 10:13:32.764: INFO: Got endpoints: latency-svc-8496t [103.298356ms]
May 21 10:13:32.765: INFO: Created: latency-svc-vw4ss
May 21 10:13:32.768: INFO: Got endpoints: latency-svc-vw4ss [99.234654ms]
May 21 10:13:32.773: INFO: Created: latency-svc-vt5fz
May 21 10:13:32.776: INFO: Got endpoints: latency-svc-vt5fz [102.865667ms]
May 21 10:13:32.777: INFO: Created: latency-svc-45n8t
May 21 10:13:32.779: INFO: Got endpoints: latency-svc-45n8t [98.503995ms]
May 21 10:13:32.790: INFO: Created: latency-svc-j66zn
May 21 10:13:32.792: INFO: Got endpoints: latency-svc-j66zn [106.20725ms]
May 21 10:13:32.797: INFO: Created: latency-svc-dsxxn
May 21 10:13:32.800: INFO: Got endpoints: latency-svc-dsxxn [110.276568ms]
May 21 10:13:32.803: INFO: Created: latency-svc-hcttm
May 21 10:13:32.806: INFO: Got endpoints: latency-svc-hcttm [109.153332ms]
May 21 10:13:32.811: INFO: Created: latency-svc-np9j2
May 21 10:13:32.814: INFO: Got endpoints: latency-svc-np9j2 [111.626262ms]
May 21 10:13:32.818: INFO: Created: latency-svc-94hcm
May 21 10:13:32.821: INFO: Got endpoints: latency-svc-94hcm [114.596896ms]
May 21 10:13:32.822: INFO: Created: latency-svc-bk2j2
May 21 10:13:32.825: INFO: Got endpoints: latency-svc-bk2j2 [113.531267ms]
May 21 10:13:32.828: INFO: Created: latency-svc-q5b8b
May 21 10:13:32.830: INFO: Got endpoints: latency-svc-q5b8b [108.535638ms]
May 21 10:13:32.833: INFO: Created: latency-svc-frn7h
May 21 10:13:32.836: INFO: Got endpoints: latency-svc-frn7h [100.211483ms]
May 21 10:13:32.840: INFO: Created: latency-svc-snrx6
May 21 10:13:32.841: INFO: Got endpoints: latency-svc-snrx6 [103.311291ms]
May 21 10:13:32.847: INFO: Created: latency-svc-p5j4v
May 21 10:13:32.853: INFO: Got endpoints: latency-svc-p5j4v [102.298162ms]
May 21 10:13:32.857: INFO: Created: latency-svc-d7gwl
May 21 10:13:32.876: INFO: Created: latency-svc-fs262
May 21 10:13:32.877: INFO: Got endpoints: latency-svc-d7gwl [118.110462ms]
May 21 10:13:32.881: INFO: Got endpoints: latency-svc-fs262 [116.289829ms]
May 21 10:13:32.883: INFO: Created: latency-svc-6jl54
May 21 10:13:32.887: INFO: Got endpoints: latency-svc-6jl54 [119.407372ms]
May 21 10:13:32.889: INFO: Created: latency-svc-jbcbd
May 21 10:13:32.892: INFO: Got endpoints: latency-svc-jbcbd [116.026821ms]
May 21 10:13:32.895: INFO: Created: latency-svc-8ll84
May 21 10:13:32.896: INFO: Got endpoints: latency-svc-8ll84 [116.97184ms]
May 21 10:13:32.902: INFO: Created: latency-svc-8pwg6
May 21 10:13:32.904: INFO: Got endpoints: latency-svc-8pwg6 [112.101589ms]
May 21 10:13:32.906: INFO: Created: latency-svc-qmq58
May 21 10:13:32.908: INFO: Got endpoints: latency-svc-qmq58 [107.91428ms]
May 21 10:13:32.911: INFO: Created: latency-svc-l5798
May 21 10:13:32.914: INFO: Got endpoints: latency-svc-l5798 [108.139529ms]
May 21 10:13:32.924: INFO: Created: latency-svc-sdz4r
May 21 10:13:32.926: INFO: Got endpoints: latency-svc-sdz4r [111.96176ms]
May 21 10:13:32.927: INFO: Created: latency-svc-5zsck
May 21 10:13:32.930: INFO: Got endpoints: latency-svc-5zsck [108.762365ms]
May 21 10:13:32.932: INFO: Created: latency-svc-szfpm
May 21 10:13:32.934: INFO: Got endpoints: latency-svc-szfpm [108.7662ms]
May 21 10:13:32.936: INFO: Created: latency-svc-qgcpn
May 21 10:13:32.937: INFO: Got endpoints: latency-svc-qgcpn [106.896987ms]
May 21 10:13:32.963: INFO: Created: latency-svc-dx54s
May 21 10:13:32.964: INFO: Created: latency-svc-qg6jz
May 21 10:13:32.965: INFO: Got endpoints: latency-svc-qg6jz [124.159155ms]
May 21 10:13:32.969: INFO: Got endpoints: latency-svc-dx54s [132.153398ms]
May 21 10:13:32.969: INFO: Created: latency-svc-pz6kj
May 21 10:13:32.972: INFO: Got endpoints: latency-svc-pz6kj [118.506823ms]
May 21 10:13:32.974: INFO: Created: latency-svc-xr2w5
May 21 10:13:32.977: INFO: Got endpoints: latency-svc-xr2w5 [100.118518ms]
May 21 10:13:32.984: INFO: Created: latency-svc-vwtk5
May 21 10:13:32.986: INFO: Got endpoints: latency-svc-vwtk5 [105.16225ms]
May 21 10:13:32.993: INFO: Created: latency-svc-4snmm
May 21 10:13:32.994: INFO: Got endpoints: latency-svc-4snmm [106.506448ms]
May 21 10:13:32.997: INFO: Created: latency-svc-zfx67
May 21 10:13:32.998: INFO: Got endpoints: latency-svc-zfx67 [106.252238ms]
May 21 10:13:33.005: INFO: Created: latency-svc-55hxr
May 21 10:13:33.006: INFO: Got endpoints: latency-svc-55hxr [109.82008ms]
May 21 10:13:33.013: INFO: Created: latency-svc-tcj2j
May 21 10:13:33.017: INFO: Got endpoints: latency-svc-tcj2j [113.172034ms]
May 21 10:13:33.021: INFO: Created: latency-svc-mftt6
May 21 10:13:33.023: INFO: Created: latency-svc-ccljt
May 21 10:13:33.024: INFO: Got endpoints: latency-svc-mftt6 [116.116262ms]
May 21 10:13:33.025: INFO: Got endpoints: latency-svc-ccljt [110.022961ms]
May 21 10:13:33.027: INFO: Created: latency-svc-99dv8
May 21 10:13:33.029: INFO: Got endpoints: latency-svc-99dv8 [102.769838ms]
May 21 10:13:33.031: INFO: Created: latency-svc-gzhw6
May 21 10:13:33.034: INFO: Got endpoints: latency-svc-gzhw6 [104.293043ms]
May 21 10:13:33.036: INFO: Created: latency-svc-k26hq
May 21 10:13:33.037: INFO: Got endpoints: latency-svc-k26hq [103.179289ms]
May 21 10:13:33.045: INFO: Created: latency-svc-wrp4f
May 21 10:13:33.054: INFO: Created: latency-svc-v5wfb
May 21 10:13:33.060: INFO: Created: latency-svc-kwmct
May 21 10:13:33.060: INFO: Got endpoints: latency-svc-v5wfb [94.620587ms]
May 21 10:13:33.063: INFO: Got endpoints: latency-svc-kwmct [94.917244ms]
May 21 10:13:33.064: INFO: Got endpoints: latency-svc-wrp4f [126.389527ms]
May 21 10:13:33.069: INFO: Created: latency-svc-49h7x
May 21 10:13:33.075: INFO: Got endpoints: latency-svc-49h7x [102.883003ms]
May 21 10:13:33.078: INFO: Created: latency-svc-qxll6
May 21 10:13:33.079: INFO: Got endpoints: latency-svc-qxll6 [102.304716ms]
May 21 10:13:33.096: INFO: Created: latency-svc-9p54b
May 21 10:13:33.097: INFO: Got endpoints: latency-svc-9p54b [110.569271ms]
May 21 10:13:33.107: INFO: Created: latency-svc-vqdcf
May 21 10:13:33.111: INFO: Got endpoints: latency-svc-vqdcf [117.726794ms]
May 21 10:13:33.121: INFO: Created: latency-svc-nfpj2
May 21 10:13:33.129: INFO: Got endpoints: latency-svc-nfpj2 [130.702874ms]
May 21 10:13:33.131: INFO: Created: latency-svc-5r7gh
May 21 10:13:33.135: INFO: Got endpoints: latency-svc-5r7gh [129.049913ms]
May 21 10:13:33.140: INFO: Created: latency-svc-ppj7c
May 21 10:13:33.143: INFO: Got endpoints: latency-svc-ppj7c [125.784015ms]
May 21 10:13:33.144: INFO: Created: latency-svc-4m7f4
May 21 10:13:33.147: INFO: Got endpoints: latency-svc-4m7f4 [122.136853ms]
May 21 10:13:33.149: INFO: Created: latency-svc-rnrhs
May 21 10:13:33.153: INFO: Got endpoints: latency-svc-rnrhs [128.402437ms]
May 21 10:13:33.156: INFO: Created: latency-svc-rv2mq
May 21 10:13:33.169: INFO: Got endpoints: latency-svc-rv2mq [140.402878ms]
May 21 10:13:33.171: INFO: Created: latency-svc-7f8r7
May 21 10:13:33.174: INFO: Created: latency-svc-wj77g
May 21 10:13:33.185: INFO: Got endpoints: latency-svc-7f8r7 [150.915218ms]
May 21 10:13:33.185: INFO: Got endpoints: latency-svc-wj77g [148.011328ms]
May 21 10:13:33.202: INFO: Created: latency-svc-5ksqs
May 21 10:13:33.218: INFO: Got endpoints: latency-svc-5ksqs [157.673257ms]
May 21 10:13:33.228: INFO: Created: latency-svc-x759v
May 21 10:13:33.228: INFO: Got endpoints: latency-svc-x759v [164.564846ms]
May 21 10:13:33.239: INFO: Created: latency-svc-47wqb
May 21 10:13:33.240: INFO: Got endpoints: latency-svc-47wqb [175.846806ms]
May 21 10:13:33.240: INFO: Created: latency-svc-phxl4
May 21 10:13:33.242: INFO: Got endpoints: latency-svc-phxl4 [167.725233ms]
May 21 10:13:33.263: INFO: Created: latency-svc-bqg8v
May 21 10:13:33.263: INFO: Got endpoints: latency-svc-bqg8v [183.901065ms]
May 21 10:13:33.267: INFO: Created: latency-svc-mr9rv
May 21 10:13:33.268: INFO: Got endpoints: latency-svc-mr9rv [171.431531ms]
May 21 10:13:33.297: INFO: Created: latency-svc-lqk22
May 21 10:13:33.299: INFO: Got endpoints: latency-svc-lqk22 [187.457891ms]
May 21 10:13:33.305: INFO: Created: latency-svc-hwj4m
May 21 10:13:33.325: INFO: Got endpoints: latency-svc-hwj4m [196.019748ms]
May 21 10:13:33.327: INFO: Created: latency-svc-6zph9
May 21 10:13:33.329: INFO: Got endpoints: latency-svc-6zph9 [193.979591ms]
May 21 10:13:33.334: INFO: Created: latency-svc-bwr6m
May 21 10:13:33.334: INFO: Got endpoints: latency-svc-bwr6m [191.381911ms]
May 21 10:13:33.342: INFO: Created: latency-svc-dxfxj
May 21 10:13:33.344: INFO: Got endpoints: latency-svc-dxfxj [197.116365ms]
May 21 10:13:33.345: INFO: Created: latency-svc-j489d
May 21 10:13:33.350: INFO: Got endpoints: latency-svc-j489d [196.82729ms]
May 21 10:13:33.360: INFO: Created: latency-svc-pqtzt
May 21 10:13:33.361: INFO: Got endpoints: latency-svc-pqtzt [191.691255ms]
May 21 10:13:33.369: INFO: Created: latency-svc-h68l7
May 21 10:13:33.369: INFO: Got endpoints: latency-svc-h68l7 [183.402399ms]
May 21 10:13:33.372: INFO: Created: latency-svc-thsh5
May 21 10:13:33.394: INFO: Got endpoints: latency-svc-thsh5 [208.449009ms]
May 21 10:13:33.396: INFO: Created: latency-svc-lt54b
May 21 10:13:33.396: INFO: Created: latency-svc-bkcg2
May 21 10:13:33.396: INFO: Created: latency-svc-qf957
May 21 10:13:33.396: INFO: Created: latency-svc-fdkm4
May 21 10:13:33.398: INFO: Created: latency-svc-hqxxk
May 21 10:13:33.400: INFO: Got endpoints: latency-svc-lt54b [182.013998ms]
May 21 10:13:33.400: INFO: Got endpoints: latency-svc-qf957 [160.348739ms]
May 21 10:13:33.401: INFO: Got endpoints: latency-svc-bkcg2 [172.992768ms]
May 21 10:13:33.402: INFO: Got endpoints: latency-svc-hqxxk [139.099845ms]
May 21 10:13:33.403: INFO: Got endpoints: latency-svc-fdkm4 [160.422415ms]
May 21 10:13:33.409: INFO: Created: latency-svc-tr77q
May 21 10:13:33.412: INFO: Got endpoints: latency-svc-tr77q [143.767357ms]
May 21 10:13:33.418: INFO: Created: latency-svc-6g8mr
May 21 10:13:33.422: INFO: Got endpoints: latency-svc-6g8mr [122.993206ms]
May 21 10:13:33.426: INFO: Created: latency-svc-2tlfh
May 21 10:13:33.428: INFO: Got endpoints: latency-svc-2tlfh [102.380118ms]
May 21 10:13:33.448: INFO: Created: latency-svc-sk2jb
May 21 10:13:33.452: INFO: Got endpoints: latency-svc-sk2jb [123.144353ms]
May 21 10:13:33.459: INFO: Created: latency-svc-5nldz
May 21 10:13:33.463: INFO: Got endpoints: latency-svc-5nldz [129.08067ms]
May 21 10:13:33.467: INFO: Created: latency-svc-jks8v
May 21 10:13:33.470: INFO: Got endpoints: latency-svc-jks8v [126.300522ms]
May 21 10:13:33.478: INFO: Created: latency-svc-cl4pg
May 21 10:13:33.480: INFO: Got endpoints: latency-svc-cl4pg [130.41084ms]
May 21 10:13:33.485: INFO: Created: latency-svc-kbx8k
May 21 10:13:33.485: INFO: Got endpoints: latency-svc-kbx8k [124.518372ms]
May 21 10:13:33.487: INFO: Created: latency-svc-d4nw2
May 21 10:13:33.488: INFO: Got endpoints: latency-svc-d4nw2 [119.624388ms]
May 21 10:13:33.494: INFO: Created: latency-svc-cncl5
May 21 10:13:33.497: INFO: Got endpoints: latency-svc-cncl5 [103.449512ms]
May 21 10:13:33.499: INFO: Created: latency-svc-x6pfb
May 21 10:13:33.502: INFO: Got endpoints: latency-svc-x6pfb [102.463583ms]
May 21 10:13:33.503: INFO: Created: latency-svc-x92mm
May 21 10:13:33.506: INFO: Got endpoints: latency-svc-x92mm [106.48008ms]
May 21 10:13:33.508: INFO: Created: latency-svc-kkvsh
May 21 10:13:33.510: INFO: Got endpoints: latency-svc-kkvsh [108.875366ms]
May 21 10:13:33.516: INFO: Created: latency-svc-vg4bd
May 21 10:13:33.522: INFO: Got endpoints: latency-svc-vg4bd [120.136802ms]
May 21 10:13:33.528: INFO: Created: latency-svc-r82js
May 21 10:13:33.528: INFO: Got endpoints: latency-svc-r82js [124.764544ms]
May 21 10:13:33.530: INFO: Created: latency-svc-w4b98
May 21 10:13:33.532: INFO: Got endpoints: latency-svc-w4b98 [120.477499ms]
May 21 10:13:33.540: INFO: Created: latency-svc-2f6vx
May 21 10:13:33.540: INFO: Got endpoints: latency-svc-2f6vx [118.543791ms]
May 21 10:13:33.543: INFO: Created: latency-svc-svh5g
May 21 10:13:33.544: INFO: Got endpoints: latency-svc-svh5g [116.671022ms]
May 21 10:13:33.550: INFO: Created: latency-svc-8bh5c
May 21 10:13:33.554: INFO: Got endpoints: latency-svc-8bh5c [101.756352ms]
May 21 10:13:33.558: INFO: Created: latency-svc-zndrp
May 21 10:13:33.561: INFO: Got endpoints: latency-svc-zndrp [98.05775ms]
May 21 10:13:33.562: INFO: Created: latency-svc-f8fkk
May 21 10:13:33.566: INFO: Got endpoints: latency-svc-f8fkk [96.012201ms]
May 21 10:13:33.579: INFO: Created: latency-svc-qlzjg
May 21 10:13:33.583: INFO: Got endpoints: latency-svc-qlzjg [103.212835ms]
May 21 10:13:33.593: INFO: Created: latency-svc-zj4dh
May 21 10:13:33.594: INFO: Got endpoints: latency-svc-zj4dh [108.554681ms]
May 21 10:13:33.600: INFO: Created: latency-svc-p7hcd
May 21 10:13:33.603: INFO: Got endpoints: latency-svc-p7hcd [114.566231ms]
May 21 10:13:33.609: INFO: Created: latency-svc-6lqk4
May 21 10:13:33.610: INFO: Got endpoints: latency-svc-6lqk4 [112.817164ms]
May 21 10:13:33.613: INFO: Created: latency-svc-z7sjk
May 21 10:13:33.614: INFO: Got endpoints: latency-svc-z7sjk [111.929258ms]
May 21 10:13:33.622: INFO: Created: latency-svc-kmlmc
May 21 10:13:33.622: INFO: Got endpoints: latency-svc-kmlmc [115.928157ms]
May 21 10:13:33.626: INFO: Created: latency-svc-sj2ft
May 21 10:13:33.630: INFO: Got endpoints: latency-svc-sj2ft [120.486527ms]
May 21 10:13:33.632: INFO: Created: latency-svc-wrclk
May 21 10:13:33.639: INFO: Created: latency-svc-rz2gd
May 21 10:13:33.639: INFO: Got endpoints: latency-svc-wrclk [116.388094ms]
May 21 10:13:33.639: INFO: Got endpoints: latency-svc-rz2gd [111.153489ms]
May 21 10:13:33.639: INFO: Latencies: [11.990408ms 15.236859ms 44.756022ms 44.857779ms 52.155242ms 54.616812ms 59.02949ms 68.585594ms 86.013331ms 89.271937ms 93.40867ms 94.226975ms 94.620587ms 94.917244ms 95.308506ms 95.676872ms 95.95216ms 96.012201ms 96.300538ms 96.771488ms 97.398378ms 97.793456ms 98.05775ms 98.138539ms 98.503995ms 98.6847ms 98.778431ms 99.202891ms 99.234654ms 99.499774ms 100.118518ms 100.15458ms 100.211483ms 101.07592ms 101.089522ms 101.203304ms 101.756352ms 101.861638ms 102.298162ms 102.304716ms 102.380118ms 102.463583ms 102.769838ms 102.865667ms 102.883003ms 103.179289ms 103.212835ms 103.298356ms 103.311291ms 103.449512ms 103.551835ms 103.768647ms 104.010788ms 104.293043ms 105.16225ms 106.20725ms 106.252238ms 106.445771ms 106.48008ms 106.506448ms 106.896987ms 107.042806ms 107.91428ms 108.139529ms 108.535638ms 108.554681ms 108.762365ms 108.7662ms 108.875366ms 109.153332ms 109.710807ms 109.818685ms 109.82008ms 110.022961ms 110.221409ms 110.276568ms 110.502967ms 110.569271ms 110.998532ms 111.153489ms 111.626262ms 111.827178ms 111.929258ms 111.96176ms 112.101589ms 112.483101ms 112.554059ms 112.817164ms 112.938865ms 113.074917ms 113.172034ms 113.392712ms 113.515939ms 113.531267ms 113.907931ms 114.279252ms 114.566231ms 114.596896ms 115.763578ms 115.869947ms 115.928157ms 116.026821ms 116.032903ms 116.10799ms 116.116262ms 116.28796ms 116.289829ms 116.388094ms 116.671022ms 116.97184ms 117.28999ms 117.512833ms 117.726794ms 118.110462ms 118.253926ms 118.430481ms 118.506823ms 118.543791ms 119.407372ms 119.624388ms 119.63237ms 120.136802ms 120.477499ms 120.486527ms 120.48773ms 120.569078ms 121.28339ms 121.421665ms 121.487197ms 121.685913ms 122.136853ms 122.418612ms 122.443606ms 122.469829ms 122.683624ms 122.993206ms 123.144353ms 123.963963ms 124.159155ms 124.518372ms 124.764544ms 125.629408ms 125.784015ms 126.300522ms 126.389527ms 126.57381ms 128.402437ms 129.049913ms 129.08067ms 130.382242ms 130.41084ms 130.702874ms 131.160232ms 132.153398ms 132.232434ms 132.331955ms 133.108994ms 133.511635ms 134.118868ms 134.258107ms 135.896141ms 138.201604ms 139.099845ms 140.402878ms 143.767357ms 147.683258ms 147.975445ms 148.011328ms 150.641138ms 150.784083ms 150.915218ms 152.368951ms 154.614397ms 157.673257ms 160.348739ms 160.422415ms 164.543498ms 164.564846ms 165.935156ms 167.725233ms 167.902228ms 171.431531ms 171.547839ms 172.992768ms 174.06675ms 175.846806ms 180.187679ms 182.013998ms 183.402399ms 183.901065ms 186.184739ms 187.457891ms 191.381911ms 191.691255ms 193.979591ms 194.703929ms 196.019748ms 196.82729ms 197.116365ms 208.449009ms]
May 21 10:13:33.639: INFO: 50 %ile: 115.928157ms
May 21 10:13:33.639: INFO: 90 %ile: 167.902228ms
May 21 10:13:33.639: INFO: 99 %ile: 197.116365ms
May 21 10:13:33.639: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:13:33.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-2b8wx" for this suite.
May 21 10:13:55.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:13:55.710: INFO: namespace: e2e-tests-svc-latency-2b8wx, resource: bindings, ignored listing per whitelist
May 21 10:13:55.723: INFO: namespace e2e-tests-svc-latency-2b8wx deletion completed in 22.080924978s

• [SLOW TEST:25.955 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:13:55.724: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 21 10:13:55.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-6xwvb'
May 21 10:13:55.872: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
May 21 10:13:55.872: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
May 21 10:13:55.878: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-wckl4]
May 21 10:13:55.878: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-wckl4" in namespace "e2e-tests-kubectl-6xwvb" to be "running and ready"
May 21 10:13:55.880: INFO: Pod "e2e-test-nginx-rc-wckl4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.564592ms
May 21 10:13:57.883: INFO: Pod "e2e-test-nginx-rc-wckl4": Phase="Running", Reason="", readiness=true. Elapsed: 2.005244621s
May 21 10:13:57.883: INFO: Pod "e2e-test-nginx-rc-wckl4" satisfied condition "running and ready"
May 21 10:13:57.883: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-wckl4]
May 21 10:13:57.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-6xwvb'
May 21 10:13:57.994: INFO: stderr: ""
May 21 10:13:57.994: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
May 21 10:13:57.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-6xwvb'
May 21 10:13:58.087: INFO: stderr: ""
May 21 10:13:58.087: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:13:58.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6xwvb" for this suite.
May 21 10:14:20.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:14:20.112: INFO: namespace: e2e-tests-kubectl-6xwvb, resource: bindings, ignored listing per whitelist
May 21 10:14:20.166: INFO: namespace e2e-tests-kubectl-6xwvb deletion completed in 22.074256659s

• [SLOW TEST:24.443 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:14:20.166: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 10:14:20.210: INFO: Creating ReplicaSet my-hostname-basic-32bbd1b6-7bb1-11e9-be4b-6e6d88bcf118
May 21 10:14:20.217: INFO: Pod name my-hostname-basic-32bbd1b6-7bb1-11e9-be4b-6e6d88bcf118: Found 0 pods out of 1
May 21 10:14:25.220: INFO: Pod name my-hostname-basic-32bbd1b6-7bb1-11e9-be4b-6e6d88bcf118: Found 1 pods out of 1
May 21 10:14:25.220: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-32bbd1b6-7bb1-11e9-be4b-6e6d88bcf118" is running
May 21 10:14:25.222: INFO: Pod "my-hostname-basic-32bbd1b6-7bb1-11e9-be4b-6e6d88bcf118-4s6nt" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-21 10:14:20 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-21 10:14:21 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-21 10:14:21 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-21 10:14:20 +0000 UTC Reason: Message:}])
May 21 10:14:25.222: INFO: Trying to dial the pod
May 21 10:14:30.232: INFO: Controller my-hostname-basic-32bbd1b6-7bb1-11e9-be4b-6e6d88bcf118: Got expected result from replica 1 [my-hostname-basic-32bbd1b6-7bb1-11e9-be4b-6e6d88bcf118-4s6nt]: "my-hostname-basic-32bbd1b6-7bb1-11e9-be4b-6e6d88bcf118-4s6nt", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:14:30.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-w29vw" for this suite.
May 21 10:14:36.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:14:36.256: INFO: namespace: e2e-tests-replicaset-w29vw, resource: bindings, ignored listing per whitelist
May 21 10:14:36.297: INFO: namespace e2e-tests-replicaset-w29vw deletion completed in 6.062225369s

• [SLOW TEST:16.131 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:14:36.297: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
May 21 10:14:38.367: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-3c5a6127-7bb1-11e9-be4b-6e6d88bcf118", GenerateName:"", Namespace:"e2e-tests-pods-kl9zt", SelfLink:"/api/v1/namespaces/e2e-tests-pods-kl9zt/pods/pod-submit-remove-3c5a6127-7bb1-11e9-be4b-6e6d88bcf118", UID:"3c5ae207-7bb1-11e9-acff-fa163e1b1d33", ResourceVersion:"11470", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63694030476, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"349474622"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-v267b", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc420deab40), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-v267b", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc4206c1d58), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"192.168.5.29", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc422d924e0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration(nil), HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694030476, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694030477, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694030477, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694030476, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.5.29", PodIP:"10.8.1.182", StartTime:(*v1.Time)(0xc42182cec0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc42182cee0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7", ContainerID:"docker://811fcd552955fa8746a2e2e42132a2182930689aae0b38b7741b3a3487a65726"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:14:43.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-kl9zt" for this suite.
May 21 10:14:49.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:14:49.759: INFO: namespace: e2e-tests-pods-kl9zt, resource: bindings, ignored listing per whitelist
May 21 10:14:49.761: INFO: namespace e2e-tests-pods-kl9zt deletion completed in 6.064442727s

• [SLOW TEST:13.463 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:14:49.761: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-kwfd
STEP: Creating a pod to test atomic-volume-subpath
May 21 10:14:49.819: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-kwfd" in namespace "e2e-tests-subpath-hmsnz" to be "success or failure"
May 21 10:14:49.823: INFO: Pod "pod-subpath-test-downwardapi-kwfd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.057023ms
May 21 10:14:51.826: INFO: Pod "pod-subpath-test-downwardapi-kwfd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006793277s
May 21 10:14:53.829: INFO: Pod "pod-subpath-test-downwardapi-kwfd": Phase="Running", Reason="", readiness=false. Elapsed: 4.010120405s
May 21 10:14:55.840: INFO: Pod "pod-subpath-test-downwardapi-kwfd": Phase="Running", Reason="", readiness=false. Elapsed: 6.020986697s
May 21 10:14:57.843: INFO: Pod "pod-subpath-test-downwardapi-kwfd": Phase="Running", Reason="", readiness=false. Elapsed: 8.023937836s
May 21 10:14:59.846: INFO: Pod "pod-subpath-test-downwardapi-kwfd": Phase="Running", Reason="", readiness=false. Elapsed: 10.02700767s
May 21 10:15:01.855: INFO: Pod "pod-subpath-test-downwardapi-kwfd": Phase="Running", Reason="", readiness=false. Elapsed: 12.036148891s
May 21 10:15:03.858: INFO: Pod "pod-subpath-test-downwardapi-kwfd": Phase="Running", Reason="", readiness=false. Elapsed: 14.038939931s
May 21 10:15:05.862: INFO: Pod "pod-subpath-test-downwardapi-kwfd": Phase="Running", Reason="", readiness=false. Elapsed: 16.042287582s
May 21 10:15:07.864: INFO: Pod "pod-subpath-test-downwardapi-kwfd": Phase="Running", Reason="", readiness=false. Elapsed: 18.04468961s
May 21 10:15:09.866: INFO: Pod "pod-subpath-test-downwardapi-kwfd": Phase="Running", Reason="", readiness=false. Elapsed: 20.047086426s
May 21 10:15:11.869: INFO: Pod "pod-subpath-test-downwardapi-kwfd": Phase="Running", Reason="", readiness=false. Elapsed: 22.050020769s
May 21 10:15:13.872: INFO: Pod "pod-subpath-test-downwardapi-kwfd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.052551103s
STEP: Saw pod success
May 21 10:15:13.872: INFO: Pod "pod-subpath-test-downwardapi-kwfd" satisfied condition "success or failure"
May 21 10:15:13.873: INFO: Trying to get logs from node 192.168.5.29 pod pod-subpath-test-downwardapi-kwfd container test-container-subpath-downwardapi-kwfd: <nil>
STEP: delete the pod
May 21 10:15:13.887: INFO: Waiting for pod pod-subpath-test-downwardapi-kwfd to disappear
May 21 10:15:13.890: INFO: Pod pod-subpath-test-downwardapi-kwfd no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-kwfd
May 21 10:15:13.890: INFO: Deleting pod "pod-subpath-test-downwardapi-kwfd" in namespace "e2e-tests-subpath-hmsnz"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:15:13.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-hmsnz" for this suite.
May 21 10:15:19.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:15:19.911: INFO: namespace: e2e-tests-subpath-hmsnz, resource: bindings, ignored listing per whitelist
May 21 10:15:19.959: INFO: namespace e2e-tests-subpath-hmsnz deletion completed in 6.063897954s

• [SLOW TEST:30.198 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:15:19.959: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
May 21 10:15:20.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 create -f - --namespace=e2e-tests-kubectl-8whmm'
May 21 10:15:20.198: INFO: stderr: ""
May 21 10:15:20.198: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
May 21 10:15:21.201: INFO: Selector matched 1 pods for map[app:redis]
May 21 10:15:21.201: INFO: Found 0 / 1
May 21 10:15:22.201: INFO: Selector matched 1 pods for map[app:redis]
May 21 10:15:22.201: INFO: Found 1 / 1
May 21 10:15:22.201: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
May 21 10:15:22.204: INFO: Selector matched 1 pods for map[app:redis]
May 21 10:15:22.204: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 21 10:15:22.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 patch pod redis-master-q5qxb --namespace=e2e-tests-kubectl-8whmm -p {"metadata":{"annotations":{"x":"y"}}}'
May 21 10:15:22.292: INFO: stderr: ""
May 21 10:15:22.292: INFO: stdout: "pod/redis-master-q5qxb patched\n"
STEP: checking annotations
May 21 10:15:22.294: INFO: Selector matched 1 pods for map[app:redis]
May 21 10:15:22.294: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:15:22.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8whmm" for this suite.
May 21 10:15:44.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:15:44.324: INFO: namespace: e2e-tests-kubectl-8whmm, resource: bindings, ignored listing per whitelist
May 21 10:15:44.360: INFO: namespace e2e-tests-kubectl-8whmm deletion completed in 22.063592296s

• [SLOW TEST:24.401 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:15:44.361: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 10:15:44.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 version --client'
May 21 10:15:44.478: INFO: stderr: ""
May 21 10:15:44.478: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
May 21 10:15:44.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 create -f - --namespace=e2e-tests-kubectl-rzzdx'
May 21 10:15:44.666: INFO: stderr: ""
May 21 10:15:44.666: INFO: stdout: "replicationcontroller/redis-master created\n"
May 21 10:15:44.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 create -f - --namespace=e2e-tests-kubectl-rzzdx'
May 21 10:15:44.831: INFO: stderr: ""
May 21 10:15:44.831: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
May 21 10:15:45.835: INFO: Selector matched 1 pods for map[app:redis]
May 21 10:15:45.835: INFO: Found 0 / 1
May 21 10:15:46.834: INFO: Selector matched 1 pods for map[app:redis]
May 21 10:15:46.834: INFO: Found 1 / 1
May 21 10:15:46.834: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 21 10:15:46.836: INFO: Selector matched 1 pods for map[app:redis]
May 21 10:15:46.836: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 21 10:15:46.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 describe pod redis-master-xwkqr --namespace=e2e-tests-kubectl-rzzdx'
May 21 10:15:46.930: INFO: stderr: ""
May 21 10:15:46.930: INFO: stdout: "Name:           redis-master-xwkqr\nNamespace:      e2e-tests-kubectl-rzzdx\nNode:           192.168.5.29/192.168.5.29\nStart Time:     Tue, 21 May 2019 10:15:44 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    <none>\nStatus:         Running\nIP:             10.8.1.185\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://4ef30f91d7c413b0c16a0054ae6691e5efadce91a1e15fe7cbe51e8f459ca647\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 21 May 2019 10:15:45 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-v4wt8 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-v4wt8:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-v4wt8\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     <none>\nEvents:\n  Type    Reason     Age   From                   Message\n  ----    ------     ----  ----                   -------\n  Normal  Scheduled  2s    default-scheduler      Successfully assigned e2e-tests-kubectl-rzzdx/redis-master-xwkqr to 192.168.5.29\n  Normal  Pulled     1s    kubelet, 192.168.5.29  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, 192.168.5.29  Created container\n  Normal  Started    1s    kubelet, 192.168.5.29  Started container\n"
May 21 10:15:46.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 describe rc redis-master --namespace=e2e-tests-kubectl-rzzdx'
May 21 10:15:47.026: INFO: stderr: ""
May 21 10:15:47.026: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-rzzdx\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-xwkqr\n"
May 21 10:15:47.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 describe service redis-master --namespace=e2e-tests-kubectl-rzzdx'
May 21 10:15:47.120: INFO: stderr: ""
May 21 10:15:47.120: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-rzzdx\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.254.33.101\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.8.1.185:6379\nSession Affinity:  None\nEvents:            <none>\n"
May 21 10:15:47.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 describe node 192.168.5.11'
May 21 10:15:47.222: INFO: stderr: ""
May 21 10:15:47.222: INFO: stdout: "Name:               192.168.5.11\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=eu-east-1\n                    failure-domain.beta.kubernetes.io/zone=eu-east-1b\n                    kubernetes.io/hostname=192.168.5.11\n                    kubernetes.io/role=master\n                    node-role.kubernetes.io/master=\nAnnotations:        flannel.alpha.coreos.com/backend-data: null\n                    flannel.alpha.coreos.com/backend-type: \n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 192.168.5.11\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 21 May 2019 09:13:36 +0000\nTaints:             dedicated=master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Tue, 21 May 2019 10:15:40 +0000   Tue, 21 May 2019 09:13:28 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Tue, 21 May 2019 10:15:40 +0000   Tue, 21 May 2019 09:13:28 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Tue, 21 May 2019 10:15:40 +0000   Tue, 21 May 2019 09:13:28 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Tue, 21 May 2019 10:15:40 +0000   Tue, 21 May 2019 09:13:28 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Tue, 21 May 2019 10:15:40 +0000   Tue, 21 May 2019 09:14:36 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.5.11\n  Hostname:    192.168.5.11\nCapacity:\n cpu:                2\n ephemeral-storage:  51474912Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             3882036Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  47439278821\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             3779636Ki\n pods:               110\nSystem Info:\n Machine ID:                 6a698a2ef7b94026a90df0cb2cdff1f9\n System UUID:                5739FB12-7E86-475E-BC7A-5388A82A836E\n Boot ID:                    1c63e7d6-7e15-45aa-a6dd-a4830465d6a6\n Kernel Version:             3.10.0-514.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.2\n Kubelet Version:            v1.12.3\n Kube-Proxy Version:         v1.12.3\nPodCIDR:                     10.8.0.0/24\nNon-terminated Pods:         (9 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-8150fbd9d34045a3-8g4mv    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                etcd-192.168.5.11                                          300m (15%)    0 (0%)      0 (0%)           0 (0%)\n  kube-system                ksc-flexvolume-ds-vgtss                                    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-apiserver-192.168.5.11                                250m (12%)    0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-controller-manager-192.168.5.11                       200m (10%)    0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-flannel-pwg8r                                         150m (7%)     300m (15%)  64M (1%)         500M (12%)\n  kube-system                kube-proxy-qc2q2                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-scheduler-192.168.5.11                                100m (5%)     0 (0%)      0 (0%)           0 (0%)\n  kube-system                system-monitor-7d7cc47bc9-r8zcc                            0 (0%)        0 (0%)      0 (0%)           0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource  Requests  Limits\n  --------  --------  ------\n  cpu       1 (50%)   300m (15%)\n  memory    64M (1%)  500M (12%)\nEvents:     <none>\n"
May 21 10:15:47.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 describe namespace e2e-tests-kubectl-rzzdx'
May 21 10:15:47.301: INFO: stderr: ""
May 21 10:15:47.301: INFO: stdout: "Name:         e2e-tests-kubectl-rzzdx\nLabels:       e2e-framework=kubectl\n              e2e-run=8d8261cc-7baa-11e9-be4b-6e6d88bcf118\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:15:47.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rzzdx" for this suite.
May 21 10:16:09.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:16:09.338: INFO: namespace: e2e-tests-kubectl-rzzdx, resource: bindings, ignored listing per whitelist
May 21 10:16:09.366: INFO: namespace e2e-tests-kubectl-rzzdx deletion completed in 22.062072928s

• [SLOW TEST:25.005 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:16:09.366: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 10:16:09.408: INFO: Waiting up to 5m0s for pod "downwardapi-volume-73d14ca5-7bb1-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-downward-api-pwhc4" to be "success or failure"
May 21 10:16:09.411: INFO: Pod "downwardapi-volume-73d14ca5-7bb1-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 3.129404ms
May 21 10:16:11.414: INFO: Pod "downwardapi-volume-73d14ca5-7bb1-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005994462s
STEP: Saw pod success
May 21 10:16:11.414: INFO: Pod "downwardapi-volume-73d14ca5-7bb1-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:16:11.416: INFO: Trying to get logs from node 192.168.5.29 pod downwardapi-volume-73d14ca5-7bb1-11e9-be4b-6e6d88bcf118 container client-container: <nil>
STEP: delete the pod
May 21 10:16:11.433: INFO: Waiting for pod downwardapi-volume-73d14ca5-7bb1-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:16:11.434: INFO: Pod downwardapi-volume-73d14ca5-7bb1-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:16:11.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pwhc4" for this suite.
May 21 10:16:17.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:16:17.492: INFO: namespace: e2e-tests-downward-api-pwhc4, resource: bindings, ignored listing per whitelist
May 21 10:16:17.499: INFO: namespace e2e-tests-downward-api-pwhc4 deletion completed in 6.061967034s

• [SLOW TEST:8.133 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:16:17.499: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-78aa8a2c-7bb1-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume secrets
May 21 10:16:17.545: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-78ab17d4-7bb1-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-projected-zvm8b" to be "success or failure"
May 21 10:16:17.547: INFO: Pod "pod-projected-secrets-78ab17d4-7bb1-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 1.581307ms
May 21 10:16:19.550: INFO: Pod "pod-projected-secrets-78ab17d4-7bb1-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004512559s
STEP: Saw pod success
May 21 10:16:19.550: INFO: Pod "pod-projected-secrets-78ab17d4-7bb1-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:16:19.551: INFO: Trying to get logs from node 192.168.5.29 pod pod-projected-secrets-78ab17d4-7bb1-11e9-be4b-6e6d88bcf118 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 21 10:16:19.566: INFO: Waiting for pod pod-projected-secrets-78ab17d4-7bb1-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:16:19.567: INFO: Pod pod-projected-secrets-78ab17d4-7bb1-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:16:19.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zvm8b" for this suite.
May 21 10:16:25.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:16:25.629: INFO: namespace: e2e-tests-projected-zvm8b, resource: bindings, ignored listing per whitelist
May 21 10:16:25.634: INFO: namespace e2e-tests-projected-zvm8b deletion completed in 6.0634402s

• [SLOW TEST:8.135 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:16:25.634: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-7d84b347-7bb1-11e9-be4b-6e6d88bcf118
STEP: Creating secret with name s-test-opt-upd-7d84b3be-7bb1-11e9-be4b-6e6d88bcf118
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-7d84b347-7bb1-11e9-be4b-6e6d88bcf118
STEP: Updating secret s-test-opt-upd-7d84b3be-7bb1-11e9-be4b-6e6d88bcf118
STEP: Creating secret with name s-test-opt-create-7d84b3cd-7bb1-11e9-be4b-6e6d88bcf118
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:18:00.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-p9cfz" for this suite.
May 21 10:18:22.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:18:22.074: INFO: namespace: e2e-tests-projected-p9cfz, resource: bindings, ignored listing per whitelist
May 21 10:18:22.115: INFO: namespace e2e-tests-projected-p9cfz deletion completed in 22.065071301s

• [SLOW TEST:116.481 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:18:22.115: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 10:18:24.185: INFO: Waiting up to 5m0s for pod "client-envvars-c426e0dc-7bb1-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-pods-659z7" to be "success or failure"
May 21 10:18:24.189: INFO: Pod "client-envvars-c426e0dc-7bb1-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 3.370972ms
May 21 10:18:26.193: INFO: Pod "client-envvars-c426e0dc-7bb1-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007395547s
STEP: Saw pod success
May 21 10:18:26.193: INFO: Pod "client-envvars-c426e0dc-7bb1-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:18:26.194: INFO: Trying to get logs from node 192.168.5.29 pod client-envvars-c426e0dc-7bb1-11e9-be4b-6e6d88bcf118 container env3cont: <nil>
STEP: delete the pod
May 21 10:18:26.208: INFO: Waiting for pod client-envvars-c426e0dc-7bb1-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:18:26.210: INFO: Pod client-envvars-c426e0dc-7bb1-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:18:26.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-659z7" for this suite.
May 21 10:19:16.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:19:16.241: INFO: namespace: e2e-tests-pods-659z7, resource: bindings, ignored listing per whitelist
May 21 10:19:16.277: INFO: namespace e2e-tests-pods-659z7 deletion completed in 50.064187723s

• [SLOW TEST:54.162 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:19:16.278: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-e33a863d-7bb1-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume configMaps
May 21 10:19:16.327: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e33b0ced-7bb1-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-projected-6zq2l" to be "success or failure"
May 21 10:19:16.329: INFO: Pod "pod-projected-configmaps-e33b0ced-7bb1-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 1.911678ms
May 21 10:19:18.332: INFO: Pod "pod-projected-configmaps-e33b0ced-7bb1-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004645962s
STEP: Saw pod success
May 21 10:19:18.332: INFO: Pod "pod-projected-configmaps-e33b0ced-7bb1-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:19:18.334: INFO: Trying to get logs from node 192.168.5.29 pod pod-projected-configmaps-e33b0ced-7bb1-11e9-be4b-6e6d88bcf118 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 10:19:18.346: INFO: Waiting for pod pod-projected-configmaps-e33b0ced-7bb1-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:19:18.348: INFO: Pod pod-projected-configmaps-e33b0ced-7bb1-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:19:18.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6zq2l" for this suite.
May 21 10:19:24.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:19:24.409: INFO: namespace: e2e-tests-projected-6zq2l, resource: bindings, ignored listing per whitelist
May 21 10:19:24.415: INFO: namespace e2e-tests-projected-6zq2l deletion completed in 6.063834827s

• [SLOW TEST:8.138 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:19:24.416: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-msdmb
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-msdmb to expose endpoints map[]
May 21 10:19:24.470: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-msdmb exposes endpoints map[] (4.473174ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-msdmb
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-msdmb to expose endpoints map[pod1:[100]]
May 21 10:19:26.504: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-msdmb exposes endpoints map[pod1:[100]] (2.016498108s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-msdmb
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-msdmb to expose endpoints map[pod1:[100] pod2:[101]]
May 21 10:19:28.527: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-msdmb exposes endpoints map[pod1:[100] pod2:[101]] (2.020371547s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-msdmb
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-msdmb to expose endpoints map[pod2:[101]]
May 21 10:19:29.542: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-msdmb exposes endpoints map[pod2:[101]] (1.009743923s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-msdmb
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-msdmb to expose endpoints map[]
May 21 10:19:30.554: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-msdmb exposes endpoints map[] (1.004494016s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:19:30.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-msdmb" for this suite.
May 21 10:19:52.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:19:52.610: INFO: namespace: e2e-tests-services-msdmb, resource: bindings, ignored listing per whitelist
May 21 10:19:52.647: INFO: namespace e2e-tests-services-msdmb deletion completed in 22.076180205s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:28.231 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:19:52.647: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 21 10:19:55.211: INFO: Successfully updated pod "pod-update-activedeadlineseconds-f8e851d7-7bb1-11e9-be4b-6e6d88bcf118"
May 21 10:19:55.211: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-f8e851d7-7bb1-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-pods-c7bn5" to be "terminated due to deadline exceeded"
May 21 10:19:55.213: INFO: Pod "pod-update-activedeadlineseconds-f8e851d7-7bb1-11e9-be4b-6e6d88bcf118": Phase="Running", Reason="", readiness=true. Elapsed: 1.927712ms
May 21 10:19:57.216: INFO: Pod "pod-update-activedeadlineseconds-f8e851d7-7bb1-11e9-be4b-6e6d88bcf118": Phase="Running", Reason="", readiness=true. Elapsed: 2.004700575s
May 21 10:19:59.219: INFO: Pod "pod-update-activedeadlineseconds-f8e851d7-7bb1-11e9-be4b-6e6d88bcf118": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.007609613s
May 21 10:19:59.219: INFO: Pod "pod-update-activedeadlineseconds-f8e851d7-7bb1-11e9-be4b-6e6d88bcf118" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:19:59.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-c7bn5" for this suite.
May 21 10:20:05.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:20:05.274: INFO: namespace: e2e-tests-pods-c7bn5, resource: bindings, ignored listing per whitelist
May 21 10:20:05.287: INFO: namespace e2e-tests-pods-c7bn5 deletion completed in 6.060882048s

• [SLOW TEST:12.639 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:20:05.287: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-0070ec02-7bb2-11e9-be4b-6e6d88bcf118
STEP: Creating configMap with name cm-test-opt-upd-0070ec7d-7bb2-11e9-be4b-6e6d88bcf118
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-0070ec02-7bb2-11e9-be4b-6e6d88bcf118
STEP: Updating configmap cm-test-opt-upd-0070ec7d-7bb2-11e9-be4b-6e6d88bcf118
STEP: Creating configMap with name cm-test-opt-create-0070ec90-7bb2-11e9-be4b-6e6d88bcf118
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:20:09.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xndx7" for this suite.
May 21 10:20:31.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:20:31.458: INFO: namespace: e2e-tests-projected-xndx7, resource: bindings, ignored listing per whitelist
May 21 10:20:31.473: INFO: namespace e2e-tests-projected-xndx7 deletion completed in 22.063859525s

• [SLOW TEST:26.186 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:20:31.473: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-100c57a3-7bb2-11e9-be4b-6e6d88bcf118
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-100c57a3-7bb2-11e9-be4b-6e6d88bcf118
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:20:35.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-jk5tj" for this suite.
May 21 10:20:57.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:20:57.592: INFO: namespace: e2e-tests-configmap-jk5tj, resource: bindings, ignored listing per whitelist
May 21 10:20:57.615: INFO: namespace e2e-tests-configmap-jk5tj deletion completed in 22.066662986s

• [SLOW TEST:26.143 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:20:57.616: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 21 10:20:57.670: INFO: Waiting up to 5m0s for pod "downward-api-1fa18102-7bb2-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-downward-api-ss9g9" to be "success or failure"
May 21 10:20:57.672: INFO: Pod "downward-api-1fa18102-7bb2-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 2.828803ms
May 21 10:20:59.675: INFO: Pod "downward-api-1fa18102-7bb2-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004926445s
STEP: Saw pod success
May 21 10:20:59.675: INFO: Pod "downward-api-1fa18102-7bb2-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:20:59.677: INFO: Trying to get logs from node 192.168.5.29 pod downward-api-1fa18102-7bb2-11e9-be4b-6e6d88bcf118 container dapi-container: <nil>
STEP: delete the pod
May 21 10:20:59.689: INFO: Waiting for pod downward-api-1fa18102-7bb2-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:20:59.691: INFO: Pod downward-api-1fa18102-7bb2-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:20:59.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ss9g9" for this suite.
May 21 10:21:05.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:21:05.741: INFO: namespace: e2e-tests-downward-api-ss9g9, resource: bindings, ignored listing per whitelist
May 21 10:21:05.769: INFO: namespace e2e-tests-downward-api-ss9g9 deletion completed in 6.072164859s

• [SLOW TEST:8.153 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:21:05.769: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
May 21 10:21:09.832: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 21 10:21:09.834: INFO: Pod pod-with-prestop-exec-hook still exists
May 21 10:21:11.834: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 21 10:21:11.837: INFO: Pod pod-with-prestop-exec-hook still exists
May 21 10:21:13.834: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 21 10:21:13.837: INFO: Pod pod-with-prestop-exec-hook still exists
May 21 10:21:15.834: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 21 10:21:15.837: INFO: Pod pod-with-prestop-exec-hook still exists
May 21 10:21:17.834: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 21 10:21:17.837: INFO: Pod pod-with-prestop-exec-hook still exists
May 21 10:21:19.834: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 21 10:21:19.837: INFO: Pod pod-with-prestop-exec-hook still exists
May 21 10:21:21.834: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 21 10:21:21.837: INFO: Pod pod-with-prestop-exec-hook still exists
May 21 10:21:23.834: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 21 10:21:23.837: INFO: Pod pod-with-prestop-exec-hook still exists
May 21 10:21:25.834: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 21 10:21:25.837: INFO: Pod pod-with-prestop-exec-hook still exists
May 21 10:21:27.834: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 21 10:21:27.838: INFO: Pod pod-with-prestop-exec-hook still exists
May 21 10:21:29.834: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 21 10:21:29.837: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:21:29.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-zrwfq" for this suite.
May 21 10:21:51.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:21:51.862: INFO: namespace: e2e-tests-container-lifecycle-hook-zrwfq, resource: bindings, ignored listing per whitelist
May 21 10:21:51.907: INFO: namespace e2e-tests-container-lifecycle-hook-zrwfq deletion completed in 22.06259977s

• [SLOW TEST:46.138 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:21:51.907: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-lnbzz
May 21 10:21:53.958: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-lnbzz
STEP: checking the pod's current state and verifying that restartCount is present
May 21 10:21:53.960: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:25:54.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-lnbzz" for this suite.
May 21 10:26:00.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:26:00.405: INFO: namespace: e2e-tests-container-probe-lnbzz, resource: bindings, ignored listing per whitelist
May 21 10:26:00.408: INFO: namespace e2e-tests-container-probe-lnbzz deletion completed in 6.07006726s

• [SLOW TEST:248.500 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:26:00.408: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-hn696/configmap-test-d41beea6-7bb2-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume configMaps
May 21 10:26:00.457: INFO: Waiting up to 5m0s for pod "pod-configmaps-d41c713c-7bb2-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-configmap-hn696" to be "success or failure"
May 21 10:26:00.459: INFO: Pod "pod-configmaps-d41c713c-7bb2-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 1.810296ms
May 21 10:26:02.462: INFO: Pod "pod-configmaps-d41c713c-7bb2-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004580845s
STEP: Saw pod success
May 21 10:26:02.462: INFO: Pod "pod-configmaps-d41c713c-7bb2-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:26:02.463: INFO: Trying to get logs from node 192.168.5.29 pod pod-configmaps-d41c713c-7bb2-11e9-be4b-6e6d88bcf118 container env-test: <nil>
STEP: delete the pod
May 21 10:26:02.479: INFO: Waiting for pod pod-configmaps-d41c713c-7bb2-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:26:02.481: INFO: Pod pod-configmaps-d41c713c-7bb2-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:26:02.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-hn696" for this suite.
May 21 10:26:08.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:26:08.538: INFO: namespace: e2e-tests-configmap-hn696, resource: bindings, ignored listing per whitelist
May 21 10:26:08.555: INFO: namespace e2e-tests-configmap-hn696 deletion completed in 6.071206182s

• [SLOW TEST:8.147 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:26:08.555: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
May 21 10:26:08.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 create -f - --namespace=e2e-tests-kubectl-fvs5h'
May 21 10:26:08.898: INFO: stderr: ""
May 21 10:26:08.898: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 21 10:26:08.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-fvs5h'
May 21 10:26:08.979: INFO: stderr: ""
May 21 10:26:08.979: INFO: stdout: "update-demo-nautilus-fbtg9 update-demo-nautilus-nskpm "
May 21 10:26:08.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods update-demo-nautilus-fbtg9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fvs5h'
May 21 10:26:09.048: INFO: stderr: ""
May 21 10:26:09.048: INFO: stdout: ""
May 21 10:26:09.048: INFO: update-demo-nautilus-fbtg9 is created but not running
May 21 10:26:14.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-fvs5h'
May 21 10:26:14.139: INFO: stderr: ""
May 21 10:26:14.139: INFO: stdout: "update-demo-nautilus-fbtg9 update-demo-nautilus-nskpm "
May 21 10:26:14.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods update-demo-nautilus-fbtg9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fvs5h'
May 21 10:26:14.215: INFO: stderr: ""
May 21 10:26:14.215: INFO: stdout: "true"
May 21 10:26:14.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods update-demo-nautilus-fbtg9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fvs5h'
May 21 10:26:14.295: INFO: stderr: ""
May 21 10:26:14.295: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 21 10:26:14.295: INFO: validating pod update-demo-nautilus-fbtg9
May 21 10:26:14.301: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 10:26:14.301: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 10:26:14.301: INFO: update-demo-nautilus-fbtg9 is verified up and running
May 21 10:26:14.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods update-demo-nautilus-nskpm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fvs5h'
May 21 10:26:14.377: INFO: stderr: ""
May 21 10:26:14.377: INFO: stdout: "true"
May 21 10:26:14.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods update-demo-nautilus-nskpm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fvs5h'
May 21 10:26:14.462: INFO: stderr: ""
May 21 10:26:14.462: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 21 10:26:14.462: INFO: validating pod update-demo-nautilus-nskpm
May 21 10:26:14.466: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 10:26:14.466: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 10:26:14.466: INFO: update-demo-nautilus-nskpm is verified up and running
STEP: using delete to clean up resources
May 21 10:26:14.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-fvs5h'
May 21 10:26:14.552: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 10:26:14.552: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 21 10:26:14.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-fvs5h'
May 21 10:26:14.657: INFO: stderr: "No resources found.\n"
May 21 10:26:14.657: INFO: stdout: ""
May 21 10:26:14.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods -l name=update-demo --namespace=e2e-tests-kubectl-fvs5h -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 21 10:26:14.767: INFO: stderr: ""
May 21 10:26:14.767: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:26:14.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fvs5h" for this suite.
May 21 10:26:36.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:26:36.788: INFO: namespace: e2e-tests-kubectl-fvs5h, resource: bindings, ignored listing per whitelist
May 21 10:26:36.846: INFO: namespace e2e-tests-kubectl-fvs5h deletion completed in 22.072629226s

• [SLOW TEST:28.291 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:26:36.846: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-8hclx
May 21 10:26:38.900: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-8hclx
STEP: checking the pod's current state and verifying that restartCount is present
May 21 10:26:38.902: INFO: Initial restart count of pod liveness-exec is 0
May 21 10:27:26.977: INFO: Restart count of pod e2e-tests-container-probe-8hclx/liveness-exec is now 1 (48.075102066s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:27:26.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-8hclx" for this suite.
May 21 10:27:32.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:27:33.005: INFO: namespace: e2e-tests-container-probe-8hclx, resource: bindings, ignored listing per whitelist
May 21 10:27:33.051: INFO: namespace e2e-tests-container-probe-8hclx deletion completed in 6.064615267s

• [SLOW TEST:56.205 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:27:33.052: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-bl6h7
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
May 21 10:27:33.100: INFO: Found 0 stateful pods, waiting for 3
May 21 10:27:43.105: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 21 10:27:43.105: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 21 10:27:43.105: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
May 21 10:27:43.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-bl6h7 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 21 10:27:43.338: INFO: stderr: ""
May 21 10:27:43.338: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 21 10:27:43.339: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
May 21 10:27:53.362: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
May 21 10:28:03.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-bl6h7 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:28:03.606: INFO: stderr: ""
May 21 10:28:03.606: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 21 10:28:03.606: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 21 10:28:23.620: INFO: Waiting for StatefulSet e2e-tests-statefulset-bl6h7/ss2 to complete update
May 21 10:28:23.620: INFO: Waiting for Pod e2e-tests-statefulset-bl6h7/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
May 21 10:28:33.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-bl6h7 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 21 10:28:33.887: INFO: stderr: ""
May 21 10:28:33.887: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 21 10:28:33.887: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 21 10:28:33.926: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
May 21 10:28:43.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 exec --namespace=e2e-tests-statefulset-bl6h7 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:28:44.185: INFO: stderr: ""
May 21 10:28:44.185: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 21 10:28:44.185: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 21 10:28:54.201: INFO: Waiting for StatefulSet e2e-tests-statefulset-bl6h7/ss2 to complete update
May 21 10:28:54.201: INFO: Waiting for Pod e2e-tests-statefulset-bl6h7/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
May 21 10:28:54.201: INFO: Waiting for Pod e2e-tests-statefulset-bl6h7/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
May 21 10:29:04.208: INFO: Waiting for StatefulSet e2e-tests-statefulset-bl6h7/ss2 to complete update
May 21 10:29:04.208: INFO: Waiting for Pod e2e-tests-statefulset-bl6h7/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 21 10:29:14.207: INFO: Deleting all statefulset in ns e2e-tests-statefulset-bl6h7
May 21 10:29:14.209: INFO: Scaling statefulset ss2 to 0
May 21 10:29:24.218: INFO: Waiting for statefulset status.replicas updated to 0
May 21 10:29:24.220: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:29:24.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-bl6h7" for this suite.
May 21 10:29:30.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:29:30.273: INFO: namespace: e2e-tests-statefulset-bl6h7, resource: bindings, ignored listing per whitelist
May 21 10:29:30.296: INFO: namespace e2e-tests-statefulset-bl6h7 deletion completed in 6.061599587s

• [SLOW TEST:117.244 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:29:30.296: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
May 21 10:29:30.344: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-mk8zp,SelfLink:/api/v1/namespaces/e2e-tests-watch-mk8zp/configmaps/e2e-watch-test-configmap-a,UID:513660f0-7bb3-11e9-acff-fa163e1b1d33,ResourceVersion:13814,Generation:0,CreationTimestamp:2019-05-21 10:29:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 21 10:29:30.344: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-mk8zp,SelfLink:/api/v1/namespaces/e2e-tests-watch-mk8zp/configmaps/e2e-watch-test-configmap-a,UID:513660f0-7bb3-11e9-acff-fa163e1b1d33,ResourceVersion:13814,Generation:0,CreationTimestamp:2019-05-21 10:29:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
May 21 10:29:40.350: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-mk8zp,SelfLink:/api/v1/namespaces/e2e-tests-watch-mk8zp/configmaps/e2e-watch-test-configmap-a,UID:513660f0-7bb3-11e9-acff-fa163e1b1d33,ResourceVersion:13828,Generation:0,CreationTimestamp:2019-05-21 10:29:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 21 10:29:40.350: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-mk8zp,SelfLink:/api/v1/namespaces/e2e-tests-watch-mk8zp/configmaps/e2e-watch-test-configmap-a,UID:513660f0-7bb3-11e9-acff-fa163e1b1d33,ResourceVersion:13828,Generation:0,CreationTimestamp:2019-05-21 10:29:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
May 21 10:29:50.356: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-mk8zp,SelfLink:/api/v1/namespaces/e2e-tests-watch-mk8zp/configmaps/e2e-watch-test-configmap-a,UID:513660f0-7bb3-11e9-acff-fa163e1b1d33,ResourceVersion:13843,Generation:0,CreationTimestamp:2019-05-21 10:29:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 21 10:29:50.357: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-mk8zp,SelfLink:/api/v1/namespaces/e2e-tests-watch-mk8zp/configmaps/e2e-watch-test-configmap-a,UID:513660f0-7bb3-11e9-acff-fa163e1b1d33,ResourceVersion:13843,Generation:0,CreationTimestamp:2019-05-21 10:29:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
May 21 10:30:00.362: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-mk8zp,SelfLink:/api/v1/namespaces/e2e-tests-watch-mk8zp/configmaps/e2e-watch-test-configmap-a,UID:513660f0-7bb3-11e9-acff-fa163e1b1d33,ResourceVersion:13859,Generation:0,CreationTimestamp:2019-05-21 10:29:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 21 10:30:00.362: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-mk8zp,SelfLink:/api/v1/namespaces/e2e-tests-watch-mk8zp/configmaps/e2e-watch-test-configmap-a,UID:513660f0-7bb3-11e9-acff-fa163e1b1d33,ResourceVersion:13859,Generation:0,CreationTimestamp:2019-05-21 10:29:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
May 21 10:30:10.368: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-mk8zp,SelfLink:/api/v1/namespaces/e2e-tests-watch-mk8zp/configmaps/e2e-watch-test-configmap-b,UID:6911c56b-7bb3-11e9-acff-fa163e1b1d33,ResourceVersion:13877,Generation:0,CreationTimestamp:2019-05-21 10:30:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 21 10:30:10.369: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-mk8zp,SelfLink:/api/v1/namespaces/e2e-tests-watch-mk8zp/configmaps/e2e-watch-test-configmap-b,UID:6911c56b-7bb3-11e9-acff-fa163e1b1d33,ResourceVersion:13877,Generation:0,CreationTimestamp:2019-05-21 10:30:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
May 21 10:30:20.374: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-mk8zp,SelfLink:/api/v1/namespaces/e2e-tests-watch-mk8zp/configmaps/e2e-watch-test-configmap-b,UID:6911c56b-7bb3-11e9-acff-fa163e1b1d33,ResourceVersion:13895,Generation:0,CreationTimestamp:2019-05-21 10:30:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 21 10:30:20.374: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-mk8zp,SelfLink:/api/v1/namespaces/e2e-tests-watch-mk8zp/configmaps/e2e-watch-test-configmap-b,UID:6911c56b-7bb3-11e9-acff-fa163e1b1d33,ResourceVersion:13895,Generation:0,CreationTimestamp:2019-05-21 10:30:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:30:30.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-mk8zp" for this suite.
May 21 10:30:36.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:30:36.438: INFO: namespace: e2e-tests-watch-mk8zp, resource: bindings, ignored listing per whitelist
May 21 10:30:36.460: INFO: namespace e2e-tests-watch-mk8zp deletion completed in 6.081491255s

• [SLOW TEST:66.164 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:30:36.461: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-78a7854b-7bb3-11e9-be4b-6e6d88bcf118
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-78a7854b-7bb3-11e9-be4b-6e6d88bcf118
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:30:40.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-96zrd" for this suite.
May 21 10:31:02.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:31:02.589: INFO: namespace: e2e-tests-projected-96zrd, resource: bindings, ignored listing per whitelist
May 21 10:31:02.624: INFO: namespace e2e-tests-projected-96zrd deletion completed in 22.068636575s

• [SLOW TEST:26.164 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:31:02.625: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
May 21 10:31:05.192: INFO: Successfully updated pod "labelsupdate883e518c-7bb3-11e9-be4b-6e6d88bcf118"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:31:09.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-b2lx6" for this suite.
May 21 10:31:31.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:31:31.257: INFO: namespace: e2e-tests-downward-api-b2lx6, resource: bindings, ignored listing per whitelist
May 21 10:31:31.290: INFO: namespace e2e-tests-downward-api-b2lx6 deletion completed in 22.073519314s

• [SLOW TEST:28.665 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:31:31.290: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 10:31:31.341: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9954eb86-7bb3-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-projected-n6lhj" to be "success or failure"
May 21 10:31:31.343: INFO: Pod "downwardapi-volume-9954eb86-7bb3-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 2.566844ms
May 21 10:31:33.346: INFO: Pod "downwardapi-volume-9954eb86-7bb3-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005487911s
STEP: Saw pod success
May 21 10:31:33.346: INFO: Pod "downwardapi-volume-9954eb86-7bb3-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:31:33.348: INFO: Trying to get logs from node 192.168.5.29 pod downwardapi-volume-9954eb86-7bb3-11e9-be4b-6e6d88bcf118 container client-container: <nil>
STEP: delete the pod
May 21 10:31:33.361: INFO: Waiting for pod downwardapi-volume-9954eb86-7bb3-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:31:33.363: INFO: Pod downwardapi-volume-9954eb86-7bb3-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:31:33.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-n6lhj" for this suite.
May 21 10:31:39.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:31:39.397: INFO: namespace: e2e-tests-projected-n6lhj, resource: bindings, ignored listing per whitelist
May 21 10:31:39.468: INFO: namespace e2e-tests-projected-n6lhj deletion completed in 6.102274925s

• [SLOW TEST:8.178 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:31:39.468: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-8hjq
STEP: Creating a pod to test atomic-volume-subpath
May 21 10:31:39.540: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-8hjq" in namespace "e2e-tests-subpath-w82ch" to be "success or failure"
May 21 10:31:39.545: INFO: Pod "pod-subpath-test-projected-8hjq": Phase="Pending", Reason="", readiness=false. Elapsed: 5.153648ms
May 21 10:31:41.547: INFO: Pod "pod-subpath-test-projected-8hjq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007852965s
May 21 10:31:43.550: INFO: Pod "pod-subpath-test-projected-8hjq": Phase="Running", Reason="", readiness=false. Elapsed: 4.010584646s
May 21 10:31:45.553: INFO: Pod "pod-subpath-test-projected-8hjq": Phase="Running", Reason="", readiness=false. Elapsed: 6.013370325s
May 21 10:31:47.556: INFO: Pod "pod-subpath-test-projected-8hjq": Phase="Running", Reason="", readiness=false. Elapsed: 8.016190031s
May 21 10:31:49.559: INFO: Pod "pod-subpath-test-projected-8hjq": Phase="Running", Reason="", readiness=false. Elapsed: 10.018912387s
May 21 10:31:51.561: INFO: Pod "pod-subpath-test-projected-8hjq": Phase="Running", Reason="", readiness=false. Elapsed: 12.021477949s
May 21 10:31:53.565: INFO: Pod "pod-subpath-test-projected-8hjq": Phase="Running", Reason="", readiness=false. Elapsed: 14.025702117s
May 21 10:31:55.569: INFO: Pod "pod-subpath-test-projected-8hjq": Phase="Running", Reason="", readiness=false. Elapsed: 16.029512836s
May 21 10:31:57.572: INFO: Pod "pod-subpath-test-projected-8hjq": Phase="Running", Reason="", readiness=false. Elapsed: 18.032484667s
May 21 10:31:59.576: INFO: Pod "pod-subpath-test-projected-8hjq": Phase="Running", Reason="", readiness=false. Elapsed: 20.035953785s
May 21 10:32:01.578: INFO: Pod "pod-subpath-test-projected-8hjq": Phase="Running", Reason="", readiness=false. Elapsed: 22.03869672s
May 21 10:32:03.581: INFO: Pod "pod-subpath-test-projected-8hjq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.041692045s
STEP: Saw pod success
May 21 10:32:03.581: INFO: Pod "pod-subpath-test-projected-8hjq" satisfied condition "success or failure"
May 21 10:32:03.585: INFO: Trying to get logs from node 192.168.5.29 pod pod-subpath-test-projected-8hjq container test-container-subpath-projected-8hjq: <nil>
STEP: delete the pod
May 21 10:32:03.599: INFO: Waiting for pod pod-subpath-test-projected-8hjq to disappear
May 21 10:32:03.601: INFO: Pod pod-subpath-test-projected-8hjq no longer exists
STEP: Deleting pod pod-subpath-test-projected-8hjq
May 21 10:32:03.601: INFO: Deleting pod "pod-subpath-test-projected-8hjq" in namespace "e2e-tests-subpath-w82ch"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:32:03.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-w82ch" for this suite.
May 21 10:32:09.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:32:09.660: INFO: namespace: e2e-tests-subpath-w82ch, resource: bindings, ignored listing per whitelist
May 21 10:32:09.672: INFO: namespace e2e-tests-subpath-w82ch deletion completed in 6.066625873s

• [SLOW TEST:30.204 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:32:09.673: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-b038a43b-7bb3-11e9-be4b-6e6d88bcf118
STEP: Creating secret with name secret-projected-all-test-volume-b038a41b-7bb3-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test Check all projections for projected volume plugin
May 21 10:32:09.748: INFO: Waiting up to 5m0s for pod "projected-volume-b038a3d3-7bb3-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-projected-dc6tq" to be "success or failure"
May 21 10:32:09.751: INFO: Pod "projected-volume-b038a3d3-7bb3-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 2.641896ms
May 21 10:32:11.754: INFO: Pod "projected-volume-b038a3d3-7bb3-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0055528s
STEP: Saw pod success
May 21 10:32:11.754: INFO: Pod "projected-volume-b038a3d3-7bb3-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:32:11.755: INFO: Trying to get logs from node 192.168.5.29 pod projected-volume-b038a3d3-7bb3-11e9-be4b-6e6d88bcf118 container projected-all-volume-test: <nil>
STEP: delete the pod
May 21 10:32:11.770: INFO: Waiting for pod projected-volume-b038a3d3-7bb3-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:32:11.773: INFO: Pod projected-volume-b038a3d3-7bb3-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:32:11.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dc6tq" for this suite.
May 21 10:32:17.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:32:17.836: INFO: namespace: e2e-tests-projected-dc6tq, resource: bindings, ignored listing per whitelist
May 21 10:32:17.838: INFO: namespace e2e-tests-projected-dc6tq deletion completed in 6.06229855s

• [SLOW TEST:8.165 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:32:17.838: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
May 21 10:32:17.890: INFO: Waiting up to 5m0s for pod "pod-b513e80f-7bb3-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-emptydir-2j9j5" to be "success or failure"
May 21 10:32:17.893: INFO: Pod "pod-b513e80f-7bb3-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 3.065798ms
May 21 10:32:19.896: INFO: Pod "pod-b513e80f-7bb3-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005698139s
STEP: Saw pod success
May 21 10:32:19.896: INFO: Pod "pod-b513e80f-7bb3-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:32:19.897: INFO: Trying to get logs from node 192.168.5.29 pod pod-b513e80f-7bb3-11e9-be4b-6e6d88bcf118 container test-container: <nil>
STEP: delete the pod
May 21 10:32:19.909: INFO: Waiting for pod pod-b513e80f-7bb3-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:32:19.911: INFO: Pod pod-b513e80f-7bb3-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:32:19.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2j9j5" for this suite.
May 21 10:32:25.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:32:25.931: INFO: namespace: e2e-tests-emptydir-2j9j5, resource: bindings, ignored listing per whitelist
May 21 10:32:25.975: INFO: namespace e2e-tests-emptydir-2j9j5 deletion completed in 6.061888205s

• [SLOW TEST:8.138 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:32:25.975: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
May 21 10:32:26.016: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:32:28.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-phvq6" for this suite.
May 21 10:32:34.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:32:34.852: INFO: namespace: e2e-tests-init-container-phvq6, resource: bindings, ignored listing per whitelist
May 21 10:32:34.878: INFO: namespace e2e-tests-init-container-phvq6 deletion completed in 6.071842912s

• [SLOW TEST:8.902 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:32:34.878: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
May 21 10:32:34.950: INFO: Waiting up to 5m0s for pod "pod-bf3f104c-7bb3-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-emptydir-9prrj" to be "success or failure"
May 21 10:32:34.954: INFO: Pod "pod-bf3f104c-7bb3-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 4.229814ms
May 21 10:32:36.957: INFO: Pod "pod-bf3f104c-7bb3-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007072243s
STEP: Saw pod success
May 21 10:32:36.957: INFO: Pod "pod-bf3f104c-7bb3-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:32:36.959: INFO: Trying to get logs from node 192.168.5.29 pod pod-bf3f104c-7bb3-11e9-be4b-6e6d88bcf118 container test-container: <nil>
STEP: delete the pod
May 21 10:32:36.973: INFO: Waiting for pod pod-bf3f104c-7bb3-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:32:36.975: INFO: Pod pod-bf3f104c-7bb3-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:32:36.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-9prrj" for this suite.
May 21 10:32:42.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:32:43.047: INFO: namespace: e2e-tests-emptydir-9prrj, resource: bindings, ignored listing per whitelist
May 21 10:32:43.047: INFO: namespace e2e-tests-emptydir-9prrj deletion completed in 6.069154904s

• [SLOW TEST:8.168 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:32:43.047: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:32:43.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-v2tmq" for this suite.
May 21 10:33:05.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:33:05.180: INFO: namespace: e2e-tests-pods-v2tmq, resource: bindings, ignored listing per whitelist
May 21 10:33:05.183: INFO: namespace e2e-tests-pods-v2tmq deletion completed in 22.08297994s

• [SLOW TEST:22.135 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:33:05.183: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
May 21 10:33:05.742: INFO: Waiting up to 5m0s for pod "pod-service-account-d1982743-7bb3-11e9-be4b-6e6d88bcf118-bhqzv" in namespace "e2e-tests-svcaccounts-kjknh" to be "success or failure"
May 21 10:33:05.746: INFO: Pod "pod-service-account-d1982743-7bb3-11e9-be4b-6e6d88bcf118-bhqzv": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039217ms
May 21 10:33:07.749: INFO: Pod "pod-service-account-d1982743-7bb3-11e9-be4b-6e6d88bcf118-bhqzv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006869307s
STEP: Saw pod success
May 21 10:33:07.749: INFO: Pod "pod-service-account-d1982743-7bb3-11e9-be4b-6e6d88bcf118-bhqzv" satisfied condition "success or failure"
May 21 10:33:07.750: INFO: Trying to get logs from node 192.168.5.29 pod pod-service-account-d1982743-7bb3-11e9-be4b-6e6d88bcf118-bhqzv container token-test: <nil>
STEP: delete the pod
May 21 10:33:07.767: INFO: Waiting for pod pod-service-account-d1982743-7bb3-11e9-be4b-6e6d88bcf118-bhqzv to disappear
May 21 10:33:07.772: INFO: Pod pod-service-account-d1982743-7bb3-11e9-be4b-6e6d88bcf118-bhqzv no longer exists
STEP: Creating a pod to test consume service account root CA
May 21 10:33:07.779: INFO: Waiting up to 5m0s for pod "pod-service-account-d1982743-7bb3-11e9-be4b-6e6d88bcf118-vjnh8" in namespace "e2e-tests-svcaccounts-kjknh" to be "success or failure"
May 21 10:33:07.784: INFO: Pod "pod-service-account-d1982743-7bb3-11e9-be4b-6e6d88bcf118-vjnh8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.148338ms
May 21 10:33:09.787: INFO: Pod "pod-service-account-d1982743-7bb3-11e9-be4b-6e6d88bcf118-vjnh8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007784603s
STEP: Saw pod success
May 21 10:33:09.787: INFO: Pod "pod-service-account-d1982743-7bb3-11e9-be4b-6e6d88bcf118-vjnh8" satisfied condition "success or failure"
May 21 10:33:09.789: INFO: Trying to get logs from node 192.168.5.29 pod pod-service-account-d1982743-7bb3-11e9-be4b-6e6d88bcf118-vjnh8 container root-ca-test: <nil>
STEP: delete the pod
May 21 10:33:09.802: INFO: Waiting for pod pod-service-account-d1982743-7bb3-11e9-be4b-6e6d88bcf118-vjnh8 to disappear
May 21 10:33:09.804: INFO: Pod pod-service-account-d1982743-7bb3-11e9-be4b-6e6d88bcf118-vjnh8 no longer exists
STEP: Creating a pod to test consume service account namespace
May 21 10:33:09.811: INFO: Waiting up to 5m0s for pod "pod-service-account-d1982743-7bb3-11e9-be4b-6e6d88bcf118-bn5lg" in namespace "e2e-tests-svcaccounts-kjknh" to be "success or failure"
May 21 10:33:09.814: INFO: Pod "pod-service-account-d1982743-7bb3-11e9-be4b-6e6d88bcf118-bn5lg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.541064ms
May 21 10:33:11.818: INFO: Pod "pod-service-account-d1982743-7bb3-11e9-be4b-6e6d88bcf118-bn5lg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006751576s
STEP: Saw pod success
May 21 10:33:11.818: INFO: Pod "pod-service-account-d1982743-7bb3-11e9-be4b-6e6d88bcf118-bn5lg" satisfied condition "success or failure"
May 21 10:33:11.820: INFO: Trying to get logs from node 192.168.5.29 pod pod-service-account-d1982743-7bb3-11e9-be4b-6e6d88bcf118-bn5lg container namespace-test: <nil>
STEP: delete the pod
May 21 10:33:11.837: INFO: Waiting for pod pod-service-account-d1982743-7bb3-11e9-be4b-6e6d88bcf118-bn5lg to disappear
May 21 10:33:11.839: INFO: Pod pod-service-account-d1982743-7bb3-11e9-be4b-6e6d88bcf118-bn5lg no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:33:11.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-kjknh" for this suite.
May 21 10:33:17.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:33:17.875: INFO: namespace: e2e-tests-svcaccounts-kjknh, resource: bindings, ignored listing per whitelist
May 21 10:33:17.910: INFO: namespace e2e-tests-svcaccounts-kjknh deletion completed in 6.063906995s

• [SLOW TEST:12.727 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:33:17.910: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 21 10:33:20.473: INFO: Successfully updated pod "pod-update-d8e1e91c-7bb3-11e9-be4b-6e6d88bcf118"
STEP: verifying the updated pod is in kubernetes
May 21 10:33:20.477: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:33:20.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-f6tdh" for this suite.
May 21 10:33:42.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:33:42.518: INFO: namespace: e2e-tests-pods-f6tdh, resource: bindings, ignored listing per whitelist
May 21 10:33:42.543: INFO: namespace e2e-tests-pods-f6tdh deletion completed in 22.063207532s

• [SLOW TEST:24.633 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:33:42.543: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-e78f1c79-7bb3-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume secrets
May 21 10:33:42.586: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e78fa2cd-7bb3-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-projected-8rbxf" to be "success or failure"
May 21 10:33:42.589: INFO: Pod "pod-projected-secrets-e78fa2cd-7bb3-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 2.590644ms
May 21 10:33:44.596: INFO: Pod "pod-projected-secrets-e78fa2cd-7bb3-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009427227s
STEP: Saw pod success
May 21 10:33:44.596: INFO: Pod "pod-projected-secrets-e78fa2cd-7bb3-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:33:44.598: INFO: Trying to get logs from node 192.168.5.29 pod pod-projected-secrets-e78fa2cd-7bb3-11e9-be4b-6e6d88bcf118 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 21 10:33:44.615: INFO: Waiting for pod pod-projected-secrets-e78fa2cd-7bb3-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:33:44.617: INFO: Pod pod-projected-secrets-e78fa2cd-7bb3-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:33:44.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8rbxf" for this suite.
May 21 10:33:50.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:33:50.659: INFO: namespace: e2e-tests-projected-8rbxf, resource: bindings, ignored listing per whitelist
May 21 10:33:50.680: INFO: namespace e2e-tests-projected-8rbxf deletion completed in 6.060441239s

• [SLOW TEST:8.138 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:33:50.681: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 10:33:50.716: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
May 21 10:33:50.722: INFO: Pod name sample-pod: Found 0 pods out of 1
May 21 10:33:55.725: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 21 10:33:55.725: INFO: Creating deployment "test-rolling-update-deployment"
May 21 10:33:55.732: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
May 21 10:33:55.736: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
May 21 10:33:57.741: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
May 21 10:33:57.743: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 21 10:33:57.748: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-72svl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-72svl/deployments/test-rolling-update-deployment,UID:ef654a46-7bb3-11e9-acff-fa163e1b1d33,ResourceVersion:14646,Generation:1,CreationTimestamp:2019-05-21 10:33:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-21 10:33:55 +0000 UTC 2019-05-21 10:33:55 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-21 10:33:57 +0000 UTC 2019-05-21 10:33:55 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 21 10:33:57.749: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-72svl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-72svl/replicasets/test-rolling-update-deployment-65b7695dcf,UID:ef66bc9b-7bb3-11e9-8d66-fa163e76243a,ResourceVersion:14636,Generation:1,CreationTimestamp:2019-05-21 10:33:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ef654a46-7bb3-11e9-acff-fa163e1b1d33 0xc4235326d7 0xc4235326d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 21 10:33:57.749: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
May 21 10:33:57.750: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-72svl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-72svl/replicasets/test-rolling-update-controller,UID:ec68dc4b-7bb3-11e9-acff-fa163e1b1d33,ResourceVersion:14645,Generation:2,CreationTimestamp:2019-05-21 10:33:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ef654a46-7bb3-11e9-acff-fa163e1b1d33 0xc42353260e 0xc42353260f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 21 10:33:57.752: INFO: Pod "test-rolling-update-deployment-65b7695dcf-5kr95" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-5kr95,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-72svl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-72svl/pods/test-rolling-update-deployment-65b7695dcf-5kr95,UID:ef67554e-7bb3-11e9-8d66-fa163e76243a,ResourceVersion:14635,Generation:0,CreationTimestamp:2019-05-21 10:33:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf ef66bc9b-7bb3-11e9-8d66-fa163e76243a 0xc4234cbd87 0xc4234cbd88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7jsd4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7jsd4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-7jsd4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:33:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:33:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:33:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:33:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.29,PodIP:10.8.1.237,StartTime:2019-05-21 10:33:55 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-21 10:33:56 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://8c2b4e78cbd513c3086d9a7ec8e49129d2b14b0fec3dc343ee6268a458c89013}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:33:57.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-72svl" for this suite.
May 21 10:34:03.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:34:03.805: INFO: namespace: e2e-tests-deployment-72svl, resource: bindings, ignored listing per whitelist
May 21 10:34:03.813: INFO: namespace e2e-tests-deployment-72svl deletion completed in 6.05819656s

• [SLOW TEST:13.132 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:34:03.813: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-f43d17bf-7bb3-11e9-be4b-6e6d88bcf118
May 21 10:34:03.856: INFO: Pod name my-hostname-basic-f43d17bf-7bb3-11e9-be4b-6e6d88bcf118: Found 0 pods out of 1
May 21 10:34:08.860: INFO: Pod name my-hostname-basic-f43d17bf-7bb3-11e9-be4b-6e6d88bcf118: Found 1 pods out of 1
May 21 10:34:08.860: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-f43d17bf-7bb3-11e9-be4b-6e6d88bcf118" are running
May 21 10:34:08.862: INFO: Pod "my-hostname-basic-f43d17bf-7bb3-11e9-be4b-6e6d88bcf118-2vv9m" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-21 10:34:03 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-21 10:34:05 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-21 10:34:05 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-21 10:34:03 +0000 UTC Reason: Message:}])
May 21 10:34:08.862: INFO: Trying to dial the pod
May 21 10:34:13.871: INFO: Controller my-hostname-basic-f43d17bf-7bb3-11e9-be4b-6e6d88bcf118: Got expected result from replica 1 [my-hostname-basic-f43d17bf-7bb3-11e9-be4b-6e6d88bcf118-2vv9m]: "my-hostname-basic-f43d17bf-7bb3-11e9-be4b-6e6d88bcf118-2vv9m", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:34:13.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-swvwt" for this suite.
May 21 10:34:19.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:34:19.940: INFO: namespace: e2e-tests-replication-controller-swvwt, resource: bindings, ignored listing per whitelist
May 21 10:34:19.958: INFO: namespace e2e-tests-replication-controller-swvwt deletion completed in 6.083285519s

• [SLOW TEST:16.145 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:34:19.958: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 21 10:34:20.004: INFO: Waiting up to 5m0s for pod "pod-fddcfe5a-7bb3-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-emptydir-qk6b9" to be "success or failure"
May 21 10:34:20.009: INFO: Pod "pod-fddcfe5a-7bb3-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 4.473121ms
May 21 10:34:22.012: INFO: Pod "pod-fddcfe5a-7bb3-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007148904s
STEP: Saw pod success
May 21 10:34:22.012: INFO: Pod "pod-fddcfe5a-7bb3-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:34:22.013: INFO: Trying to get logs from node 192.168.5.29 pod pod-fddcfe5a-7bb3-11e9-be4b-6e6d88bcf118 container test-container: <nil>
STEP: delete the pod
May 21 10:34:22.025: INFO: Waiting for pod pod-fddcfe5a-7bb3-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:34:22.028: INFO: Pod pod-fddcfe5a-7bb3-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:34:22.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qk6b9" for this suite.
May 21 10:34:28.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:34:28.075: INFO: namespace: e2e-tests-emptydir-qk6b9, resource: bindings, ignored listing per whitelist
May 21 10:34:28.095: INFO: namespace e2e-tests-emptydir-qk6b9 deletion completed in 6.064523925s

• [SLOW TEST:8.137 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:34:28.095: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 21 10:34:28.156: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:34:28.156: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:34:28.156: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:34:28.157: INFO: Number of nodes with available pods: 0
May 21 10:34:28.157: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:34:29.161: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:34:29.161: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:34:29.161: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:34:29.163: INFO: Number of nodes with available pods: 0
May 21 10:34:29.163: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:34:30.165: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:34:30.165: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:34:30.165: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:34:30.171: INFO: Number of nodes with available pods: 1
May 21 10:34:30.171: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
May 21 10:34:30.184: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:34:30.184: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:34:30.184: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:34:30.189: INFO: Number of nodes with available pods: 0
May 21 10:34:30.189: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:34:31.192: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:34:31.192: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:34:31.192: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:34:31.194: INFO: Number of nodes with available pods: 0
May 21 10:34:31.194: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:34:32.192: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:34:32.192: INFO: DaemonSet pods can't tolerate node 192.168.5.27 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:34:32.192: INFO: DaemonSet pods can't tolerate node 192.168.5.40 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 10:34:32.194: INFO: Number of nodes with available pods: 1
May 21 10:34:32.194: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-q6mb2, will wait for the garbage collector to delete the pods
May 21 10:34:32.254: INFO: Deleting {extensions DaemonSet} daemon-set took: 4.574846ms
May 21 10:34:32.354: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.141298ms
May 21 10:35:06.257: INFO: Number of nodes with available pods: 0
May 21 10:35:06.257: INFO: Number of running nodes: 0, number of available pods: 0
May 21 10:35:06.259: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-q6mb2/daemonsets","resourceVersion":"14870"},"items":null}

May 21 10:35:06.260: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-q6mb2/pods","resourceVersion":"14870"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:35:06.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-q6mb2" for this suite.
May 21 10:35:12.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:35:12.332: INFO: namespace: e2e-tests-daemonsets-q6mb2, resource: bindings, ignored listing per whitelist
May 21 10:35:12.339: INFO: namespace e2e-tests-daemonsets-q6mb2 deletion completed in 6.06630309s

• [SLOW TEST:44.244 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:35:12.340: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-1d153713-7bb4-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume configMaps
May 21 10:35:12.387: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1d15cb1d-7bb4-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-projected-twjtm" to be "success or failure"
May 21 10:35:12.389: INFO: Pod "pod-projected-configmaps-1d15cb1d-7bb4-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 1.71999ms
May 21 10:35:14.392: INFO: Pod "pod-projected-configmaps-1d15cb1d-7bb4-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004830872s
STEP: Saw pod success
May 21 10:35:14.392: INFO: Pod "pod-projected-configmaps-1d15cb1d-7bb4-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:35:14.394: INFO: Trying to get logs from node 192.168.5.29 pod pod-projected-configmaps-1d15cb1d-7bb4-11e9-be4b-6e6d88bcf118 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 10:35:14.412: INFO: Waiting for pod pod-projected-configmaps-1d15cb1d-7bb4-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:35:14.414: INFO: Pod pod-projected-configmaps-1d15cb1d-7bb4-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:35:14.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-twjtm" for this suite.
May 21 10:35:20.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:35:20.455: INFO: namespace: e2e-tests-projected-twjtm, resource: bindings, ignored listing per whitelist
May 21 10:35:20.502: INFO: namespace e2e-tests-projected-twjtm deletion completed in 6.084931612s

• [SLOW TEST:8.162 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:35:20.502: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 21 10:35:20.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-njdwj'
May 21 10:35:20.643: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
May 21 10:35:20.643: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
May 21 10:35:20.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-njdwj'
May 21 10:35:20.752: INFO: stderr: ""
May 21 10:35:20.752: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:35:20.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-njdwj" for this suite.
May 21 10:35:26.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:35:26.813: INFO: namespace: e2e-tests-kubectl-njdwj, resource: bindings, ignored listing per whitelist
May 21 10:35:26.826: INFO: namespace e2e-tests-kubectl-njdwj deletion completed in 6.066040078s

• [SLOW TEST:6.324 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:35:26.826: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-25bb0f25-7bb4-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume secrets
May 21 10:35:26.917: INFO: Waiting up to 5m0s for pod "pod-secrets-25bc6f5d-7bb4-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-secrets-g8v2d" to be "success or failure"
May 21 10:35:26.928: INFO: Pod "pod-secrets-25bc6f5d-7bb4-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 11.800267ms
May 21 10:35:28.931: INFO: Pod "pod-secrets-25bc6f5d-7bb4-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014639386s
STEP: Saw pod success
May 21 10:35:28.931: INFO: Pod "pod-secrets-25bc6f5d-7bb4-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:35:28.935: INFO: Trying to get logs from node 192.168.5.29 pod pod-secrets-25bc6f5d-7bb4-11e9-be4b-6e6d88bcf118 container secret-volume-test: <nil>
STEP: delete the pod
May 21 10:35:28.950: INFO: Waiting for pod pod-secrets-25bc6f5d-7bb4-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:35:28.952: INFO: Pod pod-secrets-25bc6f5d-7bb4-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:35:28.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-g8v2d" for this suite.
May 21 10:35:34.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:35:34.978: INFO: namespace: e2e-tests-secrets-g8v2d, resource: bindings, ignored listing per whitelist
May 21 10:35:35.016: INFO: namespace e2e-tests-secrets-g8v2d deletion completed in 6.060436226s

• [SLOW TEST:8.190 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:35:35.016: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0521 10:35:45.082627      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 21 10:35:45.082: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:35:45.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-ldk55" for this suite.
May 21 10:35:51.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:35:51.128: INFO: namespace: e2e-tests-gc-ldk55, resource: bindings, ignored listing per whitelist
May 21 10:35:51.153: INFO: namespace e2e-tests-gc-ldk55 deletion completed in 6.068132643s

• [SLOW TEST:16.137 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:35:51.154: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
May 21 10:35:51.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 api-versions'
May 21 10:35:51.288: INFO: stderr: ""
May 21 10:35:51.288: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1alpha1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:35:51.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dh6xl" for this suite.
May 21 10:35:57.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:35:57.342: INFO: namespace: e2e-tests-kubectl-dh6xl, resource: bindings, ignored listing per whitelist
May 21 10:35:57.356: INFO: namespace e2e-tests-kubectl-dh6xl deletion completed in 6.064729223s

• [SLOW TEST:6.202 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:35:57.356: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 10:35:57.403: INFO: Waiting up to 5m0s for pod "downwardapi-volume-37eacffb-7bb4-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-projected-vkhdp" to be "success or failure"
May 21 10:35:57.408: INFO: Pod "downwardapi-volume-37eacffb-7bb4-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 4.244691ms
May 21 10:35:59.411: INFO: Pod "downwardapi-volume-37eacffb-7bb4-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00781591s
STEP: Saw pod success
May 21 10:35:59.411: INFO: Pod "downwardapi-volume-37eacffb-7bb4-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:35:59.413: INFO: Trying to get logs from node 192.168.5.29 pod downwardapi-volume-37eacffb-7bb4-11e9-be4b-6e6d88bcf118 container client-container: <nil>
STEP: delete the pod
May 21 10:35:59.426: INFO: Waiting for pod downwardapi-volume-37eacffb-7bb4-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:35:59.427: INFO: Pod downwardapi-volume-37eacffb-7bb4-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:35:59.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vkhdp" for this suite.
May 21 10:36:05.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:36:05.473: INFO: namespace: e2e-tests-projected-vkhdp, resource: bindings, ignored listing per whitelist
May 21 10:36:05.503: INFO: namespace e2e-tests-projected-vkhdp deletion completed in 6.072471263s

• [SLOW TEST:8.146 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:36:05.503: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 21 10:36:05.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-c6l8d'
May 21 10:36:05.656: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
May 21 10:36:05.656: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
May 21 10:36:07.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-c6l8d'
May 21 10:36:07.753: INFO: stderr: ""
May 21 10:36:07.753: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:36:07.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-c6l8d" for this suite.
May 21 10:36:29.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:36:29.828: INFO: namespace: e2e-tests-kubectl-c6l8d, resource: bindings, ignored listing per whitelist
May 21 10:36:29.831: INFO: namespace e2e-tests-kubectl-c6l8d deletion completed in 22.073214524s

• [SLOW TEST:24.328 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:36:29.831: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-4b46f121-7bb4-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume secrets
May 21 10:36:29.885: INFO: Waiting up to 5m0s for pod "pod-secrets-4b4780c0-7bb4-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-secrets-nq8rv" to be "success or failure"
May 21 10:36:29.888: INFO: Pod "pod-secrets-4b4780c0-7bb4-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 2.479068ms
May 21 10:36:31.890: INFO: Pod "pod-secrets-4b4780c0-7bb4-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005138456s
STEP: Saw pod success
May 21 10:36:31.890: INFO: Pod "pod-secrets-4b4780c0-7bb4-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:36:31.892: INFO: Trying to get logs from node 192.168.5.29 pod pod-secrets-4b4780c0-7bb4-11e9-be4b-6e6d88bcf118 container secret-volume-test: <nil>
STEP: delete the pod
May 21 10:36:31.905: INFO: Waiting for pod pod-secrets-4b4780c0-7bb4-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:36:31.907: INFO: Pod pod-secrets-4b4780c0-7bb4-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:36:31.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-nq8rv" for this suite.
May 21 10:36:37.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:36:37.952: INFO: namespace: e2e-tests-secrets-nq8rv, resource: bindings, ignored listing per whitelist
May 21 10:36:37.972: INFO: namespace e2e-tests-secrets-nq8rv deletion completed in 6.061411129s

• [SLOW TEST:8.140 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:36:37.972: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-dkht
STEP: Creating a pod to test atomic-volume-subpath
May 21 10:36:38.020: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-dkht" in namespace "e2e-tests-subpath-x82hw" to be "success or failure"
May 21 10:36:38.023: INFO: Pod "pod-subpath-test-secret-dkht": Phase="Pending", Reason="", readiness=false. Elapsed: 2.338551ms
May 21 10:36:40.026: INFO: Pod "pod-subpath-test-secret-dkht": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005322848s
May 21 10:36:42.029: INFO: Pod "pod-subpath-test-secret-dkht": Phase="Running", Reason="", readiness=false. Elapsed: 4.008270184s
May 21 10:36:44.032: INFO: Pod "pod-subpath-test-secret-dkht": Phase="Running", Reason="", readiness=false. Elapsed: 6.011406345s
May 21 10:36:46.035: INFO: Pod "pod-subpath-test-secret-dkht": Phase="Running", Reason="", readiness=false. Elapsed: 8.014355971s
May 21 10:36:48.037: INFO: Pod "pod-subpath-test-secret-dkht": Phase="Running", Reason="", readiness=false. Elapsed: 10.016968793s
May 21 10:36:50.041: INFO: Pod "pod-subpath-test-secret-dkht": Phase="Running", Reason="", readiness=false. Elapsed: 12.020244533s
May 21 10:36:52.043: INFO: Pod "pod-subpath-test-secret-dkht": Phase="Running", Reason="", readiness=false. Elapsed: 14.02276857s
May 21 10:36:54.046: INFO: Pod "pod-subpath-test-secret-dkht": Phase="Running", Reason="", readiness=false. Elapsed: 16.025478282s
May 21 10:36:56.049: INFO: Pod "pod-subpath-test-secret-dkht": Phase="Running", Reason="", readiness=false. Elapsed: 18.028215208s
May 21 10:36:58.052: INFO: Pod "pod-subpath-test-secret-dkht": Phase="Running", Reason="", readiness=false. Elapsed: 20.031505833s
May 21 10:37:00.055: INFO: Pod "pod-subpath-test-secret-dkht": Phase="Running", Reason="", readiness=false. Elapsed: 22.034627821s
May 21 10:37:02.057: INFO: Pod "pod-subpath-test-secret-dkht": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.037004274s
STEP: Saw pod success
May 21 10:37:02.057: INFO: Pod "pod-subpath-test-secret-dkht" satisfied condition "success or failure"
May 21 10:37:02.059: INFO: Trying to get logs from node 192.168.5.29 pod pod-subpath-test-secret-dkht container test-container-subpath-secret-dkht: <nil>
STEP: delete the pod
May 21 10:37:02.072: INFO: Waiting for pod pod-subpath-test-secret-dkht to disappear
May 21 10:37:02.074: INFO: Pod pod-subpath-test-secret-dkht no longer exists
STEP: Deleting pod pod-subpath-test-secret-dkht
May 21 10:37:02.074: INFO: Deleting pod "pod-subpath-test-secret-dkht" in namespace "e2e-tests-subpath-x82hw"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:37:02.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-x82hw" for this suite.
May 21 10:37:08.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:37:08.092: INFO: namespace: e2e-tests-subpath-x82hw, resource: bindings, ignored listing per whitelist
May 21 10:37:08.138: INFO: namespace e2e-tests-subpath-x82hw deletion completed in 6.059511406s

• [SLOW TEST:30.167 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:37:08.139: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
May 21 10:37:08.187: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 21 10:37:08.191: INFO: Waiting for terminating namespaces to be deleted...
May 21 10:37:08.193: INFO: 
Logging pods the kubelet thinks is on node 192.168.5.29 before test
May 21 10:37:08.198: INFO: kube-proxy-pslz8 from kube-system started at 2019-05-21 09:14:12 +0000 UTC (1 container statuses recorded)
May 21 10:37:08.198: INFO: 	Container kube-proxy ready: true, restart count 0
May 21 10:37:08.198: INFO: traefik-ingress-controller-rm4kh from kube-system started at 2019-05-21 09:15:33 +0000 UTC (1 container statuses recorded)
May 21 10:37:08.198: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
May 21 10:37:08.198: INFO: disk-provisioner-7fb7598b96-hxs85 from kube-system started at 2019-05-21 09:15:34 +0000 UTC (1 container statuses recorded)
May 21 10:37:08.198: INFO: 	Container disk-provisioner ready: true, restart count 0
May 21 10:37:08.198: INFO: ksc-flexvolume-ds-5mzbx from kube-system started at 2019-05-21 09:15:31 +0000 UTC (1 container statuses recorded)
May 21 10:37:08.198: INFO: 	Container ksc-flexvolume-ds ready: true, restart count 0
May 21 10:37:08.198: INFO: metrics-server-774c777b9b-xzw2r from kube-system started at 2019-05-21 09:15:33 +0000 UTC (1 container statuses recorded)
May 21 10:37:08.198: INFO: 	Container metrics-server ready: true, restart count 0
May 21 10:37:08.198: INFO: sonobuoy-systemd-logs-daemon-set-8150fbd9d34045a3-ddhtz from heptio-sonobuoy started at 2019-05-21 09:25:47 +0000 UTC (2 container statuses recorded)
May 21 10:37:08.198: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 21 10:37:08.198: INFO: 	Container systemd-logs ready: true, restart count 1
May 21 10:37:08.198: INFO: coredns-57cddf5944-w8t7z from kube-system started at 2019-05-21 09:15:17 +0000 UTC (1 container statuses recorded)
May 21 10:37:08.198: INFO: 	Container coredns ready: true, restart count 0
May 21 10:37:08.198: INFO: coredns-57cddf5944-ggdnt from kube-system started at 2019-05-21 09:15:17 +0000 UTC (1 container statuses recorded)
May 21 10:37:08.198: INFO: 	Container coredns ready: true, restart count 0
May 21 10:37:08.198: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-21 09:25:36 +0000 UTC (1 container statuses recorded)
May 21 10:37:08.198: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 21 10:37:08.198: INFO: kube-flannel-w6rtw from kube-system started at 2019-05-21 09:14:18 +0000 UTC (2 container statuses recorded)
May 21 10:37:08.198: INFO: 	Container install-cni ready: true, restart count 0
May 21 10:37:08.198: INFO: 	Container kube-flannel ready: true, restart count 3
May 21 10:37:08.198: INFO: cloud-controller-manager-5b95856974-d6bg8 from kube-system started at 2019-05-21 09:15:33 +0000 UTC (1 container statuses recorded)
May 21 10:37:08.198: INFO: 	Container cloud-controller-manager ready: true, restart count 0
May 21 10:37:08.198: INFO: sonobuoy-e2e-job-ed687c3b8a094b84 from heptio-sonobuoy started at 2019-05-21 09:25:47 +0000 UTC (2 container statuses recorded)
May 21 10:37:08.198: INFO: 	Container e2e ready: true, restart count 0
May 21 10:37:08.198: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node 192.168.5.29
May 21 10:37:08.224: INFO: Pod sonobuoy requesting resource cpu=0m on Node 192.168.5.29
May 21 10:37:08.224: INFO: Pod sonobuoy-e2e-job-ed687c3b8a094b84 requesting resource cpu=0m on Node 192.168.5.29
May 21 10:37:08.224: INFO: Pod sonobuoy-systemd-logs-daemon-set-8150fbd9d34045a3-ddhtz requesting resource cpu=0m on Node 192.168.5.29
May 21 10:37:08.224: INFO: Pod cloud-controller-manager-5b95856974-d6bg8 requesting resource cpu=0m on Node 192.168.5.29
May 21 10:37:08.224: INFO: Pod coredns-57cddf5944-ggdnt requesting resource cpu=100m on Node 192.168.5.29
May 21 10:37:08.224: INFO: Pod coredns-57cddf5944-w8t7z requesting resource cpu=100m on Node 192.168.5.29
May 21 10:37:08.224: INFO: Pod disk-provisioner-7fb7598b96-hxs85 requesting resource cpu=0m on Node 192.168.5.29
May 21 10:37:08.224: INFO: Pod ksc-flexvolume-ds-5mzbx requesting resource cpu=0m on Node 192.168.5.29
May 21 10:37:08.224: INFO: Pod kube-flannel-w6rtw requesting resource cpu=150m on Node 192.168.5.29
May 21 10:37:08.224: INFO: Pod kube-proxy-pslz8 requesting resource cpu=0m on Node 192.168.5.29
May 21 10:37:08.224: INFO: Pod metrics-server-774c777b9b-xzw2r requesting resource cpu=0m on Node 192.168.5.29
May 21 10:37:08.224: INFO: Pod traefik-ingress-controller-rm4kh requesting resource cpu=0m on Node 192.168.5.29
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6222375c-7bb4-11e9-be4b-6e6d88bcf118.15a0ac66b784a7ff], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-xr292/filler-pod-6222375c-7bb4-11e9-be4b-6e6d88bcf118 to 192.168.5.29]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6222375c-7bb4-11e9-be4b-6e6d88bcf118.15a0ac66df589ac4], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6222375c-7bb4-11e9-be4b-6e6d88bcf118.15a0ac66e0031a06], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6222375c-7bb4-11e9-be4b-6e6d88bcf118.15a0ac66e6ad4318], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15a0ac672f301300], Reason = [FailedScheduling], Message = [0/4 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 3 Insufficient cpu.]
STEP: removing the label node off the node 192.168.5.29
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:37:11.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-xr292" for this suite.
May 21 10:37:17.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:37:17.294: INFO: namespace: e2e-tests-sched-pred-xr292, resource: bindings, ignored listing per whitelist
May 21 10:37:17.321: INFO: namespace e2e-tests-sched-pred-xr292 deletion completed in 6.061929528s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:9.182 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:37:17.321: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
May 21 10:37:17.376: INFO: Waiting up to 5m0s for pod "client-containers-6795e549-7bb4-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-containers-667fm" to be "success or failure"
May 21 10:37:17.378: INFO: Pod "client-containers-6795e549-7bb4-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 1.447777ms
May 21 10:37:19.380: INFO: Pod "client-containers-6795e549-7bb4-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004164414s
STEP: Saw pod success
May 21 10:37:19.381: INFO: Pod "client-containers-6795e549-7bb4-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:37:19.382: INFO: Trying to get logs from node 192.168.5.29 pod client-containers-6795e549-7bb4-11e9-be4b-6e6d88bcf118 container test-container: <nil>
STEP: delete the pod
May 21 10:37:19.394: INFO: Waiting for pod client-containers-6795e549-7bb4-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:37:19.395: INFO: Pod client-containers-6795e549-7bb4-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:37:19.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-667fm" for this suite.
May 21 10:37:25.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:37:25.417: INFO: namespace: e2e-tests-containers-667fm, resource: bindings, ignored listing per whitelist
May 21 10:37:25.468: INFO: namespace e2e-tests-containers-667fm deletion completed in 6.069477292s

• [SLOW TEST:8.147 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:37:25.468: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-whhp9
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 21 10:37:25.507: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 21 10:37:47.541: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.8.1.11 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-whhp9 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 10:37:47.541: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
May 21 10:37:48.668: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:37:48.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-whhp9" for this suite.
May 21 10:38:10.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:38:10.728: INFO: namespace: e2e-tests-pod-network-test-whhp9, resource: bindings, ignored listing per whitelist
May 21 10:38:10.738: INFO: namespace e2e-tests-pod-network-test-whhp9 deletion completed in 22.065729237s

• [SLOW TEST:45.270 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:38:10.738: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-876c0e51-7bb4-11e9-be4b-6e6d88bcf118
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:38:12.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-qxhvx" for this suite.
May 21 10:38:34.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:38:34.843: INFO: namespace: e2e-tests-configmap-qxhvx, resource: bindings, ignored listing per whitelist
May 21 10:38:34.873: INFO: namespace e2e-tests-configmap-qxhvx deletion completed in 22.063752557s

• [SLOW TEST:24.135 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:38:34.873: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
May 21 10:38:34.919: INFO: namespace e2e-tests-kubectl-cfvpc
May 21 10:38:34.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 create -f - --namespace=e2e-tests-kubectl-cfvpc'
May 21 10:38:35.186: INFO: stderr: ""
May 21 10:38:35.186: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
May 21 10:38:36.189: INFO: Selector matched 1 pods for map[app:redis]
May 21 10:38:36.189: INFO: Found 0 / 1
May 21 10:38:37.189: INFO: Selector matched 1 pods for map[app:redis]
May 21 10:38:37.189: INFO: Found 1 / 1
May 21 10:38:37.189: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 21 10:38:37.191: INFO: Selector matched 1 pods for map[app:redis]
May 21 10:38:37.191: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 21 10:38:37.191: INFO: wait on redis-master startup in e2e-tests-kubectl-cfvpc 
May 21 10:38:37.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 logs redis-master-5zm8m redis-master --namespace=e2e-tests-kubectl-cfvpc'
May 21 10:38:37.293: INFO: stderr: ""
May 21 10:38:37.293: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 May 10:38:35.973 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 May 10:38:35.973 # Server started, Redis version 3.2.12\n1:M 21 May 10:38:35.973 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 May 10:38:35.974 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
May 21 10:38:37.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-cfvpc'
May 21 10:38:37.392: INFO: stderr: ""
May 21 10:38:37.392: INFO: stdout: "service/rm2 exposed\n"
May 21 10:38:37.394: INFO: Service rm2 in namespace e2e-tests-kubectl-cfvpc found.
STEP: exposing service
May 21 10:38:39.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-cfvpc'
May 21 10:38:39.511: INFO: stderr: ""
May 21 10:38:39.511: INFO: stdout: "service/rm3 exposed\n"
May 21 10:38:39.514: INFO: Service rm3 in namespace e2e-tests-kubectl-cfvpc found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:38:41.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cfvpc" for this suite.
May 21 10:38:55.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:38:55.588: INFO: namespace: e2e-tests-kubectl-cfvpc, resource: bindings, ignored listing per whitelist
May 21 10:38:55.589: INFO: namespace e2e-tests-kubectl-cfvpc deletion completed in 14.067581202s

• [SLOW TEST:20.715 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:38:55.589: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 10:38:55.632: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
May 21 10:38:55.639: INFO: Number of nodes with available pods: 0
May 21 10:38:55.639: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
May 21 10:38:55.661: INFO: Number of nodes with available pods: 0
May 21 10:38:55.661: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:38:56.664: INFO: Number of nodes with available pods: 0
May 21 10:38:56.664: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:38:57.664: INFO: Number of nodes with available pods: 1
May 21 10:38:57.664: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
May 21 10:38:57.674: INFO: Number of nodes with available pods: 1
May 21 10:38:57.674: INFO: Number of running nodes: 0, number of available pods: 1
May 21 10:38:58.677: INFO: Number of nodes with available pods: 0
May 21 10:38:58.677: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
May 21 10:38:58.683: INFO: Number of nodes with available pods: 0
May 21 10:38:58.683: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:38:59.689: INFO: Number of nodes with available pods: 0
May 21 10:38:59.689: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:00.686: INFO: Number of nodes with available pods: 0
May 21 10:39:00.686: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:01.687: INFO: Number of nodes with available pods: 0
May 21 10:39:01.687: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:02.687: INFO: Number of nodes with available pods: 0
May 21 10:39:02.687: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:03.685: INFO: Number of nodes with available pods: 0
May 21 10:39:03.685: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:04.687: INFO: Number of nodes with available pods: 0
May 21 10:39:04.687: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:05.687: INFO: Number of nodes with available pods: 0
May 21 10:39:05.687: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:06.686: INFO: Number of nodes with available pods: 0
May 21 10:39:06.686: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:07.685: INFO: Number of nodes with available pods: 0
May 21 10:39:07.685: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:08.685: INFO: Number of nodes with available pods: 0
May 21 10:39:08.685: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:09.686: INFO: Number of nodes with available pods: 0
May 21 10:39:09.686: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:10.685: INFO: Number of nodes with available pods: 0
May 21 10:39:10.685: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:11.685: INFO: Number of nodes with available pods: 0
May 21 10:39:11.685: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:12.687: INFO: Number of nodes with available pods: 0
May 21 10:39:12.687: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:13.687: INFO: Number of nodes with available pods: 0
May 21 10:39:13.687: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:14.686: INFO: Number of nodes with available pods: 0
May 21 10:39:14.686: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:15.685: INFO: Number of nodes with available pods: 0
May 21 10:39:15.685: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:16.689: INFO: Number of nodes with available pods: 0
May 21 10:39:16.689: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:17.693: INFO: Number of nodes with available pods: 0
May 21 10:39:17.693: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:18.686: INFO: Number of nodes with available pods: 0
May 21 10:39:18.686: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:19.692: INFO: Number of nodes with available pods: 0
May 21 10:39:19.692: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:20.686: INFO: Number of nodes with available pods: 0
May 21 10:39:20.686: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:21.685: INFO: Number of nodes with available pods: 0
May 21 10:39:21.685: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:22.685: INFO: Number of nodes with available pods: 0
May 21 10:39:22.685: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:23.687: INFO: Number of nodes with available pods: 0
May 21 10:39:23.687: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:24.686: INFO: Number of nodes with available pods: 0
May 21 10:39:24.686: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:25.686: INFO: Number of nodes with available pods: 0
May 21 10:39:25.686: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:26.686: INFO: Number of nodes with available pods: 0
May 21 10:39:26.686: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:27.685: INFO: Number of nodes with available pods: 0
May 21 10:39:27.685: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:28.686: INFO: Number of nodes with available pods: 0
May 21 10:39:28.686: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:29.686: INFO: Number of nodes with available pods: 0
May 21 10:39:29.686: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:30.686: INFO: Number of nodes with available pods: 0
May 21 10:39:30.686: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:31.687: INFO: Number of nodes with available pods: 0
May 21 10:39:31.687: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:32.686: INFO: Number of nodes with available pods: 0
May 21 10:39:32.686: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:33.685: INFO: Number of nodes with available pods: 0
May 21 10:39:33.685: INFO: Node 192.168.5.29 is running more than one daemon pod
May 21 10:39:34.686: INFO: Number of nodes with available pods: 1
May 21 10:39:34.686: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-5t9mf, will wait for the garbage collector to delete the pods
May 21 10:39:34.746: INFO: Deleting {extensions DaemonSet} daemon-set took: 5.127649ms
May 21 10:39:34.846: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.118255ms
May 21 10:40:13.749: INFO: Number of nodes with available pods: 0
May 21 10:40:13.749: INFO: Number of running nodes: 0, number of available pods: 0
May 21 10:40:13.751: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-5t9mf/daemonsets","resourceVersion":"15843"},"items":null}

May 21 10:40:13.752: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-5t9mf/pods","resourceVersion":"15843"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:40:13.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-5t9mf" for this suite.
May 21 10:40:19.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:40:19.827: INFO: namespace: e2e-tests-daemonsets-5t9mf, resource: bindings, ignored listing per whitelist
May 21 10:40:19.836: INFO: namespace e2e-tests-daemonsets-5t9mf deletion completed in 6.070102441s

• [SLOW TEST:84.248 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:40:19.837: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 10:40:19.894: INFO: (0) /api/v1/nodes/192.168.5.29:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 3.196416ms)
May 21 10:40:19.897: INFO: (1) /api/v1/nodes/192.168.5.29:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.383989ms)
May 21 10:40:19.899: INFO: (2) /api/v1/nodes/192.168.5.29:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.257592ms)
May 21 10:40:19.901: INFO: (3) /api/v1/nodes/192.168.5.29:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.279183ms)
May 21 10:40:19.903: INFO: (4) /api/v1/nodes/192.168.5.29:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.210689ms)
May 21 10:40:19.906: INFO: (5) /api/v1/nodes/192.168.5.29:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.282556ms)
May 21 10:40:19.908: INFO: (6) /api/v1/nodes/192.168.5.29:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.192609ms)
May 21 10:40:19.910: INFO: (7) /api/v1/nodes/192.168.5.29:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.081557ms)
May 21 10:40:19.912: INFO: (8) /api/v1/nodes/192.168.5.29:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.301113ms)
May 21 10:40:19.915: INFO: (9) /api/v1/nodes/192.168.5.29:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.182055ms)
May 21 10:40:19.917: INFO: (10) /api/v1/nodes/192.168.5.29:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.170297ms)
May 21 10:40:19.919: INFO: (11) /api/v1/nodes/192.168.5.29:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.13779ms)
May 21 10:40:19.921: INFO: (12) /api/v1/nodes/192.168.5.29:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.271855ms)
May 21 10:40:19.923: INFO: (13) /api/v1/nodes/192.168.5.29:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.106134ms)
May 21 10:40:19.925: INFO: (14) /api/v1/nodes/192.168.5.29:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.196427ms)
May 21 10:40:19.928: INFO: (15) /api/v1/nodes/192.168.5.29:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.258105ms)
May 21 10:40:19.930: INFO: (16) /api/v1/nodes/192.168.5.29:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.169884ms)
May 21 10:40:19.932: INFO: (17) /api/v1/nodes/192.168.5.29:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.255744ms)
May 21 10:40:19.935: INFO: (18) /api/v1/nodes/192.168.5.29:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.335226ms)
May 21 10:40:19.937: INFO: (19) /api/v1/nodes/192.168.5.29:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.230511ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:40:19.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-nv7xg" for this suite.
May 21 10:40:25.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:40:25.957: INFO: namespace: e2e-tests-proxy-nv7xg, resource: bindings, ignored listing per whitelist
May 21 10:40:26.007: INFO: namespace e2e-tests-proxy-nv7xg deletion completed in 6.06747222s

• [SLOW TEST:6.170 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:40:26.007: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-d80c0ca8-7bb4-11e9-be4b-6e6d88bcf118
STEP: Creating configMap with name cm-test-opt-upd-d80c0cf8-7bb4-11e9-be4b-6e6d88bcf118
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-d80c0ca8-7bb4-11e9-be4b-6e6d88bcf118
STEP: Updating configmap cm-test-opt-upd-d80c0cf8-7bb4-11e9-be4b-6e6d88bcf118
STEP: Creating configMap with name cm-test-opt-create-d80c0d0b-7bb4-11e9-be4b-6e6d88bcf118
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:40:30.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-6kr2l" for this suite.
May 21 10:40:52.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:40:52.142: INFO: namespace: e2e-tests-configmap-6kr2l, resource: bindings, ignored listing per whitelist
May 21 10:40:52.188: INFO: namespace e2e-tests-configmap-6kr2l deletion completed in 22.070379294s

• [SLOW TEST:26.181 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:40:52.189: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-w9x98/secret-test-e7a6bf2c-7bb4-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume secrets
May 21 10:40:52.238: INFO: Waiting up to 5m0s for pod "pod-configmaps-e7a752fb-7bb4-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-secrets-w9x98" to be "success or failure"
May 21 10:40:52.241: INFO: Pod "pod-configmaps-e7a752fb-7bb4-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 2.518921ms
May 21 10:40:54.245: INFO: Pod "pod-configmaps-e7a752fb-7bb4-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006119398s
STEP: Saw pod success
May 21 10:40:54.245: INFO: Pod "pod-configmaps-e7a752fb-7bb4-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:40:54.246: INFO: Trying to get logs from node 192.168.5.29 pod pod-configmaps-e7a752fb-7bb4-11e9-be4b-6e6d88bcf118 container env-test: <nil>
STEP: delete the pod
May 21 10:40:54.259: INFO: Waiting for pod pod-configmaps-e7a752fb-7bb4-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:40:54.261: INFO: Pod pod-configmaps-e7a752fb-7bb4-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:40:54.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-w9x98" for this suite.
May 21 10:41:00.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:41:00.284: INFO: namespace: e2e-tests-secrets-w9x98, resource: bindings, ignored listing per whitelist
May 21 10:41:00.334: INFO: namespace e2e-tests-secrets-w9x98 deletion completed in 6.070687902s

• [SLOW TEST:8.146 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:41:00.335: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0521 10:41:06.454030      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 21 10:41:06.454: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:41:06.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-2kxcv" for this suite.
May 21 10:41:12.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:41:12.490: INFO: namespace: e2e-tests-gc-2kxcv, resource: bindings, ignored listing per whitelist
May 21 10:41:12.524: INFO: namespace e2e-tests-gc-2kxcv deletion completed in 6.067816329s

• [SLOW TEST:12.189 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:41:12.524: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-f3c5d277-7bb4-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume configMaps
May 21 10:41:12.574: INFO: Waiting up to 5m0s for pod "pod-configmaps-f3c65e62-7bb4-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-configmap-vxwgr" to be "success or failure"
May 21 10:41:12.577: INFO: Pod "pod-configmaps-f3c65e62-7bb4-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 3.240819ms
May 21 10:41:14.582: INFO: Pod "pod-configmaps-f3c65e62-7bb4-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008444495s
STEP: Saw pod success
May 21 10:41:14.582: INFO: Pod "pod-configmaps-f3c65e62-7bb4-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:41:14.584: INFO: Trying to get logs from node 192.168.5.29 pod pod-configmaps-f3c65e62-7bb4-11e9-be4b-6e6d88bcf118 container configmap-volume-test: <nil>
STEP: delete the pod
May 21 10:41:14.604: INFO: Waiting for pod pod-configmaps-f3c65e62-7bb4-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:41:14.606: INFO: Pod pod-configmaps-f3c65e62-7bb4-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:41:14.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vxwgr" for this suite.
May 21 10:41:20.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:41:20.661: INFO: namespace: e2e-tests-configmap-vxwgr, resource: bindings, ignored listing per whitelist
May 21 10:41:20.671: INFO: namespace e2e-tests-configmap-vxwgr deletion completed in 6.062099865s

• [SLOW TEST:8.147 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:41:20.671: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-f8a03d1e-7bb4-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume secrets
May 21 10:41:20.716: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f8a0cd84-7bb4-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-projected-kfg45" to be "success or failure"
May 21 10:41:20.720: INFO: Pod "pod-projected-secrets-f8a0cd84-7bb4-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 3.510476ms
May 21 10:41:22.723: INFO: Pod "pod-projected-secrets-f8a0cd84-7bb4-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006909794s
STEP: Saw pod success
May 21 10:41:22.723: INFO: Pod "pod-projected-secrets-f8a0cd84-7bb4-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:41:22.726: INFO: Trying to get logs from node 192.168.5.29 pod pod-projected-secrets-f8a0cd84-7bb4-11e9-be4b-6e6d88bcf118 container secret-volume-test: <nil>
STEP: delete the pod
May 21 10:41:22.739: INFO: Waiting for pod pod-projected-secrets-f8a0cd84-7bb4-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:41:22.741: INFO: Pod pod-projected-secrets-f8a0cd84-7bb4-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:41:22.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kfg45" for this suite.
May 21 10:41:28.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:41:28.800: INFO: namespace: e2e-tests-projected-kfg45, resource: bindings, ignored listing per whitelist
May 21 10:41:28.808: INFO: namespace e2e-tests-projected-kfg45 deletion completed in 6.064325232s

• [SLOW TEST:8.137 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:41:28.808: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
May 21 10:41:28.850: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-877789554 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:41:28.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sprnc" for this suite.
May 21 10:41:34.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:41:34.986: INFO: namespace: e2e-tests-kubectl-sprnc, resource: bindings, ignored listing per whitelist
May 21 10:41:35.007: INFO: namespace e2e-tests-kubectl-sprnc deletion completed in 6.061373615s

• [SLOW TEST:6.199 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:41:35.007: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 21 10:41:35.052: INFO: Waiting up to 5m0s for pod "downward-api-012c0a34-7bb5-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-downward-api-jh8hf" to be "success or failure"
May 21 10:41:35.054: INFO: Pod "downward-api-012c0a34-7bb5-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 2.626706ms
May 21 10:41:37.059: INFO: Pod "downward-api-012c0a34-7bb5-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007104837s
STEP: Saw pod success
May 21 10:41:37.059: INFO: Pod "downward-api-012c0a34-7bb5-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:41:37.060: INFO: Trying to get logs from node 192.168.5.29 pod downward-api-012c0a34-7bb5-11e9-be4b-6e6d88bcf118 container dapi-container: <nil>
STEP: delete the pod
May 21 10:41:37.072: INFO: Waiting for pod downward-api-012c0a34-7bb5-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:41:37.074: INFO: Pod downward-api-012c0a34-7bb5-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:41:37.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jh8hf" for this suite.
May 21 10:41:43.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:41:43.111: INFO: namespace: e2e-tests-downward-api-jh8hf, resource: bindings, ignored listing per whitelist
May 21 10:41:43.145: INFO: namespace e2e-tests-downward-api-jh8hf deletion completed in 6.06789945s

• [SLOW TEST:8.137 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:41:43.145: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-vzdsl
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-vzdsl
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-vzdsl
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-vzdsl
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-vzdsl
May 21 10:41:47.219: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-vzdsl, name: ss-0, uid: 084d73c7-7bb5-11e9-8d66-fa163e76243a, status phase: Pending. Waiting for statefulset controller to delete.
May 21 10:41:47.603: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-vzdsl, name: ss-0, uid: 084d73c7-7bb5-11e9-8d66-fa163e76243a, status phase: Failed. Waiting for statefulset controller to delete.
May 21 10:41:47.606: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-vzdsl, name: ss-0, uid: 084d73c7-7bb5-11e9-8d66-fa163e76243a, status phase: Failed. Waiting for statefulset controller to delete.
May 21 10:41:47.608: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-vzdsl
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-vzdsl
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-vzdsl and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 21 10:41:51.625: INFO: Deleting all statefulset in ns e2e-tests-statefulset-vzdsl
May 21 10:41:51.627: INFO: Scaling statefulset ss to 0
May 21 10:42:01.637: INFO: Waiting for statefulset status.replicas updated to 0
May 21 10:42:01.639: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:42:01.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-vzdsl" for this suite.
May 21 10:42:07.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:42:07.720: INFO: namespace: e2e-tests-statefulset-vzdsl, resource: bindings, ignored listing per whitelist
May 21 10:42:07.723: INFO: namespace e2e-tests-statefulset-vzdsl deletion completed in 6.069577357s

• [SLOW TEST:24.578 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:42:07.724: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
May 21 10:42:07.784: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-l7cpb,SelfLink:/api/v1/namespaces/e2e-tests-watch-l7cpb/configmaps/e2e-watch-test-resource-version,UID:14ac992a-7bb5-11e9-acff-fa163e1b1d33,ResourceVersion:16531,Generation:0,CreationTimestamp:2019-05-21 10:42:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 21 10:42:07.784: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-l7cpb,SelfLink:/api/v1/namespaces/e2e-tests-watch-l7cpb/configmaps/e2e-watch-test-resource-version,UID:14ac992a-7bb5-11e9-acff-fa163e1b1d33,ResourceVersion:16532,Generation:0,CreationTimestamp:2019-05-21 10:42:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:42:07.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-l7cpb" for this suite.
May 21 10:42:13.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:42:13.825: INFO: namespace: e2e-tests-watch-l7cpb, resource: bindings, ignored listing per whitelist
May 21 10:42:13.852: INFO: namespace e2e-tests-watch-l7cpb deletion completed in 6.064998498s

• [SLOW TEST:6.129 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:42:13.852: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 10:42:13.904: INFO: Waiting up to 5m0s for pod "downwardapi-volume-18546b2f-7bb5-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-projected-qmpds" to be "success or failure"
May 21 10:42:13.907: INFO: Pod "downwardapi-volume-18546b2f-7bb5-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 2.122271ms
May 21 10:42:15.909: INFO: Pod "downwardapi-volume-18546b2f-7bb5-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004735142s
STEP: Saw pod success
May 21 10:42:15.909: INFO: Pod "downwardapi-volume-18546b2f-7bb5-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:42:15.911: INFO: Trying to get logs from node 192.168.5.29 pod downwardapi-volume-18546b2f-7bb5-11e9-be4b-6e6d88bcf118 container client-container: <nil>
STEP: delete the pod
May 21 10:42:15.923: INFO: Waiting for pod downwardapi-volume-18546b2f-7bb5-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:42:15.924: INFO: Pod downwardapi-volume-18546b2f-7bb5-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:42:15.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qmpds" for this suite.
May 21 10:42:21.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:42:21.984: INFO: namespace: e2e-tests-projected-qmpds, resource: bindings, ignored listing per whitelist
May 21 10:42:22.003: INFO: namespace e2e-tests-projected-qmpds deletion completed in 6.076166707s

• [SLOW TEST:8.150 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:42:22.003: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-1d2e24a5-7bb5-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume secrets
May 21 10:42:22.044: INFO: Waiting up to 5m0s for pod "pod-secrets-1d2ea92c-7bb5-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-secrets-2ss77" to be "success or failure"
May 21 10:42:22.045: INFO: Pod "pod-secrets-1d2ea92c-7bb5-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 1.739786ms
May 21 10:42:24.048: INFO: Pod "pod-secrets-1d2ea92c-7bb5-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004558212s
STEP: Saw pod success
May 21 10:42:24.048: INFO: Pod "pod-secrets-1d2ea92c-7bb5-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:42:24.050: INFO: Trying to get logs from node 192.168.5.29 pod pod-secrets-1d2ea92c-7bb5-11e9-be4b-6e6d88bcf118 container secret-volume-test: <nil>
STEP: delete the pod
May 21 10:42:24.061: INFO: Waiting for pod pod-secrets-1d2ea92c-7bb5-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:42:24.063: INFO: Pod pod-secrets-1d2ea92c-7bb5-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:42:24.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2ss77" for this suite.
May 21 10:42:30.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:42:30.157: INFO: namespace: e2e-tests-secrets-2ss77, resource: bindings, ignored listing per whitelist
May 21 10:42:30.175: INFO: namespace e2e-tests-secrets-2ss77 deletion completed in 6.110391064s

• [SLOW TEST:8.173 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:42:30.176: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
May 21 10:42:30.218: INFO: Waiting up to 5m0s for pod "pod-220dd7ae-7bb5-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-emptydir-58jz2" to be "success or failure"
May 21 10:42:30.231: INFO: Pod "pod-220dd7ae-7bb5-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 13.063585ms
May 21 10:42:32.236: INFO: Pod "pod-220dd7ae-7bb5-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0180881s
STEP: Saw pod success
May 21 10:42:32.237: INFO: Pod "pod-220dd7ae-7bb5-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:42:32.238: INFO: Trying to get logs from node 192.168.5.29 pod pod-220dd7ae-7bb5-11e9-be4b-6e6d88bcf118 container test-container: <nil>
STEP: delete the pod
May 21 10:42:32.250: INFO: Waiting for pod pod-220dd7ae-7bb5-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:42:32.253: INFO: Pod pod-220dd7ae-7bb5-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:42:32.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-58jz2" for this suite.
May 21 10:42:38.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:42:38.317: INFO: namespace: e2e-tests-emptydir-58jz2, resource: bindings, ignored listing per whitelist
May 21 10:42:38.331: INFO: namespace e2e-tests-emptydir-58jz2 deletion completed in 6.07467537s

• [SLOW TEST:8.156 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:42:38.331: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-w7ng4
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 21 10:42:38.368: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 21 10:42:54.410: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.8.1.39:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-w7ng4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 10:42:54.410: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
May 21 10:42:54.552: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:42:54.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-w7ng4" for this suite.
May 21 10:43:16.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:43:16.620: INFO: namespace: e2e-tests-pod-network-test-w7ng4, resource: bindings, ignored listing per whitelist
May 21 10:43:16.621: INFO: namespace e2e-tests-pod-network-test-w7ng4 deletion completed in 22.063251779s

• [SLOW TEST:38.290 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:43:16.621: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-vzvs
STEP: Creating a pod to test atomic-volume-subpath
May 21 10:43:16.672: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-vzvs" in namespace "e2e-tests-subpath-pdqb5" to be "success or failure"
May 21 10:43:16.674: INFO: Pod "pod-subpath-test-configmap-vzvs": Phase="Pending", Reason="", readiness=false. Elapsed: 2.097385ms
May 21 10:43:18.680: INFO: Pod "pod-subpath-test-configmap-vzvs": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007722442s
May 21 10:43:20.682: INFO: Pod "pod-subpath-test-configmap-vzvs": Phase="Running", Reason="", readiness=false. Elapsed: 4.010004937s
May 21 10:43:22.684: INFO: Pod "pod-subpath-test-configmap-vzvs": Phase="Running", Reason="", readiness=false. Elapsed: 6.012624271s
May 21 10:43:24.687: INFO: Pod "pod-subpath-test-configmap-vzvs": Phase="Running", Reason="", readiness=false. Elapsed: 8.015360169s
May 21 10:43:26.690: INFO: Pod "pod-subpath-test-configmap-vzvs": Phase="Running", Reason="", readiness=false. Elapsed: 10.018313939s
May 21 10:43:28.693: INFO: Pod "pod-subpath-test-configmap-vzvs": Phase="Running", Reason="", readiness=false. Elapsed: 12.021202064s
May 21 10:43:30.696: INFO: Pod "pod-subpath-test-configmap-vzvs": Phase="Running", Reason="", readiness=false. Elapsed: 14.02376373s
May 21 10:43:32.698: INFO: Pod "pod-subpath-test-configmap-vzvs": Phase="Running", Reason="", readiness=false. Elapsed: 16.026573627s
May 21 10:43:34.702: INFO: Pod "pod-subpath-test-configmap-vzvs": Phase="Running", Reason="", readiness=false. Elapsed: 18.029714593s
May 21 10:43:36.711: INFO: Pod "pod-subpath-test-configmap-vzvs": Phase="Running", Reason="", readiness=false. Elapsed: 20.038787925s
May 21 10:43:38.713: INFO: Pod "pod-subpath-test-configmap-vzvs": Phase="Running", Reason="", readiness=false. Elapsed: 22.041588789s
May 21 10:43:40.721: INFO: Pod "pod-subpath-test-configmap-vzvs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.048730495s
STEP: Saw pod success
May 21 10:43:40.721: INFO: Pod "pod-subpath-test-configmap-vzvs" satisfied condition "success or failure"
May 21 10:43:40.724: INFO: Trying to get logs from node 192.168.5.29 pod pod-subpath-test-configmap-vzvs container test-container-subpath-configmap-vzvs: <nil>
STEP: delete the pod
May 21 10:43:40.751: INFO: Waiting for pod pod-subpath-test-configmap-vzvs to disappear
May 21 10:43:40.752: INFO: Pod pod-subpath-test-configmap-vzvs no longer exists
STEP: Deleting pod pod-subpath-test-configmap-vzvs
May 21 10:43:40.752: INFO: Deleting pod "pod-subpath-test-configmap-vzvs" in namespace "e2e-tests-subpath-pdqb5"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:43:40.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-pdqb5" for this suite.
May 21 10:43:46.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:43:46.783: INFO: namespace: e2e-tests-subpath-pdqb5, resource: bindings, ignored listing per whitelist
May 21 10:43:46.836: INFO: namespace e2e-tests-subpath-pdqb5 deletion completed in 6.079261664s

• [SLOW TEST:30.215 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:43:46.836: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 21 10:43:46.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-mbjht'
May 21 10:43:46.972: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
May 21 10:43:46.972: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
May 21 10:43:48.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-mbjht'
May 21 10:43:49.068: INFO: stderr: ""
May 21 10:43:49.068: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:43:49.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mbjht" for this suite.
May 21 10:43:55.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:43:55.114: INFO: namespace: e2e-tests-kubectl-mbjht, resource: bindings, ignored listing per whitelist
May 21 10:43:55.133: INFO: namespace e2e-tests-kubectl-mbjht deletion completed in 6.06058785s

• [SLOW TEST:8.297 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:43:55.133: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
May 21 10:43:55.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 create -f - --namespace=e2e-tests-kubectl-lmjg7'
May 21 10:43:55.370: INFO: stderr: ""
May 21 10:43:55.370: INFO: stdout: "pod/pause created\n"
May 21 10:43:55.370: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
May 21 10:43:55.370: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-lmjg7" to be "running and ready"
May 21 10:43:55.375: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.250058ms
May 21 10:43:57.377: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.007229925s
May 21 10:43:57.377: INFO: Pod "pause" satisfied condition "running and ready"
May 21 10:43:57.377: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
May 21 10:43:57.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-lmjg7'
May 21 10:43:57.469: INFO: stderr: ""
May 21 10:43:57.469: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
May 21 10:43:57.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pod pause -L testing-label --namespace=e2e-tests-kubectl-lmjg7'
May 21 10:43:57.559: INFO: stderr: ""
May 21 10:43:57.559: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
May 21 10:43:57.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 label pods pause testing-label- --namespace=e2e-tests-kubectl-lmjg7'
May 21 10:43:57.641: INFO: stderr: ""
May 21 10:43:57.641: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
May 21 10:43:57.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pod pause -L testing-label --namespace=e2e-tests-kubectl-lmjg7'
May 21 10:43:57.716: INFO: stderr: ""
May 21 10:43:57.716: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
May 21 10:43:57.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-lmjg7'
May 21 10:43:57.793: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 10:43:57.793: INFO: stdout: "pod \"pause\" force deleted\n"
May 21 10:43:57.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-lmjg7'
May 21 10:43:57.890: INFO: stderr: "No resources found.\n"
May 21 10:43:57.890: INFO: stdout: ""
May 21 10:43:57.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods -l name=pause --namespace=e2e-tests-kubectl-lmjg7 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 21 10:43:57.977: INFO: stderr: ""
May 21 10:43:57.977: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:43:57.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lmjg7" for this suite.
May 21 10:44:03.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:44:04.114: INFO: namespace: e2e-tests-kubectl-lmjg7, resource: bindings, ignored listing per whitelist
May 21 10:44:04.173: INFO: namespace e2e-tests-kubectl-lmjg7 deletion completed in 6.193338192s

• [SLOW TEST:9.041 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:44:04.174: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
May 21 10:44:04.813: INFO: created pod pod-service-account-defaultsa
May 21 10:44:04.813: INFO: pod pod-service-account-defaultsa service account token volume mount: true
May 21 10:44:04.817: INFO: created pod pod-service-account-mountsa
May 21 10:44:04.817: INFO: pod pod-service-account-mountsa service account token volume mount: true
May 21 10:44:04.830: INFO: created pod pod-service-account-nomountsa
May 21 10:44:04.830: INFO: pod pod-service-account-nomountsa service account token volume mount: false
May 21 10:44:04.842: INFO: created pod pod-service-account-defaultsa-mountspec
May 21 10:44:04.842: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
May 21 10:44:04.844: INFO: created pod pod-service-account-mountsa-mountspec
May 21 10:44:04.844: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
May 21 10:44:04.847: INFO: created pod pod-service-account-nomountsa-mountspec
May 21 10:44:04.847: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
May 21 10:44:04.850: INFO: created pod pod-service-account-defaultsa-nomountspec
May 21 10:44:04.850: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
May 21 10:44:04.854: INFO: created pod pod-service-account-mountsa-nomountspec
May 21 10:44:04.854: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
May 21 10:44:04.859: INFO: created pod pod-service-account-nomountsa-nomountspec
May 21 10:44:04.859: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:44:04.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-g844m" for this suite.
May 21 10:44:26.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:44:26.937: INFO: namespace: e2e-tests-svcaccounts-g844m, resource: bindings, ignored listing per whitelist
May 21 10:44:26.957: INFO: namespace e2e-tests-svcaccounts-g844m deletion completed in 22.086147358s

• [SLOW TEST:22.783 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:44:26.957: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-67a9d6d5-7bb5-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume configMaps
May 21 10:44:27.009: INFO: Waiting up to 5m0s for pod "pod-configmaps-67aa6a2c-7bb5-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-configmap-5d6xw" to be "success or failure"
May 21 10:44:27.013: INFO: Pod "pod-configmaps-67aa6a2c-7bb5-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 4.2452ms
May 21 10:44:29.017: INFO: Pod "pod-configmaps-67aa6a2c-7bb5-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007882187s
STEP: Saw pod success
May 21 10:44:29.017: INFO: Pod "pod-configmaps-67aa6a2c-7bb5-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:44:29.018: INFO: Trying to get logs from node 192.168.5.29 pod pod-configmaps-67aa6a2c-7bb5-11e9-be4b-6e6d88bcf118 container configmap-volume-test: <nil>
STEP: delete the pod
May 21 10:44:29.031: INFO: Waiting for pod pod-configmaps-67aa6a2c-7bb5-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:44:29.034: INFO: Pod pod-configmaps-67aa6a2c-7bb5-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:44:29.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-5d6xw" for this suite.
May 21 10:44:35.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:44:35.052: INFO: namespace: e2e-tests-configmap-5d6xw, resource: bindings, ignored listing per whitelist
May 21 10:44:35.101: INFO: namespace e2e-tests-configmap-5d6xw deletion completed in 6.06447998s

• [SLOW TEST:8.143 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:44:35.101: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 10:44:35.138: INFO: Creating deployment "nginx-deployment"
May 21 10:44:35.143: INFO: Waiting for observed generation 1
May 21 10:44:37.149: INFO: Waiting for all required pods to come up
May 21 10:44:37.152: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
May 21 10:44:43.158: INFO: Waiting for deployment "nginx-deployment" to complete
May 21 10:44:43.161: INFO: Updating deployment "nginx-deployment" with a non-existent image
May 21 10:44:43.166: INFO: Updating deployment nginx-deployment
May 21 10:44:43.166: INFO: Waiting for observed generation 2
May 21 10:44:45.171: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
May 21 10:44:45.173: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
May 21 10:44:45.174: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
May 21 10:44:45.180: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
May 21 10:44:45.180: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
May 21 10:44:45.182: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
May 21 10:44:45.184: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
May 21 10:44:45.184: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
May 21 10:44:45.193: INFO: Updating deployment nginx-deployment
May 21 10:44:45.193: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
May 21 10:44:45.200: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
May 21 10:44:47.210: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 21 10:44:47.215: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-v6t44,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-v6t44/deployments/nginx-deployment,UID:6c83fb55-7bb5-11e9-acff-fa163e1b1d33,ResourceVersion:17359,Generation:3,CreationTimestamp:2019-05-21 10:44:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-05-21 10:44:45 +0000 UTC 2019-05-21 10:44:45 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-05-21 10:44:45 +0000 UTC 2019-05-21 10:44:35 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

May 21 10:44:47.219: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-v6t44,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-v6t44/replicasets/nginx-deployment-7dc8f79789,UID:714ca8eb-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17352,Generation:3,CreationTimestamp:2019-05-21 10:44:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 6c83fb55-7bb5-11e9-acff-fa163e1b1d33 0xc4234c3c77 0xc4234c3c78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 21 10:44:47.219: INFO: All old ReplicaSets of Deployment "nginx-deployment":
May 21 10:44:47.219: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-v6t44,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-v6t44/replicasets/nginx-deployment-7f9675fb8b,UID:6c84875e-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17341,Generation:3,CreationTimestamp:2019-05-21 10:44:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 6c83fb55-7bb5-11e9-acff-fa163e1b1d33 0xc4234c3db7 0xc4234c3db8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
May 21 10:44:47.226: INFO: Pod "nginx-deployment-7dc8f79789-22rl2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-22rl2,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7dc8f79789-22rl2,UID:72867a19-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17351,Generation:0,CreationTimestamp:2019-05-21 10:44:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 714ca8eb-7bb5-11e9-8d66-fa163e76243a 0xc4233f3f77 0xc4233f3f78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.226: INFO: Pod "nginx-deployment-7dc8f79789-798wh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-798wh,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7dc8f79789-798wh,UID:7286e1ff-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17346,Generation:0,CreationTimestamp:2019-05-21 10:44:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 714ca8eb-7bb5-11e9-8d66-fa163e76243a 0xc423252270 0xc423252271}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.226: INFO: Pod "nginx-deployment-7dc8f79789-8whjr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-8whjr,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7dc8f79789-8whjr,UID:7151bf3d-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17286,Generation:0,CreationTimestamp:2019-05-21 10:44:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 714ca8eb-7bb5-11e9-8d66-fa163e76243a 0xc423252360 0xc423252361}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:43 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.29,PodIP:,StartTime:2019-05-21 10:44:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.226: INFO: Pod "nginx-deployment-7dc8f79789-9wtxd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-9wtxd,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7dc8f79789-9wtxd,UID:72853220-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17319,Generation:0,CreationTimestamp:2019-05-21 10:44:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 714ca8eb-7bb5-11e9-8d66-fa163e76243a 0xc423252690 0xc423252691}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.226: INFO: Pod "nginx-deployment-7dc8f79789-bcw6q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-bcw6q,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7dc8f79789-bcw6q,UID:7288d887-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17349,Generation:0,CreationTimestamp:2019-05-21 10:44:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 714ca8eb-7bb5-11e9-8d66-fa163e76243a 0xc423252be0 0xc423252be1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.226: INFO: Pod "nginx-deployment-7dc8f79789-ddnn9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-ddnn9,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7dc8f79789-ddnn9,UID:714e6a99-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17277,Generation:0,CreationTimestamp:2019-05-21 10:44:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 714ca8eb-7bb5-11e9-8d66-fa163e76243a 0xc4232531b0 0xc4232531b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:43 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.29,PodIP:,StartTime:2019-05-21 10:44:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.227: INFO: Pod "nginx-deployment-7dc8f79789-lnbjs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-lnbjs,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7dc8f79789-lnbjs,UID:72853af3-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17395,Generation:0,CreationTimestamp:2019-05-21 10:44:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 714ca8eb-7bb5-11e9-8d66-fa163e76243a 0xc4232533e0 0xc4232533e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.29,PodIP:,StartTime:2019-05-21 10:44:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.227: INFO: Pod "nginx-deployment-7dc8f79789-mllsk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-mllsk,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7dc8f79789-mllsk,UID:7286ec38-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17345,Generation:0,CreationTimestamp:2019-05-21 10:44:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 714ca8eb-7bb5-11e9-8d66-fa163e76243a 0xc4232535d0 0xc4232535d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.227: INFO: Pod "nginx-deployment-7dc8f79789-rxpxm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-rxpxm,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7dc8f79789-rxpxm,UID:714d448c-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17261,Generation:0,CreationTimestamp:2019-05-21 10:44:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 714ca8eb-7bb5-11e9-8d66-fa163e76243a 0xc423253790 0xc423253791}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:43 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.29,PodIP:,StartTime:2019-05-21 10:44:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.227: INFO: Pod "nginx-deployment-7dc8f79789-rzlt8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-rzlt8,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7dc8f79789-rzlt8,UID:72837e87-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17388,Generation:0,CreationTimestamp:2019-05-21 10:44:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 714ca8eb-7bb5-11e9-8d66-fa163e76243a 0xc423253900 0xc423253901}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.29,PodIP:,StartTime:2019-05-21 10:44:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.227: INFO: Pod "nginx-deployment-7dc8f79789-tjf7b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-tjf7b,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7dc8f79789-tjf7b,UID:714e35ee-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17281,Generation:0,CreationTimestamp:2019-05-21 10:44:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 714ca8eb-7bb5-11e9-8d66-fa163e76243a 0xc423253a80 0xc423253a81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:43 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.29,PodIP:,StartTime:2019-05-21 10:44:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.227: INFO: Pod "nginx-deployment-7dc8f79789-tkn5n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-tkn5n,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7dc8f79789-tkn5n,UID:7286d109-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17347,Generation:0,CreationTimestamp:2019-05-21 10:44:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 714ca8eb-7bb5-11e9-8d66-fa163e76243a 0xc423253c70 0xc423253c71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.227: INFO: Pod "nginx-deployment-7dc8f79789-x6r6q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-x6r6q,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7dc8f79789-x6r6q,UID:7150e583-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17280,Generation:0,CreationTimestamp:2019-05-21 10:44:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 714ca8eb-7bb5-11e9-8d66-fa163e76243a 0xc423253d40 0xc423253d41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:43 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.29,PodIP:,StartTime:2019-05-21 10:44:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.227: INFO: Pod "nginx-deployment-7f9675fb8b-2ftcn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-2ftcn,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7f9675fb8b-2ftcn,UID:6c87b8dc-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17200,Generation:0,CreationTimestamp:2019-05-21 10:44:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 6c84875e-7bb5-11e9-8d66-fa163e76243a 0xc423253e80 0xc423253e81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:35 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.29,PodIP:10.8.1.59,StartTime:2019-05-21 10:44:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-21 10:44:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://9119d02526f4e778bd15e8fef4e31844d4d584a10d2a2fc05a65e75c693488b3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.228: INFO: Pod "nginx-deployment-7f9675fb8b-2kgzx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-2kgzx,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7f9675fb8b-2kgzx,UID:7286c680-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17348,Generation:0,CreationTimestamp:2019-05-21 10:44:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 6c84875e-7bb5-11e9-8d66-fa163e76243a 0xc4231fc030 0xc4231fc031}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.228: INFO: Pod "nginx-deployment-7f9675fb8b-5dgmf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-5dgmf,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7f9675fb8b-5dgmf,UID:728544b5-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17320,Generation:0,CreationTimestamp:2019-05-21 10:44:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 6c84875e-7bb5-11e9-8d66-fa163e76243a 0xc4231fc0f0 0xc4231fc0f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.228: INFO: Pod "nginx-deployment-7f9675fb8b-7mq99" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-7mq99,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7f9675fb8b-7mq99,UID:72853a73-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17393,Generation:0,CreationTimestamp:2019-05-21 10:44:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 6c84875e-7bb5-11e9-8d66-fa163e76243a 0xc4231fc1b0 0xc4231fc1b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.29,PodIP:,StartTime:2019-05-21 10:44:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.228: INFO: Pod "nginx-deployment-7f9675fb8b-8dssp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-8dssp,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7f9675fb8b-8dssp,UID:7283dec6-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17377,Generation:0,CreationTimestamp:2019-05-21 10:44:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 6c84875e-7bb5-11e9-8d66-fa163e76243a 0xc4231fc2d7 0xc4231fc2d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.29,PodIP:,StartTime:2019-05-21 10:44:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.228: INFO: Pod "nginx-deployment-7f9675fb8b-8kq54" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-8kq54,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7f9675fb8b-8kq54,UID:6c892b6a-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17188,Generation:0,CreationTimestamp:2019-05-21 10:44:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 6c84875e-7bb5-11e9-8d66-fa163e76243a 0xc4231fc3e7 0xc4231fc3e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:35 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.29,PodIP:10.8.1.67,StartTime:2019-05-21 10:44:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-21 10:44:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://a43f5da8d747b972b75ce23ed813c01139d9ef028f5ff258c9a773be817bbc65}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.228: INFO: Pod "nginx-deployment-7f9675fb8b-dbnfd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-dbnfd,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7f9675fb8b-dbnfd,UID:6c87de9f-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17183,Generation:0,CreationTimestamp:2019-05-21 10:44:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 6c84875e-7bb5-11e9-8d66-fa163e76243a 0xc4231fc530 0xc4231fc531}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:35 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.29,PodIP:10.8.1.65,StartTime:2019-05-21 10:44:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-21 10:44:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://b37f3853598092de9a0c5b31af7843258ea55c2d1e423d80694abb1635a84cfe}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.228: INFO: Pod "nginx-deployment-7f9675fb8b-fbdxw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-fbdxw,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7f9675fb8b-fbdxw,UID:6c895dea-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17216,Generation:0,CreationTimestamp:2019-05-21 10:44:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 6c84875e-7bb5-11e9-8d66-fa163e76243a 0xc4231fc640 0xc4231fc641}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:35 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.29,PodIP:10.8.1.63,StartTime:2019-05-21 10:44:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-21 10:44:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://944074326cfb3b51eedb6e08690cce7849c84549131484ef26c7d3dde56ea4f3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.228: INFO: Pod "nginx-deployment-7f9675fb8b-ftgtk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-ftgtk,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7f9675fb8b-ftgtk,UID:6c869b38-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17193,Generation:0,CreationTimestamp:2019-05-21 10:44:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 6c84875e-7bb5-11e9-8d66-fa163e76243a 0xc4231fc750 0xc4231fc751}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:35 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.29,PodIP:10.8.1.61,StartTime:2019-05-21 10:44:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-21 10:44:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://c1e16aa9cd65cb743c3392b3aafc0fb923d32cc690813ce4c0ed267c1c2579f2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.229: INFO: Pod "nginx-deployment-7f9675fb8b-gfg8l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-gfg8l,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7f9675fb8b-gfg8l,UID:7286fcc4-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17343,Generation:0,CreationTimestamp:2019-05-21 10:44:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 6c84875e-7bb5-11e9-8d66-fa163e76243a 0xc4231fc8c0 0xc4231fc8c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.229: INFO: Pod "nginx-deployment-7f9675fb8b-gnfz9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-gnfz9,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7f9675fb8b-gnfz9,UID:6c87f359-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17181,Generation:0,CreationTimestamp:2019-05-21 10:44:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 6c84875e-7bb5-11e9-8d66-fa163e76243a 0xc4231fc9e0 0xc4231fc9e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:35 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.29,PodIP:10.8.1.66,StartTime:2019-05-21 10:44:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-21 10:44:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://f1f03bf1a4a31d1d76071eca7d42bb18a9ecd468cff160e51f40600fefe58495}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.229: INFO: Pod "nginx-deployment-7f9675fb8b-gwcbw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-gwcbw,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7f9675fb8b-gwcbw,UID:72854515-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17392,Generation:0,CreationTimestamp:2019-05-21 10:44:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 6c84875e-7bb5-11e9-8d66-fa163e76243a 0xc4231fcaf0 0xc4231fcaf1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.29,PodIP:,StartTime:2019-05-21 10:44:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.229: INFO: Pod "nginx-deployment-7f9675fb8b-hg6h2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-hg6h2,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7f9675fb8b-hg6h2,UID:7286f476-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17339,Generation:0,CreationTimestamp:2019-05-21 10:44:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 6c84875e-7bb5-11e9-8d66-fa163e76243a 0xc4231fcc37 0xc4231fcc38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.229: INFO: Pod "nginx-deployment-7f9675fb8b-hw6b8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-hw6b8,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7f9675fb8b-hw6b8,UID:72873f93-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17342,Generation:0,CreationTimestamp:2019-05-21 10:44:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 6c84875e-7bb5-11e9-8d66-fa163e76243a 0xc4231fcd60 0xc4231fcd61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.229: INFO: Pod "nginx-deployment-7f9675fb8b-k645t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-k645t,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7f9675fb8b-k645t,UID:7283afc9-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17357,Generation:0,CreationTimestamp:2019-05-21 10:44:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 6c84875e-7bb5-11e9-8d66-fa163e76243a 0xc4231fd080 0xc4231fd081}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.29,PodIP:,StartTime:2019-05-21 10:44:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.229: INFO: Pod "nginx-deployment-7f9675fb8b-kpb2j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-kpb2j,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7f9675fb8b-kpb2j,UID:7282c024-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17335,Generation:0,CreationTimestamp:2019-05-21 10:44:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 6c84875e-7bb5-11e9-8d66-fa163e76243a 0xc4231fdeb7 0xc4231fdeb8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.29,PodIP:,StartTime:2019-05-21 10:44:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.229: INFO: Pod "nginx-deployment-7f9675fb8b-mkj8h" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-mkj8h,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7f9675fb8b-mkj8h,UID:6c867405-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17210,Generation:0,CreationTimestamp:2019-05-21 10:44:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 6c84875e-7bb5-11e9-8d66-fa163e76243a 0xc4231d0087 0xc4231d0088}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:35 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.29,PodIP:10.8.1.60,StartTime:2019-05-21 10:44:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-21 10:44:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://be48a3741c3cfa1e8617bd24b714129513451b5fc853e2085c8a39d1a047b9fb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.230: INFO: Pod "nginx-deployment-7f9675fb8b-nvjk2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-nvjk2,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7f9675fb8b-nvjk2,UID:728746d4-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17344,Generation:0,CreationTimestamp:2019-05-21 10:44:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 6c84875e-7bb5-11e9-8d66-fa163e76243a 0xc4231d01b0 0xc4231d01b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.230: INFO: Pod "nginx-deployment-7f9675fb8b-p4twd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-p4twd,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7f9675fb8b-p4twd,UID:72852844-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17391,Generation:0,CreationTimestamp:2019-05-21 10:44:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 6c84875e-7bb5-11e9-8d66-fa163e76243a 0xc4231d0270 0xc4231d0271}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:45 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.29,PodIP:,StartTime:2019-05-21 10:44:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 10:44:47.230: INFO: Pod "nginx-deployment-7f9675fb8b-xnp68" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-xnp68,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-v6t44,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6t44/pods/nginx-deployment-7f9675fb8b-xnp68,UID:6c85dcc7-7bb5-11e9-8d66-fa163e76243a,ResourceVersion:17205,Generation:0,CreationTimestamp:2019-05-21 10:44:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 6c84875e-7bb5-11e9-8d66-fa163e76243a 0xc4231d0377 0xc4231d0378}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vchkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vchkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vchkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:44:35 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.29,PodIP:10.8.1.62,StartTime:2019-05-21 10:44:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-21 10:44:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://f93a714075dd6c0736cb841777339f1a0d2c1edb2c4feefc6cacdc451ea041e5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:44:47.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-v6t44" for this suite.
May 21 10:44:53.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:44:53.326: INFO: namespace: e2e-tests-deployment-v6t44, resource: bindings, ignored listing per whitelist
May 21 10:44:53.352: INFO: namespace e2e-tests-deployment-v6t44 deletion completed in 6.119646718s

• [SLOW TEST:18.251 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:44:53.352: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 10:44:53.463: INFO: Waiting up to 5m0s for pod "downwardapi-volume-776ed1f0-7bb5-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-downward-api-kfgnc" to be "success or failure"
May 21 10:44:53.467: INFO: Pod "downwardapi-volume-776ed1f0-7bb5-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 3.922685ms
May 21 10:44:55.471: INFO: Pod "downwardapi-volume-776ed1f0-7bb5-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008026342s
May 21 10:44:57.476: INFO: Pod "downwardapi-volume-776ed1f0-7bb5-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01269503s
May 21 10:44:59.479: INFO: Pod "downwardapi-volume-776ed1f0-7bb5-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015341422s
May 21 10:45:01.482: INFO: Pod "downwardapi-volume-776ed1f0-7bb5-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 8.019145427s
May 21 10:45:03.487: INFO: Pod "downwardapi-volume-776ed1f0-7bb5-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 10.023245606s
May 21 10:45:05.491: INFO: Pod "downwardapi-volume-776ed1f0-7bb5-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.027418691s
STEP: Saw pod success
May 21 10:45:05.491: INFO: Pod "downwardapi-volume-776ed1f0-7bb5-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:45:05.494: INFO: Trying to get logs from node 192.168.5.29 pod downwardapi-volume-776ed1f0-7bb5-11e9-be4b-6e6d88bcf118 container client-container: <nil>
STEP: delete the pod
May 21 10:45:05.508: INFO: Waiting for pod downwardapi-volume-776ed1f0-7bb5-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:45:05.517: INFO: Pod downwardapi-volume-776ed1f0-7bb5-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:45:05.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kfgnc" for this suite.
May 21 10:45:11.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:45:11.548: INFO: namespace: e2e-tests-downward-api-kfgnc, resource: bindings, ignored listing per whitelist
May 21 10:45:11.579: INFO: namespace e2e-tests-downward-api-kfgnc deletion completed in 6.059259585s

• [SLOW TEST:18.227 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:45:11.579: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-866q8
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-866q8 to expose endpoints map[]
May 21 10:45:11.627: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-866q8 exposes endpoints map[] (2.383831ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-866q8
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-866q8 to expose endpoints map[pod1:[80]]
May 21 10:45:13.648: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-866q8 exposes endpoints map[pod1:[80]] (2.01637255s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-866q8
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-866q8 to expose endpoints map[pod1:[80] pod2:[80]]
May 21 10:45:15.668: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-866q8 exposes endpoints map[pod1:[80] pod2:[80]] (2.016705816s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-866q8
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-866q8 to expose endpoints map[pod2:[80]]
May 21 10:45:16.680: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-866q8 exposes endpoints map[pod2:[80]] (1.007891261s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-866q8
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-866q8 to expose endpoints map[]
May 21 10:45:17.696: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-866q8 exposes endpoints map[] (1.013054989s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:45:17.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-866q8" for this suite.
May 21 10:45:39.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:45:39.738: INFO: namespace: e2e-tests-services-866q8, resource: bindings, ignored listing per whitelist
May 21 10:45:39.810: INFO: namespace e2e-tests-services-866q8 deletion completed in 22.098269634s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:28.230 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:45:39.810: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 10:46:01.869: INFO: Container started at 2019-05-21 10:45:40 +0000 UTC, pod became ready at 2019-05-21 10:46:00 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:46:01.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-q5g9b" for this suite.
May 21 10:46:23.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:46:23.927: INFO: namespace: e2e-tests-container-probe-q5g9b, resource: bindings, ignored listing per whitelist
May 21 10:46:23.936: INFO: namespace e2e-tests-container-probe-q5g9b deletion completed in 22.063512136s

• [SLOW TEST:44.126 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:46:23.936: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
May 21 10:46:23.981: INFO: Waiting up to 5m0s for pod "client-containers-ad63195c-7bb5-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-containers-lgc4m" to be "success or failure"
May 21 10:46:23.984: INFO: Pod "client-containers-ad63195c-7bb5-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 3.283894ms
May 21 10:46:25.990: INFO: Pod "client-containers-ad63195c-7bb5-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008924036s
STEP: Saw pod success
May 21 10:46:25.990: INFO: Pod "client-containers-ad63195c-7bb5-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:46:25.991: INFO: Trying to get logs from node 192.168.5.29 pod client-containers-ad63195c-7bb5-11e9-be4b-6e6d88bcf118 container test-container: <nil>
STEP: delete the pod
May 21 10:46:26.006: INFO: Waiting for pod client-containers-ad63195c-7bb5-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:46:26.009: INFO: Pod client-containers-ad63195c-7bb5-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:46:26.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-lgc4m" for this suite.
May 21 10:46:32.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:46:32.048: INFO: namespace: e2e-tests-containers-lgc4m, resource: bindings, ignored listing per whitelist
May 21 10:46:32.079: INFO: namespace e2e-tests-containers-lgc4m deletion completed in 6.064335282s

• [SLOW TEST:8.142 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:46:32.079: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
May 21 10:46:32.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 create -f - --namespace=e2e-tests-kubectl-f2rhd'
May 21 10:46:32.333: INFO: stderr: ""
May 21 10:46:32.333: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
May 21 10:46:33.335: INFO: Selector matched 1 pods for map[app:redis]
May 21 10:46:33.336: INFO: Found 0 / 1
May 21 10:46:34.335: INFO: Selector matched 1 pods for map[app:redis]
May 21 10:46:34.335: INFO: Found 1 / 1
May 21 10:46:34.335: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 21 10:46:34.337: INFO: Selector matched 1 pods for map[app:redis]
May 21 10:46:34.337: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
May 21 10:46:34.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 logs redis-master-bhwsb redis-master --namespace=e2e-tests-kubectl-f2rhd'
May 21 10:46:34.449: INFO: stderr: ""
May 21 10:46:34.449: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 May 10:46:33.138 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 May 10:46:33.138 # Server started, Redis version 3.2.12\n1:M 21 May 10:46:33.138 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 May 10:46:33.138 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
May 21 10:46:34.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 log redis-master-bhwsb redis-master --namespace=e2e-tests-kubectl-f2rhd --tail=1'
May 21 10:46:34.535: INFO: stderr: ""
May 21 10:46:34.535: INFO: stdout: "1:M 21 May 10:46:33.138 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
May 21 10:46:34.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 log redis-master-bhwsb redis-master --namespace=e2e-tests-kubectl-f2rhd --limit-bytes=1'
May 21 10:46:34.629: INFO: stderr: ""
May 21 10:46:34.629: INFO: stdout: " "
STEP: exposing timestamps
May 21 10:46:34.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 log redis-master-bhwsb redis-master --namespace=e2e-tests-kubectl-f2rhd --tail=1 --timestamps'
May 21 10:46:34.710: INFO: stderr: ""
May 21 10:46:34.710: INFO: stdout: "2019-05-21T10:46:33.139852425Z 1:M 21 May 10:46:33.138 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
May 21 10:46:37.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 log redis-master-bhwsb redis-master --namespace=e2e-tests-kubectl-f2rhd --since=1s'
May 21 10:46:37.301: INFO: stderr: ""
May 21 10:46:37.301: INFO: stdout: ""
May 21 10:46:37.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 log redis-master-bhwsb redis-master --namespace=e2e-tests-kubectl-f2rhd --since=24h'
May 21 10:46:37.390: INFO: stderr: ""
May 21 10:46:37.390: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 May 10:46:33.138 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 May 10:46:33.138 # Server started, Redis version 3.2.12\n1:M 21 May 10:46:33.138 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 May 10:46:33.138 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
May 21 10:46:37.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-f2rhd'
May 21 10:46:37.473: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 10:46:37.473: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
May 21 10:46:37.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-f2rhd'
May 21 10:46:37.566: INFO: stderr: "No resources found.\n"
May 21 10:46:37.566: INFO: stdout: ""
May 21 10:46:37.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods -l name=nginx --namespace=e2e-tests-kubectl-f2rhd -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 21 10:46:37.654: INFO: stderr: ""
May 21 10:46:37.654: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:46:37.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-f2rhd" for this suite.
May 21 10:46:59.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:46:59.689: INFO: namespace: e2e-tests-kubectl-f2rhd, resource: bindings, ignored listing per whitelist
May 21 10:46:59.733: INFO: namespace e2e-tests-kubectl-f2rhd deletion completed in 22.072694602s

• [SLOW TEST:27.654 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:46:59.734: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 10:46:59.782: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c2b9dadb-7bb5-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-downward-api-lj2kp" to be "success or failure"
May 21 10:46:59.784: INFO: Pod "downwardapi-volume-c2b9dadb-7bb5-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 2.27559ms
May 21 10:47:01.787: INFO: Pod "downwardapi-volume-c2b9dadb-7bb5-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005453047s
STEP: Saw pod success
May 21 10:47:01.787: INFO: Pod "downwardapi-volume-c2b9dadb-7bb5-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:47:01.789: INFO: Trying to get logs from node 192.168.5.29 pod downwardapi-volume-c2b9dadb-7bb5-11e9-be4b-6e6d88bcf118 container client-container: <nil>
STEP: delete the pod
May 21 10:47:01.801: INFO: Waiting for pod downwardapi-volume-c2b9dadb-7bb5-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:47:01.803: INFO: Pod downwardapi-volume-c2b9dadb-7bb5-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:47:01.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lj2kp" for this suite.
May 21 10:47:07.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:47:07.826: INFO: namespace: e2e-tests-downward-api-lj2kp, resource: bindings, ignored listing per whitelist
May 21 10:47:07.871: INFO: namespace e2e-tests-downward-api-lj2kp deletion completed in 6.065583245s

• [SLOW TEST:8.137 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:47:07.871: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 10:47:07.914: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c792c8dc-7bb5-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-projected-9rnn7" to be "success or failure"
May 21 10:47:07.915: INFO: Pod "downwardapi-volume-c792c8dc-7bb5-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 1.733414ms
May 21 10:47:09.918: INFO: Pod "downwardapi-volume-c792c8dc-7bb5-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004534773s
STEP: Saw pod success
May 21 10:47:09.918: INFO: Pod "downwardapi-volume-c792c8dc-7bb5-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:47:09.920: INFO: Trying to get logs from node 192.168.5.29 pod downwardapi-volume-c792c8dc-7bb5-11e9-be4b-6e6d88bcf118 container client-container: <nil>
STEP: delete the pod
May 21 10:47:09.930: INFO: Waiting for pod downwardapi-volume-c792c8dc-7bb5-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:47:09.933: INFO: Pod downwardapi-volume-c792c8dc-7bb5-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:47:09.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9rnn7" for this suite.
May 21 10:47:15.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:47:15.975: INFO: namespace: e2e-tests-projected-9rnn7, resource: bindings, ignored listing per whitelist
May 21 10:47:16.004: INFO: namespace e2e-tests-projected-9rnn7 deletion completed in 6.067838523s

• [SLOW TEST:8.132 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:47:16.004: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
May 21 10:47:16.052: INFO: Waiting up to 5m0s for pod "pod-cc6c9eab-7bb5-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-emptydir-wg7gd" to be "success or failure"
May 21 10:47:16.054: INFO: Pod "pod-cc6c9eab-7bb5-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 1.61406ms
May 21 10:47:18.060: INFO: Pod "pod-cc6c9eab-7bb5-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007746383s
STEP: Saw pod success
May 21 10:47:18.060: INFO: Pod "pod-cc6c9eab-7bb5-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:47:18.062: INFO: Trying to get logs from node 192.168.5.29 pod pod-cc6c9eab-7bb5-11e9-be4b-6e6d88bcf118 container test-container: <nil>
STEP: delete the pod
May 21 10:47:18.075: INFO: Waiting for pod pod-cc6c9eab-7bb5-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:47:18.076: INFO: Pod pod-cc6c9eab-7bb5-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:47:18.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wg7gd" for this suite.
May 21 10:47:24.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:47:24.135: INFO: namespace: e2e-tests-emptydir-wg7gd, resource: bindings, ignored listing per whitelist
May 21 10:47:24.142: INFO: namespace e2e-tests-emptydir-wg7gd deletion completed in 6.06305809s

• [SLOW TEST:8.138 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:47:24.142: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:48:24.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-twhk8" for this suite.
May 21 10:48:46.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:48:46.235: INFO: namespace: e2e-tests-container-probe-twhk8, resource: bindings, ignored listing per whitelist
May 21 10:48:46.272: INFO: namespace e2e-tests-container-probe-twhk8 deletion completed in 22.078677123s

• [SLOW TEST:82.130 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:48:46.273: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
May 21 10:48:46.331: INFO: Waiting up to 5m0s for pod "pod-023b0b57-7bb6-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-emptydir-t5k6j" to be "success or failure"
May 21 10:48:46.333: INFO: Pod "pod-023b0b57-7bb6-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 2.106109ms
May 21 10:48:48.336: INFO: Pod "pod-023b0b57-7bb6-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004893971s
STEP: Saw pod success
May 21 10:48:48.336: INFO: Pod "pod-023b0b57-7bb6-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:48:48.337: INFO: Trying to get logs from node 192.168.5.29 pod pod-023b0b57-7bb6-11e9-be4b-6e6d88bcf118 container test-container: <nil>
STEP: delete the pod
May 21 10:48:48.349: INFO: Waiting for pod pod-023b0b57-7bb6-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:48:48.352: INFO: Pod pod-023b0b57-7bb6-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:48:48.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-t5k6j" for this suite.
May 21 10:48:54.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:48:54.392: INFO: namespace: e2e-tests-emptydir-t5k6j, resource: bindings, ignored listing per whitelist
May 21 10:48:54.425: INFO: namespace e2e-tests-emptydir-t5k6j deletion completed in 6.070625278s

• [SLOW TEST:8.153 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:48:54.426: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
May 21 10:48:54.479: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-9btbn,SelfLink:/api/v1/namespaces/e2e-tests-watch-9btbn/configmaps/e2e-watch-test-label-changed,UID:071686aa-7bb6-11e9-acff-fa163e1b1d33,ResourceVersion:18241,Generation:0,CreationTimestamp:2019-05-21 10:48:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 21 10:48:54.480: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-9btbn,SelfLink:/api/v1/namespaces/e2e-tests-watch-9btbn/configmaps/e2e-watch-test-label-changed,UID:071686aa-7bb6-11e9-acff-fa163e1b1d33,ResourceVersion:18242,Generation:0,CreationTimestamp:2019-05-21 10:48:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 21 10:48:54.480: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-9btbn,SelfLink:/api/v1/namespaces/e2e-tests-watch-9btbn/configmaps/e2e-watch-test-label-changed,UID:071686aa-7bb6-11e9-acff-fa163e1b1d33,ResourceVersion:18243,Generation:0,CreationTimestamp:2019-05-21 10:48:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
May 21 10:49:04.498: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-9btbn,SelfLink:/api/v1/namespaces/e2e-tests-watch-9btbn/configmaps/e2e-watch-test-label-changed,UID:071686aa-7bb6-11e9-acff-fa163e1b1d33,ResourceVersion:18259,Generation:0,CreationTimestamp:2019-05-21 10:48:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 21 10:49:04.498: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-9btbn,SelfLink:/api/v1/namespaces/e2e-tests-watch-9btbn/configmaps/e2e-watch-test-label-changed,UID:071686aa-7bb6-11e9-acff-fa163e1b1d33,ResourceVersion:18260,Generation:0,CreationTimestamp:2019-05-21 10:48:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
May 21 10:49:04.498: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-9btbn,SelfLink:/api/v1/namespaces/e2e-tests-watch-9btbn/configmaps/e2e-watch-test-label-changed,UID:071686aa-7bb6-11e9-acff-fa163e1b1d33,ResourceVersion:18261,Generation:0,CreationTimestamp:2019-05-21 10:48:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:49:04.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-9btbn" for this suite.
May 21 10:49:10.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:49:10.540: INFO: namespace: e2e-tests-watch-9btbn, resource: bindings, ignored listing per whitelist
May 21 10:49:10.574: INFO: namespace e2e-tests-watch-9btbn deletion completed in 6.072576487s

• [SLOW TEST:16.148 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:49:10.574: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-10b62b66-7bb6-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume secrets
May 21 10:49:10.623: INFO: Waiting up to 5m0s for pod "pod-secrets-10b6bc9e-7bb6-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-secrets-m7nrm" to be "success or failure"
May 21 10:49:10.624: INFO: Pod "pod-secrets-10b6bc9e-7bb6-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 1.691237ms
May 21 10:49:12.627: INFO: Pod "pod-secrets-10b6bc9e-7bb6-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00461059s
STEP: Saw pod success
May 21 10:49:12.627: INFO: Pod "pod-secrets-10b6bc9e-7bb6-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:49:12.629: INFO: Trying to get logs from node 192.168.5.29 pod pod-secrets-10b6bc9e-7bb6-11e9-be4b-6e6d88bcf118 container secret-volume-test: <nil>
STEP: delete the pod
May 21 10:49:12.640: INFO: Waiting for pod pod-secrets-10b6bc9e-7bb6-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:49:12.642: INFO: Pod pod-secrets-10b6bc9e-7bb6-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:49:12.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-m7nrm" for this suite.
May 21 10:49:18.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:49:18.698: INFO: namespace: e2e-tests-secrets-m7nrm, resource: bindings, ignored listing per whitelist
May 21 10:49:18.707: INFO: namespace e2e-tests-secrets-m7nrm deletion completed in 6.061985261s

• [SLOW TEST:8.133 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:49:18.707: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-qn7cg/configmap-test-158e6774-7bb6-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume configMaps
May 21 10:49:18.750: INFO: Waiting up to 5m0s for pod "pod-configmaps-158ef3e1-7bb6-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-configmap-qn7cg" to be "success or failure"
May 21 10:49:18.751: INFO: Pod "pod-configmaps-158ef3e1-7bb6-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 1.624834ms
May 21 10:49:20.755: INFO: Pod "pod-configmaps-158ef3e1-7bb6-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004999871s
STEP: Saw pod success
May 21 10:49:20.755: INFO: Pod "pod-configmaps-158ef3e1-7bb6-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:49:20.756: INFO: Trying to get logs from node 192.168.5.29 pod pod-configmaps-158ef3e1-7bb6-11e9-be4b-6e6d88bcf118 container env-test: <nil>
STEP: delete the pod
May 21 10:49:20.772: INFO: Waiting for pod pod-configmaps-158ef3e1-7bb6-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:49:20.774: INFO: Pod pod-configmaps-158ef3e1-7bb6-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:49:20.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-qn7cg" for this suite.
May 21 10:49:26.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:49:26.827: INFO: namespace: e2e-tests-configmap-qn7cg, resource: bindings, ignored listing per whitelist
May 21 10:49:26.843: INFO: namespace e2e-tests-configmap-qn7cg deletion completed in 6.06610687s

• [SLOW TEST:8.136 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:49:26.843: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
May 21 10:49:26.891: INFO: Waiting up to 5m0s for pod "pod-1a68fb9f-7bb6-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-emptydir-fxnnm" to be "success or failure"
May 21 10:49:26.894: INFO: Pod "pod-1a68fb9f-7bb6-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 2.556422ms
May 21 10:49:28.897: INFO: Pod "pod-1a68fb9f-7bb6-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00541367s
STEP: Saw pod success
May 21 10:49:28.897: INFO: Pod "pod-1a68fb9f-7bb6-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:49:28.898: INFO: Trying to get logs from node 192.168.5.29 pod pod-1a68fb9f-7bb6-11e9-be4b-6e6d88bcf118 container test-container: <nil>
STEP: delete the pod
May 21 10:49:28.910: INFO: Waiting for pod pod-1a68fb9f-7bb6-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:49:28.911: INFO: Pod pod-1a68fb9f-7bb6-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:49:28.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-fxnnm" for this suite.
May 21 10:49:34.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:49:34.932: INFO: namespace: e2e-tests-emptydir-fxnnm, resource: bindings, ignored listing per whitelist
May 21 10:49:34.983: INFO: namespace e2e-tests-emptydir-fxnnm deletion completed in 6.068777785s

• [SLOW TEST:8.140 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:49:34.983: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 10:49:35.023: INFO: Creating deployment "test-recreate-deployment"
May 21 10:49:35.027: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
May 21 10:49:35.030: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
May 21 10:49:37.035: INFO: Waiting deployment "test-recreate-deployment" to complete
May 21 10:49:37.037: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
May 21 10:49:37.044: INFO: Updating deployment test-recreate-deployment
May 21 10:49:37.044: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 21 10:49:37.087: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-p7q28,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-p7q28/deployments/test-recreate-deployment,UID:1f42b8b7-7bb6-11e9-acff-fa163e1b1d33,ResourceVersion:18430,Generation:2,CreationTimestamp:2019-05-21 10:49:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-05-21 10:49:37 +0000 UTC 2019-05-21 10:49:37 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-05-21 10:49:37 +0000 UTC 2019-05-21 10:49:35 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

May 21 10:49:37.090: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-p7q28,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-p7q28/replicasets/test-recreate-deployment-7cf749666b,UID:2079887f-7bb6-11e9-8d66-fa163e76243a,ResourceVersion:18427,Generation:1,CreationTimestamp:2019-05-21 10:49:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 1f42b8b7-7bb6-11e9-acff-fa163e1b1d33 0xc421f3a8b7 0xc421f3a8b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 21 10:49:37.090: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
May 21 10:49:37.090: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-p7q28,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-p7q28/replicasets/test-recreate-deployment-79f694ff59,UID:1f43c1b7-7bb6-11e9-8d66-fa163e76243a,ResourceVersion:18419,Generation:2,CreationTimestamp:2019-05-21 10:49:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 1f42b8b7-7bb6-11e9-acff-fa163e1b1d33 0xc421f3a7e7 0xc421f3a7e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 21 10:49:37.092: INFO: Pod "test-recreate-deployment-7cf749666b-ltt55" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-ltt55,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-p7q28,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p7q28/pods/test-recreate-deployment-7cf749666b-ltt55,UID:207a569e-7bb6-11e9-8d66-fa163e76243a,ResourceVersion:18425,Generation:0,CreationTimestamp:2019-05-21 10:49:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b 2079887f-7bb6-11e9-8d66-fa163e76243a 0xc422cbc7c7 0xc422cbc7c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qp67f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qp67f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qp67f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 10:49:37 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:49:37.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-p7q28" for this suite.
May 21 10:49:43.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:49:43.150: INFO: namespace: e2e-tests-deployment-p7q28, resource: bindings, ignored listing per whitelist
May 21 10:49:43.161: INFO: namespace e2e-tests-deployment-p7q28 deletion completed in 6.065364057s

• [SLOW TEST:8.178 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:49:43.161: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May 21 10:49:47.230: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 10:49:47.232: INFO: Pod pod-with-poststart-exec-hook still exists
May 21 10:49:49.233: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 10:49:49.235: INFO: Pod pod-with-poststart-exec-hook still exists
May 21 10:49:51.233: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 10:49:51.236: INFO: Pod pod-with-poststart-exec-hook still exists
May 21 10:49:53.233: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 10:49:53.235: INFO: Pod pod-with-poststart-exec-hook still exists
May 21 10:49:55.233: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 10:49:55.235: INFO: Pod pod-with-poststart-exec-hook still exists
May 21 10:49:57.233: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 10:49:57.235: INFO: Pod pod-with-poststart-exec-hook still exists
May 21 10:49:59.233: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 10:49:59.235: INFO: Pod pod-with-poststart-exec-hook still exists
May 21 10:50:01.233: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 10:50:01.236: INFO: Pod pod-with-poststart-exec-hook still exists
May 21 10:50:03.233: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 10:50:03.235: INFO: Pod pod-with-poststart-exec-hook still exists
May 21 10:50:05.233: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 10:50:05.236: INFO: Pod pod-with-poststart-exec-hook still exists
May 21 10:50:07.233: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 10:50:07.236: INFO: Pod pod-with-poststart-exec-hook still exists
May 21 10:50:09.233: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 10:50:09.235: INFO: Pod pod-with-poststart-exec-hook still exists
May 21 10:50:11.233: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 10:50:11.238: INFO: Pod pod-with-poststart-exec-hook still exists
May 21 10:50:13.233: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 10:50:13.236: INFO: Pod pod-with-poststart-exec-hook still exists
May 21 10:50:15.233: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 10:50:15.236: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:50:15.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-bt9lh" for this suite.
May 21 10:50:37.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:50:37.302: INFO: namespace: e2e-tests-container-lifecycle-hook-bt9lh, resource: bindings, ignored listing per whitelist
May 21 10:50:37.304: INFO: namespace e2e-tests-container-lifecycle-hook-bt9lh deletion completed in 22.06373522s

• [SLOW TEST:54.143 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:50:37.304: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
May 21 10:50:37.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 create -f - --namespace=e2e-tests-kubectl-mcnrf'
May 21 10:50:37.640: INFO: stderr: ""
May 21 10:50:37.640: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 21 10:50:37.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-mcnrf'
May 21 10:50:37.723: INFO: stderr: ""
May 21 10:50:37.723: INFO: stdout: "update-demo-nautilus-lrd64 update-demo-nautilus-pz8g8 "
May 21 10:50:37.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods update-demo-nautilus-lrd64 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mcnrf'
May 21 10:50:37.798: INFO: stderr: ""
May 21 10:50:37.798: INFO: stdout: ""
May 21 10:50:37.798: INFO: update-demo-nautilus-lrd64 is created but not running
May 21 10:50:42.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-mcnrf'
May 21 10:50:42.892: INFO: stderr: ""
May 21 10:50:42.892: INFO: stdout: "update-demo-nautilus-lrd64 update-demo-nautilus-pz8g8 "
May 21 10:50:42.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods update-demo-nautilus-lrd64 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mcnrf'
May 21 10:50:42.973: INFO: stderr: ""
May 21 10:50:42.973: INFO: stdout: "true"
May 21 10:50:42.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods update-demo-nautilus-lrd64 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mcnrf'
May 21 10:50:43.052: INFO: stderr: ""
May 21 10:50:43.052: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 21 10:50:43.052: INFO: validating pod update-demo-nautilus-lrd64
May 21 10:50:43.056: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 10:50:43.056: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 10:50:43.056: INFO: update-demo-nautilus-lrd64 is verified up and running
May 21 10:50:43.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods update-demo-nautilus-pz8g8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mcnrf'
May 21 10:50:43.131: INFO: stderr: ""
May 21 10:50:43.131: INFO: stdout: "true"
May 21 10:50:43.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods update-demo-nautilus-pz8g8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mcnrf'
May 21 10:50:43.206: INFO: stderr: ""
May 21 10:50:43.206: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 21 10:50:43.206: INFO: validating pod update-demo-nautilus-pz8g8
May 21 10:50:43.209: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 10:50:43.209: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 10:50:43.209: INFO: update-demo-nautilus-pz8g8 is verified up and running
STEP: scaling down the replication controller
May 21 10:50:43.210: INFO: scanned /root for discovery docs: <nil>
May 21 10:50:43.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-mcnrf'
May 21 10:50:44.309: INFO: stderr: ""
May 21 10:50:44.309: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 21 10:50:44.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-mcnrf'
May 21 10:50:44.388: INFO: stderr: ""
May 21 10:50:44.388: INFO: stdout: "update-demo-nautilus-lrd64 update-demo-nautilus-pz8g8 "
STEP: Replicas for name=update-demo: expected=1 actual=2
May 21 10:50:49.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-mcnrf'
May 21 10:50:49.474: INFO: stderr: ""
May 21 10:50:49.474: INFO: stdout: "update-demo-nautilus-lrd64 "
May 21 10:50:49.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods update-demo-nautilus-lrd64 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mcnrf'
May 21 10:50:49.547: INFO: stderr: ""
May 21 10:50:49.547: INFO: stdout: "true"
May 21 10:50:49.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods update-demo-nautilus-lrd64 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mcnrf'
May 21 10:50:49.626: INFO: stderr: ""
May 21 10:50:49.626: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 21 10:50:49.626: INFO: validating pod update-demo-nautilus-lrd64
May 21 10:50:49.629: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 10:50:49.629: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 10:50:49.629: INFO: update-demo-nautilus-lrd64 is verified up and running
STEP: scaling up the replication controller
May 21 10:50:49.630: INFO: scanned /root for discovery docs: <nil>
May 21 10:50:49.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-mcnrf'
May 21 10:50:50.727: INFO: stderr: ""
May 21 10:50:50.727: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 21 10:50:50.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-mcnrf'
May 21 10:50:50.802: INFO: stderr: ""
May 21 10:50:50.802: INFO: stdout: "update-demo-nautilus-lrd64 update-demo-nautilus-rghb9 "
May 21 10:50:50.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods update-demo-nautilus-lrd64 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mcnrf'
May 21 10:50:50.881: INFO: stderr: ""
May 21 10:50:50.881: INFO: stdout: "true"
May 21 10:50:50.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods update-demo-nautilus-lrd64 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mcnrf'
May 21 10:50:50.971: INFO: stderr: ""
May 21 10:50:50.971: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 21 10:50:50.971: INFO: validating pod update-demo-nautilus-lrd64
May 21 10:50:50.974: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 10:50:50.974: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 10:50:50.974: INFO: update-demo-nautilus-lrd64 is verified up and running
May 21 10:50:50.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods update-demo-nautilus-rghb9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mcnrf'
May 21 10:50:51.053: INFO: stderr: ""
May 21 10:50:51.053: INFO: stdout: "true"
May 21 10:50:51.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods update-demo-nautilus-rghb9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mcnrf'
May 21 10:50:51.132: INFO: stderr: ""
May 21 10:50:51.132: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 21 10:50:51.132: INFO: validating pod update-demo-nautilus-rghb9
May 21 10:50:51.135: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 10:50:51.135: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 10:50:51.135: INFO: update-demo-nautilus-rghb9 is verified up and running
STEP: using delete to clean up resources
May 21 10:50:51.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-mcnrf'
May 21 10:50:51.215: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 10:50:51.215: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 21 10:50:51.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-mcnrf'
May 21 10:50:51.305: INFO: stderr: "No resources found.\n"
May 21 10:50:51.305: INFO: stdout: ""
May 21 10:50:51.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 get pods -l name=update-demo --namespace=e2e-tests-kubectl-mcnrf -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 21 10:50:51.399: INFO: stderr: ""
May 21 10:50:51.399: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:50:51.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mcnrf" for this suite.
May 21 10:51:13.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:51:13.434: INFO: namespace: e2e-tests-kubectl-mcnrf, resource: bindings, ignored listing per whitelist
May 21 10:51:13.481: INFO: namespace e2e-tests-kubectl-mcnrf deletion completed in 22.076374202s

• [SLOW TEST:36.178 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:51:13.482: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0521 10:51:43.551511      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 21 10:51:43.551: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:51:43.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-bsmvw" for this suite.
May 21 10:51:49.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:51:49.630: INFO: namespace: e2e-tests-gc-bsmvw, resource: bindings, ignored listing per whitelist
May 21 10:51:49.653: INFO: namespace e2e-tests-gc-bsmvw deletion completed in 6.098761s

• [SLOW TEST:36.171 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:51:49.653: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-6f87646c-7bb6-11e9-be4b-6e6d88bcf118
STEP: Creating a pod to test consume secrets
May 21 10:51:49.716: INFO: Waiting up to 5m0s for pod "pod-secrets-6f8a940e-7bb6-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-secrets-qbfng" to be "success or failure"
May 21 10:51:49.718: INFO: Pod "pod-secrets-6f8a940e-7bb6-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 1.559565ms
May 21 10:51:51.721: INFO: Pod "pod-secrets-6f8a940e-7bb6-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004174438s
STEP: Saw pod success
May 21 10:51:51.721: INFO: Pod "pod-secrets-6f8a940e-7bb6-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:51:51.722: INFO: Trying to get logs from node 192.168.5.29 pod pod-secrets-6f8a940e-7bb6-11e9-be4b-6e6d88bcf118 container secret-volume-test: <nil>
STEP: delete the pod
May 21 10:51:51.743: INFO: Waiting for pod pod-secrets-6f8a940e-7bb6-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:51:51.746: INFO: Pod pod-secrets-6f8a940e-7bb6-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:51:51.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-qbfng" for this suite.
May 21 10:51:57.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:51:57.809: INFO: namespace: e2e-tests-secrets-qbfng, resource: bindings, ignored listing per whitelist
May 21 10:51:57.817: INFO: namespace e2e-tests-secrets-qbfng deletion completed in 6.068135142s
STEP: Destroying namespace "e2e-tests-secret-namespace-8679s" for this suite.
May 21 10:52:03.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:52:03.889: INFO: namespace: e2e-tests-secret-namespace-8679s, resource: bindings, ignored listing per whitelist
May 21 10:52:03.889: INFO: namespace e2e-tests-secret-namespace-8679s deletion completed in 6.071832085s

• [SLOW TEST:14.236 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:52:03.889: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
May 21 10:52:06.020: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:52:30.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-gpc2r" for this suite.
May 21 10:52:36.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:52:36.069: INFO: namespace: e2e-tests-namespaces-gpc2r, resource: bindings, ignored listing per whitelist
May 21 10:52:36.115: INFO: namespace e2e-tests-namespaces-gpc2r deletion completed in 6.066827147s
STEP: Destroying namespace "e2e-tests-nsdeletetest-jtvvf" for this suite.
May 21 10:52:36.125: INFO: Namespace e2e-tests-nsdeletetest-jtvvf was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-jdr6d" for this suite.
May 21 10:52:42.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:52:42.179: INFO: namespace: e2e-tests-nsdeletetest-jdr6d, resource: bindings, ignored listing per whitelist
May 21 10:52:42.198: INFO: namespace e2e-tests-nsdeletetest-jdr6d deletion completed in 6.07228061s

• [SLOW TEST:38.308 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:52:42.198: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
May 21 10:52:42.260: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-877789554 proxy --unix-socket=/tmp/kubectl-proxy-unix581350441/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:52:42.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8zc6c" for this suite.
May 21 10:52:48.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:52:48.399: INFO: namespace: e2e-tests-kubectl-8zc6c, resource: bindings, ignored listing per whitelist
May 21 10:52:48.401: INFO: namespace e2e-tests-kubectl-8zc6c deletion completed in 6.062906229s

• [SLOW TEST:6.203 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:52:48.401: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 10:52:48.457: INFO: Waiting up to 5m0s for pod "downwardapi-volume-928bad5f-7bb6-11e9-be4b-6e6d88bcf118" in namespace "e2e-tests-downward-api-6vztt" to be "success or failure"
May 21 10:52:48.459: INFO: Pod "downwardapi-volume-928bad5f-7bb6-11e9-be4b-6e6d88bcf118": Phase="Pending", Reason="", readiness=false. Elapsed: 1.769688ms
May 21 10:52:50.461: INFO: Pod "downwardapi-volume-928bad5f-7bb6-11e9-be4b-6e6d88bcf118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00401746s
STEP: Saw pod success
May 21 10:52:50.461: INFO: Pod "downwardapi-volume-928bad5f-7bb6-11e9-be4b-6e6d88bcf118" satisfied condition "success or failure"
May 21 10:52:50.462: INFO: Trying to get logs from node 192.168.5.29 pod downwardapi-volume-928bad5f-7bb6-11e9-be4b-6e6d88bcf118 container client-container: <nil>
STEP: delete the pod
May 21 10:52:50.475: INFO: Waiting for pod downwardapi-volume-928bad5f-7bb6-11e9-be4b-6e6d88bcf118 to disappear
May 21 10:52:50.477: INFO: Pod downwardapi-volume-928bad5f-7bb6-11e9-be4b-6e6d88bcf118 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:52:50.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6vztt" for this suite.
May 21 10:52:56.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:52:56.516: INFO: namespace: e2e-tests-downward-api-6vztt, resource: bindings, ignored listing per whitelist
May 21 10:52:56.543: INFO: namespace e2e-tests-downward-api-6vztt deletion completed in 6.063722223s

• [SLOW TEST:8.143 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:52:56.544: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 21 10:52:56.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-dv42h'
May 21 10:52:56.687: INFO: stderr: ""
May 21 10:52:56.687: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
May 21 10:52:56.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-877789554 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-dv42h'
May 21 10:53:03.696: INFO: stderr: ""
May 21 10:53:03.696: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:53:03.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dv42h" for this suite.
May 21 10:53:09.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:53:09.739: INFO: namespace: e2e-tests-kubectl-dv42h, resource: bindings, ignored listing per whitelist
May 21 10:53:09.767: INFO: namespace e2e-tests-kubectl-dv42h deletion completed in 6.067254282s

• [SLOW TEST:13.223 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:53:09.767: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
May 21 10:53:09.812: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-4gtg8,SelfLink:/api/v1/namespaces/e2e-tests-watch-4gtg8/configmaps/e2e-watch-test-watch-closed,UID:9f47f3e8-7bb6-11e9-acff-fa163e1b1d33,ResourceVersion:19107,Generation:0,CreationTimestamp:2019-05-21 10:53:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 21 10:53:09.813: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-4gtg8,SelfLink:/api/v1/namespaces/e2e-tests-watch-4gtg8/configmaps/e2e-watch-test-watch-closed,UID:9f47f3e8-7bb6-11e9-acff-fa163e1b1d33,ResourceVersion:19108,Generation:0,CreationTimestamp:2019-05-21 10:53:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
May 21 10:53:09.820: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-4gtg8,SelfLink:/api/v1/namespaces/e2e-tests-watch-4gtg8/configmaps/e2e-watch-test-watch-closed,UID:9f47f3e8-7bb6-11e9-acff-fa163e1b1d33,ResourceVersion:19109,Generation:0,CreationTimestamp:2019-05-21 10:53:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 21 10:53:09.820: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-4gtg8,SelfLink:/api/v1/namespaces/e2e-tests-watch-4gtg8/configmaps/e2e-watch-test-watch-closed,UID:9f47f3e8-7bb6-11e9-acff-fa163e1b1d33,ResourceVersion:19110,Generation:0,CreationTimestamp:2019-05-21 10:53:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:53:09.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-4gtg8" for this suite.
May 21 10:53:15.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:53:15.861: INFO: namespace: e2e-tests-watch-4gtg8, resource: bindings, ignored listing per whitelist
May 21 10:53:15.893: INFO: namespace e2e-tests-watch-4gtg8 deletion completed in 6.069011119s

• [SLOW TEST:6.126 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
May 21 10:53:15.893: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 10:53:15.932: INFO: >>> kubeConfig: /tmp/kubeconfig-877789554
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
May 21 10:53:21.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-cgdvn" for this suite.
May 21 10:53:27.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:53:28.027: INFO: namespace: e2e-tests-custom-resource-definition-cgdvn, resource: bindings, ignored listing per whitelist
May 21 10:53:28.041: INFO: namespace e2e-tests-custom-resource-definition-cgdvn deletion completed in 6.069226816s

• [SLOW TEST:12.148 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSMay 21 10:53:28.042: INFO: Running AfterSuite actions on all node
May 21 10:53:28.043: INFO: Running AfterSuite actions on node 1
May 21 10:53:28.043: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 5201.247 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 1h26m42.174513875s
Test Suite Passed
