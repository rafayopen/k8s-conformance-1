Feb 13 13:33:20.624: INFO: Overriding default scale value of zero to 1
Feb 13 13:33:20.624: INFO: Overriding default milliseconds value of zero to 5000
I0213 13:33:21.110940      18 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-172602910
I0213 13:33:21.111038      18 e2e.go:304] Starting e2e run "eda826c4-2f93-11e9-9b61-026654d605e3" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1550064800 - Will randomize all specs
Will run 188 of 1814 specs

Feb 13 13:33:21.262: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
Feb 13 13:33:21.264: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb 13 13:33:21.302: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb 13 13:33:21.332: INFO: 15 / 15 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb 13 13:33:21.332: INFO: expected 6 pod replicas in namespace 'kube-system', 6 are Running and Ready.
Feb 13 13:33:21.332: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb 13 13:33:21.340: INFO: 6 / 6 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds' (0 seconds elapsed)
Feb 13 13:33:21.340: INFO: e2e test version: v1.12.1
Feb 13 13:33:21.341: INFO: kube-apiserver version: v1.12.4-3+680746c29c3258
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:33:21.342: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename projected
Feb 13 13:33:21.434: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 13:33:21.446: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ee306144-2f93-11e9-9b61-026654d605e3" in namespace "e2e-tests-projected-fklmb" to be "success or failure"
Feb 13 13:33:21.450: INFO: Pod "downwardapi-volume-ee306144-2f93-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.436303ms
Feb 13 13:33:23.454: INFO: Pod "downwardapi-volume-ee306144-2f93-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007916807s
Feb 13 13:33:25.459: INFO: Pod "downwardapi-volume-ee306144-2f93-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0130292s
STEP: Saw pod success
Feb 13 13:33:25.459: INFO: Pod "downwardapi-volume-ee306144-2f93-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 13:33:25.468: INFO: Trying to get logs from node cmp2 pod downwardapi-volume-ee306144-2f93-11e9-9b61-026654d605e3 container client-container: <nil>
STEP: delete the pod
Feb 13 13:33:25.495: INFO: Waiting for pod downwardapi-volume-ee306144-2f93-11e9-9b61-026654d605e3 to disappear
Feb 13 13:33:25.498: INFO: Pod downwardapi-volume-ee306144-2f93-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:33:25.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fklmb" for this suite.
Feb 13 13:33:31.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:33:31.596: INFO: namespace: e2e-tests-projected-fklmb, resource: bindings, ignored listing per whitelist
Feb 13 13:33:31.638: INFO: namespace e2e-tests-projected-fklmb deletion completed in 6.13529304s

• [SLOW TEST:10.297 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:33:31.639: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0213 13:33:41.823551      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 13 13:33:41.823: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:33:41.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-znrdd" for this suite.
Feb 13 13:33:47.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:33:47.932: INFO: namespace: e2e-tests-gc-znrdd, resource: bindings, ignored listing per whitelist
Feb 13 13:33:47.954: INFO: namespace e2e-tests-gc-znrdd deletion completed in 6.125619797s

• [SLOW TEST:16.315 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:33:47.955: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-p69bq/configmap-test-fe0db639-2f93-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume configMaps
Feb 13 13:33:48.066: INFO: Waiting up to 5m0s for pod "pod-configmaps-fe0ece5b-2f93-11e9-9b61-026654d605e3" in namespace "e2e-tests-configmap-p69bq" to be "success or failure"
Feb 13 13:33:48.069: INFO: Pod "pod-configmaps-fe0ece5b-2f93-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.788827ms
Feb 13 13:33:50.073: INFO: Pod "pod-configmaps-fe0ece5b-2f93-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006537607s
Feb 13 13:33:52.083: INFO: Pod "pod-configmaps-fe0ece5b-2f93-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016558036s
STEP: Saw pod success
Feb 13 13:33:52.083: INFO: Pod "pod-configmaps-fe0ece5b-2f93-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 13:33:52.086: INFO: Trying to get logs from node cmp3 pod pod-configmaps-fe0ece5b-2f93-11e9-9b61-026654d605e3 container env-test: <nil>
STEP: delete the pod
Feb 13 13:33:52.104: INFO: Waiting for pod pod-configmaps-fe0ece5b-2f93-11e9-9b61-026654d605e3 to disappear
Feb 13 13:33:52.108: INFO: Pod pod-configmaps-fe0ece5b-2f93-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:33:52.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-p69bq" for this suite.
Feb 13 13:33:58.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:33:58.134: INFO: namespace: e2e-tests-configmap-p69bq, resource: bindings, ignored listing per whitelist
Feb 13 13:33:58.236: INFO: namespace e2e-tests-configmap-p69bq deletion completed in 6.123487414s

• [SLOW TEST:10.281 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:33:58.236: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-042eb0dd-2f94-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume configMaps
Feb 13 13:33:58.348: INFO: Waiting up to 5m0s for pod "pod-configmaps-042fbec5-2f94-11e9-9b61-026654d605e3" in namespace "e2e-tests-configmap-9m6k5" to be "success or failure"
Feb 13 13:33:58.351: INFO: Pod "pod-configmaps-042fbec5-2f94-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.810145ms
Feb 13 13:34:00.355: INFO: Pod "pod-configmaps-042fbec5-2f94-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007075535s
STEP: Saw pod success
Feb 13 13:34:00.355: INFO: Pod "pod-configmaps-042fbec5-2f94-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 13:34:00.359: INFO: Trying to get logs from node cmp3 pod pod-configmaps-042fbec5-2f94-11e9-9b61-026654d605e3 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 13:34:00.387: INFO: Waiting for pod pod-configmaps-042fbec5-2f94-11e9-9b61-026654d605e3 to disappear
Feb 13 13:34:00.391: INFO: Pod pod-configmaps-042fbec5-2f94-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:34:00.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9m6k5" for this suite.
Feb 13 13:34:06.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:34:06.485: INFO: namespace: e2e-tests-configmap-9m6k5, resource: bindings, ignored listing per whitelist
Feb 13 13:34:06.517: INFO: namespace e2e-tests-configmap-9m6k5 deletion completed in 6.121478174s

• [SLOW TEST:8.281 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:34:06.517: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Feb 13 13:34:06.612: INFO: Waiting up to 5m0s for pod "var-expansion-091c097a-2f94-11e9-9b61-026654d605e3" in namespace "e2e-tests-var-expansion-ck4t7" to be "success or failure"
Feb 13 13:34:06.616: INFO: Pod "var-expansion-091c097a-2f94-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.518169ms
Feb 13 13:34:08.620: INFO: Pod "var-expansion-091c097a-2f94-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007924558s
STEP: Saw pod success
Feb 13 13:34:08.621: INFO: Pod "var-expansion-091c097a-2f94-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 13:34:08.624: INFO: Trying to get logs from node cmp3 pod var-expansion-091c097a-2f94-11e9-9b61-026654d605e3 container dapi-container: <nil>
STEP: delete the pod
Feb 13 13:34:08.641: INFO: Waiting for pod var-expansion-091c097a-2f94-11e9-9b61-026654d605e3 to disappear
Feb 13 13:34:08.644: INFO: Pod var-expansion-091c097a-2f94-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:34:08.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-ck4t7" for this suite.
Feb 13 13:34:14.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:34:14.738: INFO: namespace: e2e-tests-var-expansion-ck4t7, resource: bindings, ignored listing per whitelist
Feb 13 13:34:14.778: INFO: namespace e2e-tests-var-expansion-ck4t7 deletion completed in 6.129441914s

• [SLOW TEST:8.261 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:34:14.779: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-0e09fe85-2f94-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume configMaps
Feb 13 13:34:14.887: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0e0b26a3-2f94-11e9-9b61-026654d605e3" in namespace "e2e-tests-projected-lsk2v" to be "success or failure"
Feb 13 13:34:14.890: INFO: Pod "pod-projected-configmaps-0e0b26a3-2f94-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.819816ms
Feb 13 13:34:16.894: INFO: Pod "pod-projected-configmaps-0e0b26a3-2f94-11e9-9b61-026654d605e3": Phase="Running", Reason="", readiness=true. Elapsed: 2.006591606s
Feb 13 13:34:18.898: INFO: Pod "pod-projected-configmaps-0e0b26a3-2f94-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011121716s
STEP: Saw pod success
Feb 13 13:34:18.898: INFO: Pod "pod-projected-configmaps-0e0b26a3-2f94-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 13:34:18.901: INFO: Trying to get logs from node cmp3 pod pod-projected-configmaps-0e0b26a3-2f94-11e9-9b61-026654d605e3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 13:34:18.922: INFO: Waiting for pod pod-projected-configmaps-0e0b26a3-2f94-11e9-9b61-026654d605e3 to disappear
Feb 13 13:34:18.925: INFO: Pod pod-projected-configmaps-0e0b26a3-2f94-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:34:18.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lsk2v" for this suite.
Feb 13 13:34:24.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:34:25.011: INFO: namespace: e2e-tests-projected-lsk2v, resource: bindings, ignored listing per whitelist
Feb 13 13:34:25.070: INFO: namespace e2e-tests-projected-lsk2v deletion completed in 6.140697777s

• [SLOW TEST:10.291 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:34:25.070: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-142c0a9e-2f94-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume secrets
Feb 13 13:34:25.177: INFO: Waiting up to 5m0s for pod "pod-secrets-142d7aee-2f94-11e9-9b61-026654d605e3" in namespace "e2e-tests-secrets-kfd9w" to be "success or failure"
Feb 13 13:34:25.180: INFO: Pod "pod-secrets-142d7aee-2f94-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.829039ms
Feb 13 13:34:27.185: INFO: Pod "pod-secrets-142d7aee-2f94-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007703111s
Feb 13 13:34:29.189: INFO: Pod "pod-secrets-142d7aee-2f94-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011760631s
STEP: Saw pod success
Feb 13 13:34:29.189: INFO: Pod "pod-secrets-142d7aee-2f94-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 13:34:29.192: INFO: Trying to get logs from node cmp3 pod pod-secrets-142d7aee-2f94-11e9-9b61-026654d605e3 container secret-volume-test: <nil>
STEP: delete the pod
Feb 13 13:34:29.210: INFO: Waiting for pod pod-secrets-142d7aee-2f94-11e9-9b61-026654d605e3 to disappear
Feb 13 13:34:29.213: INFO: Pod pod-secrets-142d7aee-2f94-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:34:29.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-kfd9w" for this suite.
Feb 13 13:34:35.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:34:35.276: INFO: namespace: e2e-tests-secrets-kfd9w, resource: bindings, ignored listing per whitelist
Feb 13 13:34:35.341: INFO: namespace e2e-tests-secrets-kfd9w deletion completed in 6.12397762s

• [SLOW TEST:10.271 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:34:35.341: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 13:34:35.443: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1a4b4fb2-2f94-11e9-9b61-026654d605e3" in namespace "e2e-tests-projected-6l89l" to be "success or failure"
Feb 13 13:34:35.446: INFO: Pod "downwardapi-volume-1a4b4fb2-2f94-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.113721ms
Feb 13 13:34:37.451: INFO: Pod "downwardapi-volume-1a4b4fb2-2f94-11e9-9b61-026654d605e3": Phase="Running", Reason="", readiness=true. Elapsed: 2.007811213s
Feb 13 13:34:39.455: INFO: Pod "downwardapi-volume-1a4b4fb2-2f94-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012172299s
STEP: Saw pod success
Feb 13 13:34:39.455: INFO: Pod "downwardapi-volume-1a4b4fb2-2f94-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 13:34:39.459: INFO: Trying to get logs from node cmp3 pod downwardapi-volume-1a4b4fb2-2f94-11e9-9b61-026654d605e3 container client-container: <nil>
STEP: delete the pod
Feb 13 13:34:39.479: INFO: Waiting for pod downwardapi-volume-1a4b4fb2-2f94-11e9-9b61-026654d605e3 to disappear
Feb 13 13:34:39.482: INFO: Pod downwardapi-volume-1a4b4fb2-2f94-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:34:39.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6l89l" for this suite.
Feb 13 13:34:45.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:34:45.574: INFO: namespace: e2e-tests-projected-6l89l, resource: bindings, ignored listing per whitelist
Feb 13 13:34:45.610: INFO: namespace e2e-tests-projected-6l89l deletion completed in 6.123148959s

• [SLOW TEST:10.268 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:34:45.610: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 13:34:45.711: INFO: Waiting up to 5m0s for pod "downwardapi-volume-206a4f8e-2f94-11e9-9b61-026654d605e3" in namespace "e2e-tests-projected-jmgfw" to be "success or failure"
Feb 13 13:34:45.716: INFO: Pod "downwardapi-volume-206a4f8e-2f94-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.195551ms
Feb 13 13:34:47.720: INFO: Pod "downwardapi-volume-206a4f8e-2f94-11e9-9b61-026654d605e3": Phase="Running", Reason="", readiness=true. Elapsed: 2.008824105s
Feb 13 13:34:49.725: INFO: Pod "downwardapi-volume-206a4f8e-2f94-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013241211s
STEP: Saw pod success
Feb 13 13:34:49.725: INFO: Pod "downwardapi-volume-206a4f8e-2f94-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 13:34:49.728: INFO: Trying to get logs from node cmp3 pod downwardapi-volume-206a4f8e-2f94-11e9-9b61-026654d605e3 container client-container: <nil>
STEP: delete the pod
Feb 13 13:34:49.749: INFO: Waiting for pod downwardapi-volume-206a4f8e-2f94-11e9-9b61-026654d605e3 to disappear
Feb 13 13:34:49.753: INFO: Pod downwardapi-volume-206a4f8e-2f94-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:34:49.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jmgfw" for this suite.
Feb 13 13:34:55.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:34:55.855: INFO: namespace: e2e-tests-projected-jmgfw, resource: bindings, ignored listing per whitelist
Feb 13 13:34:55.881: INFO: namespace e2e-tests-projected-jmgfw deletion completed in 6.12296478s

• [SLOW TEST:10.271 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:34:55.881: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-268aa868-2f94-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume secrets
Feb 13 13:34:55.994: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-268bb649-2f94-11e9-9b61-026654d605e3" in namespace "e2e-tests-projected-nqjw9" to be "success or failure"
Feb 13 13:34:55.996: INFO: Pod "pod-projected-secrets-268bb649-2f94-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.522891ms
Feb 13 13:34:58.001: INFO: Pod "pod-projected-secrets-268bb649-2f94-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00732914s
Feb 13 13:35:00.006: INFO: Pod "pod-projected-secrets-268bb649-2f94-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012205209s
STEP: Saw pod success
Feb 13 13:35:00.006: INFO: Pod "pod-projected-secrets-268bb649-2f94-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 13:35:00.010: INFO: Trying to get logs from node cmp3 pod pod-projected-secrets-268bb649-2f94-11e9-9b61-026654d605e3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 13 13:35:00.031: INFO: Waiting for pod pod-projected-secrets-268bb649-2f94-11e9-9b61-026654d605e3 to disappear
Feb 13 13:35:00.034: INFO: Pod pod-projected-secrets-268bb649-2f94-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:35:00.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nqjw9" for this suite.
Feb 13 13:35:06.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:35:06.114: INFO: namespace: e2e-tests-projected-nqjw9, resource: bindings, ignored listing per whitelist
Feb 13 13:35:06.179: INFO: namespace e2e-tests-projected-nqjw9 deletion completed in 6.139816301s

• [SLOW TEST:10.298 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:35:06.180: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-2cad21d3-2f94-11e9-9b61-026654d605e3
STEP: Creating configMap with name cm-test-opt-upd-2cad221d-2f94-11e9-9b61-026654d605e3
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-2cad21d3-2f94-11e9-9b61-026654d605e3
STEP: Updating configmap cm-test-opt-upd-2cad221d-2f94-11e9-9b61-026654d605e3
STEP: Creating configMap with name cm-test-opt-create-2cad22d9-2f94-11e9-9b61-026654d605e3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:36:12.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-p4gbx" for this suite.
Feb 13 13:36:34.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:36:34.960: INFO: namespace: e2e-tests-configmap-p4gbx, resource: bindings, ignored listing per whitelist
Feb 13 13:36:35.003: INFO: namespace e2e-tests-configmap-p4gbx deletion completed in 22.121380594s

• [SLOW TEST:88.823 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:36:35.004: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-p8jhl
Feb 13 13:36:39.113: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-p8jhl
STEP: checking the pod's current state and verifying that restartCount is present
Feb 13 13:36:39.116: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:40:39.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-p8jhl" for this suite.
Feb 13 13:40:45.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:40:45.859: INFO: namespace: e2e-tests-container-probe-p8jhl, resource: bindings, ignored listing per whitelist
Feb 13 13:40:45.954: INFO: namespace e2e-tests-container-probe-p8jhl deletion completed in 6.130768477s

• [SLOW TEST:250.951 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:40:45.956: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 13:40:46.060: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f732f463-2f94-11e9-9b61-026654d605e3" in namespace "e2e-tests-downward-api-r9tnd" to be "success or failure"
Feb 13 13:40:46.063: INFO: Pod "downwardapi-volume-f732f463-2f94-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.096926ms
Feb 13 13:40:48.074: INFO: Pod "downwardapi-volume-f732f463-2f94-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013895354s
Feb 13 13:40:50.078: INFO: Pod "downwardapi-volume-f732f463-2f94-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017875227s
STEP: Saw pod success
Feb 13 13:40:50.078: INFO: Pod "downwardapi-volume-f732f463-2f94-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 13:40:50.081: INFO: Trying to get logs from node cmp3 pod downwardapi-volume-f732f463-2f94-11e9-9b61-026654d605e3 container client-container: <nil>
STEP: delete the pod
Feb 13 13:40:50.110: INFO: Waiting for pod downwardapi-volume-f732f463-2f94-11e9-9b61-026654d605e3 to disappear
Feb 13 13:40:50.113: INFO: Pod downwardapi-volume-f732f463-2f94-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:40:50.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-r9tnd" for this suite.
Feb 13 13:40:56.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:40:56.178: INFO: namespace: e2e-tests-downward-api-r9tnd, resource: bindings, ignored listing per whitelist
Feb 13 13:40:56.248: INFO: namespace e2e-tests-downward-api-r9tnd deletion completed in 6.127720462s

• [SLOW TEST:10.292 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:40:56.249: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 13 13:40:56.338: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:41:00.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-zk9rz" for this suite.
Feb 13 13:41:06.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:41:06.692: INFO: namespace: e2e-tests-init-container-zk9rz, resource: bindings, ignored listing per whitelist
Feb 13 13:41:06.735: INFO: namespace e2e-tests-init-container-zk9rz deletion completed in 6.121751111s

• [SLOW TEST:10.486 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:41:06.735: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-96wkn
Feb 13 13:41:10.847: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-96wkn
STEP: checking the pod's current state and verifying that restartCount is present
Feb 13 13:41:10.850: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:45:11.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-96wkn" for this suite.
Feb 13 13:45:17.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:45:17.624: INFO: namespace: e2e-tests-container-probe-96wkn, resource: bindings, ignored listing per whitelist
Feb 13 13:45:17.697: INFO: namespace e2e-tests-container-probe-96wkn deletion completed in 6.124585118s

• [SLOW TEST:250.962 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:45:17.697: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Feb 13 13:45:21.829: INFO: Pod pod-hostip-992b7aa2-2f95-11e9-9b61-026654d605e3 has hostIP: 10.11.1.3
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:45:21.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-tmbp4" for this suite.
Feb 13 13:45:43.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:45:43.919: INFO: namespace: e2e-tests-pods-tmbp4, resource: bindings, ignored listing per whitelist
Feb 13 13:45:43.971: INFO: namespace e2e-tests-pods-tmbp4 deletion completed in 22.133705485s

• [SLOW TEST:26.274 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:45:43.972: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 13:45:44.076: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a8d4be09-2f95-11e9-9b61-026654d605e3" in namespace "e2e-tests-projected-5czqb" to be "success or failure"
Feb 13 13:45:44.079: INFO: Pod "downwardapi-volume-a8d4be09-2f95-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.970147ms
Feb 13 13:45:46.084: INFO: Pod "downwardapi-volume-a8d4be09-2f95-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00733771s
STEP: Saw pod success
Feb 13 13:45:46.084: INFO: Pod "downwardapi-volume-a8d4be09-2f95-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 13:45:46.087: INFO: Trying to get logs from node cmp3 pod downwardapi-volume-a8d4be09-2f95-11e9-9b61-026654d605e3 container client-container: <nil>
STEP: delete the pod
Feb 13 13:45:46.106: INFO: Waiting for pod downwardapi-volume-a8d4be09-2f95-11e9-9b61-026654d605e3 to disappear
Feb 13 13:45:46.108: INFO: Pod downwardapi-volume-a8d4be09-2f95-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:45:46.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5czqb" for this suite.
Feb 13 13:45:52.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:45:52.157: INFO: namespace: e2e-tests-projected-5czqb, resource: bindings, ignored listing per whitelist
Feb 13 13:45:52.232: INFO: namespace e2e-tests-projected-5czqb deletion completed in 6.118788593s

• [SLOW TEST:8.260 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:45:52.232: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Feb 13 13:45:52.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 create -f - --namespace=e2e-tests-kubectl-s4cgl'
Feb 13 13:45:52.714: INFO: stderr: ""
Feb 13 13:45:52.714: INFO: stdout: "pod/pause created\n"
Feb 13 13:45:52.714: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb 13 13:45:52.714: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-s4cgl" to be "running and ready"
Feb 13 13:45:52.719: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.468542ms
Feb 13 13:45:54.729: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015172584s
Feb 13 13:45:56.733: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.019358345s
Feb 13 13:45:56.733: INFO: Pod "pause" satisfied condition "running and ready"
Feb 13 13:45:56.733: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Feb 13 13:45:56.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-s4cgl'
Feb 13 13:45:56.874: INFO: stderr: ""
Feb 13 13:45:56.874: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb 13 13:45:56.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pod pause -L testing-label --namespace=e2e-tests-kubectl-s4cgl'
Feb 13 13:45:56.988: INFO: stderr: ""
Feb 13 13:45:56.988: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb 13 13:45:56.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 label pods pause testing-label- --namespace=e2e-tests-kubectl-s4cgl'
Feb 13 13:45:57.120: INFO: stderr: ""
Feb 13 13:45:57.120: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb 13 13:45:57.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pod pause -L testing-label --namespace=e2e-tests-kubectl-s4cgl'
Feb 13 13:45:57.236: INFO: stderr: ""
Feb 13 13:45:57.236: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Feb 13 13:45:57.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-s4cgl'
Feb 13 13:45:57.363: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 13:45:57.363: INFO: stdout: "pod \"pause\" force deleted\n"
Feb 13 13:45:57.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-s4cgl'
Feb 13 13:45:57.503: INFO: stderr: "No resources found.\n"
Feb 13 13:45:57.503: INFO: stdout: ""
Feb 13 13:45:57.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods -l name=pause --namespace=e2e-tests-kubectl-s4cgl -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 13 13:45:57.626: INFO: stderr: ""
Feb 13 13:45:57.627: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:45:57.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-s4cgl" for this suite.
Feb 13 13:46:03.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:46:03.672: INFO: namespace: e2e-tests-kubectl-s4cgl, resource: bindings, ignored listing per whitelist
Feb 13 13:46:03.752: INFO: namespace e2e-tests-kubectl-s4cgl deletion completed in 6.119782687s

• [SLOW TEST:11.520 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:46:03.752: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0213 13:46:09.881631      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 13 13:46:09.881: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:46:09.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-szpxz" for this suite.
Feb 13 13:46:15.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:46:15.971: INFO: namespace: e2e-tests-gc-szpxz, resource: bindings, ignored listing per whitelist
Feb 13 13:46:16.013: INFO: namespace e2e-tests-gc-szpxz deletion completed in 6.12773782s

• [SLOW TEST:12.261 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:46:16.014: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-s7cds
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 13 13:46:16.110: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 13 13:46:36.197: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://192.168.119.215:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-s7cds PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 13:46:36.197: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
Feb 13 13:46:36.456: INFO: Found all expected endpoints: [netserver-0]
Feb 13 13:46:36.460: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://192.168.113.65:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-s7cds PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 13:46:36.460: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
Feb 13 13:46:36.801: INFO: Found all expected endpoints: [netserver-1]
Feb 13 13:46:36.805: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://192.168.196.218:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-s7cds PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 13:46:36.805: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
Feb 13 13:46:37.036: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:46:37.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-s7cds" for this suite.
Feb 13 13:46:59.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:46:59.149: INFO: namespace: e2e-tests-pod-network-test-s7cds, resource: bindings, ignored listing per whitelist
Feb 13 13:46:59.162: INFO: namespace e2e-tests-pod-network-test-s7cds deletion completed in 22.120722716s

• [SLOW TEST:43.148 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:46:59.162: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 13:46:59.253: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb 13 13:46:59.264: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb 13 13:47:04.268: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 13 13:47:04.268: INFO: Creating deployment "test-rolling-update-deployment"
Feb 13 13:47:04.273: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb 13 13:47:04.280: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Feb 13 13:47:06.293: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb 13 13:47:06.296: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 13 13:47:06.306: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-ln5vb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ln5vb/deployments/test-rolling-update-deployment,UID:d8a39c8d-2f95-11e9-85f4-fa163e429998,ResourceVersion:2505302,Generation:1,CreationTimestamp:2019-02-13 13:47:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-13 13:47:04 +0000 UTC 2019-02-13 13:47:04 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-13 13:47:05 +0000 UTC 2019-02-13 13:47:04 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 13 13:47:06.310: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-ln5vb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ln5vb/replicasets/test-rolling-update-deployment-65b7695dcf,UID:d8a57931-2f95-11e9-b579-fa163ed32deb,ResourceVersion:2505293,Generation:1,CreationTimestamp:2019-02-13 13:47:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment d8a39c8d-2f95-11e9-85f4-fa163e429998 0xc42104b4b7 0xc42104b4b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 13 13:47:06.310: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb 13 13:47:06.310: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-ln5vb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ln5vb/replicasets/test-rolling-update-controller,UID:d5a660ef-2f95-11e9-85f4-fa163e429998,ResourceVersion:2505301,Generation:2,CreationTimestamp:2019-02-13 13:46:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment d8a39c8d-2f95-11e9-85f4-fa163e429998 0xc42104b3ee 0xc42104b3ef}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 13 13:47:06.314: INFO: Pod "test-rolling-update-deployment-65b7695dcf-nmhnt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-nmhnt,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-ln5vb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ln5vb/pods/test-rolling-update-deployment-65b7695dcf-nmhnt,UID:d8a62fb8-2f95-11e9-b579-fa163ed32deb,ResourceVersion:2505292,Generation:0,CreationTimestamp:2019-02-13 13:47:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf d8a57931-2f95-11e9-b579-fa163ed32deb 0xc42104bd27 0xc42104bd28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lfg9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lfg9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-lfg9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cmp1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42104bda0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42104bdc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:04 +0000 UTC  }],Message:,Reason:,HostIP:10.11.1.1,PodIP:192.168.196.253,StartTime:2019-02-13 13:47:04 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-13 13:47:05 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://ca325936e212c317a51f804a26b5190eba835ff8898616d5a78730a798d8317e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:47:06.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-ln5vb" for this suite.
Feb 13 13:47:12.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:47:12.386: INFO: namespace: e2e-tests-deployment-ln5vb, resource: bindings, ignored listing per whitelist
Feb 13 13:47:12.456: INFO: namespace e2e-tests-deployment-ln5vb deletion completed in 6.137451553s

• [SLOW TEST:13.294 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:47:12.456: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 13:47:12.550: INFO: Creating deployment "nginx-deployment"
Feb 13 13:47:12.558: INFO: Waiting for observed generation 1
Feb 13 13:47:14.568: INFO: Waiting for all required pods to come up
Feb 13 13:47:14.587: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb 13 13:47:20.604: INFO: Waiting for deployment "nginx-deployment" to complete
Feb 13 13:47:20.610: INFO: Updating deployment "nginx-deployment" with a non-existent image
Feb 13 13:47:20.619: INFO: Updating deployment nginx-deployment
Feb 13 13:47:20.619: INFO: Waiting for observed generation 2
Feb 13 13:47:22.630: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb 13 13:47:22.634: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb 13 13:47:22.637: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 13 13:47:22.648: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb 13 13:47:22.648: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb 13 13:47:22.651: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 13 13:47:22.658: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Feb 13 13:47:22.658: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Feb 13 13:47:22.666: INFO: Updating deployment nginx-deployment
Feb 13 13:47:22.666: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Feb 13 13:47:22.674: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb 13 13:47:22.677: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 13 13:47:22.686: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-z6vmn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-z6vmn/deployments/nginx-deployment,UID:dd93440e-2f95-11e9-85f4-fa163e429998,ResourceVersion:2505602,Generation:3,CreationTimestamp:2019-02-13 13:47:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Available True 2019-02-13 13:47:18 +0000 UTC 2019-02-13 13:47:18 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-13 13:47:20 +0000 UTC 2019-02-13 13:47:12 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Feb 13 13:47:22.697: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-z6vmn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-z6vmn/replicasets/nginx-deployment-7dc8f79789,UID:e2617d5a-2f95-11e9-b579-fa163ed32deb,ResourceVersion:2505606,Generation:3,CreationTimestamp:2019-02-13 13:47:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment dd93440e-2f95-11e9-85f4-fa163e429998 0xc4228aa1e7 0xc4228aa1e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 13 13:47:22.697: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Feb 13 13:47:22.697: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-z6vmn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-z6vmn/replicasets/nginx-deployment-7f9675fb8b,UID:dd935c30-2f95-11e9-b579-fa163ed32deb,ResourceVersion:2505603,Generation:3,CreationTimestamp:2019-02-13 13:47:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment dd93440e-2f95-11e9-85f4-fa163e429998 0xc4228aa2a7 0xc4228aa2a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Feb 13 13:47:22.715: INFO: Pod "nginx-deployment-7dc8f79789-4jphq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-4jphq,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-z6vmn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z6vmn/pods/nginx-deployment-7dc8f79789-4jphq,UID:e39bf1f5-2f95-11e9-b579-fa163ed32deb,ResourceVersion:2505617,Generation:0,CreationTimestamp:2019-02-13 13:47:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 e2617d5a-2f95-11e9-b579-fa163ed32deb 0xc421dc3f00 0xc421dc3f01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lgd5q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lgd5q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lgd5q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cmp1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421dc3f80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421dc3fa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:22 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 13:47:22.716: INFO: Pod "nginx-deployment-7dc8f79789-6mxp8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-6mxp8,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-z6vmn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z6vmn/pods/nginx-deployment-7dc8f79789-6mxp8,UID:e2683cc4-2f95-11e9-b579-fa163ed32deb,ResourceVersion:2505577,Generation:0,CreationTimestamp:2019-02-13 13:47:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 e2617d5a-2f95-11e9-b579-fa163ed32deb 0xc421ab4017 0xc421ab4018}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lgd5q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lgd5q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lgd5q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cmp2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421ab4090} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421ab40b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:20 +0000 UTC  }],Message:,Reason:,HostIP:10.11.1.2,PodIP:,StartTime:2019-02-13 13:47:20 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 13:47:22.716: INFO: Pod "nginx-deployment-7dc8f79789-b8rpn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-b8rpn,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-z6vmn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z6vmn/pods/nginx-deployment-7dc8f79789-b8rpn,UID:e39cec0d-2f95-11e9-b579-fa163ed32deb,ResourceVersion:2505615,Generation:0,CreationTimestamp:2019-02-13 13:47:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 e2617d5a-2f95-11e9-b579-fa163ed32deb 0xc421ab4170 0xc421ab4171}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lgd5q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lgd5q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lgd5q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421ab41e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421ab4200}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 13:47:22.716: INFO: Pod "nginx-deployment-7dc8f79789-j9n8m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-j9n8m,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-z6vmn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z6vmn/pods/nginx-deployment-7dc8f79789-j9n8m,UID:e263814a-2f95-11e9-b579-fa163ed32deb,ResourceVersion:2505574,Generation:0,CreationTimestamp:2019-02-13 13:47:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 e2617d5a-2f95-11e9-b579-fa163ed32deb 0xc421ab4260 0xc421ab4261}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lgd5q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lgd5q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lgd5q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cmp3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421ab42e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421ab4300}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:20 +0000 UTC  }],Message:,Reason:,HostIP:10.11.1.3,PodIP:,StartTime:2019-02-13 13:47:20 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 13:47:22.716: INFO: Pod "nginx-deployment-7dc8f79789-knlzk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-knlzk,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-z6vmn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z6vmn/pods/nginx-deployment-7dc8f79789-knlzk,UID:e2635fec-2f95-11e9-b579-fa163ed32deb,ResourceVersion:2505559,Generation:0,CreationTimestamp:2019-02-13 13:47:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 e2617d5a-2f95-11e9-b579-fa163ed32deb 0xc421ab43c0 0xc421ab43c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lgd5q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lgd5q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lgd5q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cmp1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421ab4440} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421ab4460}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:20 +0000 UTC  }],Message:,Reason:,HostIP:10.11.1.1,PodIP:,StartTime:2019-02-13 13:47:20 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 13:47:22.716: INFO: Pod "nginx-deployment-7dc8f79789-phxqp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-phxqp,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-z6vmn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z6vmn/pods/nginx-deployment-7dc8f79789-phxqp,UID:e2694221-2f95-11e9-b579-fa163ed32deb,ResourceVersion:2505578,Generation:0,CreationTimestamp:2019-02-13 13:47:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 e2617d5a-2f95-11e9-b579-fa163ed32deb 0xc421ab4520 0xc421ab4521}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lgd5q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lgd5q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lgd5q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cmp3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421ab45a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421ab45c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:20 +0000 UTC  }],Message:,Reason:,HostIP:10.11.1.3,PodIP:,StartTime:2019-02-13 13:47:20 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 13:47:22.717: INFO: Pod "nginx-deployment-7dc8f79789-spc2x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-spc2x,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-z6vmn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z6vmn/pods/nginx-deployment-7dc8f79789-spc2x,UID:e2624332-2f95-11e9-b579-fa163ed32deb,ResourceVersion:2505561,Generation:0,CreationTimestamp:2019-02-13 13:47:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 e2617d5a-2f95-11e9-b579-fa163ed32deb 0xc421ab4680 0xc421ab4681}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lgd5q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lgd5q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lgd5q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cmp2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421ab4700} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421ab4720}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:20 +0000 UTC  }],Message:,Reason:,HostIP:10.11.1.2,PodIP:,StartTime:2019-02-13 13:47:20 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 13:47:22.717: INFO: Pod "nginx-deployment-7dc8f79789-zgxvn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-zgxvn,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-z6vmn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z6vmn/pods/nginx-deployment-7dc8f79789-zgxvn,UID:e39cde92-2f95-11e9-b579-fa163ed32deb,ResourceVersion:2505614,Generation:0,CreationTimestamp:2019-02-13 13:47:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 e2617d5a-2f95-11e9-b579-fa163ed32deb 0xc421ab47e0 0xc421ab47e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lgd5q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lgd5q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lgd5q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421ab4850} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421ab4870}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 13:47:22.717: INFO: Pod "nginx-deployment-7f9675fb8b-2dvnx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-2dvnx,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z6vmn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z6vmn/pods/nginx-deployment-7f9675fb8b-2dvnx,UID:dd9a0125-2f95-11e9-b579-fa163ed32deb,ResourceVersion:2505483,Generation:0,CreationTimestamp:2019-02-13 13:47:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b dd935c30-2f95-11e9-b579-fa163ed32deb 0xc421ab48d0 0xc421ab48d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lgd5q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lgd5q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lgd5q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cmp2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421ab4940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421ab4960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:12 +0000 UTC  }],Message:,Reason:,HostIP:10.11.1.2,PodIP:192.168.119.200,StartTime:2019-02-13 13:47:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-13 13:47:16 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://87862e88bc3e5e9da9e9bda5fd0fd3d7b09efec37b1baea8291997dcf4338d9d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 13:47:22.717: INFO: Pod "nginx-deployment-7f9675fb8b-4r99l" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-4r99l,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z6vmn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z6vmn/pods/nginx-deployment-7f9675fb8b-4r99l,UID:dd97411f-2f95-11e9-b579-fa163ed32deb,ResourceVersion:2505513,Generation:0,CreationTimestamp:2019-02-13 13:47:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b dd935c30-2f95-11e9-b579-fa163ed32deb 0xc421ab4a27 0xc421ab4a28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lgd5q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lgd5q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lgd5q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cmp1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421ab4aa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421ab4ac0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:18 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:18 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:12 +0000 UTC  }],Message:,Reason:,HostIP:10.11.1.1,PodIP:192.168.196.207,StartTime:2019-02-13 13:47:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-13 13:47:17 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://327697a2f18165ddc248e84d6db110e9dac17e578c50969f63d69d646d9cc531}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 13:47:22.717: INFO: Pod "nginx-deployment-7f9675fb8b-55dp6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-55dp6,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z6vmn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z6vmn/pods/nginx-deployment-7f9675fb8b-55dp6,UID:dd976a5c-2f95-11e9-b579-fa163ed32deb,ResourceVersion:2505478,Generation:0,CreationTimestamp:2019-02-13 13:47:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b dd935c30-2f95-11e9-b579-fa163ed32deb 0xc421ab4b87 0xc421ab4b88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lgd5q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lgd5q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lgd5q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cmp2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421ab4c00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421ab4c20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:12 +0000 UTC  }],Message:,Reason:,HostIP:10.11.1.2,PodIP:192.168.119.247,StartTime:2019-02-13 13:47:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-13 13:47:16 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://99c048fb4c33ea079f8b5a0d4f2d0869f9f750213aaf5fb3c56e881f2fed94e9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 13:47:22.717: INFO: Pod "nginx-deployment-7f9675fb8b-8hhmz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-8hhmz,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z6vmn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z6vmn/pods/nginx-deployment-7f9675fb8b-8hhmz,UID:dd98951c-2f95-11e9-b579-fa163ed32deb,ResourceVersion:2505480,Generation:0,CreationTimestamp:2019-02-13 13:47:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b dd935c30-2f95-11e9-b579-fa163ed32deb 0xc421ab4ce7 0xc421ab4ce8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lgd5q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lgd5q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lgd5q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cmp2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421ab4d60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421ab4d80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:12 +0000 UTC  }],Message:,Reason:,HostIP:10.11.1.2,PodIP:192.168.119.224,StartTime:2019-02-13 13:47:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-13 13:47:16 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://64c318ec1dd5472bfdcdd3a92205d1179354323d92ff643e90d4ad2cfb175d25}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 13:47:22.717: INFO: Pod "nginx-deployment-7f9675fb8b-f95xr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-f95xr,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z6vmn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z6vmn/pods/nginx-deployment-7f9675fb8b-f95xr,UID:e39cbc03-2f95-11e9-b579-fa163ed32deb,ResourceVersion:2505619,Generation:0,CreationTimestamp:2019-02-13 13:47:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b dd935c30-2f95-11e9-b579-fa163ed32deb 0xc421ab4e47 0xc421ab4e48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lgd5q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lgd5q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lgd5q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cmp1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421ab4ec0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421ab4ee0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:22 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 13:47:22.718: INFO: Pod "nginx-deployment-7f9675fb8b-gm4zf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-gm4zf,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z6vmn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z6vmn/pods/nginx-deployment-7f9675fb8b-gm4zf,UID:dd9a14c4-2f95-11e9-b579-fa163ed32deb,ResourceVersion:2505499,Generation:0,CreationTimestamp:2019-02-13 13:47:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b dd935c30-2f95-11e9-b579-fa163ed32deb 0xc421ab4f57 0xc421ab4f58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lgd5q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lgd5q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lgd5q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cmp3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421ab4fd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421ab4ff0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:12 +0000 UTC  }],Message:,Reason:,HostIP:10.11.1.3,PodIP:192.168.113.68,StartTime:2019-02-13 13:47:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-13 13:47:17 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://084020b923972c614568092f01852d744cf78599aa9b0fbf55151f6b4c87eeb4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 13:47:22.718: INFO: Pod "nginx-deployment-7f9675fb8b-jnlfc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-jnlfc,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z6vmn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z6vmn/pods/nginx-deployment-7f9675fb8b-jnlfc,UID:dd98794d-2f95-11e9-b579-fa163ed32deb,ResourceVersion:2505493,Generation:0,CreationTimestamp:2019-02-13 13:47:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b dd935c30-2f95-11e9-b579-fa163ed32deb 0xc421ab50b7 0xc421ab50b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lgd5q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lgd5q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lgd5q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cmp3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421ab5130} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421ab5150}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:12 +0000 UTC  }],Message:,Reason:,HostIP:10.11.1.3,PodIP:192.168.113.69,StartTime:2019-02-13 13:47:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-13 13:47:17 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://cfd5a11d5acacc8e78b6a38e613891e6426fafa437714f0819c9ef6cfee36a00}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 13:47:22.718: INFO: Pod "nginx-deployment-7f9675fb8b-lczc5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-lczc5,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z6vmn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z6vmn/pods/nginx-deployment-7f9675fb8b-lczc5,UID:e39bec4a-2f95-11e9-b579-fa163ed32deb,ResourceVersion:2505612,Generation:0,CreationTimestamp:2019-02-13 13:47:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b dd935c30-2f95-11e9-b579-fa163ed32deb 0xc421ab5217 0xc421ab5218}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lgd5q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lgd5q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lgd5q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cmp1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421ab5290} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421ab52b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:22 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 13:47:22.718: INFO: Pod "nginx-deployment-7f9675fb8b-td5nw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-td5nw,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z6vmn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z6vmn/pods/nginx-deployment-7f9675fb8b-td5nw,UID:dd99e650-2f95-11e9-b579-fa163ed32deb,ResourceVersion:2505520,Generation:0,CreationTimestamp:2019-02-13 13:47:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b dd935c30-2f95-11e9-b579-fa163ed32deb 0xc421ab5327 0xc421ab5328}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lgd5q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lgd5q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lgd5q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cmp1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421ab53a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421ab53c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:18 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:18 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:12 +0000 UTC  }],Message:,Reason:,HostIP:10.11.1.1,PodIP:192.168.196.232,StartTime:2019-02-13 13:47:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-13 13:47:17 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://aa9d1a4904bf8be7dc3225b807444236c3615df1a215c26a17f5f9651b155db4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 13:47:22.718: INFO: Pod "nginx-deployment-7f9675fb8b-tt2nd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-tt2nd,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z6vmn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z6vmn/pods/nginx-deployment-7f9675fb8b-tt2nd,UID:e39cd837-2f95-11e9-b579-fa163ed32deb,ResourceVersion:2505613,Generation:0,CreationTimestamp:2019-02-13 13:47:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b dd935c30-2f95-11e9-b579-fa163ed32deb 0xc421ab5487 0xc421ab5488}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lgd5q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lgd5q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lgd5q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421ab54f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421ab5510}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 13:47:22.718: INFO: Pod "nginx-deployment-7f9675fb8b-xgmb9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-xgmb9,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z6vmn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z6vmn/pods/nginx-deployment-7f9675fb8b-xgmb9,UID:dd96852d-2f95-11e9-b579-fa163ed32deb,ResourceVersion:2505496,Generation:0,CreationTimestamp:2019-02-13 13:47:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b dd935c30-2f95-11e9-b579-fa163ed32deb 0xc421ab5570 0xc421ab5571}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lgd5q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lgd5q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lgd5q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cmp3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421ab55e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421ab5600}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 13:47:12 +0000 UTC  }],Message:,Reason:,HostIP:10.11.1.3,PodIP:192.168.113.70,StartTime:2019-02-13 13:47:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-13 13:47:17 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://e8c704fd16a7a9ee9c09a95f221a578f30a443b106833ffa902c2341480d8366}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:47:22.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-z6vmn" for this suite.
Feb 13 13:47:30.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:47:30.828: INFO: namespace: e2e-tests-deployment-z6vmn, resource: bindings, ignored listing per whitelist
Feb 13 13:47:30.869: INFO: namespace e2e-tests-deployment-z6vmn deletion completed in 8.136708782s

• [SLOW TEST:18.413 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:47:30.869: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 13 13:47:30.965: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:47:40.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-vqf9f" for this suite.
Feb 13 13:48:02.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:48:02.925: INFO: namespace: e2e-tests-init-container-vqf9f, resource: bindings, ignored listing per whitelist
Feb 13 13:48:02.967: INFO: namespace e2e-tests-init-container-vqf9f deletion completed in 22.131299684s

• [SLOW TEST:32.098 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:48:02.968: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-s2cxn
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-s2cxn
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-s2cxn
Feb 13 13:48:03.077: INFO: Found 0 stateful pods, waiting for 1
Feb 13 13:48:13.086: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb 13 13:48:13.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-s2cxn ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 13 13:48:13.416: INFO: stderr: ""
Feb 13 13:48:13.416: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 13 13:48:13.416: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 13 13:48:13.420: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 13 13:48:23.431: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 13 13:48:23.431: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 13:48:23.455: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999976s
Feb 13 13:48:24.460: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995347976s
Feb 13 13:48:25.465: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.990252732s
Feb 13 13:48:26.470: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.985532821s
Feb 13 13:48:27.475: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.980746736s
Feb 13 13:48:28.480: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.975795457s
Feb 13 13:48:29.485: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.970806338s
Feb 13 13:48:30.490: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.965928757s
Feb 13 13:48:31.496: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.960028021s
Feb 13 13:48:32.501: INFO: Verifying statefulset ss doesn't scale past 1 for another 954.627925ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-s2cxn
Feb 13 13:48:33.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-s2cxn ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 13:48:33.830: INFO: stderr: ""
Feb 13 13:48:33.830: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 13 13:48:33.830: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 13 13:48:33.834: INFO: Found 1 stateful pods, waiting for 3
Feb 13 13:48:43.844: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 13:48:43.844: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 13:48:43.844: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb 13 13:48:43.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-s2cxn ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 13 13:48:44.568: INFO: stderr: ""
Feb 13 13:48:44.568: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 13 13:48:44.568: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 13 13:48:44.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-s2cxn ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 13 13:48:44.921: INFO: stderr: ""
Feb 13 13:48:44.921: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 13 13:48:44.921: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 13 13:48:44.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-s2cxn ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 13 13:48:45.350: INFO: stderr: ""
Feb 13 13:48:45.350: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 13 13:48:45.350: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 13 13:48:45.350: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 13:48:45.354: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb 13 13:48:55.368: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 13 13:48:55.368: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 13 13:48:55.368: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 13 13:48:55.384: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999758s
Feb 13 13:48:56.390: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996222985s
Feb 13 13:48:57.395: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990786145s
Feb 13 13:48:58.400: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985602293s
Feb 13 13:48:59.405: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.980187888s
Feb 13 13:49:00.410: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.975386023s
Feb 13 13:49:01.415: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.970230239s
Feb 13 13:49:02.420: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.965600748s
Feb 13 13:49:03.424: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.960636115s
Feb 13 13:49:04.438: INFO: Verifying statefulset ss doesn't scale past 3 for another 956.313378ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-s2cxn
Feb 13 13:49:05.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-s2cxn ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 13:49:05.826: INFO: stderr: ""
Feb 13 13:49:05.826: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 13 13:49:05.826: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 13 13:49:05.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-s2cxn ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 13:49:06.128: INFO: stderr: ""
Feb 13 13:49:06.128: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 13 13:49:06.128: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 13 13:49:06.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-s2cxn ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 13:49:06.502: INFO: stderr: ""
Feb 13 13:49:06.502: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 13 13:49:06.502: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 13 13:49:06.502: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 13 13:49:36.525: INFO: Deleting all statefulset in ns e2e-tests-statefulset-s2cxn
Feb 13 13:49:36.528: INFO: Scaling statefulset ss to 0
Feb 13 13:49:36.538: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 13:49:36.540: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:49:36.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-s2cxn" for this suite.
Feb 13 13:49:42.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:49:42.625: INFO: namespace: e2e-tests-statefulset-s2cxn, resource: bindings, ignored listing per whitelist
Feb 13 13:49:42.689: INFO: namespace e2e-tests-statefulset-s2cxn deletion completed in 6.129012406s

• [SLOW TEST:99.722 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:49:42.691: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 13 13:49:47.340: INFO: Successfully updated pod "annotationupdate371e5341-2f96-11e9-9b61-026654d605e3"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:49:49.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2sqrj" for this suite.
Feb 13 13:50:11.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:50:11.403: INFO: namespace: e2e-tests-projected-2sqrj, resource: bindings, ignored listing per whitelist
Feb 13 13:50:11.480: INFO: namespace e2e-tests-projected-2sqrj deletion completed in 22.117010896s

• [SLOW TEST:28.789 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:50:11.480: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Feb 13 13:50:11.585: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-f2wxk" to be "success or failure"
Feb 13 13:50:11.588: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 3.001169ms
Feb 13 13:50:13.592: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006948057s
Feb 13 13:50:15.596: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010999022s
STEP: Saw pod success
Feb 13 13:50:15.596: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb 13 13:50:15.599: INFO: Trying to get logs from node cmp3 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb 13 13:50:15.625: INFO: Waiting for pod pod-host-path-test to disappear
Feb 13 13:50:15.628: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:50:15.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-f2wxk" for this suite.
Feb 13 13:50:21.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:50:21.727: INFO: namespace: e2e-tests-hostpath-f2wxk, resource: bindings, ignored listing per whitelist
Feb 13 13:50:21.758: INFO: namespace e2e-tests-hostpath-f2wxk deletion completed in 6.125518375s

• [SLOW TEST:10.278 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:50:21.758: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 13:50:21.880: INFO: (0) /api/v1/nodes/cmp1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 5.215617ms)
Feb 13 13:50:21.884: INFO: (1) /api/v1/nodes/cmp1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.265293ms)
Feb 13 13:50:21.888: INFO: (2) /api/v1/nodes/cmp1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.099127ms)
Feb 13 13:50:21.892: INFO: (3) /api/v1/nodes/cmp1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.023204ms)
Feb 13 13:50:21.897: INFO: (4) /api/v1/nodes/cmp1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.226644ms)
Feb 13 13:50:21.900: INFO: (5) /api/v1/nodes/cmp1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.685309ms)
Feb 13 13:50:21.904: INFO: (6) /api/v1/nodes/cmp1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.687351ms)
Feb 13 13:50:21.908: INFO: (7) /api/v1/nodes/cmp1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.970667ms)
Feb 13 13:50:21.912: INFO: (8) /api/v1/nodes/cmp1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.336166ms)
Feb 13 13:50:21.916: INFO: (9) /api/v1/nodes/cmp1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.103712ms)
Feb 13 13:50:21.921: INFO: (10) /api/v1/nodes/cmp1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.128584ms)
Feb 13 13:50:21.925: INFO: (11) /api/v1/nodes/cmp1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.496571ms)
Feb 13 13:50:21.929: INFO: (12) /api/v1/nodes/cmp1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.01561ms)
Feb 13 13:50:21.933: INFO: (13) /api/v1/nodes/cmp1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.075464ms)
Feb 13 13:50:21.937: INFO: (14) /api/v1/nodes/cmp1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.885299ms)
Feb 13 13:50:21.941: INFO: (15) /api/v1/nodes/cmp1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.168855ms)
Feb 13 13:50:21.946: INFO: (16) /api/v1/nodes/cmp1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.311527ms)
Feb 13 13:50:21.950: INFO: (17) /api/v1/nodes/cmp1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.191941ms)
Feb 13 13:50:21.954: INFO: (18) /api/v1/nodes/cmp1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.071842ms)
Feb 13 13:50:21.958: INFO: (19) /api/v1/nodes/cmp1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.316014ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:50:21.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-g2gqb" for this suite.
Feb 13 13:50:27.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:50:28.044: INFO: namespace: e2e-tests-proxy-g2gqb, resource: bindings, ignored listing per whitelist
Feb 13 13:50:28.087: INFO: namespace e2e-tests-proxy-g2gqb deletion completed in 6.124494486s

• [SLOW TEST:6.329 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:50:28.089: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-b7j4p
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Feb 13 13:50:28.200: INFO: Found 0 stateful pods, waiting for 3
Feb 13 13:50:38.212: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 13:50:38.212: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 13:50:38.212: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 13:50:38.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-b7j4p ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 13 13:50:38.521: INFO: stderr: ""
Feb 13 13:50:38.521: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 13 13:50:38.521: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 13 13:50:48.562: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb 13 13:50:58.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-b7j4p ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 13:50:59.146: INFO: stderr: ""
Feb 13 13:50:59.146: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 13 13:50:59.146: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 13 13:51:09.178: INFO: Waiting for StatefulSet e2e-tests-statefulset-b7j4p/ss2 to complete update
Feb 13 13:51:09.178: INFO: Waiting for Pod e2e-tests-statefulset-b7j4p/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 13 13:51:09.178: INFO: Waiting for Pod e2e-tests-statefulset-b7j4p/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 13 13:51:09.178: INFO: Waiting for Pod e2e-tests-statefulset-b7j4p/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 13 13:51:19.201: INFO: Waiting for StatefulSet e2e-tests-statefulset-b7j4p/ss2 to complete update
Feb 13 13:51:19.201: INFO: Waiting for Pod e2e-tests-statefulset-b7j4p/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 13 13:51:29.186: INFO: Waiting for StatefulSet e2e-tests-statefulset-b7j4p/ss2 to complete update
STEP: Rolling back to a previous revision
Feb 13 13:51:39.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-b7j4p ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 13 13:51:39.503: INFO: stderr: ""
Feb 13 13:51:39.503: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 13 13:51:39.503: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 13 13:51:49.546: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb 13 13:51:59.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-b7j4p ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 13:51:59.936: INFO: stderr: ""
Feb 13 13:51:59.936: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 13 13:51:59.936: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 13 13:51:59.956: INFO: Waiting for StatefulSet e2e-tests-statefulset-b7j4p/ss2 to complete update
Feb 13 13:51:59.956: INFO: Waiting for Pod e2e-tests-statefulset-b7j4p/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 13 13:51:59.956: INFO: Waiting for Pod e2e-tests-statefulset-b7j4p/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 13 13:51:59.956: INFO: Waiting for Pod e2e-tests-statefulset-b7j4p/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 13 13:52:09.970: INFO: Waiting for StatefulSet e2e-tests-statefulset-b7j4p/ss2 to complete update
Feb 13 13:52:09.970: INFO: Waiting for Pod e2e-tests-statefulset-b7j4p/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 13 13:52:09.970: INFO: Waiting for Pod e2e-tests-statefulset-b7j4p/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 13 13:52:09.970: INFO: Waiting for Pod e2e-tests-statefulset-b7j4p/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 13 13:52:19.966: INFO: Waiting for StatefulSet e2e-tests-statefulset-b7j4p/ss2 to complete update
Feb 13 13:52:19.966: INFO: Waiting for Pod e2e-tests-statefulset-b7j4p/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 13 13:52:29.972: INFO: Deleting all statefulset in ns e2e-tests-statefulset-b7j4p
Feb 13 13:52:29.975: INFO: Scaling statefulset ss2 to 0
Feb 13 13:52:59.997: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 13:53:00.000: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:53:00.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-b7j4p" for this suite.
Feb 13 13:53:06.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:53:06.074: INFO: namespace: e2e-tests-statefulset-b7j4p, resource: bindings, ignored listing per whitelist
Feb 13 13:53:06.144: INFO: namespace e2e-tests-statefulset-b7j4p deletion completed in 6.125070272s

• [SLOW TEST:158.056 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:53:06.144: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 13 13:53:06.254: INFO: Waiting up to 5m0s for pod "downward-api-b0639bdc-2f96-11e9-9b61-026654d605e3" in namespace "e2e-tests-downward-api-4dtff" to be "success or failure"
Feb 13 13:53:06.257: INFO: Pod "downward-api-b0639bdc-2f96-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.160045ms
Feb 13 13:53:08.261: INFO: Pod "downward-api-b0639bdc-2f96-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007578597s
STEP: Saw pod success
Feb 13 13:53:08.261: INFO: Pod "downward-api-b0639bdc-2f96-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 13:53:08.265: INFO: Trying to get logs from node cmp3 pod downward-api-b0639bdc-2f96-11e9-9b61-026654d605e3 container dapi-container: <nil>
STEP: delete the pod
Feb 13 13:53:08.284: INFO: Waiting for pod downward-api-b0639bdc-2f96-11e9-9b61-026654d605e3 to disappear
Feb 13 13:53:08.287: INFO: Pod downward-api-b0639bdc-2f96-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:53:08.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4dtff" for this suite.
Feb 13 13:53:14.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:53:14.345: INFO: namespace: e2e-tests-downward-api-4dtff, resource: bindings, ignored listing per whitelist
Feb 13 13:53:14.410: INFO: namespace e2e-tests-downward-api-4dtff deletion completed in 6.118514329s

• [SLOW TEST:8.265 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:53:14.410: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Feb 13 13:53:14.499: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb 13 13:53:14.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 create -f - --namespace=e2e-tests-kubectl-bvmm8'
Feb 13 13:53:14.729: INFO: stderr: ""
Feb 13 13:53:14.729: INFO: stdout: "service/redis-slave created\n"
Feb 13 13:53:14.729: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb 13 13:53:14.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 create -f - --namespace=e2e-tests-kubectl-bvmm8'
Feb 13 13:53:14.961: INFO: stderr: ""
Feb 13 13:53:14.962: INFO: stdout: "service/redis-master created\n"
Feb 13 13:53:14.962: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb 13 13:53:14.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 create -f - --namespace=e2e-tests-kubectl-bvmm8'
Feb 13 13:53:15.204: INFO: stderr: ""
Feb 13 13:53:15.204: INFO: stdout: "service/frontend created\n"
Feb 13 13:53:15.204: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb 13 13:53:15.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 create -f - --namespace=e2e-tests-kubectl-bvmm8'
Feb 13 13:53:15.418: INFO: stderr: ""
Feb 13 13:53:15.418: INFO: stdout: "deployment.extensions/frontend created\n"
Feb 13 13:53:15.419: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb 13 13:53:15.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 create -f - --namespace=e2e-tests-kubectl-bvmm8'
Feb 13 13:53:15.649: INFO: stderr: ""
Feb 13 13:53:15.649: INFO: stdout: "deployment.extensions/redis-master created\n"
Feb 13 13:53:15.649: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb 13 13:53:15.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 create -f - --namespace=e2e-tests-kubectl-bvmm8'
Feb 13 13:53:15.878: INFO: stderr: ""
Feb 13 13:53:15.878: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Feb 13 13:53:15.878: INFO: Waiting for all frontend pods to be Running.
Feb 13 13:53:20.928: INFO: Waiting for frontend to serve content.
Feb 13 13:53:20.974: INFO: Trying to add a new entry to the guestbook.
Feb 13 13:53:21.024: INFO: Verifying that added entry can be retrieved.
Feb 13 13:53:21.039: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Feb 13 13:53:26.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bvmm8'
Feb 13 13:53:26.208: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 13:53:26.208: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb 13 13:53:26.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bvmm8'
Feb 13 13:53:26.377: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 13:53:26.377: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 13 13:53:26.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bvmm8'
Feb 13 13:53:26.506: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 13:53:26.506: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 13 13:53:26.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bvmm8'
Feb 13 13:53:26.635: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 13:53:26.635: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 13 13:53:26.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bvmm8'
Feb 13 13:53:26.755: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 13:53:26.755: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 13 13:53:26.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bvmm8'
Feb 13 13:53:26.888: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 13:53:26.888: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:53:26.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bvmm8" for this suite.
Feb 13 13:54:10.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:54:10.951: INFO: namespace: e2e-tests-kubectl-bvmm8, resource: bindings, ignored listing per whitelist
Feb 13 13:54:11.025: INFO: namespace e2e-tests-kubectl-bvmm8 deletion completed in 44.131726054s

• [SLOW TEST:56.616 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:54:11.025: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb 13 13:54:11.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 create -f - --namespace=e2e-tests-kubectl-9cd8q'
Feb 13 13:54:11.356: INFO: stderr: ""
Feb 13 13:54:11.356: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 13 13:54:12.360: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 13:54:12.360: INFO: Found 0 / 1
Feb 13 13:54:13.360: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 13:54:13.360: INFO: Found 1 / 1
Feb 13 13:54:13.360: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb 13 13:54:13.366: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 13:54:13.366: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 13 13:54:13.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 patch pod redis-master-htb8x --namespace=e2e-tests-kubectl-9cd8q -p {"metadata":{"annotations":{"x":"y"}}}'
Feb 13 13:54:13.489: INFO: stderr: ""
Feb 13 13:54:13.489: INFO: stdout: "pod/redis-master-htb8x patched\n"
STEP: checking annotations
Feb 13 13:54:13.494: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 13:54:13.494: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:54:13.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9cd8q" for this suite.
Feb 13 13:54:35.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:54:35.605: INFO: namespace: e2e-tests-kubectl-9cd8q, resource: bindings, ignored listing per whitelist
Feb 13 13:54:35.624: INFO: namespace e2e-tests-kubectl-9cd8q deletion completed in 22.124792776s

• [SLOW TEST:24.599 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:54:35.624: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-hptjq
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-hptjq
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-hptjq
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-hptjq
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-hptjq
Feb 13 13:54:39.753: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-hptjq, name: ss-0, uid: e7e5f864-2f96-11e9-b579-fa163ed32deb, status phase: Pending. Waiting for statefulset controller to delete.
Feb 13 13:54:39.960: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-hptjq, name: ss-0, uid: e7e5f864-2f96-11e9-b579-fa163ed32deb, status phase: Failed. Waiting for statefulset controller to delete.
Feb 13 13:54:39.967: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-hptjq, name: ss-0, uid: e7e5f864-2f96-11e9-b579-fa163ed32deb, status phase: Failed. Waiting for statefulset controller to delete.
Feb 13 13:54:39.971: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-hptjq
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-hptjq
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-hptjq and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 13 13:54:44.001: INFO: Deleting all statefulset in ns e2e-tests-statefulset-hptjq
Feb 13 13:54:44.004: INFO: Scaling statefulset ss to 0
Feb 13 13:54:54.026: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 13:54:54.030: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:54:54.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-hptjq" for this suite.
Feb 13 13:55:00.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:55:00.089: INFO: namespace: e2e-tests-statefulset-hptjq, resource: bindings, ignored listing per whitelist
Feb 13 13:55:00.181: INFO: namespace e2e-tests-statefulset-hptjq deletion completed in 6.133016142s

• [SLOW TEST:24.556 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:55:00.182: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-f45afbc7-2f96-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume configMaps
Feb 13 13:55:00.286: INFO: Waiting up to 5m0s for pod "pod-configmaps-f45c1c09-2f96-11e9-9b61-026654d605e3" in namespace "e2e-tests-configmap-stz6r" to be "success or failure"
Feb 13 13:55:00.289: INFO: Pod "pod-configmaps-f45c1c09-2f96-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.965021ms
Feb 13 13:55:02.293: INFO: Pod "pod-configmaps-f45c1c09-2f96-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00741329s
Feb 13 13:55:04.303: INFO: Pod "pod-configmaps-f45c1c09-2f96-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01734902s
STEP: Saw pod success
Feb 13 13:55:04.303: INFO: Pod "pod-configmaps-f45c1c09-2f96-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 13:55:04.306: INFO: Trying to get logs from node cmp3 pod pod-configmaps-f45c1c09-2f96-11e9-9b61-026654d605e3 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 13:55:04.333: INFO: Waiting for pod pod-configmaps-f45c1c09-2f96-11e9-9b61-026654d605e3 to disappear
Feb 13 13:55:04.336: INFO: Pod pod-configmaps-f45c1c09-2f96-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:55:04.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-stz6r" for this suite.
Feb 13 13:55:10.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:55:10.433: INFO: namespace: e2e-tests-configmap-stz6r, resource: bindings, ignored listing per whitelist
Feb 13 13:55:10.460: INFO: namespace e2e-tests-configmap-stz6r deletion completed in 6.12041681s

• [SLOW TEST:10.278 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:55:10.460: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-fa7b6de7-2f96-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume secrets
Feb 13 13:55:10.564: INFO: Waiting up to 5m0s for pod "pod-secrets-fa7c7e8d-2f96-11e9-9b61-026654d605e3" in namespace "e2e-tests-secrets-jvps9" to be "success or failure"
Feb 13 13:55:10.568: INFO: Pod "pod-secrets-fa7c7e8d-2f96-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.371107ms
Feb 13 13:55:12.572: INFO: Pod "pod-secrets-fa7c7e8d-2f96-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007520557s
Feb 13 13:55:14.581: INFO: Pod "pod-secrets-fa7c7e8d-2f96-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016790654s
STEP: Saw pod success
Feb 13 13:55:14.581: INFO: Pod "pod-secrets-fa7c7e8d-2f96-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 13:55:14.584: INFO: Trying to get logs from node cmp3 pod pod-secrets-fa7c7e8d-2f96-11e9-9b61-026654d605e3 container secret-env-test: <nil>
STEP: delete the pod
Feb 13 13:55:14.606: INFO: Waiting for pod pod-secrets-fa7c7e8d-2f96-11e9-9b61-026654d605e3 to disappear
Feb 13 13:55:14.609: INFO: Pod pod-secrets-fa7c7e8d-2f96-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:55:14.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-jvps9" for this suite.
Feb 13 13:55:20.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:55:20.745: INFO: namespace: e2e-tests-secrets-jvps9, resource: bindings, ignored listing per whitelist
Feb 13 13:55:20.757: INFO: namespace e2e-tests-secrets-jvps9 deletion completed in 6.142131078s

• [SLOW TEST:10.296 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:55:20.757: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb 13 13:55:20.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 create -f - --namespace=e2e-tests-kubectl-vtpf9'
Feb 13 13:55:21.076: INFO: stderr: ""
Feb 13 13:55:21.076: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 13 13:55:21.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-vtpf9'
Feb 13 13:55:21.203: INFO: stderr: ""
Feb 13 13:55:21.203: INFO: stdout: "update-demo-nautilus-9kvkv update-demo-nautilus-vl55g "
Feb 13 13:55:21.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods update-demo-nautilus-9kvkv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vtpf9'
Feb 13 13:55:21.321: INFO: stderr: ""
Feb 13 13:55:21.321: INFO: stdout: ""
Feb 13 13:55:21.321: INFO: update-demo-nautilus-9kvkv is created but not running
Feb 13 13:55:26.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-vtpf9'
Feb 13 13:55:26.438: INFO: stderr: ""
Feb 13 13:55:26.438: INFO: stdout: "update-demo-nautilus-9kvkv update-demo-nautilus-vl55g "
Feb 13 13:55:26.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods update-demo-nautilus-9kvkv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vtpf9'
Feb 13 13:55:26.561: INFO: stderr: ""
Feb 13 13:55:26.561: INFO: stdout: "true"
Feb 13 13:55:26.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods update-demo-nautilus-9kvkv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vtpf9'
Feb 13 13:55:26.688: INFO: stderr: ""
Feb 13 13:55:26.688: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 13 13:55:26.688: INFO: validating pod update-demo-nautilus-9kvkv
Feb 13 13:55:26.704: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 13:55:26.704: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 13:55:26.704: INFO: update-demo-nautilus-9kvkv is verified up and running
Feb 13 13:55:26.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods update-demo-nautilus-vl55g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vtpf9'
Feb 13 13:55:26.837: INFO: stderr: ""
Feb 13 13:55:26.837: INFO: stdout: "true"
Feb 13 13:55:26.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods update-demo-nautilus-vl55g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vtpf9'
Feb 13 13:55:26.955: INFO: stderr: ""
Feb 13 13:55:26.955: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 13 13:55:26.955: INFO: validating pod update-demo-nautilus-vl55g
Feb 13 13:55:26.965: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 13:55:26.965: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 13:55:26.965: INFO: update-demo-nautilus-vl55g is verified up and running
STEP: using delete to clean up resources
Feb 13 13:55:26.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-vtpf9'
Feb 13 13:55:27.083: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 13:55:27.083: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 13 13:55:27.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-vtpf9'
Feb 13 13:55:27.223: INFO: stderr: "No resources found.\n"
Feb 13 13:55:27.223: INFO: stdout: ""
Feb 13 13:55:27.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods -l name=update-demo --namespace=e2e-tests-kubectl-vtpf9 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 13 13:55:27.341: INFO: stderr: ""
Feb 13 13:55:27.341: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:55:27.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vtpf9" for this suite.
Feb 13 13:55:49.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:55:49.406: INFO: namespace: e2e-tests-kubectl-vtpf9, resource: bindings, ignored listing per whitelist
Feb 13 13:55:49.474: INFO: namespace e2e-tests-kubectl-vtpf9 deletion completed in 22.127976166s

• [SLOW TEST:28.718 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:55:49.475: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-11bc7abc-2f97-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume configMaps
Feb 13 13:55:49.579: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-11bdabbb-2f97-11e9-9b61-026654d605e3" in namespace "e2e-tests-projected-97df8" to be "success or failure"
Feb 13 13:55:49.582: INFO: Pod "pod-projected-configmaps-11bdabbb-2f97-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.995375ms
Feb 13 13:55:51.586: INFO: Pod "pod-projected-configmaps-11bdabbb-2f97-11e9-9b61-026654d605e3": Phase="Running", Reason="", readiness=true. Elapsed: 2.007025648s
Feb 13 13:55:53.590: INFO: Pod "pod-projected-configmaps-11bdabbb-2f97-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011070244s
STEP: Saw pod success
Feb 13 13:55:53.590: INFO: Pod "pod-projected-configmaps-11bdabbb-2f97-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 13:55:53.593: INFO: Trying to get logs from node cmp3 pod pod-projected-configmaps-11bdabbb-2f97-11e9-9b61-026654d605e3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 13:55:53.614: INFO: Waiting for pod pod-projected-configmaps-11bdabbb-2f97-11e9-9b61-026654d605e3 to disappear
Feb 13 13:55:53.617: INFO: Pod pod-projected-configmaps-11bdabbb-2f97-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:55:53.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-97df8" for this suite.
Feb 13 13:55:59.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:55:59.735: INFO: namespace: e2e-tests-projected-97df8, resource: bindings, ignored listing per whitelist
Feb 13 13:55:59.758: INFO: namespace e2e-tests-projected-97df8 deletion completed in 6.136494659s

• [SLOW TEST:10.283 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:55:59.758: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Feb 13 13:55:59.851: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 13 13:55:59.859: INFO: Waiting for terminating namespaces to be deleted...
Feb 13 13:55:59.863: INFO: 
Logging pods the kubelet thinks is on node cmp1 before test
Feb 13 13:55:59.871: INFO: speaker-9ktjr from metallb-system started at 2019-02-01 18:30:05 +0000 UTC (1 container statuses recorded)
Feb 13 13:55:59.871: INFO: 	Container speaker ready: true, restart count 2
Feb 13 13:55:59.871: INFO: kube-flannel-ds-z7czt from kube-system started at 2019-02-01 18:30:05 +0000 UTC (1 container statuses recorded)
Feb 13 13:55:59.871: INFO: 	Container kube-flannel ready: true, restart count 2
Feb 13 13:55:59.871: INFO: sonobuoy-systemd-logs-daemon-set-e9328804e2d54b8e-kmd4p from heptio-sonobuoy started at 2019-02-13 13:32:31 +0000 UTC (2 container statuses recorded)
Feb 13 13:55:59.871: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 13 13:55:59.871: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 13 13:55:59.871: INFO: netchecker-agent-rgq6k from netchecker started at 2019-02-01 18:30:05 +0000 UTC (1 container statuses recorded)
Feb 13 13:55:59.871: INFO: 	Container netchecker-agent ready: true, restart count 2
Feb 13 13:55:59.871: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-13 13:32:27 +0000 UTC (1 container statuses recorded)
Feb 13 13:55:59.871: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 13 13:55:59.871: INFO: 
Logging pods the kubelet thinks is on node cmp2 before test
Feb 13 13:55:59.878: INFO: netchecker-agent-m2b92 from netchecker started at 2019-02-01 18:30:05 +0000 UTC (1 container statuses recorded)
Feb 13 13:55:59.878: INFO: 	Container netchecker-agent ready: true, restart count 1
Feb 13 13:55:59.878: INFO: speaker-smqxw from metallb-system started at 2019-02-01 18:30:05 +0000 UTC (1 container statuses recorded)
Feb 13 13:55:59.878: INFO: 	Container speaker ready: true, restart count 1
Feb 13 13:55:59.878: INFO: kube-flannel-ds-pszdm from kube-system started at 2019-02-01 18:30:05 +0000 UTC (1 container statuses recorded)
Feb 13 13:55:59.878: INFO: 	Container kube-flannel ready: true, restart count 1
Feb 13 13:55:59.878: INFO: controller-5755b9ccc-5szmk from metallb-system started at 2019-02-12 00:42:37 +0000 UTC (1 container statuses recorded)
Feb 13 13:55:59.878: INFO: 	Container controller ready: true, restart count 1
Feb 13 13:55:59.878: INFO: sonobuoy-systemd-logs-daemon-set-e9328804e2d54b8e-5qtht from heptio-sonobuoy started at 2019-02-13 13:32:32 +0000 UTC (2 container statuses recorded)
Feb 13 13:55:59.878: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 13 13:55:59.878: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 13 13:55:59.878: INFO: 
Logging pods the kubelet thinks is on node cmp3 before test
Feb 13 13:55:59.884: INFO: netchecker-agent-xghwc from netchecker started at 2019-02-01 18:30:05 +0000 UTC (1 container statuses recorded)
Feb 13 13:55:59.885: INFO: 	Container netchecker-agent ready: true, restart count 2
Feb 13 13:55:59.885: INFO: speaker-zqc6w from metallb-system started at 2019-02-01 18:30:05 +0000 UTC (1 container statuses recorded)
Feb 13 13:55:59.885: INFO: 	Container speaker ready: true, restart count 2
Feb 13 13:55:59.885: INFO: kube-flannel-ds-vxppb from kube-system started at 2019-02-01 18:30:05 +0000 UTC (1 container statuses recorded)
Feb 13 13:55:59.885: INFO: 	Container kube-flannel ready: true, restart count 2
Feb 13 13:55:59.885: INFO: sonobuoy-systemd-logs-daemon-set-e9328804e2d54b8e-9bmpk from heptio-sonobuoy started at 2019-02-13 13:32:31 +0000 UTC (2 container statuses recorded)
Feb 13 13:55:59.885: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 13 13:55:59.885: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-1919ba5a-2f97-11e9-9b61-026654d605e3 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-1919ba5a-2f97-11e9-9b61-026654d605e3 off the node cmp3
STEP: verifying the node doesn't have the label kubernetes.io/e2e-1919ba5a-2f97-11e9-9b61-026654d605e3
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:56:05.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-c596p" for this suite.
Feb 13 13:56:19.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:56:19.998: INFO: namespace: e2e-tests-sched-pred-c596p, resource: bindings, ignored listing per whitelist
Feb 13 13:56:20.098: INFO: namespace e2e-tests-sched-pred-c596p deletion completed in 14.134910289s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:20.340 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:56:20.098: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-23fda6fe-2f97-11e9-9b61-026654d605e3
STEP: Creating secret with name s-test-opt-upd-23fda744-2f97-11e9-9b61-026654d605e3
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-23fda6fe-2f97-11e9-9b61-026654d605e3
STEP: Updating secret s-test-opt-upd-23fda744-2f97-11e9-9b61-026654d605e3
STEP: Creating secret with name s-test-opt-create-23fda75c-2f97-11e9-9b61-026654d605e3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:56:26.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-zq26f" for this suite.
Feb 13 13:56:48.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:56:48.316: INFO: namespace: e2e-tests-secrets-zq26f, resource: bindings, ignored listing per whitelist
Feb 13 13:56:48.417: INFO: namespace e2e-tests-secrets-zq26f deletion completed in 22.119724853s

• [SLOW TEST:28.318 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:56:48.417: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb 13 13:56:48.545: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-rvcxm,SelfLink:/api/v1/namespaces/e2e-tests-watch-rvcxm/configmaps/e2e-watch-test-resource-version,UID:34e0aa46-2f97-11e9-85f4-fa163e429998,ResourceVersion:2508791,Generation:0,CreationTimestamp:2019-02-13 13:56:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 13 13:56:48.545: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-rvcxm,SelfLink:/api/v1/namespaces/e2e-tests-watch-rvcxm/configmaps/e2e-watch-test-resource-version,UID:34e0aa46-2f97-11e9-85f4-fa163e429998,ResourceVersion:2508792,Generation:0,CreationTimestamp:2019-02-13 13:56:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:56:48.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-rvcxm" for this suite.
Feb 13 13:56:54.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:56:54.612: INFO: namespace: e2e-tests-watch-rvcxm, resource: bindings, ignored listing per whitelist
Feb 13 13:56:54.674: INFO: namespace e2e-tests-watch-rvcxm deletion completed in 6.122921385s

• [SLOW TEST:6.257 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:56:54.674: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 13 13:56:54.771: INFO: Waiting up to 5m0s for pod "pod-3898c186-2f97-11e9-9b61-026654d605e3" in namespace "e2e-tests-emptydir-zgmmr" to be "success or failure"
Feb 13 13:56:54.774: INFO: Pod "pod-3898c186-2f97-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.774485ms
Feb 13 13:56:56.777: INFO: Pod "pod-3898c186-2f97-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00631754s
Feb 13 13:56:58.781: INFO: Pod "pod-3898c186-2f97-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009900192s
STEP: Saw pod success
Feb 13 13:56:58.781: INFO: Pod "pod-3898c186-2f97-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 13:56:58.784: INFO: Trying to get logs from node cmp3 pod pod-3898c186-2f97-11e9-9b61-026654d605e3 container test-container: <nil>
STEP: delete the pod
Feb 13 13:56:58.806: INFO: Waiting for pod pod-3898c186-2f97-11e9-9b61-026654d605e3 to disappear
Feb 13 13:56:58.809: INFO: Pod pod-3898c186-2f97-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:56:58.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-zgmmr" for this suite.
Feb 13 13:57:04.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:57:04.839: INFO: namespace: e2e-tests-emptydir-zgmmr, resource: bindings, ignored listing per whitelist
Feb 13 13:57:04.941: INFO: namespace e2e-tests-emptydir-zgmmr deletion completed in 6.126366841s

• [SLOW TEST:10.267 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:57:04.941: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-nkxs
STEP: Creating a pod to test atomic-volume-subpath
Feb 13 13:57:05.067: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-nkxs" in namespace "e2e-tests-subpath-z2fjk" to be "success or failure"
Feb 13 13:57:05.070: INFO: Pod "pod-subpath-test-configmap-nkxs": Phase="Pending", Reason="", readiness=false. Elapsed: 3.290959ms
Feb 13 13:57:07.075: INFO: Pod "pod-subpath-test-configmap-nkxs": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008062417s
Feb 13 13:57:09.079: INFO: Pod "pod-subpath-test-configmap-nkxs": Phase="Running", Reason="", readiness=false. Elapsed: 4.011821911s
Feb 13 13:57:11.083: INFO: Pod "pod-subpath-test-configmap-nkxs": Phase="Running", Reason="", readiness=false. Elapsed: 6.016536203s
Feb 13 13:57:13.094: INFO: Pod "pod-subpath-test-configmap-nkxs": Phase="Running", Reason="", readiness=false. Elapsed: 8.027408546s
Feb 13 13:57:15.098: INFO: Pod "pod-subpath-test-configmap-nkxs": Phase="Running", Reason="", readiness=false. Elapsed: 10.03127707s
Feb 13 13:57:17.103: INFO: Pod "pod-subpath-test-configmap-nkxs": Phase="Running", Reason="", readiness=false. Elapsed: 12.0356341s
Feb 13 13:57:19.107: INFO: Pod "pod-subpath-test-configmap-nkxs": Phase="Running", Reason="", readiness=false. Elapsed: 14.039640981s
Feb 13 13:57:21.114: INFO: Pod "pod-subpath-test-configmap-nkxs": Phase="Running", Reason="", readiness=false. Elapsed: 16.047447483s
Feb 13 13:57:23.125: INFO: Pod "pod-subpath-test-configmap-nkxs": Phase="Running", Reason="", readiness=false. Elapsed: 18.058596223s
Feb 13 13:57:25.130: INFO: Pod "pod-subpath-test-configmap-nkxs": Phase="Running", Reason="", readiness=false. Elapsed: 20.063021944s
Feb 13 13:57:27.135: INFO: Pod "pod-subpath-test-configmap-nkxs": Phase="Running", Reason="", readiness=false. Elapsed: 22.068243806s
Feb 13 13:57:29.140: INFO: Pod "pod-subpath-test-configmap-nkxs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.07300567s
STEP: Saw pod success
Feb 13 13:57:29.140: INFO: Pod "pod-subpath-test-configmap-nkxs" satisfied condition "success or failure"
Feb 13 13:57:29.144: INFO: Trying to get logs from node cmp3 pod pod-subpath-test-configmap-nkxs container test-container-subpath-configmap-nkxs: <nil>
STEP: delete the pod
Feb 13 13:57:29.169: INFO: Waiting for pod pod-subpath-test-configmap-nkxs to disappear
Feb 13 13:57:29.173: INFO: Pod pod-subpath-test-configmap-nkxs no longer exists
STEP: Deleting pod pod-subpath-test-configmap-nkxs
Feb 13 13:57:29.173: INFO: Deleting pod "pod-subpath-test-configmap-nkxs" in namespace "e2e-tests-subpath-z2fjk"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:57:29.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-z2fjk" for this suite.
Feb 13 13:57:35.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:57:35.218: INFO: namespace: e2e-tests-subpath-z2fjk, resource: bindings, ignored listing per whitelist
Feb 13 13:57:35.302: INFO: namespace e2e-tests-subpath-z2fjk deletion completed in 6.121731969s

• [SLOW TEST:30.361 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:57:35.303: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 13 13:57:35.417: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 13:57:35.417: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 13:57:35.417: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 13:57:35.420: INFO: Number of nodes with available pods: 0
Feb 13 13:57:35.420: INFO: Node cmp1 is running more than one daemon pod
Feb 13 13:57:36.426: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 13:57:36.426: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 13:57:36.426: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 13:57:36.429: INFO: Number of nodes with available pods: 0
Feb 13 13:57:36.429: INFO: Node cmp1 is running more than one daemon pod
Feb 13 13:57:37.426: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 13:57:37.426: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 13:57:37.426: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 13:57:37.430: INFO: Number of nodes with available pods: 1
Feb 13 13:57:37.430: INFO: Node cmp2 is running more than one daemon pod
Feb 13 13:57:38.426: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 13:57:38.426: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 13:57:38.426: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 13:57:38.430: INFO: Number of nodes with available pods: 3
Feb 13 13:57:38.430: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb 13 13:57:38.449: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 13:57:38.450: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 13:57:38.450: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 13:57:38.454: INFO: Number of nodes with available pods: 2
Feb 13 13:57:38.454: INFO: Node cmp3 is running more than one daemon pod
Feb 13 13:57:39.461: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 13:57:39.461: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 13:57:39.461: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 13:57:39.464: INFO: Number of nodes with available pods: 2
Feb 13 13:57:39.464: INFO: Node cmp3 is running more than one daemon pod
Feb 13 13:57:40.461: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 13:57:40.461: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 13:57:40.461: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 13:57:40.465: INFO: Number of nodes with available pods: 2
Feb 13 13:57:40.465: INFO: Node cmp3 is running more than one daemon pod
Feb 13 13:57:41.461: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 13:57:41.461: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 13:57:41.461: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 13:57:41.464: INFO: Number of nodes with available pods: 3
Feb 13 13:57:41.464: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-zkxt7, will wait for the garbage collector to delete the pods
Feb 13 13:57:41.535: INFO: Deleting {extensions DaemonSet} daemon-set took: 10.416385ms
Feb 13 13:57:41.636: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.391501ms
Feb 13 13:58:23.847: INFO: Number of nodes with available pods: 0
Feb 13 13:58:23.847: INFO: Number of running nodes: 0, number of available pods: 0
Feb 13 13:58:23.853: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-zkxt7/daemonsets","resourceVersion":"2509205"},"items":null}

Feb 13 13:58:23.857: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-zkxt7/pods","resourceVersion":"2509205"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:58:23.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-zkxt7" for this suite.
Feb 13 13:58:29.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:58:29.936: INFO: namespace: e2e-tests-daemonsets-zkxt7, resource: bindings, ignored listing per whitelist
Feb 13 13:58:30.010: INFO: namespace e2e-tests-daemonsets-zkxt7 deletion completed in 6.129978763s

• [SLOW TEST:54.707 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:58:30.010: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-kbh4c
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 13 13:58:30.101: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 13 13:58:52.186: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.113.105:8080/dial?request=hostName&protocol=udp&host=192.168.113.104&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-kbh4c PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 13:58:52.186: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
Feb 13 13:58:52.434: INFO: Waiting for endpoints: map[]
Feb 13 13:58:52.437: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.113.105:8080/dial?request=hostName&protocol=udp&host=192.168.197.3&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-kbh4c PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 13:58:52.437: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
Feb 13 13:58:52.604: INFO: Waiting for endpoints: map[]
Feb 13 13:58:52.608: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.113.105:8080/dial?request=hostName&protocol=udp&host=192.168.119.196&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-kbh4c PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 13:58:52.608: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
Feb 13 13:58:52.784: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:58:52.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-kbh4c" for this suite.
Feb 13 13:59:14.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:59:14.853: INFO: namespace: e2e-tests-pod-network-test-kbh4c, resource: bindings, ignored listing per whitelist
Feb 13 13:59:14.915: INFO: namespace e2e-tests-pod-network-test-kbh4c deletion completed in 22.125110949s

• [SLOW TEST:44.905 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:59:14.915: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 13 13:59:15.020: INFO: Waiting up to 5m0s for pod "pod-8c311da7-2f97-11e9-9b61-026654d605e3" in namespace "e2e-tests-emptydir-brgk8" to be "success or failure"
Feb 13 13:59:15.023: INFO: Pod "pod-8c311da7-2f97-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.859908ms
Feb 13 13:59:17.028: INFO: Pod "pod-8c311da7-2f97-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007701853s
Feb 13 13:59:19.039: INFO: Pod "pod-8c311da7-2f97-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018691365s
STEP: Saw pod success
Feb 13 13:59:19.039: INFO: Pod "pod-8c311da7-2f97-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 13:59:19.042: INFO: Trying to get logs from node cmp3 pod pod-8c311da7-2f97-11e9-9b61-026654d605e3 container test-container: <nil>
STEP: delete the pod
Feb 13 13:59:19.062: INFO: Waiting for pod pod-8c311da7-2f97-11e9-9b61-026654d605e3 to disappear
Feb 13 13:59:19.065: INFO: Pod pod-8c311da7-2f97-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:59:19.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-brgk8" for this suite.
Feb 13 13:59:25.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:59:25.119: INFO: namespace: e2e-tests-emptydir-brgk8, resource: bindings, ignored listing per whitelist
Feb 13 13:59:25.199: INFO: namespace e2e-tests-emptydir-brgk8 deletion completed in 6.129432577s

• [SLOW TEST:10.284 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:59:25.199: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 13:59:25.301: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9251c293-2f97-11e9-9b61-026654d605e3" in namespace "e2e-tests-projected-6zbx7" to be "success or failure"
Feb 13 13:59:25.305: INFO: Pod "downwardapi-volume-9251c293-2f97-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.781679ms
Feb 13 13:59:27.309: INFO: Pod "downwardapi-volume-9251c293-2f97-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008690504s
Feb 13 13:59:29.319: INFO: Pod "downwardapi-volume-9251c293-2f97-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018507575s
STEP: Saw pod success
Feb 13 13:59:29.319: INFO: Pod "downwardapi-volume-9251c293-2f97-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 13:59:29.322: INFO: Trying to get logs from node cmp3 pod downwardapi-volume-9251c293-2f97-11e9-9b61-026654d605e3 container client-container: <nil>
STEP: delete the pod
Feb 13 13:59:29.343: INFO: Waiting for pod downwardapi-volume-9251c293-2f97-11e9-9b61-026654d605e3 to disappear
Feb 13 13:59:29.346: INFO: Pod downwardapi-volume-9251c293-2f97-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:59:29.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6zbx7" for this suite.
Feb 13 13:59:35.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:59:35.448: INFO: namespace: e2e-tests-projected-6zbx7, resource: bindings, ignored listing per whitelist
Feb 13 13:59:35.475: INFO: namespace e2e-tests-projected-6zbx7 deletion completed in 6.12339536s

• [SLOW TEST:10.276 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:59:35.476: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-9871623c-2f97-11e9-9b61-026654d605e3
STEP: Creating secret with name secret-projected-all-test-volume-9871622a-2f97-11e9-9b61-026654d605e3
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb 13 13:59:35.583: INFO: Waiting up to 5m0s for pod "projected-volume-987161f4-2f97-11e9-9b61-026654d605e3" in namespace "e2e-tests-projected-4476z" to be "success or failure"
Feb 13 13:59:35.585: INFO: Pod "projected-volume-987161f4-2f97-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.73568ms
Feb 13 13:59:37.590: INFO: Pod "projected-volume-987161f4-2f97-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00721341s
Feb 13 13:59:39.599: INFO: Pod "projected-volume-987161f4-2f97-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016821995s
STEP: Saw pod success
Feb 13 13:59:39.599: INFO: Pod "projected-volume-987161f4-2f97-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 13:59:39.603: INFO: Trying to get logs from node cmp3 pod projected-volume-987161f4-2f97-11e9-9b61-026654d605e3 container projected-all-volume-test: <nil>
STEP: delete the pod
Feb 13 13:59:39.623: INFO: Waiting for pod projected-volume-987161f4-2f97-11e9-9b61-026654d605e3 to disappear
Feb 13 13:59:39.626: INFO: Pod projected-volume-987161f4-2f97-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:59:39.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4476z" for this suite.
Feb 13 13:59:45.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:59:45.755: INFO: namespace: e2e-tests-projected-4476z, resource: bindings, ignored listing per whitelist
Feb 13 13:59:45.755: INFO: namespace e2e-tests-projected-4476z deletion completed in 6.12410454s

• [SLOW TEST:10.279 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:59:45.755: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-9e920034-2f97-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume configMaps
Feb 13 13:59:45.858: INFO: Waiting up to 5m0s for pod "pod-configmaps-9e92f13f-2f97-11e9-9b61-026654d605e3" in namespace "e2e-tests-configmap-rkkqv" to be "success or failure"
Feb 13 13:59:45.861: INFO: Pod "pod-configmaps-9e92f13f-2f97-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.059246ms
Feb 13 13:59:47.866: INFO: Pod "pod-configmaps-9e92f13f-2f97-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007549092s
Feb 13 13:59:49.876: INFO: Pod "pod-configmaps-9e92f13f-2f97-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017279214s
STEP: Saw pod success
Feb 13 13:59:49.876: INFO: Pod "pod-configmaps-9e92f13f-2f97-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 13:59:49.879: INFO: Trying to get logs from node cmp3 pod pod-configmaps-9e92f13f-2f97-11e9-9b61-026654d605e3 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 13:59:49.899: INFO: Waiting for pod pod-configmaps-9e92f13f-2f97-11e9-9b61-026654d605e3 to disappear
Feb 13 13:59:49.902: INFO: Pod pod-configmaps-9e92f13f-2f97-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 13:59:49.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-rkkqv" for this suite.
Feb 13 13:59:55.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 13:59:55.961: INFO: namespace: e2e-tests-configmap-rkkqv, resource: bindings, ignored listing per whitelist
Feb 13 13:59:56.032: INFO: namespace e2e-tests-configmap-rkkqv deletion completed in 6.125131986s

• [SLOW TEST:10.277 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 13:59:56.032: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-a4b31e71-2f97-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume secrets
Feb 13 13:59:56.142: INFO: Waiting up to 5m0s for pod "pod-secrets-a4b43e35-2f97-11e9-9b61-026654d605e3" in namespace "e2e-tests-secrets-h6nsv" to be "success or failure"
Feb 13 13:59:56.147: INFO: Pod "pod-secrets-a4b43e35-2f97-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.951974ms
Feb 13 13:59:58.151: INFO: Pod "pod-secrets-a4b43e35-2f97-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008710272s
Feb 13 14:00:00.163: INFO: Pod "pod-secrets-a4b43e35-2f97-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020281839s
STEP: Saw pod success
Feb 13 14:00:00.163: INFO: Pod "pod-secrets-a4b43e35-2f97-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:00:00.166: INFO: Trying to get logs from node cmp3 pod pod-secrets-a4b43e35-2f97-11e9-9b61-026654d605e3 container secret-volume-test: <nil>
STEP: delete the pod
Feb 13 14:00:00.187: INFO: Waiting for pod pod-secrets-a4b43e35-2f97-11e9-9b61-026654d605e3 to disappear
Feb 13 14:00:00.191: INFO: Pod pod-secrets-a4b43e35-2f97-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:00:00.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-h6nsv" for this suite.
Feb 13 14:00:06.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:00:06.269: INFO: namespace: e2e-tests-secrets-h6nsv, resource: bindings, ignored listing per whitelist
Feb 13 14:00:06.320: INFO: namespace e2e-tests-secrets-h6nsv deletion completed in 6.124157127s

• [SLOW TEST:10.288 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:00:06.321: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-vr5bv
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-vr5bv
STEP: Deleting pre-stop pod
Feb 13 14:00:19.482: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:00:19.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-vr5bv" for this suite.
Feb 13 14:00:57.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:00:57.536: INFO: namespace: e2e-tests-prestop-vr5bv, resource: bindings, ignored listing per whitelist
Feb 13 14:00:57.628: INFO: namespace e2e-tests-prestop-vr5bv deletion completed in 38.133538254s

• [SLOW TEST:51.308 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:00:57.629: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-c96a4cc3-2f97-11e9-9b61-026654d605e3
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:01:01.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-6r8sj" for this suite.
Feb 13 14:01:23.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:01:23.864: INFO: namespace: e2e-tests-configmap-6r8sj, resource: bindings, ignored listing per whitelist
Feb 13 14:01:23.897: INFO: namespace e2e-tests-configmap-6r8sj deletion completed in 22.119765396s

• [SLOW TEST:26.268 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:01:23.897: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 13 14:01:32.045: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 13 14:01:32.048: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 13 14:01:34.048: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 13 14:01:34.053: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 13 14:01:36.048: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 13 14:01:36.053: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 13 14:01:38.049: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 13 14:01:38.053: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 13 14:01:40.048: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 13 14:01:40.060: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 13 14:01:42.048: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 13 14:01:42.053: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 13 14:01:44.048: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 13 14:01:44.052: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 13 14:01:46.053: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 13 14:01:46.059: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 13 14:01:48.049: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 13 14:01:48.062: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 13 14:01:50.048: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 13 14:01:50.053: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 13 14:01:52.049: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 13 14:01:52.059: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 13 14:01:54.048: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 13 14:01:54.052: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:01:54.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-rzfzp" for this suite.
Feb 13 14:02:16.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:02:16.089: INFO: namespace: e2e-tests-container-lifecycle-hook-rzfzp, resource: bindings, ignored listing per whitelist
Feb 13 14:02:16.196: INFO: namespace e2e-tests-container-lifecycle-hook-rzfzp deletion completed in 22.12993469s

• [SLOW TEST:52.299 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:02:16.196: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Feb 13 14:02:16.285: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 13 14:02:16.293: INFO: Waiting for terminating namespaces to be deleted...
Feb 13 14:02:16.297: INFO: 
Logging pods the kubelet thinks is on node cmp1 before test
Feb 13 14:02:16.304: INFO: kube-flannel-ds-z7czt from kube-system started at 2019-02-01 18:30:05 +0000 UTC (1 container statuses recorded)
Feb 13 14:02:16.304: INFO: 	Container kube-flannel ready: true, restart count 2
Feb 13 14:02:16.304: INFO: sonobuoy-systemd-logs-daemon-set-e9328804e2d54b8e-kmd4p from heptio-sonobuoy started at 2019-02-13 13:32:31 +0000 UTC (2 container statuses recorded)
Feb 13 14:02:16.304: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 13 14:02:16.304: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 13 14:02:16.304: INFO: netchecker-agent-rgq6k from netchecker started at 2019-02-01 18:30:05 +0000 UTC (1 container statuses recorded)
Feb 13 14:02:16.304: INFO: 	Container netchecker-agent ready: true, restart count 2
Feb 13 14:02:16.304: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-13 13:32:27 +0000 UTC (1 container statuses recorded)
Feb 13 14:02:16.304: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 13 14:02:16.304: INFO: speaker-9ktjr from metallb-system started at 2019-02-01 18:30:05 +0000 UTC (1 container statuses recorded)
Feb 13 14:02:16.304: INFO: 	Container speaker ready: true, restart count 2
Feb 13 14:02:16.304: INFO: 
Logging pods the kubelet thinks is on node cmp2 before test
Feb 13 14:02:16.311: INFO: speaker-smqxw from metallb-system started at 2019-02-01 18:30:05 +0000 UTC (1 container statuses recorded)
Feb 13 14:02:16.311: INFO: 	Container speaker ready: true, restart count 1
Feb 13 14:02:16.311: INFO: kube-flannel-ds-pszdm from kube-system started at 2019-02-01 18:30:05 +0000 UTC (1 container statuses recorded)
Feb 13 14:02:16.311: INFO: 	Container kube-flannel ready: true, restart count 1
Feb 13 14:02:16.311: INFO: sonobuoy-systemd-logs-daemon-set-e9328804e2d54b8e-5qtht from heptio-sonobuoy started at 2019-02-13 13:32:32 +0000 UTC (2 container statuses recorded)
Feb 13 14:02:16.311: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 13 14:02:16.311: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 13 14:02:16.311: INFO: controller-5755b9ccc-5szmk from metallb-system started at 2019-02-12 00:42:37 +0000 UTC (1 container statuses recorded)
Feb 13 14:02:16.311: INFO: 	Container controller ready: true, restart count 1
Feb 13 14:02:16.311: INFO: netchecker-agent-m2b92 from netchecker started at 2019-02-01 18:30:05 +0000 UTC (1 container statuses recorded)
Feb 13 14:02:16.311: INFO: 	Container netchecker-agent ready: true, restart count 1
Feb 13 14:02:16.311: INFO: 
Logging pods the kubelet thinks is on node cmp3 before test
Feb 13 14:02:16.317: INFO: netchecker-agent-xghwc from netchecker started at 2019-02-01 18:30:05 +0000 UTC (1 container statuses recorded)
Feb 13 14:02:16.317: INFO: 	Container netchecker-agent ready: true, restart count 2
Feb 13 14:02:16.317: INFO: speaker-zqc6w from metallb-system started at 2019-02-01 18:30:05 +0000 UTC (1 container statuses recorded)
Feb 13 14:02:16.317: INFO: 	Container speaker ready: true, restart count 2
Feb 13 14:02:16.317: INFO: kube-flannel-ds-vxppb from kube-system started at 2019-02-01 18:30:05 +0000 UTC (1 container statuses recorded)
Feb 13 14:02:16.317: INFO: 	Container kube-flannel ready: true, restart count 2
Feb 13 14:02:16.317: INFO: sonobuoy-systemd-logs-daemon-set-e9328804e2d54b8e-9bmpk from heptio-sonobuoy started at 2019-02-13 13:32:31 +0000 UTC (2 container statuses recorded)
Feb 13 14:02:16.317: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 13 14:02:16.317: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1582f14d5d143267], Reason = [FailedScheduling], Message = [0/6 nodes are available: 6 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:02:17.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-tkwfk" for this suite.
Feb 13 14:02:23.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:02:23.407: INFO: namespace: e2e-tests-sched-pred-tkwfk, resource: bindings, ignored listing per whitelist
Feb 13 14:02:23.477: INFO: namespace e2e-tests-sched-pred-tkwfk deletion completed in 6.125964223s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:7.281 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:02:23.477: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 13 14:02:28.102: INFO: Successfully updated pod "labelsupdatefc93d0df-2f97-11e9-9b61-026654d605e3"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:02:30.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dksl9" for this suite.
Feb 13 14:02:52.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:02:52.210: INFO: namespace: e2e-tests-projected-dksl9, resource: bindings, ignored listing per whitelist
Feb 13 14:02:52.245: INFO: namespace e2e-tests-projected-dksl9 deletion completed in 22.120550273s

• [SLOW TEST:28.767 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:02:52.245: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-0dba6dc2-2f98-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume secrets
Feb 13 14:02:52.351: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0dbb83a4-2f98-11e9-9b61-026654d605e3" in namespace "e2e-tests-projected-vbhw6" to be "success or failure"
Feb 13 14:02:52.354: INFO: Pod "pod-projected-secrets-0dbb83a4-2f98-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.809125ms
Feb 13 14:02:54.358: INFO: Pod "pod-projected-secrets-0dbb83a4-2f98-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007380719s
Feb 13 14:02:56.363: INFO: Pod "pod-projected-secrets-0dbb83a4-2f98-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011580559s
STEP: Saw pod success
Feb 13 14:02:56.363: INFO: Pod "pod-projected-secrets-0dbb83a4-2f98-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:02:56.366: INFO: Trying to get logs from node cmp3 pod pod-projected-secrets-0dbb83a4-2f98-11e9-9b61-026654d605e3 container secret-volume-test: <nil>
STEP: delete the pod
Feb 13 14:02:56.393: INFO: Waiting for pod pod-projected-secrets-0dbb83a4-2f98-11e9-9b61-026654d605e3 to disappear
Feb 13 14:02:56.397: INFO: Pod pod-projected-secrets-0dbb83a4-2f98-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:02:56.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vbhw6" for this suite.
Feb 13 14:03:02.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:03:02.488: INFO: namespace: e2e-tests-projected-vbhw6, resource: bindings, ignored listing per whitelist
Feb 13 14:03:02.534: INFO: namespace e2e-tests-projected-vbhw6 deletion completed in 6.12526217s

• [SLOW TEST:10.290 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:03:02.536: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-13dd2c0c-2f98-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume configMaps
Feb 13 14:03:02.645: INFO: Waiting up to 5m0s for pod "pod-configmaps-13de35b7-2f98-11e9-9b61-026654d605e3" in namespace "e2e-tests-configmap-9vfpv" to be "success or failure"
Feb 13 14:03:02.650: INFO: Pod "pod-configmaps-13de35b7-2f98-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.092092ms
Feb 13 14:03:04.654: INFO: Pod "pod-configmaps-13de35b7-2f98-11e9-9b61-026654d605e3": Phase="Running", Reason="", readiness=true. Elapsed: 2.009570488s
Feb 13 14:03:06.659: INFO: Pod "pod-configmaps-13de35b7-2f98-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014185076s
STEP: Saw pod success
Feb 13 14:03:06.659: INFO: Pod "pod-configmaps-13de35b7-2f98-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:03:06.662: INFO: Trying to get logs from node cmp3 pod pod-configmaps-13de35b7-2f98-11e9-9b61-026654d605e3 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 14:03:06.683: INFO: Waiting for pod pod-configmaps-13de35b7-2f98-11e9-9b61-026654d605e3 to disappear
Feb 13 14:03:06.686: INFO: Pod pod-configmaps-13de35b7-2f98-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:03:06.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9vfpv" for this suite.
Feb 13 14:03:12.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:03:12.821: INFO: namespace: e2e-tests-configmap-9vfpv, resource: bindings, ignored listing per whitelist
Feb 13 14:03:12.821: INFO: namespace e2e-tests-configmap-9vfpv deletion completed in 6.129692261s

• [SLOW TEST:10.285 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:03:12.822: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 13 14:03:12.929: INFO: Waiting up to 5m0s for pod "pod-19feca42-2f98-11e9-9b61-026654d605e3" in namespace "e2e-tests-emptydir-pjdsx" to be "success or failure"
Feb 13 14:03:12.932: INFO: Pod "pod-19feca42-2f98-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.345328ms
Feb 13 14:03:14.936: INFO: Pod "pod-19feca42-2f98-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007459154s
Feb 13 14:03:16.940: INFO: Pod "pod-19feca42-2f98-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011323477s
STEP: Saw pod success
Feb 13 14:03:16.940: INFO: Pod "pod-19feca42-2f98-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:03:16.945: INFO: Trying to get logs from node cmp3 pod pod-19feca42-2f98-11e9-9b61-026654d605e3 container test-container: <nil>
STEP: delete the pod
Feb 13 14:03:16.966: INFO: Waiting for pod pod-19feca42-2f98-11e9-9b61-026654d605e3 to disappear
Feb 13 14:03:16.978: INFO: Pod pod-19feca42-2f98-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:03:16.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pjdsx" for this suite.
Feb 13 14:03:23.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:03:23.088: INFO: namespace: e2e-tests-emptydir-pjdsx, resource: bindings, ignored listing per whitelist
Feb 13 14:03:23.115: INFO: namespace e2e-tests-emptydir-pjdsx deletion completed in 6.132446793s

• [SLOW TEST:10.294 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:03:23.116: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 14:03:23.219: INFO: Waiting up to 5m0s for pod "downwardapi-volume-202138c4-2f98-11e9-9b61-026654d605e3" in namespace "e2e-tests-projected-hxnb4" to be "success or failure"
Feb 13 14:03:23.222: INFO: Pod "downwardapi-volume-202138c4-2f98-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.307292ms
Feb 13 14:03:25.227: INFO: Pod "downwardapi-volume-202138c4-2f98-11e9-9b61-026654d605e3": Phase="Running", Reason="", readiness=true. Elapsed: 2.008283869s
Feb 13 14:03:27.240: INFO: Pod "downwardapi-volume-202138c4-2f98-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020741951s
STEP: Saw pod success
Feb 13 14:03:27.240: INFO: Pod "downwardapi-volume-202138c4-2f98-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:03:27.246: INFO: Trying to get logs from node cmp2 pod downwardapi-volume-202138c4-2f98-11e9-9b61-026654d605e3 container client-container: <nil>
STEP: delete the pod
Feb 13 14:03:27.279: INFO: Waiting for pod downwardapi-volume-202138c4-2f98-11e9-9b61-026654d605e3 to disappear
Feb 13 14:03:27.284: INFO: Pod downwardapi-volume-202138c4-2f98-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:03:27.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hxnb4" for this suite.
Feb 13 14:03:33.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:03:33.358: INFO: namespace: e2e-tests-projected-hxnb4, resource: bindings, ignored listing per whitelist
Feb 13 14:03:33.419: INFO: namespace e2e-tests-projected-hxnb4 deletion completed in 6.130936976s

• [SLOW TEST:10.304 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:03:33.419: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-26s5
STEP: Creating a pod to test atomic-volume-subpath
Feb 13 14:03:33.539: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-26s5" in namespace "e2e-tests-subpath-hblxx" to be "success or failure"
Feb 13 14:03:33.543: INFO: Pod "pod-subpath-test-downwardapi-26s5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.332891ms
Feb 13 14:03:35.549: INFO: Pod "pod-subpath-test-downwardapi-26s5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009309136s
Feb 13 14:03:37.553: INFO: Pod "pod-subpath-test-downwardapi-26s5": Phase="Running", Reason="", readiness=false. Elapsed: 4.013624193s
Feb 13 14:03:39.564: INFO: Pod "pod-subpath-test-downwardapi-26s5": Phase="Running", Reason="", readiness=false. Elapsed: 6.025094508s
Feb 13 14:03:41.569: INFO: Pod "pod-subpath-test-downwardapi-26s5": Phase="Running", Reason="", readiness=false. Elapsed: 8.030131682s
Feb 13 14:03:43.574: INFO: Pod "pod-subpath-test-downwardapi-26s5": Phase="Running", Reason="", readiness=false. Elapsed: 10.034284211s
Feb 13 14:03:45.578: INFO: Pod "pod-subpath-test-downwardapi-26s5": Phase="Running", Reason="", readiness=false. Elapsed: 12.038759328s
Feb 13 14:03:47.583: INFO: Pod "pod-subpath-test-downwardapi-26s5": Phase="Running", Reason="", readiness=false. Elapsed: 14.043487823s
Feb 13 14:03:49.593: INFO: Pod "pod-subpath-test-downwardapi-26s5": Phase="Running", Reason="", readiness=false. Elapsed: 16.053186264s
Feb 13 14:03:51.596: INFO: Pod "pod-subpath-test-downwardapi-26s5": Phase="Running", Reason="", readiness=false. Elapsed: 18.056793425s
Feb 13 14:03:53.602: INFO: Pod "pod-subpath-test-downwardapi-26s5": Phase="Running", Reason="", readiness=false. Elapsed: 20.062710129s
Feb 13 14:03:55.608: INFO: Pod "pod-subpath-test-downwardapi-26s5": Phase="Running", Reason="", readiness=false. Elapsed: 22.068188162s
Feb 13 14:03:57.612: INFO: Pod "pod-subpath-test-downwardapi-26s5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.072367342s
STEP: Saw pod success
Feb 13 14:03:57.612: INFO: Pod "pod-subpath-test-downwardapi-26s5" satisfied condition "success or failure"
Feb 13 14:03:57.615: INFO: Trying to get logs from node cmp3 pod pod-subpath-test-downwardapi-26s5 container test-container-subpath-downwardapi-26s5: <nil>
STEP: delete the pod
Feb 13 14:03:57.636: INFO: Waiting for pod pod-subpath-test-downwardapi-26s5 to disappear
Feb 13 14:03:57.639: INFO: Pod pod-subpath-test-downwardapi-26s5 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-26s5
Feb 13 14:03:57.639: INFO: Deleting pod "pod-subpath-test-downwardapi-26s5" in namespace "e2e-tests-subpath-hblxx"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:03:57.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-hblxx" for this suite.
Feb 13 14:04:03.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:04:03.730: INFO: namespace: e2e-tests-subpath-hblxx, resource: bindings, ignored listing per whitelist
Feb 13 14:04:03.766: INFO: namespace e2e-tests-subpath-hblxx deletion completed in 6.11929953s

• [SLOW TEST:30.347 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:04:03.767: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Feb 13 14:04:03.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 --namespace=e2e-tests-kubectl-p6mg2 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb 13 14:04:06.823: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb 13 14:04:06.823: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:04:08.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-p6mg2" for this suite.
Feb 13 14:04:14.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:04:14.909: INFO: namespace: e2e-tests-kubectl-p6mg2, resource: bindings, ignored listing per whitelist
Feb 13 14:04:14.965: INFO: namespace e2e-tests-kubectl-p6mg2 deletion completed in 6.127293332s

• [SLOW TEST:11.199 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:04:14.966: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-3f0902ab-2f98-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume secrets
Feb 13 14:04:15.075: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3f0a3c3d-2f98-11e9-9b61-026654d605e3" in namespace "e2e-tests-projected-j7xrm" to be "success or failure"
Feb 13 14:04:15.079: INFO: Pod "pod-projected-secrets-3f0a3c3d-2f98-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.145577ms
Feb 13 14:04:17.084: INFO: Pod "pod-projected-secrets-3f0a3c3d-2f98-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008627558s
STEP: Saw pod success
Feb 13 14:04:17.084: INFO: Pod "pod-projected-secrets-3f0a3c3d-2f98-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:04:17.087: INFO: Trying to get logs from node cmp3 pod pod-projected-secrets-3f0a3c3d-2f98-11e9-9b61-026654d605e3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 13 14:04:17.111: INFO: Waiting for pod pod-projected-secrets-3f0a3c3d-2f98-11e9-9b61-026654d605e3 to disappear
Feb 13 14:04:17.115: INFO: Pod pod-projected-secrets-3f0a3c3d-2f98-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:04:17.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j7xrm" for this suite.
Feb 13 14:04:23.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:04:23.153: INFO: namespace: e2e-tests-projected-j7xrm, resource: bindings, ignored listing per whitelist
Feb 13 14:04:23.241: INFO: namespace e2e-tests-projected-j7xrm deletion completed in 6.12148655s

• [SLOW TEST:8.275 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:04:23.241: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 14:04:23.343: INFO: Waiting up to 5m0s for pod "downwardapi-volume-43f75024-2f98-11e9-9b61-026654d605e3" in namespace "e2e-tests-downward-api-zd22j" to be "success or failure"
Feb 13 14:04:23.347: INFO: Pod "downwardapi-volume-43f75024-2f98-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.155052ms
Feb 13 14:04:25.351: INFO: Pod "downwardapi-volume-43f75024-2f98-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007566651s
Feb 13 14:04:27.355: INFO: Pod "downwardapi-volume-43f75024-2f98-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011468422s
STEP: Saw pod success
Feb 13 14:04:27.355: INFO: Pod "downwardapi-volume-43f75024-2f98-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:04:27.358: INFO: Trying to get logs from node cmp3 pod downwardapi-volume-43f75024-2f98-11e9-9b61-026654d605e3 container client-container: <nil>
STEP: delete the pod
Feb 13 14:04:27.377: INFO: Waiting for pod downwardapi-volume-43f75024-2f98-11e9-9b61-026654d605e3 to disappear
Feb 13 14:04:27.380: INFO: Pod downwardapi-volume-43f75024-2f98-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:04:27.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zd22j" for this suite.
Feb 13 14:04:33.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:04:33.410: INFO: namespace: e2e-tests-downward-api-zd22j, resource: bindings, ignored listing per whitelist
Feb 13 14:04:33.511: INFO: namespace e2e-tests-downward-api-zd22j deletion completed in 6.125740674s

• [SLOW TEST:10.270 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:04:33.511: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 14:04:33.610: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4a15e28a-2f98-11e9-9b61-026654d605e3" in namespace "e2e-tests-downward-api-fldnw" to be "success or failure"
Feb 13 14:04:33.613: INFO: Pod "downwardapi-volume-4a15e28a-2f98-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.849155ms
Feb 13 14:04:35.617: INFO: Pod "downwardapi-volume-4a15e28a-2f98-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00683074s
Feb 13 14:04:37.622: INFO: Pod "downwardapi-volume-4a15e28a-2f98-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011550722s
STEP: Saw pod success
Feb 13 14:04:37.622: INFO: Pod "downwardapi-volume-4a15e28a-2f98-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:04:37.625: INFO: Trying to get logs from node cmp3 pod downwardapi-volume-4a15e28a-2f98-11e9-9b61-026654d605e3 container client-container: <nil>
STEP: delete the pod
Feb 13 14:04:37.696: INFO: Waiting for pod downwardapi-volume-4a15e28a-2f98-11e9-9b61-026654d605e3 to disappear
Feb 13 14:04:37.699: INFO: Pod downwardapi-volume-4a15e28a-2f98-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:04:37.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fldnw" for this suite.
Feb 13 14:04:43.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:04:43.815: INFO: namespace: e2e-tests-downward-api-fldnw, resource: bindings, ignored listing per whitelist
Feb 13 14:04:43.827: INFO: namespace e2e-tests-downward-api-fldnw deletion completed in 6.123189687s

• [SLOW TEST:10.316 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:04:43.829: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 13 14:04:51.998: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 13 14:04:52.002: INFO: Pod pod-with-poststart-http-hook still exists
Feb 13 14:04:54.003: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 13 14:04:54.007: INFO: Pod pod-with-poststart-http-hook still exists
Feb 13 14:04:56.003: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 13 14:04:56.012: INFO: Pod pod-with-poststart-http-hook still exists
Feb 13 14:04:58.003: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 13 14:04:58.006: INFO: Pod pod-with-poststart-http-hook still exists
Feb 13 14:05:00.003: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 13 14:05:00.006: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:05:00.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-npvkl" for this suite.
Feb 13 14:05:22.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:05:22.065: INFO: namespace: e2e-tests-container-lifecycle-hook-npvkl, resource: bindings, ignored listing per whitelist
Feb 13 14:05:22.138: INFO: namespace e2e-tests-container-lifecycle-hook-npvkl deletion completed in 22.126357598s

• [SLOW TEST:38.309 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:05:22.139: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Feb 13 14:05:26.308: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:05:50.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-zzxtn" for this suite.
Feb 13 14:05:56.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:05:56.468: INFO: namespace: e2e-tests-namespaces-zzxtn, resource: bindings, ignored listing per whitelist
Feb 13 14:05:56.530: INFO: namespace e2e-tests-namespaces-zzxtn deletion completed in 6.1411094s
STEP: Destroying namespace "e2e-tests-nsdeletetest-jqx26" for this suite.
Feb 13 14:05:56.533: INFO: Namespace e2e-tests-nsdeletetest-jqx26 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-66ks9" for this suite.
Feb 13 14:06:02.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:06:02.645: INFO: namespace: e2e-tests-nsdeletetest-66ks9, resource: bindings, ignored listing per whitelist
Feb 13 14:06:02.669: INFO: namespace e2e-tests-nsdeletetest-66ks9 deletion completed in 6.135103344s

• [SLOW TEST:40.530 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:06:02.670: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 14:06:02.772: INFO: (0) /api/v1/nodes/cmp1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.506591ms)
Feb 13 14:06:02.776: INFO: (1) /api/v1/nodes/cmp1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.975027ms)
Feb 13 14:06:02.780: INFO: (2) /api/v1/nodes/cmp1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.811994ms)
Feb 13 14:06:02.783: INFO: (3) /api/v1/nodes/cmp1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.634403ms)
Feb 13 14:06:02.787: INFO: (4) /api/v1/nodes/cmp1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.844143ms)
Feb 13 14:06:02.791: INFO: (5) /api/v1/nodes/cmp1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.810979ms)
Feb 13 14:06:02.795: INFO: (6) /api/v1/nodes/cmp1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.850845ms)
Feb 13 14:06:02.799: INFO: (7) /api/v1/nodes/cmp1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.916093ms)
Feb 13 14:06:02.803: INFO: (8) /api/v1/nodes/cmp1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.687421ms)
Feb 13 14:06:02.807: INFO: (9) /api/v1/nodes/cmp1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.187653ms)
Feb 13 14:06:02.811: INFO: (10) /api/v1/nodes/cmp1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.001533ms)
Feb 13 14:06:02.815: INFO: (11) /api/v1/nodes/cmp1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.03517ms)
Feb 13 14:06:02.819: INFO: (12) /api/v1/nodes/cmp1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.906184ms)
Feb 13 14:06:02.823: INFO: (13) /api/v1/nodes/cmp1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.966128ms)
Feb 13 14:06:02.828: INFO: (14) /api/v1/nodes/cmp1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.761348ms)
Feb 13 14:06:02.836: INFO: (15) /api/v1/nodes/cmp1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 8.210543ms)
Feb 13 14:06:02.841: INFO: (16) /api/v1/nodes/cmp1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.568467ms)
Feb 13 14:06:02.845: INFO: (17) /api/v1/nodes/cmp1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.273737ms)
Feb 13 14:06:02.849: INFO: (18) /api/v1/nodes/cmp1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.185209ms)
Feb 13 14:06:02.853: INFO: (19) /api/v1/nodes/cmp1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.921716ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:06:02.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-5gpb4" for this suite.
Feb 13 14:06:08.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:06:08.927: INFO: namespace: e2e-tests-proxy-5gpb4, resource: bindings, ignored listing per whitelist
Feb 13 14:06:08.987: INFO: namespace e2e-tests-proxy-5gpb4 deletion completed in 6.130086353s

• [SLOW TEST:6.318 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:06:08.987: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 14:06:09.081: INFO: Waiting up to 5m0s for pod "downwardapi-volume-82fdbc03-2f98-11e9-9b61-026654d605e3" in namespace "e2e-tests-downward-api-z98gp" to be "success or failure"
Feb 13 14:06:09.084: INFO: Pod "downwardapi-volume-82fdbc03-2f98-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.800419ms
Feb 13 14:06:11.088: INFO: Pod "downwardapi-volume-82fdbc03-2f98-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007253428s
Feb 13 14:06:13.092: INFO: Pod "downwardapi-volume-82fdbc03-2f98-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011226142s
STEP: Saw pod success
Feb 13 14:06:13.092: INFO: Pod "downwardapi-volume-82fdbc03-2f98-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:06:13.095: INFO: Trying to get logs from node cmp3 pod downwardapi-volume-82fdbc03-2f98-11e9-9b61-026654d605e3 container client-container: <nil>
STEP: delete the pod
Feb 13 14:06:13.118: INFO: Waiting for pod downwardapi-volume-82fdbc03-2f98-11e9-9b61-026654d605e3 to disappear
Feb 13 14:06:13.121: INFO: Pod downwardapi-volume-82fdbc03-2f98-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:06:13.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-z98gp" for this suite.
Feb 13 14:06:19.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:06:19.145: INFO: namespace: e2e-tests-downward-api-z98gp, resource: bindings, ignored listing per whitelist
Feb 13 14:06:19.248: INFO: namespace e2e-tests-downward-api-z98gp deletion completed in 6.122220105s

• [SLOW TEST:10.261 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:06:19.248: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-891d0bc0-2f98-11e9-9b61-026654d605e3
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-891d0bc0-2f98-11e9-9b61-026654d605e3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:07:37.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2kpx7" for this suite.
Feb 13 14:07:59.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:08:00.013: INFO: namespace: e2e-tests-projected-2kpx7, resource: bindings, ignored listing per whitelist
Feb 13 14:08:00.068: INFO: namespace e2e-tests-projected-2kpx7 deletion completed in 22.135188669s

• [SLOW TEST:100.820 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:08:00.069: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 14:08:04.208: INFO: Waiting up to 5m0s for pod "client-envvars-c79d868b-2f98-11e9-9b61-026654d605e3" in namespace "e2e-tests-pods-6wvs5" to be "success or failure"
Feb 13 14:08:04.212: INFO: Pod "client-envvars-c79d868b-2f98-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.305617ms
Feb 13 14:08:06.216: INFO: Pod "client-envvars-c79d868b-2f98-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008864917s
Feb 13 14:08:08.221: INFO: Pod "client-envvars-c79d868b-2f98-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013241635s
STEP: Saw pod success
Feb 13 14:08:08.221: INFO: Pod "client-envvars-c79d868b-2f98-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:08:08.224: INFO: Trying to get logs from node cmp3 pod client-envvars-c79d868b-2f98-11e9-9b61-026654d605e3 container env3cont: <nil>
STEP: delete the pod
Feb 13 14:08:08.245: INFO: Waiting for pod client-envvars-c79d868b-2f98-11e9-9b61-026654d605e3 to disappear
Feb 13 14:08:08.248: INFO: Pod client-envvars-c79d868b-2f98-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:08:08.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-6wvs5" for this suite.
Feb 13 14:08:50.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:08:50.362: INFO: namespace: e2e-tests-pods-6wvs5, resource: bindings, ignored listing per whitelist
Feb 13 14:08:50.374: INFO: namespace e2e-tests-pods-6wvs5 deletion completed in 42.121023087s

• [SLOW TEST:50.305 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:08:50.374: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-k8hkr
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 13 14:08:50.463: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 13 14:09:14.549: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 192.168.113.84 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-k8hkr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 14:09:14.549: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
Feb 13 14:09:15.913: INFO: Found all expected endpoints: [netserver-0]
Feb 13 14:09:15.918: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 192.168.197.6 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-k8hkr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 14:09:15.918: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
Feb 13 14:09:17.093: INFO: Found all expected endpoints: [netserver-1]
Feb 13 14:09:17.097: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 192.168.119.207 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-k8hkr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 14:09:17.097: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
Feb 13 14:09:18.307: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:09:18.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-k8hkr" for this suite.
Feb 13 14:09:40.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:09:40.350: INFO: namespace: e2e-tests-pod-network-test-k8hkr, resource: bindings, ignored listing per whitelist
Feb 13 14:09:40.450: INFO: namespace e2e-tests-pod-network-test-k8hkr deletion completed in 22.137190759s

• [SLOW TEST:50.076 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:09:40.451: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-0109d51c-2f99-11e9-9b61-026654d605e3
Feb 13 14:09:40.553: INFO: Pod name my-hostname-basic-0109d51c-2f99-11e9-9b61-026654d605e3: Found 0 pods out of 1
Feb 13 14:09:45.563: INFO: Pod name my-hostname-basic-0109d51c-2f99-11e9-9b61-026654d605e3: Found 1 pods out of 1
Feb 13 14:09:45.563: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-0109d51c-2f99-11e9-9b61-026654d605e3" are running
Feb 13 14:09:45.566: INFO: Pod "my-hostname-basic-0109d51c-2f99-11e9-9b61-026654d605e3-w5r72" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-13 14:09:40 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-13 14:09:43 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-13 14:09:43 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-13 14:09:40 +0000 UTC Reason: Message:}])
Feb 13 14:09:45.566: INFO: Trying to dial the pod
Feb 13 14:09:50.581: INFO: Controller my-hostname-basic-0109d51c-2f99-11e9-9b61-026654d605e3: Got expected result from replica 1 [my-hostname-basic-0109d51c-2f99-11e9-9b61-026654d605e3-w5r72]: "my-hostname-basic-0109d51c-2f99-11e9-9b61-026654d605e3-w5r72", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:09:50.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-xr4n6" for this suite.
Feb 13 14:09:56.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:09:56.651: INFO: namespace: e2e-tests-replication-controller-xr4n6, resource: bindings, ignored listing per whitelist
Feb 13 14:09:56.713: INFO: namespace e2e-tests-replication-controller-xr4n6 deletion completed in 6.127581973s

• [SLOW TEST:16.262 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:09:56.714: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-0abae667-2f99-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume configMaps
Feb 13 14:09:56.818: INFO: Waiting up to 5m0s for pod "pod-configmaps-0abc02db-2f99-11e9-9b61-026654d605e3" in namespace "e2e-tests-configmap-67whp" to be "success or failure"
Feb 13 14:09:56.821: INFO: Pod "pod-configmaps-0abc02db-2f99-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.133464ms
Feb 13 14:09:58.826: INFO: Pod "pod-configmaps-0abc02db-2f99-11e9-9b61-026654d605e3": Phase="Running", Reason="", readiness=true. Elapsed: 2.00805838s
Feb 13 14:10:00.831: INFO: Pod "pod-configmaps-0abc02db-2f99-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012802068s
STEP: Saw pod success
Feb 13 14:10:00.831: INFO: Pod "pod-configmaps-0abc02db-2f99-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:10:00.835: INFO: Trying to get logs from node cmp3 pod pod-configmaps-0abc02db-2f99-11e9-9b61-026654d605e3 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 14:10:00.858: INFO: Waiting for pod pod-configmaps-0abc02db-2f99-11e9-9b61-026654d605e3 to disappear
Feb 13 14:10:00.860: INFO: Pod pod-configmaps-0abc02db-2f99-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:10:00.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-67whp" for this suite.
Feb 13 14:10:06.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:10:06.903: INFO: namespace: e2e-tests-configmap-67whp, resource: bindings, ignored listing per whitelist
Feb 13 14:10:06.992: INFO: namespace e2e-tests-configmap-67whp deletion completed in 6.127093848s

• [SLOW TEST:10.278 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:10:06.992: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0213 14:10:37.643651      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 13 14:10:37.643: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:10:37.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-952kj" for this suite.
Feb 13 14:10:43.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:10:43.707: INFO: namespace: e2e-tests-gc-952kj, resource: bindings, ignored listing per whitelist
Feb 13 14:10:43.771: INFO: namespace e2e-tests-gc-952kj deletion completed in 6.124039493s

• [SLOW TEST:36.779 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:10:43.772: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 14:10:43.880: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Feb 13 14:10:43.887: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-fk76g/daemonsets","resourceVersion":"2512319"},"items":null}

Feb 13 14:10:43.890: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-fk76g/pods","resourceVersion":"2512319"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:10:43.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-fk76g" for this suite.
Feb 13 14:10:49.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:10:49.954: INFO: namespace: e2e-tests-daemonsets-fk76g, resource: bindings, ignored listing per whitelist
Feb 13 14:10:50.030: INFO: namespace e2e-tests-daemonsets-fk76g deletion completed in 6.124016844s

S [SKIPPING] [6.258 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Feb 13 14:10:43.880: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:10:50.030: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 13 14:10:50.122: INFO: Waiting up to 5m0s for pod "downward-api-2a812d70-2f99-11e9-9b61-026654d605e3" in namespace "e2e-tests-downward-api-5vnmj" to be "success or failure"
Feb 13 14:10:50.127: INFO: Pod "downward-api-2a812d70-2f99-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.582869ms
Feb 13 14:10:52.131: INFO: Pod "downward-api-2a812d70-2f99-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008987464s
STEP: Saw pod success
Feb 13 14:10:52.131: INFO: Pod "downward-api-2a812d70-2f99-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:10:52.134: INFO: Trying to get logs from node cmp2 pod downward-api-2a812d70-2f99-11e9-9b61-026654d605e3 container dapi-container: <nil>
STEP: delete the pod
Feb 13 14:10:52.157: INFO: Waiting for pod downward-api-2a812d70-2f99-11e9-9b61-026654d605e3 to disappear
Feb 13 14:10:52.160: INFO: Pod downward-api-2a812d70-2f99-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:10:52.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5vnmj" for this suite.
Feb 13 14:10:58.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:10:58.191: INFO: namespace: e2e-tests-downward-api-5vnmj, resource: bindings, ignored listing per whitelist
Feb 13 14:10:58.286: INFO: namespace e2e-tests-downward-api-5vnmj deletion completed in 6.122060767s

• [SLOW TEST:8.256 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:10:58.287: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:10:58.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-8cm29" for this suite.
Feb 13 14:11:20.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:11:20.424: INFO: namespace: e2e-tests-pods-8cm29, resource: bindings, ignored listing per whitelist
Feb 13 14:11:20.533: INFO: namespace e2e-tests-pods-8cm29 deletion completed in 22.134822673s

• [SLOW TEST:22.246 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:11:20.533: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 14:11:20.639: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3cb1b9f3-2f99-11e9-9b61-026654d605e3" in namespace "e2e-tests-projected-lbd4p" to be "success or failure"
Feb 13 14:11:20.642: INFO: Pod "downwardapi-volume-3cb1b9f3-2f99-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.87222ms
Feb 13 14:11:22.646: INFO: Pod "downwardapi-volume-3cb1b9f3-2f99-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007030847s
Feb 13 14:11:24.650: INFO: Pod "downwardapi-volume-3cb1b9f3-2f99-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010707806s
STEP: Saw pod success
Feb 13 14:11:24.650: INFO: Pod "downwardapi-volume-3cb1b9f3-2f99-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:11:24.658: INFO: Trying to get logs from node cmp3 pod downwardapi-volume-3cb1b9f3-2f99-11e9-9b61-026654d605e3 container client-container: <nil>
STEP: delete the pod
Feb 13 14:11:24.687: INFO: Waiting for pod downwardapi-volume-3cb1b9f3-2f99-11e9-9b61-026654d605e3 to disappear
Feb 13 14:11:24.690: INFO: Pod downwardapi-volume-3cb1b9f3-2f99-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:11:24.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lbd4p" for this suite.
Feb 13 14:11:30.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:11:30.757: INFO: namespace: e2e-tests-projected-lbd4p, resource: bindings, ignored listing per whitelist
Feb 13 14:11:30.824: INFO: namespace e2e-tests-projected-lbd4p deletion completed in 6.12970674s

• [SLOW TEST:10.291 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:11:30.825: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 14:11:54.952: INFO: Container started at 2019-02-13 14:11:33 +0000 UTC, pod became ready at 2019-02-13 14:11:53 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:11:54.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-blkxh" for this suite.
Feb 13 14:12:16.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:12:17.018: INFO: namespace: e2e-tests-container-probe-blkxh, resource: bindings, ignored listing per whitelist
Feb 13 14:12:17.093: INFO: namespace e2e-tests-container-probe-blkxh deletion completed in 22.136978578s

• [SLOW TEST:46.268 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:12:17.093: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-5e67adc0-2f99-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume configMaps
Feb 13 14:12:17.201: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5e68cfb6-2f99-11e9-9b61-026654d605e3" in namespace "e2e-tests-projected-2s7gk" to be "success or failure"
Feb 13 14:12:17.205: INFO: Pod "pod-projected-configmaps-5e68cfb6-2f99-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.664874ms
Feb 13 14:12:19.209: INFO: Pod "pod-projected-configmaps-5e68cfb6-2f99-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007651273s
Feb 13 14:12:21.213: INFO: Pod "pod-projected-configmaps-5e68cfb6-2f99-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011851689s
STEP: Saw pod success
Feb 13 14:12:21.213: INFO: Pod "pod-projected-configmaps-5e68cfb6-2f99-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:12:21.217: INFO: Trying to get logs from node cmp3 pod pod-projected-configmaps-5e68cfb6-2f99-11e9-9b61-026654d605e3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 14:12:21.235: INFO: Waiting for pod pod-projected-configmaps-5e68cfb6-2f99-11e9-9b61-026654d605e3 to disappear
Feb 13 14:12:21.238: INFO: Pod pod-projected-configmaps-5e68cfb6-2f99-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:12:21.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2s7gk" for this suite.
Feb 13 14:12:27.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:12:27.273: INFO: namespace: e2e-tests-projected-2s7gk, resource: bindings, ignored listing per whitelist
Feb 13 14:12:27.378: INFO: namespace e2e-tests-projected-2s7gk deletion completed in 6.135563669s

• [SLOW TEST:10.284 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:12:27.378: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 13 14:12:27.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-rcwzb'
Feb 13 14:12:27.618: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb 13 14:12:27.618: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Feb 13 14:12:29.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-rcwzb'
Feb 13 14:12:29.761: INFO: stderr: ""
Feb 13 14:12:29.761: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:12:29.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rcwzb" for this suite.
Feb 13 14:13:51.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:13:51.887: INFO: namespace: e2e-tests-kubectl-rcwzb, resource: bindings, ignored listing per whitelist
Feb 13 14:13:51.897: INFO: namespace e2e-tests-kubectl-rcwzb deletion completed in 1m22.130487964s

• [SLOW TEST:84.519 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:13:51.897: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-96e9b6e9-2f99-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume secrets
Feb 13 14:13:52.005: INFO: Waiting up to 5m0s for pod "pod-secrets-96ead3f5-2f99-11e9-9b61-026654d605e3" in namespace "e2e-tests-secrets-8zjjh" to be "success or failure"
Feb 13 14:13:52.010: INFO: Pod "pod-secrets-96ead3f5-2f99-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.69185ms
Feb 13 14:13:54.014: INFO: Pod "pod-secrets-96ead3f5-2f99-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00885477s
Feb 13 14:13:56.018: INFO: Pod "pod-secrets-96ead3f5-2f99-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012988283s
STEP: Saw pod success
Feb 13 14:13:56.018: INFO: Pod "pod-secrets-96ead3f5-2f99-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:13:56.021: INFO: Trying to get logs from node cmp3 pod pod-secrets-96ead3f5-2f99-11e9-9b61-026654d605e3 container secret-volume-test: <nil>
STEP: delete the pod
Feb 13 14:13:56.042: INFO: Waiting for pod pod-secrets-96ead3f5-2f99-11e9-9b61-026654d605e3 to disappear
Feb 13 14:13:56.045: INFO: Pod pod-secrets-96ead3f5-2f99-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:13:56.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-8zjjh" for this suite.
Feb 13 14:14:02.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:14:02.170: INFO: namespace: e2e-tests-secrets-8zjjh, resource: bindings, ignored listing per whitelist
Feb 13 14:14:02.173: INFO: namespace e2e-tests-secrets-8zjjh deletion completed in 6.123219683s

• [SLOW TEST:10.277 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:14:02.174: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 13 14:14:02.281: INFO: Waiting up to 5m0s for pod "pod-9d0a3621-2f99-11e9-9b61-026654d605e3" in namespace "e2e-tests-emptydir-cqr9x" to be "success or failure"
Feb 13 14:14:02.284: INFO: Pod "pod-9d0a3621-2f99-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.239573ms
Feb 13 14:14:04.289: INFO: Pod "pod-9d0a3621-2f99-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007971476s
Feb 13 14:14:06.293: INFO: Pod "pod-9d0a3621-2f99-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011788432s
STEP: Saw pod success
Feb 13 14:14:06.293: INFO: Pod "pod-9d0a3621-2f99-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:14:06.296: INFO: Trying to get logs from node cmp3 pod pod-9d0a3621-2f99-11e9-9b61-026654d605e3 container test-container: <nil>
STEP: delete the pod
Feb 13 14:14:06.319: INFO: Waiting for pod pod-9d0a3621-2f99-11e9-9b61-026654d605e3 to disappear
Feb 13 14:14:06.321: INFO: Pod pod-9d0a3621-2f99-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:14:06.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cqr9x" for this suite.
Feb 13 14:14:12.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:14:12.346: INFO: namespace: e2e-tests-emptydir-cqr9x, resource: bindings, ignored listing per whitelist
Feb 13 14:14:12.463: INFO: namespace e2e-tests-emptydir-cqr9x deletion completed in 6.137662575s

• [SLOW TEST:10.290 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:14:12.464: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Feb 13 14:14:12.564: INFO: Waiting up to 5m0s for pod "var-expansion-a32b8388-2f99-11e9-9b61-026654d605e3" in namespace "e2e-tests-var-expansion-tx52r" to be "success or failure"
Feb 13 14:14:12.567: INFO: Pod "var-expansion-a32b8388-2f99-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.939222ms
Feb 13 14:14:14.572: INFO: Pod "var-expansion-a32b8388-2f99-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007617279s
Feb 13 14:14:16.576: INFO: Pod "var-expansion-a32b8388-2f99-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012034522s
STEP: Saw pod success
Feb 13 14:14:16.576: INFO: Pod "var-expansion-a32b8388-2f99-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:14:16.579: INFO: Trying to get logs from node cmp3 pod var-expansion-a32b8388-2f99-11e9-9b61-026654d605e3 container dapi-container: <nil>
STEP: delete the pod
Feb 13 14:14:16.632: INFO: Waiting for pod var-expansion-a32b8388-2f99-11e9-9b61-026654d605e3 to disappear
Feb 13 14:14:16.635: INFO: Pod var-expansion-a32b8388-2f99-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:14:16.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-tx52r" for this suite.
Feb 13 14:14:22.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:14:22.744: INFO: namespace: e2e-tests-var-expansion-tx52r, resource: bindings, ignored listing per whitelist
Feb 13 14:14:22.760: INFO: namespace e2e-tests-var-expansion-tx52r deletion completed in 6.12074664s

• [SLOW TEST:10.296 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:14:22.760: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-22fh5
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 13 14:14:22.853: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 13 14:14:44.940: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.113.99:8080/dial?request=hostName&protocol=http&host=192.168.197.8&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-22fh5 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 14:14:44.940: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
Feb 13 14:14:45.108: INFO: Waiting for endpoints: map[]
Feb 13 14:14:45.112: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.113.99:8080/dial?request=hostName&protocol=http&host=192.168.119.235&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-22fh5 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 14:14:45.112: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
Feb 13 14:14:45.289: INFO: Waiting for endpoints: map[]
Feb 13 14:14:45.292: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.113.99:8080/dial?request=hostName&protocol=http&host=192.168.113.98&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-22fh5 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 14:14:45.293: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
Feb 13 14:14:45.580: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:14:45.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-22fh5" for this suite.
Feb 13 14:15:07.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:15:07.666: INFO: namespace: e2e-tests-pod-network-test-22fh5, resource: bindings, ignored listing per whitelist
Feb 13 14:15:07.715: INFO: namespace e2e-tests-pod-network-test-22fh5 deletion completed in 22.130590699s

• [SLOW TEST:44.954 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:15:07.716: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 14:15:07.811: INFO: Creating ReplicaSet my-hostname-basic-c41b060a-2f99-11e9-9b61-026654d605e3
Feb 13 14:15:07.823: INFO: Pod name my-hostname-basic-c41b060a-2f99-11e9-9b61-026654d605e3: Found 0 pods out of 1
Feb 13 14:15:12.837: INFO: Pod name my-hostname-basic-c41b060a-2f99-11e9-9b61-026654d605e3: Found 1 pods out of 1
Feb 13 14:15:12.837: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-c41b060a-2f99-11e9-9b61-026654d605e3" is running
Feb 13 14:15:12.840: INFO: Pod "my-hostname-basic-c41b060a-2f99-11e9-9b61-026654d605e3-4sgxt" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-13 14:15:07 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-13 14:15:10 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-13 14:15:10 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-13 14:15:07 +0000 UTC Reason: Message:}])
Feb 13 14:15:12.840: INFO: Trying to dial the pod
Feb 13 14:15:17.856: INFO: Controller my-hostname-basic-c41b060a-2f99-11e9-9b61-026654d605e3: Got expected result from replica 1 [my-hostname-basic-c41b060a-2f99-11e9-9b61-026654d605e3-4sgxt]: "my-hostname-basic-c41b060a-2f99-11e9-9b61-026654d605e3-4sgxt", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:15:17.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-756z2" for this suite.
Feb 13 14:15:23.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:15:23.956: INFO: namespace: e2e-tests-replicaset-756z2, resource: bindings, ignored listing per whitelist
Feb 13 14:15:23.992: INFO: namespace e2e-tests-replicaset-756z2 deletion completed in 6.130790483s

• [SLOW TEST:16.276 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:15:23.993: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-cdce38a5-2f99-11e9-9b61-026654d605e3
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-cdce38a5-2f99-11e9-9b61-026654d605e3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:16:42.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-gbjx8" for this suite.
Feb 13 14:17:04.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:17:04.743: INFO: namespace: e2e-tests-configmap-gbjx8, resource: bindings, ignored listing per whitelist
Feb 13 14:17:04.768: INFO: namespace e2e-tests-configmap-gbjx8 deletion completed in 22.133654763s

• [SLOW TEST:100.775 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:17:04.769: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-cz4m5/configmap-test-09e0e668-2f9a-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume configMaps
Feb 13 14:17:04.885: INFO: Waiting up to 5m0s for pod "pod-configmaps-09e210f4-2f9a-11e9-9b61-026654d605e3" in namespace "e2e-tests-configmap-cz4m5" to be "success or failure"
Feb 13 14:17:04.888: INFO: Pod "pod-configmaps-09e210f4-2f9a-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.895222ms
Feb 13 14:17:06.899: INFO: Pod "pod-configmaps-09e210f4-2f9a-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013607125s
Feb 13 14:17:08.908: INFO: Pod "pod-configmaps-09e210f4-2f9a-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022854676s
STEP: Saw pod success
Feb 13 14:17:08.908: INFO: Pod "pod-configmaps-09e210f4-2f9a-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:17:08.912: INFO: Trying to get logs from node cmp3 pod pod-configmaps-09e210f4-2f9a-11e9-9b61-026654d605e3 container env-test: <nil>
STEP: delete the pod
Feb 13 14:17:08.933: INFO: Waiting for pod pod-configmaps-09e210f4-2f9a-11e9-9b61-026654d605e3 to disappear
Feb 13 14:17:08.937: INFO: Pod pod-configmaps-09e210f4-2f9a-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:17:08.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-cz4m5" for this suite.
Feb 13 14:17:14.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:17:15.004: INFO: namespace: e2e-tests-configmap-cz4m5, resource: bindings, ignored listing per whitelist
Feb 13 14:17:15.066: INFO: namespace e2e-tests-configmap-cz4m5 deletion completed in 6.123579841s

• [SLOW TEST:10.298 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:17:15.067: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb 13 14:17:19.188: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-10031663-2f9a-11e9-9b61-026654d605e3,GenerateName:,Namespace:e2e-tests-events-zbvzx,SelfLink:/api/v1/namespaces/e2e-tests-events-zbvzx/pods/send-events-10031663-2f9a-11e9-9b61-026654d605e3,UID:1003ce08-2f9a-11e9-85f4-fa163e429998,ResourceVersion:2513791,Generation:0,CreationTimestamp:2019-02-13 14:17:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 161767814,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dszhf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dszhf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-dszhf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cmp3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421948dc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421948de0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:17:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:17:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:17:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:17:15 +0000 UTC  }],Message:,Reason:,HostIP:10.11.1.3,PodIP:192.168.113.106,StartTime:2019-02-13 14:17:15 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-02-13 14:17:16 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 containerd://8f8e5f46a20f95e5db097bd138345abc8f905ea5994783658041b34041dea771}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Feb 13 14:17:21.192: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb 13 14:17:23.197: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:17:23.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-zbvzx" for this suite.
Feb 13 14:18:01.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:18:01.281: INFO: namespace: e2e-tests-events-zbvzx, resource: bindings, ignored listing per whitelist
Feb 13 14:18:01.353: INFO: namespace e2e-tests-events-zbvzx deletion completed in 38.143934735s

• [SLOW TEST:46.287 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:18:01.354: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-2b9bfe8a-2f9a-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume secrets
Feb 13 14:18:01.485: INFO: Waiting up to 5m0s for pod "pod-secrets-2b9e5ac7-2f9a-11e9-9b61-026654d605e3" in namespace "e2e-tests-secrets-52nfx" to be "success or failure"
Feb 13 14:18:01.488: INFO: Pod "pod-secrets-2b9e5ac7-2f9a-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.090328ms
Feb 13 14:18:03.493: INFO: Pod "pod-secrets-2b9e5ac7-2f9a-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007506326s
STEP: Saw pod success
Feb 13 14:18:03.493: INFO: Pod "pod-secrets-2b9e5ac7-2f9a-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:18:03.496: INFO: Trying to get logs from node cmp3 pod pod-secrets-2b9e5ac7-2f9a-11e9-9b61-026654d605e3 container secret-volume-test: <nil>
STEP: delete the pod
Feb 13 14:18:03.525: INFO: Waiting for pod pod-secrets-2b9e5ac7-2f9a-11e9-9b61-026654d605e3 to disappear
Feb 13 14:18:03.528: INFO: Pod pod-secrets-2b9e5ac7-2f9a-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:18:03.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-52nfx" for this suite.
Feb 13 14:18:09.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:18:09.640: INFO: namespace: e2e-tests-secrets-52nfx, resource: bindings, ignored listing per whitelist
Feb 13 14:18:09.659: INFO: namespace e2e-tests-secrets-52nfx deletion completed in 6.125840734s

• [SLOW TEST:8.305 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:18:09.659: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb 13 14:18:09.752: INFO: Waiting up to 5m0s for pod "pod-308b50e3-2f9a-11e9-9b61-026654d605e3" in namespace "e2e-tests-emptydir-9gnnx" to be "success or failure"
Feb 13 14:18:09.755: INFO: Pod "pod-308b50e3-2f9a-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.924485ms
Feb 13 14:18:11.765: INFO: Pod "pod-308b50e3-2f9a-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013379362s
STEP: Saw pod success
Feb 13 14:18:11.765: INFO: Pod "pod-308b50e3-2f9a-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:18:11.768: INFO: Trying to get logs from node cmp3 pod pod-308b50e3-2f9a-11e9-9b61-026654d605e3 container test-container: <nil>
STEP: delete the pod
Feb 13 14:18:11.788: INFO: Waiting for pod pod-308b50e3-2f9a-11e9-9b61-026654d605e3 to disappear
Feb 13 14:18:11.791: INFO: Pod pod-308b50e3-2f9a-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:18:11.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-9gnnx" for this suite.
Feb 13 14:18:17.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:18:17.903: INFO: namespace: e2e-tests-emptydir-9gnnx, resource: bindings, ignored listing per whitelist
Feb 13 14:18:17.946: INFO: namespace e2e-tests-emptydir-9gnnx deletion completed in 6.150019239s

• [SLOW TEST:8.287 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:18:17.946: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-357dea29-2f9a-11e9-9b61-026654d605e3
STEP: Creating secret with name s-test-opt-upd-357dea6c-2f9a-11e9-9b61-026654d605e3
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-357dea29-2f9a-11e9-9b61-026654d605e3
STEP: Updating secret s-test-opt-upd-357dea6c-2f9a-11e9-9b61-026654d605e3
STEP: Creating secret with name s-test-opt-create-357dea81-2f9a-11e9-9b61-026654d605e3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:19:32.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vf84c" for this suite.
Feb 13 14:20:00.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:20:00.692: INFO: namespace: e2e-tests-projected-vf84c, resource: bindings, ignored listing per whitelist
Feb 13 14:20:00.768: INFO: namespace e2e-tests-projected-vf84c deletion completed in 28.122175322s

• [SLOW TEST:102.822 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:20:00.769: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 13 14:20:00.874: INFO: Waiting up to 5m0s for pod "pod-72c7104d-2f9a-11e9-9b61-026654d605e3" in namespace "e2e-tests-emptydir-qfcg4" to be "success or failure"
Feb 13 14:20:00.877: INFO: Pod "pod-72c7104d-2f9a-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.549526ms
Feb 13 14:20:02.882: INFO: Pod "pod-72c7104d-2f9a-11e9-9b61-026654d605e3": Phase="Running", Reason="", readiness=true. Elapsed: 2.007898946s
Feb 13 14:20:04.893: INFO: Pod "pod-72c7104d-2f9a-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018959003s
STEP: Saw pod success
Feb 13 14:20:04.893: INFO: Pod "pod-72c7104d-2f9a-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:20:04.897: INFO: Trying to get logs from node cmp3 pod pod-72c7104d-2f9a-11e9-9b61-026654d605e3 container test-container: <nil>
STEP: delete the pod
Feb 13 14:20:04.932: INFO: Waiting for pod pod-72c7104d-2f9a-11e9-9b61-026654d605e3 to disappear
Feb 13 14:20:04.936: INFO: Pod pod-72c7104d-2f9a-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:20:04.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qfcg4" for this suite.
Feb 13 14:20:10.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:20:11.012: INFO: namespace: e2e-tests-emptydir-qfcg4, resource: bindings, ignored listing per whitelist
Feb 13 14:20:11.059: INFO: namespace e2e-tests-emptydir-qfcg4 deletion completed in 6.118590136s

• [SLOW TEST:10.291 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:20:11.059: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 13 14:20:11.155: INFO: Waiting up to 5m0s for pod "pod-78e828dd-2f9a-11e9-9b61-026654d605e3" in namespace "e2e-tests-emptydir-2mzz2" to be "success or failure"
Feb 13 14:20:11.158: INFO: Pod "pod-78e828dd-2f9a-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.773203ms
Feb 13 14:20:13.161: INFO: Pod "pod-78e828dd-2f9a-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006579617s
Feb 13 14:20:15.173: INFO: Pod "pod-78e828dd-2f9a-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017840084s
STEP: Saw pod success
Feb 13 14:20:15.173: INFO: Pod "pod-78e828dd-2f9a-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:20:15.177: INFO: Trying to get logs from node cmp3 pod pod-78e828dd-2f9a-11e9-9b61-026654d605e3 container test-container: <nil>
STEP: delete the pod
Feb 13 14:20:15.199: INFO: Waiting for pod pod-78e828dd-2f9a-11e9-9b61-026654d605e3 to disappear
Feb 13 14:20:15.202: INFO: Pod pod-78e828dd-2f9a-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:20:15.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2mzz2" for this suite.
Feb 13 14:20:21.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:20:21.304: INFO: namespace: e2e-tests-emptydir-2mzz2, resource: bindings, ignored listing per whitelist
Feb 13 14:20:21.338: INFO: namespace e2e-tests-emptydir-2mzz2 deletion completed in 6.131539978s

• [SLOW TEST:10.279 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:20:21.339: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 13 14:20:21.446: INFO: Waiting up to 5m0s for pod "pod-7f0a5e09-2f9a-11e9-9b61-026654d605e3" in namespace "e2e-tests-emptydir-ls5ls" to be "success or failure"
Feb 13 14:20:21.450: INFO: Pod "pod-7f0a5e09-2f9a-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.317103ms
Feb 13 14:20:23.453: INFO: Pod "pod-7f0a5e09-2f9a-11e9-9b61-026654d605e3": Phase="Running", Reason="", readiness=true. Elapsed: 2.007247598s
Feb 13 14:20:25.464: INFO: Pod "pod-7f0a5e09-2f9a-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018008982s
STEP: Saw pod success
Feb 13 14:20:25.464: INFO: Pod "pod-7f0a5e09-2f9a-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:20:25.469: INFO: Trying to get logs from node cmp3 pod pod-7f0a5e09-2f9a-11e9-9b61-026654d605e3 container test-container: <nil>
STEP: delete the pod
Feb 13 14:20:25.488: INFO: Waiting for pod pod-7f0a5e09-2f9a-11e9-9b61-026654d605e3 to disappear
Feb 13 14:20:25.491: INFO: Pod pod-7f0a5e09-2f9a-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:20:25.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ls5ls" for this suite.
Feb 13 14:20:31.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:20:31.520: INFO: namespace: e2e-tests-emptydir-ls5ls, resource: bindings, ignored listing per whitelist
Feb 13 14:20:31.616: INFO: namespace e2e-tests-emptydir-ls5ls deletion completed in 6.120364238s

• [SLOW TEST:10.277 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:20:31.616: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0213 14:21:11.753413      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 13 14:21:11.753: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:21:11.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-k66xn" for this suite.
Feb 13 14:21:17.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:21:17.880: INFO: namespace: e2e-tests-gc-k66xn, resource: bindings, ignored listing per whitelist
Feb 13 14:21:17.888: INFO: namespace e2e-tests-gc-k66xn deletion completed in 6.131807851s

• [SLOW TEST:46.272 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:21:17.889: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 14:21:17.981: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:21:19.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-5n7zn" for this suite.
Feb 13 14:21:25.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:21:25.095: INFO: namespace: e2e-tests-custom-resource-definition-5n7zn, resource: bindings, ignored listing per whitelist
Feb 13 14:21:25.204: INFO: namespace e2e-tests-custom-resource-definition-5n7zn deletion completed in 6.129647311s

• [SLOW TEST:7.315 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:21:25.204: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 13 14:21:25.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-9fft9'
Feb 13 14:21:25.550: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb 13 14:21:25.550: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Feb 13 14:21:25.554: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Feb 13 14:21:25.562: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Feb 13 14:21:25.568: INFO: scanned /root for discovery docs: <nil>
Feb 13 14:21:25.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-9fft9'
Feb 13 14:21:41.369: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 13 14:21:41.370: INFO: stdout: "Created e2e-test-nginx-rc-296a6f6d907bea6e9bd748cc4c41b4bd\nScaling up e2e-test-nginx-rc-296a6f6d907bea6e9bd748cc4c41b4bd from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-296a6f6d907bea6e9bd748cc4c41b4bd up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-296a6f6d907bea6e9bd748cc4c41b4bd to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Feb 13 14:21:41.370: INFO: stdout: "Created e2e-test-nginx-rc-296a6f6d907bea6e9bd748cc4c41b4bd\nScaling up e2e-test-nginx-rc-296a6f6d907bea6e9bd748cc4c41b4bd from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-296a6f6d907bea6e9bd748cc4c41b4bd up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-296a6f6d907bea6e9bd748cc4c41b4bd to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Feb 13 14:21:41.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-9fft9'
Feb 13 14:21:41.490: INFO: stderr: ""
Feb 13 14:21:41.490: INFO: stdout: "e2e-test-nginx-rc-296a6f6d907bea6e9bd748cc4c41b4bd-wct59 "
Feb 13 14:21:41.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods e2e-test-nginx-rc-296a6f6d907bea6e9bd748cc4c41b4bd-wct59 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9fft9'
Feb 13 14:21:41.598: INFO: stderr: ""
Feb 13 14:21:41.598: INFO: stdout: "true"
Feb 13 14:21:41.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods e2e-test-nginx-rc-296a6f6d907bea6e9bd748cc4c41b4bd-wct59 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9fft9'
Feb 13 14:21:41.727: INFO: stderr: ""
Feb 13 14:21:41.727: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Feb 13 14:21:41.727: INFO: e2e-test-nginx-rc-296a6f6d907bea6e9bd748cc4c41b4bd-wct59 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Feb 13 14:21:41.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-9fft9'
Feb 13 14:21:41.863: INFO: stderr: ""
Feb 13 14:21:41.863: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:21:41.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9fft9" for this suite.
Feb 13 14:22:03.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:22:03.914: INFO: namespace: e2e-tests-kubectl-9fft9, resource: bindings, ignored listing per whitelist
Feb 13 14:22:03.990: INFO: namespace e2e-tests-kubectl-9fft9 deletion completed in 22.121375635s

• [SLOW TEST:38.785 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:22:03.990: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Feb 13 14:22:04.612: INFO: created pod pod-service-account-defaultsa
Feb 13 14:22:04.612: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb 13 14:22:04.616: INFO: created pod pod-service-account-mountsa
Feb 13 14:22:04.616: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb 13 14:22:04.621: INFO: created pod pod-service-account-nomountsa
Feb 13 14:22:04.621: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb 13 14:22:04.626: INFO: created pod pod-service-account-defaultsa-mountspec
Feb 13 14:22:04.626: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb 13 14:22:04.631: INFO: created pod pod-service-account-mountsa-mountspec
Feb 13 14:22:04.631: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb 13 14:22:04.636: INFO: created pod pod-service-account-nomountsa-mountspec
Feb 13 14:22:04.636: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb 13 14:22:04.644: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb 13 14:22:04.644: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb 13 14:22:04.650: INFO: created pod pod-service-account-mountsa-nomountspec
Feb 13 14:22:04.650: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb 13 14:22:04.655: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb 13 14:22:04.655: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:22:04.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-7d5tm" for this suite.
Feb 13 14:22:26.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:22:26.783: INFO: namespace: e2e-tests-svcaccounts-7d5tm, resource: bindings, ignored listing per whitelist
Feb 13 14:22:26.789: INFO: namespace e2e-tests-svcaccounts-7d5tm deletion completed in 22.129694981s

• [SLOW TEST:22.800 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:22:26.789: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 13 14:22:26.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-kbm4b'
Feb 13 14:22:27.024: INFO: stderr: ""
Feb 13 14:22:27.024: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Feb 13 14:22:27.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-kbm4b'
Feb 13 14:22:38.437: INFO: stderr: ""
Feb 13 14:22:38.437: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:22:38.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kbm4b" for this suite.
Feb 13 14:22:44.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:22:44.546: INFO: namespace: e2e-tests-kubectl-kbm4b, resource: bindings, ignored listing per whitelist
Feb 13 14:22:44.584: INFO: namespace e2e-tests-kubectl-kbm4b deletion completed in 6.136081506s

• [SLOW TEST:17.794 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:22:44.584: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb 13 14:22:44.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 create -f - --namespace=e2e-tests-kubectl-zt2jb'
Feb 13 14:22:44.935: INFO: stderr: ""
Feb 13 14:22:44.935: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 13 14:22:44.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zt2jb'
Feb 13 14:22:45.060: INFO: stderr: ""
Feb 13 14:22:45.060: INFO: stdout: "update-demo-nautilus-4h4lw update-demo-nautilus-cw8dr "
Feb 13 14:22:45.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods update-demo-nautilus-4h4lw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zt2jb'
Feb 13 14:22:45.178: INFO: stderr: ""
Feb 13 14:22:45.178: INFO: stdout: ""
Feb 13 14:22:45.178: INFO: update-demo-nautilus-4h4lw is created but not running
Feb 13 14:22:50.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zt2jb'
Feb 13 14:22:50.298: INFO: stderr: ""
Feb 13 14:22:50.298: INFO: stdout: "update-demo-nautilus-4h4lw update-demo-nautilus-cw8dr "
Feb 13 14:22:50.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods update-demo-nautilus-4h4lw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zt2jb'
Feb 13 14:22:50.407: INFO: stderr: ""
Feb 13 14:22:50.407: INFO: stdout: "true"
Feb 13 14:22:50.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods update-demo-nautilus-4h4lw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zt2jb'
Feb 13 14:22:50.533: INFO: stderr: ""
Feb 13 14:22:50.533: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 13 14:22:50.533: INFO: validating pod update-demo-nautilus-4h4lw
Feb 13 14:22:50.543: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 14:22:50.543: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 14:22:50.543: INFO: update-demo-nautilus-4h4lw is verified up and running
Feb 13 14:22:50.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods update-demo-nautilus-cw8dr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zt2jb'
Feb 13 14:22:50.664: INFO: stderr: ""
Feb 13 14:22:50.664: INFO: stdout: "true"
Feb 13 14:22:50.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods update-demo-nautilus-cw8dr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zt2jb'
Feb 13 14:22:50.778: INFO: stderr: ""
Feb 13 14:22:50.778: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 13 14:22:50.778: INFO: validating pod update-demo-nautilus-cw8dr
Feb 13 14:22:50.789: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 14:22:50.789: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 14:22:50.789: INFO: update-demo-nautilus-cw8dr is verified up and running
STEP: scaling down the replication controller
Feb 13 14:22:50.790: INFO: scanned /root for discovery docs: <nil>
Feb 13 14:22:50.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-zt2jb'
Feb 13 14:22:51.947: INFO: stderr: ""
Feb 13 14:22:51.947: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 13 14:22:51.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zt2jb'
Feb 13 14:22:52.083: INFO: stderr: ""
Feb 13 14:22:52.083: INFO: stdout: "update-demo-nautilus-4h4lw update-demo-nautilus-cw8dr "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 13 14:22:57.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zt2jb'
Feb 13 14:22:57.201: INFO: stderr: ""
Feb 13 14:22:57.201: INFO: stdout: "update-demo-nautilus-4h4lw update-demo-nautilus-cw8dr "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 13 14:23:02.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zt2jb'
Feb 13 14:23:02.335: INFO: stderr: ""
Feb 13 14:23:02.335: INFO: stdout: "update-demo-nautilus-4h4lw update-demo-nautilus-cw8dr "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 13 14:23:07.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zt2jb'
Feb 13 14:23:07.459: INFO: stderr: ""
Feb 13 14:23:07.459: INFO: stdout: "update-demo-nautilus-cw8dr "
Feb 13 14:23:07.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods update-demo-nautilus-cw8dr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zt2jb'
Feb 13 14:23:07.566: INFO: stderr: ""
Feb 13 14:23:07.566: INFO: stdout: "true"
Feb 13 14:23:07.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods update-demo-nautilus-cw8dr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zt2jb'
Feb 13 14:23:07.675: INFO: stderr: ""
Feb 13 14:23:07.675: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 13 14:23:07.675: INFO: validating pod update-demo-nautilus-cw8dr
Feb 13 14:23:07.680: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 14:23:07.680: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 14:23:07.680: INFO: update-demo-nautilus-cw8dr is verified up and running
STEP: scaling up the replication controller
Feb 13 14:23:07.681: INFO: scanned /root for discovery docs: <nil>
Feb 13 14:23:07.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-zt2jb'
Feb 13 14:23:08.841: INFO: stderr: ""
Feb 13 14:23:08.841: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 13 14:23:08.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zt2jb'
Feb 13 14:23:08.957: INFO: stderr: ""
Feb 13 14:23:08.957: INFO: stdout: "update-demo-nautilus-cw8dr update-demo-nautilus-xn577 "
Feb 13 14:23:08.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods update-demo-nautilus-cw8dr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zt2jb'
Feb 13 14:23:09.079: INFO: stderr: ""
Feb 13 14:23:09.079: INFO: stdout: "true"
Feb 13 14:23:09.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods update-demo-nautilus-cw8dr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zt2jb'
Feb 13 14:23:09.186: INFO: stderr: ""
Feb 13 14:23:09.186: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 13 14:23:09.186: INFO: validating pod update-demo-nautilus-cw8dr
Feb 13 14:23:09.193: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 14:23:09.193: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 14:23:09.193: INFO: update-demo-nautilus-cw8dr is verified up and running
Feb 13 14:23:09.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods update-demo-nautilus-xn577 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zt2jb'
Feb 13 14:23:09.312: INFO: stderr: ""
Feb 13 14:23:09.312: INFO: stdout: ""
Feb 13 14:23:09.312: INFO: update-demo-nautilus-xn577 is created but not running
Feb 13 14:23:14.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zt2jb'
Feb 13 14:23:14.457: INFO: stderr: ""
Feb 13 14:23:14.457: INFO: stdout: "update-demo-nautilus-cw8dr update-demo-nautilus-xn577 "
Feb 13 14:23:14.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods update-demo-nautilus-cw8dr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zt2jb'
Feb 13 14:23:14.573: INFO: stderr: ""
Feb 13 14:23:14.573: INFO: stdout: "true"
Feb 13 14:23:14.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods update-demo-nautilus-cw8dr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zt2jb'
Feb 13 14:23:14.691: INFO: stderr: ""
Feb 13 14:23:14.691: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 13 14:23:14.691: INFO: validating pod update-demo-nautilus-cw8dr
Feb 13 14:23:14.696: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 14:23:14.696: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 14:23:14.696: INFO: update-demo-nautilus-cw8dr is verified up and running
Feb 13 14:23:14.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods update-demo-nautilus-xn577 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zt2jb'
Feb 13 14:23:14.808: INFO: stderr: ""
Feb 13 14:23:14.808: INFO: stdout: "true"
Feb 13 14:23:14.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods update-demo-nautilus-xn577 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zt2jb'
Feb 13 14:23:14.929: INFO: stderr: ""
Feb 13 14:23:14.929: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 13 14:23:14.929: INFO: validating pod update-demo-nautilus-xn577
Feb 13 14:23:14.934: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 14:23:14.934: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 14:23:14.934: INFO: update-demo-nautilus-xn577 is verified up and running
STEP: using delete to clean up resources
Feb 13 14:23:14.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-zt2jb'
Feb 13 14:23:15.050: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 14:23:15.050: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 13 14:23:15.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-zt2jb'
Feb 13 14:23:15.193: INFO: stderr: "No resources found.\n"
Feb 13 14:23:15.193: INFO: stdout: ""
Feb 13 14:23:15.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods -l name=update-demo --namespace=e2e-tests-kubectl-zt2jb -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 13 14:23:15.307: INFO: stderr: ""
Feb 13 14:23:15.307: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:23:15.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zt2jb" for this suite.
Feb 13 14:23:37.331: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:23:37.422: INFO: namespace: e2e-tests-kubectl-zt2jb, resource: bindings, ignored listing per whitelist
Feb 13 14:23:37.442: INFO: namespace e2e-tests-kubectl-zt2jb deletion completed in 22.13133255s

• [SLOW TEST:52.859 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:23:37.443: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 13 14:23:37.545: INFO: Waiting up to 5m0s for pod "pod-f3ec912b-2f9a-11e9-9b61-026654d605e3" in namespace "e2e-tests-emptydir-lsdbs" to be "success or failure"
Feb 13 14:23:37.549: INFO: Pod "pod-f3ec912b-2f9a-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.575218ms
Feb 13 14:23:39.553: INFO: Pod "pod-f3ec912b-2f9a-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008260669s
Feb 13 14:23:41.557: INFO: Pod "pod-f3ec912b-2f9a-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01189332s
STEP: Saw pod success
Feb 13 14:23:41.557: INFO: Pod "pod-f3ec912b-2f9a-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:23:41.561: INFO: Trying to get logs from node cmp3 pod pod-f3ec912b-2f9a-11e9-9b61-026654d605e3 container test-container: <nil>
STEP: delete the pod
Feb 13 14:23:41.593: INFO: Waiting for pod pod-f3ec912b-2f9a-11e9-9b61-026654d605e3 to disappear
Feb 13 14:23:41.596: INFO: Pod pod-f3ec912b-2f9a-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:23:41.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lsdbs" for this suite.
Feb 13 14:23:47.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:23:47.628: INFO: namespace: e2e-tests-emptydir-lsdbs, resource: bindings, ignored listing per whitelist
Feb 13 14:23:47.726: INFO: namespace e2e-tests-emptydir-lsdbs deletion completed in 6.124945833s

• [SLOW TEST:10.284 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:23:47.727: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-fa0eeb5c-2f9a-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume secrets
Feb 13 14:23:47.897: INFO: Waiting up to 5m0s for pod "pod-secrets-fa189ce0-2f9a-11e9-9b61-026654d605e3" in namespace "e2e-tests-secrets-l5cbm" to be "success or failure"
Feb 13 14:23:47.900: INFO: Pod "pod-secrets-fa189ce0-2f9a-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.134178ms
Feb 13 14:23:49.904: INFO: Pod "pod-secrets-fa189ce0-2f9a-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007232661s
Feb 13 14:23:51.908: INFO: Pod "pod-secrets-fa189ce0-2f9a-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011190126s
STEP: Saw pod success
Feb 13 14:23:51.908: INFO: Pod "pod-secrets-fa189ce0-2f9a-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:23:51.911: INFO: Trying to get logs from node cmp3 pod pod-secrets-fa189ce0-2f9a-11e9-9b61-026654d605e3 container secret-volume-test: <nil>
STEP: delete the pod
Feb 13 14:23:51.960: INFO: Waiting for pod pod-secrets-fa189ce0-2f9a-11e9-9b61-026654d605e3 to disappear
Feb 13 14:23:51.963: INFO: Pod pod-secrets-fa189ce0-2f9a-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:23:51.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-l5cbm" for this suite.
Feb 13 14:23:57.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:23:58.002: INFO: namespace: e2e-tests-secrets-l5cbm, resource: bindings, ignored listing per whitelist
Feb 13 14:23:58.101: INFO: namespace e2e-tests-secrets-l5cbm deletion completed in 6.13368903s
STEP: Destroying namespace "e2e-tests-secret-namespace-j7dqw" for this suite.
Feb 13 14:24:04.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:24:04.150: INFO: namespace: e2e-tests-secret-namespace-j7dqw, resource: bindings, ignored listing per whitelist
Feb 13 14:24:04.229: INFO: namespace e2e-tests-secret-namespace-j7dqw deletion completed in 6.128662161s

• [SLOW TEST:16.503 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:24:04.230: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 14:24:04.346: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Feb 13 14:24:09.358: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 13 14:24:09.358: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 13 14:24:09.377: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-gbmtt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gbmtt/deployments/test-cleanup-deployment,UID:06e55a33-2f9b-11e9-85f4-fa163e429998,ResourceVersion:2515730,Generation:1,CreationTimestamp:2019-02-13 14:24:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Feb 13 14:24:09.380: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:24:09.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-gbmtt" for this suite.
Feb 13 14:24:15.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:24:15.473: INFO: namespace: e2e-tests-deployment-gbmtt, resource: bindings, ignored listing per whitelist
Feb 13 14:24:15.519: INFO: namespace e2e-tests-deployment-gbmtt deletion completed in 6.130382548s

• [SLOW TEST:11.289 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:24:15.519: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-0aa06699-2f9b-11e9-9b61-026654d605e3
STEP: Creating configMap with name cm-test-opt-upd-0aa066dd-2f9b-11e9-9b61-026654d605e3
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-0aa06699-2f9b-11e9-9b61-026654d605e3
STEP: Updating configmap cm-test-opt-upd-0aa066dd-2f9b-11e9-9b61-026654d605e3
STEP: Creating configMap with name cm-test-opt-create-0aa066f0-2f9b-11e9-9b61-026654d605e3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:24:23.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-m5z2j" for this suite.
Feb 13 14:24:43.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:24:43.822: INFO: namespace: e2e-tests-projected-m5z2j, resource: bindings, ignored listing per whitelist
Feb 13 14:24:43.864: INFO: namespace e2e-tests-projected-m5z2j deletion completed in 20.123209724s

• [SLOW TEST:28.345 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:24:43.864: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 14:24:43.994: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"1b87df35-2f9b-11e9-85f4-fa163e429998", Controller:(*bool)(0xc4227c8eb6), BlockOwnerDeletion:(*bool)(0xc4227c8eb7)}}
Feb 13 14:24:43.998: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"1b84e10e-2f9b-11e9-85f4-fa163e429998", Controller:(*bool)(0xc42271470a), BlockOwnerDeletion:(*bool)(0xc42271470b)}}
Feb 13 14:24:44.003: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"1b870503-2f9b-11e9-85f4-fa163e429998", Controller:(*bool)(0xc4227c90a2), BlockOwnerDeletion:(*bool)(0xc4227c90a3)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:24:49.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-hgstd" for this suite.
Feb 13 14:24:55.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:24:55.066: INFO: namespace: e2e-tests-gc-hgstd, resource: bindings, ignored listing per whitelist
Feb 13 14:24:55.138: INFO: namespace e2e-tests-gc-hgstd deletion completed in 6.119315155s

• [SLOW TEST:11.274 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:24:55.138: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 13 14:24:55.232: INFO: PodSpec: initContainers in spec.initContainers
Feb 13 14:25:45.394: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-223c59f2-2f9b-11e9-9b61-026654d605e3", GenerateName:"", Namespace:"e2e-tests-init-container-j22zq", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-j22zq/pods/pod-init-223c59f2-2f9b-11e9-9b61-026654d605e3", UID:"223cfa7c-2f9b-11e9-85f4-fa163e429998", ResourceVersion:"2516179", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63685664695, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"time":"232771213", "name":"foo"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-kt56r", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc422702680), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-kt56r", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-kt56r", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-kt56r", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc4223a3458), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"cmp3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc421e700c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4223a35b0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4223a35d0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc4223a35d8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685664695, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685664695, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685664695, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685664695, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.11.1.3", PodIP:"192.168.113.81", StartTime:(*v1.Time)(0xc421cafc60), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc420adb030)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc420adb260)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://c8416f544c2628b41f0781f0d2e798b5aed1e402fe3a4d1e0d1f5331b0424953"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc421cafca0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc421cafc80), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:25:45.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-j22zq" for this suite.
Feb 13 14:26:07.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:26:07.500: INFO: namespace: e2e-tests-init-container-j22zq, resource: bindings, ignored listing per whitelist
Feb 13 14:26:07.529: INFO: namespace e2e-tests-init-container-j22zq deletion completed in 22.123498551s

• [SLOW TEST:72.391 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:26:07.529: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 13 14:26:15.663: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 13 14:26:15.666: INFO: Pod pod-with-prestop-http-hook still exists
Feb 13 14:26:17.667: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 13 14:26:17.678: INFO: Pod pod-with-prestop-http-hook still exists
Feb 13 14:26:19.666: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 13 14:26:19.671: INFO: Pod pod-with-prestop-http-hook still exists
Feb 13 14:26:21.666: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 13 14:26:21.671: INFO: Pod pod-with-prestop-http-hook still exists
Feb 13 14:26:23.666: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 13 14:26:23.671: INFO: Pod pod-with-prestop-http-hook still exists
Feb 13 14:26:25.666: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 13 14:26:25.671: INFO: Pod pod-with-prestop-http-hook still exists
Feb 13 14:26:27.666: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 13 14:26:27.671: INFO: Pod pod-with-prestop-http-hook still exists
Feb 13 14:26:29.666: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 13 14:26:29.677: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:26:29.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-j85db" for this suite.
Feb 13 14:26:51.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:26:51.777: INFO: namespace: e2e-tests-container-lifecycle-hook-j85db, resource: bindings, ignored listing per whitelist
Feb 13 14:26:51.825: INFO: namespace e2e-tests-container-lifecycle-hook-j85db deletion completed in 22.134838182s

• [SLOW TEST:44.296 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:26:51.825: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0213 14:26:52.974271      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 13 14:26:52.974: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:26:52.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-qqzsf" for this suite.
Feb 13 14:26:58.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:26:59.045: INFO: namespace: e2e-tests-gc-qqzsf, resource: bindings, ignored listing per whitelist
Feb 13 14:26:59.102: INFO: namespace e2e-tests-gc-qqzsf deletion completed in 6.124600261s

• [SLOW TEST:7.277 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:26:59.102: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0213 14:27:09.231279      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 13 14:27:09.231: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:27:09.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-nf2xs" for this suite.
Feb 13 14:27:15.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:27:15.331: INFO: namespace: e2e-tests-gc-nf2xs, resource: bindings, ignored listing per whitelist
Feb 13 14:27:15.367: INFO: namespace e2e-tests-gc-nf2xs deletion completed in 6.131441305s

• [SLOW TEST:16.265 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:27:15.368: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 13 14:27:15.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-txrkw'
Feb 13 14:27:15.609: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb 13 14:27:15.609: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Feb 13 14:27:19.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-txrkw'
Feb 13 14:27:19.753: INFO: stderr: ""
Feb 13 14:27:19.753: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:27:19.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-txrkw" for this suite.
Feb 13 14:27:41.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:27:41.799: INFO: namespace: e2e-tests-kubectl-txrkw, resource: bindings, ignored listing per whitelist
Feb 13 14:27:41.894: INFO: namespace e2e-tests-kubectl-txrkw deletion completed in 22.136788552s

• [SLOW TEST:26.526 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:27:41.895: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 14:27:42.003: INFO: Waiting up to 5m0s for pod "downwardapi-volume-85a112cf-2f9b-11e9-9b61-026654d605e3" in namespace "e2e-tests-projected-hgnvg" to be "success or failure"
Feb 13 14:27:42.007: INFO: Pod "downwardapi-volume-85a112cf-2f9b-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.524507ms
Feb 13 14:27:44.011: INFO: Pod "downwardapi-volume-85a112cf-2f9b-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007629274s
Feb 13 14:27:46.015: INFO: Pod "downwardapi-volume-85a112cf-2f9b-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012279164s
STEP: Saw pod success
Feb 13 14:27:46.015: INFO: Pod "downwardapi-volume-85a112cf-2f9b-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:27:46.019: INFO: Trying to get logs from node cmp3 pod downwardapi-volume-85a112cf-2f9b-11e9-9b61-026654d605e3 container client-container: <nil>
STEP: delete the pod
Feb 13 14:27:46.041: INFO: Waiting for pod downwardapi-volume-85a112cf-2f9b-11e9-9b61-026654d605e3 to disappear
Feb 13 14:27:46.044: INFO: Pod downwardapi-volume-85a112cf-2f9b-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:27:46.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hgnvg" for this suite.
Feb 13 14:27:52.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:27:52.153: INFO: namespace: e2e-tests-projected-hgnvg, resource: bindings, ignored listing per whitelist
Feb 13 14:27:52.180: INFO: namespace e2e-tests-projected-hgnvg deletion completed in 6.13089057s

• [SLOW TEST:10.286 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:27:52.181: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 13 14:27:52.286: INFO: Waiting up to 5m0s for pod "downward-api-8bc2f98c-2f9b-11e9-9b61-026654d605e3" in namespace "e2e-tests-downward-api-qp8xm" to be "success or failure"
Feb 13 14:27:52.291: INFO: Pod "downward-api-8bc2f98c-2f9b-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.263432ms
Feb 13 14:27:54.295: INFO: Pod "downward-api-8bc2f98c-2f9b-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0088035s
STEP: Saw pod success
Feb 13 14:27:54.295: INFO: Pod "downward-api-8bc2f98c-2f9b-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:27:54.299: INFO: Trying to get logs from node cmp2 pod downward-api-8bc2f98c-2f9b-11e9-9b61-026654d605e3 container dapi-container: <nil>
STEP: delete the pod
Feb 13 14:27:54.330: INFO: Waiting for pod downward-api-8bc2f98c-2f9b-11e9-9b61-026654d605e3 to disappear
Feb 13 14:27:54.333: INFO: Pod downward-api-8bc2f98c-2f9b-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:27:54.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qp8xm" for this suite.
Feb 13 14:28:00.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:28:00.469: INFO: namespace: e2e-tests-downward-api-qp8xm, resource: bindings, ignored listing per whitelist
Feb 13 14:28:00.475: INFO: namespace e2e-tests-downward-api-qp8xm deletion completed in 6.137271378s

• [SLOW TEST:8.294 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:28:00.475: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 13 14:28:05.097: INFO: Successfully updated pod "pod-update-activedeadlineseconds-90b41506-2f9b-11e9-9b61-026654d605e3"
Feb 13 14:28:05.098: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-90b41506-2f9b-11e9-9b61-026654d605e3" in namespace "e2e-tests-pods-pfmf5" to be "terminated due to deadline exceeded"
Feb 13 14:28:05.100: INFO: Pod "pod-update-activedeadlineseconds-90b41506-2f9b-11e9-9b61-026654d605e3": Phase="Running", Reason="", readiness=true. Elapsed: 2.927063ms
Feb 13 14:28:07.104: INFO: Pod "pod-update-activedeadlineseconds-90b41506-2f9b-11e9-9b61-026654d605e3": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.006949204s
Feb 13 14:28:07.105: INFO: Pod "pod-update-activedeadlineseconds-90b41506-2f9b-11e9-9b61-026654d605e3" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:28:07.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-pfmf5" for this suite.
Feb 13 14:28:13.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:28:13.162: INFO: namespace: e2e-tests-pods-pfmf5, resource: bindings, ignored listing per whitelist
Feb 13 14:28:13.241: INFO: namespace e2e-tests-pods-pfmf5 deletion completed in 6.130701478s

• [SLOW TEST:12.765 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:28:13.241: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 13 14:28:13.346: INFO: Waiting up to 5m0s for pod "pod-9850534e-2f9b-11e9-9b61-026654d605e3" in namespace "e2e-tests-emptydir-2w5f9" to be "success or failure"
Feb 13 14:28:13.349: INFO: Pod "pod-9850534e-2f9b-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.820127ms
Feb 13 14:28:15.354: INFO: Pod "pod-9850534e-2f9b-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008283557s
Feb 13 14:28:17.359: INFO: Pod "pod-9850534e-2f9b-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013009712s
STEP: Saw pod success
Feb 13 14:28:17.359: INFO: Pod "pod-9850534e-2f9b-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:28:17.362: INFO: Trying to get logs from node cmp3 pod pod-9850534e-2f9b-11e9-9b61-026654d605e3 container test-container: <nil>
STEP: delete the pod
Feb 13 14:28:17.382: INFO: Waiting for pod pod-9850534e-2f9b-11e9-9b61-026654d605e3 to disappear
Feb 13 14:28:17.385: INFO: Pod pod-9850534e-2f9b-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:28:17.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2w5f9" for this suite.
Feb 13 14:28:23.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:28:23.502: INFO: namespace: e2e-tests-emptydir-2w5f9, resource: bindings, ignored listing per whitelist
Feb 13 14:28:23.515: INFO: namespace e2e-tests-emptydir-2w5f9 deletion completed in 6.125491289s

• [SLOW TEST:10.274 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:28:23.515: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Feb 13 14:28:23.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 api-versions'
Feb 13 14:28:23.724: INFO: stderr: ""
Feb 13 14:28:23.724: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\netcd.database.coreos.com/v1beta2\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\nvirtlet.k8s/v1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:28:23.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8dkqg" for this suite.
Feb 13 14:28:29.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:28:29.790: INFO: namespace: e2e-tests-kubectl-8dkqg, resource: bindings, ignored listing per whitelist
Feb 13 14:28:29.881: INFO: namespace e2e-tests-kubectl-8dkqg deletion completed in 6.152804487s

• [SLOW TEST:6.366 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:28:29.881: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 14:28:29.987: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a23bbb0b-2f9b-11e9-9b61-026654d605e3" in namespace "e2e-tests-downward-api-scrvx" to be "success or failure"
Feb 13 14:28:29.991: INFO: Pod "downwardapi-volume-a23bbb0b-2f9b-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.489681ms
Feb 13 14:28:31.995: INFO: Pod "downwardapi-volume-a23bbb0b-2f9b-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007895095s
Feb 13 14:28:34.000: INFO: Pod "downwardapi-volume-a23bbb0b-2f9b-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012307907s
STEP: Saw pod success
Feb 13 14:28:34.000: INFO: Pod "downwardapi-volume-a23bbb0b-2f9b-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:28:34.003: INFO: Trying to get logs from node cmp3 pod downwardapi-volume-a23bbb0b-2f9b-11e9-9b61-026654d605e3 container client-container: <nil>
STEP: delete the pod
Feb 13 14:28:34.022: INFO: Waiting for pod downwardapi-volume-a23bbb0b-2f9b-11e9-9b61-026654d605e3 to disappear
Feb 13 14:28:34.024: INFO: Pod downwardapi-volume-a23bbb0b-2f9b-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:28:34.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-scrvx" for this suite.
Feb 13 14:28:40.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:28:40.108: INFO: namespace: e2e-tests-downward-api-scrvx, resource: bindings, ignored listing per whitelist
Feb 13 14:28:40.164: INFO: namespace e2e-tests-downward-api-scrvx deletion completed in 6.134319958s

• [SLOW TEST:10.283 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:28:40.165: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-xtt7r in namespace e2e-tests-proxy-8bckx
I0213 14:28:40.293801      18 runners.go:180] Created replication controller with name: proxy-service-xtt7r, namespace: e2e-tests-proxy-8bckx, replica count: 1
I0213 14:28:41.344289      18 runners.go:180] proxy-service-xtt7r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0213 14:28:42.344486      18 runners.go:180] proxy-service-xtt7r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0213 14:28:43.344676      18 runners.go:180] proxy-service-xtt7r Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0213 14:28:44.344826      18 runners.go:180] proxy-service-xtt7r Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 13 14:28:44.348: INFO: setup took 4.074809728s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb 13 14:28:44.361: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/... (200; 13.448229ms)
Feb 13 14:28:44.361: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname2/proxy/: bar (200; 13.377502ms)
Feb 13 14:28:44.361: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/rewriteme"... (200; 13.339168ms)
Feb 13 14:28:44.365: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname1/proxy/: foo (200; 17.506281ms)
Feb 13 14:28:44.369: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 21.318495ms)
Feb 13 14:28:44.369: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/rewri... (200; 21.372267ms)
Feb 13 14:28:44.369: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname2/proxy/: bar (200; 21.305269ms)
Feb 13 14:28:44.369: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 21.640486ms)
Feb 13 14:28:44.379: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 31.377733ms)
Feb 13 14:28:44.379: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname1/proxy/: foo (200; 31.346585ms)
Feb 13 14:28:44.379: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 31.308421ms)
Feb 13 14:28:44.396: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname2/proxy/: tls qux (200; 48.368393ms)
Feb 13 14:28:44.396: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/... (200; 48.665319ms)
Feb 13 14:28:44.397: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:462/proxy/: tls qux (200; 49.14115ms)
Feb 13 14:28:44.397: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname1/proxy/: tls baz (200; 49.192483ms)
Feb 13 14:28:44.398: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:460/proxy/: tls baz (200; 50.479359ms)
Feb 13 14:28:44.410: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname1/proxy/: tls baz (200; 11.265549ms)
Feb 13 14:28:44.410: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:460/proxy/: tls baz (200; 10.930494ms)
Feb 13 14:28:44.410: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname2/proxy/: tls qux (200; 11.265259ms)
Feb 13 14:28:44.410: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 11.528104ms)
Feb 13 14:28:44.410: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:462/proxy/: tls qux (200; 10.876485ms)
Feb 13 14:28:44.410: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname1/proxy/: foo (200; 11.412155ms)
Feb 13 14:28:44.410: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/rewri... (200; 11.17155ms)
Feb 13 14:28:44.412: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 12.556452ms)
Feb 13 14:28:44.413: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/rewriteme"... (200; 14.020705ms)
Feb 13 14:28:44.414: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 14.171363ms)
Feb 13 14:28:44.414: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/... (200; 14.280102ms)
Feb 13 14:28:44.414: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 14.30126ms)
Feb 13 14:28:44.414: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/... (200; 14.338312ms)
Feb 13 14:28:44.414: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname2/proxy/: bar (200; 14.534694ms)
Feb 13 14:28:44.449: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname1/proxy/: foo (200; 49.010101ms)
Feb 13 14:28:44.449: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname2/proxy/: bar (200; 49.320008ms)
Feb 13 14:28:44.452: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 3.676836ms)
Feb 13 14:28:44.453: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/... (200; 4.500208ms)
Feb 13 14:28:44.454: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/rewri... (200; 4.888226ms)
Feb 13 14:28:44.454: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/rewriteme"... (200; 5.050627ms)
Feb 13 14:28:44.454: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 5.236616ms)
Feb 13 14:28:44.454: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 5.409779ms)
Feb 13 14:28:44.455: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 5.936961ms)
Feb 13 14:28:44.455: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:462/proxy/: tls qux (200; 6.18948ms)
Feb 13 14:28:44.456: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:460/proxy/: tls baz (200; 6.53008ms)
Feb 13 14:28:44.456: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname1/proxy/: foo (200; 6.564659ms)
Feb 13 14:28:44.456: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname1/proxy/: tls baz (200; 6.836845ms)
Feb 13 14:28:44.456: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname1/proxy/: foo (200; 6.853558ms)
Feb 13 14:28:44.456: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname2/proxy/: bar (200; 6.990994ms)
Feb 13 14:28:44.456: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname2/proxy/: bar (200; 7.320352ms)
Feb 13 14:28:44.456: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/... (200; 7.320092ms)
Feb 13 14:28:44.456: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname2/proxy/: tls qux (200; 7.603519ms)
Feb 13 14:28:44.460: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 3.535868ms)
Feb 13 14:28:44.461: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/... (200; 3.728255ms)
Feb 13 14:28:44.461: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:460/proxy/: tls baz (200; 3.866881ms)
Feb 13 14:28:44.462: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/... (200; 3.820481ms)
Feb 13 14:28:44.462: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 5.338646ms)
Feb 13 14:28:44.462: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/rewriteme"... (200; 4.643427ms)
Feb 13 14:28:44.463: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 4.623226ms)
Feb 13 14:28:44.463: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 5.096493ms)
Feb 13 14:28:44.463: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:462/proxy/: tls qux (200; 5.678375ms)
Feb 13 14:28:44.463: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname1/proxy/: foo (200; 6.487141ms)
Feb 13 14:28:44.463: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/rewri... (200; 5.607793ms)
Feb 13 14:28:44.463: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname2/proxy/: bar (200; 6.484214ms)
Feb 13 14:28:44.464: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname1/proxy/: foo (200; 6.534543ms)
Feb 13 14:28:44.464: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname2/proxy/: bar (200; 6.154693ms)
Feb 13 14:28:44.464: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname1/proxy/: tls baz (200; 6.566596ms)
Feb 13 14:28:44.464: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname2/proxy/: tls qux (200; 6.559869ms)
Feb 13 14:28:44.469: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/rewriteme"... (200; 5.110442ms)
Feb 13 14:28:44.469: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/rewri... (200; 5.355913ms)
Feb 13 14:28:44.470: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 5.488096ms)
Feb 13 14:28:44.470: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 5.694748ms)
Feb 13 14:28:44.470: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/... (200; 5.893587ms)
Feb 13 14:28:44.471: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/... (200; 5.980045ms)
Feb 13 14:28:44.471: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 5.9898ms)
Feb 13 14:28:44.471: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 5.94011ms)
Feb 13 14:28:44.472: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:460/proxy/: tls baz (200; 6.973623ms)
Feb 13 14:28:44.473: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname2/proxy/: bar (200; 8.662264ms)
Feb 13 14:28:44.473: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname1/proxy/: foo (200; 8.574515ms)
Feb 13 14:28:44.473: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:462/proxy/: tls qux (200; 8.130476ms)
Feb 13 14:28:44.473: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname2/proxy/: bar (200; 8.605568ms)
Feb 13 14:28:44.474: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname1/proxy/: tls baz (200; 8.460328ms)
Feb 13 14:28:44.475: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname2/proxy/: tls qux (200; 9.196448ms)
Feb 13 14:28:44.475: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname1/proxy/: foo (200; 9.46951ms)
Feb 13 14:28:44.478: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 3.301712ms)
Feb 13 14:28:44.479: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 3.877005ms)
Feb 13 14:28:44.479: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 3.625193ms)
Feb 13 14:28:44.480: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/... (200; 3.921193ms)
Feb 13 14:28:44.480: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname2/proxy/: bar (200; 4.954958ms)
Feb 13 14:28:44.480: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/... (200; 5.094427ms)
Feb 13 14:28:44.480: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/rewri... (200; 4.776771ms)
Feb 13 14:28:44.480: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 5.042431ms)
Feb 13 14:28:44.480: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:460/proxy/: tls baz (200; 4.75327ms)
Feb 13 14:28:44.480: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:462/proxy/: tls qux (200; 4.847076ms)
Feb 13 14:28:44.480: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/rewriteme"... (200; 4.748263ms)
Feb 13 14:28:44.481: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname2/proxy/: tls qux (200; 5.525843ms)
Feb 13 14:28:44.481: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname1/proxy/: foo (200; 5.987316ms)
Feb 13 14:28:44.481: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname1/proxy/: foo (200; 5.549405ms)
Feb 13 14:28:44.481: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname1/proxy/: tls baz (200; 6.086491ms)
Feb 13 14:28:44.481: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname2/proxy/: bar (200; 6.7828ms)
Feb 13 14:28:44.486: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/... (200; 4.281277ms)
Feb 13 14:28:44.487: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 5.420401ms)
Feb 13 14:28:44.488: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/... (200; 6.110156ms)
Feb 13 14:28:44.488: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 5.586871ms)
Feb 13 14:28:44.488: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/rewriteme"... (200; 5.790859ms)
Feb 13 14:28:44.488: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 5.942551ms)
Feb 13 14:28:44.488: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:462/proxy/: tls qux (200; 6.345678ms)
Feb 13 14:28:44.488: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname1/proxy/: foo (200; 6.694874ms)
Feb 13 14:28:44.488: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:460/proxy/: tls baz (200; 6.499654ms)
Feb 13 14:28:44.488: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 6.580881ms)
Feb 13 14:28:44.489: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname1/proxy/: foo (200; 6.811717ms)
Feb 13 14:28:44.489: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/rewri... (200; 6.619638ms)
Feb 13 14:28:44.489: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname2/proxy/: bar (200; 7.22411ms)
Feb 13 14:28:44.489: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname2/proxy/: tls qux (200; 7.254062ms)
Feb 13 14:28:44.489: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname1/proxy/: tls baz (200; 7.346715ms)
Feb 13 14:28:44.490: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname2/proxy/: bar (200; 7.165311ms)
Feb 13 14:28:44.493: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/rewri... (200; 3.465724ms)
Feb 13 14:28:44.494: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/... (200; 4.297987ms)
Feb 13 14:28:44.494: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 4.231286ms)
Feb 13 14:28:44.494: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/rewriteme"... (200; 3.831853ms)
Feb 13 14:28:44.495: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 4.567159ms)
Feb 13 14:28:44.495: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/... (200; 5.182162ms)
Feb 13 14:28:44.495: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 5.033799ms)
Feb 13 14:28:44.495: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 5.015152ms)
Feb 13 14:28:44.495: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:462/proxy/: tls qux (200; 5.607487ms)
Feb 13 14:28:44.496: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname1/proxy/: tls baz (200; 6.315251ms)
Feb 13 14:28:44.496: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname1/proxy/: foo (200; 6.449302ms)
Feb 13 14:28:44.497: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:460/proxy/: tls baz (200; 6.814259ms)
Feb 13 14:28:44.497: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname2/proxy/: bar (200; 6.899869ms)
Feb 13 14:28:44.499: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname1/proxy/: foo (200; 8.20288ms)
Feb 13 14:28:44.499: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname2/proxy/: tls qux (200; 8.69746ms)
Feb 13 14:28:44.499: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname2/proxy/: bar (200; 8.230032ms)
Feb 13 14:28:44.503: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 3.949802ms)
Feb 13 14:28:44.504: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 4.567273ms)
Feb 13 14:28:44.504: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/... (200; 4.843224ms)
Feb 13 14:28:44.504: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname2/proxy/: bar (200; 5.155046ms)
Feb 13 14:28:44.504: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:462/proxy/: tls qux (200; 4.851271ms)
Feb 13 14:28:44.504: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 5.03844ms)
Feb 13 14:28:44.505: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/rewri... (200; 5.22808ms)
Feb 13 14:28:44.505: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 5.131728ms)
Feb 13 14:28:44.505: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:460/proxy/: tls baz (200; 5.881497ms)
Feb 13 14:28:44.505: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/... (200; 5.550431ms)
Feb 13 14:28:44.506: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/rewriteme"... (200; 5.806804ms)
Feb 13 14:28:44.506: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname1/proxy/: tls baz (200; 6.121223ms)
Feb 13 14:28:44.506: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname1/proxy/: foo (200; 6.224603ms)
Feb 13 14:28:44.506: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname2/proxy/: tls qux (200; 6.679689ms)
Feb 13 14:28:44.506: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname1/proxy/: foo (200; 7.452959ms)
Feb 13 14:28:44.506: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname2/proxy/: bar (200; 6.704738ms)
Feb 13 14:28:44.510: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/rewri... (200; 3.535403ms)
Feb 13 14:28:44.512: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 5.309012ms)
Feb 13 14:28:44.512: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 5.496635ms)
Feb 13 14:28:44.512: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 5.579233ms)
Feb 13 14:28:44.512: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:462/proxy/: tls qux (200; 5.648712ms)
Feb 13 14:28:44.512: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:460/proxy/: tls baz (200; 5.994153ms)
Feb 13 14:28:44.513: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/... (200; 6.117299ms)
Feb 13 14:28:44.513: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname1/proxy/: tls baz (200; 5.983246ms)
Feb 13 14:28:44.513: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 6.180248ms)
Feb 13 14:28:44.513: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/... (200; 6.643208ms)
Feb 13 14:28:44.513: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/rewriteme"... (200; 6.537998ms)
Feb 13 14:28:44.513: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname2/proxy/: bar (200; 6.770132ms)
Feb 13 14:28:44.513: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname2/proxy/: tls qux (200; 6.958719ms)
Feb 13 14:28:44.514: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname2/proxy/: bar (200; 7.257457ms)
Feb 13 14:28:44.514: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname1/proxy/: foo (200; 7.233698ms)
Feb 13 14:28:44.514: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname1/proxy/: foo (200; 7.342944ms)
Feb 13 14:28:44.527: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 11.979531ms)
Feb 13 14:28:44.527: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname2/proxy/: bar (200; 11.752843ms)
Feb 13 14:28:44.527: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 12.774236ms)
Feb 13 14:28:44.527: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname1/proxy/: foo (200; 12.863372ms)
Feb 13 14:28:44.527: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/rewri... (200; 12.554495ms)
Feb 13 14:28:44.527: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname2/proxy/: bar (200; 13.205972ms)
Feb 13 14:28:44.528: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/rewriteme"... (200; 12.541339ms)
Feb 13 14:28:44.528: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 13.415522ms)
Feb 13 14:28:44.528: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname1/proxy/: foo (200; 13.484702ms)
Feb 13 14:28:44.528: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/... (200; 13.64348ms)
Feb 13 14:28:44.528: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 12.980851ms)
Feb 13 14:28:44.528: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/... (200; 13.079771ms)
Feb 13 14:28:44.528: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:460/proxy/: tls baz (200; 13.522505ms)
Feb 13 14:28:44.529: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:462/proxy/: tls qux (200; 13.658851ms)
Feb 13 14:28:44.529: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname2/proxy/: tls qux (200; 14.112561ms)
Feb 13 14:28:44.529: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname1/proxy/: tls baz (200; 14.337273ms)
Feb 13 14:28:44.533: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/... (200; 3.852063ms)
Feb 13 14:28:44.535: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:462/proxy/: tls qux (200; 5.56979ms)
Feb 13 14:28:44.535: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/... (200; 5.743779ms)
Feb 13 14:28:44.535: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 5.860587ms)
Feb 13 14:28:44.535: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/rewri... (200; 6.026178ms)
Feb 13 14:28:44.535: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/rewriteme"... (200; 6.10705ms)
Feb 13 14:28:44.536: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 6.582999ms)
Feb 13 14:28:44.536: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname2/proxy/: bar (200; 6.923458ms)
Feb 13 14:28:44.536: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 7.225361ms)
Feb 13 14:28:44.537: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname2/proxy/: tls qux (200; 7.861334ms)
Feb 13 14:28:44.537: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname2/proxy/: bar (200; 7.913911ms)
Feb 13 14:28:44.537: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 7.923256ms)
Feb 13 14:28:44.537: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:460/proxy/: tls baz (200; 7.893665ms)
Feb 13 14:28:44.537: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname1/proxy/: foo (200; 8.06261ms)
Feb 13 14:28:44.537: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname1/proxy/: tls baz (200; 8.157501ms)
Feb 13 14:28:44.537: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname1/proxy/: foo (200; 8.408245ms)
Feb 13 14:28:44.541: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/rewri... (200; 3.804493ms)
Feb 13 14:28:44.549: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/rewriteme"... (200; 11.002585ms)
Feb 13 14:28:44.549: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname2/proxy/: bar (200; 10.822158ms)
Feb 13 14:28:44.549: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/... (200; 11.025102ms)
Feb 13 14:28:44.549: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname1/proxy/: foo (200; 11.149138ms)
Feb 13 14:28:44.549: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 10.966357ms)
Feb 13 14:28:44.549: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname1/proxy/: foo (200; 10.684069ms)
Feb 13 14:28:44.549: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 10.90703ms)
Feb 13 14:28:44.549: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname2/proxy/: bar (200; 11.729102ms)
Feb 13 14:28:44.549: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 11.633147ms)
Feb 13 14:28:44.550: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 11.68357ms)
Feb 13 14:28:44.550: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:460/proxy/: tls baz (200; 11.418644ms)
Feb 13 14:28:44.550: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname1/proxy/: tls baz (200; 11.269282ms)
Feb 13 14:28:44.550: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/... (200; 12.144827ms)
Feb 13 14:28:44.550: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname2/proxy/: tls qux (200; 11.370489ms)
Feb 13 14:28:44.550: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:462/proxy/: tls qux (200; 11.640818ms)
Feb 13 14:28:44.554: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 3.805732ms)
Feb 13 14:28:44.555: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/... (200; 4.682858ms)
Feb 13 14:28:44.555: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:460/proxy/: tls baz (200; 4.472101ms)
Feb 13 14:28:44.555: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:462/proxy/: tls qux (200; 4.755681ms)
Feb 13 14:28:44.555: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 5.36681ms)
Feb 13 14:28:44.556: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/rewri... (200; 5.094518ms)
Feb 13 14:28:44.556: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 5.42003ms)
Feb 13 14:28:44.556: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 4.559084ms)
Feb 13 14:28:44.556: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/rewriteme"... (200; 4.680018ms)
Feb 13 14:28:44.556: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname1/proxy/: foo (200; 6.048172ms)
Feb 13 14:28:44.558: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname1/proxy/: tls baz (200; 6.617933ms)
Feb 13 14:28:44.558: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/... (200; 6.013004ms)
Feb 13 14:28:44.558: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname2/proxy/: bar (200; 7.437909ms)
Feb 13 14:28:44.558: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname1/proxy/: foo (200; 6.945949ms)
Feb 13 14:28:44.558: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname2/proxy/: bar (200; 6.354626ms)
Feb 13 14:28:44.558: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname2/proxy/: tls qux (200; 6.99119ms)
Feb 13 14:28:44.562: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 3.993296ms)
Feb 13 14:28:44.564: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:460/proxy/: tls baz (200; 5.81798ms)
Feb 13 14:28:44.564: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 5.985311ms)
Feb 13 14:28:44.564: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/rewri... (200; 5.997795ms)
Feb 13 14:28:44.565: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 6.106411ms)
Feb 13 14:28:44.565: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/... (200; 6.216534ms)
Feb 13 14:28:44.565: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/rewriteme"... (200; 6.254025ms)
Feb 13 14:28:44.565: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 6.413568ms)
Feb 13 14:28:44.565: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname1/proxy/: foo (200; 6.626624ms)
Feb 13 14:28:44.565: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/... (200; 6.578398ms)
Feb 13 14:28:44.565: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:462/proxy/: tls qux (200; 6.704914ms)
Feb 13 14:28:44.565: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname1/proxy/: foo (200; 6.861391ms)
Feb 13 14:28:44.566: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname1/proxy/: tls baz (200; 7.214801ms)
Feb 13 14:28:44.566: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname2/proxy/: tls qux (200; 7.216473ms)
Feb 13 14:28:44.566: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname2/proxy/: bar (200; 7.2522ms)
Feb 13 14:28:44.566: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname2/proxy/: bar (200; 7.455413ms)
Feb 13 14:28:44.570: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:462/proxy/: tls qux (200; 3.670672ms)
Feb 13 14:28:44.570: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 3.97017ms)
Feb 13 14:28:44.572: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/... (200; 5.031791ms)
Feb 13 14:28:44.572: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname2/proxy/: bar (200; 5.644932ms)
Feb 13 14:28:44.572: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 5.54833ms)
Feb 13 14:28:44.572: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/rewriteme"... (200; 5.62593ms)
Feb 13 14:28:44.574: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname1/proxy/: foo (200; 7.30152ms)
Feb 13 14:28:44.574: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 7.374176ms)
Feb 13 14:28:44.574: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname2/proxy/: bar (200; 7.617946ms)
Feb 13 14:28:44.574: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 7.481246ms)
Feb 13 14:28:44.575: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/rewri... (200; 8.02757ms)
Feb 13 14:28:44.575: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:460/proxy/: tls baz (200; 7.982171ms)
Feb 13 14:28:44.575: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/... (200; 8.764744ms)
Feb 13 14:28:44.575: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname1/proxy/: tls baz (200; 8.251136ms)
Feb 13 14:28:44.575: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname1/proxy/: foo (200; 8.427039ms)
Feb 13 14:28:44.576: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname2/proxy/: tls qux (200; 8.727369ms)
Feb 13 14:28:44.579: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 3.561379ms)
Feb 13 14:28:44.581: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:460/proxy/: tls baz (200; 4.944182ms)
Feb 13 14:28:44.581: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 5.071761ms)
Feb 13 14:28:44.581: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/rewri... (200; 5.1909ms)
Feb 13 14:28:44.581: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/rewriteme"... (200; 4.79066ms)
Feb 13 14:28:44.581: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 4.724864ms)
Feb 13 14:28:44.582: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/... (200; 5.047347ms)
Feb 13 14:28:44.582: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 5.18953ms)
Feb 13 14:28:44.582: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/... (200; 5.030161ms)
Feb 13 14:28:44.582: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname1/proxy/: foo (200; 6.500678ms)
Feb 13 14:28:44.582: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:462/proxy/: tls qux (200; 5.983781ms)
Feb 13 14:28:44.583: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname2/proxy/: bar (200; 6.280679ms)
Feb 13 14:28:44.583: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname2/proxy/: tls qux (200; 6.849931ms)
Feb 13 14:28:44.583: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname1/proxy/: tls baz (200; 7.15067ms)
Feb 13 14:28:44.583: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname2/proxy/: bar (200; 6.5385ms)
Feb 13 14:28:44.584: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname1/proxy/: foo (200; 6.776578ms)
Feb 13 14:28:44.587: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:462/proxy/: tls qux (200; 3.417898ms)
Feb 13 14:28:44.588: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 3.557432ms)
Feb 13 14:28:44.588: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/... (200; 3.754496ms)
Feb 13 14:28:44.588: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/rewriteme"... (200; 3.996936ms)
Feb 13 14:28:44.588: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 4.21983ms)
Feb 13 14:28:44.588: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 3.691175ms)
Feb 13 14:28:44.589: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname2/proxy/: bar (200; 5.008091ms)
Feb 13 14:28:44.589: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/... (200; 4.3674ms)
Feb 13 14:28:44.589: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:460/proxy/: tls baz (200; 4.268838ms)
Feb 13 14:28:44.589: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 4.344858ms)
Feb 13 14:28:44.589: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/rewri... (200; 4.474889ms)
Feb 13 14:28:44.591: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname1/proxy/: foo (200; 5.895504ms)
Feb 13 14:28:44.591: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname2/proxy/: bar (200; 6.371409ms)
Feb 13 14:28:44.591: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname1/proxy/: foo (200; 6.485212ms)
Feb 13 14:28:44.591: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname1/proxy/: tls baz (200; 6.024871ms)
Feb 13 14:28:44.591: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname2/proxy/: tls qux (200; 6.332293ms)
Feb 13 14:28:44.595: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:462/proxy/: tls qux (200; 3.242261ms)
Feb 13 14:28:44.596: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 4.824445ms)
Feb 13 14:28:44.596: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:460/proxy/: tls baz (200; 4.33353ms)
Feb 13 14:28:44.596: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/rewriteme"... (200; 4.264984ms)
Feb 13 14:28:44.596: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 4.137014ms)
Feb 13 14:28:44.597: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/... (200; 4.859884ms)
Feb 13 14:28:44.597: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 5.427116ms)
Feb 13 14:28:44.597: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/... (200; 5.527368ms)
Feb 13 14:28:44.598: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 5.917969ms)
Feb 13 14:28:44.600: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/rewri... (200; 8.365082ms)
Feb 13 14:28:44.600: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname2/proxy/: bar (200; 7.864565ms)
Feb 13 14:28:44.600: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname2/proxy/: tls qux (200; 8.873792ms)
Feb 13 14:28:44.600: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname1/proxy/: foo (200; 8.322211ms)
Feb 13 14:28:44.600: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname2/proxy/: bar (200; 8.669912ms)
Feb 13 14:28:44.600: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname1/proxy/: foo (200; 9.077797ms)
Feb 13 14:28:44.600: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname1/proxy/: tls baz (200; 9.064674ms)
Feb 13 14:28:44.604: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 3.531367ms)
Feb 13 14:28:44.606: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86/proxy/rewriteme"... (200; 4.316515ms)
Feb 13 14:28:44.606: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:462/proxy/: tls qux (200; 4.812831ms)
Feb 13 14:28:44.606: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 5.132869ms)
Feb 13 14:28:44.607: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:460/proxy/: tls baz (200; 5.681998ms)
Feb 13 14:28:44.607: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname2/proxy/: bar (200; 5.945272ms)
Feb 13 14:28:44.607: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/http:proxy-service-xtt7r-vzj86:1080/proxy/... (200; 6.054075ms)
Feb 13 14:28:44.607: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname1/proxy/: foo (200; 5.939951ms)
Feb 13 14:28:44.607: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:160/proxy/: foo (200; 5.509894ms)
Feb 13 14:28:44.607: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:162/proxy/: bar (200; 5.895359ms)
Feb 13 14:28:44.607: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/proxy-service-xtt7r-vzj86:1080/proxy/rewri... (200; 6.132286ms)
Feb 13 14:28:44.608: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8bckx/pods/https:proxy-service-xtt7r-vzj86:443/proxy/... (200; 5.929746ms)
Feb 13 14:28:44.608: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname2/proxy/: tls qux (200; 6.649476ms)
Feb 13 14:28:44.608: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/proxy-service-xtt7r:portname1/proxy/: foo (200; 7.529591ms)
Feb 13 14:28:44.608: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/https:proxy-service-xtt7r:tlsportname1/proxy/: tls baz (200; 7.063024ms)
Feb 13 14:28:44.608: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8bckx/services/http:proxy-service-xtt7r:portname2/proxy/: bar (200; 6.795319ms)
STEP: deleting { ReplicationController} proxy-service-xtt7r in namespace e2e-tests-proxy-8bckx, will wait for the garbage collector to delete the pods
Feb 13 14:28:44.671: INFO: Deleting { ReplicationController} proxy-service-xtt7r took: 9.863479ms
Feb 13 14:28:44.772: INFO: Terminating { ReplicationController} proxy-service-xtt7r pods took: 100.236629ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:28:58.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-8bckx" for this suite.
Feb 13 14:29:04.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:29:04.590: INFO: namespace: e2e-tests-proxy-8bckx, resource: bindings, ignored listing per whitelist
Feb 13 14:29:04.620: INFO: namespace e2e-tests-proxy-8bckx deletion completed in 6.137152934s

• [SLOW TEST:24.455 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:29:04.620: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb 13 14:29:04.719: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qs7fg,SelfLink:/api/v1/namespaces/e2e-tests-watch-qs7fg/configmaps/e2e-watch-test-configmap-a,UID:b6f03ce2-2f9b-11e9-85f4-fa163e429998,ResourceVersion:2517125,Generation:0,CreationTimestamp:2019-02-13 14:29:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 13 14:29:04.719: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qs7fg,SelfLink:/api/v1/namespaces/e2e-tests-watch-qs7fg/configmaps/e2e-watch-test-configmap-a,UID:b6f03ce2-2f9b-11e9-85f4-fa163e429998,ResourceVersion:2517125,Generation:0,CreationTimestamp:2019-02-13 14:29:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb 13 14:29:14.734: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qs7fg,SelfLink:/api/v1/namespaces/e2e-tests-watch-qs7fg/configmaps/e2e-watch-test-configmap-a,UID:b6f03ce2-2f9b-11e9-85f4-fa163e429998,ResourceVersion:2517150,Generation:0,CreationTimestamp:2019-02-13 14:29:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 13 14:29:14.734: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qs7fg,SelfLink:/api/v1/namespaces/e2e-tests-watch-qs7fg/configmaps/e2e-watch-test-configmap-a,UID:b6f03ce2-2f9b-11e9-85f4-fa163e429998,ResourceVersion:2517150,Generation:0,CreationTimestamp:2019-02-13 14:29:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb 13 14:29:24.749: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qs7fg,SelfLink:/api/v1/namespaces/e2e-tests-watch-qs7fg/configmaps/e2e-watch-test-configmap-a,UID:b6f03ce2-2f9b-11e9-85f4-fa163e429998,ResourceVersion:2517175,Generation:0,CreationTimestamp:2019-02-13 14:29:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 13 14:29:24.750: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qs7fg,SelfLink:/api/v1/namespaces/e2e-tests-watch-qs7fg/configmaps/e2e-watch-test-configmap-a,UID:b6f03ce2-2f9b-11e9-85f4-fa163e429998,ResourceVersion:2517175,Generation:0,CreationTimestamp:2019-02-13 14:29:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb 13 14:29:34.765: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qs7fg,SelfLink:/api/v1/namespaces/e2e-tests-watch-qs7fg/configmaps/e2e-watch-test-configmap-a,UID:b6f03ce2-2f9b-11e9-85f4-fa163e429998,ResourceVersion:2517200,Generation:0,CreationTimestamp:2019-02-13 14:29:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 13 14:29:34.765: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qs7fg,SelfLink:/api/v1/namespaces/e2e-tests-watch-qs7fg/configmaps/e2e-watch-test-configmap-a,UID:b6f03ce2-2f9b-11e9-85f4-fa163e429998,ResourceVersion:2517200,Generation:0,CreationTimestamp:2019-02-13 14:29:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb 13 14:29:44.780: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-qs7fg,SelfLink:/api/v1/namespaces/e2e-tests-watch-qs7fg/configmaps/e2e-watch-test-configmap-b,UID:ced0c1b3-2f9b-11e9-85f4-fa163e429998,ResourceVersion:2517225,Generation:0,CreationTimestamp:2019-02-13 14:29:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 13 14:29:44.780: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-qs7fg,SelfLink:/api/v1/namespaces/e2e-tests-watch-qs7fg/configmaps/e2e-watch-test-configmap-b,UID:ced0c1b3-2f9b-11e9-85f4-fa163e429998,ResourceVersion:2517225,Generation:0,CreationTimestamp:2019-02-13 14:29:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb 13 14:29:54.795: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-qs7fg,SelfLink:/api/v1/namespaces/e2e-tests-watch-qs7fg/configmaps/e2e-watch-test-configmap-b,UID:ced0c1b3-2f9b-11e9-85f4-fa163e429998,ResourceVersion:2517250,Generation:0,CreationTimestamp:2019-02-13 14:29:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 13 14:29:54.795: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-qs7fg,SelfLink:/api/v1/namespaces/e2e-tests-watch-qs7fg/configmaps/e2e-watch-test-configmap-b,UID:ced0c1b3-2f9b-11e9-85f4-fa163e429998,ResourceVersion:2517250,Generation:0,CreationTimestamp:2019-02-13 14:29:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:30:04.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-qs7fg" for this suite.
Feb 13 14:30:10.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:30:10.833: INFO: namespace: e2e-tests-watch-qs7fg, resource: bindings, ignored listing per whitelist
Feb 13 14:30:10.936: INFO: namespace e2e-tests-watch-qs7fg deletion completed in 6.129127914s

• [SLOW TEST:66.316 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:30:10.936: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Feb 13 14:30:11.035: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-172602910 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:30:11.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cczvk" for this suite.
Feb 13 14:30:17.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:30:17.215: INFO: namespace: e2e-tests-kubectl-cczvk, resource: bindings, ignored listing per whitelist
Feb 13 14:30:17.274: INFO: namespace e2e-tests-kubectl-cczvk deletion completed in 6.125886128s

• [SLOW TEST:6.338 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:30:17.275: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-e23dbd39-2f9b-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume configMaps
Feb 13 14:30:17.379: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e23ed74e-2f9b-11e9-9b61-026654d605e3" in namespace "e2e-tests-projected-llbkr" to be "success or failure"
Feb 13 14:30:17.382: INFO: Pod "pod-projected-configmaps-e23ed74e-2f9b-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.820949ms
Feb 13 14:30:19.387: INFO: Pod "pod-projected-configmaps-e23ed74e-2f9b-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008010196s
Feb 13 14:30:21.392: INFO: Pod "pod-projected-configmaps-e23ed74e-2f9b-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013021481s
STEP: Saw pod success
Feb 13 14:30:21.392: INFO: Pod "pod-projected-configmaps-e23ed74e-2f9b-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:30:21.396: INFO: Trying to get logs from node cmp3 pod pod-projected-configmaps-e23ed74e-2f9b-11e9-9b61-026654d605e3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 14:30:21.417: INFO: Waiting for pod pod-projected-configmaps-e23ed74e-2f9b-11e9-9b61-026654d605e3 to disappear
Feb 13 14:30:21.420: INFO: Pod pod-projected-configmaps-e23ed74e-2f9b-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:30:21.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-llbkr" for this suite.
Feb 13 14:30:27.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:30:27.505: INFO: namespace: e2e-tests-projected-llbkr, resource: bindings, ignored listing per whitelist
Feb 13 14:30:27.547: INFO: namespace e2e-tests-projected-llbkr deletion completed in 6.12281137s

• [SLOW TEST:10.273 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:30:27.547: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 13 14:30:27.665: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:27.665: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:27.666: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:27.669: INFO: Number of nodes with available pods: 0
Feb 13 14:30:27.669: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:30:28.675: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:28.675: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:28.675: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:28.678: INFO: Number of nodes with available pods: 0
Feb 13 14:30:28.678: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:30:29.675: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:29.675: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:29.675: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:29.679: INFO: Number of nodes with available pods: 1
Feb 13 14:30:29.679: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:30:30.675: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:30.675: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:30.675: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:30.679: INFO: Number of nodes with available pods: 3
Feb 13 14:30:30.679: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb 13 14:30:30.698: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:30.699: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:30.699: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:30.702: INFO: Number of nodes with available pods: 2
Feb 13 14:30:30.702: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:30:31.708: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:31.708: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:31.708: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:31.712: INFO: Number of nodes with available pods: 2
Feb 13 14:30:31.712: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:30:32.708: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:32.708: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:32.708: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:32.712: INFO: Number of nodes with available pods: 2
Feb 13 14:30:32.713: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:30:33.707: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:33.708: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:33.708: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:33.711: INFO: Number of nodes with available pods: 2
Feb 13 14:30:33.711: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:30:34.708: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:34.708: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:34.708: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:34.711: INFO: Number of nodes with available pods: 2
Feb 13 14:30:34.711: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:30:35.714: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:35.714: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:35.714: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:35.718: INFO: Number of nodes with available pods: 2
Feb 13 14:30:35.718: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:30:36.708: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:36.708: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:36.708: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:36.711: INFO: Number of nodes with available pods: 2
Feb 13 14:30:36.711: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:30:37.708: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:37.708: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:37.708: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:37.712: INFO: Number of nodes with available pods: 2
Feb 13 14:30:37.712: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:30:38.709: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:38.709: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:38.709: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:38.712: INFO: Number of nodes with available pods: 2
Feb 13 14:30:38.712: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:30:39.709: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:39.710: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:39.710: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:39.713: INFO: Number of nodes with available pods: 2
Feb 13 14:30:39.713: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:30:40.709: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:40.709: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:40.709: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:40.714: INFO: Number of nodes with available pods: 2
Feb 13 14:30:40.714: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:30:41.708: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:41.708: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:41.708: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:41.712: INFO: Number of nodes with available pods: 2
Feb 13 14:30:41.712: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:30:42.708: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:42.709: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:42.709: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:42.712: INFO: Number of nodes with available pods: 2
Feb 13 14:30:42.713: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:30:43.709: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:43.709: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:43.709: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:43.713: INFO: Number of nodes with available pods: 2
Feb 13 14:30:43.713: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:30:44.708: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:44.708: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:44.708: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:44.713: INFO: Number of nodes with available pods: 2
Feb 13 14:30:44.713: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:30:45.708: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:45.709: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:45.709: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:45.713: INFO: Number of nodes with available pods: 2
Feb 13 14:30:45.713: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:30:46.714: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:46.714: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:46.714: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:46.718: INFO: Number of nodes with available pods: 2
Feb 13 14:30:46.718: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:30:47.708: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:47.708: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:47.708: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:47.711: INFO: Number of nodes with available pods: 2
Feb 13 14:30:47.711: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:30:48.708: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:48.708: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:48.708: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:48.712: INFO: Number of nodes with available pods: 2
Feb 13 14:30:48.712: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:30:49.708: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:49.708: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:49.708: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:49.712: INFO: Number of nodes with available pods: 2
Feb 13 14:30:49.712: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:30:50.709: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:50.709: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:50.709: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:50.716: INFO: Number of nodes with available pods: 2
Feb 13 14:30:50.716: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:30:51.707: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:51.707: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:51.707: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:51.710: INFO: Number of nodes with available pods: 2
Feb 13 14:30:51.711: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:30:52.709: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:52.709: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:52.709: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:52.712: INFO: Number of nodes with available pods: 2
Feb 13 14:30:52.713: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:30:53.708: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:53.708: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:53.708: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:53.712: INFO: Number of nodes with available pods: 2
Feb 13 14:30:53.712: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:30:54.708: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:54.708: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:54.708: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:54.712: INFO: Number of nodes with available pods: 2
Feb 13 14:30:54.712: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:30:55.708: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:55.708: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:55.708: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:55.712: INFO: Number of nodes with available pods: 2
Feb 13 14:30:55.712: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:30:56.709: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:56.709: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:56.709: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:56.713: INFO: Number of nodes with available pods: 2
Feb 13 14:30:56.713: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:30:57.714: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:57.714: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:57.714: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:57.718: INFO: Number of nodes with available pods: 2
Feb 13 14:30:57.718: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:30:58.708: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:58.708: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:58.708: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:58.712: INFO: Number of nodes with available pods: 2
Feb 13 14:30:58.712: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:30:59.708: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:59.708: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:59.708: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:30:59.711: INFO: Number of nodes with available pods: 2
Feb 13 14:30:59.711: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:31:00.708: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:31:00.708: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:31:00.708: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:31:00.712: INFO: Number of nodes with available pods: 2
Feb 13 14:31:00.712: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:31:01.708: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:31:01.708: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:31:01.708: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:31:01.712: INFO: Number of nodes with available pods: 2
Feb 13 14:31:01.712: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:31:02.708: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:31:02.708: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:31:02.708: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:31:02.712: INFO: Number of nodes with available pods: 2
Feb 13 14:31:02.712: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:31:03.708: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:31:03.708: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:31:03.708: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:31:03.712: INFO: Number of nodes with available pods: 2
Feb 13 14:31:03.712: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:31:04.708: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:31:04.708: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:31:04.708: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:31:04.711: INFO: Number of nodes with available pods: 2
Feb 13 14:31:04.711: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:31:05.710: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:31:05.710: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:31:05.710: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:31:05.714: INFO: Number of nodes with available pods: 2
Feb 13 14:31:05.714: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:31:06.707: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:31:06.707: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:31:06.707: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:31:06.711: INFO: Number of nodes with available pods: 2
Feb 13 14:31:06.711: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:31:07.708: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:31:07.708: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:31:07.708: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:31:07.712: INFO: Number of nodes with available pods: 2
Feb 13 14:31:07.712: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:31:08.715: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:31:08.715: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:31:08.715: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:31:08.718: INFO: Number of nodes with available pods: 3
Feb 13 14:31:08.718: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-xsdgn, will wait for the garbage collector to delete the pods
Feb 13 14:31:08.783: INFO: Deleting {extensions DaemonSet} daemon-set took: 8.429032ms
Feb 13 14:31:08.883: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.241798ms
Feb 13 14:31:52.893: INFO: Number of nodes with available pods: 0
Feb 13 14:31:52.893: INFO: Number of running nodes: 0, number of available pods: 0
Feb 13 14:31:52.896: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-xsdgn/daemonsets","resourceVersion":"2517682"},"items":null}

Feb 13 14:31:52.899: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-xsdgn/pods","resourceVersion":"2517682"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:31:52.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-xsdgn" for this suite.
Feb 13 14:31:58.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:31:59.000: INFO: namespace: e2e-tests-daemonsets-xsdgn, resource: bindings, ignored listing per whitelist
Feb 13 14:31:59.054: INFO: namespace e2e-tests-daemonsets-xsdgn deletion completed in 6.135985458s

• [SLOW TEST:91.507 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:31:59.055: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-jvgvr
I0213 14:31:59.154342      18 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-jvgvr, replica count: 1
I0213 14:32:00.204806      18 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0213 14:32:01.204990      18 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 13 14:32:01.325: INFO: Created: latency-svc-n66n5
Feb 13 14:32:01.337: INFO: Got endpoints: latency-svc-n66n5 [31.787232ms]
Feb 13 14:32:01.347: INFO: Created: latency-svc-tndrj
Feb 13 14:32:01.352: INFO: Got endpoints: latency-svc-tndrj [15.066546ms]
Feb 13 14:32:01.354: INFO: Created: latency-svc-lh6zh
Feb 13 14:32:01.359: INFO: Got endpoints: latency-svc-lh6zh [22.742195ms]
Feb 13 14:32:01.360: INFO: Created: latency-svc-xnlcm
Feb 13 14:32:01.365: INFO: Got endpoints: latency-svc-xnlcm [28.129935ms]
Feb 13 14:32:01.367: INFO: Created: latency-svc-qft29
Feb 13 14:32:01.371: INFO: Got endpoints: latency-svc-qft29 [33.933591ms]
Feb 13 14:32:01.374: INFO: Created: latency-svc-vwsrq
Feb 13 14:32:01.388: INFO: Got endpoints: latency-svc-vwsrq [50.720576ms]
Feb 13 14:32:01.391: INFO: Created: latency-svc-x94mt
Feb 13 14:32:01.394: INFO: Got endpoints: latency-svc-x94mt [57.651302ms]
Feb 13 14:32:01.397: INFO: Created: latency-svc-46gwh
Feb 13 14:32:01.400: INFO: Got endpoints: latency-svc-46gwh [63.76704ms]
Feb 13 14:32:01.403: INFO: Created: latency-svc-q96sv
Feb 13 14:32:01.408: INFO: Got endpoints: latency-svc-q96sv [71.601377ms]
Feb 13 14:32:01.411: INFO: Created: latency-svc-dx9j4
Feb 13 14:32:01.414: INFO: Got endpoints: latency-svc-dx9j4 [77.656595ms]
Feb 13 14:32:01.418: INFO: Created: latency-svc-qvbcs
Feb 13 14:32:01.422: INFO: Got endpoints: latency-svc-qvbcs [85.098692ms]
Feb 13 14:32:01.426: INFO: Created: latency-svc-mr6tf
Feb 13 14:32:01.429: INFO: Got endpoints: latency-svc-mr6tf [92.120049ms]
Feb 13 14:32:01.431: INFO: Created: latency-svc-hlzw4
Feb 13 14:32:01.435: INFO: Got endpoints: latency-svc-hlzw4 [98.101888ms]
Feb 13 14:32:01.439: INFO: Created: latency-svc-jsldq
Feb 13 14:32:01.443: INFO: Got endpoints: latency-svc-jsldq [105.83012ms]
Feb 13 14:32:01.447: INFO: Created: latency-svc-bmj77
Feb 13 14:32:01.452: INFO: Got endpoints: latency-svc-bmj77 [115.536654ms]
Feb 13 14:32:01.456: INFO: Created: latency-svc-t7jz2
Feb 13 14:32:01.461: INFO: Got endpoints: latency-svc-t7jz2 [17.954087ms]
Feb 13 14:32:01.464: INFO: Created: latency-svc-f28nb
Feb 13 14:32:01.476: INFO: Got endpoints: latency-svc-f28nb [139.248523ms]
Feb 13 14:32:01.488: INFO: Created: latency-svc-m9vd7
Feb 13 14:32:01.492: INFO: Got endpoints: latency-svc-m9vd7 [140.550574ms]
Feb 13 14:32:01.497: INFO: Created: latency-svc-9h69k
Feb 13 14:32:01.502: INFO: Got endpoints: latency-svc-9h69k [142.816978ms]
Feb 13 14:32:01.505: INFO: Created: latency-svc-zw97z
Feb 13 14:32:01.508: INFO: Got endpoints: latency-svc-zw97z [143.127167ms]
Feb 13 14:32:01.510: INFO: Created: latency-svc-w5dlw
Feb 13 14:32:01.514: INFO: Got endpoints: latency-svc-w5dlw [143.048639ms]
Feb 13 14:32:01.517: INFO: Created: latency-svc-gqcfh
Feb 13 14:32:01.521: INFO: Got endpoints: latency-svc-gqcfh [133.13326ms]
Feb 13 14:32:01.525: INFO: Created: latency-svc-8cx78
Feb 13 14:32:01.530: INFO: Got endpoints: latency-svc-8cx78 [135.729981ms]
Feb 13 14:32:01.532: INFO: Created: latency-svc-448hw
Feb 13 14:32:01.535: INFO: Got endpoints: latency-svc-448hw [134.559218ms]
Feb 13 14:32:01.538: INFO: Created: latency-svc-2clff
Feb 13 14:32:01.542: INFO: Got endpoints: latency-svc-2clff [133.463425ms]
Feb 13 14:32:01.545: INFO: Created: latency-svc-kff25
Feb 13 14:32:01.550: INFO: Got endpoints: latency-svc-kff25 [135.775396ms]
Feb 13 14:32:01.552: INFO: Created: latency-svc-78zzs
Feb 13 14:32:01.556: INFO: Got endpoints: latency-svc-78zzs [133.723029ms]
Feb 13 14:32:01.559: INFO: Created: latency-svc-wx4zx
Feb 13 14:32:01.564: INFO: Got endpoints: latency-svc-wx4zx [134.827618ms]
Feb 13 14:32:01.567: INFO: Created: latency-svc-gtwg7
Feb 13 14:32:01.572: INFO: Got endpoints: latency-svc-gtwg7 [137.117973ms]
Feb 13 14:32:01.574: INFO: Created: latency-svc-6kwrm
Feb 13 14:32:01.578: INFO: Got endpoints: latency-svc-6kwrm [125.338535ms]
Feb 13 14:32:01.580: INFO: Created: latency-svc-44ts9
Feb 13 14:32:01.585: INFO: Got endpoints: latency-svc-44ts9 [124.347206ms]
Feb 13 14:32:01.588: INFO: Created: latency-svc-jkfrq
Feb 13 14:32:01.593: INFO: Got endpoints: latency-svc-jkfrq [116.704078ms]
Feb 13 14:32:01.596: INFO: Created: latency-svc-ng769
Feb 13 14:32:01.601: INFO: Got endpoints: latency-svc-ng769 [108.959896ms]
Feb 13 14:32:01.604: INFO: Created: latency-svc-zhcdb
Feb 13 14:32:01.607: INFO: Got endpoints: latency-svc-zhcdb [105.057892ms]
Feb 13 14:32:01.611: INFO: Created: latency-svc-7nf7f
Feb 13 14:32:01.627: INFO: Got endpoints: latency-svc-7nf7f [118.564237ms]
Feb 13 14:32:01.630: INFO: Created: latency-svc-prbjj
Feb 13 14:32:01.634: INFO: Got endpoints: latency-svc-prbjj [119.799835ms]
Feb 13 14:32:01.637: INFO: Created: latency-svc-2kmbg
Feb 13 14:32:01.645: INFO: Created: latency-svc-gpprk
Feb 13 14:32:01.652: INFO: Created: latency-svc-wrs5k
Feb 13 14:32:01.659: INFO: Created: latency-svc-h8qkt
Feb 13 14:32:01.665: INFO: Created: latency-svc-rjkz9
Feb 13 14:32:01.671: INFO: Created: latency-svc-5xcqc
Feb 13 14:32:01.678: INFO: Created: latency-svc-kxspg
Feb 13 14:32:01.680: INFO: Got endpoints: latency-svc-2kmbg [159.000484ms]
Feb 13 14:32:01.688: INFO: Created: latency-svc-5t776
Feb 13 14:32:01.695: INFO: Created: latency-svc-4xk2v
Feb 13 14:32:01.703: INFO: Created: latency-svc-gk8z4
Feb 13 14:32:01.710: INFO: Created: latency-svc-ntggt
Feb 13 14:32:01.717: INFO: Created: latency-svc-99lwx
Feb 13 14:32:01.725: INFO: Created: latency-svc-nk64q
Feb 13 14:32:01.732: INFO: Got endpoints: latency-svc-gpprk [202.129427ms]
Feb 13 14:32:01.738: INFO: Created: latency-svc-7tdq5
Feb 13 14:32:01.745: INFO: Created: latency-svc-n89gg
Feb 13 14:32:01.752: INFO: Created: latency-svc-w9krl
Feb 13 14:32:01.760: INFO: Created: latency-svc-qhrvl
Feb 13 14:32:01.780: INFO: Got endpoints: latency-svc-wrs5k [245.315828ms]
Feb 13 14:32:01.791: INFO: Created: latency-svc-xsqvt
Feb 13 14:32:01.831: INFO: Got endpoints: latency-svc-h8qkt [288.985113ms]
Feb 13 14:32:01.842: INFO: Created: latency-svc-f8ct6
Feb 13 14:32:01.880: INFO: Got endpoints: latency-svc-rjkz9 [330.175189ms]
Feb 13 14:32:01.891: INFO: Created: latency-svc-7p665
Feb 13 14:32:01.930: INFO: Got endpoints: latency-svc-5xcqc [374.202321ms]
Feb 13 14:32:01.940: INFO: Created: latency-svc-5hjdn
Feb 13 14:32:01.981: INFO: Got endpoints: latency-svc-kxspg [416.837155ms]
Feb 13 14:32:01.991: INFO: Created: latency-svc-dmdwz
Feb 13 14:32:02.030: INFO: Got endpoints: latency-svc-5t776 [458.205249ms]
Feb 13 14:32:02.041: INFO: Created: latency-svc-gmwmx
Feb 13 14:32:02.081: INFO: Got endpoints: latency-svc-4xk2v [503.027511ms]
Feb 13 14:32:02.091: INFO: Created: latency-svc-5xtmx
Feb 13 14:32:02.131: INFO: Got endpoints: latency-svc-gk8z4 [545.931904ms]
Feb 13 14:32:02.142: INFO: Created: latency-svc-rgnv6
Feb 13 14:32:02.181: INFO: Got endpoints: latency-svc-ntggt [588.090554ms]
Feb 13 14:32:02.194: INFO: Created: latency-svc-fq2p9
Feb 13 14:32:02.230: INFO: Got endpoints: latency-svc-99lwx [629.022082ms]
Feb 13 14:32:02.242: INFO: Created: latency-svc-r8rj4
Feb 13 14:32:02.282: INFO: Got endpoints: latency-svc-nk64q [674.745744ms]
Feb 13 14:32:02.294: INFO: Created: latency-svc-pfvbq
Feb 13 14:32:02.330: INFO: Got endpoints: latency-svc-7tdq5 [703.1847ms]
Feb 13 14:32:02.340: INFO: Created: latency-svc-26tw2
Feb 13 14:32:02.380: INFO: Got endpoints: latency-svc-n89gg [746.440023ms]
Feb 13 14:32:02.390: INFO: Created: latency-svc-65znb
Feb 13 14:32:02.430: INFO: Got endpoints: latency-svc-w9krl [750.663668ms]
Feb 13 14:32:02.442: INFO: Created: latency-svc-98s2p
Feb 13 14:32:02.480: INFO: Got endpoints: latency-svc-qhrvl [748.012127ms]
Feb 13 14:32:02.491: INFO: Created: latency-svc-h8h8g
Feb 13 14:32:02.532: INFO: Got endpoints: latency-svc-xsqvt [751.180009ms]
Feb 13 14:32:02.541: INFO: Created: latency-svc-hw7w7
Feb 13 14:32:02.581: INFO: Got endpoints: latency-svc-f8ct6 [750.405205ms]
Feb 13 14:32:02.593: INFO: Created: latency-svc-bmt72
Feb 13 14:32:02.630: INFO: Got endpoints: latency-svc-7p665 [749.921086ms]
Feb 13 14:32:02.641: INFO: Created: latency-svc-4fsww
Feb 13 14:32:02.680: INFO: Got endpoints: latency-svc-5hjdn [750.20041ms]
Feb 13 14:32:02.691: INFO: Created: latency-svc-dhctg
Feb 13 14:32:02.731: INFO: Got endpoints: latency-svc-dmdwz [749.977596ms]
Feb 13 14:32:02.742: INFO: Created: latency-svc-ztq6w
Feb 13 14:32:02.780: INFO: Got endpoints: latency-svc-gmwmx [749.915934ms]
Feb 13 14:32:02.791: INFO: Created: latency-svc-5srjk
Feb 13 14:32:02.830: INFO: Got endpoints: latency-svc-5xtmx [748.87349ms]
Feb 13 14:32:02.845: INFO: Created: latency-svc-5knjd
Feb 13 14:32:02.880: INFO: Got endpoints: latency-svc-rgnv6 [749.318763ms]
Feb 13 14:32:02.890: INFO: Created: latency-svc-rhzkp
Feb 13 14:32:02.930: INFO: Got endpoints: latency-svc-fq2p9 [748.698804ms]
Feb 13 14:32:02.945: INFO: Created: latency-svc-sfzt9
Feb 13 14:32:02.980: INFO: Got endpoints: latency-svc-r8rj4 [750.084012ms]
Feb 13 14:32:02.992: INFO: Created: latency-svc-7tjrk
Feb 13 14:32:03.031: INFO: Got endpoints: latency-svc-pfvbq [748.506225ms]
Feb 13 14:32:03.041: INFO: Created: latency-svc-mwp7n
Feb 13 14:32:03.081: INFO: Got endpoints: latency-svc-26tw2 [750.781535ms]
Feb 13 14:32:03.091: INFO: Created: latency-svc-6qkbr
Feb 13 14:32:03.130: INFO: Got endpoints: latency-svc-65znb [750.394875ms]
Feb 13 14:32:03.140: INFO: Created: latency-svc-k2smn
Feb 13 14:32:03.180: INFO: Got endpoints: latency-svc-98s2p [749.690238ms]
Feb 13 14:32:03.191: INFO: Created: latency-svc-b84s8
Feb 13 14:32:03.230: INFO: Got endpoints: latency-svc-h8h8g [749.980843ms]
Feb 13 14:32:03.242: INFO: Created: latency-svc-nfmh6
Feb 13 14:32:03.280: INFO: Got endpoints: latency-svc-hw7w7 [748.810347ms]
Feb 13 14:32:03.290: INFO: Created: latency-svc-g755d
Feb 13 14:32:03.333: INFO: Got endpoints: latency-svc-bmt72 [751.3527ms]
Feb 13 14:32:03.344: INFO: Created: latency-svc-7xzml
Feb 13 14:32:03.380: INFO: Got endpoints: latency-svc-4fsww [749.854538ms]
Feb 13 14:32:03.390: INFO: Created: latency-svc-6txqm
Feb 13 14:32:03.430: INFO: Got endpoints: latency-svc-dhctg [749.758647ms]
Feb 13 14:32:03.441: INFO: Created: latency-svc-wvs4t
Feb 13 14:32:03.480: INFO: Got endpoints: latency-svc-ztq6w [749.727213ms]
Feb 13 14:32:03.491: INFO: Created: latency-svc-k6bwj
Feb 13 14:32:03.531: INFO: Got endpoints: latency-svc-5srjk [750.220562ms]
Feb 13 14:32:03.543: INFO: Created: latency-svc-fbx5s
Feb 13 14:32:03.580: INFO: Got endpoints: latency-svc-5knjd [750.774086ms]
Feb 13 14:32:03.591: INFO: Created: latency-svc-97wbz
Feb 13 14:32:03.631: INFO: Got endpoints: latency-svc-rhzkp [750.846959ms]
Feb 13 14:32:03.642: INFO: Created: latency-svc-4nc5p
Feb 13 14:32:03.681: INFO: Got endpoints: latency-svc-sfzt9 [751.079408ms]
Feb 13 14:32:03.691: INFO: Created: latency-svc-mbws2
Feb 13 14:32:03.731: INFO: Got endpoints: latency-svc-7tjrk [750.337581ms]
Feb 13 14:32:03.743: INFO: Created: latency-svc-gzz46
Feb 13 14:32:03.781: INFO: Got endpoints: latency-svc-mwp7n [750.290093ms]
Feb 13 14:32:03.792: INFO: Created: latency-svc-294vn
Feb 13 14:32:03.830: INFO: Got endpoints: latency-svc-6qkbr [749.631004ms]
Feb 13 14:32:03.841: INFO: Created: latency-svc-gd67b
Feb 13 14:32:03.880: INFO: Got endpoints: latency-svc-k2smn [749.494516ms]
Feb 13 14:32:03.890: INFO: Created: latency-svc-6kfh2
Feb 13 14:32:03.931: INFO: Got endpoints: latency-svc-b84s8 [751.210029ms]
Feb 13 14:32:03.942: INFO: Created: latency-svc-bdtn9
Feb 13 14:32:03.980: INFO: Got endpoints: latency-svc-nfmh6 [749.961515ms]
Feb 13 14:32:03.991: INFO: Created: latency-svc-xpfb9
Feb 13 14:32:04.030: INFO: Got endpoints: latency-svc-g755d [749.120734ms]
Feb 13 14:32:04.041: INFO: Created: latency-svc-p5qp2
Feb 13 14:32:04.081: INFO: Got endpoints: latency-svc-7xzml [747.924803ms]
Feb 13 14:32:04.093: INFO: Created: latency-svc-bsl8c
Feb 13 14:32:04.130: INFO: Got endpoints: latency-svc-6txqm [749.490205ms]
Feb 13 14:32:04.140: INFO: Created: latency-svc-bfwgk
Feb 13 14:32:04.180: INFO: Got endpoints: latency-svc-wvs4t [750.007966ms]
Feb 13 14:32:04.191: INFO: Created: latency-svc-gmhxs
Feb 13 14:32:04.230: INFO: Got endpoints: latency-svc-k6bwj [749.573475ms]
Feb 13 14:32:04.240: INFO: Created: latency-svc-6bjsw
Feb 13 14:32:04.281: INFO: Got endpoints: latency-svc-fbx5s [750.116656ms]
Feb 13 14:32:04.291: INFO: Created: latency-svc-nbh7s
Feb 13 14:32:04.330: INFO: Got endpoints: latency-svc-97wbz [749.56704ms]
Feb 13 14:32:04.340: INFO: Created: latency-svc-6rp2v
Feb 13 14:32:04.382: INFO: Got endpoints: latency-svc-4nc5p [750.487295ms]
Feb 13 14:32:04.392: INFO: Created: latency-svc-x6fwz
Feb 13 14:32:04.434: INFO: Got endpoints: latency-svc-mbws2 [752.839716ms]
Feb 13 14:32:04.444: INFO: Created: latency-svc-k4tp4
Feb 13 14:32:04.480: INFO: Got endpoints: latency-svc-gzz46 [749.391111ms]
Feb 13 14:32:04.492: INFO: Created: latency-svc-7xkqm
Feb 13 14:32:04.530: INFO: Got endpoints: latency-svc-294vn [748.542374ms]
Feb 13 14:32:04.541: INFO: Created: latency-svc-q6s75
Feb 13 14:32:04.580: INFO: Got endpoints: latency-svc-gd67b [749.453143ms]
Feb 13 14:32:04.590: INFO: Created: latency-svc-jnvrl
Feb 13 14:32:04.630: INFO: Got endpoints: latency-svc-6kfh2 [749.875469ms]
Feb 13 14:32:04.641: INFO: Created: latency-svc-df4ht
Feb 13 14:32:04.680: INFO: Got endpoints: latency-svc-bdtn9 [748.781206ms]
Feb 13 14:32:04.691: INFO: Created: latency-svc-z6w7r
Feb 13 14:32:04.730: INFO: Got endpoints: latency-svc-xpfb9 [750.122609ms]
Feb 13 14:32:04.741: INFO: Created: latency-svc-c5gjz
Feb 13 14:32:04.781: INFO: Got endpoints: latency-svc-p5qp2 [751.808503ms]
Feb 13 14:32:04.791: INFO: Created: latency-svc-5fdlj
Feb 13 14:32:04.830: INFO: Got endpoints: latency-svc-bsl8c [749.524491ms]
Feb 13 14:32:04.841: INFO: Created: latency-svc-kvfq8
Feb 13 14:32:04.880: INFO: Got endpoints: latency-svc-bfwgk [750.484154ms]
Feb 13 14:32:04.898: INFO: Created: latency-svc-x8vwp
Feb 13 14:32:04.930: INFO: Got endpoints: latency-svc-gmhxs [749.936899ms]
Feb 13 14:32:04.940: INFO: Created: latency-svc-v27sq
Feb 13 14:32:04.980: INFO: Got endpoints: latency-svc-6bjsw [750.23735ms]
Feb 13 14:32:04.994: INFO: Created: latency-svc-2v5bv
Feb 13 14:32:05.030: INFO: Got endpoints: latency-svc-nbh7s [749.462842ms]
Feb 13 14:32:05.041: INFO: Created: latency-svc-z2fhm
Feb 13 14:32:05.080: INFO: Got endpoints: latency-svc-6rp2v [750.192892ms]
Feb 13 14:32:05.090: INFO: Created: latency-svc-288pr
Feb 13 14:32:05.130: INFO: Got endpoints: latency-svc-x6fwz [748.709222ms]
Feb 13 14:32:05.140: INFO: Created: latency-svc-jxbfm
Feb 13 14:32:05.180: INFO: Got endpoints: latency-svc-k4tp4 [746.439164ms]
Feb 13 14:32:05.191: INFO: Created: latency-svc-94xrw
Feb 13 14:32:05.230: INFO: Got endpoints: latency-svc-7xkqm [749.933725ms]
Feb 13 14:32:05.239: INFO: Created: latency-svc-c7wjx
Feb 13 14:32:05.281: INFO: Got endpoints: latency-svc-q6s75 [750.871869ms]
Feb 13 14:32:05.290: INFO: Created: latency-svc-c2zj5
Feb 13 14:32:05.330: INFO: Got endpoints: latency-svc-jnvrl [750.257763ms]
Feb 13 14:32:05.340: INFO: Created: latency-svc-nn9ts
Feb 13 14:32:05.380: INFO: Got endpoints: latency-svc-df4ht [750.348677ms]
Feb 13 14:32:05.392: INFO: Created: latency-svc-42jms
Feb 13 14:32:05.430: INFO: Got endpoints: latency-svc-z6w7r [749.976883ms]
Feb 13 14:32:05.441: INFO: Created: latency-svc-ft4jf
Feb 13 14:32:05.480: INFO: Got endpoints: latency-svc-c5gjz [749.455561ms]
Feb 13 14:32:05.489: INFO: Created: latency-svc-vd4wn
Feb 13 14:32:05.531: INFO: Got endpoints: latency-svc-5fdlj [749.223017ms]
Feb 13 14:32:05.541: INFO: Created: latency-svc-vqwr4
Feb 13 14:32:05.580: INFO: Got endpoints: latency-svc-kvfq8 [749.886667ms]
Feb 13 14:32:05.590: INFO: Created: latency-svc-4kbsx
Feb 13 14:32:05.630: INFO: Got endpoints: latency-svc-x8vwp [749.183326ms]
Feb 13 14:32:05.641: INFO: Created: latency-svc-m9bhz
Feb 13 14:32:05.681: INFO: Got endpoints: latency-svc-v27sq [750.871217ms]
Feb 13 14:32:05.692: INFO: Created: latency-svc-7cs6w
Feb 13 14:32:05.731: INFO: Got endpoints: latency-svc-2v5bv [750.272272ms]
Feb 13 14:32:05.742: INFO: Created: latency-svc-fjpz7
Feb 13 14:32:05.781: INFO: Got endpoints: latency-svc-z2fhm [750.583089ms]
Feb 13 14:32:05.791: INFO: Created: latency-svc-v2mrs
Feb 13 14:32:05.832: INFO: Got endpoints: latency-svc-288pr [751.999084ms]
Feb 13 14:32:05.845: INFO: Created: latency-svc-tvrbz
Feb 13 14:32:05.881: INFO: Got endpoints: latency-svc-jxbfm [750.821894ms]
Feb 13 14:32:05.893: INFO: Created: latency-svc-xgj7z
Feb 13 14:32:05.930: INFO: Got endpoints: latency-svc-94xrw [750.002447ms]
Feb 13 14:32:05.942: INFO: Created: latency-svc-qqm5h
Feb 13 14:32:05.980: INFO: Got endpoints: latency-svc-c7wjx [749.360523ms]
Feb 13 14:32:05.992: INFO: Created: latency-svc-5rc4d
Feb 13 14:32:06.030: INFO: Got endpoints: latency-svc-c2zj5 [749.601893ms]
Feb 13 14:32:06.041: INFO: Created: latency-svc-578xq
Feb 13 14:32:06.080: INFO: Got endpoints: latency-svc-nn9ts [750.360816ms]
Feb 13 14:32:06.096: INFO: Created: latency-svc-q8m25
Feb 13 14:32:06.130: INFO: Got endpoints: latency-svc-42jms [749.90982ms]
Feb 13 14:32:06.142: INFO: Created: latency-svc-2shl5
Feb 13 14:32:06.180: INFO: Got endpoints: latency-svc-ft4jf [749.944219ms]
Feb 13 14:32:06.190: INFO: Created: latency-svc-rgcg4
Feb 13 14:32:06.230: INFO: Got endpoints: latency-svc-vd4wn [750.086784ms]
Feb 13 14:32:06.240: INFO: Created: latency-svc-zgvww
Feb 13 14:32:06.280: INFO: Got endpoints: latency-svc-vqwr4 [749.539601ms]
Feb 13 14:32:06.290: INFO: Created: latency-svc-n5qhp
Feb 13 14:32:06.330: INFO: Got endpoints: latency-svc-4kbsx [750.321127ms]
Feb 13 14:32:06.340: INFO: Created: latency-svc-nq4nq
Feb 13 14:32:06.386: INFO: Got endpoints: latency-svc-m9bhz [755.96463ms]
Feb 13 14:32:06.395: INFO: Created: latency-svc-lk46c
Feb 13 14:32:06.431: INFO: Got endpoints: latency-svc-7cs6w [749.681674ms]
Feb 13 14:32:06.442: INFO: Created: latency-svc-7wqzm
Feb 13 14:32:06.480: INFO: Got endpoints: latency-svc-fjpz7 [749.011556ms]
Feb 13 14:32:06.490: INFO: Created: latency-svc-kkd97
Feb 13 14:32:06.533: INFO: Got endpoints: latency-svc-v2mrs [752.189451ms]
Feb 13 14:32:06.544: INFO: Created: latency-svc-vkjkx
Feb 13 14:32:06.581: INFO: Got endpoints: latency-svc-tvrbz [748.23024ms]
Feb 13 14:32:06.592: INFO: Created: latency-svc-svfpl
Feb 13 14:32:06.631: INFO: Got endpoints: latency-svc-xgj7z [749.388888ms]
Feb 13 14:32:06.650: INFO: Created: latency-svc-2cfpc
Feb 13 14:32:06.681: INFO: Got endpoints: latency-svc-qqm5h [750.464309ms]
Feb 13 14:32:06.691: INFO: Created: latency-svc-45q6g
Feb 13 14:32:06.730: INFO: Got endpoints: latency-svc-5rc4d [750.403571ms]
Feb 13 14:32:06.741: INFO: Created: latency-svc-g7w2f
Feb 13 14:32:06.781: INFO: Got endpoints: latency-svc-578xq [750.395926ms]
Feb 13 14:32:06.791: INFO: Created: latency-svc-52w6c
Feb 13 14:32:06.831: INFO: Got endpoints: latency-svc-q8m25 [750.477834ms]
Feb 13 14:32:06.843: INFO: Created: latency-svc-xtxtr
Feb 13 14:32:06.880: INFO: Got endpoints: latency-svc-2shl5 [749.897655ms]
Feb 13 14:32:06.890: INFO: Created: latency-svc-9tkzp
Feb 13 14:32:06.930: INFO: Got endpoints: latency-svc-rgcg4 [749.931966ms]
Feb 13 14:32:06.941: INFO: Created: latency-svc-hwbtz
Feb 13 14:32:06.980: INFO: Got endpoints: latency-svc-zgvww [750.386888ms]
Feb 13 14:32:07.015: INFO: Created: latency-svc-6mcnp
Feb 13 14:32:07.033: INFO: Got endpoints: latency-svc-n5qhp [752.282223ms]
Feb 13 14:32:07.044: INFO: Created: latency-svc-gflg2
Feb 13 14:32:07.080: INFO: Got endpoints: latency-svc-nq4nq [749.20944ms]
Feb 13 14:32:07.100: INFO: Created: latency-svc-9ccfl
Feb 13 14:32:07.130: INFO: Got endpoints: latency-svc-lk46c [744.541846ms]
Feb 13 14:32:07.141: INFO: Created: latency-svc-4gq68
Feb 13 14:32:07.181: INFO: Got endpoints: latency-svc-7wqzm [750.112163ms]
Feb 13 14:32:07.191: INFO: Created: latency-svc-pv5pw
Feb 13 14:32:07.230: INFO: Got endpoints: latency-svc-kkd97 [750.761396ms]
Feb 13 14:32:07.242: INFO: Created: latency-svc-b9nzz
Feb 13 14:32:07.280: INFO: Got endpoints: latency-svc-vkjkx [746.781256ms]
Feb 13 14:32:07.290: INFO: Created: latency-svc-xk4f8
Feb 13 14:32:07.331: INFO: Got endpoints: latency-svc-svfpl [750.127793ms]
Feb 13 14:32:07.342: INFO: Created: latency-svc-bknjf
Feb 13 14:32:07.381: INFO: Got endpoints: latency-svc-2cfpc [749.944654ms]
Feb 13 14:32:07.391: INFO: Created: latency-svc-4bwr8
Feb 13 14:32:07.431: INFO: Got endpoints: latency-svc-45q6g [749.776864ms]
Feb 13 14:32:07.440: INFO: Created: latency-svc-9pcpk
Feb 13 14:32:07.481: INFO: Got endpoints: latency-svc-g7w2f [750.565413ms]
Feb 13 14:32:07.492: INFO: Created: latency-svc-rgvdp
Feb 13 14:32:07.531: INFO: Got endpoints: latency-svc-52w6c [750.288119ms]
Feb 13 14:32:07.542: INFO: Created: latency-svc-g6ln8
Feb 13 14:32:07.579: INFO: Got endpoints: latency-svc-xtxtr [748.382214ms]
Feb 13 14:32:07.591: INFO: Created: latency-svc-d5kb4
Feb 13 14:32:07.630: INFO: Got endpoints: latency-svc-9tkzp [749.687227ms]
Feb 13 14:32:07.640: INFO: Created: latency-svc-mprjv
Feb 13 14:32:07.680: INFO: Got endpoints: latency-svc-hwbtz [749.663708ms]
Feb 13 14:32:07.690: INFO: Created: latency-svc-dvd8v
Feb 13 14:32:07.730: INFO: Got endpoints: latency-svc-6mcnp [749.527466ms]
Feb 13 14:32:07.740: INFO: Created: latency-svc-s2rpj
Feb 13 14:32:07.780: INFO: Got endpoints: latency-svc-gflg2 [747.357849ms]
Feb 13 14:32:07.791: INFO: Created: latency-svc-dqgs7
Feb 13 14:32:07.830: INFO: Got endpoints: latency-svc-9ccfl [750.633325ms]
Feb 13 14:32:07.840: INFO: Created: latency-svc-m29d6
Feb 13 14:32:07.880: INFO: Got endpoints: latency-svc-4gq68 [749.818453ms]
Feb 13 14:32:07.891: INFO: Created: latency-svc-qzjmn
Feb 13 14:32:07.930: INFO: Got endpoints: latency-svc-pv5pw [748.978318ms]
Feb 13 14:32:07.942: INFO: Created: latency-svc-mhht4
Feb 13 14:32:07.980: INFO: Got endpoints: latency-svc-b9nzz [749.646222ms]
Feb 13 14:32:07.991: INFO: Created: latency-svc-8qkmq
Feb 13 14:32:08.031: INFO: Got endpoints: latency-svc-xk4f8 [750.6941ms]
Feb 13 14:32:08.041: INFO: Created: latency-svc-r2x5k
Feb 13 14:32:08.081: INFO: Got endpoints: latency-svc-bknjf [750.001569ms]
Feb 13 14:32:08.091: INFO: Created: latency-svc-m7q7d
Feb 13 14:32:08.131: INFO: Got endpoints: latency-svc-4bwr8 [749.665519ms]
Feb 13 14:32:08.140: INFO: Created: latency-svc-qc9qq
Feb 13 14:32:08.180: INFO: Got endpoints: latency-svc-9pcpk [749.55596ms]
Feb 13 14:32:08.190: INFO: Created: latency-svc-zcx8r
Feb 13 14:32:08.231: INFO: Got endpoints: latency-svc-rgvdp [750.253155ms]
Feb 13 14:32:08.241: INFO: Created: latency-svc-v7vr8
Feb 13 14:32:08.280: INFO: Got endpoints: latency-svc-g6ln8 [749.096805ms]
Feb 13 14:32:08.290: INFO: Created: latency-svc-jtgxs
Feb 13 14:32:08.330: INFO: Got endpoints: latency-svc-d5kb4 [750.449928ms]
Feb 13 14:32:08.341: INFO: Created: latency-svc-mdq6f
Feb 13 14:32:08.381: INFO: Got endpoints: latency-svc-mprjv [751.387681ms]
Feb 13 14:32:08.401: INFO: Created: latency-svc-8lggv
Feb 13 14:32:08.438: INFO: Got endpoints: latency-svc-dvd8v [758.404461ms]
Feb 13 14:32:08.452: INFO: Created: latency-svc-8wvh6
Feb 13 14:32:08.480: INFO: Got endpoints: latency-svc-s2rpj [749.770659ms]
Feb 13 14:32:08.498: INFO: Created: latency-svc-67g97
Feb 13 14:32:08.537: INFO: Got endpoints: latency-svc-dqgs7 [756.79555ms]
Feb 13 14:32:08.549: INFO: Created: latency-svc-k9f44
Feb 13 14:32:08.580: INFO: Got endpoints: latency-svc-m29d6 [750.008628ms]
Feb 13 14:32:08.593: INFO: Created: latency-svc-4s55f
Feb 13 14:32:08.630: INFO: Got endpoints: latency-svc-qzjmn [750.352762ms]
Feb 13 14:32:08.641: INFO: Created: latency-svc-59mzr
Feb 13 14:32:08.680: INFO: Got endpoints: latency-svc-mhht4 [750.145341ms]
Feb 13 14:32:08.691: INFO: Created: latency-svc-2hfsf
Feb 13 14:32:08.730: INFO: Got endpoints: latency-svc-8qkmq [749.723588ms]
Feb 13 14:32:08.740: INFO: Created: latency-svc-hgxfr
Feb 13 14:32:08.780: INFO: Got endpoints: latency-svc-r2x5k [749.45093ms]
Feb 13 14:32:08.791: INFO: Created: latency-svc-rlp9r
Feb 13 14:32:08.831: INFO: Got endpoints: latency-svc-m7q7d [749.635549ms]
Feb 13 14:32:08.843: INFO: Created: latency-svc-tmlhl
Feb 13 14:32:08.881: INFO: Got endpoints: latency-svc-qc9qq [750.751906ms]
Feb 13 14:32:08.893: INFO: Created: latency-svc-kptsp
Feb 13 14:32:08.932: INFO: Got endpoints: latency-svc-zcx8r [751.510417ms]
Feb 13 14:32:08.942: INFO: Created: latency-svc-8kkcc
Feb 13 14:32:08.980: INFO: Got endpoints: latency-svc-v7vr8 [748.910503ms]
Feb 13 14:32:08.992: INFO: Created: latency-svc-c9nx4
Feb 13 14:32:09.036: INFO: Got endpoints: latency-svc-jtgxs [755.42451ms]
Feb 13 14:32:09.056: INFO: Created: latency-svc-54jkh
Feb 13 14:32:09.080: INFO: Got endpoints: latency-svc-mdq6f [749.856176ms]
Feb 13 14:32:09.091: INFO: Created: latency-svc-d5skl
Feb 13 14:32:09.130: INFO: Got endpoints: latency-svc-8lggv [748.922016ms]
Feb 13 14:32:09.141: INFO: Created: latency-svc-4q8cm
Feb 13 14:32:09.181: INFO: Got endpoints: latency-svc-8wvh6 [742.665488ms]
Feb 13 14:32:09.231: INFO: Got endpoints: latency-svc-67g97 [750.663687ms]
Feb 13 14:32:09.280: INFO: Got endpoints: latency-svc-k9f44 [743.399558ms]
Feb 13 14:32:09.330: INFO: Got endpoints: latency-svc-4s55f [749.845294ms]
Feb 13 14:32:09.380: INFO: Got endpoints: latency-svc-59mzr [749.596506ms]
Feb 13 14:32:09.432: INFO: Got endpoints: latency-svc-2hfsf [752.247282ms]
Feb 13 14:32:09.480: INFO: Got endpoints: latency-svc-hgxfr [750.190906ms]
Feb 13 14:32:09.532: INFO: Got endpoints: latency-svc-rlp9r [751.78373ms]
Feb 13 14:32:09.580: INFO: Got endpoints: latency-svc-tmlhl [749.444685ms]
Feb 13 14:32:09.631: INFO: Got endpoints: latency-svc-kptsp [748.997939ms]
Feb 13 14:32:09.680: INFO: Got endpoints: latency-svc-8kkcc [748.408452ms]
Feb 13 14:32:09.730: INFO: Got endpoints: latency-svc-c9nx4 [749.661042ms]
Feb 13 14:32:09.779: INFO: Got endpoints: latency-svc-54jkh [743.496331ms]
Feb 13 14:32:09.830: INFO: Got endpoints: latency-svc-d5skl [750.338269ms]
Feb 13 14:32:09.881: INFO: Got endpoints: latency-svc-4q8cm [750.863624ms]
Feb 13 14:32:09.881: INFO: Latencies: [15.066546ms 17.954087ms 22.742195ms 28.129935ms 33.933591ms 50.720576ms 57.651302ms 63.76704ms 71.601377ms 77.656595ms 85.098692ms 92.120049ms 98.101888ms 105.057892ms 105.83012ms 108.959896ms 115.536654ms 116.704078ms 118.564237ms 119.799835ms 124.347206ms 125.338535ms 133.13326ms 133.463425ms 133.723029ms 134.559218ms 134.827618ms 135.729981ms 135.775396ms 137.117973ms 139.248523ms 140.550574ms 142.816978ms 143.048639ms 143.127167ms 159.000484ms 202.129427ms 245.315828ms 288.985113ms 330.175189ms 374.202321ms 416.837155ms 458.205249ms 503.027511ms 545.931904ms 588.090554ms 629.022082ms 674.745744ms 703.1847ms 742.665488ms 743.399558ms 743.496331ms 744.541846ms 746.439164ms 746.440023ms 746.781256ms 747.357849ms 747.924803ms 748.012127ms 748.23024ms 748.382214ms 748.408452ms 748.506225ms 748.542374ms 748.698804ms 748.709222ms 748.781206ms 748.810347ms 748.87349ms 748.910503ms 748.922016ms 748.978318ms 748.997939ms 749.011556ms 749.096805ms 749.120734ms 749.183326ms 749.20944ms 749.223017ms 749.318763ms 749.360523ms 749.388888ms 749.391111ms 749.444685ms 749.45093ms 749.453143ms 749.455561ms 749.462842ms 749.490205ms 749.494516ms 749.524491ms 749.527466ms 749.539601ms 749.55596ms 749.56704ms 749.573475ms 749.596506ms 749.601893ms 749.631004ms 749.635549ms 749.646222ms 749.661042ms 749.663708ms 749.665519ms 749.681674ms 749.687227ms 749.690238ms 749.723588ms 749.727213ms 749.758647ms 749.770659ms 749.776864ms 749.818453ms 749.845294ms 749.854538ms 749.856176ms 749.875469ms 749.886667ms 749.897655ms 749.90982ms 749.915934ms 749.921086ms 749.931966ms 749.933725ms 749.936899ms 749.944219ms 749.944654ms 749.961515ms 749.976883ms 749.977596ms 749.980843ms 750.001569ms 750.002447ms 750.007966ms 750.008628ms 750.084012ms 750.086784ms 750.112163ms 750.116656ms 750.122609ms 750.127793ms 750.145341ms 750.190906ms 750.192892ms 750.20041ms 750.220562ms 750.23735ms 750.253155ms 750.257763ms 750.272272ms 750.288119ms 750.290093ms 750.321127ms 750.337581ms 750.338269ms 750.348677ms 750.352762ms 750.360816ms 750.386888ms 750.394875ms 750.395926ms 750.403571ms 750.405205ms 750.449928ms 750.464309ms 750.477834ms 750.484154ms 750.487295ms 750.565413ms 750.583089ms 750.633325ms 750.663668ms 750.663687ms 750.6941ms 750.751906ms 750.761396ms 750.774086ms 750.781535ms 750.821894ms 750.846959ms 750.863624ms 750.871217ms 750.871869ms 751.079408ms 751.180009ms 751.210029ms 751.3527ms 751.387681ms 751.510417ms 751.78373ms 751.808503ms 751.999084ms 752.189451ms 752.247282ms 752.282223ms 752.839716ms 755.42451ms 755.96463ms 756.79555ms 758.404461ms]
Feb 13 14:32:09.881: INFO: 50 %ile: 749.646222ms
Feb 13 14:32:09.881: INFO: 90 %ile: 750.863624ms
Feb 13 14:32:09.881: INFO: 99 %ile: 756.79555ms
Feb 13 14:32:09.881: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:32:09.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-jvgvr" for this suite.
Feb 13 14:32:33.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:32:33.913: INFO: namespace: e2e-tests-svc-latency-jvgvr, resource: bindings, ignored listing per whitelist
Feb 13 14:32:34.009: INFO: namespace e2e-tests-svc-latency-jvgvr deletion completed in 24.122386334s

• [SLOW TEST:34.954 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:32:34.009: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Feb 13 14:32:34.114: INFO: Waiting up to 5m0s for pod "client-containers-33be611d-2f9c-11e9-9b61-026654d605e3" in namespace "e2e-tests-containers-ltfmx" to be "success or failure"
Feb 13 14:32:34.117: INFO: Pod "client-containers-33be611d-2f9c-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.442678ms
Feb 13 14:32:36.129: INFO: Pod "client-containers-33be611d-2f9c-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015032539s
Feb 13 14:32:38.133: INFO: Pod "client-containers-33be611d-2f9c-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018969805s
STEP: Saw pod success
Feb 13 14:32:38.133: INFO: Pod "client-containers-33be611d-2f9c-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:32:38.136: INFO: Trying to get logs from node cmp3 pod client-containers-33be611d-2f9c-11e9-9b61-026654d605e3 container test-container: <nil>
STEP: delete the pod
Feb 13 14:32:38.156: INFO: Waiting for pod client-containers-33be611d-2f9c-11e9-9b61-026654d605e3 to disappear
Feb 13 14:32:38.159: INFO: Pod client-containers-33be611d-2f9c-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:32:38.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-ltfmx" for this suite.
Feb 13 14:32:44.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:32:44.227: INFO: namespace: e2e-tests-containers-ltfmx, resource: bindings, ignored listing per whitelist
Feb 13 14:32:44.315: INFO: namespace e2e-tests-containers-ltfmx deletion completed in 6.150829583s

• [SLOW TEST:10.306 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:32:44.315: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-39e8be3f-2f9c-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume configMaps
Feb 13 14:32:44.462: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-39ea03ae-2f9c-11e9-9b61-026654d605e3" in namespace "e2e-tests-projected-zjvt2" to be "success or failure"
Feb 13 14:32:44.465: INFO: Pod "pod-projected-configmaps-39ea03ae-2f9c-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.927504ms
Feb 13 14:32:46.475: INFO: Pod "pod-projected-configmaps-39ea03ae-2f9c-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012588641s
Feb 13 14:32:48.479: INFO: Pod "pod-projected-configmaps-39ea03ae-2f9c-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016723136s
Feb 13 14:32:50.483: INFO: Pod "pod-projected-configmaps-39ea03ae-2f9c-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020643797s
STEP: Saw pod success
Feb 13 14:32:50.483: INFO: Pod "pod-projected-configmaps-39ea03ae-2f9c-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:32:50.486: INFO: Trying to get logs from node cmp3 pod pod-projected-configmaps-39ea03ae-2f9c-11e9-9b61-026654d605e3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 14:32:50.543: INFO: Waiting for pod pod-projected-configmaps-39ea03ae-2f9c-11e9-9b61-026654d605e3 to disappear
Feb 13 14:32:50.546: INFO: Pod pod-projected-configmaps-39ea03ae-2f9c-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:32:50.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zjvt2" for this suite.
Feb 13 14:32:56.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:32:56.601: INFO: namespace: e2e-tests-projected-zjvt2, resource: bindings, ignored listing per whitelist
Feb 13 14:32:56.688: INFO: namespace e2e-tests-projected-zjvt2 deletion completed in 6.137740474s

• [SLOW TEST:12.373 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:32:56.689: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 13 14:32:56.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-nsjtz'
Feb 13 14:32:57.044: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb 13 14:32:57.044: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Feb 13 14:32:57.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-nsjtz'
Feb 13 14:32:57.181: INFO: stderr: ""
Feb 13 14:32:57.181: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:32:57.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nsjtz" for this suite.
Feb 13 14:33:19.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:33:19.265: INFO: namespace: e2e-tests-kubectl-nsjtz, resource: bindings, ignored listing per whitelist
Feb 13 14:33:19.316: INFO: namespace e2e-tests-kubectl-nsjtz deletion completed in 22.130289231s

• [SLOW TEST:22.627 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:33:19.318: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Feb 13 14:33:19.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 create -f - --namespace=e2e-tests-kubectl-d6bzk'
Feb 13 14:33:19.624: INFO: stderr: ""
Feb 13 14:33:19.624: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Feb 13 14:33:20.628: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 14:33:20.628: INFO: Found 0 / 1
Feb 13 14:33:21.628: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 14:33:21.628: INFO: Found 0 / 1
Feb 13 14:33:22.628: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 14:33:22.628: INFO: Found 1 / 1
Feb 13 14:33:22.628: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 13 14:33:22.632: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 14:33:22.632: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Feb 13 14:33:22.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 logs redis-master-7gs6g redis-master --namespace=e2e-tests-kubectl-d6bzk'
Feb 13 14:33:22.765: INFO: stderr: ""
Feb 13 14:33:22.765: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 13 Feb 14:33:21.805 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 13 Feb 14:33:21.805 # Server started, Redis version 3.2.12\n1:M 13 Feb 14:33:21.805 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 13 Feb 14:33:21.805 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Feb 13 14:33:22.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 log redis-master-7gs6g redis-master --namespace=e2e-tests-kubectl-d6bzk --tail=1'
Feb 13 14:33:22.905: INFO: stderr: ""
Feb 13 14:33:22.905: INFO: stdout: "1:M 13 Feb 14:33:21.805 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Feb 13 14:33:22.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 log redis-master-7gs6g redis-master --namespace=e2e-tests-kubectl-d6bzk --limit-bytes=1'
Feb 13 14:33:23.035: INFO: stderr: ""
Feb 13 14:33:23.035: INFO: stdout: " "
STEP: exposing timestamps
Feb 13 14:33:23.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 log redis-master-7gs6g redis-master --namespace=e2e-tests-kubectl-d6bzk --tail=1 --timestamps'
Feb 13 14:33:23.156: INFO: stderr: ""
Feb 13 14:33:23.156: INFO: stdout: "2019-02-13T14:33:21.807258907Z 1:M 13 Feb 14:33:21.805 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Feb 13 14:33:25.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 log redis-master-7gs6g redis-master --namespace=e2e-tests-kubectl-d6bzk --since=1s'
Feb 13 14:33:25.790: INFO: stderr: ""
Feb 13 14:33:25.790: INFO: stdout: ""
Feb 13 14:33:25.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 log redis-master-7gs6g redis-master --namespace=e2e-tests-kubectl-d6bzk --since=24h'
Feb 13 14:33:25.917: INFO: stderr: ""
Feb 13 14:33:25.917: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 13 Feb 14:33:21.805 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 13 Feb 14:33:21.805 # Server started, Redis version 3.2.12\n1:M 13 Feb 14:33:21.805 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 13 Feb 14:33:21.805 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Feb 13 14:33:25.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-d6bzk'
Feb 13 14:33:26.034: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 14:33:26.034: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Feb 13 14:33:26.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-d6bzk'
Feb 13 14:33:26.164: INFO: stderr: "No resources found.\n"
Feb 13 14:33:26.164: INFO: stdout: ""
Feb 13 14:33:26.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods -l name=nginx --namespace=e2e-tests-kubectl-d6bzk -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 13 14:33:26.295: INFO: stderr: ""
Feb 13 14:33:26.295: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:33:26.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d6bzk" for this suite.
Feb 13 14:33:32.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:33:32.335: INFO: namespace: e2e-tests-kubectl-d6bzk, resource: bindings, ignored listing per whitelist
Feb 13 14:33:32.438: INFO: namespace e2e-tests-kubectl-d6bzk deletion completed in 6.138489758s

• [SLOW TEST:13.121 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:33:32.439: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-56925b35-2f9c-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume secrets
Feb 13 14:33:32.549: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5693801d-2f9c-11e9-9b61-026654d605e3" in namespace "e2e-tests-projected-xswb2" to be "success or failure"
Feb 13 14:33:32.552: INFO: Pod "pod-projected-secrets-5693801d-2f9c-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.227826ms
Feb 13 14:33:34.557: INFO: Pod "pod-projected-secrets-5693801d-2f9c-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008150927s
Feb 13 14:33:36.562: INFO: Pod "pod-projected-secrets-5693801d-2f9c-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012313315s
STEP: Saw pod success
Feb 13 14:33:36.562: INFO: Pod "pod-projected-secrets-5693801d-2f9c-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:33:36.567: INFO: Trying to get logs from node cmp3 pod pod-projected-secrets-5693801d-2f9c-11e9-9b61-026654d605e3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 13 14:33:36.587: INFO: Waiting for pod pod-projected-secrets-5693801d-2f9c-11e9-9b61-026654d605e3 to disappear
Feb 13 14:33:36.590: INFO: Pod pod-projected-secrets-5693801d-2f9c-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:33:36.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xswb2" for this suite.
Feb 13 14:33:42.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:33:42.654: INFO: namespace: e2e-tests-projected-xswb2, resource: bindings, ignored listing per whitelist
Feb 13 14:33:42.718: INFO: namespace e2e-tests-projected-xswb2 deletion completed in 6.123074776s

• [SLOW TEST:10.279 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:33:42.719: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 14:33:42.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 version'
Feb 13 14:33:42.923: INFO: stderr: ""
Feb 13 14:33:42.923: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12+\", GitVersion:\"v1.12.4-3+680746c29c3258\", GitCommit:\"680746c29c32583d2dc273f425bba26a4f5c6e12\", GitTreeState:\"clean\", BuildDate:\"2019-01-10T14:39:04Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:33:42.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4rnsn" for this suite.
Feb 13 14:33:48.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:33:48.963: INFO: namespace: e2e-tests-kubectl-4rnsn, resource: bindings, ignored listing per whitelist
Feb 13 14:33:49.062: INFO: namespace e2e-tests-kubectl-4rnsn deletion completed in 6.133140422s

• [SLOW TEST:6.343 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:33:49.063: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-mp8tg/secret-test-6078f61c-2f9c-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume secrets
Feb 13 14:33:49.159: INFO: Waiting up to 5m0s for pod "pod-configmaps-607a08fe-2f9c-11e9-9b61-026654d605e3" in namespace "e2e-tests-secrets-mp8tg" to be "success or failure"
Feb 13 14:33:49.162: INFO: Pod "pod-configmaps-607a08fe-2f9c-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.320243ms
Feb 13 14:33:51.173: INFO: Pod "pod-configmaps-607a08fe-2f9c-11e9-9b61-026654d605e3": Phase="Running", Reason="", readiness=true. Elapsed: 2.013901282s
Feb 13 14:33:53.177: INFO: Pod "pod-configmaps-607a08fe-2f9c-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018325723s
STEP: Saw pod success
Feb 13 14:33:53.177: INFO: Pod "pod-configmaps-607a08fe-2f9c-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:33:53.181: INFO: Trying to get logs from node cmp3 pod pod-configmaps-607a08fe-2f9c-11e9-9b61-026654d605e3 container env-test: <nil>
STEP: delete the pod
Feb 13 14:33:53.199: INFO: Waiting for pod pod-configmaps-607a08fe-2f9c-11e9-9b61-026654d605e3 to disappear
Feb 13 14:33:53.202: INFO: Pod pod-configmaps-607a08fe-2f9c-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:33:53.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-mp8tg" for this suite.
Feb 13 14:33:59.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:33:59.246: INFO: namespace: e2e-tests-secrets-mp8tg, resource: bindings, ignored listing per whitelist
Feb 13 14:33:59.326: INFO: namespace e2e-tests-secrets-mp8tg deletion completed in 6.12003245s

• [SLOW TEST:10.264 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:33:59.327: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-l7t4
STEP: Creating a pod to test atomic-volume-subpath
Feb 13 14:33:59.442: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-l7t4" in namespace "e2e-tests-subpath-lhpgt" to be "success or failure"
Feb 13 14:33:59.447: INFO: Pod "pod-subpath-test-configmap-l7t4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.297614ms
Feb 13 14:34:01.461: INFO: Pod "pod-subpath-test-configmap-l7t4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018283272s
Feb 13 14:34:03.465: INFO: Pod "pod-subpath-test-configmap-l7t4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022420895s
Feb 13 14:34:05.469: INFO: Pod "pod-subpath-test-configmap-l7t4": Phase="Running", Reason="", readiness=false. Elapsed: 6.026543487s
Feb 13 14:34:07.473: INFO: Pod "pod-subpath-test-configmap-l7t4": Phase="Running", Reason="", readiness=false. Elapsed: 8.030583449s
Feb 13 14:34:09.478: INFO: Pod "pod-subpath-test-configmap-l7t4": Phase="Running", Reason="", readiness=false. Elapsed: 10.035116705s
Feb 13 14:34:11.489: INFO: Pod "pod-subpath-test-configmap-l7t4": Phase="Running", Reason="", readiness=false. Elapsed: 12.046081033s
Feb 13 14:34:13.492: INFO: Pod "pod-subpath-test-configmap-l7t4": Phase="Running", Reason="", readiness=false. Elapsed: 14.049942496s
Feb 13 14:34:15.497: INFO: Pod "pod-subpath-test-configmap-l7t4": Phase="Running", Reason="", readiness=false. Elapsed: 16.054578028s
Feb 13 14:34:17.502: INFO: Pod "pod-subpath-test-configmap-l7t4": Phase="Running", Reason="", readiness=false. Elapsed: 18.059123599s
Feb 13 14:34:19.506: INFO: Pod "pod-subpath-test-configmap-l7t4": Phase="Running", Reason="", readiness=false. Elapsed: 20.063446044s
Feb 13 14:34:21.515: INFO: Pod "pod-subpath-test-configmap-l7t4": Phase="Running", Reason="", readiness=false. Elapsed: 22.072543414s
Feb 13 14:34:23.520: INFO: Pod "pod-subpath-test-configmap-l7t4": Phase="Running", Reason="", readiness=false. Elapsed: 24.077318956s
Feb 13 14:34:25.523: INFO: Pod "pod-subpath-test-configmap-l7t4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.080986386s
STEP: Saw pod success
Feb 13 14:34:25.523: INFO: Pod "pod-subpath-test-configmap-l7t4" satisfied condition "success or failure"
Feb 13 14:34:25.527: INFO: Trying to get logs from node cmp3 pod pod-subpath-test-configmap-l7t4 container test-container-subpath-configmap-l7t4: <nil>
STEP: delete the pod
Feb 13 14:34:25.553: INFO: Waiting for pod pod-subpath-test-configmap-l7t4 to disappear
Feb 13 14:34:25.557: INFO: Pod pod-subpath-test-configmap-l7t4 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-l7t4
Feb 13 14:34:25.557: INFO: Deleting pod "pod-subpath-test-configmap-l7t4" in namespace "e2e-tests-subpath-lhpgt"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:34:25.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-lhpgt" for this suite.
Feb 13 14:34:31.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:34:31.652: INFO: namespace: e2e-tests-subpath-lhpgt, resource: bindings, ignored listing per whitelist
Feb 13 14:34:31.698: INFO: namespace e2e-tests-subpath-lhpgt deletion completed in 6.13404274s

• [SLOW TEST:32.371 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:34:31.699: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-gxsz4 A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-gxsz4;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-gxsz4 A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-gxsz4;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-gxsz4.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-gxsz4.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-gxsz4.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-gxsz4.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-gxsz4.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-gxsz4.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-gxsz4.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gxsz4.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-gxsz4.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-gxsz4.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-gxsz4.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-gxsz4.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-gxsz4.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 112.92.254.10.in-addr.arpa. PTR)" && echo OK > /results/10.254.92.112_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 112.92.254.10.in-addr.arpa. PTR)" && echo OK > /results/10.254.92.112_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-gxsz4 A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-gxsz4;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-gxsz4 A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-gxsz4;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-gxsz4.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-gxsz4.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-gxsz4.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-gxsz4.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-gxsz4.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-gxsz4.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-gxsz4.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gxsz4.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-gxsz4.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-gxsz4.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-gxsz4.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-gxsz4.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-gxsz4.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 112.92.254.10.in-addr.arpa. PTR)" && echo OK > /results/10.254.92.112_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 112.92.254.10.in-addr.arpa. PTR)" && echo OK > /results/10.254.92.112_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 13 14:34:45.852: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-gxsz4/dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3: the server could not find the requested resource (get pods dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3)
Feb 13 14:34:45.857: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-gxsz4/dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3: the server could not find the requested resource (get pods dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3)
Feb 13 14:34:45.873: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-gxsz4 from pod e2e-tests-dns-gxsz4/dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3: the server could not find the requested resource (get pods dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3)
Feb 13 14:34:45.881: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-gxsz4.svc from pod e2e-tests-dns-gxsz4/dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3: the server could not find the requested resource (get pods dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3)
Feb 13 14:34:45.919: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-gxsz4/dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3: the server could not find the requested resource (get pods dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3)
Feb 13 14:34:45.922: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-gxsz4/dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3: the server could not find the requested resource (get pods dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3)
Feb 13 14:34:45.927: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-gxsz4 from pod e2e-tests-dns-gxsz4/dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3: the server could not find the requested resource (get pods dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3)
Feb 13 14:34:45.934: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-gxsz4 from pod e2e-tests-dns-gxsz4/dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3: the server could not find the requested resource (get pods dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3)
Feb 13 14:34:45.938: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-gxsz4.svc from pod e2e-tests-dns-gxsz4/dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3: the server could not find the requested resource (get pods dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3)
Feb 13 14:34:45.944: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-gxsz4.svc from pod e2e-tests-dns-gxsz4/dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3: the server could not find the requested resource (get pods dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3)
Feb 13 14:34:45.987: INFO: Lookups using e2e-tests-dns-gxsz4/dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-gxsz4 wheezy_tcp@dns-test-service.e2e-tests-dns-gxsz4.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-gxsz4 jessie_tcp@dns-test-service.e2e-tests-dns-gxsz4 jessie_udp@dns-test-service.e2e-tests-dns-gxsz4.svc jessie_tcp@dns-test-service.e2e-tests-dns-gxsz4.svc]

Feb 13 14:34:55.842: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-gxsz4/dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3: the server could not find the requested resource (get pods dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3)
Feb 13 14:34:55.847: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-gxsz4/dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3: the server could not find the requested resource (get pods dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3)
Feb 13 14:34:55.862: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-gxsz4 from pod e2e-tests-dns-gxsz4/dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3: the server could not find the requested resource (get pods dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3)
Feb 13 14:34:55.870: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-gxsz4.svc from pod e2e-tests-dns-gxsz4/dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3: the server could not find the requested resource (get pods dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3)
Feb 13 14:34:55.913: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-gxsz4/dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3: the server could not find the requested resource (get pods dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3)
Feb 13 14:34:55.927: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-gxsz4/dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3: the server could not find the requested resource (get pods dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3)
Feb 13 14:34:55.933: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-gxsz4 from pod e2e-tests-dns-gxsz4/dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3: the server could not find the requested resource (get pods dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3)
Feb 13 14:34:55.943: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-gxsz4 from pod e2e-tests-dns-gxsz4/dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3: the server could not find the requested resource (get pods dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3)
Feb 13 14:34:55.946: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-gxsz4.svc from pod e2e-tests-dns-gxsz4/dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3: the server could not find the requested resource (get pods dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3)
Feb 13 14:34:55.954: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-gxsz4.svc from pod e2e-tests-dns-gxsz4/dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3: the server could not find the requested resource (get pods dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3)
Feb 13 14:34:55.994: INFO: Lookups using e2e-tests-dns-gxsz4/dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-gxsz4 wheezy_tcp@dns-test-service.e2e-tests-dns-gxsz4.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-gxsz4 jessie_tcp@dns-test-service.e2e-tests-dns-gxsz4 jessie_udp@dns-test-service.e2e-tests-dns-gxsz4.svc jessie_tcp@dns-test-service.e2e-tests-dns-gxsz4.svc]

Feb 13 14:35:06.011: INFO: DNS probes using e2e-tests-dns-gxsz4/dns-test-79e769dc-2f9c-11e9-9b61-026654d605e3 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:35:06.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-gxsz4" for this suite.
Feb 13 14:35:12.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:35:12.089: INFO: namespace: e2e-tests-dns-gxsz4, resource: bindings, ignored listing per whitelist
Feb 13 14:35:12.195: INFO: namespace e2e-tests-dns-gxsz4 deletion completed in 6.127414079s

• [SLOW TEST:40.496 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:35:12.196: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Feb 13 14:35:12.302: INFO: Waiting up to 5m0s for pod "client-containers-92080ac2-2f9c-11e9-9b61-026654d605e3" in namespace "e2e-tests-containers-pqf6m" to be "success or failure"
Feb 13 14:35:12.306: INFO: Pod "client-containers-92080ac2-2f9c-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.549511ms
Feb 13 14:35:14.310: INFO: Pod "client-containers-92080ac2-2f9c-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008370111s
Feb 13 14:35:16.322: INFO: Pod "client-containers-92080ac2-2f9c-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019736701s
STEP: Saw pod success
Feb 13 14:35:16.322: INFO: Pod "client-containers-92080ac2-2f9c-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:35:16.326: INFO: Trying to get logs from node cmp3 pod client-containers-92080ac2-2f9c-11e9-9b61-026654d605e3 container test-container: <nil>
STEP: delete the pod
Feb 13 14:35:16.346: INFO: Waiting for pod client-containers-92080ac2-2f9c-11e9-9b61-026654d605e3 to disappear
Feb 13 14:35:16.349: INFO: Pod client-containers-92080ac2-2f9c-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:35:16.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-pqf6m" for this suite.
Feb 13 14:35:22.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:35:22.435: INFO: namespace: e2e-tests-containers-pqf6m, resource: bindings, ignored listing per whitelist
Feb 13 14:35:22.478: INFO: namespace e2e-tests-containers-pqf6m deletion completed in 6.124372237s

• [SLOW TEST:10.282 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:35:22.478: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-9827e816-2f9c-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume secrets
Feb 13 14:35:22.590: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-982a4fbd-2f9c-11e9-9b61-026654d605e3" in namespace "e2e-tests-projected-br6gv" to be "success or failure"
Feb 13 14:35:22.593: INFO: Pod "pod-projected-secrets-982a4fbd-2f9c-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.249883ms
Feb 13 14:35:24.598: INFO: Pod "pod-projected-secrets-982a4fbd-2f9c-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00817546s
Feb 13 14:35:26.609: INFO: Pod "pod-projected-secrets-982a4fbd-2f9c-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018792295s
STEP: Saw pod success
Feb 13 14:35:26.609: INFO: Pod "pod-projected-secrets-982a4fbd-2f9c-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:35:26.613: INFO: Trying to get logs from node cmp3 pod pod-projected-secrets-982a4fbd-2f9c-11e9-9b61-026654d605e3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 13 14:35:26.635: INFO: Waiting for pod pod-projected-secrets-982a4fbd-2f9c-11e9-9b61-026654d605e3 to disappear
Feb 13 14:35:26.638: INFO: Pod pod-projected-secrets-982a4fbd-2f9c-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:35:26.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-br6gv" for this suite.
Feb 13 14:35:32.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:35:32.704: INFO: namespace: e2e-tests-projected-br6gv, resource: bindings, ignored listing per whitelist
Feb 13 14:35:32.770: INFO: namespace e2e-tests-projected-br6gv deletion completed in 6.127956511s

• [SLOW TEST:10.292 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:35:32.771: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-9e4b1b57-2f9c-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume configMaps
Feb 13 14:35:32.877: INFO: Waiting up to 5m0s for pod "pod-configmaps-9e4c2784-2f9c-11e9-9b61-026654d605e3" in namespace "e2e-tests-configmap-hv9pn" to be "success or failure"
Feb 13 14:35:32.881: INFO: Pod "pod-configmaps-9e4c2784-2f9c-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.605117ms
Feb 13 14:35:34.886: INFO: Pod "pod-configmaps-9e4c2784-2f9c-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008138926s
Feb 13 14:35:36.895: INFO: Pod "pod-configmaps-9e4c2784-2f9c-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017988344s
STEP: Saw pod success
Feb 13 14:35:36.895: INFO: Pod "pod-configmaps-9e4c2784-2f9c-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:35:36.898: INFO: Trying to get logs from node cmp3 pod pod-configmaps-9e4c2784-2f9c-11e9-9b61-026654d605e3 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 14:35:36.918: INFO: Waiting for pod pod-configmaps-9e4c2784-2f9c-11e9-9b61-026654d605e3 to disappear
Feb 13 14:35:36.921: INFO: Pod pod-configmaps-9e4c2784-2f9c-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:35:36.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-hv9pn" for this suite.
Feb 13 14:35:42.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:35:42.980: INFO: namespace: e2e-tests-configmap-hv9pn, resource: bindings, ignored listing per whitelist
Feb 13 14:35:43.050: INFO: namespace e2e-tests-configmap-hv9pn deletion completed in 6.125272075s

• [SLOW TEST:10.280 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:35:43.051: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-a46cedac-2f9c-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume secrets
Feb 13 14:35:43.169: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a46e3966-2f9c-11e9-9b61-026654d605e3" in namespace "e2e-tests-projected-gznms" to be "success or failure"
Feb 13 14:35:43.172: INFO: Pod "pod-projected-secrets-a46e3966-2f9c-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.549815ms
Feb 13 14:35:45.177: INFO: Pod "pod-projected-secrets-a46e3966-2f9c-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008460128s
Feb 13 14:35:47.188: INFO: Pod "pod-projected-secrets-a46e3966-2f9c-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019168073s
STEP: Saw pod success
Feb 13 14:35:47.188: INFO: Pod "pod-projected-secrets-a46e3966-2f9c-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:35:47.191: INFO: Trying to get logs from node cmp3 pod pod-projected-secrets-a46e3966-2f9c-11e9-9b61-026654d605e3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 13 14:35:47.224: INFO: Waiting for pod pod-projected-secrets-a46e3966-2f9c-11e9-9b61-026654d605e3 to disappear
Feb 13 14:35:47.227: INFO: Pod pod-projected-secrets-a46e3966-2f9c-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:35:47.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gznms" for this suite.
Feb 13 14:35:53.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:35:53.318: INFO: namespace: e2e-tests-projected-gznms, resource: bindings, ignored listing per whitelist
Feb 13 14:35:53.365: INFO: namespace e2e-tests-projected-gznms deletion completed in 6.133132614s

• [SLOW TEST:10.313 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:35:53.365: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 13 14:35:58.009: INFO: Successfully updated pod "pod-update-aa925cd0-2f9c-11e9-9b61-026654d605e3"
STEP: verifying the updated pod is in kubernetes
Feb 13 14:35:58.017: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:35:58.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-9j7mr" for this suite.
Feb 13 14:36:20.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:36:20.052: INFO: namespace: e2e-tests-pods-9j7mr, resource: bindings, ignored listing per whitelist
Feb 13 14:36:20.151: INFO: namespace e2e-tests-pods-9j7mr deletion completed in 22.130150445s

• [SLOW TEST:26.786 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:36:20.152: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 13 14:36:20.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-4hvrr'
Feb 13 14:36:20.373: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb 13 14:36:20.373: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Feb 13 14:36:20.382: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-m7j2h]
Feb 13 14:36:20.382: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-m7j2h" in namespace "e2e-tests-kubectl-4hvrr" to be "running and ready"
Feb 13 14:36:20.386: INFO: Pod "e2e-test-nginx-rc-m7j2h": Phase="Pending", Reason="", readiness=false. Elapsed: 3.05882ms
Feb 13 14:36:22.390: INFO: Pod "e2e-test-nginx-rc-m7j2h": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007837731s
Feb 13 14:36:24.394: INFO: Pod "e2e-test-nginx-rc-m7j2h": Phase="Running", Reason="", readiness=true. Elapsed: 4.011788463s
Feb 13 14:36:24.394: INFO: Pod "e2e-test-nginx-rc-m7j2h" satisfied condition "running and ready"
Feb 13 14:36:24.394: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-m7j2h]
Feb 13 14:36:24.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-4hvrr'
Feb 13 14:36:24.526: INFO: stderr: ""
Feb 13 14:36:24.526: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Feb 13 14:36:24.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-4hvrr'
Feb 13 14:36:24.648: INFO: stderr: ""
Feb 13 14:36:24.648: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:36:24.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4hvrr" for this suite.
Feb 13 14:36:46.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:36:46.776: INFO: namespace: e2e-tests-kubectl-4hvrr, resource: bindings, ignored listing per whitelist
Feb 13 14:36:46.779: INFO: namespace e2e-tests-kubectl-4hvrr deletion completed in 22.125166263s

• [SLOW TEST:26.627 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:36:46.780: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-ca6825bd-2f9c-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume configMaps
Feb 13 14:36:46.890: INFO: Waiting up to 5m0s for pod "pod-configmaps-ca696d5e-2f9c-11e9-9b61-026654d605e3" in namespace "e2e-tests-configmap-r5ftc" to be "success or failure"
Feb 13 14:36:46.894: INFO: Pod "pod-configmaps-ca696d5e-2f9c-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.0555ms
Feb 13 14:36:48.897: INFO: Pod "pod-configmaps-ca696d5e-2f9c-11e9-9b61-026654d605e3": Phase="Running", Reason="", readiness=true. Elapsed: 2.006530968s
Feb 13 14:36:50.901: INFO: Pod "pod-configmaps-ca696d5e-2f9c-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010606004s
STEP: Saw pod success
Feb 13 14:36:50.901: INFO: Pod "pod-configmaps-ca696d5e-2f9c-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:36:50.905: INFO: Trying to get logs from node cmp3 pod pod-configmaps-ca696d5e-2f9c-11e9-9b61-026654d605e3 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 14:36:50.932: INFO: Waiting for pod pod-configmaps-ca696d5e-2f9c-11e9-9b61-026654d605e3 to disappear
Feb 13 14:36:50.935: INFO: Pod pod-configmaps-ca696d5e-2f9c-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:36:50.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-r5ftc" for this suite.
Feb 13 14:36:56.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:36:57.000: INFO: namespace: e2e-tests-configmap-r5ftc, resource: bindings, ignored listing per whitelist
Feb 13 14:36:57.073: INFO: namespace e2e-tests-configmap-r5ftc deletion completed in 6.133445283s

• [SLOW TEST:10.294 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:36:57.073: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-d08a3837-2f9c-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume secrets
Feb 13 14:36:57.177: INFO: Waiting up to 5m0s for pod "pod-secrets-d08b3970-2f9c-11e9-9b61-026654d605e3" in namespace "e2e-tests-secrets-m7scm" to be "success or failure"
Feb 13 14:36:57.180: INFO: Pod "pod-secrets-d08b3970-2f9c-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.718895ms
Feb 13 14:36:59.184: INFO: Pod "pod-secrets-d08b3970-2f9c-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007623285s
Feb 13 14:37:01.189: INFO: Pod "pod-secrets-d08b3970-2f9c-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01212969s
STEP: Saw pod success
Feb 13 14:37:01.189: INFO: Pod "pod-secrets-d08b3970-2f9c-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:37:01.192: INFO: Trying to get logs from node cmp3 pod pod-secrets-d08b3970-2f9c-11e9-9b61-026654d605e3 container secret-volume-test: <nil>
STEP: delete the pod
Feb 13 14:37:01.232: INFO: Waiting for pod pod-secrets-d08b3970-2f9c-11e9-9b61-026654d605e3 to disappear
Feb 13 14:37:01.235: INFO: Pod pod-secrets-d08b3970-2f9c-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:37:01.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-m7scm" for this suite.
Feb 13 14:37:07.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:37:07.339: INFO: namespace: e2e-tests-secrets-m7scm, resource: bindings, ignored listing per whitelist
Feb 13 14:37:07.367: INFO: namespace e2e-tests-secrets-m7scm deletion completed in 6.126609684s

• [SLOW TEST:10.294 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:37:07.367: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 14:37:07.477: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d6adba42-2f9c-11e9-9b61-026654d605e3" in namespace "e2e-tests-downward-api-gnr75" to be "success or failure"
Feb 13 14:37:07.480: INFO: Pod "downwardapi-volume-d6adba42-2f9c-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.123597ms
Feb 13 14:37:09.485: INFO: Pod "downwardapi-volume-d6adba42-2f9c-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007825082s
Feb 13 14:37:11.490: INFO: Pod "downwardapi-volume-d6adba42-2f9c-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012427724s
STEP: Saw pod success
Feb 13 14:37:11.490: INFO: Pod "downwardapi-volume-d6adba42-2f9c-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:37:11.494: INFO: Trying to get logs from node cmp3 pod downwardapi-volume-d6adba42-2f9c-11e9-9b61-026654d605e3 container client-container: <nil>
STEP: delete the pod
Feb 13 14:37:11.534: INFO: Waiting for pod downwardapi-volume-d6adba42-2f9c-11e9-9b61-026654d605e3 to disappear
Feb 13 14:37:11.537: INFO: Pod downwardapi-volume-d6adba42-2f9c-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:37:11.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-gnr75" for this suite.
Feb 13 14:37:17.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:37:17.573: INFO: namespace: e2e-tests-downward-api-gnr75, resource: bindings, ignored listing per whitelist
Feb 13 14:37:17.667: INFO: namespace e2e-tests-downward-api-gnr75 deletion completed in 6.125780171s

• [SLOW TEST:10.300 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:37:17.668: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:37:17.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-c6zhp" for this suite.
Feb 13 14:37:23.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:37:23.801: INFO: namespace: e2e-tests-services-c6zhp, resource: bindings, ignored listing per whitelist
Feb 13 14:37:23.899: INFO: namespace e2e-tests-services-c6zhp deletion completed in 6.128942828s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.231 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:37:23.899: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 13 14:37:23.988: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:37:28.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-clw2v" for this suite.
Feb 13 14:37:34.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:37:34.726: INFO: namespace: e2e-tests-init-container-clw2v, resource: bindings, ignored listing per whitelist
Feb 13 14:37:34.776: INFO: namespace e2e-tests-init-container-clw2v deletion completed in 6.126560958s

• [SLOW TEST:10.876 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:37:34.776: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-e7033113-2f9c-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume configMaps
Feb 13 14:37:34.880: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e7043d21-2f9c-11e9-9b61-026654d605e3" in namespace "e2e-tests-projected-gb9mw" to be "success or failure"
Feb 13 14:37:34.883: INFO: Pod "pod-projected-configmaps-e7043d21-2f9c-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.183091ms
Feb 13 14:37:36.887: INFO: Pod "pod-projected-configmaps-e7043d21-2f9c-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007113204s
Feb 13 14:37:38.892: INFO: Pod "pod-projected-configmaps-e7043d21-2f9c-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01177405s
STEP: Saw pod success
Feb 13 14:37:38.892: INFO: Pod "pod-projected-configmaps-e7043d21-2f9c-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:37:38.900: INFO: Trying to get logs from node cmp3 pod pod-projected-configmaps-e7043d21-2f9c-11e9-9b61-026654d605e3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 14:37:38.921: INFO: Waiting for pod pod-projected-configmaps-e7043d21-2f9c-11e9-9b61-026654d605e3 to disappear
Feb 13 14:37:38.924: INFO: Pod pod-projected-configmaps-e7043d21-2f9c-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:37:38.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gb9mw" for this suite.
Feb 13 14:37:44.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:37:45.061: INFO: namespace: e2e-tests-projected-gb9mw, resource: bindings, ignored listing per whitelist
Feb 13 14:37:45.090: INFO: namespace e2e-tests-projected-gb9mw deletion completed in 6.159755015s

• [SLOW TEST:10.313 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:37:45.090: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb 13 14:37:45.202: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-lskp9,SelfLink:/api/v1/namespaces/e2e-tests-watch-lskp9/configmaps/e2e-watch-test-watch-closed,UID:ed2a5519-2f9c-11e9-85f4-fa163e429998,ResourceVersion:2520700,Generation:0,CreationTimestamp:2019-02-13 14:37:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 13 14:37:45.202: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-lskp9,SelfLink:/api/v1/namespaces/e2e-tests-watch-lskp9/configmaps/e2e-watch-test-watch-closed,UID:ed2a5519-2f9c-11e9-85f4-fa163e429998,ResourceVersion:2520701,Generation:0,CreationTimestamp:2019-02-13 14:37:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb 13 14:37:45.218: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-lskp9,SelfLink:/api/v1/namespaces/e2e-tests-watch-lskp9/configmaps/e2e-watch-test-watch-closed,UID:ed2a5519-2f9c-11e9-85f4-fa163e429998,ResourceVersion:2520702,Generation:0,CreationTimestamp:2019-02-13 14:37:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 13 14:37:45.218: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-lskp9,SelfLink:/api/v1/namespaces/e2e-tests-watch-lskp9/configmaps/e2e-watch-test-watch-closed,UID:ed2a5519-2f9c-11e9-85f4-fa163e429998,ResourceVersion:2520703,Generation:0,CreationTimestamp:2019-02-13 14:37:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:37:45.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-lskp9" for this suite.
Feb 13 14:37:51.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:37:51.324: INFO: namespace: e2e-tests-watch-lskp9, resource: bindings, ignored listing per whitelist
Feb 13 14:37:51.352: INFO: namespace e2e-tests-watch-lskp9 deletion completed in 6.128980783s

• [SLOW TEST:6.262 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:37:51.352: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 13 14:37:59.548: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 13 14:37:59.551: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 13 14:38:01.551: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 13 14:38:01.556: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 13 14:38:03.551: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 13 14:38:03.556: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 13 14:38:05.551: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 13 14:38:05.561: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 13 14:38:07.551: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 13 14:38:07.556: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 13 14:38:09.551: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 13 14:38:09.556: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 13 14:38:11.551: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 13 14:38:11.556: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 13 14:38:13.551: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 13 14:38:13.555: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 13 14:38:15.551: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 13 14:38:15.556: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 13 14:38:17.551: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 13 14:38:17.563: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 13 14:38:19.551: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 13 14:38:19.555: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:38:19.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-4tgqs" for this suite.
Feb 13 14:38:41.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:38:41.645: INFO: namespace: e2e-tests-container-lifecycle-hook-4tgqs, resource: bindings, ignored listing per whitelist
Feb 13 14:38:41.685: INFO: namespace e2e-tests-container-lifecycle-hook-4tgqs deletion completed in 22.124913344s

• [SLOW TEST:50.333 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:38:41.686: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-9ph88
Feb 13 14:38:45.797: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-9ph88
STEP: checking the pod's current state and verifying that restartCount is present
Feb 13 14:38:45.801: INFO: Initial restart count of pod liveness-http is 0
Feb 13 14:39:09.886: INFO: Restart count of pod e2e-tests-container-probe-9ph88/liveness-http is now 1 (24.085001404s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:39:09.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-9ph88" for this suite.
Feb 13 14:39:15.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:39:16.018: INFO: namespace: e2e-tests-container-probe-9ph88, resource: bindings, ignored listing per whitelist
Feb 13 14:39:16.036: INFO: namespace e2e-tests-container-probe-9ph88 deletion completed in 6.132462158s

• [SLOW TEST:34.350 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:39:16.037: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-ds2w6
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-ds2w6 to expose endpoints map[]
Feb 13 14:39:16.154: INFO: Get endpoints failed (3.29269ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Feb 13 14:39:17.157: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-ds2w6 exposes endpoints map[] (1.006899019s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-ds2w6
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-ds2w6 to expose endpoints map[pod1:[80]]
Feb 13 14:39:20.199: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-ds2w6 exposes endpoints map[pod1:[80]] (3.031257s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-ds2w6
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-ds2w6 to expose endpoints map[pod1:[80] pod2:[80]]
Feb 13 14:39:22.233: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-ds2w6 exposes endpoints map[pod1:[80] pod2:[80]] (2.028238198s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-ds2w6
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-ds2w6 to expose endpoints map[pod2:[80]]
Feb 13 14:39:23.252: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-ds2w6 exposes endpoints map[pod2:[80]] (1.012852865s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-ds2w6
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-ds2w6 to expose endpoints map[]
Feb 13 14:39:24.271: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-ds2w6 exposes endpoints map[] (1.011892427s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:39:24.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-ds2w6" for this suite.
Feb 13 14:39:44.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:39:44.364: INFO: namespace: e2e-tests-services-ds2w6, resource: bindings, ignored listing per whitelist
Feb 13 14:39:44.416: INFO: namespace e2e-tests-services-ds2w6 deletion completed in 20.118325527s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:28.379 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:39:44.417: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 14:39:44.529: INFO: Waiting up to 5m0s for pod "downwardapi-volume-344a68f4-2f9d-11e9-9b61-026654d605e3" in namespace "e2e-tests-projected-h6z9l" to be "success or failure"
Feb 13 14:39:44.533: INFO: Pod "downwardapi-volume-344a68f4-2f9d-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.849098ms
Feb 13 14:39:46.537: INFO: Pod "downwardapi-volume-344a68f4-2f9d-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007802744s
Feb 13 14:39:48.542: INFO: Pod "downwardapi-volume-344a68f4-2f9d-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012477997s
STEP: Saw pod success
Feb 13 14:39:48.542: INFO: Pod "downwardapi-volume-344a68f4-2f9d-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:39:48.545: INFO: Trying to get logs from node cmp3 pod downwardapi-volume-344a68f4-2f9d-11e9-9b61-026654d605e3 container client-container: <nil>
STEP: delete the pod
Feb 13 14:39:48.564: INFO: Waiting for pod downwardapi-volume-344a68f4-2f9d-11e9-9b61-026654d605e3 to disappear
Feb 13 14:39:48.567: INFO: Pod downwardapi-volume-344a68f4-2f9d-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:39:48.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h6z9l" for this suite.
Feb 13 14:39:54.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:39:54.593: INFO: namespace: e2e-tests-projected-h6z9l, resource: bindings, ignored listing per whitelist
Feb 13 14:39:54.695: INFO: namespace e2e-tests-projected-h6z9l deletion completed in 6.123111598s

• [SLOW TEST:10.278 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:39:54.695: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 13 14:39:54.795: INFO: Waiting up to 5m0s for pod "downward-api-3a691d7e-2f9d-11e9-9b61-026654d605e3" in namespace "e2e-tests-downward-api-7chw7" to be "success or failure"
Feb 13 14:39:54.799: INFO: Pod "downward-api-3a691d7e-2f9d-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.301149ms
Feb 13 14:39:56.803: INFO: Pod "downward-api-3a691d7e-2f9d-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007887147s
Feb 13 14:39:58.808: INFO: Pod "downward-api-3a691d7e-2f9d-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012789695s
STEP: Saw pod success
Feb 13 14:39:58.808: INFO: Pod "downward-api-3a691d7e-2f9d-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:39:58.811: INFO: Trying to get logs from node cmp3 pod downward-api-3a691d7e-2f9d-11e9-9b61-026654d605e3 container dapi-container: <nil>
STEP: delete the pod
Feb 13 14:39:58.846: INFO: Waiting for pod downward-api-3a691d7e-2f9d-11e9-9b61-026654d605e3 to disappear
Feb 13 14:39:58.849: INFO: Pod downward-api-3a691d7e-2f9d-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:39:58.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7chw7" for this suite.
Feb 13 14:40:04.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:40:04.950: INFO: namespace: e2e-tests-downward-api-7chw7, resource: bindings, ignored listing per whitelist
Feb 13 14:40:04.988: INFO: namespace e2e-tests-downward-api-7chw7 deletion completed in 6.133416175s

• [SLOW TEST:10.292 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:40:04.988: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb 13 14:40:05.082: INFO: namespace e2e-tests-kubectl-2xvmk
Feb 13 14:40:05.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 create -f - --namespace=e2e-tests-kubectl-2xvmk'
Feb 13 14:40:05.300: INFO: stderr: ""
Feb 13 14:40:05.300: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 13 14:40:06.304: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 14:40:06.304: INFO: Found 0 / 1
Feb 13 14:40:07.305: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 14:40:07.305: INFO: Found 1 / 1
Feb 13 14:40:07.305: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 13 14:40:07.309: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 14:40:07.309: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 13 14:40:07.309: INFO: wait on redis-master startup in e2e-tests-kubectl-2xvmk 
Feb 13 14:40:07.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 logs redis-master-xrslr redis-master --namespace=e2e-tests-kubectl-2xvmk'
Feb 13 14:40:07.426: INFO: stderr: ""
Feb 13 14:40:07.426: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 13 Feb 14:40:06.840 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 13 Feb 14:40:06.841 # Server started, Redis version 3.2.12\n1:M 13 Feb 14:40:06.841 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 13 Feb 14:40:06.841 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Feb 13 14:40:07.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-2xvmk'
Feb 13 14:40:07.573: INFO: stderr: ""
Feb 13 14:40:07.573: INFO: stdout: "service/rm2 exposed\n"
Feb 13 14:40:07.577: INFO: Service rm2 in namespace e2e-tests-kubectl-2xvmk found.
STEP: exposing service
Feb 13 14:40:09.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-2xvmk'
Feb 13 14:40:09.710: INFO: stderr: ""
Feb 13 14:40:09.710: INFO: stdout: "service/rm3 exposed\n"
Feb 13 14:40:09.714: INFO: Service rm3 in namespace e2e-tests-kubectl-2xvmk found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:40:11.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2xvmk" for this suite.
Feb 13 14:40:33.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:40:33.757: INFO: namespace: e2e-tests-kubectl-2xvmk, resource: bindings, ignored listing per whitelist
Feb 13 14:40:33.859: INFO: namespace e2e-tests-kubectl-2xvmk deletion completed in 22.133285873s

• [SLOW TEST:28.871 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:40:33.860: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-bdw7f
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-bdw7f
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-bdw7f
Feb 13 14:40:33.967: INFO: Found 0 stateful pods, waiting for 1
Feb 13 14:40:43.979: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb 13 14:40:43.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 13 14:40:44.393: INFO: stderr: ""
Feb 13 14:40:44.393: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 13 14:40:44.393: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 13 14:40:44.397: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 13 14:40:54.408: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 13 14:40:54.408: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 14:40:54.425: INFO: POD   NODE  PHASE    GRACE  CONDITIONS
Feb 13 14:40:54.425: INFO: ss-0  cmp3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:33 +0000 UTC  }]
Feb 13 14:40:54.426: INFO: 
Feb 13 14:40:54.426: INFO: StatefulSet ss has not reached scale 3, at 1
Feb 13 14:40:55.431: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995582847s
Feb 13 14:40:56.436: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990498486s
Feb 13 14:40:57.442: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985252378s
Feb 13 14:40:58.447: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.979276676s
Feb 13 14:40:59.452: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.974659401s
Feb 13 14:41:00.457: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.969377283s
Feb 13 14:41:01.461: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.964848719s
Feb 13 14:41:02.467: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.960172156s
Feb 13 14:41:03.472: INFO: Verifying statefulset ss doesn't scale past 3 for another 954.998657ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-bdw7f
Feb 13 14:41:04.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:41:04.957: INFO: stderr: ""
Feb 13 14:41:04.957: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 13 14:41:04.957: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 13 14:41:04.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:41:05.308: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb 13 14:41:05.308: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 13 14:41:05.308: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 13 14:41:05.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:41:05.599: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb 13 14:41:05.599: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 13 14:41:05.599: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 13 14:41:05.604: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 14:41:05.604: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 14:41:05.604: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb 13 14:41:05.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 13 14:41:05.959: INFO: stderr: ""
Feb 13 14:41:05.959: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 13 14:41:05.959: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 13 14:41:05.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 13 14:41:06.380: INFO: stderr: ""
Feb 13 14:41:06.380: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 13 14:41:06.380: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 13 14:41:06.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 13 14:41:06.712: INFO: stderr: ""
Feb 13 14:41:06.712: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 13 14:41:06.712: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 13 14:41:06.712: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 14:41:06.716: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb 13 14:41:16.730: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 13 14:41:16.730: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 13 14:41:16.730: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 13 14:41:16.742: INFO: POD   NODE  PHASE    GRACE  CONDITIONS
Feb 13 14:41:16.742: INFO: ss-0  cmp3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:33 +0000 UTC  }]
Feb 13 14:41:16.742: INFO: ss-1  cmp1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:54 +0000 UTC  }]
Feb 13 14:41:16.742: INFO: ss-2  cmp2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:54 +0000 UTC  }]
Feb 13 14:41:16.742: INFO: 
Feb 13 14:41:16.742: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 13 14:41:17.747: INFO: POD   NODE  PHASE    GRACE  CONDITIONS
Feb 13 14:41:17.747: INFO: ss-0  cmp3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:33 +0000 UTC  }]
Feb 13 14:41:17.747: INFO: ss-1  cmp1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:54 +0000 UTC  }]
Feb 13 14:41:17.747: INFO: ss-2  cmp2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:54 +0000 UTC  }]
Feb 13 14:41:17.747: INFO: 
Feb 13 14:41:17.747: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 13 14:41:18.773: INFO: POD   NODE  PHASE    GRACE  CONDITIONS
Feb 13 14:41:18.773: INFO: ss-0  cmp3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:33 +0000 UTC  }]
Feb 13 14:41:18.773: INFO: ss-1  cmp1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:54 +0000 UTC  }]
Feb 13 14:41:18.773: INFO: ss-2  cmp2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:54 +0000 UTC  }]
Feb 13 14:41:18.773: INFO: 
Feb 13 14:41:18.773: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 13 14:41:19.777: INFO: POD   NODE  PHASE    GRACE  CONDITIONS
Feb 13 14:41:19.777: INFO: ss-0  cmp3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:33 +0000 UTC  }]
Feb 13 14:41:19.777: INFO: ss-1  cmp1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:54 +0000 UTC  }]
Feb 13 14:41:19.777: INFO: ss-2  cmp2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:54 +0000 UTC  }]
Feb 13 14:41:19.777: INFO: 
Feb 13 14:41:19.777: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 13 14:41:20.782: INFO: POD   NODE  PHASE    GRACE  CONDITIONS
Feb 13 14:41:20.782: INFO: ss-0  cmp3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:33 +0000 UTC  }]
Feb 13 14:41:20.782: INFO: ss-1  cmp1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:54 +0000 UTC  }]
Feb 13 14:41:20.782: INFO: ss-2  cmp2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:54 +0000 UTC  }]
Feb 13 14:41:20.782: INFO: 
Feb 13 14:41:20.782: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 13 14:41:21.787: INFO: POD   NODE  PHASE    GRACE  CONDITIONS
Feb 13 14:41:21.787: INFO: ss-0  cmp3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:33 +0000 UTC  }]
Feb 13 14:41:21.787: INFO: ss-1  cmp1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:54 +0000 UTC  }]
Feb 13 14:41:21.787: INFO: ss-2  cmp2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:54 +0000 UTC  }]
Feb 13 14:41:21.787: INFO: 
Feb 13 14:41:21.787: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 13 14:41:22.792: INFO: POD   NODE  PHASE    GRACE  CONDITIONS
Feb 13 14:41:22.792: INFO: ss-0  cmp3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:33 +0000 UTC  }]
Feb 13 14:41:22.792: INFO: ss-1  cmp1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:54 +0000 UTC  }]
Feb 13 14:41:22.792: INFO: ss-2  cmp2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:54 +0000 UTC  }]
Feb 13 14:41:22.792: INFO: 
Feb 13 14:41:22.792: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 13 14:41:23.797: INFO: POD   NODE  PHASE    GRACE  CONDITIONS
Feb 13 14:41:23.797: INFO: ss-0  cmp3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:33 +0000 UTC  }]
Feb 13 14:41:23.797: INFO: 
Feb 13 14:41:23.797: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 13 14:41:24.811: INFO: POD   NODE  PHASE    GRACE  CONDITIONS
Feb 13 14:41:24.811: INFO: ss-0  cmp3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:33 +0000 UTC  }]
Feb 13 14:41:24.811: INFO: 
Feb 13 14:41:24.811: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 13 14:41:25.825: INFO: POD   NODE  PHASE    GRACE  CONDITIONS
Feb 13 14:41:25.825: INFO: ss-0  cmp3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:41:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:40:33 +0000 UTC  }]
Feb 13 14:41:25.825: INFO: 
Feb 13 14:41:25.825: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-bdw7f
Feb 13 14:41:26.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:41:27.013: INFO: rc: 1
Feb 13 14:41:27.013: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc42287c9c0 exit status 1 <nil> <nil> true [0xc42000f7a8 0xc42000f8a0 0xc42000f960] [0xc42000f7a8 0xc42000f8a0 0xc42000f960] [0xc42000f860 0xc42000f8c8] [0x8fd520 0x8fd520] 0xc421556360 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Feb 13 14:41:37.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:41:37.125: INFO: rc: 1
Feb 13 14:41:37.125: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42287cd50 exit status 1 <nil> <nil> true [0xc42000f980 0xc42000fa20 0xc42000fab0] [0xc42000f980 0xc42000fa20 0xc42000fab0] [0xc42000f9e0 0xc42000faa8] [0x8fd520 0x8fd520] 0xc421556720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 13 14:41:47.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:41:47.233: INFO: rc: 1
Feb 13 14:41:47.233: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42152a390 exit status 1 <nil> <nil> true [0xc420a66048 0xc420a660a8 0xc420a66280] [0xc420a66048 0xc420a660a8 0xc420a66280] [0xc420a66080 0xc420a661b0] [0x8fd520 0x8fd520] 0xc421cd8060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 13 14:41:57.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:41:57.346: INFO: rc: 1
Feb 13 14:41:57.346: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc422afe750 exit status 1 <nil> <nil> true [0xc4200f21e8 0xc4200f2250 0xc4200f22e8] [0xc4200f21e8 0xc4200f2250 0xc4200f22e8] [0xc4200f2248 0xc4200f2298] [0x8fd520 0x8fd520] 0xc42223c1e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 13 14:42:07.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:42:07.447: INFO: rc: 1
Feb 13 14:42:07.447: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42152a750 exit status 1 <nil> <nil> true [0xc420a66308 0xc420a663e8 0xc420a66430] [0xc420a66308 0xc420a663e8 0xc420a66430] [0xc420a663b0 0xc420a66418] [0x8fd520 0x8fd520] 0xc421cd8180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 13 14:42:17.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:42:17.556: INFO: rc: 1
Feb 13 14:42:17.556: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc422afeb40 exit status 1 <nil> <nil> true [0xc4200f2398 0xc4200f23f8 0xc4200f24e0] [0xc4200f2398 0xc4200f23f8 0xc4200f24e0] [0xc4200f23c8 0xc4200f24c8] [0x8fd520 0x8fd520] 0xc4220b2120 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 13 14:42:27.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:42:27.697: INFO: rc: 1
Feb 13 14:42:27.697: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42287d110 exit status 1 <nil> <nil> true [0xc42000fb48 0xc42000fc88 0xc42000fd90] [0xc42000fb48 0xc42000fc88 0xc42000fd90] [0xc42000fc30 0xc42000fd60] [0x8fd520 0x8fd520] 0xc421556840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 13 14:42:37.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:42:37.838: INFO: rc: 1
Feb 13 14:42:37.838: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4228343f0 exit status 1 <nil> <nil> true [0xc421782000 0xc421782060 0xc4217820c0] [0xc421782000 0xc421782060 0xc4217820c0] [0xc421782040 0xc4217820a8] [0x8fd520 0x8fd520] 0xc421f34060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 13 14:42:47.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:42:47.967: INFO: rc: 1
Feb 13 14:42:47.967: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4228348a0 exit status 1 <nil> <nil> true [0xc4217820c8 0xc421782118 0xc421782158] [0xc4217820c8 0xc421782118 0xc421782158] [0xc4217820f0 0xc421782138] [0x8fd520 0x8fd520] 0xc421f34180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 13 14:42:57.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:42:58.068: INFO: rc: 1
Feb 13 14:42:58.068: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc422834d50 exit status 1 <nil> <nil> true [0xc421782160 0xc4217821d0 0xc421782210] [0xc421782160 0xc4217821d0 0xc421782210] [0xc4217821c0 0xc4217821f8] [0x8fd520 0x8fd520] 0xc421f34300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 13 14:43:08.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:43:08.178: INFO: rc: 1
Feb 13 14:43:08.178: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc422835110 exit status 1 <nil> <nil> true [0xc421782220 0xc421782270 0xc4217822a0] [0xc421782220 0xc421782270 0xc4217822a0] [0xc421782250 0xc421782288] [0x8fd520 0x8fd520] 0xc421f34660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 13 14:43:18.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:43:18.289: INFO: rc: 1
Feb 13 14:43:18.289: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4228354d0 exit status 1 <nil> <nil> true [0xc4217822b8 0xc421782318 0xc421782330] [0xc4217822b8 0xc421782318 0xc421782330] [0xc4217822f8 0xc421782328] [0x8fd520 0x8fd520] 0xc421f349c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 13 14:43:28.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:43:28.424: INFO: rc: 1
Feb 13 14:43:28.424: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc422834420 exit status 1 <nil> <nil> true [0xc421782000 0xc421782060 0xc4217820c0] [0xc421782000 0xc421782060 0xc4217820c0] [0xc421782040 0xc4217820a8] [0x8fd520 0x8fd520] 0xc42223c0c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 13 14:43:38.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:43:38.534: INFO: rc: 1
Feb 13 14:43:38.534: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42152a3c0 exit status 1 <nil> <nil> true [0xc420a66048 0xc420a660a8 0xc420a66280] [0xc420a66048 0xc420a660a8 0xc420a66280] [0xc420a66080 0xc420a661b0] [0x8fd520 0x8fd520] 0xc421f34060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 13 14:43:48.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:43:48.648: INFO: rc: 1
Feb 13 14:43:48.648: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc422834930 exit status 1 <nil> <nil> true [0xc4217820c8 0xc421782118 0xc421782158] [0xc4217820c8 0xc421782118 0xc421782158] [0xc4217820f0 0xc421782138] [0x8fd520 0x8fd520] 0xc42223c1e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 13 14:43:58.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:43:58.774: INFO: rc: 1
Feb 13 14:43:58.774: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc422834de0 exit status 1 <nil> <nil> true [0xc421782160 0xc4217821d0 0xc421782210] [0xc421782160 0xc4217821d0 0xc421782210] [0xc4217821c0 0xc4217821f8] [0x8fd520 0x8fd520] 0xc421cd8000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 13 14:44:08.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:44:08.874: INFO: rc: 1
Feb 13 14:44:08.874: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42287c390 exit status 1 <nil> <nil> true [0xc42000e138 0xc42000f750 0xc42000f860] [0xc42000e138 0xc42000f750 0xc42000f860] [0xc42000f6f8 0xc42000f858] [0x8fd520 0x8fd520] 0xc421556120 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 13 14:44:18.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:44:18.988: INFO: rc: 1
Feb 13 14:44:18.988: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc422afe3c0 exit status 1 <nil> <nil> true [0xc4200f2058 0xc4200f2120 0xc4200f2230] [0xc4200f2058 0xc4200f2120 0xc4200f2230] [0xc4200f2100 0xc4200f21e8] [0x8fd520 0x8fd520] 0xc4220b2180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 13 14:44:28.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:44:29.099: INFO: rc: 1
Feb 13 14:44:29.099: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42287c900 exit status 1 <nil> <nil> true [0xc42000f8a0 0xc42000f960 0xc42000f9e0] [0xc42000f8a0 0xc42000f960 0xc42000f9e0] [0xc42000f8c8 0xc42000f9c8] [0x8fd520 0x8fd520] 0xc4215562a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 13 14:44:39.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:44:39.227: INFO: rc: 1
Feb 13 14:44:39.227: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc422afe7b0 exit status 1 <nil> <nil> true [0xc4200f2248 0xc4200f2298 0xc4200f23a0] [0xc4200f2248 0xc4200f2298 0xc4200f23a0] [0xc4200f2268 0xc4200f2398] [0x8fd520 0x8fd520] 0xc4220b2360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 13 14:44:49.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:44:49.344: INFO: rc: 1
Feb 13 14:44:49.344: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42152a810 exit status 1 <nil> <nil> true [0xc420a66308 0xc420a663e8 0xc420a66430] [0xc420a66308 0xc420a663e8 0xc420a66430] [0xc420a663b0 0xc420a66418] [0x8fd520 0x8fd520] 0xc421f34180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 13 14:44:59.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:44:59.450: INFO: rc: 1
Feb 13 14:44:59.450: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42287ccf0 exit status 1 <nil> <nil> true [0xc42000fa20 0xc42000fab0 0xc42000fc30] [0xc42000fa20 0xc42000fab0 0xc42000fc30] [0xc42000faa8 0xc42000fb58] [0x8fd520 0x8fd520] 0xc421556660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 13 14:45:09.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:45:09.565: INFO: rc: 1
Feb 13 14:45:09.565: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42287d0e0 exit status 1 <nil> <nil> true [0xc42000fc88 0xc42000fd90 0xc42000fde8] [0xc42000fc88 0xc42000fd90 0xc42000fde8] [0xc42000fd60 0xc42000fdd0] [0x8fd520 0x8fd520] 0xc4215567e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 13 14:45:19.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:45:19.709: INFO: rc: 1
Feb 13 14:45:19.709: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42287d560 exit status 1 <nil> <nil> true [0xc42000fe48 0xc42000ff38 0xc42000ffb0] [0xc42000fe48 0xc42000ff38 0xc42000ffb0] [0xc42000fed0 0xc42000ffa8] [0x8fd520 0x8fd520] 0xc421556a20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 13 14:45:29.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:45:29.829: INFO: rc: 1
Feb 13 14:45:29.829: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42152acf0 exit status 1 <nil> <nil> true [0xc420a664a8 0xc420a66500 0xc420a66540] [0xc420a664a8 0xc420a66500 0xc420a66540] [0xc420a664d8 0xc420a66530] [0x8fd520 0x8fd520] 0xc421f34300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 13 14:45:39.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:45:39.935: INFO: rc: 1
Feb 13 14:45:39.935: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42287c360 exit status 1 <nil> <nil> true [0xc4200dc000 0xc421782040 0xc4217820a8] [0xc4200dc000 0xc421782040 0xc4217820a8] [0xc421782028 0xc421782090] [0x8fd520 0x8fd520] 0xc42223c0c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 13 14:45:49.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:45:50.071: INFO: rc: 1
Feb 13 14:45:50.071: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42287c930 exit status 1 <nil> <nil> true [0xc4217820c0 0xc4217820f0 0xc421782138] [0xc4217820c0 0xc4217820f0 0xc421782138] [0xc4217820d0 0xc421782130] [0x8fd520 0x8fd520] 0xc42223c1e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 13 14:46:00.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:46:00.193: INFO: rc: 1
Feb 13 14:46:00.193: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42287ccc0 exit status 1 <nil> <nil> true [0xc421782158 0xc4217821c0 0xc4217821f8] [0xc421782158 0xc4217821c0 0xc4217821f8] [0xc4217821a0 0xc4217821d8] [0x8fd520 0x8fd520] 0xc421cd8000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 13 14:46:10.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:46:10.303: INFO: rc: 1
Feb 13 14:46:10.303: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42287d080 exit status 1 <nil> <nil> true [0xc421782210 0xc421782250 0xc421782288] [0xc421782210 0xc421782250 0xc421782288] [0xc421782228 0xc421782280] [0x8fd520 0x8fd520] 0xc421cd8120 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 13 14:46:20.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:46:20.440: INFO: rc: 1
Feb 13 14:46:20.440: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42152a420 exit status 1 <nil> <nil> true [0xc42000e138 0xc42000f750 0xc42000f860] [0xc42000e138 0xc42000f750 0xc42000f860] [0xc42000f6f8 0xc42000f858] [0x8fd520 0x8fd520] 0xc421556120 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 13 14:46:30.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 exec --namespace=e2e-tests-statefulset-bdw7f ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 14:46:30.558: INFO: rc: 1
Feb 13 14:46:30.558: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Feb 13 14:46:30.558: INFO: Scaling statefulset ss to 0
Feb 13 14:46:30.570: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 13 14:46:30.573: INFO: Deleting all statefulset in ns e2e-tests-statefulset-bdw7f
Feb 13 14:46:30.577: INFO: Scaling statefulset ss to 0
Feb 13 14:46:30.586: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 14:46:30.589: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:46:30.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-bdw7f" for this suite.
Feb 13 14:46:36.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:46:36.706: INFO: namespace: e2e-tests-statefulset-bdw7f, resource: bindings, ignored listing per whitelist
Feb 13 14:46:36.734: INFO: namespace e2e-tests-statefulset-bdw7f deletion completed in 6.125136802s

• [SLOW TEST:362.875 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:46:36.735: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 14:46:36.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 version --client'
Feb 13 14:46:36.918: INFO: stderr: ""
Feb 13 14:46:36.918: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Feb 13 14:46:36.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 create -f - --namespace=e2e-tests-kubectl-5xq9t'
Feb 13 14:46:37.267: INFO: stderr: ""
Feb 13 14:46:37.267: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb 13 14:46:37.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 create -f - --namespace=e2e-tests-kubectl-5xq9t'
Feb 13 14:46:37.495: INFO: stderr: ""
Feb 13 14:46:37.495: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 13 14:46:38.499: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 14:46:38.499: INFO: Found 0 / 1
Feb 13 14:46:39.514: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 14:46:39.514: INFO: Found 0 / 1
Feb 13 14:46:40.499: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 14:46:40.499: INFO: Found 1 / 1
Feb 13 14:46:40.499: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 13 14:46:40.502: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 14:46:40.502: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 13 14:46:40.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 describe pod redis-master-t5hxx --namespace=e2e-tests-kubectl-5xq9t'
Feb 13 14:46:40.634: INFO: stderr: ""
Feb 13 14:46:40.634: INFO: stdout: "Name:               redis-master-t5hxx\nNamespace:          e2e-tests-kubectl-5xq9t\nPriority:           0\nPriorityClassName:  <none>\nNode:               cmp3/10.11.1.3\nStart Time:         Wed, 13 Feb 2019 14:46:37 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 192.168.113.106\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://a56eef3ed26da9850c14565d56ec087c519e66f3481e1ef551db135a3d6c6a52\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 13 Feb 2019 14:46:39 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-m66b8 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-m66b8:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-m66b8\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  3s    default-scheduler  Successfully assigned e2e-tests-kubectl-5xq9t/redis-master-t5hxx to cmp3\n  Normal  Pulled     1s    kubelet, cmp3      Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, cmp3      Created container\n  Normal  Started    1s    kubelet, cmp3      Started container\n"
Feb 13 14:46:40.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 describe rc redis-master --namespace=e2e-tests-kubectl-5xq9t'
Feb 13 14:46:40.784: INFO: stderr: ""
Feb 13 14:46:40.784: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-5xq9t\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-t5hxx\n"
Feb 13 14:46:40.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 describe service redis-master --namespace=e2e-tests-kubectl-5xq9t'
Feb 13 14:46:40.915: INFO: stderr: ""
Feb 13 14:46:40.915: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-5xq9t\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.254.231.10\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         192.168.113.106:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb 13 14:46:40.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 describe node cmp1'
Feb 13 14:46:41.055: INFO: stderr: ""
Feb 13 14:46:41.055: INFO: stdout: "Name:               cmp1\nRoles:              node\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    extraRuntime=virtlet\n                    kubernetes.io/hostname=cmp1\n                    node-role.kubernetes.io/node=true\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"1a:32:c2:08:52:88\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 10.10.100.24\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 01 Feb 2019 18:28:24 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Wed, 13 Feb 2019 14:46:35 +0000   Thu, 07 Feb 2019 15:32:27 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Wed, 13 Feb 2019 14:46:35 +0000   Thu, 07 Feb 2019 15:32:27 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 13 Feb 2019 14:46:35 +0000   Thu, 07 Feb 2019 15:32:27 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 13 Feb 2019 14:46:35 +0000   Fri, 01 Feb 2019 18:28:24 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 13 Feb 2019 14:46:35 +0000   Wed, 13 Feb 2019 12:01:15 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.11.1.1\n  Hostname:    cmp1\nCapacity:\n cpu:                1\n ephemeral-storage:  25231544Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             2041208Ki\n pods:               110\nAllocatable:\n cpu:                1\n ephemeral-storage:  23253390912\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             1938808Ki\n pods:               110\nSystem Info:\n Machine ID:                 7b17cfb3a5724e06a2b1b8d17cc0e2cb\n System UUID:                A2A7F862-5FD0-493E-A6E3-0831D3686339\n Boot ID:                    2609cf2c-6e7c-4f5c-b3c5-94722e335b6d\n Kernel Version:             4.15.0-43-generic\n OS Image:                   Ubuntu 16.04.5 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.2.1\n Kubelet Version:            v1.12.4-3+680746c29c3258\n Kube-Proxy Version:         v1.12.4-3+680746c29c3258\nPodCIDR:                     10.20.4.0/24\nNon-terminated Pods:         (5 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-e9328804e2d54b8e-kmd4p    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-flannel-ds-z7czt                                      100m (10%)    100m (10%)  50Mi (2%)        50Mi (2%)\n  metallb-system             speaker-9ktjr                                              100m (10%)    100m (10%)  100Mi (5%)       100Mi (5%)\n  netchecker                 netchecker-agent-rgq6k                                     0 (0%)        0 (0%)      0 (0%)           0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource  Requests    Limits\n  --------  --------    ------\n  cpu       200m (20%)  200m (20%)\n  memory    150Mi (7%)  150Mi (7%)\nEvents:     <none>\n"
Feb 13 14:46:41.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 describe namespace e2e-tests-kubectl-5xq9t'
Feb 13 14:46:41.187: INFO: stderr: ""
Feb 13 14:46:41.187: INFO: stdout: "Name:         e2e-tests-kubectl-5xq9t\nLabels:       e2e-framework=kubectl\n              e2e-run=eda826c4-2f93-11e9-9b61-026654d605e3\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:46:41.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5xq9t" for this suite.
Feb 13 14:47:03.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:47:03.217: INFO: namespace: e2e-tests-kubectl-5xq9t, resource: bindings, ignored listing per whitelist
Feb 13 14:47:03.320: INFO: namespace e2e-tests-kubectl-5xq9t deletion completed in 22.127759684s

• [SLOW TEST:26.585 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:47:03.320: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-5ppr
STEP: Creating a pod to test atomic-volume-subpath
Feb 13 14:47:03.437: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-5ppr" in namespace "e2e-tests-subpath-6v62w" to be "success or failure"
Feb 13 14:47:03.440: INFO: Pod "pod-subpath-test-secret-5ppr": Phase="Pending", Reason="", readiness=false. Elapsed: 3.095769ms
Feb 13 14:47:05.444: INFO: Pod "pod-subpath-test-secret-5ppr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007141435s
Feb 13 14:47:07.448: INFO: Pod "pod-subpath-test-secret-5ppr": Phase="Running", Reason="", readiness=false. Elapsed: 4.011104727s
Feb 13 14:47:09.452: INFO: Pod "pod-subpath-test-secret-5ppr": Phase="Running", Reason="", readiness=false. Elapsed: 6.014832063s
Feb 13 14:47:11.456: INFO: Pod "pod-subpath-test-secret-5ppr": Phase="Running", Reason="", readiness=false. Elapsed: 8.019670161s
Feb 13 14:47:13.465: INFO: Pod "pod-subpath-test-secret-5ppr": Phase="Running", Reason="", readiness=false. Elapsed: 10.027865896s
Feb 13 14:47:15.469: INFO: Pod "pod-subpath-test-secret-5ppr": Phase="Running", Reason="", readiness=false. Elapsed: 12.031994428s
Feb 13 14:47:17.473: INFO: Pod "pod-subpath-test-secret-5ppr": Phase="Running", Reason="", readiness=false. Elapsed: 14.036236977s
Feb 13 14:47:19.477: INFO: Pod "pod-subpath-test-secret-5ppr": Phase="Running", Reason="", readiness=false. Elapsed: 16.040315101s
Feb 13 14:47:21.482: INFO: Pod "pod-subpath-test-secret-5ppr": Phase="Running", Reason="", readiness=false. Elapsed: 18.0452259s
Feb 13 14:47:23.493: INFO: Pod "pod-subpath-test-secret-5ppr": Phase="Running", Reason="", readiness=false. Elapsed: 20.055754613s
Feb 13 14:47:25.497: INFO: Pod "pod-subpath-test-secret-5ppr": Phase="Running", Reason="", readiness=false. Elapsed: 22.060522725s
Feb 13 14:47:27.502: INFO: Pod "pod-subpath-test-secret-5ppr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.065085594s
STEP: Saw pod success
Feb 13 14:47:27.502: INFO: Pod "pod-subpath-test-secret-5ppr" satisfied condition "success or failure"
Feb 13 14:47:27.505: INFO: Trying to get logs from node cmp3 pod pod-subpath-test-secret-5ppr container test-container-subpath-secret-5ppr: <nil>
STEP: delete the pod
Feb 13 14:47:27.537: INFO: Waiting for pod pod-subpath-test-secret-5ppr to disappear
Feb 13 14:47:27.541: INFO: Pod pod-subpath-test-secret-5ppr no longer exists
STEP: Deleting pod pod-subpath-test-secret-5ppr
Feb 13 14:47:27.541: INFO: Deleting pod "pod-subpath-test-secret-5ppr" in namespace "e2e-tests-subpath-6v62w"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:47:27.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-6v62w" for this suite.
Feb 13 14:47:33.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:47:33.608: INFO: namespace: e2e-tests-subpath-6v62w, resource: bindings, ignored listing per whitelist
Feb 13 14:47:33.672: INFO: namespace e2e-tests-subpath-6v62w deletion completed in 6.123073451s

• [SLOW TEST:30.352 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:47:33.672: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 14:47:33.775: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4bfbee9e-2f9e-11e9-9b61-026654d605e3" in namespace "e2e-tests-downward-api-brmp2" to be "success or failure"
Feb 13 14:47:33.778: INFO: Pod "downwardapi-volume-4bfbee9e-2f9e-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.848843ms
Feb 13 14:47:35.783: INFO: Pod "downwardapi-volume-4bfbee9e-2f9e-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00781935s
Feb 13 14:47:37.788: INFO: Pod "downwardapi-volume-4bfbee9e-2f9e-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012487717s
STEP: Saw pod success
Feb 13 14:47:37.788: INFO: Pod "downwardapi-volume-4bfbee9e-2f9e-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:47:37.791: INFO: Trying to get logs from node cmp3 pod downwardapi-volume-4bfbee9e-2f9e-11e9-9b61-026654d605e3 container client-container: <nil>
STEP: delete the pod
Feb 13 14:47:37.809: INFO: Waiting for pod downwardapi-volume-4bfbee9e-2f9e-11e9-9b61-026654d605e3 to disappear
Feb 13 14:47:37.812: INFO: Pod downwardapi-volume-4bfbee9e-2f9e-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:47:37.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-brmp2" for this suite.
Feb 13 14:47:43.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:47:43.874: INFO: namespace: e2e-tests-downward-api-brmp2, resource: bindings, ignored listing per whitelist
Feb 13 14:47:43.941: INFO: namespace e2e-tests-downward-api-brmp2 deletion completed in 6.124624392s

• [SLOW TEST:10.269 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:47:43.941: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 13 14:47:44.042: INFO: Waiting up to 5m0s for pod "pod-521aa6a6-2f9e-11e9-9b61-026654d605e3" in namespace "e2e-tests-emptydir-v28dz" to be "success or failure"
Feb 13 14:47:44.045: INFO: Pod "pod-521aa6a6-2f9e-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.740414ms
Feb 13 14:47:46.050: INFO: Pod "pod-521aa6a6-2f9e-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007526564s
Feb 13 14:47:48.055: INFO: Pod "pod-521aa6a6-2f9e-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012758784s
STEP: Saw pod success
Feb 13 14:47:48.055: INFO: Pod "pod-521aa6a6-2f9e-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:47:48.058: INFO: Trying to get logs from node cmp3 pod pod-521aa6a6-2f9e-11e9-9b61-026654d605e3 container test-container: <nil>
STEP: delete the pod
Feb 13 14:47:48.097: INFO: Waiting for pod pod-521aa6a6-2f9e-11e9-9b61-026654d605e3 to disappear
Feb 13 14:47:48.101: INFO: Pod pod-521aa6a6-2f9e-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:47:48.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-v28dz" for this suite.
Feb 13 14:47:54.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:47:54.207: INFO: namespace: e2e-tests-emptydir-v28dz, resource: bindings, ignored listing per whitelist
Feb 13 14:47:54.228: INFO: namespace e2e-tests-emptydir-v28dz deletion completed in 6.122341678s

• [SLOW TEST:10.287 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:47:54.229: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 14:47:54.319: INFO: Creating deployment "test-recreate-deployment"
Feb 13 14:47:54.327: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb 13 14:47:54.333: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Feb 13 14:47:56.343: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb 13 14:47:56.346: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685666074, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685666074, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685666074, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685666074, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 14:47:58.351: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb 13 14:47:58.358: INFO: Updating deployment test-recreate-deployment
Feb 13 14:47:58.358: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 13 14:47:58.415: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-lqv4c,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lqv4c/deployments/test-recreate-deployment,UID:583c3d2d-2f9e-11e9-85f4-fa163e429998,ResourceVersion:2522858,Generation:2,CreationTimestamp:2019-02-13 14:47:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-02-13 14:47:58 +0000 UTC 2019-02-13 14:47:58 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-13 14:47:58 +0000 UTC 2019-02-13 14:47:54 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Feb 13 14:47:58.418: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-lqv4c,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lqv4c/replicasets/test-recreate-deployment-7cf749666b,UID:5aa8e502-2f9e-11e9-b579-fa163ed32deb,ResourceVersion:2522856,Generation:1,CreationTimestamp:2019-02-13 14:47:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 583c3d2d-2f9e-11e9-85f4-fa163e429998 0xc42267c777 0xc42267c778}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 13 14:47:58.418: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb 13 14:47:58.418: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-lqv4c,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lqv4c/replicasets/test-recreate-deployment-79f694ff59,UID:583e8e6a-2f9e-11e9-b579-fa163ed32deb,ResourceVersion:2522847,Generation:2,CreationTimestamp:2019-02-13 14:47:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 583c3d2d-2f9e-11e9-85f4-fa163e429998 0xc42267c567 0xc42267c568}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 13 14:47:58.422: INFO: Pod "test-recreate-deployment-7cf749666b-khr9f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-khr9f,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-lqv4c,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lqv4c/pods/test-recreate-deployment-7cf749666b-khr9f,UID:5aa9a6d2-2f9e-11e9-b579-fa163ed32deb,ResourceVersion:2522854,Generation:0,CreationTimestamp:2019-02-13 14:47:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b 5aa8e502-2f9e-11e9-b579-fa163ed32deb 0xc42267d387 0xc42267d388}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-62bk7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-62bk7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-62bk7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cmp3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42267d400} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42267d420}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 14:47:58 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:47:58.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-lqv4c" for this suite.
Feb 13 14:48:04.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:48:04.452: INFO: namespace: e2e-tests-deployment-lqv4c, resource: bindings, ignored listing per whitelist
Feb 13 14:48:04.553: INFO: namespace e2e-tests-deployment-lqv4c deletion completed in 6.126148169s

• [SLOW TEST:10.324 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:48:04.553: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Feb 13 14:48:04.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 create -f - --namespace=e2e-tests-kubectl-lqtks'
Feb 13 14:48:04.865: INFO: stderr: ""
Feb 13 14:48:04.866: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 13 14:48:04.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-lqtks'
Feb 13 14:48:05.023: INFO: stderr: ""
Feb 13 14:48:05.023: INFO: stdout: "update-demo-nautilus-jwpdf update-demo-nautilus-zjwl6 "
Feb 13 14:48:05.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods update-demo-nautilus-jwpdf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lqtks'
Feb 13 14:48:05.139: INFO: stderr: ""
Feb 13 14:48:05.139: INFO: stdout: ""
Feb 13 14:48:05.139: INFO: update-demo-nautilus-jwpdf is created but not running
Feb 13 14:48:10.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-lqtks'
Feb 13 14:48:10.279: INFO: stderr: ""
Feb 13 14:48:10.279: INFO: stdout: "update-demo-nautilus-jwpdf update-demo-nautilus-zjwl6 "
Feb 13 14:48:10.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods update-demo-nautilus-jwpdf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lqtks'
Feb 13 14:48:10.414: INFO: stderr: ""
Feb 13 14:48:10.414: INFO: stdout: "true"
Feb 13 14:48:10.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods update-demo-nautilus-jwpdf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lqtks'
Feb 13 14:48:10.536: INFO: stderr: ""
Feb 13 14:48:10.536: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 13 14:48:10.536: INFO: validating pod update-demo-nautilus-jwpdf
Feb 13 14:48:10.542: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 14:48:10.542: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 14:48:10.542: INFO: update-demo-nautilus-jwpdf is verified up and running
Feb 13 14:48:10.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods update-demo-nautilus-zjwl6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lqtks'
Feb 13 14:48:10.683: INFO: stderr: ""
Feb 13 14:48:10.683: INFO: stdout: "true"
Feb 13 14:48:10.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods update-demo-nautilus-zjwl6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lqtks'
Feb 13 14:48:10.810: INFO: stderr: ""
Feb 13 14:48:10.810: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 13 14:48:10.810: INFO: validating pod update-demo-nautilus-zjwl6
Feb 13 14:48:10.820: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 14:48:10.820: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 14:48:10.820: INFO: update-demo-nautilus-zjwl6 is verified up and running
STEP: rolling-update to new replication controller
Feb 13 14:48:10.822: INFO: scanned /root for discovery docs: <nil>
Feb 13 14:48:10.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-lqtks'
Feb 13 14:48:33.255: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 13 14:48:33.255: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 13 14:48:33.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-lqtks'
Feb 13 14:48:33.362: INFO: stderr: ""
Feb 13 14:48:33.362: INFO: stdout: "update-demo-kitten-85z4h update-demo-kitten-z4rhk update-demo-nautilus-jwpdf "
STEP: Replicas for name=update-demo: expected=2 actual=3
Feb 13 14:48:38.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-lqtks'
Feb 13 14:48:38.482: INFO: stderr: ""
Feb 13 14:48:38.482: INFO: stdout: "update-demo-kitten-85z4h update-demo-kitten-z4rhk "
Feb 13 14:48:38.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods update-demo-kitten-85z4h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lqtks'
Feb 13 14:48:38.617: INFO: stderr: ""
Feb 13 14:48:38.617: INFO: stdout: "true"
Feb 13 14:48:38.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods update-demo-kitten-85z4h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lqtks'
Feb 13 14:48:38.734: INFO: stderr: ""
Feb 13 14:48:38.734: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 13 14:48:38.734: INFO: validating pod update-demo-kitten-85z4h
Feb 13 14:48:38.742: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 13 14:48:38.742: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 13 14:48:38.742: INFO: update-demo-kitten-85z4h is verified up and running
Feb 13 14:48:38.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods update-demo-kitten-z4rhk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lqtks'
Feb 13 14:48:38.862: INFO: stderr: ""
Feb 13 14:48:38.862: INFO: stdout: "true"
Feb 13 14:48:38.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pods update-demo-kitten-z4rhk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lqtks'
Feb 13 14:48:38.978: INFO: stderr: ""
Feb 13 14:48:38.978: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 13 14:48:38.978: INFO: validating pod update-demo-kitten-z4rhk
Feb 13 14:48:38.986: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 13 14:48:38.986: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 13 14:48:38.986: INFO: update-demo-kitten-z4rhk is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:48:38.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lqtks" for this suite.
Feb 13 14:49:01.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:49:01.090: INFO: namespace: e2e-tests-kubectl-lqtks, resource: bindings, ignored listing per whitelist
Feb 13 14:49:01.131: INFO: namespace e2e-tests-kubectl-lqtks deletion completed in 22.139529556s

• [SLOW TEST:56.578 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:49:01.131: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Feb 13 14:49:01.227: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-172602910 proxy --unix-socket=/tmp/kubectl-proxy-unix459841253/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:49:01.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2krm5" for this suite.
Feb 13 14:49:07.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:49:07.400: INFO: namespace: e2e-tests-kubectl-2krm5, resource: bindings, ignored listing per whitelist
Feb 13 14:49:07.467: INFO: namespace e2e-tests-kubectl-2krm5 deletion completed in 6.14089512s

• [SLOW TEST:6.336 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:49:07.468: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 14:49:07.577: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb 13 14:49:07.589: INFO: Number of nodes with available pods: 0
Feb 13 14:49:07.589: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb 13 14:49:07.618: INFO: Number of nodes with available pods: 0
Feb 13 14:49:07.618: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:08.623: INFO: Number of nodes with available pods: 0
Feb 13 14:49:08.623: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:09.622: INFO: Number of nodes with available pods: 0
Feb 13 14:49:09.622: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:10.624: INFO: Number of nodes with available pods: 1
Feb 13 14:49:10.624: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb 13 14:49:10.656: INFO: Number of nodes with available pods: 0
Feb 13 14:49:10.656: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb 13 14:49:10.664: INFO: Number of nodes with available pods: 0
Feb 13 14:49:10.664: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:11.675: INFO: Number of nodes with available pods: 0
Feb 13 14:49:11.675: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:12.670: INFO: Number of nodes with available pods: 0
Feb 13 14:49:12.670: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:13.669: INFO: Number of nodes with available pods: 0
Feb 13 14:49:13.669: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:14.668: INFO: Number of nodes with available pods: 0
Feb 13 14:49:14.668: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:15.668: INFO: Number of nodes with available pods: 0
Feb 13 14:49:15.668: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:16.669: INFO: Number of nodes with available pods: 0
Feb 13 14:49:16.669: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:17.669: INFO: Number of nodes with available pods: 0
Feb 13 14:49:17.669: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:18.669: INFO: Number of nodes with available pods: 0
Feb 13 14:49:18.669: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:19.669: INFO: Number of nodes with available pods: 0
Feb 13 14:49:19.669: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:20.669: INFO: Number of nodes with available pods: 0
Feb 13 14:49:20.669: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:21.670: INFO: Number of nodes with available pods: 0
Feb 13 14:49:21.670: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:22.676: INFO: Number of nodes with available pods: 0
Feb 13 14:49:22.676: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:23.668: INFO: Number of nodes with available pods: 0
Feb 13 14:49:23.669: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:24.669: INFO: Number of nodes with available pods: 0
Feb 13 14:49:24.669: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:25.670: INFO: Number of nodes with available pods: 0
Feb 13 14:49:25.670: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:26.669: INFO: Number of nodes with available pods: 0
Feb 13 14:49:26.669: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:27.669: INFO: Number of nodes with available pods: 0
Feb 13 14:49:27.669: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:28.669: INFO: Number of nodes with available pods: 0
Feb 13 14:49:28.669: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:29.669: INFO: Number of nodes with available pods: 0
Feb 13 14:49:29.669: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:30.669: INFO: Number of nodes with available pods: 0
Feb 13 14:49:30.669: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:31.669: INFO: Number of nodes with available pods: 0
Feb 13 14:49:31.669: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:32.669: INFO: Number of nodes with available pods: 0
Feb 13 14:49:32.669: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:33.681: INFO: Number of nodes with available pods: 0
Feb 13 14:49:33.681: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:34.669: INFO: Number of nodes with available pods: 0
Feb 13 14:49:34.669: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:35.669: INFO: Number of nodes with available pods: 0
Feb 13 14:49:35.669: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:36.668: INFO: Number of nodes with available pods: 0
Feb 13 14:49:36.668: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:37.668: INFO: Number of nodes with available pods: 0
Feb 13 14:49:37.668: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:38.669: INFO: Number of nodes with available pods: 0
Feb 13 14:49:38.669: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:39.668: INFO: Number of nodes with available pods: 0
Feb 13 14:49:39.668: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:40.669: INFO: Number of nodes with available pods: 0
Feb 13 14:49:40.669: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:41.669: INFO: Number of nodes with available pods: 0
Feb 13 14:49:41.669: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:42.669: INFO: Number of nodes with available pods: 0
Feb 13 14:49:42.670: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:43.668: INFO: Number of nodes with available pods: 0
Feb 13 14:49:43.668: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:44.675: INFO: Number of nodes with available pods: 0
Feb 13 14:49:44.675: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:45.668: INFO: Number of nodes with available pods: 0
Feb 13 14:49:45.668: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:46.669: INFO: Number of nodes with available pods: 0
Feb 13 14:49:46.669: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:47.669: INFO: Number of nodes with available pods: 0
Feb 13 14:49:47.669: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:48.668: INFO: Number of nodes with available pods: 0
Feb 13 14:49:48.668: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:49.669: INFO: Number of nodes with available pods: 0
Feb 13 14:49:49.669: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:50.668: INFO: Number of nodes with available pods: 0
Feb 13 14:49:50.668: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:51.669: INFO: Number of nodes with available pods: 0
Feb 13 14:49:51.669: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:52.669: INFO: Number of nodes with available pods: 0
Feb 13 14:49:52.669: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:53.668: INFO: Number of nodes with available pods: 0
Feb 13 14:49:53.669: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:54.668: INFO: Number of nodes with available pods: 0
Feb 13 14:49:54.669: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:55.675: INFO: Number of nodes with available pods: 0
Feb 13 14:49:55.675: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:49:56.669: INFO: Number of nodes with available pods: 1
Feb 13 14:49:56.669: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-cmq5v, will wait for the garbage collector to delete the pods
Feb 13 14:49:56.752: INFO: Deleting {extensions DaemonSet} daemon-set took: 22.553356ms
Feb 13 14:49:56.852: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.249061ms
Feb 13 14:50:30.262: INFO: Number of nodes with available pods: 0
Feb 13 14:50:30.262: INFO: Number of running nodes: 0, number of available pods: 0
Feb 13 14:50:30.265: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-cmq5v/daemonsets","resourceVersion":"2523487"},"items":null}

Feb 13 14:50:30.268: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-cmq5v/pods","resourceVersion":"2523487"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:50:30.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-cmq5v" for this suite.
Feb 13 14:50:36.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:50:36.341: INFO: namespace: e2e-tests-daemonsets-cmq5v, resource: bindings, ignored listing per whitelist
Feb 13 14:50:36.406: INFO: namespace e2e-tests-daemonsets-cmq5v deletion completed in 6.116501608s

• [SLOW TEST:88.939 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:50:36.407: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb 13 14:50:42.539: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wkbgs PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 14:50:42.539: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
Feb 13 14:50:42.718: INFO: Exec stderr: ""
Feb 13 14:50:42.718: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wkbgs PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 14:50:42.718: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
Feb 13 14:50:42.936: INFO: Exec stderr: ""
Feb 13 14:50:42.936: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wkbgs PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 14:50:42.936: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
Feb 13 14:50:43.142: INFO: Exec stderr: ""
Feb 13 14:50:43.142: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wkbgs PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 14:50:43.142: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
Feb 13 14:50:43.325: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb 13 14:50:43.325: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wkbgs PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 14:50:43.325: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
Feb 13 14:50:43.530: INFO: Exec stderr: ""
Feb 13 14:50:43.530: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wkbgs PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 14:50:43.530: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
Feb 13 14:50:43.750: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb 13 14:50:43.750: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wkbgs PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 14:50:43.750: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
Feb 13 14:50:44.085: INFO: Exec stderr: ""
Feb 13 14:50:44.085: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wkbgs PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 14:50:44.085: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
Feb 13 14:50:44.266: INFO: Exec stderr: ""
Feb 13 14:50:44.266: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wkbgs PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 14:50:44.266: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
Feb 13 14:50:44.468: INFO: Exec stderr: ""
Feb 13 14:50:44.469: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wkbgs PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 14:50:44.469: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
Feb 13 14:50:44.649: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:50:44.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-wkbgs" for this suite.
Feb 13 14:51:26.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:51:26.748: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-wkbgs, resource: bindings, ignored listing per whitelist
Feb 13 14:51:26.783: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-wkbgs deletion completed in 42.128369846s

• [SLOW TEST:50.376 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:51:26.783: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Feb 13 14:51:26.888: INFO: Waiting up to 5m0s for pod "client-containers-d6ee2b07-2f9e-11e9-9b61-026654d605e3" in namespace "e2e-tests-containers-lxmlh" to be "success or failure"
Feb 13 14:51:26.891: INFO: Pod "client-containers-d6ee2b07-2f9e-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.894869ms
Feb 13 14:51:28.896: INFO: Pod "client-containers-d6ee2b07-2f9e-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007446765s
Feb 13 14:51:30.900: INFO: Pod "client-containers-d6ee2b07-2f9e-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0118225s
STEP: Saw pod success
Feb 13 14:51:30.900: INFO: Pod "client-containers-d6ee2b07-2f9e-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:51:30.903: INFO: Trying to get logs from node cmp3 pod client-containers-d6ee2b07-2f9e-11e9-9b61-026654d605e3 container test-container: <nil>
STEP: delete the pod
Feb 13 14:51:30.940: INFO: Waiting for pod client-containers-d6ee2b07-2f9e-11e9-9b61-026654d605e3 to disappear
Feb 13 14:51:30.943: INFO: Pod client-containers-d6ee2b07-2f9e-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:51:30.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-lxmlh" for this suite.
Feb 13 14:51:36.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:51:36.986: INFO: namespace: e2e-tests-containers-lxmlh, resource: bindings, ignored listing per whitelist
Feb 13 14:51:37.099: INFO: namespace e2e-tests-containers-lxmlh deletion completed in 6.152019648s

• [SLOW TEST:10.316 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:51:37.100: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 13 14:51:37.201: INFO: Waiting up to 5m0s for pod "pod-dd13e9e7-2f9e-11e9-9b61-026654d605e3" in namespace "e2e-tests-emptydir-f8jjt" to be "success or failure"
Feb 13 14:51:37.205: INFO: Pod "pod-dd13e9e7-2f9e-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.000899ms
Feb 13 14:51:39.210: INFO: Pod "pod-dd13e9e7-2f9e-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008102456s
Feb 13 14:51:41.213: INFO: Pod "pod-dd13e9e7-2f9e-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011940336s
STEP: Saw pod success
Feb 13 14:51:41.213: INFO: Pod "pod-dd13e9e7-2f9e-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:51:41.231: INFO: Trying to get logs from node cmp3 pod pod-dd13e9e7-2f9e-11e9-9b61-026654d605e3 container test-container: <nil>
STEP: delete the pod
Feb 13 14:51:41.261: INFO: Waiting for pod pod-dd13e9e7-2f9e-11e9-9b61-026654d605e3 to disappear
Feb 13 14:51:41.264: INFO: Pod pod-dd13e9e7-2f9e-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:51:41.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-f8jjt" for this suite.
Feb 13 14:51:47.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:51:47.308: INFO: namespace: e2e-tests-emptydir-f8jjt, resource: bindings, ignored listing per whitelist
Feb 13 14:51:47.391: INFO: namespace e2e-tests-emptydir-f8jjt deletion completed in 6.123190375s

• [SLOW TEST:10.291 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:51:47.391: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-e337f71b-2f9e-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume secrets
Feb 13 14:51:47.509: INFO: Waiting up to 5m0s for pod "pod-secrets-e33911ec-2f9e-11e9-9b61-026654d605e3" in namespace "e2e-tests-secrets-zkq9m" to be "success or failure"
Feb 13 14:51:47.512: INFO: Pod "pod-secrets-e33911ec-2f9e-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.905199ms
Feb 13 14:51:49.516: INFO: Pod "pod-secrets-e33911ec-2f9e-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007287704s
Feb 13 14:51:51.520: INFO: Pod "pod-secrets-e33911ec-2f9e-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011635862s
STEP: Saw pod success
Feb 13 14:51:51.520: INFO: Pod "pod-secrets-e33911ec-2f9e-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:51:51.523: INFO: Trying to get logs from node cmp3 pod pod-secrets-e33911ec-2f9e-11e9-9b61-026654d605e3 container secret-volume-test: <nil>
STEP: delete the pod
Feb 13 14:51:51.548: INFO: Waiting for pod pod-secrets-e33911ec-2f9e-11e9-9b61-026654d605e3 to disappear
Feb 13 14:51:51.550: INFO: Pod pod-secrets-e33911ec-2f9e-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:51:51.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-zkq9m" for this suite.
Feb 13 14:51:57.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:51:57.625: INFO: namespace: e2e-tests-secrets-zkq9m, resource: bindings, ignored listing per whitelist
Feb 13 14:51:57.685: INFO: namespace e2e-tests-secrets-zkq9m deletion completed in 6.13043599s

• [SLOW TEST:10.294 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:51:57.686: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Feb 13 14:51:57.785: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 13 14:51:57.793: INFO: Waiting for terminating namespaces to be deleted...
Feb 13 14:51:57.796: INFO: 
Logging pods the kubelet thinks is on node cmp1 before test
Feb 13 14:51:57.803: INFO: netchecker-agent-rgq6k from netchecker started at 2019-02-01 18:30:05 +0000 UTC (1 container statuses recorded)
Feb 13 14:51:57.803: INFO: 	Container netchecker-agent ready: true, restart count 2
Feb 13 14:51:57.803: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-13 13:32:27 +0000 UTC (1 container statuses recorded)
Feb 13 14:51:57.803: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 13 14:51:57.803: INFO: speaker-9ktjr from metallb-system started at 2019-02-01 18:30:05 +0000 UTC (1 container statuses recorded)
Feb 13 14:51:57.803: INFO: 	Container speaker ready: true, restart count 2
Feb 13 14:51:57.803: INFO: kube-flannel-ds-z7czt from kube-system started at 2019-02-01 18:30:05 +0000 UTC (1 container statuses recorded)
Feb 13 14:51:57.803: INFO: 	Container kube-flannel ready: true, restart count 2
Feb 13 14:51:57.803: INFO: sonobuoy-systemd-logs-daemon-set-e9328804e2d54b8e-kmd4p from heptio-sonobuoy started at 2019-02-13 13:32:31 +0000 UTC (2 container statuses recorded)
Feb 13 14:51:57.803: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 13 14:51:57.803: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 13 14:51:57.803: INFO: 
Logging pods the kubelet thinks is on node cmp2 before test
Feb 13 14:51:57.812: INFO: speaker-smqxw from metallb-system started at 2019-02-01 18:30:05 +0000 UTC (1 container statuses recorded)
Feb 13 14:51:57.812: INFO: 	Container speaker ready: true, restart count 1
Feb 13 14:51:57.812: INFO: kube-flannel-ds-pszdm from kube-system started at 2019-02-01 18:30:05 +0000 UTC (1 container statuses recorded)
Feb 13 14:51:57.812: INFO: 	Container kube-flannel ready: true, restart count 1
Feb 13 14:51:57.812: INFO: controller-5755b9ccc-5szmk from metallb-system started at 2019-02-12 00:42:37 +0000 UTC (1 container statuses recorded)
Feb 13 14:51:57.812: INFO: 	Container controller ready: true, restart count 1
Feb 13 14:51:57.812: INFO: sonobuoy-systemd-logs-daemon-set-e9328804e2d54b8e-5qtht from heptio-sonobuoy started at 2019-02-13 13:32:32 +0000 UTC (2 container statuses recorded)
Feb 13 14:51:57.812: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 13 14:51:57.812: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 13 14:51:57.812: INFO: netchecker-agent-m2b92 from netchecker started at 2019-02-01 18:30:05 +0000 UTC (1 container statuses recorded)
Feb 13 14:51:57.812: INFO: 	Container netchecker-agent ready: true, restart count 1
Feb 13 14:51:57.812: INFO: 
Logging pods the kubelet thinks is on node cmp3 before test
Feb 13 14:51:57.828: INFO: netchecker-agent-xghwc from netchecker started at 2019-02-01 18:30:05 +0000 UTC (1 container statuses recorded)
Feb 13 14:51:57.828: INFO: 	Container netchecker-agent ready: true, restart count 2
Feb 13 14:51:57.828: INFO: speaker-zqc6w from metallb-system started at 2019-02-01 18:30:05 +0000 UTC (1 container statuses recorded)
Feb 13 14:51:57.828: INFO: 	Container speaker ready: true, restart count 2
Feb 13 14:51:57.828: INFO: kube-flannel-ds-vxppb from kube-system started at 2019-02-01 18:30:05 +0000 UTC (1 container statuses recorded)
Feb 13 14:51:57.828: INFO: 	Container kube-flannel ready: true, restart count 2
Feb 13 14:51:57.828: INFO: sonobuoy-systemd-logs-daemon-set-e9328804e2d54b8e-9bmpk from heptio-sonobuoy started at 2019-02-13 13:32:31 +0000 UTC (2 container statuses recorded)
Feb 13 14:51:57.828: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 13 14:51:57.828: INFO: 	Container sonobuoy-worker ready: true, restart count 1
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node cmp1
STEP: verifying the node has the label node cmp2
STEP: verifying the node has the label node cmp3
Feb 13 14:51:57.882: INFO: Pod sonobuoy requesting resource cpu=0m on Node cmp1
Feb 13 14:51:57.882: INFO: Pod sonobuoy-systemd-logs-daemon-set-e9328804e2d54b8e-5qtht requesting resource cpu=0m on Node cmp2
Feb 13 14:51:57.882: INFO: Pod sonobuoy-systemd-logs-daemon-set-e9328804e2d54b8e-9bmpk requesting resource cpu=0m on Node cmp3
Feb 13 14:51:57.882: INFO: Pod sonobuoy-systemd-logs-daemon-set-e9328804e2d54b8e-kmd4p requesting resource cpu=0m on Node cmp1
Feb 13 14:51:57.882: INFO: Pod kube-flannel-ds-pszdm requesting resource cpu=100m on Node cmp2
Feb 13 14:51:57.882: INFO: Pod kube-flannel-ds-vxppb requesting resource cpu=100m on Node cmp3
Feb 13 14:51:57.882: INFO: Pod kube-flannel-ds-z7czt requesting resource cpu=100m on Node cmp1
Feb 13 14:51:57.882: INFO: Pod controller-5755b9ccc-5szmk requesting resource cpu=100m on Node cmp2
Feb 13 14:51:57.882: INFO: Pod speaker-9ktjr requesting resource cpu=100m on Node cmp1
Feb 13 14:51:57.882: INFO: Pod speaker-smqxw requesting resource cpu=100m on Node cmp2
Feb 13 14:51:57.882: INFO: Pod speaker-zqc6w requesting resource cpu=100m on Node cmp3
Feb 13 14:51:57.882: INFO: Pod netchecker-agent-m2b92 requesting resource cpu=0m on Node cmp2
Feb 13 14:51:57.882: INFO: Pod netchecker-agent-rgq6k requesting resource cpu=0m on Node cmp1
Feb 13 14:51:57.882: INFO: Pod netchecker-agent-xghwc requesting resource cpu=0m on Node cmp3
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e9690393-2f9e-11e9-9b61-026654d605e3.1582f4038f927f77], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-sc5zr/filler-pod-e9690393-2f9e-11e9-9b61-026654d605e3 to cmp1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e9690393-2f9e-11e9-9b61-026654d605e3.1582f403dd8f3400], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e9690393-2f9e-11e9-9b61-026654d605e3.1582f403e2801d1b], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e9690393-2f9e-11e9-9b61-026654d605e3.1582f403f4031e8a], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e96abe59-2f9e-11e9-9b61-026654d605e3.1582f4038fd7e9d0], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-sc5zr/filler-pod-e96abe59-2f9e-11e9-9b61-026654d605e3 to cmp2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e96abe59-2f9e-11e9-9b61-026654d605e3.1582f403e702473e], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e96abe59-2f9e-11e9-9b61-026654d605e3.1582f403ea16b8e3], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e96abe59-2f9e-11e9-9b61-026654d605e3.1582f403f977960d], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e96b881b-2f9e-11e9-9b61-026654d605e3.1582f4039022f316], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-sc5zr/filler-pod-e96b881b-2f9e-11e9-9b61-026654d605e3 to cmp3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e96b881b-2f9e-11e9-9b61-026654d605e3.1582f403f0795b76], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e96b881b-2f9e-11e9-9b61-026654d605e3.1582f403f90d887a], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e96b881b-2f9e-11e9-9b61-026654d605e3.1582f4040a7c4c87], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1582f4047ff4209c], Reason = [FailedScheduling], Message = [0/6 nodes are available: 3 Insufficient cpu, 3 node(s) had taints that the pod didn't tolerate.]
STEP: removing the label node off the node cmp3
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node cmp1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node cmp2
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:52:02.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-sc5zr" for this suite.
Feb 13 14:52:09.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:52:09.100: INFO: namespace: e2e-tests-sched-pred-sc5zr, resource: bindings, ignored listing per whitelist
Feb 13 14:52:09.115: INFO: namespace e2e-tests-sched-pred-sc5zr deletion completed in 6.137763758s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:11.430 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:52:09.115: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Feb 13 14:52:09.229: INFO: Waiting up to 5m0s for pod "var-expansion-f02adff5-2f9e-11e9-9b61-026654d605e3" in namespace "e2e-tests-var-expansion-c28j6" to be "success or failure"
Feb 13 14:52:09.236: INFO: Pod "var-expansion-f02adff5-2f9e-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.520018ms
Feb 13 14:52:11.241: INFO: Pod "var-expansion-f02adff5-2f9e-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011510596s
Feb 13 14:52:13.244: INFO: Pod "var-expansion-f02adff5-2f9e-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015178635s
STEP: Saw pod success
Feb 13 14:52:13.244: INFO: Pod "var-expansion-f02adff5-2f9e-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:52:13.248: INFO: Trying to get logs from node cmp3 pod var-expansion-f02adff5-2f9e-11e9-9b61-026654d605e3 container dapi-container: <nil>
STEP: delete the pod
Feb 13 14:52:13.272: INFO: Waiting for pod var-expansion-f02adff5-2f9e-11e9-9b61-026654d605e3 to disappear
Feb 13 14:52:13.275: INFO: Pod var-expansion-f02adff5-2f9e-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:52:13.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-c28j6" for this suite.
Feb 13 14:52:19.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:52:19.325: INFO: namespace: e2e-tests-var-expansion-c28j6, resource: bindings, ignored listing per whitelist
Feb 13 14:52:19.405: INFO: namespace e2e-tests-var-expansion-c28j6 deletion completed in 6.126318098s

• [SLOW TEST:10.290 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:52:19.406: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-wlntp
Feb 13 14:52:23.513: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-wlntp
STEP: checking the pod's current state and verifying that restartCount is present
Feb 13 14:52:23.516: INFO: Initial restart count of pod liveness-exec is 0
Feb 13 14:53:13.664: INFO: Restart count of pod e2e-tests-container-probe-wlntp/liveness-exec is now 1 (50.148115962s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:53:13.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-wlntp" for this suite.
Feb 13 14:53:19.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:53:19.810: INFO: namespace: e2e-tests-container-probe-wlntp, resource: bindings, ignored listing per whitelist
Feb 13 14:53:19.824: INFO: namespace e2e-tests-container-probe-wlntp deletion completed in 6.138197952s

• [SLOW TEST:60.418 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:53:19.824: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 14:53:19.931: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb 13 14:53:19.944: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:19.944: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:19.944: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:19.947: INFO: Number of nodes with available pods: 0
Feb 13 14:53:19.947: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:53:20.954: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:20.954: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:20.954: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:20.958: INFO: Number of nodes with available pods: 0
Feb 13 14:53:20.958: INFO: Node cmp1 is running more than one daemon pod
Feb 13 14:53:21.954: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:21.954: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:21.954: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:21.958: INFO: Number of nodes with available pods: 1
Feb 13 14:53:21.958: INFO: Node cmp2 is running more than one daemon pod
Feb 13 14:53:22.954: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:22.954: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:22.954: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:22.958: INFO: Number of nodes with available pods: 2
Feb 13 14:53:22.958: INFO: Node cmp3 is running more than one daemon pod
Feb 13 14:53:23.954: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:23.954: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:23.954: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:23.958: INFO: Number of nodes with available pods: 3
Feb 13 14:53:23.958: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb 13 14:53:23.984: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:23.984: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:23.984: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:23.988: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:23.988: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:23.988: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:25.002: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:25.002: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:25.002: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:25.006: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:25.006: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:25.006: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:25.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:25.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:25.993: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:25.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:25.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:25.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:26.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:26.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:26.993: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:26.999: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:26.999: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:26.999: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:27.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:27.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:27.993: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:27.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:27.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:27.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:29.003: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:29.003: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:29.003: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:29.009: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:29.009: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:29.009: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:29.999: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:29.999: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:29.999: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:30.004: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:30.004: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:30.004: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:30.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:30.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:30.993: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:30.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:30.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:30.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:31.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:31.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:31.993: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:31.999: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:31.999: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:31.999: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:33.008: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:33.008: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:33.008: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:33.013: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:33.013: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:33.013: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:33.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:33.992: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:33.992: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:33.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:33.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:33.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:34.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:34.992: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:34.992: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:34.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:34.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:34.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:35.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:35.992: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:35.992: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:35.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:35.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:35.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:36.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:36.992: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:36.992: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:37.010: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:37.010: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:37.010: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:37.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:37.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:37.993: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:37.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:37.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:37.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:38.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:38.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:38.994: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:38.999: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:38.999: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:38.999: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:39.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:39.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:39.993: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:39.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:39.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:39.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:41.005: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:41.005: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:41.005: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:41.009: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:41.009: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:41.009: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:41.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:41.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:41.993: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:41.999: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:41.999: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:41.999: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:42.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:42.992: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:42.992: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:42.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:42.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:42.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:43.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:43.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:43.993: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:44.000: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:44.000: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:44.000: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:44.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:44.992: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:44.992: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:44.996: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:44.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:44.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:45.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:45.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:45.993: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:45.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:45.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:45.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:46.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:46.992: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:46.992: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:46.996: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:46.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:46.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:47.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:47.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:47.993: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:47.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:47.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:47.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:49.002: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:49.002: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:49.002: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:49.007: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:49.007: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:49.007: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:49.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:49.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:49.993: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:49.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:49.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:49.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:50.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:50.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:50.993: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:50.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:50.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:50.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:51.999: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:51.999: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:51.999: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:52.003: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:52.003: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:52.003: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:53.006: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:53.006: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:53.006: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:53.011: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:53.011: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:53.011: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:53.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:53.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:53.993: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:53.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:53.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:53.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:54.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:54.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:54.993: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:54.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:54.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:54.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:55.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:55.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:55.993: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:55.993: INFO: Pod daemon-set-ldjdm is not available
Feb 13 14:53:56.005: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:56.005: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:56.005: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:57.006: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:57.006: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:57.006: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:57.006: INFO: Pod daemon-set-ldjdm is not available
Feb 13 14:53:57.010: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:57.010: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:57.010: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:57.994: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:57.994: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:57.994: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:57.994: INFO: Pod daemon-set-ldjdm is not available
Feb 13 14:53:57.999: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:57.999: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:57.999: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:58.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:58.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:58.993: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:58.993: INFO: Pod daemon-set-ldjdm is not available
Feb 13 14:53:58.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:58.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:58.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:59.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:59.992: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:59.993: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:53:59.993: INFO: Pod daemon-set-ldjdm is not available
Feb 13 14:53:59.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:59.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:53:59.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:01.007: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:01.007: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:01.007: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:01.007: INFO: Pod daemon-set-ldjdm is not available
Feb 13 14:54:01.011: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:01.011: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:01.011: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:01.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:01.992: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:01.992: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:01.992: INFO: Pod daemon-set-ldjdm is not available
Feb 13 14:54:01.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:01.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:01.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:02.998: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:02.998: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:02.998: INFO: Wrong image for pod: daemon-set-ldjdm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:02.998: INFO: Pod daemon-set-ldjdm is not available
Feb 13 14:54:03.002: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:03.002: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:03.002: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:03.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:03.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:03.993: INFO: Pod daemon-set-gtnmb is not available
Feb 13 14:54:03.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:03.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:03.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:05.002: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:05.002: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:05.002: INFO: Pod daemon-set-gtnmb is not available
Feb 13 14:54:05.007: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:05.007: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:05.007: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:05.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:05.992: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:05.992: INFO: Pod daemon-set-gtnmb is not available
Feb 13 14:54:05.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:05.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:05.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:06.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:06.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:06.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:06.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:06.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:07.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:07.992: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:07.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:07.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:07.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:09.007: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:09.007: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:09.011: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:09.011: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:09.011: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:09.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:09.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:09.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:09.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:09.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:10.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:10.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:10.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:10.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:10.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:11.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:11.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:11.999: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:11.999: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:12.000: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:13.002: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:13.002: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:13.013: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:13.013: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:13.013: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:13.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:13.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:13.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:13.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:13.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:14.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:14.992: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:14.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:14.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:14.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:15.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:15.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:15.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:15.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:15.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:17.006: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:17.006: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:17.011: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:17.011: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:17.011: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:17.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:17.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:17.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:17.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:17.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:18.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:18.992: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:18.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:18.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:18.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:19.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:19.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:19.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:19.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:19.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:21.003: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:21.003: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:21.007: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:21.007: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:21.007: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:21.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:21.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:21.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:21.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:21.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:22.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:22.992: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:22.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:22.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:22.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:23.998: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:23.998: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:24.003: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:24.003: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:24.003: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:25.001: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:25.002: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:25.006: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:25.006: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:25.006: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:25.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:25.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:25.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:25.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:25.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:26.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:26.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:26.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:26.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:26.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:27.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:27.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:27.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:27.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:27.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:29.006: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:29.006: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:29.011: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:29.011: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:29.011: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:29.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:29.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:29.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:29.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:29.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:30.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:30.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:30.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:30.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:30.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:31.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:31.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:31.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:31.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:31.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:32.996: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:32.996: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:33.001: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:33.001: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:33.001: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:33.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:33.992: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:33.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:33.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:33.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:34.998: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:34.998: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:35.003: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:35.003: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:35.003: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:35.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:35.992: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:35.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:35.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:35.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:36.996: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:36.996: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:37.000: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:37.000: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:37.000: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:37.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:37.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:37.993: INFO: Pod daemon-set-884nv is not available
Feb 13 14:54:37.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:37.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:37.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:38.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:38.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:38.993: INFO: Pod daemon-set-884nv is not available
Feb 13 14:54:38.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:38.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:38.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:39.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:39.993: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:39.993: INFO: Pod daemon-set-884nv is not available
Feb 13 14:54:39.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:39.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:39.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:41.004: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:41.004: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:41.004: INFO: Pod daemon-set-884nv is not available
Feb 13 14:54:41.008: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:41.008: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:41.008: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:41.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:41.992: INFO: Wrong image for pod: daemon-set-884nv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:41.992: INFO: Pod daemon-set-884nv is not available
Feb 13 14:54:41.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:41.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:41.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:42.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:42.993: INFO: Pod daemon-set-bjvzn is not available
Feb 13 14:54:42.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:42.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:42.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:43.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:43.993: INFO: Pod daemon-set-bjvzn is not available
Feb 13 14:54:43.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:43.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:43.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:45.007: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:45.016: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:45.016: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:45.016: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:45.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:45.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:45.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:45.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:46.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:46.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:46.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:46.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:47.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:47.996: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:47.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:47.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:48.995: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:49.016: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:49.016: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:49.016: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:49.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:49.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:49.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:49.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:50.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:50.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:50.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:50.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:51.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:51.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:51.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:51.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:53.006: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:53.011: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:53.011: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:53.011: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:53.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:53.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:53.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:53.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:54.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:54.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:54.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:54.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:55.999: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:56.004: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:56.004: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:56.004: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:57.006: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:57.011: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:57.011: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:57.011: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:57.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:57.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:57.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:57.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:58.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:58.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:58.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:58.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:59.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:54:59.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:59.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:54:59.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:01.007: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:55:01.012: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:01.012: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:01.012: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:01.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:55:01.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:01.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:01.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:02.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:55:02.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:02.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:02.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:03.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:55:03.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:03.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:03.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:05.003: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:55:05.007: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:05.007: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:05.007: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:05.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:55:05.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:05.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:05.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:06.999: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:55:07.004: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:07.004: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:07.004: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:07.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:55:07.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:07.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:07.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:09.006: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:55:09.010: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:09.010: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:09.010: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:09.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:55:10.000: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:10.000: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:10.000: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:10.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:55:10.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:10.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:10.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:11.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:55:11.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:11.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:11.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:13.006: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:55:13.011: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:13.011: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:13.011: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:13.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:55:13.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:13.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:13.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:14.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:55:14.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:14.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:14.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:15.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:55:15.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:15.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:15.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:17.006: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:55:17.019: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:17.019: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:17.019: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:17.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:55:17.993: INFO: Pod daemon-set-6j7mj is not available
Feb 13 14:55:17.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:17.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:17.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:18.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:55:18.992: INFO: Pod daemon-set-6j7mj is not available
Feb 13 14:55:18.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:18.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:18.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:19.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:55:19.992: INFO: Pod daemon-set-6j7mj is not available
Feb 13 14:55:19.996: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:19.996: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:19.996: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:20.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:55:20.992: INFO: Pod daemon-set-6j7mj is not available
Feb 13 14:55:21.003: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:21.003: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:21.003: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:21.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:55:21.992: INFO: Pod daemon-set-6j7mj is not available
Feb 13 14:55:21.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:21.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:21.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:22.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:55:22.993: INFO: Pod daemon-set-6j7mj is not available
Feb 13 14:55:22.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:22.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:22.997: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:23.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:55:23.993: INFO: Pod daemon-set-6j7mj is not available
Feb 13 14:55:23.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:23.998: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:23.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:25.007: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:55:25.007: INFO: Pod daemon-set-6j7mj is not available
Feb 13 14:55:25.011: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:25.011: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:25.011: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:25.993: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:55:25.993: INFO: Pod daemon-set-6j7mj is not available
Feb 13 14:55:25.998: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:25.999: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:25.999: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:26.992: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:55:26.992: INFO: Pod daemon-set-6j7mj is not available
Feb 13 14:55:26.997: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:26.997: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:26.998: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:27.999: INFO: Wrong image for pod: daemon-set-6j7mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 14:55:27.999: INFO: Pod daemon-set-6j7mj is not available
Feb 13 14:55:28.004: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:28.004: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:28.004: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:28.992: INFO: Pod daemon-set-9r5jt is not available
Feb 13 14:55:29.011: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:29.011: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:29.011: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Feb 13 14:55:29.016: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:29.016: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:29.016: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:29.021: INFO: Number of nodes with available pods: 2
Feb 13 14:55:29.021: INFO: Node cmp3 is running more than one daemon pod
Feb 13 14:55:30.026: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:30.027: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:30.027: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:30.030: INFO: Number of nodes with available pods: 2
Feb 13 14:55:30.030: INFO: Node cmp3 is running more than one daemon pod
Feb 13 14:55:31.027: INFO: DaemonSet pods can't tolerate node ctl01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:31.027: INFO: DaemonSet pods can't tolerate node ctl02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:31.027: INFO: DaemonSet pods can't tolerate node ctl03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 14:55:31.030: INFO: Number of nodes with available pods: 3
Feb 13 14:55:31.030: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-glpgs, will wait for the garbage collector to delete the pods
Feb 13 14:55:31.107: INFO: Deleting {extensions DaemonSet} daemon-set took: 7.437105ms
Feb 13 14:55:31.207: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.347684ms
Feb 13 14:55:43.818: INFO: Number of nodes with available pods: 0
Feb 13 14:55:43.818: INFO: Number of running nodes: 0, number of available pods: 0
Feb 13 14:55:43.822: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-glpgs/daemonsets","resourceVersion":"2524717"},"items":null}

Feb 13 14:55:43.825: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-glpgs/pods","resourceVersion":"2524717"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:55:43.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-glpgs" for this suite.
Feb 13 14:55:49.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:55:49.887: INFO: namespace: e2e-tests-daemonsets-glpgs, resource: bindings, ignored listing per whitelist
Feb 13 14:55:49.969: INFO: namespace e2e-tests-daemonsets-glpgs deletion completed in 6.122934336s

• [SLOW TEST:150.145 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:55:49.969: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 14:55:50.068: INFO: Waiting up to 5m0s for pod "downwardapi-volume-73cc3917-2f9f-11e9-9b61-026654d605e3" in namespace "e2e-tests-downward-api-s927v" to be "success or failure"
Feb 13 14:55:50.071: INFO: Pod "downwardapi-volume-73cc3917-2f9f-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.084972ms
Feb 13 14:55:52.076: INFO: Pod "downwardapi-volume-73cc3917-2f9f-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007568616s
Feb 13 14:55:54.087: INFO: Pod "downwardapi-volume-73cc3917-2f9f-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018743589s
STEP: Saw pod success
Feb 13 14:55:54.087: INFO: Pod "downwardapi-volume-73cc3917-2f9f-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:55:54.090: INFO: Trying to get logs from node cmp2 pod downwardapi-volume-73cc3917-2f9f-11e9-9b61-026654d605e3 container client-container: <nil>
STEP: delete the pod
Feb 13 14:55:54.114: INFO: Waiting for pod downwardapi-volume-73cc3917-2f9f-11e9-9b61-026654d605e3 to disappear
Feb 13 14:55:54.117: INFO: Pod downwardapi-volume-73cc3917-2f9f-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:55:54.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-s927v" for this suite.
Feb 13 14:56:00.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:56:00.220: INFO: namespace: e2e-tests-downward-api-s927v, resource: bindings, ignored listing per whitelist
Feb 13 14:56:00.243: INFO: namespace e2e-tests-downward-api-s927v deletion completed in 6.12194674s

• [SLOW TEST:10.274 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:56:00.244: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 13 14:56:00.348: INFO: Waiting up to 5m0s for pod "pod-79ecb5eb-2f9f-11e9-9b61-026654d605e3" in namespace "e2e-tests-emptydir-f9m25" to be "success or failure"
Feb 13 14:56:00.351: INFO: Pod "pod-79ecb5eb-2f9f-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.69575ms
Feb 13 14:56:02.356: INFO: Pod "pod-79ecb5eb-2f9f-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007781754s
Feb 13 14:56:04.372: INFO: Pod "pod-79ecb5eb-2f9f-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023725808s
STEP: Saw pod success
Feb 13 14:56:04.372: INFO: Pod "pod-79ecb5eb-2f9f-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:56:04.375: INFO: Trying to get logs from node cmp3 pod pod-79ecb5eb-2f9f-11e9-9b61-026654d605e3 container test-container: <nil>
STEP: delete the pod
Feb 13 14:56:04.394: INFO: Waiting for pod pod-79ecb5eb-2f9f-11e9-9b61-026654d605e3 to disappear
Feb 13 14:56:04.406: INFO: Pod pod-79ecb5eb-2f9f-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:56:04.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-f9m25" for this suite.
Feb 13 14:56:10.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:56:10.454: INFO: namespace: e2e-tests-emptydir-f9m25, resource: bindings, ignored listing per whitelist
Feb 13 14:56:10.535: INFO: namespace e2e-tests-emptydir-f9m25 deletion completed in 6.124932722s

• [SLOW TEST:10.291 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:56:10.536: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-m9vnw
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-m9vnw to expose endpoints map[]
Feb 13 14:56:10.644: INFO: Get endpoints failed (2.937099ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Feb 13 14:56:11.648: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-m9vnw exposes endpoints map[] (1.006851145s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-m9vnw
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-m9vnw to expose endpoints map[pod1:[100]]
Feb 13 14:56:14.690: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-m9vnw exposes endpoints map[pod1:[100]] (3.032859708s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-m9vnw
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-m9vnw to expose endpoints map[pod1:[100] pod2:[101]]
Feb 13 14:56:17.737: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-m9vnw exposes endpoints map[pod1:[100] pod2:[101]] (3.042076315s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-m9vnw
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-m9vnw to expose endpoints map[pod2:[101]]
Feb 13 14:56:18.759: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-m9vnw exposes endpoints map[pod2:[101]] (1.015069012s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-m9vnw
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-m9vnw to expose endpoints map[]
Feb 13 14:56:19.772: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-m9vnw exposes endpoints map[] (1.005973332s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:56:19.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-m9vnw" for this suite.
Feb 13 14:56:41.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:56:41.931: INFO: namespace: e2e-tests-services-m9vnw, resource: bindings, ignored listing per whitelist
Feb 13 14:56:41.939: INFO: namespace e2e-tests-services-m9vnw deletion completed in 22.142527926s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:31.404 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:56:41.940: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Feb 13 14:56:42.041: INFO: Waiting up to 5m0s for pod "pod-92c69ec9-2f9f-11e9-9b61-026654d605e3" in namespace "e2e-tests-emptydir-85vqf" to be "success or failure"
Feb 13 14:56:42.044: INFO: Pod "pod-92c69ec9-2f9f-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.36513ms
Feb 13 14:56:44.048: INFO: Pod "pod-92c69ec9-2f9f-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007843077s
Feb 13 14:56:46.053: INFO: Pod "pod-92c69ec9-2f9f-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012569866s
STEP: Saw pod success
Feb 13 14:56:46.053: INFO: Pod "pod-92c69ec9-2f9f-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:56:46.056: INFO: Trying to get logs from node cmp3 pod pod-92c69ec9-2f9f-11e9-9b61-026654d605e3 container test-container: <nil>
STEP: delete the pod
Feb 13 14:56:46.079: INFO: Waiting for pod pod-92c69ec9-2f9f-11e9-9b61-026654d605e3 to disappear
Feb 13 14:56:46.082: INFO: Pod pod-92c69ec9-2f9f-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:56:46.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-85vqf" for this suite.
Feb 13 14:56:52.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:56:52.107: INFO: namespace: e2e-tests-emptydir-85vqf, resource: bindings, ignored listing per whitelist
Feb 13 14:56:52.205: INFO: namespace e2e-tests-emptydir-85vqf deletion completed in 6.117328223s

• [SLOW TEST:10.265 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:56:52.205: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-z4zm7.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-z4zm7.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-z4zm7.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-z4zm7.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-z4zm7.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-z4zm7.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 13 14:57:06.414: INFO: DNS probes using e2e-tests-dns-z4zm7/dns-test-98e521d1-2f9f-11e9-9b61-026654d605e3 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:57:06.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-z4zm7" for this suite.
Feb 13 14:57:12.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:57:12.564: INFO: namespace: e2e-tests-dns-z4zm7, resource: bindings, ignored listing per whitelist
Feb 13 14:57:12.567: INFO: namespace e2e-tests-dns-z4zm7 deletion completed in 6.13718551s

• [SLOW TEST:20.362 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:57:12.567: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Feb 13 14:57:12.686: INFO: Waiting up to 5m0s for pod "client-containers-a50a5e33-2f9f-11e9-9b61-026654d605e3" in namespace "e2e-tests-containers-pzrrs" to be "success or failure"
Feb 13 14:57:12.690: INFO: Pod "client-containers-a50a5e33-2f9f-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.393833ms
Feb 13 14:57:14.694: INFO: Pod "client-containers-a50a5e33-2f9f-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007382831s
Feb 13 14:57:16.704: INFO: Pod "client-containers-a50a5e33-2f9f-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017744742s
STEP: Saw pod success
Feb 13 14:57:16.704: INFO: Pod "client-containers-a50a5e33-2f9f-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:57:16.707: INFO: Trying to get logs from node cmp3 pod client-containers-a50a5e33-2f9f-11e9-9b61-026654d605e3 container test-container: <nil>
STEP: delete the pod
Feb 13 14:57:16.734: INFO: Waiting for pod client-containers-a50a5e33-2f9f-11e9-9b61-026654d605e3 to disappear
Feb 13 14:57:16.737: INFO: Pod client-containers-a50a5e33-2f9f-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:57:16.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-pzrrs" for this suite.
Feb 13 14:57:22.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:57:22.777: INFO: namespace: e2e-tests-containers-pzrrs, resource: bindings, ignored listing per whitelist
Feb 13 14:57:22.865: INFO: namespace e2e-tests-containers-pzrrs deletion completed in 6.123273501s

• [SLOW TEST:10.298 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:57:22.867: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Feb 13 14:57:23.475: INFO: Waiting up to 5m0s for pod "pod-service-account-ab79057f-2f9f-11e9-9b61-026654d605e3-vddp9" in namespace "e2e-tests-svcaccounts-8swwh" to be "success or failure"
Feb 13 14:57:23.478: INFO: Pod "pod-service-account-ab79057f-2f9f-11e9-9b61-026654d605e3-vddp9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.034719ms
Feb 13 14:57:25.483: INFO: Pod "pod-service-account-ab79057f-2f9f-11e9-9b61-026654d605e3-vddp9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007710099s
Feb 13 14:57:27.495: INFO: Pod "pod-service-account-ab79057f-2f9f-11e9-9b61-026654d605e3-vddp9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019415004s
STEP: Saw pod success
Feb 13 14:57:27.495: INFO: Pod "pod-service-account-ab79057f-2f9f-11e9-9b61-026654d605e3-vddp9" satisfied condition "success or failure"
Feb 13 14:57:27.498: INFO: Trying to get logs from node cmp3 pod pod-service-account-ab79057f-2f9f-11e9-9b61-026654d605e3-vddp9 container token-test: <nil>
STEP: delete the pod
Feb 13 14:57:27.527: INFO: Waiting for pod pod-service-account-ab79057f-2f9f-11e9-9b61-026654d605e3-vddp9 to disappear
Feb 13 14:57:27.530: INFO: Pod pod-service-account-ab79057f-2f9f-11e9-9b61-026654d605e3-vddp9 no longer exists
STEP: Creating a pod to test consume service account root CA
Feb 13 14:57:27.535: INFO: Waiting up to 5m0s for pod "pod-service-account-ab79057f-2f9f-11e9-9b61-026654d605e3-4lvw5" in namespace "e2e-tests-svcaccounts-8swwh" to be "success or failure"
Feb 13 14:57:27.538: INFO: Pod "pod-service-account-ab79057f-2f9f-11e9-9b61-026654d605e3-4lvw5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.109822ms
Feb 13 14:57:29.542: INFO: Pod "pod-service-account-ab79057f-2f9f-11e9-9b61-026654d605e3-4lvw5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007232062s
Feb 13 14:57:31.546: INFO: Pod "pod-service-account-ab79057f-2f9f-11e9-9b61-026654d605e3-4lvw5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01128654s
STEP: Saw pod success
Feb 13 14:57:31.546: INFO: Pod "pod-service-account-ab79057f-2f9f-11e9-9b61-026654d605e3-4lvw5" satisfied condition "success or failure"
Feb 13 14:57:31.550: INFO: Trying to get logs from node cmp3 pod pod-service-account-ab79057f-2f9f-11e9-9b61-026654d605e3-4lvw5 container root-ca-test: <nil>
STEP: delete the pod
Feb 13 14:57:31.580: INFO: Waiting for pod pod-service-account-ab79057f-2f9f-11e9-9b61-026654d605e3-4lvw5 to disappear
Feb 13 14:57:31.583: INFO: Pod pod-service-account-ab79057f-2f9f-11e9-9b61-026654d605e3-4lvw5 no longer exists
STEP: Creating a pod to test consume service account namespace
Feb 13 14:57:31.588: INFO: Waiting up to 5m0s for pod "pod-service-account-ab79057f-2f9f-11e9-9b61-026654d605e3-7bghj" in namespace "e2e-tests-svcaccounts-8swwh" to be "success or failure"
Feb 13 14:57:31.592: INFO: Pod "pod-service-account-ab79057f-2f9f-11e9-9b61-026654d605e3-7bghj": Phase="Pending", Reason="", readiness=false. Elapsed: 3.615619ms
Feb 13 14:57:33.597: INFO: Pod "pod-service-account-ab79057f-2f9f-11e9-9b61-026654d605e3-7bghj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008407743s
Feb 13 14:57:35.601: INFO: Pod "pod-service-account-ab79057f-2f9f-11e9-9b61-026654d605e3-7bghj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012475956s
STEP: Saw pod success
Feb 13 14:57:35.601: INFO: Pod "pod-service-account-ab79057f-2f9f-11e9-9b61-026654d605e3-7bghj" satisfied condition "success or failure"
Feb 13 14:57:35.604: INFO: Trying to get logs from node cmp3 pod pod-service-account-ab79057f-2f9f-11e9-9b61-026654d605e3-7bghj container namespace-test: <nil>
STEP: delete the pod
Feb 13 14:57:35.656: INFO: Waiting for pod pod-service-account-ab79057f-2f9f-11e9-9b61-026654d605e3-7bghj to disappear
Feb 13 14:57:35.660: INFO: Pod pod-service-account-ab79057f-2f9f-11e9-9b61-026654d605e3-7bghj no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:57:35.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-8swwh" for this suite.
Feb 13 14:57:41.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:57:41.778: INFO: namespace: e2e-tests-svcaccounts-8swwh, resource: bindings, ignored listing per whitelist
Feb 13 14:57:41.783: INFO: namespace e2e-tests-svcaccounts-8swwh deletion completed in 6.118436497s

• [SLOW TEST:18.916 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:57:41.783: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 14:57:41.890: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b672f746-2f9f-11e9-9b61-026654d605e3" in namespace "e2e-tests-downward-api-g4s5g" to be "success or failure"
Feb 13 14:57:41.893: INFO: Pod "downwardapi-volume-b672f746-2f9f-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.860421ms
Feb 13 14:57:43.898: INFO: Pod "downwardapi-volume-b672f746-2f9f-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008313034s
Feb 13 14:57:45.903: INFO: Pod "downwardapi-volume-b672f746-2f9f-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012790145s
STEP: Saw pod success
Feb 13 14:57:45.903: INFO: Pod "downwardapi-volume-b672f746-2f9f-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 14:57:45.906: INFO: Trying to get logs from node cmp3 pod downwardapi-volume-b672f746-2f9f-11e9-9b61-026654d605e3 container client-container: <nil>
STEP: delete the pod
Feb 13 14:57:45.926: INFO: Waiting for pod downwardapi-volume-b672f746-2f9f-11e9-9b61-026654d605e3 to disappear
Feb 13 14:57:45.929: INFO: Pod downwardapi-volume-b672f746-2f9f-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 14:57:45.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-g4s5g" for this suite.
Feb 13 14:57:51.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 14:57:52.018: INFO: namespace: e2e-tests-downward-api-g4s5g, resource: bindings, ignored listing per whitelist
Feb 13 14:57:52.060: INFO: namespace e2e-tests-downward-api-g4s5g deletion completed in 6.125932731s

• [SLOW TEST:10.277 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 14:57:52.060: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-d9hjk
Feb 13 14:57:54.169: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-d9hjk
STEP: checking the pod's current state and verifying that restartCount is present
Feb 13 14:57:54.172: INFO: Initial restart count of pod liveness-http is 0
Feb 13 14:58:12.226: INFO: Restart count of pod e2e-tests-container-probe-d9hjk/liveness-http is now 1 (18.053597607s elapsed)
Feb 13 14:58:32.282: INFO: Restart count of pod e2e-tests-container-probe-d9hjk/liveness-http is now 2 (38.109895253s elapsed)
Feb 13 14:58:54.341: INFO: Restart count of pod e2e-tests-container-probe-d9hjk/liveness-http is now 3 (1m0.168380738s elapsed)
Feb 13 14:59:12.400: INFO: Restart count of pod e2e-tests-container-probe-d9hjk/liveness-http is now 4 (1m18.227036881s elapsed)
Feb 13 15:00:14.602: INFO: Restart count of pod e2e-tests-container-probe-d9hjk/liveness-http is now 5 (2m20.429137424s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 15:00:14.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-d9hjk" for this suite.
Feb 13 15:00:20.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 15:00:20.710: INFO: namespace: e2e-tests-container-probe-d9hjk, resource: bindings, ignored listing per whitelist
Feb 13 15:00:20.744: INFO: namespace e2e-tests-container-probe-d9hjk deletion completed in 6.12561774s

• [SLOW TEST:148.685 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 15:00:20.745: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb 13 15:00:20.868: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-2kmvg,SelfLink:/api/v1/namespaces/e2e-tests-watch-2kmvg/configmaps/e2e-watch-test-label-changed,UID:15334697-2fa0-11e9-85f4-fa163e429998,ResourceVersion:2525870,Generation:0,CreationTimestamp:2019-02-13 15:00:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 13 15:00:20.868: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-2kmvg,SelfLink:/api/v1/namespaces/e2e-tests-watch-2kmvg/configmaps/e2e-watch-test-label-changed,UID:15334697-2fa0-11e9-85f4-fa163e429998,ResourceVersion:2525871,Generation:0,CreationTimestamp:2019-02-13 15:00:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 13 15:00:20.868: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-2kmvg,SelfLink:/api/v1/namespaces/e2e-tests-watch-2kmvg/configmaps/e2e-watch-test-label-changed,UID:15334697-2fa0-11e9-85f4-fa163e429998,ResourceVersion:2525872,Generation:0,CreationTimestamp:2019-02-13 15:00:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb 13 15:00:30.906: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-2kmvg,SelfLink:/api/v1/namespaces/e2e-tests-watch-2kmvg/configmaps/e2e-watch-test-label-changed,UID:15334697-2fa0-11e9-85f4-fa163e429998,ResourceVersion:2525898,Generation:0,CreationTimestamp:2019-02-13 15:00:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 13 15:00:30.907: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-2kmvg,SelfLink:/api/v1/namespaces/e2e-tests-watch-2kmvg/configmaps/e2e-watch-test-label-changed,UID:15334697-2fa0-11e9-85f4-fa163e429998,ResourceVersion:2525899,Generation:0,CreationTimestamp:2019-02-13 15:00:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb 13 15:00:30.907: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-2kmvg,SelfLink:/api/v1/namespaces/e2e-tests-watch-2kmvg/configmaps/e2e-watch-test-label-changed,UID:15334697-2fa0-11e9-85f4-fa163e429998,ResourceVersion:2525900,Generation:0,CreationTimestamp:2019-02-13 15:00:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 15:00:30.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-2kmvg" for this suite.
Feb 13 15:00:36.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 15:00:36.965: INFO: namespace: e2e-tests-watch-2kmvg, resource: bindings, ignored listing per whitelist
Feb 13 15:00:37.060: INFO: namespace e2e-tests-watch-2kmvg deletion completed in 6.146384613s

• [SLOW TEST:16.315 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 15:00:37.061: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-p99c
STEP: Creating a pod to test atomic-volume-subpath
Feb 13 15:00:37.172: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-p99c" in namespace "e2e-tests-subpath-q5cp9" to be "success or failure"
Feb 13 15:00:37.176: INFO: Pod "pod-subpath-test-projected-p99c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.103148ms
Feb 13 15:00:39.180: INFO: Pod "pod-subpath-test-projected-p99c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007271846s
Feb 13 15:00:41.190: INFO: Pod "pod-subpath-test-projected-p99c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017685466s
Feb 13 15:00:43.195: INFO: Pod "pod-subpath-test-projected-p99c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.022140397s
Feb 13 15:00:45.198: INFO: Pod "pod-subpath-test-projected-p99c": Phase="Running", Reason="", readiness=false. Elapsed: 8.026011247s
Feb 13 15:00:47.203: INFO: Pod "pod-subpath-test-projected-p99c": Phase="Running", Reason="", readiness=false. Elapsed: 10.030508374s
Feb 13 15:00:49.207: INFO: Pod "pod-subpath-test-projected-p99c": Phase="Running", Reason="", readiness=false. Elapsed: 12.034618972s
Feb 13 15:00:51.219: INFO: Pod "pod-subpath-test-projected-p99c": Phase="Running", Reason="", readiness=false. Elapsed: 14.046499066s
Feb 13 15:00:53.223: INFO: Pod "pod-subpath-test-projected-p99c": Phase="Running", Reason="", readiness=false. Elapsed: 16.050291726s
Feb 13 15:00:55.228: INFO: Pod "pod-subpath-test-projected-p99c": Phase="Running", Reason="", readiness=false. Elapsed: 18.055138293s
Feb 13 15:00:57.232: INFO: Pod "pod-subpath-test-projected-p99c": Phase="Running", Reason="", readiness=false. Elapsed: 20.059887991s
Feb 13 15:00:59.237: INFO: Pod "pod-subpath-test-projected-p99c": Phase="Running", Reason="", readiness=false. Elapsed: 22.064285933s
Feb 13 15:01:01.248: INFO: Pod "pod-subpath-test-projected-p99c": Phase="Running", Reason="", readiness=false. Elapsed: 24.075714689s
Feb 13 15:01:03.254: INFO: Pod "pod-subpath-test-projected-p99c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.081355423s
STEP: Saw pod success
Feb 13 15:01:03.254: INFO: Pod "pod-subpath-test-projected-p99c" satisfied condition "success or failure"
Feb 13 15:01:03.257: INFO: Trying to get logs from node cmp3 pod pod-subpath-test-projected-p99c container test-container-subpath-projected-p99c: <nil>
STEP: delete the pod
Feb 13 15:01:03.281: INFO: Waiting for pod pod-subpath-test-projected-p99c to disappear
Feb 13 15:01:03.284: INFO: Pod pod-subpath-test-projected-p99c no longer exists
STEP: Deleting pod pod-subpath-test-projected-p99c
Feb 13 15:01:03.284: INFO: Deleting pod "pod-subpath-test-projected-p99c" in namespace "e2e-tests-subpath-q5cp9"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 15:01:03.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-q5cp9" for this suite.
Feb 13 15:01:09.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 15:01:09.391: INFO: namespace: e2e-tests-subpath-q5cp9, resource: bindings, ignored listing per whitelist
Feb 13 15:01:09.420: INFO: namespace e2e-tests-subpath-q5cp9 deletion completed in 6.128144411s

• [SLOW TEST:32.360 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 15:01:09.420: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-nkmzv
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Feb 13 15:01:09.538: INFO: Found 0 stateful pods, waiting for 3
Feb 13 15:01:19.549: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 15:01:19.550: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 15:01:19.550: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 13 15:01:19.582: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb 13 15:01:29.626: INFO: Updating stateful set ss2
Feb 13 15:01:29.632: INFO: Waiting for Pod e2e-tests-statefulset-nkmzv/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 13 15:01:39.649: INFO: Waiting for Pod e2e-tests-statefulset-nkmzv/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Feb 13 15:01:49.687: INFO: Found 2 stateful pods, waiting for 3
Feb 13 15:01:59.698: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 15:01:59.698: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 15:01:59.698: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 13 15:02:09.691: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 15:02:09.691: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 15:02:09.691: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 13 15:02:19.699: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 15:02:19.699: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 15:02:19.699: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb 13 15:02:19.725: INFO: Updating stateful set ss2
Feb 13 15:02:19.733: INFO: Waiting for Pod e2e-tests-statefulset-nkmzv/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 13 15:02:29.747: INFO: Waiting for Pod e2e-tests-statefulset-nkmzv/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 13 15:02:39.765: INFO: Updating stateful set ss2
Feb 13 15:02:39.783: INFO: Waiting for StatefulSet e2e-tests-statefulset-nkmzv/ss2 to complete update
Feb 13 15:02:39.783: INFO: Waiting for Pod e2e-tests-statefulset-nkmzv/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 13 15:02:49.797: INFO: Waiting for StatefulSet e2e-tests-statefulset-nkmzv/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 13 15:02:59.794: INFO: Deleting all statefulset in ns e2e-tests-statefulset-nkmzv
Feb 13 15:02:59.803: INFO: Scaling statefulset ss2 to 0
Feb 13 15:03:29.826: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 15:03:29.829: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 15:03:29.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-nkmzv" for this suite.
Feb 13 15:03:35.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 15:03:35.905: INFO: namespace: e2e-tests-statefulset-nkmzv, resource: bindings, ignored listing per whitelist
Feb 13 15:03:35.980: INFO: namespace e2e-tests-statefulset-nkmzv deletion completed in 6.123885279s

• [SLOW TEST:146.560 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 15:03:35.981: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Feb 13 15:03:40.109: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-8990a4cc-2fa0-11e9-9b61-026654d605e3", GenerateName:"", Namespace:"e2e-tests-pods-vjq6s", SelfLink:"/api/v1/namespaces/e2e-tests-pods-vjq6s/pods/pod-submit-remove-8990a4cc-2fa0-11e9-9b61-026654d605e3", UID:"8991976e-2fa0-11e9-85f4-fa163e429998", ResourceVersion:"2526736", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63685667016, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"74163297"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-qwg59", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc4212463c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-qwg59", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc421fa8178), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"cmp3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc42126ff20), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421fa81c0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421fa81e0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc421fa81e8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685667016, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685667018, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685667018, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685667016, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.11.1.3", PodIP:"192.168.113.126", StartTime:(*v1.Time)(0xc4211c1720), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc4211c17a0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"docker.io/library/nginx:1.14-alpine", ImageID:"docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632", ContainerID:"containerd://376b4d40c42d19abac8039e4f76813365ea449c3943780a5e737e9f4f6a644b8"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 15:03:48.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-vjq6s" for this suite.
Feb 13 15:03:54.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 15:03:54.511: INFO: namespace: e2e-tests-pods-vjq6s, resource: bindings, ignored listing per whitelist
Feb 13 15:03:54.565: INFO: namespace e2e-tests-pods-vjq6s deletion completed in 6.11595563s

• [SLOW TEST:18.584 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 15:03:54.565: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 15:04:54.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-mzw5n" for this suite.
Feb 13 15:05:16.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 15:05:16.732: INFO: namespace: e2e-tests-container-probe-mzw5n, resource: bindings, ignored listing per whitelist
Feb 13 15:05:16.809: INFO: namespace e2e-tests-container-probe-mzw5n deletion completed in 22.125737842s

• [SLOW TEST:82.244 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 15:05:16.809: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Feb 13 15:05:16.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 cluster-info'
Feb 13 15:05:17.139: INFO: stderr: ""
Feb 13 15:05:17.139: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 15:05:17.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-c9gf8" for this suite.
Feb 13 15:05:23.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 15:05:23.267: INFO: namespace: e2e-tests-kubectl-c9gf8, resource: bindings, ignored listing per whitelist
Feb 13 15:05:23.270: INFO: namespace e2e-tests-kubectl-c9gf8 deletion completed in 6.125595361s

• [SLOW TEST:6.461 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 15:05:23.271: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 13 15:05:23.379: INFO: Waiting up to 5m0s for pod "downward-api-c984b993-2fa0-11e9-9b61-026654d605e3" in namespace "e2e-tests-downward-api-pkk4t" to be "success or failure"
Feb 13 15:05:23.383: INFO: Pod "downward-api-c984b993-2fa0-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025955ms
Feb 13 15:05:25.395: INFO: Pod "downward-api-c984b993-2fa0-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015166602s
Feb 13 15:05:27.398: INFO: Pod "downward-api-c984b993-2fa0-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019100172s
STEP: Saw pod success
Feb 13 15:05:27.399: INFO: Pod "downward-api-c984b993-2fa0-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 15:05:27.401: INFO: Trying to get logs from node cmp3 pod downward-api-c984b993-2fa0-11e9-9b61-026654d605e3 container dapi-container: <nil>
STEP: delete the pod
Feb 13 15:05:27.432: INFO: Waiting for pod downward-api-c984b993-2fa0-11e9-9b61-026654d605e3 to disappear
Feb 13 15:05:27.435: INFO: Pod downward-api-c984b993-2fa0-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 15:05:27.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pkk4t" for this suite.
Feb 13 15:05:33.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 15:05:33.472: INFO: namespace: e2e-tests-downward-api-pkk4t, resource: bindings, ignored listing per whitelist
Feb 13 15:05:33.566: INFO: namespace e2e-tests-downward-api-pkk4t deletion completed in 6.126109342s

• [SLOW TEST:10.295 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 15:05:33.567: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-cfa60a87-2fa0-11e9-9b61-026654d605e3
STEP: Creating a pod to test consume configMaps
Feb 13 15:05:33.669: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-cfa71a06-2fa0-11e9-9b61-026654d605e3" in namespace "e2e-tests-projected-8wnfv" to be "success or failure"
Feb 13 15:05:33.672: INFO: Pod "pod-projected-configmaps-cfa71a06-2fa0-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.00703ms
Feb 13 15:05:35.682: INFO: Pod "pod-projected-configmaps-cfa71a06-2fa0-11e9-9b61-026654d605e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013307641s
Feb 13 15:05:37.687: INFO: Pod "pod-projected-configmaps-cfa71a06-2fa0-11e9-9b61-026654d605e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018265276s
STEP: Saw pod success
Feb 13 15:05:37.687: INFO: Pod "pod-projected-configmaps-cfa71a06-2fa0-11e9-9b61-026654d605e3" satisfied condition "success or failure"
Feb 13 15:05:37.691: INFO: Trying to get logs from node cmp3 pod pod-projected-configmaps-cfa71a06-2fa0-11e9-9b61-026654d605e3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 15:05:37.710: INFO: Waiting for pod pod-projected-configmaps-cfa71a06-2fa0-11e9-9b61-026654d605e3 to disappear
Feb 13 15:05:37.713: INFO: Pod pod-projected-configmaps-cfa71a06-2fa0-11e9-9b61-026654d605e3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 15:05:37.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8wnfv" for this suite.
Feb 13 15:05:43.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 15:05:43.807: INFO: namespace: e2e-tests-projected-8wnfv, resource: bindings, ignored listing per whitelist
Feb 13 15:05:43.866: INFO: namespace e2e-tests-projected-8wnfv deletion completed in 6.148756142s

• [SLOW TEST:10.299 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 15:05:43.867: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 13 15:05:48.520: INFO: Successfully updated pod "annotationupdated5cad730-2fa0-11e9-9b61-026654d605e3"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 15:05:52.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ffc5c" for this suite.
Feb 13 15:06:14.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 15:06:14.567: INFO: namespace: e2e-tests-downward-api-ffc5c, resource: bindings, ignored listing per whitelist
Feb 13 15:06:14.670: INFO: namespace e2e-tests-downward-api-ffc5c deletion completed in 22.12238522s

• [SLOW TEST:30.804 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 15:06:14.671: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 13 15:06:14.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-rz5mv'
Feb 13 15:06:14.915: INFO: stderr: ""
Feb 13 15:06:14.915: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Feb 13 15:06:19.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-rz5mv -o json'
Feb 13 15:06:20.085: INFO: stderr: ""
Feb 13 15:06:20.086: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-02-13T15:06:14Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-rz5mv\",\n        \"resourceVersion\": \"2527307\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-rz5mv/pods/e2e-test-nginx-pod\",\n        \"uid\": \"e83b40c1-2fa0-11e9-85f4-fa163e429998\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-xt2pn\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"cmp3\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-xt2pn\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-xt2pn\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-13T15:06:14Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-13T15:06:18Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-13T15:06:18Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-13T15:06:14Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://9724fcf959be07328500aff17cd3e41d9582ff1c0be38becc000a526b771cf91\",\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imageID\": \"docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-02-13T15:06:18Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.11.1.3\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.113.91\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-02-13T15:06:14Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb 13 15:06:20.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 replace -f - --namespace=e2e-tests-kubectl-rz5mv'
Feb 13 15:06:20.318: INFO: stderr: ""
Feb 13 15:06:20.318: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Feb 13 15:06:20.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-172602910 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-rz5mv'
Feb 13 15:06:28.455: INFO: stderr: ""
Feb 13 15:06:28.455: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 15:06:28.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rz5mv" for this suite.
Feb 13 15:06:34.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 15:06:34.489: INFO: namespace: e2e-tests-kubectl-rz5mv, resource: bindings, ignored listing per whitelist
Feb 13 15:06:34.584: INFO: namespace e2e-tests-kubectl-rz5mv deletion completed in 6.124972539s

• [SLOW TEST:19.913 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 15:06:34.585: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 15:06:34.697: INFO: Pod name rollover-pod: Found 0 pods out of 1
Feb 13 15:06:39.702: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 13 15:06:39.702: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb 13 15:06:41.712: INFO: Creating deployment "test-rollover-deployment"
Feb 13 15:06:41.721: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb 13 15:06:43.729: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb 13 15:06:43.735: INFO: Ensure that both replica sets have 1 created replica
Feb 13 15:06:43.741: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb 13 15:06:43.749: INFO: Updating deployment test-rollover-deployment
Feb 13 15:06:43.749: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb 13 15:06:45.756: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb 13 15:06:45.763: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb 13 15:06:45.771: INFO: all replica sets need to contain the pod-template-hash label
Feb 13 15:06:45.771: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685667201, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685667201, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685667203, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685667201, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 15:06:47.781: INFO: all replica sets need to contain the pod-template-hash label
Feb 13 15:06:47.781: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685667201, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685667201, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685667206, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685667201, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 15:06:49.780: INFO: all replica sets need to contain the pod-template-hash label
Feb 13 15:06:49.780: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685667201, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685667201, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685667206, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685667201, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 15:06:51.786: INFO: all replica sets need to contain the pod-template-hash label
Feb 13 15:06:51.786: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685667201, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685667201, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685667206, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685667201, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 15:06:53.781: INFO: all replica sets need to contain the pod-template-hash label
Feb 13 15:06:53.781: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685667201, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685667201, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685667206, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685667201, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 15:06:55.780: INFO: all replica sets need to contain the pod-template-hash label
Feb 13 15:06:55.780: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685667201, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685667201, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685667206, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685667201, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 15:06:57.781: INFO: 
Feb 13 15:06:57.781: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 13 15:06:57.791: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-9rwkr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9rwkr/deployments/test-rollover-deployment,UID:f836a28a-2fa0-11e9-85f4-fa163e429998,ResourceVersion:2527514,Generation:2,CreationTimestamp:2019-02-13 15:06:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-13 15:06:41 +0000 UTC 2019-02-13 15:06:41 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-13 15:06:56 +0000 UTC 2019-02-13 15:06:41 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 13 15:06:57.795: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-9rwkr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9rwkr/replicasets/test-rollover-deployment-5b76ff8c4,UID:f96df3fc-2fa0-11e9-b579-fa163ed32deb,ResourceVersion:2527505,Generation:2,CreationTimestamp:2019-02-13 15:06:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment f836a28a-2fa0-11e9-85f4-fa163e429998 0xc422714c67 0xc422714c68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 13 15:06:57.796: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb 13 15:06:57.796: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-9rwkr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9rwkr/replicasets/test-rollover-controller,UID:f4065786-2fa0-11e9-85f4-fa163e429998,ResourceVersion:2527513,Generation:2,CreationTimestamp:2019-02-13 15:06:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment f836a28a-2fa0-11e9-85f4-fa163e429998 0xc422714b2e 0xc422714b2f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 13 15:06:57.796: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-9rwkr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9rwkr/replicasets/test-rollover-deployment-6975f4fb87,UID:f83a6727-2fa0-11e9-b579-fa163ed32deb,ResourceVersion:2527456,Generation:2,CreationTimestamp:2019-02-13 15:06:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment f836a28a-2fa0-11e9-85f4-fa163e429998 0xc422714d27 0xc422714d28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 13 15:06:57.800: INFO: Pod "test-rollover-deployment-5b76ff8c4-xl2qx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-xl2qx,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-9rwkr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rwkr/pods/test-rollover-deployment-5b76ff8c4-xl2qx,UID:f971f72f-2fa0-11e9-b579-fa163ed32deb,ResourceVersion:2527478,Generation:0,CreationTimestamp:2019-02-13 15:06:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 f96df3fc-2fa0-11e9-b579-fa163ed32deb 0xc4227c8440 0xc4227c8441}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j6h54 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j6h54,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-j6h54 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cmp3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4227c84e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4227c8510}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 15:06:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 15:06:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 15:06:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 15:06:43 +0000 UTC  }],Message:,Reason:,HostIP:10.11.1.3,PodIP:192.168.113.95,StartTime:2019-02-13 15:06:43 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-13 15:06:46 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://f0890032b71103f613a236b5e42706709175cd221ad85c0831c33b9fbf21a6e1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 15:06:57.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-9rwkr" for this suite.
Feb 13 15:07:03.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 15:07:03.921: INFO: namespace: e2e-tests-deployment-9rwkr, resource: bindings, ignored listing per whitelist
Feb 13 15:07:03.933: INFO: namespace e2e-tests-deployment-9rwkr deletion completed in 6.128583958s

• [SLOW TEST:29.348 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 15:07:03.934: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 13 15:07:08.583: INFO: Successfully updated pod "labelsupdate05848566-2fa1-11e9-9b61-026654d605e3"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 15:07:10.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mrzh8" for this suite.
Feb 13 15:07:32.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 15:07:32.634: INFO: namespace: e2e-tests-downward-api-mrzh8, resource: bindings, ignored listing per whitelist
Feb 13 15:07:32.739: INFO: namespace e2e-tests-downward-api-mrzh8 deletion completed in 22.131041124s

• [SLOW TEST:28.806 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 15:07:32.740: INFO: >>> kubeConfig: /tmp/kubeconfig-172602910
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 15:07:38.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-x62lw" for this suite.
Feb 13 15:07:45.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 15:07:45.050: INFO: namespace: e2e-tests-namespaces-x62lw, resource: bindings, ignored listing per whitelist
Feb 13 15:07:45.117: INFO: namespace e2e-tests-namespaces-x62lw deletion completed in 6.146715232s
STEP: Destroying namespace "e2e-tests-nsdeletetest-ncwbx" for this suite.
Feb 13 15:07:45.121: INFO: Namespace e2e-tests-nsdeletetest-ncwbx was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-xswzt" for this suite.
Feb 13 15:07:51.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 15:07:51.180: INFO: namespace: e2e-tests-nsdeletetest-xswzt, resource: bindings, ignored listing per whitelist
Feb 13 15:07:51.245: INFO: namespace e2e-tests-nsdeletetest-xswzt deletion completed in 6.124336008s

• [SLOW TEST:18.505 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SFeb 13 15:07:51.245: INFO: Running AfterSuite actions on all node
Feb 13 15:07:51.245: INFO: Running AfterSuite actions on node 1
Feb 13 15:07:51.245: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 5669.984 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 1h34m30.821073176s
Test Suite Passed
