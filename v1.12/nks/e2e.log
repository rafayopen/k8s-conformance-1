Feb  8 22:19:57.829: INFO: Overriding default scale value of zero to 1
Feb  8 22:19:57.829: INFO: Overriding default milliseconds value of zero to 5000
I0208 22:19:58.242665      14 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-821255472
I0208 22:19:58.242775      14 e2e.go:304] Starting e2e run "ab0032aa-2bef-11e9-a551-0a580a020303" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1549664397 - Will randomize all specs
Will run 188 of 1814 specs

Feb  8 22:19:58.399: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
Feb  8 22:19:58.402: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb  8 22:19:58.419: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb  8 22:19:58.449: INFO: 17 / 17 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb  8 22:19:58.449: INFO: expected 6 pod replicas in namespace 'kube-system', 6 are Running and Ready.
Feb  8 22:19:58.449: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb  8 22:19:58.458: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds' (0 seconds elapsed)
Feb  8 22:19:58.458: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Feb  8 22:19:58.458: INFO: e2e test version: v1.12.1
Feb  8 22:19:58.459: INFO: kube-apiserver version: v1.12.4
SSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:19:58.459: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename configmap
Feb  8 22:19:58.566: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-95nqx/configmap-test-ab7b69df-2bef-11e9-a551-0a580a020303
STEP: Creating a pod to test consume configMaps
Feb  8 22:19:58.583: INFO: Waiting up to 5m0s for pod "pod-configmaps-ab7c4501-2bef-11e9-a551-0a580a020303" in namespace "e2e-tests-configmap-95nqx" to be "success or failure"
Feb  8 22:19:58.586: INFO: Pod "pod-configmaps-ab7c4501-2bef-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 3.369829ms
Feb  8 22:20:00.590: INFO: Pod "pod-configmaps-ab7c4501-2bef-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006858595s
Feb  8 22:20:02.593: INFO: Pod "pod-configmaps-ab7c4501-2bef-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010337689s
STEP: Saw pod success
Feb  8 22:20:02.593: INFO: Pod "pod-configmaps-ab7c4501-2bef-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:20:02.596: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod pod-configmaps-ab7c4501-2bef-11e9-a551-0a580a020303 container env-test: <nil>
STEP: delete the pod
Feb  8 22:20:02.625: INFO: Waiting for pod pod-configmaps-ab7c4501-2bef-11e9-a551-0a580a020303 to disappear
Feb  8 22:20:02.627: INFO: Pod pod-configmaps-ab7c4501-2bef-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:20:02.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-95nqx" for this suite.
Feb  8 22:20:10.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:20:10.761: INFO: namespace: e2e-tests-configmap-95nqx, resource: bindings, ignored listing per whitelist
Feb  8 22:20:10.773: INFO: namespace e2e-tests-configmap-95nqx deletion completed in 8.13809433s

• [SLOW TEST:12.313 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:20:10.773: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-nzxxg
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  8 22:20:10.827: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  8 22:20:34.907: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.1.6:8080/dial?request=hostName&protocol=udp&host=10.2.2.4&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-nzxxg PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  8 22:20:34.907: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
Feb  8 22:20:35.028: INFO: Waiting for endpoints: map[]
Feb  8 22:20:35.031: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.1.6:8080/dial?request=hostName&protocol=udp&host=10.2.3.4&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-nzxxg PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  8 22:20:35.031: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
Feb  8 22:20:35.154: INFO: Waiting for endpoints: map[]
Feb  8 22:20:35.157: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.1.6:8080/dial?request=hostName&protocol=udp&host=10.2.1.5&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-nzxxg PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  8 22:20:35.157: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
Feb  8 22:20:35.280: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:20:35.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-nzxxg" for this suite.
Feb  8 22:20:57.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:20:57.326: INFO: namespace: e2e-tests-pod-network-test-nzxxg, resource: bindings, ignored listing per whitelist
Feb  8 22:20:57.373: INFO: namespace e2e-tests-pod-network-test-nzxxg deletion completed in 22.090121125s

• [SLOW TEST:46.601 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:20:57.374: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-s7j9n
Feb  8 22:21:01.443: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-s7j9n
STEP: checking the pod's current state and verifying that restartCount is present
Feb  8 22:21:01.446: INFO: Initial restart count of pod liveness-http is 0
Feb  8 22:21:21.481: INFO: Restart count of pod e2e-tests-container-probe-s7j9n/liveness-http is now 1 (20.035534013s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:21:21.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-s7j9n" for this suite.
Feb  8 22:21:27.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:21:27.550: INFO: namespace: e2e-tests-container-probe-s7j9n, resource: bindings, ignored listing per whitelist
Feb  8 22:21:27.582: INFO: namespace e2e-tests-container-probe-s7j9n deletion completed in 6.086586672s

• [SLOW TEST:30.208 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:21:27.582: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb  8 22:21:27.640: INFO: Waiting up to 5m0s for pod "pod-e091b528-2bef-11e9-a551-0a580a020303" in namespace "e2e-tests-emptydir-frbjd" to be "success or failure"
Feb  8 22:21:27.642: INFO: Pod "pod-e091b528-2bef-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.100744ms
Feb  8 22:21:29.645: INFO: Pod "pod-e091b528-2bef-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005088131s
Feb  8 22:21:31.649: INFO: Pod "pod-e091b528-2bef-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008801694s
STEP: Saw pod success
Feb  8 22:21:31.649: INFO: Pod "pod-e091b528-2bef-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:21:31.651: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod pod-e091b528-2bef-11e9-a551-0a580a020303 container test-container: <nil>
STEP: delete the pod
Feb  8 22:21:31.669: INFO: Waiting for pod pod-e091b528-2bef-11e9-a551-0a580a020303 to disappear
Feb  8 22:21:31.671: INFO: Pod pod-e091b528-2bef-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:21:31.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-frbjd" for this suite.
Feb  8 22:21:37.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:21:37.718: INFO: namespace: e2e-tests-emptydir-frbjd, resource: bindings, ignored listing per whitelist
Feb  8 22:21:37.760: INFO: namespace e2e-tests-emptydir-frbjd deletion completed in 6.086239374s

• [SLOW TEST:10.178 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:21:37.760: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-e6a2d13c-2bef-11e9-a551-0a580a020303
STEP: Creating a pod to test consume secrets
Feb  8 22:21:37.821: INFO: Waiting up to 5m0s for pod "pod-secrets-e6a35753-2bef-11e9-a551-0a580a020303" in namespace "e2e-tests-secrets-mthl6" to be "success or failure"
Feb  8 22:21:37.827: INFO: Pod "pod-secrets-e6a35753-2bef-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 5.063699ms
Feb  8 22:21:39.830: INFO: Pod "pod-secrets-e6a35753-2bef-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008528534s
STEP: Saw pod success
Feb  8 22:21:39.830: INFO: Pod "pod-secrets-e6a35753-2bef-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:21:39.832: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod pod-secrets-e6a35753-2bef-11e9-a551-0a580a020303 container secret-volume-test: <nil>
STEP: delete the pod
Feb  8 22:21:39.851: INFO: Waiting for pod pod-secrets-e6a35753-2bef-11e9-a551-0a580a020303 to disappear
Feb  8 22:21:39.853: INFO: Pod pod-secrets-e6a35753-2bef-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:21:39.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-mthl6" for this suite.
Feb  8 22:21:45.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:21:45.944: INFO: namespace: e2e-tests-secrets-mthl6, resource: bindings, ignored listing per whitelist
Feb  8 22:21:45.944: INFO: namespace e2e-tests-secrets-mthl6 deletion completed in 6.087962227s

• [SLOW TEST:8.183 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:21:45.944: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Feb  8 22:21:46.515: INFO: created pod pod-service-account-defaultsa
Feb  8 22:21:46.515: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb  8 22:21:46.521: INFO: created pod pod-service-account-mountsa
Feb  8 22:21:46.521: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb  8 22:21:46.526: INFO: created pod pod-service-account-nomountsa
Feb  8 22:21:46.526: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb  8 22:21:46.531: INFO: created pod pod-service-account-defaultsa-mountspec
Feb  8 22:21:46.531: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb  8 22:21:46.538: INFO: created pod pod-service-account-mountsa-mountspec
Feb  8 22:21:46.538: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb  8 22:21:46.546: INFO: created pod pod-service-account-nomountsa-mountspec
Feb  8 22:21:46.546: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb  8 22:21:46.552: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb  8 22:21:46.552: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb  8 22:21:46.559: INFO: created pod pod-service-account-mountsa-nomountspec
Feb  8 22:21:46.559: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb  8 22:21:46.566: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb  8 22:21:46.566: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:21:46.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-pdsn9" for this suite.
Feb  8 22:21:52.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:21:52.631: INFO: namespace: e2e-tests-svcaccounts-pdsn9, resource: bindings, ignored listing per whitelist
Feb  8 22:21:52.672: INFO: namespace e2e-tests-svcaccounts-pdsn9 deletion completed in 6.101760093s

• [SLOW TEST:6.728 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:21:52.672: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb  8 22:21:52.762: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:21:52.765: INFO: Number of nodes with available pods: 0
Feb  8 22:21:52.765: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:21:53.770: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:21:53.773: INFO: Number of nodes with available pods: 0
Feb  8 22:21:53.773: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:21:54.769: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:21:54.772: INFO: Number of nodes with available pods: 0
Feb  8 22:21:54.772: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:21:55.769: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:21:55.772: INFO: Number of nodes with available pods: 3
Feb  8 22:21:55.772: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb  8 22:21:55.788: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:21:55.793: INFO: Number of nodes with available pods: 2
Feb  8 22:21:55.793: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:21:56.796: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:21:56.799: INFO: Number of nodes with available pods: 2
Feb  8 22:21:56.799: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:21:57.797: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:21:57.800: INFO: Number of nodes with available pods: 3
Feb  8 22:21:57.800: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-59r7g, will wait for the garbage collector to delete the pods
Feb  8 22:21:57.862: INFO: Deleting {extensions DaemonSet} daemon-set took: 5.848128ms
Feb  8 22:21:57.963: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.209654ms
Feb  8 22:22:38.066: INFO: Number of nodes with available pods: 0
Feb  8 22:22:38.066: INFO: Number of running nodes: 0, number of available pods: 0
Feb  8 22:22:38.070: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-59r7g/daemonsets","resourceVersion":"1927"},"items":null}

Feb  8 22:22:38.073: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-59r7g/pods","resourceVersion":"1927"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:22:38.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-59r7g" for this suite.
Feb  8 22:22:44.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:22:44.134: INFO: namespace: e2e-tests-daemonsets-59r7g, resource: bindings, ignored listing per whitelist
Feb  8 22:22:44.166: INFO: namespace e2e-tests-daemonsets-59r7g deletion completed in 6.080545011s

• [SLOW TEST:51.494 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:22:44.166: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  8 22:22:44.229: INFO: Waiting up to 5m0s for pod "downward-api-0e37d0a4-2bf0-11e9-a551-0a580a020303" in namespace "e2e-tests-downward-api-zwpzd" to be "success or failure"
Feb  8 22:22:44.233: INFO: Pod "downward-api-0e37d0a4-2bf0-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 4.149124ms
Feb  8 22:22:46.236: INFO: Pod "downward-api-0e37d0a4-2bf0-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007826341s
STEP: Saw pod success
Feb  8 22:22:46.236: INFO: Pod "downward-api-0e37d0a4-2bf0-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:22:46.239: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod downward-api-0e37d0a4-2bf0-11e9-a551-0a580a020303 container dapi-container: <nil>
STEP: delete the pod
Feb  8 22:22:46.256: INFO: Waiting for pod downward-api-0e37d0a4-2bf0-11e9-a551-0a580a020303 to disappear
Feb  8 22:22:46.258: INFO: Pod downward-api-0e37d0a4-2bf0-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:22:46.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zwpzd" for this suite.
Feb  8 22:22:52.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:22:52.289: INFO: namespace: e2e-tests-downward-api-zwpzd, resource: bindings, ignored listing per whitelist
Feb  8 22:22:52.342: INFO: namespace e2e-tests-downward-api-zwpzd deletion completed in 6.080560501s

• [SLOW TEST:8.176 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:22:52.342: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  8 22:22:52.447: INFO: Waiting up to 5m0s for pod "downward-api-131e53ad-2bf0-11e9-a551-0a580a020303" in namespace "e2e-tests-downward-api-xn65n" to be "success or failure"
Feb  8 22:22:52.452: INFO: Pod "downward-api-131e53ad-2bf0-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 4.789058ms
Feb  8 22:22:54.455: INFO: Pod "downward-api-131e53ad-2bf0-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008117463s
STEP: Saw pod success
Feb  8 22:22:54.455: INFO: Pod "downward-api-131e53ad-2bf0-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:22:54.457: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod downward-api-131e53ad-2bf0-11e9-a551-0a580a020303 container dapi-container: <nil>
STEP: delete the pod
Feb  8 22:22:54.476: INFO: Waiting for pod downward-api-131e53ad-2bf0-11e9-a551-0a580a020303 to disappear
Feb  8 22:22:54.478: INFO: Pod downward-api-131e53ad-2bf0-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:22:54.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xn65n" for this suite.
Feb  8 22:23:00.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:23:00.504: INFO: namespace: e2e-tests-downward-api-xn65n, resource: bindings, ignored listing per whitelist
Feb  8 22:23:00.567: INFO: namespace e2e-tests-downward-api-xn65n deletion completed in 6.086584842s

• [SLOW TEST:8.225 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:23:00.567: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-17fed890-2bf0-11e9-a551-0a580a020303
STEP: Creating a pod to test consume configMaps
Feb  8 22:23:00.633: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-17ff80d9-2bf0-11e9-a551-0a580a020303" in namespace "e2e-tests-projected-knsj5" to be "success or failure"
Feb  8 22:23:00.635: INFO: Pod "pod-projected-configmaps-17ff80d9-2bf0-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.28958ms
Feb  8 22:23:02.639: INFO: Pod "pod-projected-configmaps-17ff80d9-2bf0-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005694832s
STEP: Saw pod success
Feb  8 22:23:02.639: INFO: Pod "pod-projected-configmaps-17ff80d9-2bf0-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:23:02.641: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod pod-projected-configmaps-17ff80d9-2bf0-11e9-a551-0a580a020303 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  8 22:23:02.660: INFO: Waiting for pod pod-projected-configmaps-17ff80d9-2bf0-11e9-a551-0a580a020303 to disappear
Feb  8 22:23:02.663: INFO: Pod pod-projected-configmaps-17ff80d9-2bf0-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:23:02.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-knsj5" for this suite.
Feb  8 22:23:08.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:23:08.730: INFO: namespace: e2e-tests-projected-knsj5, resource: bindings, ignored listing per whitelist
Feb  8 22:23:08.753: INFO: namespace e2e-tests-projected-knsj5 deletion completed in 6.08665056s

• [SLOW TEST:8.186 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:23:08.754: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-1cdf037e-2bf0-11e9-a551-0a580a020303
STEP: Creating a pod to test consume secrets
Feb  8 22:23:08.816: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1cdf84ec-2bf0-11e9-a551-0a580a020303" in namespace "e2e-tests-projected-7vgx4" to be "success or failure"
Feb  8 22:23:08.818: INFO: Pod "pod-projected-secrets-1cdf84ec-2bf0-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.310673ms
Feb  8 22:23:10.821: INFO: Pod "pod-projected-secrets-1cdf84ec-2bf0-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005390782s
STEP: Saw pod success
Feb  8 22:23:10.821: INFO: Pod "pod-projected-secrets-1cdf84ec-2bf0-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:23:10.824: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod pod-projected-secrets-1cdf84ec-2bf0-11e9-a551-0a580a020303 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  8 22:23:10.843: INFO: Waiting for pod pod-projected-secrets-1cdf84ec-2bf0-11e9-a551-0a580a020303 to disappear
Feb  8 22:23:10.846: INFO: Pod pod-projected-secrets-1cdf84ec-2bf0-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:23:10.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7vgx4" for this suite.
Feb  8 22:23:16.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:23:16.895: INFO: namespace: e2e-tests-projected-7vgx4, resource: bindings, ignored listing per whitelist
Feb  8 22:23:16.935: INFO: namespace e2e-tests-projected-7vgx4 deletion completed in 6.085955989s

• [SLOW TEST:8.181 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:23:16.935: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  8 22:23:16.993: INFO: Waiting up to 5m0s for pod "downwardapi-volume-21bfbcc0-2bf0-11e9-a551-0a580a020303" in namespace "e2e-tests-projected-bk6wb" to be "success or failure"
Feb  8 22:23:16.999: INFO: Pod "downwardapi-volume-21bfbcc0-2bf0-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 5.204837ms
Feb  8 22:23:19.002: INFO: Pod "downwardapi-volume-21bfbcc0-2bf0-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008881429s
STEP: Saw pod success
Feb  8 22:23:19.002: INFO: Pod "downwardapi-volume-21bfbcc0-2bf0-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:23:19.005: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod downwardapi-volume-21bfbcc0-2bf0-11e9-a551-0a580a020303 container client-container: <nil>
STEP: delete the pod
Feb  8 22:23:19.024: INFO: Waiting for pod downwardapi-volume-21bfbcc0-2bf0-11e9-a551-0a580a020303 to disappear
Feb  8 22:23:19.027: INFO: Pod downwardapi-volume-21bfbcc0-2bf0-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:23:19.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bk6wb" for this suite.
Feb  8 22:23:25.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:23:25.083: INFO: namespace: e2e-tests-projected-bk6wb, resource: bindings, ignored listing per whitelist
Feb  8 22:23:25.114: INFO: namespace e2e-tests-projected-bk6wb deletion completed in 6.084103051s

• [SLOW TEST:8.180 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:23:25.115: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  8 22:23:25.169: INFO: Waiting up to 5m0s for pod "downwardapi-volume-269f3773-2bf0-11e9-a551-0a580a020303" in namespace "e2e-tests-downward-api-fmnxt" to be "success or failure"
Feb  8 22:23:25.173: INFO: Pod "downwardapi-volume-269f3773-2bf0-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010257ms
Feb  8 22:23:27.177: INFO: Pod "downwardapi-volume-269f3773-2bf0-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007570212s
STEP: Saw pod success
Feb  8 22:23:27.177: INFO: Pod "downwardapi-volume-269f3773-2bf0-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:23:27.179: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod downwardapi-volume-269f3773-2bf0-11e9-a551-0a580a020303 container client-container: <nil>
STEP: delete the pod
Feb  8 22:23:27.198: INFO: Waiting for pod downwardapi-volume-269f3773-2bf0-11e9-a551-0a580a020303 to disappear
Feb  8 22:23:27.201: INFO: Pod downwardapi-volume-269f3773-2bf0-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:23:27.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fmnxt" for this suite.
Feb  8 22:23:33.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:23:33.290: INFO: namespace: e2e-tests-downward-api-fmnxt, resource: bindings, ignored listing per whitelist
Feb  8 22:23:33.291: INFO: namespace e2e-tests-downward-api-fmnxt deletion completed in 6.087741235s

• [SLOW TEST:8.177 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:23:33.292: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-2b7f7fd1-2bf0-11e9-a551-0a580a020303
STEP: Creating a pod to test consume secrets
Feb  8 22:23:33.353: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2b800b62-2bf0-11e9-a551-0a580a020303" in namespace "e2e-tests-projected-x5wtt" to be "success or failure"
Feb  8 22:23:33.356: INFO: Pod "pod-projected-secrets-2b800b62-2bf0-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.596891ms
Feb  8 22:23:35.359: INFO: Pod "pod-projected-secrets-2b800b62-2bf0-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006172868s
STEP: Saw pod success
Feb  8 22:23:35.359: INFO: Pod "pod-projected-secrets-2b800b62-2bf0-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:23:35.362: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod pod-projected-secrets-2b800b62-2bf0-11e9-a551-0a580a020303 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  8 22:23:35.391: INFO: Waiting for pod pod-projected-secrets-2b800b62-2bf0-11e9-a551-0a580a020303 to disappear
Feb  8 22:23:35.394: INFO: Pod pod-projected-secrets-2b800b62-2bf0-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:23:35.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-x5wtt" for this suite.
Feb  8 22:23:41.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:23:41.437: INFO: namespace: e2e-tests-projected-x5wtt, resource: bindings, ignored listing per whitelist
Feb  8 22:23:41.480: INFO: namespace e2e-tests-projected-x5wtt deletion completed in 6.08379563s

• [SLOW TEST:8.188 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:23:41.480: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb  8 22:23:41.547: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:23:41.553: INFO: Number of nodes with available pods: 0
Feb  8 22:23:41.553: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:23:42.557: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:23:42.559: INFO: Number of nodes with available pods: 0
Feb  8 22:23:42.559: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:23:43.557: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:23:43.559: INFO: Number of nodes with available pods: 3
Feb  8 22:23:43.559: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb  8 22:23:43.574: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:23:43.577: INFO: Number of nodes with available pods: 2
Feb  8 22:23:43.577: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:23:44.580: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:23:44.583: INFO: Number of nodes with available pods: 2
Feb  8 22:23:44.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:23:45.581: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:23:45.583: INFO: Number of nodes with available pods: 2
Feb  8 22:23:45.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:23:46.581: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:23:46.583: INFO: Number of nodes with available pods: 2
Feb  8 22:23:46.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:23:47.586: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:23:47.588: INFO: Number of nodes with available pods: 2
Feb  8 22:23:47.588: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:23:48.581: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:23:48.584: INFO: Number of nodes with available pods: 2
Feb  8 22:23:48.584: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:23:49.581: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:23:49.590: INFO: Number of nodes with available pods: 2
Feb  8 22:23:49.590: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:23:50.580: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:23:50.583: INFO: Number of nodes with available pods: 2
Feb  8 22:23:50.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:23:51.580: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:23:51.583: INFO: Number of nodes with available pods: 2
Feb  8 22:23:51.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:23:52.581: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:23:52.583: INFO: Number of nodes with available pods: 2
Feb  8 22:23:52.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:23:53.580: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:23:53.583: INFO: Number of nodes with available pods: 2
Feb  8 22:23:53.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:23:54.580: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:23:54.583: INFO: Number of nodes with available pods: 2
Feb  8 22:23:54.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:23:55.580: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:23:55.583: INFO: Number of nodes with available pods: 2
Feb  8 22:23:55.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:23:56.580: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:23:56.583: INFO: Number of nodes with available pods: 2
Feb  8 22:23:56.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:23:57.580: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:23:57.583: INFO: Number of nodes with available pods: 2
Feb  8 22:23:57.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:23:58.581: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:23:58.583: INFO: Number of nodes with available pods: 2
Feb  8 22:23:58.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:23:59.581: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:23:59.583: INFO: Number of nodes with available pods: 2
Feb  8 22:23:59.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:00.581: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:00.583: INFO: Number of nodes with available pods: 2
Feb  8 22:24:00.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:01.581: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:01.583: INFO: Number of nodes with available pods: 2
Feb  8 22:24:01.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:02.580: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:02.583: INFO: Number of nodes with available pods: 2
Feb  8 22:24:02.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:03.580: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:03.583: INFO: Number of nodes with available pods: 2
Feb  8 22:24:03.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:04.580: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:04.583: INFO: Number of nodes with available pods: 2
Feb  8 22:24:04.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:05.581: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:05.583: INFO: Number of nodes with available pods: 2
Feb  8 22:24:05.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:06.581: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:06.583: INFO: Number of nodes with available pods: 2
Feb  8 22:24:06.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:07.580: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:07.583: INFO: Number of nodes with available pods: 2
Feb  8 22:24:07.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:08.581: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:08.583: INFO: Number of nodes with available pods: 2
Feb  8 22:24:08.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:09.581: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:09.583: INFO: Number of nodes with available pods: 2
Feb  8 22:24:09.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:10.581: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:10.583: INFO: Number of nodes with available pods: 2
Feb  8 22:24:10.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:11.581: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:11.583: INFO: Number of nodes with available pods: 2
Feb  8 22:24:11.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:12.580: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:12.583: INFO: Number of nodes with available pods: 2
Feb  8 22:24:12.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:13.581: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:13.583: INFO: Number of nodes with available pods: 2
Feb  8 22:24:13.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:14.581: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:14.583: INFO: Number of nodes with available pods: 2
Feb  8 22:24:14.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:15.581: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:15.584: INFO: Number of nodes with available pods: 2
Feb  8 22:24:15.584: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:16.584: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:16.590: INFO: Number of nodes with available pods: 2
Feb  8 22:24:16.590: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:17.580: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:17.583: INFO: Number of nodes with available pods: 2
Feb  8 22:24:17.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:18.581: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:18.583: INFO: Number of nodes with available pods: 2
Feb  8 22:24:18.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:19.580: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:19.583: INFO: Number of nodes with available pods: 2
Feb  8 22:24:19.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:20.582: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:20.585: INFO: Number of nodes with available pods: 2
Feb  8 22:24:20.585: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:21.580: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:21.583: INFO: Number of nodes with available pods: 2
Feb  8 22:24:21.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:22.581: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:22.583: INFO: Number of nodes with available pods: 2
Feb  8 22:24:22.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:23.581: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:23.583: INFO: Number of nodes with available pods: 2
Feb  8 22:24:23.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:24.581: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:24.583: INFO: Number of nodes with available pods: 2
Feb  8 22:24:24.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:25.580: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:25.583: INFO: Number of nodes with available pods: 2
Feb  8 22:24:25.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:26.581: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:26.583: INFO: Number of nodes with available pods: 2
Feb  8 22:24:26.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:27.580: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:27.583: INFO: Number of nodes with available pods: 2
Feb  8 22:24:27.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:28.581: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:28.583: INFO: Number of nodes with available pods: 2
Feb  8 22:24:28.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:29.581: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:29.583: INFO: Number of nodes with available pods: 2
Feb  8 22:24:29.583: INFO: Node ip-172-23-7-130.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:24:30.581: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:24:30.583: INFO: Number of nodes with available pods: 3
Feb  8 22:24:30.583: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-bc847, will wait for the garbage collector to delete the pods
Feb  8 22:24:30.644: INFO: Deleting {extensions DaemonSet} daemon-set took: 6.260591ms
Feb  8 22:24:30.744: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.231852ms
Feb  8 22:25:04.248: INFO: Number of nodes with available pods: 0
Feb  8 22:25:04.248: INFO: Number of running nodes: 0, number of available pods: 0
Feb  8 22:25:04.250: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-bc847/daemonsets","resourceVersion":"2422"},"items":null}

Feb  8 22:25:04.252: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-bc847/pods","resourceVersion":"2422"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:25:04.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-bc847" for this suite.
Feb  8 22:25:10.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:25:10.288: INFO: namespace: e2e-tests-daemonsets-bc847, resource: bindings, ignored listing per whitelist
Feb  8 22:25:10.351: INFO: namespace e2e-tests-daemonsets-bc847 deletion completed in 6.085790215s

• [SLOW TEST:88.870 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:25:10.351: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-6559be90-2bf0-11e9-a551-0a580a020303
STEP: Creating a pod to test consume secrets
Feb  8 22:25:10.416: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-655a4e5b-2bf0-11e9-a551-0a580a020303" in namespace "e2e-tests-projected-bkntn" to be "success or failure"
Feb  8 22:25:10.418: INFO: Pod "pod-projected-secrets-655a4e5b-2bf0-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.283993ms
Feb  8 22:25:12.422: INFO: Pod "pod-projected-secrets-655a4e5b-2bf0-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005924207s
STEP: Saw pod success
Feb  8 22:25:12.422: INFO: Pod "pod-projected-secrets-655a4e5b-2bf0-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:25:12.424: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod pod-projected-secrets-655a4e5b-2bf0-11e9-a551-0a580a020303 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  8 22:25:12.444: INFO: Waiting for pod pod-projected-secrets-655a4e5b-2bf0-11e9-a551-0a580a020303 to disappear
Feb  8 22:25:12.446: INFO: Pod pod-projected-secrets-655a4e5b-2bf0-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:25:12.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bkntn" for this suite.
Feb  8 22:25:18.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:25:18.507: INFO: namespace: e2e-tests-projected-bkntn, resource: bindings, ignored listing per whitelist
Feb  8 22:25:18.543: INFO: namespace e2e-tests-projected-bkntn deletion completed in 6.094542974s

• [SLOW TEST:8.192 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:25:18.543: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb  8 22:25:23.120: INFO: Successfully updated pod "pod-update-6a3b3468-2bf0-11e9-a551-0a580a020303"
STEP: verifying the updated pod is in kubernetes
Feb  8 22:25:23.124: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:25:23.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-pkhts" for this suite.
Feb  8 22:25:45.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:25:45.195: INFO: namespace: e2e-tests-pods-pkhts, resource: bindings, ignored listing per whitelist
Feb  8 22:25:45.219: INFO: namespace e2e-tests-pods-pkhts deletion completed in 22.09140372s

• [SLOW TEST:26.676 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:25:45.219: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb  8 22:25:47.814: INFO: Successfully updated pod "labelsupdate7a222d37-2bf0-11e9-a551-0a580a020303"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:25:49.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wk7nn" for this suite.
Feb  8 22:26:11.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:26:11.912: INFO: namespace: e2e-tests-projected-wk7nn, resource: bindings, ignored listing per whitelist
Feb  8 22:26:11.916: INFO: namespace e2e-tests-projected-wk7nn deletion completed in 22.084833934s

• [SLOW TEST:26.697 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:26:11.916: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Feb  8 22:26:11.970: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb  8 22:26:11.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 create -f - --namespace=e2e-tests-kubectl-lhms8'
Feb  8 22:26:12.322: INFO: stderr: ""
Feb  8 22:26:12.322: INFO: stdout: "service/redis-slave created\n"
Feb  8 22:26:12.322: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb  8 22:26:12.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 create -f - --namespace=e2e-tests-kubectl-lhms8'
Feb  8 22:26:12.496: INFO: stderr: ""
Feb  8 22:26:12.497: INFO: stdout: "service/redis-master created\n"
Feb  8 22:26:12.497: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb  8 22:26:12.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 create -f - --namespace=e2e-tests-kubectl-lhms8'
Feb  8 22:26:12.665: INFO: stderr: ""
Feb  8 22:26:12.665: INFO: stdout: "service/frontend created\n"
Feb  8 22:26:12.665: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb  8 22:26:12.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 create -f - --namespace=e2e-tests-kubectl-lhms8'
Feb  8 22:26:12.848: INFO: stderr: ""
Feb  8 22:26:12.848: INFO: stdout: "deployment.extensions/frontend created\n"
Feb  8 22:26:12.849: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb  8 22:26:12.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 create -f - --namespace=e2e-tests-kubectl-lhms8'
Feb  8 22:26:13.013: INFO: stderr: ""
Feb  8 22:26:13.013: INFO: stdout: "deployment.extensions/redis-master created\n"
Feb  8 22:26:13.013: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb  8 22:26:13.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 create -f - --namespace=e2e-tests-kubectl-lhms8'
Feb  8 22:26:13.188: INFO: stderr: ""
Feb  8 22:26:13.188: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Feb  8 22:26:13.188: INFO: Waiting for all frontend pods to be Running.
Feb  8 22:26:23.239: INFO: Waiting for frontend to serve content.
Feb  8 22:26:28.257: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Feb  8 22:26:33.271: INFO: Trying to add a new entry to the guestbook.
Feb  8 22:26:33.282: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Feb  8 22:26:33.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-lhms8'
Feb  8 22:26:33.390: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  8 22:26:33.390: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb  8 22:26:33.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-lhms8'
Feb  8 22:26:33.490: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  8 22:26:33.490: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb  8 22:26:33.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-lhms8'
Feb  8 22:26:33.602: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  8 22:26:33.602: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb  8 22:26:33.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-lhms8'
Feb  8 22:26:33.690: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  8 22:26:33.690: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb  8 22:26:33.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-lhms8'
Feb  8 22:26:33.799: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  8 22:26:33.799: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb  8 22:26:33.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-lhms8'
Feb  8 22:26:33.934: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  8 22:26:33.934: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:26:33.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lhms8" for this suite.
Feb  8 22:27:11.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:27:12.010: INFO: namespace: e2e-tests-kubectl-lhms8, resource: bindings, ignored listing per whitelist
Feb  8 22:27:12.033: INFO: namespace e2e-tests-kubectl-lhms8 deletion completed in 38.095541103s

• [SLOW TEST:60.117 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:27:12.033: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-qth69/secret-test-ade0e769-2bf0-11e9-a551-0a580a020303
STEP: Creating a pod to test consume secrets
Feb  8 22:27:12.094: INFO: Waiting up to 5m0s for pod "pod-configmaps-ade1603a-2bf0-11e9-a551-0a580a020303" in namespace "e2e-tests-secrets-qth69" to be "success or failure"
Feb  8 22:27:12.098: INFO: Pod "pod-configmaps-ade1603a-2bf0-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 3.970237ms
Feb  8 22:27:14.101: INFO: Pod "pod-configmaps-ade1603a-2bf0-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007382937s
Feb  8 22:27:16.104: INFO: Pod "pod-configmaps-ade1603a-2bf0-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010351799s
STEP: Saw pod success
Feb  8 22:27:16.104: INFO: Pod "pod-configmaps-ade1603a-2bf0-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:27:16.106: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod pod-configmaps-ade1603a-2bf0-11e9-a551-0a580a020303 container env-test: <nil>
STEP: delete the pod
Feb  8 22:27:16.126: INFO: Waiting for pod pod-configmaps-ade1603a-2bf0-11e9-a551-0a580a020303 to disappear
Feb  8 22:27:16.128: INFO: Pod pod-configmaps-ade1603a-2bf0-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:27:16.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-qth69" for this suite.
Feb  8 22:27:22.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:27:22.202: INFO: namespace: e2e-tests-secrets-qth69, resource: bindings, ignored listing per whitelist
Feb  8 22:27:22.217: INFO: namespace e2e-tests-secrets-qth69 deletion completed in 6.085366253s

• [SLOW TEST:10.184 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:27:22.217: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-96ssj
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  8 22:27:22.269: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  8 22:27:44.352: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.2.3.12:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-96ssj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  8 22:27:44.352: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
Feb  8 22:27:44.490: INFO: Found all expected endpoints: [netserver-0]
Feb  8 22:27:44.493: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.2.1.30:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-96ssj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  8 22:27:44.493: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
Feb  8 22:27:44.634: INFO: Found all expected endpoints: [netserver-1]
Feb  8 22:27:44.637: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.2.2.20:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-96ssj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  8 22:27:44.637: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
Feb  8 22:27:44.755: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:27:44.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-96ssj" for this suite.
Feb  8 22:28:06.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:28:06.800: INFO: namespace: e2e-tests-pod-network-test-96ssj, resource: bindings, ignored listing per whitelist
Feb  8 22:28:06.848: INFO: namespace e2e-tests-pod-network-test-96ssj deletion completed in 22.083004127s

• [SLOW TEST:44.631 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:28:06.849: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:28:06.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-h8h59" for this suite.
Feb  8 22:28:28.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:28:28.948: INFO: namespace: e2e-tests-pods-h8h59, resource: bindings, ignored listing per whitelist
Feb  8 22:28:29.000: INFO: namespace e2e-tests-pods-h8h59 deletion completed in 22.088283842s

• [SLOW TEST:22.151 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:28:29.000: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-dbc155d8-2bf0-11e9-a551-0a580a020303
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-dbc155d8-2bf0-11e9-a551-0a580a020303
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:28:35.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9hqvv" for this suite.
Feb  8 22:28:57.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:28:57.184: INFO: namespace: e2e-tests-configmap-9hqvv, resource: bindings, ignored listing per whitelist
Feb  8 22:28:57.204: INFO: namespace e2e-tests-configmap-9hqvv deletion completed in 22.090227067s

• [SLOW TEST:28.204 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:28:57.204: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  8 22:28:57.262: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ec90b431-2bf0-11e9-a551-0a580a020303" in namespace "e2e-tests-downward-api-bkcrd" to be "success or failure"
Feb  8 22:28:57.268: INFO: Pod "downwardapi-volume-ec90b431-2bf0-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 5.67277ms
Feb  8 22:28:59.271: INFO: Pod "downwardapi-volume-ec90b431-2bf0-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008194161s
STEP: Saw pod success
Feb  8 22:28:59.271: INFO: Pod "downwardapi-volume-ec90b431-2bf0-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:28:59.273: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod downwardapi-volume-ec90b431-2bf0-11e9-a551-0a580a020303 container client-container: <nil>
STEP: delete the pod
Feb  8 22:28:59.290: INFO: Waiting for pod downwardapi-volume-ec90b431-2bf0-11e9-a551-0a580a020303 to disappear
Feb  8 22:28:59.293: INFO: Pod downwardapi-volume-ec90b431-2bf0-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:28:59.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bkcrd" for this suite.
Feb  8 22:29:05.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:29:05.352: INFO: namespace: e2e-tests-downward-api-bkcrd, resource: bindings, ignored listing per whitelist
Feb  8 22:29:05.397: INFO: namespace e2e-tests-downward-api-bkcrd deletion completed in 6.10126006s

• [SLOW TEST:8.193 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:29:05.397: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb  8 22:29:09.493: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  8 22:29:09.496: INFO: Pod pod-with-poststart-http-hook still exists
Feb  8 22:29:11.496: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  8 22:29:11.499: INFO: Pod pod-with-poststart-http-hook still exists
Feb  8 22:29:13.496: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  8 22:29:13.499: INFO: Pod pod-with-poststart-http-hook still exists
Feb  8 22:29:15.497: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  8 22:29:15.501: INFO: Pod pod-with-poststart-http-hook still exists
Feb  8 22:29:17.496: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  8 22:29:17.500: INFO: Pod pod-with-poststart-http-hook still exists
Feb  8 22:29:19.497: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  8 22:29:19.500: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:29:19.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-zrtts" for this suite.
Feb  8 22:29:41.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:29:41.568: INFO: namespace: e2e-tests-container-lifecycle-hook-zrtts, resource: bindings, ignored listing per whitelist
Feb  8 22:29:41.591: INFO: namespace e2e-tests-container-lifecycle-hook-zrtts deletion completed in 22.087384554s

• [SLOW TEST:36.194 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:29:41.591: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  8 22:29:41.651: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0705de29-2bf1-11e9-a551-0a580a020303" in namespace "e2e-tests-projected-9dhl4" to be "success or failure"
Feb  8 22:29:41.653: INFO: Pod "downwardapi-volume-0705de29-2bf1-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.790897ms
Feb  8 22:29:43.656: INFO: Pod "downwardapi-volume-0705de29-2bf1-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005617165s
STEP: Saw pod success
Feb  8 22:29:43.656: INFO: Pod "downwardapi-volume-0705de29-2bf1-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:29:43.658: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod downwardapi-volume-0705de29-2bf1-11e9-a551-0a580a020303 container client-container: <nil>
STEP: delete the pod
Feb  8 22:29:43.678: INFO: Waiting for pod downwardapi-volume-0705de29-2bf1-11e9-a551-0a580a020303 to disappear
Feb  8 22:29:43.680: INFO: Pod downwardapi-volume-0705de29-2bf1-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:29:43.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9dhl4" for this suite.
Feb  8 22:29:49.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:29:49.735: INFO: namespace: e2e-tests-projected-9dhl4, resource: bindings, ignored listing per whitelist
Feb  8 22:29:49.769: INFO: namespace e2e-tests-projected-9dhl4 deletion completed in 6.08584605s

• [SLOW TEST:8.178 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:29:49.769: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb  8 22:29:52.351: INFO: Successfully updated pod "annotationupdate0be4eecb-2bf1-11e9-a551-0a580a020303"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:29:56.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4k7xn" for this suite.
Feb  8 22:30:18.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:30:18.411: INFO: namespace: e2e-tests-projected-4k7xn, resource: bindings, ignored listing per whitelist
Feb  8 22:30:18.468: INFO: namespace e2e-tests-projected-4k7xn deletion completed in 22.089748349s

• [SLOW TEST:28.700 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:30:18.469: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-zjd2l.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-zjd2l.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-zjd2l.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-zjd2l.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-zjd2l.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-zjd2l.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb  8 22:30:38.616: INFO: DNS probes using e2e-tests-dns-zjd2l/dns-test-1d00fde2-2bf1-11e9-a551-0a580a020303 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:30:38.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-zjd2l" for this suite.
Feb  8 22:30:44.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:30:44.682: INFO: namespace: e2e-tests-dns-zjd2l, resource: bindings, ignored listing per whitelist
Feb  8 22:30:44.717: INFO: namespace e2e-tests-dns-zjd2l deletion completed in 6.085483805s

• [SLOW TEST:26.249 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:30:44.717: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-2ca625d4-2bf1-11e9-a551-0a580a020303
STEP: Creating a pod to test consume configMaps
Feb  8 22:30:44.781: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2ca6b8e9-2bf1-11e9-a551-0a580a020303" in namespace "e2e-tests-projected-5vrrz" to be "success or failure"
Feb  8 22:30:44.783: INFO: Pod "pod-projected-configmaps-2ca6b8e9-2bf1-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.48674ms
Feb  8 22:30:46.787: INFO: Pod "pod-projected-configmaps-2ca6b8e9-2bf1-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006083392s
STEP: Saw pod success
Feb  8 22:30:46.787: INFO: Pod "pod-projected-configmaps-2ca6b8e9-2bf1-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:30:46.789: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod pod-projected-configmaps-2ca6b8e9-2bf1-11e9-a551-0a580a020303 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  8 22:30:46.808: INFO: Waiting for pod pod-projected-configmaps-2ca6b8e9-2bf1-11e9-a551-0a580a020303 to disappear
Feb  8 22:30:46.811: INFO: Pod pod-projected-configmaps-2ca6b8e9-2bf1-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:30:46.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5vrrz" for this suite.
Feb  8 22:30:52.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:30:52.865: INFO: namespace: e2e-tests-projected-5vrrz, resource: bindings, ignored listing per whitelist
Feb  8 22:30:52.897: INFO: namespace e2e-tests-projected-5vrrz deletion completed in 6.083914667s

• [SLOW TEST:8.180 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:30:52.898: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb  8 22:30:52.960: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-vp2k9,SelfLink:/api/v1/namespaces/e2e-tests-watch-vp2k9/configmaps/e2e-watch-test-configmap-a,UID:3187a2ec-2bf1-11e9-a760-02d2eeadbd48,ResourceVersion:3613,Generation:0,CreationTimestamp:2019-02-08 22:30:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  8 22:30:52.960: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-vp2k9,SelfLink:/api/v1/namespaces/e2e-tests-watch-vp2k9/configmaps/e2e-watch-test-configmap-a,UID:3187a2ec-2bf1-11e9-a760-02d2eeadbd48,ResourceVersion:3613,Generation:0,CreationTimestamp:2019-02-08 22:30:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb  8 22:31:02.969: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-vp2k9,SelfLink:/api/v1/namespaces/e2e-tests-watch-vp2k9/configmaps/e2e-watch-test-configmap-a,UID:3187a2ec-2bf1-11e9-a760-02d2eeadbd48,ResourceVersion:3629,Generation:0,CreationTimestamp:2019-02-08 22:30:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb  8 22:31:02.969: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-vp2k9,SelfLink:/api/v1/namespaces/e2e-tests-watch-vp2k9/configmaps/e2e-watch-test-configmap-a,UID:3187a2ec-2bf1-11e9-a760-02d2eeadbd48,ResourceVersion:3629,Generation:0,CreationTimestamp:2019-02-08 22:30:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb  8 22:31:12.977: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-vp2k9,SelfLink:/api/v1/namespaces/e2e-tests-watch-vp2k9/configmaps/e2e-watch-test-configmap-a,UID:3187a2ec-2bf1-11e9-a760-02d2eeadbd48,ResourceVersion:3645,Generation:0,CreationTimestamp:2019-02-08 22:30:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  8 22:31:12.977: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-vp2k9,SelfLink:/api/v1/namespaces/e2e-tests-watch-vp2k9/configmaps/e2e-watch-test-configmap-a,UID:3187a2ec-2bf1-11e9-a760-02d2eeadbd48,ResourceVersion:3645,Generation:0,CreationTimestamp:2019-02-08 22:30:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb  8 22:31:22.985: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-vp2k9,SelfLink:/api/v1/namespaces/e2e-tests-watch-vp2k9/configmaps/e2e-watch-test-configmap-a,UID:3187a2ec-2bf1-11e9-a760-02d2eeadbd48,ResourceVersion:3661,Generation:0,CreationTimestamp:2019-02-08 22:30:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  8 22:31:22.985: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-vp2k9,SelfLink:/api/v1/namespaces/e2e-tests-watch-vp2k9/configmaps/e2e-watch-test-configmap-a,UID:3187a2ec-2bf1-11e9-a760-02d2eeadbd48,ResourceVersion:3661,Generation:0,CreationTimestamp:2019-02-08 22:30:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb  8 22:31:32.992: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-vp2k9,SelfLink:/api/v1/namespaces/e2e-tests-watch-vp2k9/configmaps/e2e-watch-test-configmap-b,UID:49639f92-2bf1-11e9-a760-02d2eeadbd48,ResourceVersion:3677,Generation:0,CreationTimestamp:2019-02-08 22:31:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  8 22:31:32.992: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-vp2k9,SelfLink:/api/v1/namespaces/e2e-tests-watch-vp2k9/configmaps/e2e-watch-test-configmap-b,UID:49639f92-2bf1-11e9-a760-02d2eeadbd48,ResourceVersion:3677,Generation:0,CreationTimestamp:2019-02-08 22:31:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb  8 22:31:43.001: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-vp2k9,SelfLink:/api/v1/namespaces/e2e-tests-watch-vp2k9/configmaps/e2e-watch-test-configmap-b,UID:49639f92-2bf1-11e9-a760-02d2eeadbd48,ResourceVersion:3693,Generation:0,CreationTimestamp:2019-02-08 22:31:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  8 22:31:43.001: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-vp2k9,SelfLink:/api/v1/namespaces/e2e-tests-watch-vp2k9/configmaps/e2e-watch-test-configmap-b,UID:49639f92-2bf1-11e9-a760-02d2eeadbd48,ResourceVersion:3693,Generation:0,CreationTimestamp:2019-02-08 22:31:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:31:53.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-vp2k9" for this suite.
Feb  8 22:31:59.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:31:59.078: INFO: namespace: e2e-tests-watch-vp2k9, resource: bindings, ignored listing per whitelist
Feb  8 22:31:59.093: INFO: namespace e2e-tests-watch-vp2k9 deletion completed in 6.08740735s

• [SLOW TEST:66.195 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:31:59.093: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-58faa31f-2bf1-11e9-a551-0a580a020303
STEP: Creating a pod to test consume configMaps
Feb  8 22:31:59.156: INFO: Waiting up to 5m0s for pod "pod-configmaps-58fb3222-2bf1-11e9-a551-0a580a020303" in namespace "e2e-tests-configmap-s6rzd" to be "success or failure"
Feb  8 22:31:59.160: INFO: Pod "pod-configmaps-58fb3222-2bf1-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 4.20625ms
Feb  8 22:32:01.164: INFO: Pod "pod-configmaps-58fb3222-2bf1-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008013102s
STEP: Saw pod success
Feb  8 22:32:01.164: INFO: Pod "pod-configmaps-58fb3222-2bf1-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:32:01.167: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod pod-configmaps-58fb3222-2bf1-11e9-a551-0a580a020303 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  8 22:32:01.186: INFO: Waiting for pod pod-configmaps-58fb3222-2bf1-11e9-a551-0a580a020303 to disappear
Feb  8 22:32:01.188: INFO: Pod pod-configmaps-58fb3222-2bf1-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:32:01.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-s6rzd" for this suite.
Feb  8 22:32:07.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:32:07.214: INFO: namespace: e2e-tests-configmap-s6rzd, resource: bindings, ignored listing per whitelist
Feb  8 22:32:07.279: INFO: namespace e2e-tests-configmap-s6rzd deletion completed in 6.087440775s

• [SLOW TEST:8.187 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:32:07.280: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Feb  8 22:32:07.335: INFO: Waiting up to 5m0s for pod "pod-5ddb6f0a-2bf1-11e9-a551-0a580a020303" in namespace "e2e-tests-emptydir-tcvx8" to be "success or failure"
Feb  8 22:32:07.338: INFO: Pod "pod-5ddb6f0a-2bf1-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.685444ms
Feb  8 22:32:09.341: INFO: Pod "pod-5ddb6f0a-2bf1-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006094401s
STEP: Saw pod success
Feb  8 22:32:09.341: INFO: Pod "pod-5ddb6f0a-2bf1-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:32:09.343: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod pod-5ddb6f0a-2bf1-11e9-a551-0a580a020303 container test-container: <nil>
STEP: delete the pod
Feb  8 22:32:09.361: INFO: Waiting for pod pod-5ddb6f0a-2bf1-11e9-a551-0a580a020303 to disappear
Feb  8 22:32:09.364: INFO: Pod pod-5ddb6f0a-2bf1-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:32:09.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-tcvx8" for this suite.
Feb  8 22:32:15.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:32:15.410: INFO: namespace: e2e-tests-emptydir-tcvx8, resource: bindings, ignored listing per whitelist
Feb  8 22:32:15.457: INFO: namespace e2e-tests-emptydir-tcvx8 deletion completed in 6.089751993s

• [SLOW TEST:8.178 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:32:15.457: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Feb  8 22:32:17.527: INFO: Pod pod-hostip-62bbe292-2bf1-11e9-a551-0a580a020303 has hostIP: 172.23.7.130
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:32:17.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-sthr6" for this suite.
Feb  8 22:32:39.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:32:39.601: INFO: namespace: e2e-tests-pods-sthr6, resource: bindings, ignored listing per whitelist
Feb  8 22:32:39.615: INFO: namespace e2e-tests-pods-sthr6 deletion completed in 22.084826385s

• [SLOW TEST:24.158 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:32:39.615: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-pdmdj
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-pdmdj to expose endpoints map[]
Feb  8 22:32:39.681: INFO: Get endpoints failed (4.747471ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Feb  8 22:32:40.684: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-pdmdj exposes endpoints map[] (1.00810034s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-pdmdj
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-pdmdj to expose endpoints map[pod1:[100]]
Feb  8 22:32:41.703: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-pdmdj exposes endpoints map[pod1:[100]] (1.012128261s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-pdmdj
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-pdmdj to expose endpoints map[pod1:[100] pod2:[101]]
Feb  8 22:32:43.732: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-pdmdj exposes endpoints map[pod1:[100] pod2:[101]] (2.023531713s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-pdmdj
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-pdmdj to expose endpoints map[pod2:[101]]
Feb  8 22:32:43.750: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-pdmdj exposes endpoints map[pod2:[101]] (9.965575ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-pdmdj
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-pdmdj to expose endpoints map[]
Feb  8 22:32:44.767: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-pdmdj exposes endpoints map[] (1.006273107s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:32:44.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-pdmdj" for this suite.
Feb  8 22:33:06.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:33:06.871: INFO: namespace: e2e-tests-services-pdmdj, resource: bindings, ignored listing per whitelist
Feb  8 22:33:06.882: INFO: namespace e2e-tests-services-pdmdj deletion completed in 22.081020123s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:27.266 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:33:06.882: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Feb  8 22:33:06.943: INFO: Waiting up to 5m0s for pod "var-expansion-8162b250-2bf1-11e9-a551-0a580a020303" in namespace "e2e-tests-var-expansion-chs65" to be "success or failure"
Feb  8 22:33:06.946: INFO: Pod "var-expansion-8162b250-2bf1-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 3.109498ms
Feb  8 22:33:08.952: INFO: Pod "var-expansion-8162b250-2bf1-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009306819s
STEP: Saw pod success
Feb  8 22:33:08.952: INFO: Pod "var-expansion-8162b250-2bf1-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:33:08.954: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod var-expansion-8162b250-2bf1-11e9-a551-0a580a020303 container dapi-container: <nil>
STEP: delete the pod
Feb  8 22:33:08.972: INFO: Waiting for pod var-expansion-8162b250-2bf1-11e9-a551-0a580a020303 to disappear
Feb  8 22:33:08.975: INFO: Pod var-expansion-8162b250-2bf1-11e9-a551-0a580a020303 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:33:08.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-chs65" for this suite.
Feb  8 22:33:14.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:33:15.060: INFO: namespace: e2e-tests-var-expansion-chs65, resource: bindings, ignored listing per whitelist
Feb  8 22:33:15.064: INFO: namespace e2e-tests-var-expansion-chs65 deletion completed in 6.084255304s

• [SLOW TEST:8.182 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:33:15.064: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb  8 22:33:15.126: INFO: Waiting up to 5m0s for pod "pod-8643a902-2bf1-11e9-a551-0a580a020303" in namespace "e2e-tests-emptydir-d2jfm" to be "success or failure"
Feb  8 22:33:15.132: INFO: Pod "pod-8643a902-2bf1-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 5.760319ms
Feb  8 22:33:17.135: INFO: Pod "pod-8643a902-2bf1-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009330291s
Feb  8 22:33:19.138: INFO: Pod "pod-8643a902-2bf1-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01206379s
STEP: Saw pod success
Feb  8 22:33:19.138: INFO: Pod "pod-8643a902-2bf1-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:33:19.140: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod pod-8643a902-2bf1-11e9-a551-0a580a020303 container test-container: <nil>
STEP: delete the pod
Feb  8 22:33:19.165: INFO: Waiting for pod pod-8643a902-2bf1-11e9-a551-0a580a020303 to disappear
Feb  8 22:33:19.167: INFO: Pod pod-8643a902-2bf1-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:33:19.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-d2jfm" for this suite.
Feb  8 22:33:25.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:33:25.196: INFO: namespace: e2e-tests-emptydir-d2jfm, resource: bindings, ignored listing per whitelist
Feb  8 22:33:25.258: INFO: namespace e2e-tests-emptydir-d2jfm deletion completed in 6.087907215s

• [SLOW TEST:10.195 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:33:25.259: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb  8 22:33:29.339: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-lrk9z PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  8 22:33:29.339: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
Feb  8 22:33:29.452: INFO: Exec stderr: ""
Feb  8 22:33:29.452: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-lrk9z PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  8 22:33:29.452: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
Feb  8 22:33:29.563: INFO: Exec stderr: ""
Feb  8 22:33:29.563: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-lrk9z PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  8 22:33:29.563: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
Feb  8 22:33:29.665: INFO: Exec stderr: ""
Feb  8 22:33:29.665: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-lrk9z PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  8 22:33:29.665: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
Feb  8 22:33:29.775: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb  8 22:33:29.775: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-lrk9z PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  8 22:33:29.775: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
Feb  8 22:33:29.900: INFO: Exec stderr: ""
Feb  8 22:33:29.900: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-lrk9z PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  8 22:33:29.900: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
Feb  8 22:33:30.020: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb  8 22:33:30.020: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-lrk9z PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  8 22:33:30.020: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
Feb  8 22:33:30.139: INFO: Exec stderr: ""
Feb  8 22:33:30.139: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-lrk9z PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  8 22:33:30.139: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
Feb  8 22:33:30.265: INFO: Exec stderr: ""
Feb  8 22:33:30.265: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-lrk9z PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  8 22:33:30.265: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
Feb  8 22:33:30.393: INFO: Exec stderr: ""
Feb  8 22:33:30.393: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-lrk9z PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  8 22:33:30.393: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
Feb  8 22:33:30.518: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:33:30.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-lrk9z" for this suite.
Feb  8 22:34:24.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:34:24.590: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-lrk9z, resource: bindings, ignored listing per whitelist
Feb  8 22:34:24.612: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-lrk9z deletion completed in 54.09016671s

• [SLOW TEST:59.353 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:34:24.612: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Feb  8 22:34:24.676: INFO: Waiting up to 5m0s for pod "var-expansion-afb83202-2bf1-11e9-a551-0a580a020303" in namespace "e2e-tests-var-expansion-nvxz6" to be "success or failure"
Feb  8 22:34:24.678: INFO: Pod "var-expansion-afb83202-2bf1-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.499457ms
Feb  8 22:34:26.681: INFO: Pod "var-expansion-afb83202-2bf1-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005374407s
STEP: Saw pod success
Feb  8 22:34:26.681: INFO: Pod "var-expansion-afb83202-2bf1-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:34:26.683: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod var-expansion-afb83202-2bf1-11e9-a551-0a580a020303 container dapi-container: <nil>
STEP: delete the pod
Feb  8 22:34:26.703: INFO: Waiting for pod var-expansion-afb83202-2bf1-11e9-a551-0a580a020303 to disappear
Feb  8 22:34:26.705: INFO: Pod var-expansion-afb83202-2bf1-11e9-a551-0a580a020303 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:34:26.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-nvxz6" for this suite.
Feb  8 22:34:32.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:34:32.761: INFO: namespace: e2e-tests-var-expansion-nvxz6, resource: bindings, ignored listing per whitelist
Feb  8 22:34:32.795: INFO: namespace e2e-tests-var-expansion-nvxz6 deletion completed in 6.086979745s

• [SLOW TEST:8.183 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:34:32.795: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb  8 22:34:32.859: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-dg2f6,SelfLink:/api/v1/namespaces/e2e-tests-watch-dg2f6/configmaps/e2e-watch-test-label-changed,UID:b497ba5a-2bf1-11e9-a760-02d2eeadbd48,ResourceVersion:4224,Generation:0,CreationTimestamp:2019-02-08 22:34:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  8 22:34:32.859: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-dg2f6,SelfLink:/api/v1/namespaces/e2e-tests-watch-dg2f6/configmaps/e2e-watch-test-label-changed,UID:b497ba5a-2bf1-11e9-a760-02d2eeadbd48,ResourceVersion:4225,Generation:0,CreationTimestamp:2019-02-08 22:34:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb  8 22:34:32.859: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-dg2f6,SelfLink:/api/v1/namespaces/e2e-tests-watch-dg2f6/configmaps/e2e-watch-test-label-changed,UID:b497ba5a-2bf1-11e9-a760-02d2eeadbd48,ResourceVersion:4226,Generation:0,CreationTimestamp:2019-02-08 22:34:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb  8 22:34:42.884: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-dg2f6,SelfLink:/api/v1/namespaces/e2e-tests-watch-dg2f6/configmaps/e2e-watch-test-label-changed,UID:b497ba5a-2bf1-11e9-a760-02d2eeadbd48,ResourceVersion:4243,Generation:0,CreationTimestamp:2019-02-08 22:34:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  8 22:34:42.884: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-dg2f6,SelfLink:/api/v1/namespaces/e2e-tests-watch-dg2f6/configmaps/e2e-watch-test-label-changed,UID:b497ba5a-2bf1-11e9-a760-02d2eeadbd48,ResourceVersion:4244,Generation:0,CreationTimestamp:2019-02-08 22:34:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb  8 22:34:42.884: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-dg2f6,SelfLink:/api/v1/namespaces/e2e-tests-watch-dg2f6/configmaps/e2e-watch-test-label-changed,UID:b497ba5a-2bf1-11e9-a760-02d2eeadbd48,ResourceVersion:4245,Generation:0,CreationTimestamp:2019-02-08 22:34:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:34:42.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-dg2f6" for this suite.
Feb  8 22:34:48.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:34:48.969: INFO: namespace: e2e-tests-watch-dg2f6, resource: bindings, ignored listing per whitelist
Feb  8 22:34:48.988: INFO: namespace e2e-tests-watch-dg2f6 deletion completed in 6.100813219s

• [SLOW TEST:16.193 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:34:48.988: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Feb  8 22:34:49.064: INFO: Waiting up to 5m0s for pod "client-containers-be415b52-2bf1-11e9-a551-0a580a020303" in namespace "e2e-tests-containers-7q76z" to be "success or failure"
Feb  8 22:34:49.077: INFO: Pod "client-containers-be415b52-2bf1-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 12.605776ms
Feb  8 22:34:51.081: INFO: Pod "client-containers-be415b52-2bf1-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016153649s
Feb  8 22:34:53.084: INFO: Pod "client-containers-be415b52-2bf1-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019761129s
STEP: Saw pod success
Feb  8 22:34:53.084: INFO: Pod "client-containers-be415b52-2bf1-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:34:53.086: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod client-containers-be415b52-2bf1-11e9-a551-0a580a020303 container test-container: <nil>
STEP: delete the pod
Feb  8 22:34:53.107: INFO: Waiting for pod client-containers-be415b52-2bf1-11e9-a551-0a580a020303 to disappear
Feb  8 22:34:53.109: INFO: Pod client-containers-be415b52-2bf1-11e9-a551-0a580a020303 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:34:53.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-7q76z" for this suite.
Feb  8 22:34:59.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:34:59.199: INFO: namespace: e2e-tests-containers-7q76z, resource: bindings, ignored listing per whitelist
Feb  8 22:34:59.199: INFO: namespace e2e-tests-containers-7q76z deletion completed in 6.086666305s

• [SLOW TEST:10.210 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:34:59.199: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-c45551c6-2bf1-11e9-a551-0a580a020303
STEP: Creating configMap with name cm-test-opt-upd-c45552c6-2bf1-11e9-a551-0a580a020303
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-c45551c6-2bf1-11e9-a551-0a580a020303
STEP: Updating configmap cm-test-opt-upd-c45552c6-2bf1-11e9-a551-0a580a020303
STEP: Creating configMap with name cm-test-opt-create-c45552f0-2bf1-11e9-a551-0a580a020303
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:36:35.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2rvtd" for this suite.
Feb  8 22:36:57.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:36:57.776: INFO: namespace: e2e-tests-projected-2rvtd, resource: bindings, ignored listing per whitelist
Feb  8 22:36:57.815: INFO: namespace e2e-tests-projected-2rvtd deletion completed in 22.083323324s

• [SLOW TEST:118.615 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:36:57.815: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-0b0847d7-2bf2-11e9-a551-0a580a020303
STEP: Creating a pod to test consume configMaps
Feb  8 22:36:57.878: INFO: Waiting up to 5m0s for pod "pod-configmaps-0b08e730-2bf2-11e9-a551-0a580a020303" in namespace "e2e-tests-configmap-w9xzl" to be "success or failure"
Feb  8 22:36:57.881: INFO: Pod "pod-configmaps-0b08e730-2bf2-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.329216ms
Feb  8 22:36:59.884: INFO: Pod "pod-configmaps-0b08e730-2bf2-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005879572s
STEP: Saw pod success
Feb  8 22:36:59.884: INFO: Pod "pod-configmaps-0b08e730-2bf2-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:36:59.886: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod pod-configmaps-0b08e730-2bf2-11e9-a551-0a580a020303 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  8 22:36:59.904: INFO: Waiting for pod pod-configmaps-0b08e730-2bf2-11e9-a551-0a580a020303 to disappear
Feb  8 22:36:59.907: INFO: Pod pod-configmaps-0b08e730-2bf2-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:36:59.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-w9xzl" for this suite.
Feb  8 22:37:05.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:37:05.951: INFO: namespace: e2e-tests-configmap-w9xzl, resource: bindings, ignored listing per whitelist
Feb  8 22:37:06.000: INFO: namespace e2e-tests-configmap-w9xzl deletion completed in 6.089322574s

• [SLOW TEST:8.185 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:37:06.000: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-r4pz2
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-r4pz2
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-r4pz2
Feb  8 22:37:06.070: INFO: Found 0 stateful pods, waiting for 1
Feb  8 22:37:16.079: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb  8 22:37:16.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 exec --namespace=e2e-tests-statefulset-r4pz2 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  8 22:37:16.274: INFO: stderr: ""
Feb  8 22:37:16.274: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  8 22:37:16.274: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  8 22:37:16.277: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb  8 22:37:26.280: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  8 22:37:26.281: INFO: Waiting for statefulset status.replicas updated to 0
Feb  8 22:37:26.296: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999122s
Feb  8 22:37:27.300: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996679914s
Feb  8 22:37:28.303: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.993009034s
Feb  8 22:37:29.307: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.989396655s
Feb  8 22:37:30.310: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.98569431s
Feb  8 22:37:31.314: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.982408559s
Feb  8 22:37:32.317: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.978625355s
Feb  8 22:37:33.321: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.975186273s
Feb  8 22:37:34.325: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.971330554s
Feb  8 22:37:35.328: INFO: Verifying statefulset ss doesn't scale past 1 for another 967.925566ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-r4pz2
Feb  8 22:37:36.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 exec --namespace=e2e-tests-statefulset-r4pz2 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  8 22:37:36.512: INFO: stderr: ""
Feb  8 22:37:36.512: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  8 22:37:36.512: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  8 22:37:36.515: INFO: Found 1 stateful pods, waiting for 3
Feb  8 22:37:46.519: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  8 22:37:46.519: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  8 22:37:46.519: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb  8 22:37:46.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 exec --namespace=e2e-tests-statefulset-r4pz2 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  8 22:37:46.709: INFO: stderr: ""
Feb  8 22:37:46.709: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  8 22:37:46.709: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  8 22:37:46.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 exec --namespace=e2e-tests-statefulset-r4pz2 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  8 22:37:46.911: INFO: stderr: ""
Feb  8 22:37:46.911: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  8 22:37:46.911: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  8 22:37:46.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 exec --namespace=e2e-tests-statefulset-r4pz2 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  8 22:37:47.107: INFO: stderr: ""
Feb  8 22:37:47.107: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  8 22:37:47.107: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  8 22:37:47.107: INFO: Waiting for statefulset status.replicas updated to 0
Feb  8 22:37:47.110: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Feb  8 22:37:57.117: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  8 22:37:57.117: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb  8 22:37:57.117: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb  8 22:37:57.129: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999129s
Feb  8 22:37:58.132: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995684086s
Feb  8 22:37:59.136: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991845026s
Feb  8 22:38:00.140: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.988201281s
Feb  8 22:38:01.144: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.984211529s
Feb  8 22:38:02.148: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.980296416s
Feb  8 22:38:03.152: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.97647698s
Feb  8 22:38:04.156: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.972454496s
Feb  8 22:38:05.160: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.96858394s
Feb  8 22:38:06.163: INFO: Verifying statefulset ss doesn't scale past 3 for another 964.64252ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-r4pz2
Feb  8 22:38:07.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 exec --namespace=e2e-tests-statefulset-r4pz2 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  8 22:38:07.366: INFO: stderr: ""
Feb  8 22:38:07.366: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  8 22:38:07.366: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  8 22:38:07.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 exec --namespace=e2e-tests-statefulset-r4pz2 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  8 22:38:07.557: INFO: stderr: ""
Feb  8 22:38:07.557: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  8 22:38:07.557: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  8 22:38:07.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 exec --namespace=e2e-tests-statefulset-r4pz2 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  8 22:38:07.746: INFO: stderr: ""
Feb  8 22:38:07.746: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  8 22:38:07.746: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  8 22:38:07.746: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  8 22:38:37.758: INFO: Deleting all statefulset in ns e2e-tests-statefulset-r4pz2
Feb  8 22:38:37.761: INFO: Scaling statefulset ss to 0
Feb  8 22:38:37.768: INFO: Waiting for statefulset status.replicas updated to 0
Feb  8 22:38:37.770: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:38:37.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-r4pz2" for this suite.
Feb  8 22:38:43.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:38:43.846: INFO: namespace: e2e-tests-statefulset-r4pz2, resource: bindings, ignored listing per whitelist
Feb  8 22:38:43.873: INFO: namespace e2e-tests-statefulset-r4pz2 deletion completed in 6.087649726s

• [SLOW TEST:97.874 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:38:43.874: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  8 22:38:43.933: INFO: Waiting up to 5m0s for pod "downward-api-4a3f7a8e-2bf2-11e9-a551-0a580a020303" in namespace "e2e-tests-downward-api-rxv8c" to be "success or failure"
Feb  8 22:38:43.936: INFO: Pod "downward-api-4a3f7a8e-2bf2-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.728255ms
Feb  8 22:38:45.940: INFO: Pod "downward-api-4a3f7a8e-2bf2-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006102648s
STEP: Saw pod success
Feb  8 22:38:45.940: INFO: Pod "downward-api-4a3f7a8e-2bf2-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:38:45.942: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod downward-api-4a3f7a8e-2bf2-11e9-a551-0a580a020303 container dapi-container: <nil>
STEP: delete the pod
Feb  8 22:38:45.959: INFO: Waiting for pod downward-api-4a3f7a8e-2bf2-11e9-a551-0a580a020303 to disappear
Feb  8 22:38:45.961: INFO: Pod downward-api-4a3f7a8e-2bf2-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:38:45.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rxv8c" for this suite.
Feb  8 22:38:51.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:38:52.011: INFO: namespace: e2e-tests-downward-api-rxv8c, resource: bindings, ignored listing per whitelist
Feb  8 22:38:52.048: INFO: namespace e2e-tests-downward-api-rxv8c deletion completed in 6.083182738s

• [SLOW TEST:8.174 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:38:52.048: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-d2654
Feb  8 22:38:56.107: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-d2654
STEP: checking the pod's current state and verifying that restartCount is present
Feb  8 22:38:56.109: INFO: Initial restart count of pod liveness-http is 0
Feb  8 22:39:14.144: INFO: Restart count of pod e2e-tests-container-probe-d2654/liveness-http is now 1 (18.034389249s elapsed)
Feb  8 22:39:34.177: INFO: Restart count of pod e2e-tests-container-probe-d2654/liveness-http is now 2 (38.067464549s elapsed)
Feb  8 22:39:54.210: INFO: Restart count of pod e2e-tests-container-probe-d2654/liveness-http is now 3 (58.100679996s elapsed)
Feb  8 22:40:14.243: INFO: Restart count of pod e2e-tests-container-probe-d2654/liveness-http is now 4 (1m18.134122528s elapsed)
Feb  8 22:41:16.487: INFO: Restart count of pod e2e-tests-container-probe-d2654/liveness-http is now 5 (2m20.377864117s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:41:16.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-d2654" for this suite.
Feb  8 22:41:22.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:41:22.569: INFO: namespace: e2e-tests-container-probe-d2654, resource: bindings, ignored listing per whitelist
Feb  8 22:41:22.599: INFO: namespace e2e-tests-container-probe-d2654 deletion completed in 6.093777046s

• [SLOW TEST:150.552 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:41:22.600: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: Gathering metrics
W0208 22:41:23.692347      14 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  8 22:41:23.692: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:41:23.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-zcdkt" for this suite.
Feb  8 22:41:29.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:41:29.724: INFO: namespace: e2e-tests-gc-zcdkt, resource: bindings, ignored listing per whitelist
Feb  8 22:41:29.779: INFO: namespace e2e-tests-gc-zcdkt deletion completed in 6.084051635s

• [SLOW TEST:7.179 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:41:29.779: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  8 22:41:29.835: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Feb  8 22:41:34.839: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb  8 22:41:34.839: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  8 22:41:34.856: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-nbxt5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-nbxt5/deployments/test-cleanup-deployment,UID:b01f7995-2bf2-11e9-a760-02d2eeadbd48,ResourceVersion:5305,Generation:1,CreationTimestamp:2019-02-08 22:41:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Feb  8 22:41:34.859: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:41:34.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-nbxt5" for this suite.
Feb  8 22:41:40.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:41:40.928: INFO: namespace: e2e-tests-deployment-nbxt5, resource: bindings, ignored listing per whitelist
Feb  8 22:41:40.978: INFO: namespace e2e-tests-deployment-nbxt5 deletion completed in 6.102891896s

• [SLOW TEST:11.199 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:41:40.978: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  8 22:41:43.064: INFO: Waiting up to 5m0s for pod "client-envvars-b504b735-2bf2-11e9-a551-0a580a020303" in namespace "e2e-tests-pods-hp6pq" to be "success or failure"
Feb  8 22:41:43.068: INFO: Pod "client-envvars-b504b735-2bf2-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 3.678244ms
Feb  8 22:41:45.071: INFO: Pod "client-envvars-b504b735-2bf2-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007160816s
STEP: Saw pod success
Feb  8 22:41:45.071: INFO: Pod "client-envvars-b504b735-2bf2-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:41:45.073: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod client-envvars-b504b735-2bf2-11e9-a551-0a580a020303 container env3cont: <nil>
STEP: delete the pod
Feb  8 22:41:45.094: INFO: Waiting for pod client-envvars-b504b735-2bf2-11e9-a551-0a580a020303 to disappear
Feb  8 22:41:45.096: INFO: Pod client-envvars-b504b735-2bf2-11e9-a551-0a580a020303 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:41:45.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-hp6pq" for this suite.
Feb  8 22:42:23.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:42:23.187: INFO: namespace: e2e-tests-pods-hp6pq, resource: bindings, ignored listing per whitelist
Feb  8 22:42:23.190: INFO: namespace e2e-tests-pods-hp6pq deletion completed in 38.091385707s

• [SLOW TEST:42.212 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:42:23.191: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-ccf943c5-2bf2-11e9-a551-0a580a020303
STEP: Creating secret with name s-test-opt-upd-ccf94436-2bf2-11e9-a551-0a580a020303
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-ccf943c5-2bf2-11e9-a551-0a580a020303
STEP: Updating secret s-test-opt-upd-ccf94436-2bf2-11e9-a551-0a580a020303
STEP: Creating secret with name s-test-opt-create-ccf94450-2bf2-11e9-a551-0a580a020303
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:43:49.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-4gtc4" for this suite.
Feb  8 22:44:17.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:44:17.740: INFO: namespace: e2e-tests-secrets-4gtc4, resource: bindings, ignored listing per whitelist
Feb  8 22:44:17.764: INFO: namespace e2e-tests-secrets-4gtc4 deletion completed in 28.087553216s

• [SLOW TEST:114.573 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:44:17.764: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0208 22:44:27.879558      14 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  8 22:44:27.879: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:44:27.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-6lswf" for this suite.
Feb  8 22:44:33.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:44:33.946: INFO: namespace: e2e-tests-gc-6lswf, resource: bindings, ignored listing per whitelist
Feb  8 22:44:33.977: INFO: namespace e2e-tests-gc-6lswf deletion completed in 6.09459981s

• [SLOW TEST:16.213 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:44:33.977: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-hpl6
STEP: Creating a pod to test atomic-volume-subpath
Feb  8 22:44:34.053: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-hpl6" in namespace "e2e-tests-subpath-8qzqw" to be "success or failure"
Feb  8 22:44:34.056: INFO: Pod "pod-subpath-test-configmap-hpl6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.518295ms
Feb  8 22:44:36.060: INFO: Pod "pod-subpath-test-configmap-hpl6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006292627s
Feb  8 22:44:38.063: INFO: Pod "pod-subpath-test-configmap-hpl6": Phase="Running", Reason="", readiness=false. Elapsed: 4.010111347s
Feb  8 22:44:40.067: INFO: Pod "pod-subpath-test-configmap-hpl6": Phase="Running", Reason="", readiness=false. Elapsed: 6.01388011s
Feb  8 22:44:42.070: INFO: Pod "pod-subpath-test-configmap-hpl6": Phase="Running", Reason="", readiness=false. Elapsed: 8.017218377s
Feb  8 22:44:44.074: INFO: Pod "pod-subpath-test-configmap-hpl6": Phase="Running", Reason="", readiness=false. Elapsed: 10.020801427s
Feb  8 22:44:46.077: INFO: Pod "pod-subpath-test-configmap-hpl6": Phase="Running", Reason="", readiness=false. Elapsed: 12.024123748s
Feb  8 22:44:48.080: INFO: Pod "pod-subpath-test-configmap-hpl6": Phase="Running", Reason="", readiness=false. Elapsed: 14.02719187s
Feb  8 22:44:50.084: INFO: Pod "pod-subpath-test-configmap-hpl6": Phase="Running", Reason="", readiness=false. Elapsed: 16.030807736s
Feb  8 22:44:52.088: INFO: Pod "pod-subpath-test-configmap-hpl6": Phase="Running", Reason="", readiness=false. Elapsed: 18.034245831s
Feb  8 22:44:54.091: INFO: Pod "pod-subpath-test-configmap-hpl6": Phase="Running", Reason="", readiness=false. Elapsed: 20.037450339s
Feb  8 22:44:56.094: INFO: Pod "pod-subpath-test-configmap-hpl6": Phase="Running", Reason="", readiness=false. Elapsed: 22.040765348s
Feb  8 22:44:58.098: INFO: Pod "pod-subpath-test-configmap-hpl6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.044342999s
STEP: Saw pod success
Feb  8 22:44:58.098: INFO: Pod "pod-subpath-test-configmap-hpl6" satisfied condition "success or failure"
Feb  8 22:44:58.100: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod pod-subpath-test-configmap-hpl6 container test-container-subpath-configmap-hpl6: <nil>
STEP: delete the pod
Feb  8 22:44:58.119: INFO: Waiting for pod pod-subpath-test-configmap-hpl6 to disappear
Feb  8 22:44:58.121: INFO: Pod pod-subpath-test-configmap-hpl6 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-hpl6
Feb  8 22:44:58.121: INFO: Deleting pod "pod-subpath-test-configmap-hpl6" in namespace "e2e-tests-subpath-8qzqw"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:44:58.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-8qzqw" for this suite.
Feb  8 22:45:04.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:45:04.203: INFO: namespace: e2e-tests-subpath-8qzqw, resource: bindings, ignored listing per whitelist
Feb  8 22:45:04.216: INFO: namespace e2e-tests-subpath-8qzqw deletion completed in 6.089440635s

• [SLOW TEST:30.238 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:45:04.216: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Feb  8 22:45:04.270: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  8 22:45:04.277: INFO: Waiting for terminating namespaces to be deleted...
Feb  8 22:45:04.279: INFO: 
Logging pods the kubelet thinks is on node ip-172-23-7-110.us-west-2.compute.internal before test
Feb  8 22:45:04.284: INFO: kube-flannel-ds-5cwbb from kube-system started at 2019-02-08 22:14:48 +0000 UTC (1 container statuses recorded)
Feb  8 22:45:04.284: INFO: 	Container kube-flannel ready: true, restart count 0
Feb  8 22:45:04.284: INFO: kube-proxy-74ndc from kube-system started at 2019-02-08 22:14:48 +0000 UTC (1 container statuses recorded)
Feb  8 22:45:04.284: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  8 22:45:04.284: INFO: tiller-deploy-6fb6d4777d-pswxg from kube-system started at 2019-02-08 22:15:35 +0000 UTC (1 container statuses recorded)
Feb  8 22:45:04.284: INFO: 	Container tiller ready: true, restart count 0
Feb  8 22:45:04.284: INFO: sonobuoy-systemd-logs-daemon-set-97ae410a3d2d4a52-tsw98 from heptio-sonobuoy started at 2019-02-08 22:19:47 +0000 UTC (2 container statuses recorded)
Feb  8 22:45:04.284: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb  8 22:45:04.284: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  8 22:45:04.284: INFO: 
Logging pods the kubelet thinks is on node ip-172-23-7-130.us-west-2.compute.internal before test
Feb  8 22:45:04.290: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-08 22:19:44 +0000 UTC (1 container statuses recorded)
Feb  8 22:45:04.290: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb  8 22:45:04.290: INFO: kube-flannel-ds-hbllw from kube-system started at 2019-02-08 22:14:48 +0000 UTC (1 container statuses recorded)
Feb  8 22:45:04.290: INFO: 	Container kube-flannel ready: true, restart count 0
Feb  8 22:45:04.290: INFO: kube-proxy-4fjpj from kube-system started at 2019-02-08 22:14:48 +0000 UTC (1 container statuses recorded)
Feb  8 22:45:04.290: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  8 22:45:04.290: INFO: kubernetes-dashboard-778d4ccc65-2mgbl from kube-system started at 2019-02-08 22:16:05 +0000 UTC (1 container statuses recorded)
Feb  8 22:45:04.290: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb  8 22:45:04.290: INFO: sonobuoy-systemd-logs-daemon-set-97ae410a3d2d4a52-rhwxj from heptio-sonobuoy started at 2019-02-08 22:19:47 +0000 UTC (2 container statuses recorded)
Feb  8 22:45:04.290: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb  8 22:45:04.290: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  8 22:45:04.290: INFO: 
Logging pods the kubelet thinks is on node ip-172-23-7-34.us-west-2.compute.internal before test
Feb  8 22:45:04.306: INFO: kube-flannel-ds-n6skb from kube-system started at 2019-02-08 22:14:48 +0000 UTC (1 container statuses recorded)
Feb  8 22:45:04.306: INFO: 	Container kube-flannel ready: true, restart count 0
Feb  8 22:45:04.306: INFO: kube-proxy-c97zb from kube-system started at 2019-02-08 22:14:48 +0000 UTC (1 container statuses recorded)
Feb  8 22:45:04.306: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  8 22:45:04.306: INFO: heapster-5459947ccc-rlxzx from kube-system started at 2019-02-08 22:16:05 +0000 UTC (1 container statuses recorded)
Feb  8 22:45:04.306: INFO: 	Container heapster ready: true, restart count 0
Feb  8 22:45:04.306: INFO: sonobuoy-e2e-job-3bb448efb05f49ae from heptio-sonobuoy started at 2019-02-08 22:19:47 +0000 UTC (2 container statuses recorded)
Feb  8 22:45:04.306: INFO: 	Container e2e ready: true, restart count 0
Feb  8 22:45:04.306: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  8 22:45:04.306: INFO: sonobuoy-systemd-logs-daemon-set-97ae410a3d2d4a52-vzm9c from heptio-sonobuoy started at 2019-02-08 22:19:47 +0000 UTC (2 container statuses recorded)
Feb  8 22:45:04.306: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb  8 22:45:04.306: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node ip-172-23-7-110.us-west-2.compute.internal
STEP: verifying the node has the label node ip-172-23-7-130.us-west-2.compute.internal
STEP: verifying the node has the label node ip-172-23-7-34.us-west-2.compute.internal
Feb  8 22:45:04.350: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-23-7-130.us-west-2.compute.internal
Feb  8 22:45:04.350: INFO: Pod sonobuoy-e2e-job-3bb448efb05f49ae requesting resource cpu=0m on Node ip-172-23-7-34.us-west-2.compute.internal
Feb  8 22:45:04.350: INFO: Pod sonobuoy-systemd-logs-daemon-set-97ae410a3d2d4a52-rhwxj requesting resource cpu=0m on Node ip-172-23-7-130.us-west-2.compute.internal
Feb  8 22:45:04.350: INFO: Pod sonobuoy-systemd-logs-daemon-set-97ae410a3d2d4a52-tsw98 requesting resource cpu=0m on Node ip-172-23-7-110.us-west-2.compute.internal
Feb  8 22:45:04.350: INFO: Pod sonobuoy-systemd-logs-daemon-set-97ae410a3d2d4a52-vzm9c requesting resource cpu=0m on Node ip-172-23-7-34.us-west-2.compute.internal
Feb  8 22:45:04.350: INFO: Pod heapster-5459947ccc-rlxzx requesting resource cpu=0m on Node ip-172-23-7-34.us-west-2.compute.internal
Feb  8 22:45:04.350: INFO: Pod kube-flannel-ds-5cwbb requesting resource cpu=100m on Node ip-172-23-7-110.us-west-2.compute.internal
Feb  8 22:45:04.350: INFO: Pod kube-flannel-ds-hbllw requesting resource cpu=100m on Node ip-172-23-7-130.us-west-2.compute.internal
Feb  8 22:45:04.350: INFO: Pod kube-flannel-ds-n6skb requesting resource cpu=100m on Node ip-172-23-7-34.us-west-2.compute.internal
Feb  8 22:45:04.350: INFO: Pod kube-proxy-4fjpj requesting resource cpu=0m on Node ip-172-23-7-130.us-west-2.compute.internal
Feb  8 22:45:04.350: INFO: Pod kube-proxy-74ndc requesting resource cpu=0m on Node ip-172-23-7-110.us-west-2.compute.internal
Feb  8 22:45:04.350: INFO: Pod kube-proxy-c97zb requesting resource cpu=0m on Node ip-172-23-7-34.us-west-2.compute.internal
Feb  8 22:45:04.350: INFO: Pod kubernetes-dashboard-778d4ccc65-2mgbl requesting resource cpu=0m on Node ip-172-23-7-130.us-west-2.compute.internal
Feb  8 22:45:04.350: INFO: Pod tiller-deploy-6fb6d4777d-pswxg requesting resource cpu=0m on Node ip-172-23-7-110.us-west-2.compute.internal
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2cff86de-2bf3-11e9-a551-0a580a020303.158184edf61abdee], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-rvqgv/filler-pod-2cff86de-2bf3-11e9-a551-0a580a020303 to ip-172-23-7-110.us-west-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2cff86de-2bf3-11e9-a551-0a580a020303.158184ee1dab8f04], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2cff86de-2bf3-11e9-a551-0a580a020303.158184ee2092cc37], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2cff86de-2bf3-11e9-a551-0a580a020303.158184ee3088e52a], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2d007c7e-2bf3-11e9-a551-0a580a020303.158184edf6bf1993], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-rvqgv/filler-pod-2d007c7e-2bf3-11e9-a551-0a580a020303 to ip-172-23-7-130.us-west-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2d007c7e-2bf3-11e9-a551-0a580a020303.158184ee21b6235d], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2d007c7e-2bf3-11e9-a551-0a580a020303.158184ee23f719ed], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2d007c7e-2bf3-11e9-a551-0a580a020303.158184ee33531c4e], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2d01a840-2bf3-11e9-a551-0a580a020303.158184edf758dbc4], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-rvqgv/filler-pod-2d01a840-2bf3-11e9-a551-0a580a020303 to ip-172-23-7-34.us-west-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2d01a840-2bf3-11e9-a551-0a580a020303.158184ee1da6896f], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2d01a840-2bf3-11e9-a551-0a580a020303.158184ee200d14c6], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2d01a840-2bf3-11e9-a551-0a580a020303.158184ee2f51998e], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.158184ee6f1e4fe1], Reason = [FailedScheduling], Message = [0/4 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 3 Insufficient cpu.]
STEP: removing the label node off the node ip-172-23-7-130.us-west-2.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-172-23-7-34.us-west-2.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-172-23-7-110.us-west-2.compute.internal
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:45:07.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-rvqgv" for this suite.
Feb  8 22:45:13.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:45:13.460: INFO: namespace: e2e-tests-sched-pred-rvqgv, resource: bindings, ignored listing per whitelist
Feb  8 22:45:13.529: INFO: namespace e2e-tests-sched-pred-rvqgv deletion completed in 6.085732154s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:9.313 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:45:13.529: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-328052d1-2bf3-11e9-a551-0a580a020303
STEP: Creating a pod to test consume secrets
Feb  8 22:45:13.592: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3280cb22-2bf3-11e9-a551-0a580a020303" in namespace "e2e-tests-projected-dqlzl" to be "success or failure"
Feb  8 22:45:13.594: INFO: Pod "pod-projected-secrets-3280cb22-2bf3-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.47048ms
Feb  8 22:45:15.597: INFO: Pod "pod-projected-secrets-3280cb22-2bf3-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005836652s
STEP: Saw pod success
Feb  8 22:45:15.597: INFO: Pod "pod-projected-secrets-3280cb22-2bf3-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:45:15.600: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod pod-projected-secrets-3280cb22-2bf3-11e9-a551-0a580a020303 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  8 22:45:15.617: INFO: Waiting for pod pod-projected-secrets-3280cb22-2bf3-11e9-a551-0a580a020303 to disappear
Feb  8 22:45:15.620: INFO: Pod pod-projected-secrets-3280cb22-2bf3-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:45:15.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dqlzl" for this suite.
Feb  8 22:45:21.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:45:21.704: INFO: namespace: e2e-tests-projected-dqlzl, resource: bindings, ignored listing per whitelist
Feb  8 22:45:21.706: INFO: namespace e2e-tests-projected-dqlzl deletion completed in 6.083330292s

• [SLOW TEST:8.178 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:45:21.707: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  8 22:45:21.765: INFO: Waiting up to 5m0s for pod "downwardapi-volume-375fd336-2bf3-11e9-a551-0a580a020303" in namespace "e2e-tests-projected-p9k97" to be "success or failure"
Feb  8 22:45:21.767: INFO: Pod "downwardapi-volume-375fd336-2bf3-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.380046ms
Feb  8 22:45:23.770: INFO: Pod "downwardapi-volume-375fd336-2bf3-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005432242s
STEP: Saw pod success
Feb  8 22:45:23.770: INFO: Pod "downwardapi-volume-375fd336-2bf3-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:45:23.773: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod downwardapi-volume-375fd336-2bf3-11e9-a551-0a580a020303 container client-container: <nil>
STEP: delete the pod
Feb  8 22:45:23.790: INFO: Waiting for pod downwardapi-volume-375fd336-2bf3-11e9-a551-0a580a020303 to disappear
Feb  8 22:45:23.792: INFO: Pod downwardapi-volume-375fd336-2bf3-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:45:23.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-p9k97" for this suite.
Feb  8 22:45:29.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:45:29.838: INFO: namespace: e2e-tests-projected-p9k97, resource: bindings, ignored listing per whitelist
Feb  8 22:45:29.883: INFO: namespace e2e-tests-projected-p9k97 deletion completed in 6.088294614s

• [SLOW TEST:8.177 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:45:29.883: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Feb  8 22:45:29.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 api-versions'
Feb  8 22:45:30.020: INFO: stderr: ""
Feb  8 22:45:30.021: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:45:30.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b8d7q" for this suite.
Feb  8 22:45:36.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:45:36.073: INFO: namespace: e2e-tests-kubectl-b8d7q, resource: bindings, ignored listing per whitelist
Feb  8 22:45:36.110: INFO: namespace e2e-tests-kubectl-b8d7q deletion completed in 6.085194282s

• [SLOW TEST:6.226 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:45:36.111: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Feb  8 22:45:36.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 create -f - --namespace=e2e-tests-kubectl-rkdcd'
Feb  8 22:45:36.458: INFO: stderr: ""
Feb  8 22:45:36.458: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  8 22:45:36.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rkdcd'
Feb  8 22:45:36.540: INFO: stderr: ""
Feb  8 22:45:36.540: INFO: stdout: "update-demo-nautilus-bj797 update-demo-nautilus-cftxj "
Feb  8 22:45:36.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods update-demo-nautilus-bj797 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rkdcd'
Feb  8 22:45:36.615: INFO: stderr: ""
Feb  8 22:45:36.616: INFO: stdout: ""
Feb  8 22:45:36.616: INFO: update-demo-nautilus-bj797 is created but not running
Feb  8 22:45:41.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rkdcd'
Feb  8 22:45:41.693: INFO: stderr: ""
Feb  8 22:45:41.693: INFO: stdout: "update-demo-nautilus-bj797 update-demo-nautilus-cftxj "
Feb  8 22:45:41.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods update-demo-nautilus-bj797 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rkdcd'
Feb  8 22:45:41.769: INFO: stderr: ""
Feb  8 22:45:41.769: INFO: stdout: "true"
Feb  8 22:45:41.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods update-demo-nautilus-bj797 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rkdcd'
Feb  8 22:45:41.852: INFO: stderr: ""
Feb  8 22:45:41.852: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  8 22:45:41.852: INFO: validating pod update-demo-nautilus-bj797
Feb  8 22:45:41.856: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  8 22:45:41.856: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  8 22:45:41.856: INFO: update-demo-nautilus-bj797 is verified up and running
Feb  8 22:45:41.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods update-demo-nautilus-cftxj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rkdcd'
Feb  8 22:45:41.932: INFO: stderr: ""
Feb  8 22:45:41.932: INFO: stdout: "true"
Feb  8 22:45:41.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods update-demo-nautilus-cftxj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rkdcd'
Feb  8 22:45:42.015: INFO: stderr: ""
Feb  8 22:45:42.015: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  8 22:45:42.015: INFO: validating pod update-demo-nautilus-cftxj
Feb  8 22:45:42.019: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  8 22:45:42.019: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  8 22:45:42.019: INFO: update-demo-nautilus-cftxj is verified up and running
STEP: rolling-update to new replication controller
Feb  8 22:45:42.020: INFO: scanned /root for discovery docs: <nil>
Feb  8 22:45:42.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-rkdcd'
Feb  8 22:46:04.357: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb  8 22:46:04.357: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  8 22:46:04.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rkdcd'
Feb  8 22:46:04.438: INFO: stderr: ""
Feb  8 22:46:04.438: INFO: stdout: "update-demo-kitten-6rqhw update-demo-kitten-h49mq "
Feb  8 22:46:04.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods update-demo-kitten-6rqhw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rkdcd'
Feb  8 22:46:04.515: INFO: stderr: ""
Feb  8 22:46:04.515: INFO: stdout: "true"
Feb  8 22:46:04.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods update-demo-kitten-6rqhw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rkdcd'
Feb  8 22:46:04.590: INFO: stderr: ""
Feb  8 22:46:04.590: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb  8 22:46:04.590: INFO: validating pod update-demo-kitten-6rqhw
Feb  8 22:46:04.595: INFO: got data: {
  "image": "kitten.jpg"
}

Feb  8 22:46:04.595: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb  8 22:46:04.595: INFO: update-demo-kitten-6rqhw is verified up and running
Feb  8 22:46:04.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods update-demo-kitten-h49mq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rkdcd'
Feb  8 22:46:04.671: INFO: stderr: ""
Feb  8 22:46:04.671: INFO: stdout: "true"
Feb  8 22:46:04.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods update-demo-kitten-h49mq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rkdcd'
Feb  8 22:46:04.748: INFO: stderr: ""
Feb  8 22:46:04.748: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb  8 22:46:04.748: INFO: validating pod update-demo-kitten-h49mq
Feb  8 22:46:04.752: INFO: got data: {
  "image": "kitten.jpg"
}

Feb  8 22:46:04.752: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb  8 22:46:04.752: INFO: update-demo-kitten-h49mq is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:46:04.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rkdcd" for this suite.
Feb  8 22:46:26.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:46:26.838: INFO: namespace: e2e-tests-kubectl-rkdcd, resource: bindings, ignored listing per whitelist
Feb  8 22:46:26.854: INFO: namespace e2e-tests-kubectl-rkdcd deletion completed in 22.099276589s

• [SLOW TEST:50.744 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:46:26.855: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb  8 22:46:28.967: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-5e395a15-2bf3-11e9-a551-0a580a020303,GenerateName:,Namespace:e2e-tests-events-ct882,SelfLink:/api/v1/namespaces/e2e-tests-events-ct882/pods/send-events-5e395a15-2bf3-11e9-a551-0a580a020303,UID:5e3b9030-2bf3-11e9-a760-02d2eeadbd48,ResourceVersion:6411,Generation:0,CreationTimestamp:2019-02-08 22:46:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 937504907,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-b8q6c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-b8q6c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-b8q6c true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-23-7-130.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420fc6740} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420fc6760}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 22:46:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 22:46:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 22:46:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 22:46:26 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.130,PodIP:10.2.2.49,StartTime:2019-02-08 22:46:26 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-02-08 22:46:27 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://a01c805c3159017f6bda7f7cb567fa51a14008dda3c708691d2f3be1e854b8b2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Feb  8 22:46:30.971: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb  8 22:46:32.975: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:46:32.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-ct882" for this suite.
Feb  8 22:47:10.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:47:11.067: INFO: namespace: e2e-tests-events-ct882, resource: bindings, ignored listing per whitelist
Feb  8 22:47:11.076: INFO: namespace e2e-tests-events-ct882 deletion completed in 38.091699096s

• [SLOW TEST:44.221 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:47:11.076: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-747q
STEP: Creating a pod to test atomic-volume-subpath
Feb  8 22:47:11.146: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-747q" in namespace "e2e-tests-subpath-qprvg" to be "success or failure"
Feb  8 22:47:11.151: INFO: Pod "pod-subpath-test-downwardapi-747q": Phase="Pending", Reason="", readiness=false. Elapsed: 4.768788ms
Feb  8 22:47:13.154: INFO: Pod "pod-subpath-test-downwardapi-747q": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008457104s
Feb  8 22:47:15.158: INFO: Pod "pod-subpath-test-downwardapi-747q": Phase="Running", Reason="", readiness=false. Elapsed: 4.012036155s
Feb  8 22:47:17.162: INFO: Pod "pod-subpath-test-downwardapi-747q": Phase="Running", Reason="", readiness=false. Elapsed: 6.015674094s
Feb  8 22:47:19.165: INFO: Pod "pod-subpath-test-downwardapi-747q": Phase="Running", Reason="", readiness=false. Elapsed: 8.01930548s
Feb  8 22:47:21.169: INFO: Pod "pod-subpath-test-downwardapi-747q": Phase="Running", Reason="", readiness=false. Elapsed: 10.022967314s
Feb  8 22:47:23.172: INFO: Pod "pod-subpath-test-downwardapi-747q": Phase="Running", Reason="", readiness=false. Elapsed: 12.026125726s
Feb  8 22:47:25.175: INFO: Pod "pod-subpath-test-downwardapi-747q": Phase="Running", Reason="", readiness=false. Elapsed: 14.029558517s
Feb  8 22:47:27.179: INFO: Pod "pod-subpath-test-downwardapi-747q": Phase="Running", Reason="", readiness=false. Elapsed: 16.033153526s
Feb  8 22:47:29.183: INFO: Pod "pod-subpath-test-downwardapi-747q": Phase="Running", Reason="", readiness=false. Elapsed: 18.036668936s
Feb  8 22:47:31.187: INFO: Pod "pod-subpath-test-downwardapi-747q": Phase="Running", Reason="", readiness=false. Elapsed: 20.041495714s
Feb  8 22:47:33.191: INFO: Pod "pod-subpath-test-downwardapi-747q": Phase="Running", Reason="", readiness=false. Elapsed: 22.044905044s
Feb  8 22:47:35.194: INFO: Pod "pod-subpath-test-downwardapi-747q": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.048502809s
STEP: Saw pod success
Feb  8 22:47:35.194: INFO: Pod "pod-subpath-test-downwardapi-747q" satisfied condition "success or failure"
Feb  8 22:47:35.197: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod pod-subpath-test-downwardapi-747q container test-container-subpath-downwardapi-747q: <nil>
STEP: delete the pod
Feb  8 22:47:35.217: INFO: Waiting for pod pod-subpath-test-downwardapi-747q to disappear
Feb  8 22:47:35.219: INFO: Pod pod-subpath-test-downwardapi-747q no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-747q
Feb  8 22:47:35.219: INFO: Deleting pod "pod-subpath-test-downwardapi-747q" in namespace "e2e-tests-subpath-qprvg"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:47:35.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-qprvg" for this suite.
Feb  8 22:47:41.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:47:41.295: INFO: namespace: e2e-tests-subpath-qprvg, resource: bindings, ignored listing per whitelist
Feb  8 22:47:41.314: INFO: namespace e2e-tests-subpath-qprvg deletion completed in 6.089187588s

• [SLOW TEST:30.238 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:47:41.314: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb  8 22:47:41.376: INFO: Waiting up to 5m0s for pod "pod-8a96b6ee-2bf3-11e9-a551-0a580a020303" in namespace "e2e-tests-emptydir-s6ldw" to be "success or failure"
Feb  8 22:47:41.378: INFO: Pod "pod-8a96b6ee-2bf3-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.512113ms
Feb  8 22:47:43.382: INFO: Pod "pod-8a96b6ee-2bf3-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005998525s
STEP: Saw pod success
Feb  8 22:47:43.382: INFO: Pod "pod-8a96b6ee-2bf3-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:47:43.384: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod pod-8a96b6ee-2bf3-11e9-a551-0a580a020303 container test-container: <nil>
STEP: delete the pod
Feb  8 22:47:43.403: INFO: Waiting for pod pod-8a96b6ee-2bf3-11e9-a551-0a580a020303 to disappear
Feb  8 22:47:43.405: INFO: Pod pod-8a96b6ee-2bf3-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:47:43.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-s6ldw" for this suite.
Feb  8 22:47:49.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:47:49.486: INFO: namespace: e2e-tests-emptydir-s6ldw, resource: bindings, ignored listing per whitelist
Feb  8 22:47:49.495: INFO: namespace e2e-tests-emptydir-s6ldw deletion completed in 6.086066183s

• [SLOW TEST:8.181 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:47:49.495: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb  8 22:47:49.549: INFO: Waiting up to 5m0s for pod "pod-8f75f831-2bf3-11e9-a551-0a580a020303" in namespace "e2e-tests-emptydir-z6tmj" to be "success or failure"
Feb  8 22:47:49.553: INFO: Pod "pod-8f75f831-2bf3-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 4.741147ms
Feb  8 22:47:51.556: INFO: Pod "pod-8f75f831-2bf3-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00788998s
STEP: Saw pod success
Feb  8 22:47:51.557: INFO: Pod "pod-8f75f831-2bf3-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:47:51.559: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod pod-8f75f831-2bf3-11e9-a551-0a580a020303 container test-container: <nil>
STEP: delete the pod
Feb  8 22:47:51.578: INFO: Waiting for pod pod-8f75f831-2bf3-11e9-a551-0a580a020303 to disappear
Feb  8 22:47:51.581: INFO: Pod pod-8f75f831-2bf3-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:47:51.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-z6tmj" for this suite.
Feb  8 22:47:57.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:47:57.614: INFO: namespace: e2e-tests-emptydir-z6tmj, resource: bindings, ignored listing per whitelist
Feb  8 22:47:57.670: INFO: namespace e2e-tests-emptydir-z6tmj deletion completed in 6.085516079s

• [SLOW TEST:8.175 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:47:57.670: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Feb  8 22:47:57.726: INFO: Waiting up to 5m0s for pod "client-containers-9455e1d9-2bf3-11e9-a551-0a580a020303" in namespace "e2e-tests-containers-tgskr" to be "success or failure"
Feb  8 22:47:57.732: INFO: Pod "client-containers-9455e1d9-2bf3-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 5.28822ms
Feb  8 22:47:59.735: INFO: Pod "client-containers-9455e1d9-2bf3-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008688689s
STEP: Saw pod success
Feb  8 22:47:59.735: INFO: Pod "client-containers-9455e1d9-2bf3-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:47:59.737: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod client-containers-9455e1d9-2bf3-11e9-a551-0a580a020303 container test-container: <nil>
STEP: delete the pod
Feb  8 22:47:59.755: INFO: Waiting for pod client-containers-9455e1d9-2bf3-11e9-a551-0a580a020303 to disappear
Feb  8 22:47:59.757: INFO: Pod client-containers-9455e1d9-2bf3-11e9-a551-0a580a020303 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:47:59.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-tgskr" for this suite.
Feb  8 22:48:05.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:48:05.842: INFO: namespace: e2e-tests-containers-tgskr, resource: bindings, ignored listing per whitelist
Feb  8 22:48:05.844: INFO: namespace e2e-tests-containers-tgskr deletion completed in 6.083491909s

• [SLOW TEST:8.174 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:48:05.844: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-99350d7f-2bf3-11e9-a551-0a580a020303
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:48:07.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-hm7s2" for this suite.
Feb  8 22:48:29.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:48:29.954: INFO: namespace: e2e-tests-configmap-hm7s2, resource: bindings, ignored listing per whitelist
Feb  8 22:48:30.015: INFO: namespace e2e-tests-configmap-hm7s2 deletion completed in 22.083902817s

• [SLOW TEST:24.170 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:48:30.015: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Feb  8 22:48:30.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 create -f - --namespace=e2e-tests-kubectl-hnhk7'
Feb  8 22:48:30.215: INFO: stderr: ""
Feb  8 22:48:30.215: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Feb  8 22:48:31.219: INFO: Selector matched 1 pods for map[app:redis]
Feb  8 22:48:31.219: INFO: Found 0 / 1
Feb  8 22:48:32.219: INFO: Selector matched 1 pods for map[app:redis]
Feb  8 22:48:32.219: INFO: Found 0 / 1
Feb  8 22:48:33.219: INFO: Selector matched 1 pods for map[app:redis]
Feb  8 22:48:33.219: INFO: Found 1 / 1
Feb  8 22:48:33.219: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb  8 22:48:33.222: INFO: Selector matched 1 pods for map[app:redis]
Feb  8 22:48:33.222: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Feb  8 22:48:33.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 logs redis-master-pnccx redis-master --namespace=e2e-tests-kubectl-hnhk7'
Feb  8 22:48:33.309: INFO: stderr: ""
Feb  8 22:48:33.309: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 08 Feb 22:48:32.230 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 08 Feb 22:48:32.230 # Server started, Redis version 3.2.12\n1:M 08 Feb 22:48:32.230 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 08 Feb 22:48:32.230 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Feb  8 22:48:33.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 log redis-master-pnccx redis-master --namespace=e2e-tests-kubectl-hnhk7 --tail=1'
Feb  8 22:48:33.397: INFO: stderr: ""
Feb  8 22:48:33.397: INFO: stdout: "1:M 08 Feb 22:48:32.230 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Feb  8 22:48:33.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 log redis-master-pnccx redis-master --namespace=e2e-tests-kubectl-hnhk7 --limit-bytes=1'
Feb  8 22:48:33.485: INFO: stderr: ""
Feb  8 22:48:33.485: INFO: stdout: " "
STEP: exposing timestamps
Feb  8 22:48:33.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 log redis-master-pnccx redis-master --namespace=e2e-tests-kubectl-hnhk7 --tail=1 --timestamps'
Feb  8 22:48:33.571: INFO: stderr: ""
Feb  8 22:48:33.571: INFO: stdout: "2019-02-08T22:48:32.231047456Z 1:M 08 Feb 22:48:32.230 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Feb  8 22:48:36.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 log redis-master-pnccx redis-master --namespace=e2e-tests-kubectl-hnhk7 --since=1s'
Feb  8 22:48:36.158: INFO: stderr: ""
Feb  8 22:48:36.158: INFO: stdout: ""
Feb  8 22:48:36.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 log redis-master-pnccx redis-master --namespace=e2e-tests-kubectl-hnhk7 --since=24h'
Feb  8 22:48:36.244: INFO: stderr: ""
Feb  8 22:48:36.244: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 08 Feb 22:48:32.230 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 08 Feb 22:48:32.230 # Server started, Redis version 3.2.12\n1:M 08 Feb 22:48:32.230 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 08 Feb 22:48:32.230 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Feb  8 22:48:36.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hnhk7'
Feb  8 22:48:36.328: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  8 22:48:36.328: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Feb  8 22:48:36.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-hnhk7'
Feb  8 22:48:36.412: INFO: stderr: "No resources found.\n"
Feb  8 22:48:36.412: INFO: stdout: ""
Feb  8 22:48:36.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods -l name=nginx --namespace=e2e-tests-kubectl-hnhk7 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  8 22:48:36.489: INFO: stderr: ""
Feb  8 22:48:36.490: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:48:36.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hnhk7" for this suite.
Feb  8 22:48:42.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:48:42.527: INFO: namespace: e2e-tests-kubectl-hnhk7, resource: bindings, ignored listing per whitelist
Feb  8 22:48:42.583: INFO: namespace e2e-tests-kubectl-hnhk7 deletion completed in 6.090033474s

• [SLOW TEST:12.568 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:48:42.583: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  8 22:48:42.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-lgvw8'
Feb  8 22:48:42.732: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb  8 22:48:42.732: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Feb  8 22:48:46.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-lgvw8'
Feb  8 22:48:46.839: INFO: stderr: ""
Feb  8 22:48:46.839: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:48:46.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lgvw8" for this suite.
Feb  8 22:49:00.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:49:00.903: INFO: namespace: e2e-tests-kubectl-lgvw8, resource: bindings, ignored listing per whitelist
Feb  8 22:49:00.946: INFO: namespace e2e-tests-kubectl-lgvw8 deletion completed in 14.103998631s

• [SLOW TEST:18.363 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:49:00.946: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0208 22:49:41.030775      14 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  8 22:49:41.030: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:49:41.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-7bbld" for this suite.
Feb  8 22:49:47.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:49:47.052: INFO: namespace: e2e-tests-gc-7bbld, resource: bindings, ignored listing per whitelist
Feb  8 22:49:47.117: INFO: namespace e2e-tests-gc-7bbld deletion completed in 6.083834768s

• [SLOW TEST:46.171 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:49:47.117: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb  8 22:49:47.169: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:49:49.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-kj2pn" for this suite.
Feb  8 22:49:55.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:49:55.957: INFO: namespace: e2e-tests-init-container-kj2pn, resource: bindings, ignored listing per whitelist
Feb  8 22:49:56.035: INFO: namespace e2e-tests-init-container-kj2pn deletion completed in 6.102159614s

• [SLOW TEST:8.917 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:49:56.035: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-dae33950-2bf3-11e9-a551-0a580a020303
Feb  8 22:49:56.097: INFO: Pod name my-hostname-basic-dae33950-2bf3-11e9-a551-0a580a020303: Found 0 pods out of 1
Feb  8 22:50:01.101: INFO: Pod name my-hostname-basic-dae33950-2bf3-11e9-a551-0a580a020303: Found 1 pods out of 1
Feb  8 22:50:01.101: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-dae33950-2bf3-11e9-a551-0a580a020303" are running
Feb  8 22:50:01.103: INFO: Pod "my-hostname-basic-dae33950-2bf3-11e9-a551-0a580a020303-wtw7v" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-08 22:49:56 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-08 22:49:56 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-08 22:49:56 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-08 22:49:56 +0000 UTC Reason: Message:}])
Feb  8 22:50:01.103: INFO: Trying to dial the pod
Feb  8 22:50:06.113: INFO: Controller my-hostname-basic-dae33950-2bf3-11e9-a551-0a580a020303: Got expected result from replica 1 [my-hostname-basic-dae33950-2bf3-11e9-a551-0a580a020303-wtw7v]: "my-hostname-basic-dae33950-2bf3-11e9-a551-0a580a020303-wtw7v", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:50:06.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-8wqz4" for this suite.
Feb  8 22:50:12.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:50:12.157: INFO: namespace: e2e-tests-replication-controller-8wqz4, resource: bindings, ignored listing per whitelist
Feb  8 22:50:12.201: INFO: namespace e2e-tests-replication-controller-8wqz4 deletion completed in 6.084165014s

• [SLOW TEST:16.166 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:50:12.201: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  8 22:50:12.259: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e485d3d1-2bf3-11e9-a551-0a580a020303" in namespace "e2e-tests-downward-api-lvb9k" to be "success or failure"
Feb  8 22:50:12.264: INFO: Pod "downwardapi-volume-e485d3d1-2bf3-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 4.923856ms
Feb  8 22:50:14.268: INFO: Pod "downwardapi-volume-e485d3d1-2bf3-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008624998s
Feb  8 22:50:16.271: INFO: Pod "downwardapi-volume-e485d3d1-2bf3-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012110961s
STEP: Saw pod success
Feb  8 22:50:16.271: INFO: Pod "downwardapi-volume-e485d3d1-2bf3-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:50:16.274: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod downwardapi-volume-e485d3d1-2bf3-11e9-a551-0a580a020303 container client-container: <nil>
STEP: delete the pod
Feb  8 22:50:16.293: INFO: Waiting for pod downwardapi-volume-e485d3d1-2bf3-11e9-a551-0a580a020303 to disappear
Feb  8 22:50:16.296: INFO: Pod downwardapi-volume-e485d3d1-2bf3-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:50:16.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lvb9k" for this suite.
Feb  8 22:50:22.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:50:22.366: INFO: namespace: e2e-tests-downward-api-lvb9k, resource: bindings, ignored listing per whitelist
Feb  8 22:50:22.386: INFO: namespace e2e-tests-downward-api-lvb9k deletion completed in 6.085683088s

• [SLOW TEST:10.185 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:50:22.386: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb  8 22:50:22.448: INFO: Waiting up to 5m0s for pod "pod-ea988349-2bf3-11e9-a551-0a580a020303" in namespace "e2e-tests-emptydir-t54lv" to be "success or failure"
Feb  8 22:50:22.452: INFO: Pod "pod-ea988349-2bf3-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 4.034083ms
Feb  8 22:50:24.456: INFO: Pod "pod-ea988349-2bf3-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00767335s
STEP: Saw pod success
Feb  8 22:50:24.456: INFO: Pod "pod-ea988349-2bf3-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:50:24.458: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod pod-ea988349-2bf3-11e9-a551-0a580a020303 container test-container: <nil>
STEP: delete the pod
Feb  8 22:50:24.478: INFO: Waiting for pod pod-ea988349-2bf3-11e9-a551-0a580a020303 to disappear
Feb  8 22:50:24.481: INFO: Pod pod-ea988349-2bf3-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:50:24.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-t54lv" for this suite.
Feb  8 22:50:30.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:50:30.504: INFO: namespace: e2e-tests-emptydir-t54lv, resource: bindings, ignored listing per whitelist
Feb  8 22:50:30.568: INFO: namespace e2e-tests-emptydir-t54lv deletion completed in 6.084501515s

• [SLOW TEST:8.182 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:50:30.568: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  8 22:50:30.641: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ef7ac695-2bf3-11e9-a551-0a580a020303" in namespace "e2e-tests-projected-5dr5p" to be "success or failure"
Feb  8 22:50:30.644: INFO: Pod "downwardapi-volume-ef7ac695-2bf3-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.359383ms
Feb  8 22:50:32.647: INFO: Pod "downwardapi-volume-ef7ac695-2bf3-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005936981s
STEP: Saw pod success
Feb  8 22:50:32.647: INFO: Pod "downwardapi-volume-ef7ac695-2bf3-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:50:32.649: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod downwardapi-volume-ef7ac695-2bf3-11e9-a551-0a580a020303 container client-container: <nil>
STEP: delete the pod
Feb  8 22:50:32.667: INFO: Waiting for pod downwardapi-volume-ef7ac695-2bf3-11e9-a551-0a580a020303 to disappear
Feb  8 22:50:32.670: INFO: Pod downwardapi-volume-ef7ac695-2bf3-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:50:32.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5dr5p" for this suite.
Feb  8 22:50:38.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:50:38.736: INFO: namespace: e2e-tests-projected-5dr5p, resource: bindings, ignored listing per whitelist
Feb  8 22:50:38.760: INFO: namespace e2e-tests-projected-5dr5p deletion completed in 6.087231714s

• [SLOW TEST:8.192 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:50:38.760: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  8 22:51:04.836: INFO: Container started at 2019-02-08 22:50:39 +0000 UTC, pod became ready at 2019-02-08 22:51:02 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:51:04.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-fbfdh" for this suite.
Feb  8 22:51:26.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:51:26.915: INFO: namespace: e2e-tests-container-probe-fbfdh, resource: bindings, ignored listing per whitelist
Feb  8 22:51:26.923: INFO: namespace e2e-tests-container-probe-fbfdh deletion completed in 22.084511289s

• [SLOW TEST:48.163 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:51:26.924: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0208 22:51:57.513373      14 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  8 22:51:57.513: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:51:57.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-qkm4v" for this suite.
Feb  8 22:52:03.526: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:52:03.582: INFO: namespace: e2e-tests-gc-qkm4v, resource: bindings, ignored listing per whitelist
Feb  8 22:52:03.599: INFO: namespace e2e-tests-gc-qkm4v deletion completed in 6.083392072s

• [SLOW TEST:36.676 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:52:03.600: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  8 22:52:03.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-dk2b2'
Feb  8 22:52:03.734: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb  8 22:52:03.734: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Feb  8 22:52:03.740: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Feb  8 22:52:03.744: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Feb  8 22:52:03.755: INFO: scanned /root for discovery docs: <nil>
Feb  8 22:52:03.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-dk2b2'
Feb  8 22:52:19.520: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb  8 22:52:19.520: INFO: stdout: "Created e2e-test-nginx-rc-654f8870e610f9b37872a614cbc251bb\nScaling up e2e-test-nginx-rc-654f8870e610f9b37872a614cbc251bb from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-654f8870e610f9b37872a614cbc251bb up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-654f8870e610f9b37872a614cbc251bb to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Feb  8 22:52:19.520: INFO: stdout: "Created e2e-test-nginx-rc-654f8870e610f9b37872a614cbc251bb\nScaling up e2e-test-nginx-rc-654f8870e610f9b37872a614cbc251bb from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-654f8870e610f9b37872a614cbc251bb up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-654f8870e610f9b37872a614cbc251bb to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Feb  8 22:52:19.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-dk2b2'
Feb  8 22:52:19.600: INFO: stderr: ""
Feb  8 22:52:19.600: INFO: stdout: "e2e-test-nginx-rc-654f8870e610f9b37872a614cbc251bb-8tzgb "
Feb  8 22:52:19.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods e2e-test-nginx-rc-654f8870e610f9b37872a614cbc251bb-8tzgb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dk2b2'
Feb  8 22:52:19.675: INFO: stderr: ""
Feb  8 22:52:19.675: INFO: stdout: "true"
Feb  8 22:52:19.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods e2e-test-nginx-rc-654f8870e610f9b37872a614cbc251bb-8tzgb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dk2b2'
Feb  8 22:52:19.752: INFO: stderr: ""
Feb  8 22:52:19.752: INFO: stdout: "nginx:1.14-alpine"
Feb  8 22:52:19.752: INFO: e2e-test-nginx-rc-654f8870e610f9b37872a614cbc251bb-8tzgb is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Feb  8 22:52:19.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-dk2b2'
Feb  8 22:52:19.836: INFO: stderr: ""
Feb  8 22:52:19.836: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:52:19.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dk2b2" for this suite.
Feb  8 22:52:25.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:52:25.927: INFO: namespace: e2e-tests-kubectl-dk2b2, resource: bindings, ignored listing per whitelist
Feb  8 22:52:25.927: INFO: namespace e2e-tests-kubectl-dk2b2 deletion completed in 6.086999393s

• [SLOW TEST:22.327 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:52:25.927: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-343b402b-2bf4-11e9-a551-0a580a020303
STEP: Creating secret with name secret-projected-all-test-volume-343b4011-2bf4-11e9-a551-0a580a020303
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb  8 22:52:25.995: INFO: Waiting up to 5m0s for pod "projected-volume-343b3fd4-2bf4-11e9-a551-0a580a020303" in namespace "e2e-tests-projected-lwsgf" to be "success or failure"
Feb  8 22:52:26.001: INFO: Pod "projected-volume-343b3fd4-2bf4-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 5.619447ms
Feb  8 22:52:28.004: INFO: Pod "projected-volume-343b3fd4-2bf4-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009316023s
STEP: Saw pod success
Feb  8 22:52:28.005: INFO: Pod "projected-volume-343b3fd4-2bf4-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:52:28.007: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod projected-volume-343b3fd4-2bf4-11e9-a551-0a580a020303 container projected-all-volume-test: <nil>
STEP: delete the pod
Feb  8 22:52:28.026: INFO: Waiting for pod projected-volume-343b3fd4-2bf4-11e9-a551-0a580a020303 to disappear
Feb  8 22:52:28.028: INFO: Pod projected-volume-343b3fd4-2bf4-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:52:28.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lwsgf" for this suite.
Feb  8 22:52:34.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:52:34.049: INFO: namespace: e2e-tests-projected-lwsgf, resource: bindings, ignored listing per whitelist
Feb  8 22:52:34.117: INFO: namespace e2e-tests-projected-lwsgf deletion completed in 6.085287362s

• [SLOW TEST:8.190 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:52:34.117: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb  8 22:52:34.163: INFO: namespace e2e-tests-kubectl-9pz9f
Feb  8 22:52:34.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 create -f - --namespace=e2e-tests-kubectl-9pz9f'
Feb  8 22:52:34.312: INFO: stderr: ""
Feb  8 22:52:34.312: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb  8 22:52:35.315: INFO: Selector matched 1 pods for map[app:redis]
Feb  8 22:52:35.315: INFO: Found 0 / 1
Feb  8 22:52:36.316: INFO: Selector matched 1 pods for map[app:redis]
Feb  8 22:52:36.316: INFO: Found 1 / 1
Feb  8 22:52:36.316: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb  8 22:52:36.318: INFO: Selector matched 1 pods for map[app:redis]
Feb  8 22:52:36.318: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb  8 22:52:36.318: INFO: wait on redis-master startup in e2e-tests-kubectl-9pz9f 
Feb  8 22:52:36.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 logs redis-master-8jq6r redis-master --namespace=e2e-tests-kubectl-9pz9f'
Feb  8 22:52:36.412: INFO: stderr: ""
Feb  8 22:52:36.412: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 08 Feb 22:52:35.126 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 08 Feb 22:52:35.126 # Server started, Redis version 3.2.12\n1:M 08 Feb 22:52:35.126 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 08 Feb 22:52:35.126 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Feb  8 22:52:36.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-9pz9f'
Feb  8 22:52:36.505: INFO: stderr: ""
Feb  8 22:52:36.505: INFO: stdout: "service/rm2 exposed\n"
Feb  8 22:52:36.509: INFO: Service rm2 in namespace e2e-tests-kubectl-9pz9f found.
STEP: exposing service
Feb  8 22:52:38.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-9pz9f'
Feb  8 22:52:38.604: INFO: stderr: ""
Feb  8 22:52:38.604: INFO: stdout: "service/rm3 exposed\n"
Feb  8 22:52:38.607: INFO: Service rm3 in namespace e2e-tests-kubectl-9pz9f found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:52:40.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9pz9f" for this suite.
Feb  8 22:53:02.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:53:02.636: INFO: namespace: e2e-tests-kubectl-9pz9f, resource: bindings, ignored listing per whitelist
Feb  8 22:53:02.705: INFO: namespace e2e-tests-kubectl-9pz9f deletion completed in 22.088937836s

• [SLOW TEST:28.588 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:53:02.705: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Feb  8 22:53:02.758: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-821255472 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:53:02.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-h6k4m" for this suite.
Feb  8 22:53:08.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:53:08.847: INFO: namespace: e2e-tests-kubectl-h6k4m, resource: bindings, ignored listing per whitelist
Feb  8 22:53:08.914: INFO: namespace e2e-tests-kubectl-h6k4m deletion completed in 6.084405304s

• [SLOW TEST:6.209 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:53:08.914: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Feb  8 22:53:08.968: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  8 22:53:08.974: INFO: Waiting for terminating namespaces to be deleted...
Feb  8 22:53:08.976: INFO: 
Logging pods the kubelet thinks is on node ip-172-23-7-110.us-west-2.compute.internal before test
Feb  8 22:53:08.981: INFO: sonobuoy-systemd-logs-daemon-set-97ae410a3d2d4a52-tsw98 from heptio-sonobuoy started at 2019-02-08 22:19:47 +0000 UTC (2 container statuses recorded)
Feb  8 22:53:08.981: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb  8 22:53:08.981: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  8 22:53:08.981: INFO: kube-flannel-ds-5cwbb from kube-system started at 2019-02-08 22:14:48 +0000 UTC (1 container statuses recorded)
Feb  8 22:53:08.981: INFO: 	Container kube-flannel ready: true, restart count 0
Feb  8 22:53:08.981: INFO: kube-proxy-74ndc from kube-system started at 2019-02-08 22:14:48 +0000 UTC (1 container statuses recorded)
Feb  8 22:53:08.981: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  8 22:53:08.981: INFO: tiller-deploy-6fb6d4777d-pswxg from kube-system started at 2019-02-08 22:15:35 +0000 UTC (1 container statuses recorded)
Feb  8 22:53:08.981: INFO: 	Container tiller ready: true, restart count 0
Feb  8 22:53:08.981: INFO: 
Logging pods the kubelet thinks is on node ip-172-23-7-130.us-west-2.compute.internal before test
Feb  8 22:53:08.986: INFO: kubernetes-dashboard-778d4ccc65-2mgbl from kube-system started at 2019-02-08 22:16:05 +0000 UTC (1 container statuses recorded)
Feb  8 22:53:08.986: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb  8 22:53:08.986: INFO: sonobuoy-systemd-logs-daemon-set-97ae410a3d2d4a52-rhwxj from heptio-sonobuoy started at 2019-02-08 22:19:47 +0000 UTC (2 container statuses recorded)
Feb  8 22:53:08.986: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb  8 22:53:08.986: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  8 22:53:08.986: INFO: kube-flannel-ds-hbllw from kube-system started at 2019-02-08 22:14:48 +0000 UTC (1 container statuses recorded)
Feb  8 22:53:08.986: INFO: 	Container kube-flannel ready: true, restart count 0
Feb  8 22:53:08.986: INFO: kube-proxy-4fjpj from kube-system started at 2019-02-08 22:14:48 +0000 UTC (1 container statuses recorded)
Feb  8 22:53:08.986: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  8 22:53:08.986: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-08 22:19:44 +0000 UTC (1 container statuses recorded)
Feb  8 22:53:08.986: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb  8 22:53:08.986: INFO: 
Logging pods the kubelet thinks is on node ip-172-23-7-34.us-west-2.compute.internal before test
Feb  8 22:53:08.991: INFO: kube-flannel-ds-n6skb from kube-system started at 2019-02-08 22:14:48 +0000 UTC (1 container statuses recorded)
Feb  8 22:53:08.991: INFO: 	Container kube-flannel ready: true, restart count 0
Feb  8 22:53:08.991: INFO: kube-proxy-c97zb from kube-system started at 2019-02-08 22:14:48 +0000 UTC (1 container statuses recorded)
Feb  8 22:53:08.991: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  8 22:53:08.991: INFO: heapster-5459947ccc-rlxzx from kube-system started at 2019-02-08 22:16:05 +0000 UTC (1 container statuses recorded)
Feb  8 22:53:08.991: INFO: 	Container heapster ready: true, restart count 0
Feb  8 22:53:08.991: INFO: sonobuoy-e2e-job-3bb448efb05f49ae from heptio-sonobuoy started at 2019-02-08 22:19:47 +0000 UTC (2 container statuses recorded)
Feb  8 22:53:08.991: INFO: 	Container e2e ready: true, restart count 0
Feb  8 22:53:08.991: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  8 22:53:08.991: INFO: sonobuoy-systemd-logs-daemon-set-97ae410a3d2d4a52-vzm9c from heptio-sonobuoy started at 2019-02-08 22:19:47 +0000 UTC (2 container statuses recorded)
Feb  8 22:53:08.991: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb  8 22:53:08.991: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1581855ecd334d3d], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:53:10.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-xvjdf" for this suite.
Feb  8 22:53:16.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:53:16.047: INFO: namespace: e2e-tests-sched-pred-xvjdf, resource: bindings, ignored listing per whitelist
Feb  8 22:53:16.102: INFO: namespace e2e-tests-sched-pred-xvjdf deletion completed in 6.083801408s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:7.188 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:53:16.102: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-s65st
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  8 22:53:16.155: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  8 22:53:40.240: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.2.2.64 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-s65st PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  8 22:53:40.240: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
Feb  8 22:53:41.342: INFO: Found all expected endpoints: [netserver-0]
Feb  8 22:53:41.346: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.2.3.21 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-s65st PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  8 22:53:41.346: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
Feb  8 22:53:42.450: INFO: Found all expected endpoints: [netserver-1]
Feb  8 22:53:42.454: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.2.1.77 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-s65st PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  8 22:53:42.454: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
Feb  8 22:53:43.570: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:53:43.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-s65st" for this suite.
Feb  8 22:54:01.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:54:01.590: INFO: namespace: e2e-tests-pod-network-test-s65st, resource: bindings, ignored listing per whitelist
Feb  8 22:54:01.664: INFO: namespace e2e-tests-pod-network-test-s65st deletion completed in 18.0900825s

• [SLOW TEST:45.561 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:54:01.664: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  8 22:54:01.719: INFO: Creating deployment "test-recreate-deployment"
Feb  8 22:54:01.723: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb  8 22:54:01.732: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Feb  8 22:54:03.738: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb  8 22:54:03.740: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb  8 22:54:03.746: INFO: Updating deployment test-recreate-deployment
Feb  8 22:54:03.746: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  8 22:54:03.812: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-p94mj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-p94mj/deployments/test-recreate-deployment,UID:6d4c121a-2bf4-11e9-a760-02d2eeadbd48,ResourceVersion:8055,Generation:2,CreationTimestamp:2019-02-08 22:54:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-02-08 22:54:03 +0000 UTC 2019-02-08 22:54:03 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-08 22:54:03 +0000 UTC 2019-02-08 22:54:01 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Feb  8 22:54:03.814: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-p94mj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-p94mj/replicasets/test-recreate-deployment-7cf749666b,UID:6e860078-2bf4-11e9-a760-02d2eeadbd48,ResourceVersion:8053,Generation:1,CreationTimestamp:2019-02-08 22:54:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 6d4c121a-2bf4-11e9-a760-02d2eeadbd48 0xc4223450c7 0xc4223450c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  8 22:54:03.814: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb  8 22:54:03.814: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-p94mj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-p94mj/replicasets/test-recreate-deployment-79f694ff59,UID:6d4d5734-2bf4-11e9-a760-02d2eeadbd48,ResourceVersion:8044,Generation:2,CreationTimestamp:2019-02-08 22:54:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 6d4c121a-2bf4-11e9-a760-02d2eeadbd48 0xc422345017 0xc422345018}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  8 22:54:03.817: INFO: Pod "test-recreate-deployment-7cf749666b-jmr7f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-jmr7f,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-p94mj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p94mj/pods/test-recreate-deployment-7cf749666b-jmr7f,UID:6e86af9d-2bf4-11e9-a760-02d2eeadbd48,ResourceVersion:8056,Generation:0,CreationTimestamp:2019-02-08 22:54:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b 6e860078-2bf4-11e9-a760-02d2eeadbd48 0xc4223458a7 0xc4223458a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bp6f6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bp6f6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bp6f6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-23-7-110.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422345910} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422345930}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 22:54:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-08 22:54:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-08 22:54:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 22:54:03 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.110,PodIP:,StartTime:2019-02-08 22:54:03 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:54:03.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-p94mj" for this suite.
Feb  8 22:54:09.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:54:09.877: INFO: namespace: e2e-tests-deployment-p94mj, resource: bindings, ignored listing per whitelist
Feb  8 22:54:09.921: INFO: namespace e2e-tests-deployment-p94mj deletion completed in 6.100920408s

• [SLOW TEST:8.257 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:54:09.921: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-72369f59-2bf4-11e9-a551-0a580a020303
STEP: Creating a pod to test consume secrets
Feb  8 22:54:09.985: INFO: Waiting up to 5m0s for pod "pod-secrets-7237d0dd-2bf4-11e9-a551-0a580a020303" in namespace "e2e-tests-secrets-bq458" to be "success or failure"
Feb  8 22:54:09.989: INFO: Pod "pod-secrets-7237d0dd-2bf4-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018393ms
Feb  8 22:54:11.992: INFO: Pod "pod-secrets-7237d0dd-2bf4-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00681858s
STEP: Saw pod success
Feb  8 22:54:11.992: INFO: Pod "pod-secrets-7237d0dd-2bf4-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:54:11.995: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod pod-secrets-7237d0dd-2bf4-11e9-a551-0a580a020303 container secret-volume-test: <nil>
STEP: delete the pod
Feb  8 22:54:12.012: INFO: Waiting for pod pod-secrets-7237d0dd-2bf4-11e9-a551-0a580a020303 to disappear
Feb  8 22:54:12.015: INFO: Pod pod-secrets-7237d0dd-2bf4-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:54:12.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-bq458" for this suite.
Feb  8 22:54:18.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:54:18.085: INFO: namespace: e2e-tests-secrets-bq458, resource: bindings, ignored listing per whitelist
Feb  8 22:54:18.100: INFO: namespace e2e-tests-secrets-bq458 deletion completed in 6.081888648s

• [SLOW TEST:8.179 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:54:18.100: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-771ae1b7-2bf4-11e9-a551-0a580a020303
STEP: Creating a pod to test consume configMaps
Feb  8 22:54:18.195: INFO: Waiting up to 5m0s for pod "pod-configmaps-771bac86-2bf4-11e9-a551-0a580a020303" in namespace "e2e-tests-configmap-fkvg4" to be "success or failure"
Feb  8 22:54:18.200: INFO: Pod "pod-configmaps-771bac86-2bf4-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 4.650719ms
Feb  8 22:54:20.203: INFO: Pod "pod-configmaps-771bac86-2bf4-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007895133s
STEP: Saw pod success
Feb  8 22:54:20.203: INFO: Pod "pod-configmaps-771bac86-2bf4-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:54:20.205: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod pod-configmaps-771bac86-2bf4-11e9-a551-0a580a020303 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  8 22:54:20.226: INFO: Waiting for pod pod-configmaps-771bac86-2bf4-11e9-a551-0a580a020303 to disappear
Feb  8 22:54:20.228: INFO: Pod pod-configmaps-771bac86-2bf4-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:54:20.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-fkvg4" for this suite.
Feb  8 22:54:26.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:54:26.278: INFO: namespace: e2e-tests-configmap-fkvg4, resource: bindings, ignored listing per whitelist
Feb  8 22:54:26.327: INFO: namespace e2e-tests-configmap-fkvg4 deletion completed in 6.095465793s

• [SLOW TEST:8.227 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:54:26.327: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Feb  8 22:54:26.888: INFO: Waiting up to 5m0s for pod "pod-service-account-7c4afe2a-2bf4-11e9-a551-0a580a020303-zzlwd" in namespace "e2e-tests-svcaccounts-sxrpm" to be "success or failure"
Feb  8 22:54:26.893: INFO: Pod "pod-service-account-7c4afe2a-2bf4-11e9-a551-0a580a020303-zzlwd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.763495ms
Feb  8 22:54:28.896: INFO: Pod "pod-service-account-7c4afe2a-2bf4-11e9-a551-0a580a020303-zzlwd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008197268s
STEP: Saw pod success
Feb  8 22:54:28.896: INFO: Pod "pod-service-account-7c4afe2a-2bf4-11e9-a551-0a580a020303-zzlwd" satisfied condition "success or failure"
Feb  8 22:54:28.899: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod pod-service-account-7c4afe2a-2bf4-11e9-a551-0a580a020303-zzlwd container token-test: <nil>
STEP: delete the pod
Feb  8 22:54:28.916: INFO: Waiting for pod pod-service-account-7c4afe2a-2bf4-11e9-a551-0a580a020303-zzlwd to disappear
Feb  8 22:54:28.918: INFO: Pod pod-service-account-7c4afe2a-2bf4-11e9-a551-0a580a020303-zzlwd no longer exists
STEP: Creating a pod to test consume service account root CA
Feb  8 22:54:28.922: INFO: Waiting up to 5m0s for pod "pod-service-account-7c4afe2a-2bf4-11e9-a551-0a580a020303-j846l" in namespace "e2e-tests-svcaccounts-sxrpm" to be "success or failure"
Feb  8 22:54:28.927: INFO: Pod "pod-service-account-7c4afe2a-2bf4-11e9-a551-0a580a020303-j846l": Phase="Pending", Reason="", readiness=false. Elapsed: 5.467806ms
Feb  8 22:54:30.935: INFO: Pod "pod-service-account-7c4afe2a-2bf4-11e9-a551-0a580a020303-j846l": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012820746s
STEP: Saw pod success
Feb  8 22:54:30.935: INFO: Pod "pod-service-account-7c4afe2a-2bf4-11e9-a551-0a580a020303-j846l" satisfied condition "success or failure"
Feb  8 22:54:30.938: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod pod-service-account-7c4afe2a-2bf4-11e9-a551-0a580a020303-j846l container root-ca-test: <nil>
STEP: delete the pod
Feb  8 22:54:30.956: INFO: Waiting for pod pod-service-account-7c4afe2a-2bf4-11e9-a551-0a580a020303-j846l to disappear
Feb  8 22:54:30.959: INFO: Pod pod-service-account-7c4afe2a-2bf4-11e9-a551-0a580a020303-j846l no longer exists
STEP: Creating a pod to test consume service account namespace
Feb  8 22:54:30.964: INFO: Waiting up to 5m0s for pod "pod-service-account-7c4afe2a-2bf4-11e9-a551-0a580a020303-btkmm" in namespace "e2e-tests-svcaccounts-sxrpm" to be "success or failure"
Feb  8 22:54:30.969: INFO: Pod "pod-service-account-7c4afe2a-2bf4-11e9-a551-0a580a020303-btkmm": Phase="Pending", Reason="", readiness=false. Elapsed: 4.702208ms
Feb  8 22:54:32.972: INFO: Pod "pod-service-account-7c4afe2a-2bf4-11e9-a551-0a580a020303-btkmm": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007949812s
STEP: Saw pod success
Feb  8 22:54:32.972: INFO: Pod "pod-service-account-7c4afe2a-2bf4-11e9-a551-0a580a020303-btkmm" satisfied condition "success or failure"
Feb  8 22:54:32.975: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod pod-service-account-7c4afe2a-2bf4-11e9-a551-0a580a020303-btkmm container namespace-test: <nil>
STEP: delete the pod
Feb  8 22:54:32.993: INFO: Waiting for pod pod-service-account-7c4afe2a-2bf4-11e9-a551-0a580a020303-btkmm to disappear
Feb  8 22:54:32.997: INFO: Pod pod-service-account-7c4afe2a-2bf4-11e9-a551-0a580a020303-btkmm no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:54:32.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-sxrpm" for this suite.
Feb  8 22:54:39.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:54:39.078: INFO: namespace: e2e-tests-svcaccounts-sxrpm, resource: bindings, ignored listing per whitelist
Feb  8 22:54:39.086: INFO: namespace e2e-tests-svcaccounts-sxrpm deletion completed in 6.086839823s

• [SLOW TEST:12.759 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:54:39.086: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-8399204d-2bf4-11e9-a551-0a580a020303
STEP: Creating a pod to test consume configMaps
Feb  8 22:54:39.148: INFO: Waiting up to 5m0s for pod "pod-configmaps-8399a640-2bf4-11e9-a551-0a580a020303" in namespace "e2e-tests-configmap-m77h2" to be "success or failure"
Feb  8 22:54:39.151: INFO: Pod "pod-configmaps-8399a640-2bf4-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 3.126085ms
Feb  8 22:54:41.155: INFO: Pod "pod-configmaps-8399a640-2bf4-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00691902s
STEP: Saw pod success
Feb  8 22:54:41.155: INFO: Pod "pod-configmaps-8399a640-2bf4-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:54:41.157: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod pod-configmaps-8399a640-2bf4-11e9-a551-0a580a020303 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  8 22:54:41.176: INFO: Waiting for pod pod-configmaps-8399a640-2bf4-11e9-a551-0a580a020303 to disappear
Feb  8 22:54:41.178: INFO: Pod pod-configmaps-8399a640-2bf4-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:54:41.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-m77h2" for this suite.
Feb  8 22:54:47.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:54:47.202: INFO: namespace: e2e-tests-configmap-m77h2, resource: bindings, ignored listing per whitelist
Feb  8 22:54:47.263: INFO: namespace e2e-tests-configmap-m77h2 deletion completed in 6.08189607s

• [SLOW TEST:8.177 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:54:47.263: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  8 22:54:47.368: INFO: Waiting up to 5m0s for pod "downwardapi-volume-88802df7-2bf4-11e9-a551-0a580a020303" in namespace "e2e-tests-downward-api-2ftlk" to be "success or failure"
Feb  8 22:54:47.374: INFO: Pod "downwardapi-volume-88802df7-2bf4-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 5.895007ms
Feb  8 22:54:49.377: INFO: Pod "downwardapi-volume-88802df7-2bf4-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009443621s
STEP: Saw pod success
Feb  8 22:54:49.377: INFO: Pod "downwardapi-volume-88802df7-2bf4-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:54:49.379: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod downwardapi-volume-88802df7-2bf4-11e9-a551-0a580a020303 container client-container: <nil>
STEP: delete the pod
Feb  8 22:54:49.399: INFO: Waiting for pod downwardapi-volume-88802df7-2bf4-11e9-a551-0a580a020303 to disappear
Feb  8 22:54:49.401: INFO: Pod downwardapi-volume-88802df7-2bf4-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:54:49.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2ftlk" for this suite.
Feb  8 22:54:55.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:54:55.476: INFO: namespace: e2e-tests-downward-api-2ftlk, resource: bindings, ignored listing per whitelist
Feb  8 22:54:55.488: INFO: namespace e2e-tests-downward-api-2ftlk deletion completed in 6.084532587s

• [SLOW TEST:8.225 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:54:55.489: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  8 22:54:55.548: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8d60423a-2bf4-11e9-a551-0a580a020303" in namespace "e2e-tests-downward-api-khxtx" to be "success or failure"
Feb  8 22:54:55.552: INFO: Pod "downwardapi-volume-8d60423a-2bf4-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 4.17136ms
Feb  8 22:54:57.556: INFO: Pod "downwardapi-volume-8d60423a-2bf4-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007713335s
STEP: Saw pod success
Feb  8 22:54:57.556: INFO: Pod "downwardapi-volume-8d60423a-2bf4-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:54:57.558: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod downwardapi-volume-8d60423a-2bf4-11e9-a551-0a580a020303 container client-container: <nil>
STEP: delete the pod
Feb  8 22:54:57.576: INFO: Waiting for pod downwardapi-volume-8d60423a-2bf4-11e9-a551-0a580a020303 to disappear
Feb  8 22:54:57.579: INFO: Pod downwardapi-volume-8d60423a-2bf4-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:54:57.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-khxtx" for this suite.
Feb  8 22:55:03.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:55:03.661: INFO: namespace: e2e-tests-downward-api-khxtx, resource: bindings, ignored listing per whitelist
Feb  8 22:55:03.676: INFO: namespace e2e-tests-downward-api-khxtx deletion completed in 6.094554826s

• [SLOW TEST:8.187 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:55:03.676: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  8 22:55:03.735: INFO: Waiting up to 5m0s for pod "downwardapi-volume-92414298-2bf4-11e9-a551-0a580a020303" in namespace "e2e-tests-downward-api-5n4rl" to be "success or failure"
Feb  8 22:55:03.737: INFO: Pod "downwardapi-volume-92414298-2bf4-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.563213ms
Feb  8 22:55:05.741: INFO: Pod "downwardapi-volume-92414298-2bf4-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006353604s
STEP: Saw pod success
Feb  8 22:55:05.741: INFO: Pod "downwardapi-volume-92414298-2bf4-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:55:05.743: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod downwardapi-volume-92414298-2bf4-11e9-a551-0a580a020303 container client-container: <nil>
STEP: delete the pod
Feb  8 22:55:05.761: INFO: Waiting for pod downwardapi-volume-92414298-2bf4-11e9-a551-0a580a020303 to disappear
Feb  8 22:55:05.764: INFO: Pod downwardapi-volume-92414298-2bf4-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:55:05.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5n4rl" for this suite.
Feb  8 22:55:11.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:55:11.850: INFO: namespace: e2e-tests-downward-api-5n4rl, resource: bindings, ignored listing per whitelist
Feb  8 22:55:11.854: INFO: namespace e2e-tests-downward-api-5n4rl deletion completed in 6.087077633s

• [SLOW TEST:8.178 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:55:11.854: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb  8 22:55:11.906: INFO: PodSpec: initContainers in spec.initContainers
Feb  8 22:55:59.909: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-972147c1-2bf4-11e9-a551-0a580a020303", GenerateName:"", Namespace:"e2e-tests-init-container-kqcp4", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-kqcp4/pods/pod-init-972147c1-2bf4-11e9-a551-0a580a020303", UID:"972205eb-2bf4-11e9-a760-02d2eeadbd48", ResourceVersion:"8530", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63685263311, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"906610595"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-6rfbp", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc422651140), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-6rfbp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-6rfbp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-6rfbp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc42251e0a8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-23-7-110.us-west-2.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc4222fff20), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc42251e120)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc42251e140)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc42251e148), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685263311, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685263311, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685263311, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685263311, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.23.7.110", PodIP:"10.2.1.93", StartTime:(*v1.Time)(0xc421dcc4e0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc42227c2a0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc42227c380)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://c49139406b01d8ebe4c0bc4ab4cc17d516c37667abb414066621dc931298cad6"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc421dcc520), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc421dcc500), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:55:59.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-kqcp4" for this suite.
Feb  8 22:56:21.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:56:21.968: INFO: namespace: e2e-tests-init-container-kqcp4, resource: bindings, ignored listing per whitelist
Feb  8 22:56:22.001: INFO: namespace e2e-tests-init-container-kqcp4 deletion completed in 22.088062721s

• [SLOW TEST:70.147 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:56:22.001: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb  8 22:56:26.089: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  8 22:56:26.091: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  8 22:56:28.091: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  8 22:56:28.095: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  8 22:56:30.091: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  8 22:56:30.095: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  8 22:56:32.091: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  8 22:56:32.095: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  8 22:56:34.091: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  8 22:56:34.095: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  8 22:56:36.091: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  8 22:56:36.095: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  8 22:56:38.091: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  8 22:56:38.095: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  8 22:56:40.091: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  8 22:56:40.095: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  8 22:56:42.091: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  8 22:56:42.095: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  8 22:56:44.091: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  8 22:56:44.095: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  8 22:56:46.091: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  8 22:56:46.095: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:56:46.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-46mjt" for this suite.
Feb  8 22:57:08.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:57:08.184: INFO: namespace: e2e-tests-container-lifecycle-hook-46mjt, resource: bindings, ignored listing per whitelist
Feb  8 22:57:08.191: INFO: namespace e2e-tests-container-lifecycle-hook-46mjt deletion completed in 22.084742225s

• [SLOW TEST:46.190 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:57:08.191: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  8 22:57:08.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 version --client'
Feb  8 22:57:08.303: INFO: stderr: ""
Feb  8 22:57:08.303: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Feb  8 22:57:08.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 create -f - --namespace=e2e-tests-kubectl-z5h8h'
Feb  8 22:57:08.605: INFO: stderr: ""
Feb  8 22:57:08.605: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb  8 22:57:08.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 create -f - --namespace=e2e-tests-kubectl-z5h8h'
Feb  8 22:57:08.764: INFO: stderr: ""
Feb  8 22:57:08.764: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb  8 22:57:09.768: INFO: Selector matched 1 pods for map[app:redis]
Feb  8 22:57:09.768: INFO: Found 0 / 1
Feb  8 22:57:10.768: INFO: Selector matched 1 pods for map[app:redis]
Feb  8 22:57:10.768: INFO: Found 1 / 1
Feb  8 22:57:10.768: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb  8 22:57:10.770: INFO: Selector matched 1 pods for map[app:redis]
Feb  8 22:57:10.770: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb  8 22:57:10.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 describe pod redis-master-lvdhw --namespace=e2e-tests-kubectl-z5h8h'
Feb  8 22:57:10.859: INFO: stderr: ""
Feb  8 22:57:10.859: INFO: stdout: "Name:               redis-master-lvdhw\nNamespace:          e2e-tests-kubectl-z5h8h\nPriority:           0\nPriorityClassName:  <none>\nNode:               ip-172-23-7-130.us-west-2.compute.internal/172.23.7.130\nStart Time:         Fri, 08 Feb 2019 22:57:08 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.2.2.68\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://6af49cf5e97729a14d7a9bd9f0fe508bcb7f64e08386aba39d8c557a5e36d773\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 08 Feb 2019 22:57:09 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-7258z (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-7258z:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-7258z\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                 Message\n  ----    ------     ----  ----                                                 -------\n  Normal  Scheduled  2s    default-scheduler                                    Successfully assigned e2e-tests-kubectl-z5h8h/redis-master-lvdhw to ip-172-23-7-130.us-west-2.compute.internal\n  Normal  Pulled     1s    kubelet, ip-172-23-7-130.us-west-2.compute.internal  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, ip-172-23-7-130.us-west-2.compute.internal  Created container\n  Normal  Started    1s    kubelet, ip-172-23-7-130.us-west-2.compute.internal  Started container\n"
Feb  8 22:57:10.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 describe rc redis-master --namespace=e2e-tests-kubectl-z5h8h'
Feb  8 22:57:10.955: INFO: stderr: ""
Feb  8 22:57:10.955: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-z5h8h\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-lvdhw\n"
Feb  8 22:57:10.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 describe service redis-master --namespace=e2e-tests-kubectl-z5h8h'
Feb  8 22:57:11.041: INFO: stderr: ""
Feb  8 22:57:11.041: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-z5h8h\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.3.0.211\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.2.2.68:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb  8 22:57:11.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 describe node ip-172-23-7-110.us-west-2.compute.internal'
Feb  8 22:57:11.145: INFO: stderr: ""
Feb  8 22:57:11.145: INFO: stdout: "Name:               ip-172-23-7-110.us-west-2.compute.internal\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=t2.large\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-west-2\n                    failure-domain.beta.kubernetes.io/zone=us-west-2a\n                    kubernetes.io/hostname=ip-172-23-7-110.us-west-2.compute.internal\n                    stackpoint.io/cluster_id=5704\n                    stackpoint.io/instance_id=netb9x95g0-worker-3\n                    stackpoint.io/node_group=autoscaling-netb9x95g0-pool-1\n                    stackpoint.io/node_id=18213\n                    stackpoint.io/node_pool=Default-Worker-Pool\n                    stackpoint.io/private_ip=172.23.7.110\n                    stackpoint.io/role=worker\n                    stackpoint.io/size=t2.large\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"4a:2f:71:b5:93:83\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 172.23.7.110\n                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 08 Feb 2019 22:14:47 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Fri, 08 Feb 2019 22:57:02 +0000   Fri, 08 Feb 2019 22:14:47 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Fri, 08 Feb 2019 22:57:02 +0000   Fri, 08 Feb 2019 22:14:47 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Fri, 08 Feb 2019 22:57:02 +0000   Fri, 08 Feb 2019 22:14:47 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Fri, 08 Feb 2019 22:57:02 +0000   Fri, 08 Feb 2019 22:14:47 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Fri, 08 Feb 2019 22:57:02 +0000   Fri, 08 Feb 2019 22:15:18 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:   172.23.7.110\n  ExternalIP:   34.220.200.70\n  InternalDNS:  ip-172-23-7-110.us-west-2.compute.internal\n  ExternalDNS:  ec2-34-220-200-70.us-west-2.compute.amazonaws.com\n  Hostname:     ip-172-23-7-110.us-west-2.compute.internal\nCapacity:\n attachable-volumes-aws-ebs:  39\n cpu:                         2\n ephemeral-storage:           50758760Ki\n hugepages-2Mi:               0\n memory:                      8173744Ki\n pods:                        110\nAllocatable:\n attachable-volumes-aws-ebs:  39\n cpu:                         2\n ephemeral-storage:           46779273139\n hugepages-2Mi:               0\n memory:                      8071344Ki\n pods:                        110\nSystem Info:\n Machine ID:                 04750f7db24e4aa89e426bbc3758c8bc\n System UUID:                EC273D6A-B9B3-C115-C01B-387CFA32CA8E\n Boot ID:                    ec229290-5924-480d-bb4d-5e188d752d32\n Kernel Version:             4.4.0-1075-aws\n OS Image:                   Ubuntu 16.04.5 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.0\n Kubelet Version:            v1.12.4\n Kube-Proxy Version:         v1.12.4\nPodCIDR:                     10.2.1.0/24\nProviderID:                  aws:///us-west-2a/i-0d92d50c4f94d3364\nNon-terminated Pods:         (4 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-97ae410a3d2d4a52-tsw98    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-flannel-ds-5cwbb                                      100m (5%)     100m (5%)   50Mi (0%)        50Mi (0%)\n  kube-system                kube-proxy-74ndc                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                tiller-deploy-6fb6d4777d-pswxg                             0 (0%)        0 (0%)      0 (0%)           0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                    Requests   Limits\n  --------                    --------   ------\n  cpu                         100m (5%)  100m (5%)\n  memory                      50Mi (0%)  50Mi (0%)\n  attachable-volumes-aws-ebs  0          0\nEvents:\n  Type    Reason                   Age   From                                                 Message\n  ----    ------                   ----  ----                                                 -------\n  Normal  Starting                 42m   kubelet, ip-172-23-7-110.us-west-2.compute.internal  Starting kubelet.\n  Normal  NodeHasSufficientDisk    42m   kubelet, ip-172-23-7-110.us-west-2.compute.internal  Node ip-172-23-7-110.us-west-2.compute.internal status is now: NodeHasSufficientDisk\n  Normal  NodeHasSufficientMemory  42m   kubelet, ip-172-23-7-110.us-west-2.compute.internal  Node ip-172-23-7-110.us-west-2.compute.internal status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    42m   kubelet, ip-172-23-7-110.us-west-2.compute.internal  Node ip-172-23-7-110.us-west-2.compute.internal status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     42m   kubelet, ip-172-23-7-110.us-west-2.compute.internal  Node ip-172-23-7-110.us-west-2.compute.internal status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  42m   kubelet, ip-172-23-7-110.us-west-2.compute.internal  Updated Node Allocatable limit across pods\n  Normal  NodeReady                41m   kubelet, ip-172-23-7-110.us-west-2.compute.internal  Node ip-172-23-7-110.us-west-2.compute.internal status is now: NodeReady\n"
Feb  8 22:57:11.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 describe namespace e2e-tests-kubectl-z5h8h'
Feb  8 22:57:11.235: INFO: stderr: ""
Feb  8 22:57:11.235: INFO: stdout: "Name:         e2e-tests-kubectl-z5h8h\nLabels:       e2e-framework=kubectl\n              e2e-run=ab0032aa-2bef-11e9-a551-0a580a020303\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:57:11.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-z5h8h" for this suite.
Feb  8 22:57:33.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:57:33.322: INFO: namespace: e2e-tests-kubectl-z5h8h, resource: bindings, ignored listing per whitelist
Feb  8 22:57:33.322: INFO: namespace e2e-tests-kubectl-z5h8h deletion completed in 22.083155032s

• [SLOW TEST:25.131 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:57:33.322: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-cldtq in namespace e2e-tests-proxy-zdnzl
I0208 22:57:33.392074      14 runners.go:180] Created replication controller with name: proxy-service-cldtq, namespace: e2e-tests-proxy-zdnzl, replica count: 1
I0208 22:57:34.442487      14 runners.go:180] proxy-service-cldtq Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0208 22:57:35.442761      14 runners.go:180] proxy-service-cldtq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0208 22:57:36.443003      14 runners.go:180] proxy-service-cldtq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0208 22:57:37.443276      14 runners.go:180] proxy-service-cldtq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0208 22:57:38.443486      14 runners.go:180] proxy-service-cldtq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0208 22:57:39.443715      14 runners.go:180] proxy-service-cldtq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0208 22:57:40.443947      14 runners.go:180] proxy-service-cldtq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0208 22:57:41.444179      14 runners.go:180] proxy-service-cldtq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0208 22:57:42.444417      14 runners.go:180] proxy-service-cldtq Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb  8 22:57:42.447: INFO: setup took 9.071278864s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb  8 22:57:42.458: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/... (200; 9.99519ms)
Feb  8 22:57:42.461: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname2/proxy/: bar (200; 13.845608ms)
Feb  8 22:57:42.462: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/rewriteme"... (200; 14.145455ms)
Feb  8 22:57:42.462: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname1/proxy/: foo (200; 13.995899ms)
Feb  8 22:57:42.464: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:162/proxy/: bar (200; 16.078815ms)
Feb  8 22:57:42.464: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/rewri... (200; 16.261065ms)
Feb  8 22:57:42.464: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:160/proxy/: foo (200; 16.169182ms)
Feb  8 22:57:42.466: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:162/proxy/: bar (200; 18.196292ms)
Feb  8 22:57:42.466: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname1/proxy/: foo (200; 18.80907ms)
Feb  8 22:57:42.466: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname2/proxy/: bar (200; 18.714684ms)
Feb  8 22:57:42.466: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:160/proxy/: foo (200; 18.908564ms)
Feb  8 22:57:42.467: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:462/proxy/: tls qux (200; 20.035068ms)
Feb  8 22:57:42.467: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/... (200; 19.671026ms)
Feb  8 22:57:42.468: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname1/proxy/: tls baz (200; 20.342518ms)
Feb  8 22:57:42.468: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:460/proxy/: tls baz (200; 20.405645ms)
Feb  8 22:57:42.468: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname2/proxy/: tls qux (200; 20.70618ms)
Feb  8 22:57:42.472: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:460/proxy/: tls baz (200; 4.244411ms)
Feb  8 22:57:42.475: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:462/proxy/: tls qux (200; 6.096235ms)
Feb  8 22:57:42.475: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:160/proxy/: foo (200; 6.440276ms)
Feb  8 22:57:42.475: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/... (200; 6.626392ms)
Feb  8 22:57:42.475: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:162/proxy/: bar (200; 6.64774ms)
Feb  8 22:57:42.477: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/rewriteme"... (200; 8.249472ms)
Feb  8 22:57:42.477: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:162/proxy/: bar (200; 8.608824ms)
Feb  8 22:57:42.478: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/... (200; 8.881668ms)
Feb  8 22:57:42.479: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:160/proxy/: foo (200; 10.188522ms)
Feb  8 22:57:42.479: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/rewri... (200; 10.639198ms)
Feb  8 22:57:42.479: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname1/proxy/: foo (200; 10.711442ms)
Feb  8 22:57:42.479: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname1/proxy/: foo (200; 10.848673ms)
Feb  8 22:57:42.481: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname1/proxy/: tls baz (200; 12.078702ms)
Feb  8 22:57:42.481: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname2/proxy/: tls qux (200; 12.120812ms)
Feb  8 22:57:42.481: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname2/proxy/: bar (200; 12.036087ms)
Feb  8 22:57:42.481: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname2/proxy/: bar (200; 12.207044ms)
Feb  8 22:57:42.489: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/rewri... (200; 7.467439ms)
Feb  8 22:57:42.489: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:462/proxy/: tls qux (200; 7.497636ms)
Feb  8 22:57:42.489: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:162/proxy/: bar (200; 7.658896ms)
Feb  8 22:57:42.489: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:460/proxy/: tls baz (200; 8.059667ms)
Feb  8 22:57:42.490: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/rewriteme"... (200; 8.558867ms)
Feb  8 22:57:42.490: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/... (200; 8.568866ms)
Feb  8 22:57:42.490: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:160/proxy/: foo (200; 8.848556ms)
Feb  8 22:57:42.490: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:160/proxy/: foo (200; 8.486381ms)
Feb  8 22:57:42.490: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/... (200; 8.728951ms)
Feb  8 22:57:42.490: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname2/proxy/: bar (200; 9.047566ms)
Feb  8 22:57:42.490: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:162/proxy/: bar (200; 9.200409ms)
Feb  8 22:57:42.493: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname2/proxy/: tls qux (200; 11.837731ms)
Feb  8 22:57:42.494: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname1/proxy/: foo (200; 12.710847ms)
Feb  8 22:57:42.494: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname1/proxy/: tls baz (200; 13.31157ms)
Feb  8 22:57:42.494: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname1/proxy/: foo (200; 13.229403ms)
Feb  8 22:57:42.494: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname2/proxy/: bar (200; 13.459291ms)
Feb  8 22:57:42.502: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/... (200; 7.199744ms)
Feb  8 22:57:42.502: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:462/proxy/: tls qux (200; 6.861255ms)
Feb  8 22:57:42.502: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:460/proxy/: tls baz (200; 7.332663ms)
Feb  8 22:57:42.502: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:162/proxy/: bar (200; 7.391209ms)
Feb  8 22:57:42.502: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/rewriteme"... (200; 7.131613ms)
Feb  8 22:57:42.502: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/rewri... (200; 7.476964ms)
Feb  8 22:57:42.503: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:162/proxy/: bar (200; 7.941368ms)
Feb  8 22:57:42.503: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname1/proxy/: foo (200; 8.557836ms)
Feb  8 22:57:42.503: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:160/proxy/: foo (200; 8.178423ms)
Feb  8 22:57:42.504: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname1/proxy/: foo (200; 8.965007ms)
Feb  8 22:57:42.505: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/... (200; 9.224776ms)
Feb  8 22:57:42.505: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname2/proxy/: tls qux (200; 9.899457ms)
Feb  8 22:57:42.505: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname2/proxy/: bar (200; 9.702698ms)
Feb  8 22:57:42.505: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:160/proxy/: foo (200; 9.922506ms)
Feb  8 22:57:42.506: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname1/proxy/: tls baz (200; 10.636457ms)
Feb  8 22:57:42.507: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname2/proxy/: bar (200; 11.372751ms)
Feb  8 22:57:42.513: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/... (200; 6.268607ms)
Feb  8 22:57:42.516: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/rewri... (200; 8.335892ms)
Feb  8 22:57:42.516: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:460/proxy/: tls baz (200; 8.851016ms)
Feb  8 22:57:42.516: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/... (200; 9.328407ms)
Feb  8 22:57:42.516: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:160/proxy/: foo (200; 9.421338ms)
Feb  8 22:57:42.516: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:162/proxy/: bar (200; 9.230082ms)
Feb  8 22:57:42.516: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:160/proxy/: foo (200; 9.587785ms)
Feb  8 22:57:42.517: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/rewriteme"... (200; 9.524817ms)
Feb  8 22:57:42.517: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname1/proxy/: tls baz (200; 9.911373ms)
Feb  8 22:57:42.517: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:462/proxy/: tls qux (200; 10.203767ms)
Feb  8 22:57:42.517: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:162/proxy/: bar (200; 10.183043ms)
Feb  8 22:57:42.521: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname2/proxy/: tls qux (200; 13.743043ms)
Feb  8 22:57:42.524: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname1/proxy/: foo (200; 16.466796ms)
Feb  8 22:57:42.524: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname2/proxy/: bar (200; 16.903731ms)
Feb  8 22:57:42.524: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname2/proxy/: bar (200; 16.906709ms)
Feb  8 22:57:42.527: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname1/proxy/: foo (200; 19.36909ms)
Feb  8 22:57:42.533: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:162/proxy/: bar (200; 6.503853ms)
Feb  8 22:57:42.534: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/rewriteme"... (200; 6.538939ms)
Feb  8 22:57:42.534: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/rewri... (200; 7.0033ms)
Feb  8 22:57:42.534: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:160/proxy/: foo (200; 6.800649ms)
Feb  8 22:57:42.534: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:462/proxy/: tls qux (200; 7.189727ms)
Feb  8 22:57:42.535: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:162/proxy/: bar (200; 7.9709ms)
Feb  8 22:57:42.535: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:160/proxy/: foo (200; 8.295534ms)
Feb  8 22:57:42.536: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:460/proxy/: tls baz (200; 8.121837ms)
Feb  8 22:57:42.536: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/... (200; 8.348574ms)
Feb  8 22:57:42.537: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/... (200; 9.053075ms)
Feb  8 22:57:42.537: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname1/proxy/: foo (200; 9.945574ms)
Feb  8 22:57:42.537: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname2/proxy/: tls qux (200; 9.814864ms)
Feb  8 22:57:42.537: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname1/proxy/: foo (200; 10.299226ms)
Feb  8 22:57:42.538: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname2/proxy/: bar (200; 10.550312ms)
Feb  8 22:57:42.539: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname2/proxy/: bar (200; 11.685083ms)
Feb  8 22:57:42.540: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname1/proxy/: tls baz (200; 12.386612ms)
Feb  8 22:57:42.547: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:160/proxy/: foo (200; 6.303163ms)
Feb  8 22:57:42.547: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:460/proxy/: tls baz (200; 7.247913ms)
Feb  8 22:57:42.547: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/... (200; 7.192039ms)
Feb  8 22:57:42.547: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:162/proxy/: bar (200; 7.152754ms)
Feb  8 22:57:42.548: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/rewri... (200; 8.115332ms)
Feb  8 22:57:42.549: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname1/proxy/: foo (200; 8.827916ms)
Feb  8 22:57:42.549: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname2/proxy/: tls qux (200; 8.489696ms)
Feb  8 22:57:42.549: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:162/proxy/: bar (200; 8.944092ms)
Feb  8 22:57:42.549: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:462/proxy/: tls qux (200; 9.155103ms)
Feb  8 22:57:42.550: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:160/proxy/: foo (200; 8.741036ms)
Feb  8 22:57:42.550: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/... (200; 8.818238ms)
Feb  8 22:57:42.551: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname2/proxy/: bar (200; 10.061506ms)
Feb  8 22:57:42.551: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/rewriteme"... (200; 10.038395ms)
Feb  8 22:57:42.551: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname2/proxy/: bar (200; 10.443648ms)
Feb  8 22:57:42.551: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname1/proxy/: tls baz (200; 10.473015ms)
Feb  8 22:57:42.552: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname1/proxy/: foo (200; 11.58685ms)
Feb  8 22:57:42.559: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:460/proxy/: tls baz (200; 7.415341ms)
Feb  8 22:57:42.559: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/... (200; 6.485177ms)
Feb  8 22:57:42.560: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/rewriteme"... (200; 6.888257ms)
Feb  8 22:57:42.560: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:160/proxy/: foo (200; 7.028387ms)
Feb  8 22:57:42.560: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/... (200; 7.87922ms)
Feb  8 22:57:42.561: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/rewri... (200; 8.541471ms)
Feb  8 22:57:42.561: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:462/proxy/: tls qux (200; 8.508052ms)
Feb  8 22:57:42.561: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:162/proxy/: bar (200; 8.5393ms)
Feb  8 22:57:42.561: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname1/proxy/: foo (200; 8.912428ms)
Feb  8 22:57:42.561: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:160/proxy/: foo (200; 8.69207ms)
Feb  8 22:57:42.561: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:162/proxy/: bar (200; 9.10026ms)
Feb  8 22:57:42.563: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname2/proxy/: bar (200; 10.612308ms)
Feb  8 22:57:42.564: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname2/proxy/: bar (200; 11.985974ms)
Feb  8 22:57:42.565: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname2/proxy/: tls qux (200; 12.129184ms)
Feb  8 22:57:42.565: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname1/proxy/: foo (200; 12.662439ms)
Feb  8 22:57:42.565: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname1/proxy/: tls baz (200; 12.195017ms)
Feb  8 22:57:42.572: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/... (200; 6.477247ms)
Feb  8 22:57:42.572: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:462/proxy/: tls qux (200; 7.719662ms)
Feb  8 22:57:42.573: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/... (200; 7.077919ms)
Feb  8 22:57:42.573: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/rewri... (200; 6.650956ms)
Feb  8 22:57:42.573: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:160/proxy/: foo (200; 7.585898ms)
Feb  8 22:57:42.573: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:460/proxy/: tls baz (200; 7.080125ms)
Feb  8 22:57:42.573: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:160/proxy/: foo (200; 7.71604ms)
Feb  8 22:57:42.573: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:162/proxy/: bar (200; 7.656898ms)
Feb  8 22:57:42.573: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/rewriteme"... (200; 7.909927ms)
Feb  8 22:57:42.573: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:162/proxy/: bar (200; 7.098728ms)
Feb  8 22:57:42.574: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname2/proxy/: bar (200; 8.702573ms)
Feb  8 22:57:42.575: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname2/proxy/: bar (200; 9.681878ms)
Feb  8 22:57:42.576: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname1/proxy/: foo (200; 10.299155ms)
Feb  8 22:57:42.576: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname2/proxy/: tls qux (200; 10.86472ms)
Feb  8 22:57:42.576: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname1/proxy/: foo (200; 10.630008ms)
Feb  8 22:57:42.577: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname1/proxy/: tls baz (200; 11.333822ms)
Feb  8 22:57:42.584: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:460/proxy/: tls baz (200; 7.774496ms)
Feb  8 22:57:42.585: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/... (200; 7.728568ms)
Feb  8 22:57:42.585: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:462/proxy/: tls qux (200; 7.373017ms)
Feb  8 22:57:42.585: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/rewriteme"... (200; 7.051548ms)
Feb  8 22:57:42.585: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:162/proxy/: bar (200; 7.727473ms)
Feb  8 22:57:42.585: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/rewri... (200; 7.523565ms)
Feb  8 22:57:42.585: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:162/proxy/: bar (200; 7.0052ms)
Feb  8 22:57:42.585: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:160/proxy/: foo (200; 7.17256ms)
Feb  8 22:57:42.586: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname1/proxy/: foo (200; 9.081674ms)
Feb  8 22:57:42.586: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname1/proxy/: foo (200; 9.485202ms)
Feb  8 22:57:42.586: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname2/proxy/: bar (200; 9.176203ms)
Feb  8 22:57:42.587: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:160/proxy/: foo (200; 9.042426ms)
Feb  8 22:57:42.587: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/... (200; 9.010272ms)
Feb  8 22:57:42.588: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname1/proxy/: tls baz (200; 10.40448ms)
Feb  8 22:57:42.588: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname2/proxy/: tls qux (200; 10.441677ms)
Feb  8 22:57:42.588: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname2/proxy/: bar (200; 10.823935ms)
Feb  8 22:57:42.595: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/... (200; 6.164742ms)
Feb  8 22:57:42.595: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/rewri... (200; 7.119334ms)
Feb  8 22:57:42.595: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:162/proxy/: bar (200; 6.487178ms)
Feb  8 22:57:42.595: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/... (200; 6.730987ms)
Feb  8 22:57:42.596: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/rewriteme"... (200; 7.013412ms)
Feb  8 22:57:42.596: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:160/proxy/: foo (200; 6.951198ms)
Feb  8 22:57:42.596: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:460/proxy/: tls baz (200; 6.915726ms)
Feb  8 22:57:42.596: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:162/proxy/: bar (200; 7.719298ms)
Feb  8 22:57:42.596: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:462/proxy/: tls qux (200; 7.84489ms)
Feb  8 22:57:42.596: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:160/proxy/: foo (200; 7.471405ms)
Feb  8 22:57:42.597: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname1/proxy/: tls baz (200; 8.947569ms)
Feb  8 22:57:42.598: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname1/proxy/: foo (200; 9.693178ms)
Feb  8 22:57:42.599: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname2/proxy/: tls qux (200; 10.323135ms)
Feb  8 22:57:42.599: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname1/proxy/: foo (200; 9.997651ms)
Feb  8 22:57:42.599: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname2/proxy/: bar (200; 10.818957ms)
Feb  8 22:57:42.599: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname2/proxy/: bar (200; 10.953907ms)
Feb  8 22:57:42.607: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:160/proxy/: foo (200; 7.282021ms)
Feb  8 22:57:42.607: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/... (200; 7.216632ms)
Feb  8 22:57:42.608: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:162/proxy/: bar (200; 7.473845ms)
Feb  8 22:57:42.608: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:460/proxy/: tls baz (200; 7.620763ms)
Feb  8 22:57:42.608: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/rewri... (200; 8.310992ms)
Feb  8 22:57:42.608: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:462/proxy/: tls qux (200; 7.548161ms)
Feb  8 22:57:42.608: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/... (200; 7.890619ms)
Feb  8 22:57:42.608: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:160/proxy/: foo (200; 8.328827ms)
Feb  8 22:57:42.608: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:162/proxy/: bar (200; 8.478553ms)
Feb  8 22:57:42.608: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/rewriteme"... (200; 8.746062ms)
Feb  8 22:57:42.609: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname2/proxy/: bar (200; 10.03172ms)
Feb  8 22:57:42.610: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname1/proxy/: foo (200; 10.045313ms)
Feb  8 22:57:42.612: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname1/proxy/: tls baz (200; 12.129761ms)
Feb  8 22:57:42.612: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname2/proxy/: bar (200; 11.736081ms)
Feb  8 22:57:42.612: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname1/proxy/: foo (200; 11.426113ms)
Feb  8 22:57:42.612: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname2/proxy/: tls qux (200; 12.179383ms)
Feb  8 22:57:42.621: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/... (200; 8.612955ms)
Feb  8 22:57:42.621: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:460/proxy/: tls baz (200; 8.599857ms)
Feb  8 22:57:42.621: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:162/proxy/: bar (200; 8.736258ms)
Feb  8 22:57:42.621: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:160/proxy/: foo (200; 8.871887ms)
Feb  8 22:57:42.621: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:162/proxy/: bar (200; 8.903231ms)
Feb  8 22:57:42.621: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/... (200; 8.684694ms)
Feb  8 22:57:42.621: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/rewri... (200; 8.833152ms)
Feb  8 22:57:42.621: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:160/proxy/: foo (200; 9.226396ms)
Feb  8 22:57:42.621: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:462/proxy/: tls qux (200; 9.249557ms)
Feb  8 22:57:42.622: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/rewriteme"... (200; 9.847824ms)
Feb  8 22:57:42.622: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname1/proxy/: tls baz (200; 9.896196ms)
Feb  8 22:57:42.622: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname2/proxy/: bar (200; 10.164313ms)
Feb  8 22:57:42.622: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname2/proxy/: bar (200; 10.249019ms)
Feb  8 22:57:42.622: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname1/proxy/: foo (200; 10.263266ms)
Feb  8 22:57:42.622: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname1/proxy/: foo (200; 10.313266ms)
Feb  8 22:57:42.623: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname2/proxy/: tls qux (200; 10.9718ms)
Feb  8 22:57:42.627: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/... (200; 3.51925ms)
Feb  8 22:57:42.628: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/rewriteme"... (200; 5.059413ms)
Feb  8 22:57:42.629: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:460/proxy/: tls baz (200; 5.48658ms)
Feb  8 22:57:42.629: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:162/proxy/: bar (200; 5.130998ms)
Feb  8 22:57:42.630: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/... (200; 6.12351ms)
Feb  8 22:57:42.632: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:162/proxy/: bar (200; 8.593071ms)
Feb  8 22:57:42.632: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:160/proxy/: foo (200; 8.67269ms)
Feb  8 22:57:42.632: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:160/proxy/: foo (200; 8.658252ms)
Feb  8 22:57:42.633: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname2/proxy/: bar (200; 9.514018ms)
Feb  8 22:57:42.633: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:462/proxy/: tls qux (200; 9.879752ms)
Feb  8 22:57:42.634: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/rewri... (200; 10.031082ms)
Feb  8 22:57:42.634: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname1/proxy/: tls baz (200; 10.121353ms)
Feb  8 22:57:42.634: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname2/proxy/: bar (200; 10.250462ms)
Feb  8 22:57:42.635: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname2/proxy/: tls qux (200; 11.844213ms)
Feb  8 22:57:42.635: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname1/proxy/: foo (200; 11.863403ms)
Feb  8 22:57:42.635: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname1/proxy/: foo (200; 11.996092ms)
Feb  8 22:57:42.641: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:462/proxy/: tls qux (200; 4.968164ms)
Feb  8 22:57:42.642: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/rewri... (200; 5.921778ms)
Feb  8 22:57:42.642: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/rewriteme"... (200; 5.899192ms)
Feb  8 22:57:42.642: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:160/proxy/: foo (200; 6.29898ms)
Feb  8 22:57:42.642: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:160/proxy/: foo (200; 6.411925ms)
Feb  8 22:57:42.643: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:162/proxy/: bar (200; 6.693044ms)
Feb  8 22:57:42.646: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:460/proxy/: tls baz (200; 9.604797ms)
Feb  8 22:57:42.646: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/... (200; 9.759492ms)
Feb  8 22:57:42.646: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/... (200; 9.685966ms)
Feb  8 22:57:42.646: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname1/proxy/: foo (200; 10.560538ms)
Feb  8 22:57:42.647: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname2/proxy/: tls qux (200; 11.252699ms)
Feb  8 22:57:42.647: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:162/proxy/: bar (200; 10.61946ms)
Feb  8 22:57:42.647: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname1/proxy/: foo (200; 11.020275ms)
Feb  8 22:57:42.648: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname1/proxy/: tls baz (200; 11.516762ms)
Feb  8 22:57:42.648: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname2/proxy/: bar (200; 11.742127ms)
Feb  8 22:57:42.648: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname2/proxy/: bar (200; 11.804674ms)
Feb  8 22:57:42.656: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:160/proxy/: foo (200; 7.52072ms)
Feb  8 22:57:42.656: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/... (200; 7.063058ms)
Feb  8 22:57:42.656: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/rewriteme"... (200; 7.520132ms)
Feb  8 22:57:42.656: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:162/proxy/: bar (200; 7.448804ms)
Feb  8 22:57:42.656: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:160/proxy/: foo (200; 7.729559ms)
Feb  8 22:57:42.657: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname2/proxy/: tls qux (200; 8.74694ms)
Feb  8 22:57:42.658: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:462/proxy/: tls qux (200; 9.541057ms)
Feb  8 22:57:42.658: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/... (200; 8.938048ms)
Feb  8 22:57:42.658: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/rewri... (200; 9.761437ms)
Feb  8 22:57:42.658: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:460/proxy/: tls baz (200; 9.743951ms)
Feb  8 22:57:42.659: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname2/proxy/: bar (200; 10.373916ms)
Feb  8 22:57:42.659: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname1/proxy/: tls baz (200; 10.706686ms)
Feb  8 22:57:42.659: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname2/proxy/: bar (200; 10.914109ms)
Feb  8 22:57:42.659: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname1/proxy/: foo (200; 11.546714ms)
Feb  8 22:57:42.660: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:162/proxy/: bar (200; 11.365988ms)
Feb  8 22:57:42.660: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname1/proxy/: foo (200; 10.771507ms)
Feb  8 22:57:42.666: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:162/proxy/: bar (200; 6.22212ms)
Feb  8 22:57:42.666: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:462/proxy/: tls qux (200; 6.346376ms)
Feb  8 22:57:42.666: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/rewri... (200; 6.448081ms)
Feb  8 22:57:42.666: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/rewriteme"... (200; 6.252576ms)
Feb  8 22:57:42.667: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:160/proxy/: foo (200; 6.793015ms)
Feb  8 22:57:42.667: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:160/proxy/: foo (200; 7.062318ms)
Feb  8 22:57:42.668: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:162/proxy/: bar (200; 7.196747ms)
Feb  8 22:57:42.668: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/... (200; 7.522168ms)
Feb  8 22:57:42.668: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:460/proxy/: tls baz (200; 7.705969ms)
Feb  8 22:57:42.669: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname2/proxy/: tls qux (200; 8.510639ms)
Feb  8 22:57:42.669: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname1/proxy/: foo (200; 9.082302ms)
Feb  8 22:57:42.670: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname2/proxy/: bar (200; 9.077399ms)
Feb  8 22:57:42.671: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname1/proxy/: tls baz (200; 9.92231ms)
Feb  8 22:57:42.671: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname2/proxy/: bar (200; 10.253743ms)
Feb  8 22:57:42.671: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname1/proxy/: foo (200; 11.538584ms)
Feb  8 22:57:42.673: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/... (200; 11.913288ms)
Feb  8 22:57:42.678: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:462/proxy/: tls qux (200; 4.802545ms)
Feb  8 22:57:42.678: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/rewriteme"... (200; 5.204691ms)
Feb  8 22:57:42.679: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:162/proxy/: bar (200; 5.400286ms)
Feb  8 22:57:42.679: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:160/proxy/: foo (200; 5.805653ms)
Feb  8 22:57:42.679: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:160/proxy/: foo (200; 5.758556ms)
Feb  8 22:57:42.680: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/... (200; 6.838053ms)
Feb  8 22:57:42.681: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/... (200; 7.179069ms)
Feb  8 22:57:42.681: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:460/proxy/: tls baz (200; 7.170911ms)
Feb  8 22:57:42.682: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname2/proxy/: tls qux (200; 9.129258ms)
Feb  8 22:57:42.684: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/rewri... (200; 9.957445ms)
Feb  8 22:57:42.684: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname1/proxy/: tls baz (200; 10.754063ms)
Feb  8 22:57:42.684: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:162/proxy/: bar (200; 10.481311ms)
Feb  8 22:57:42.684: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname2/proxy/: bar (200; 11.317635ms)
Feb  8 22:57:42.685: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname2/proxy/: bar (200; 11.433192ms)
Feb  8 22:57:42.685: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname1/proxy/: foo (200; 11.182991ms)
Feb  8 22:57:42.686: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname1/proxy/: foo (200; 11.939096ms)
Feb  8 22:57:42.692: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/rewri... (200; 6.143896ms)
Feb  8 22:57:42.694: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:162/proxy/: bar (200; 7.751693ms)
Feb  8 22:57:42.694: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:462/proxy/: tls qux (200; 8.692007ms)
Feb  8 22:57:42.694: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/rewriteme"... (200; 8.570542ms)
Feb  8 22:57:42.695: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/... (200; 8.244446ms)
Feb  8 22:57:42.695: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:162/proxy/: bar (200; 8.211664ms)
Feb  8 22:57:42.695: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:460/proxy/: tls baz (200; 8.809722ms)
Feb  8 22:57:42.695: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/... (200; 9.014962ms)
Feb  8 22:57:42.695: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:160/proxy/: foo (200; 9.550282ms)
Feb  8 22:57:42.695: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:160/proxy/: foo (200; 9.401532ms)
Feb  8 22:57:42.696: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname1/proxy/: foo (200; 10.005368ms)
Feb  8 22:57:42.697: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname2/proxy/: bar (200; 10.400867ms)
Feb  8 22:57:42.697: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname1/proxy/: foo (200; 10.202308ms)
Feb  8 22:57:42.697: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname2/proxy/: tls qux (200; 11.157338ms)
Feb  8 22:57:42.697: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname2/proxy/: bar (200; 11.110576ms)
Feb  8 22:57:42.697: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname1/proxy/: tls baz (200; 11.004808ms)
Feb  8 22:57:42.704: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:462/proxy/: tls qux (200; 6.517355ms)
Feb  8 22:57:42.704: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:1080/proxy/rewri... (200; 6.731662ms)
Feb  8 22:57:42.704: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:460/proxy/: tls baz (200; 6.437075ms)
Feb  8 22:57:42.705: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/https:proxy-service-cldtq-85qvc:443/proxy/... (200; 7.150947ms)
Feb  8 22:57:42.705: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc/proxy/rewriteme"... (200; 7.558445ms)
Feb  8 22:57:42.705: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:1080/proxy/... (200; 7.174725ms)
Feb  8 22:57:42.705: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:160/proxy/: foo (200; 7.702914ms)
Feb  8 22:57:42.705: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:160/proxy/: foo (200; 7.68402ms)
Feb  8 22:57:42.705: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/http:proxy-service-cldtq-85qvc:162/proxy/: bar (200; 7.638941ms)
Feb  8 22:57:42.705: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdnzl/pods/proxy-service-cldtq-85qvc:162/proxy/: bar (200; 7.412631ms)
Feb  8 22:57:42.707: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname2/proxy/: tls qux (200; 9.425454ms)
Feb  8 22:57:42.708: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname1/proxy/: foo (200; 10.890091ms)
Feb  8 22:57:42.708: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname2/proxy/: bar (200; 10.838417ms)
Feb  8 22:57:42.708: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/http:proxy-service-cldtq:portname1/proxy/: foo (200; 10.268457ms)
Feb  8 22:57:42.709: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/proxy-service-cldtq:portname2/proxy/: bar (200; 10.763286ms)
Feb  8 22:57:42.709: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdnzl/services/https:proxy-service-cldtq:tlsportname1/proxy/: tls baz (200; 11.259709ms)
STEP: deleting { ReplicationController} proxy-service-cldtq in namespace e2e-tests-proxy-zdnzl, will wait for the garbage collector to delete the pods
Feb  8 22:57:42.768: INFO: Deleting { ReplicationController} proxy-service-cldtq took: 7.137544ms
Feb  8 22:57:42.869: INFO: Terminating { ReplicationController} proxy-service-cldtq pods took: 100.202974ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:57:44.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-zdnzl" for this suite.
Feb  8 22:57:50.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:57:50.493: INFO: namespace: e2e-tests-proxy-zdnzl, resource: bindings, ignored listing per whitelist
Feb  8 22:57:50.558: INFO: namespace e2e-tests-proxy-zdnzl deletion completed in 6.085476119s

• [SLOW TEST:17.236 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:57:50.558: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  8 22:57:50.622: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f5ba65eb-2bf4-11e9-a551-0a580a020303" in namespace "e2e-tests-projected-7lx2q" to be "success or failure"
Feb  8 22:57:50.627: INFO: Pod "downwardapi-volume-f5ba65eb-2bf4-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 5.625877ms
Feb  8 22:57:52.631: INFO: Pod "downwardapi-volume-f5ba65eb-2bf4-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009287133s
STEP: Saw pod success
Feb  8 22:57:52.631: INFO: Pod "downwardapi-volume-f5ba65eb-2bf4-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:57:52.633: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod downwardapi-volume-f5ba65eb-2bf4-11e9-a551-0a580a020303 container client-container: <nil>
STEP: delete the pod
Feb  8 22:57:52.651: INFO: Waiting for pod downwardapi-volume-f5ba65eb-2bf4-11e9-a551-0a580a020303 to disappear
Feb  8 22:57:52.653: INFO: Pod downwardapi-volume-f5ba65eb-2bf4-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:57:52.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7lx2q" for this suite.
Feb  8 22:57:58.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:57:58.736: INFO: namespace: e2e-tests-projected-7lx2q, resource: bindings, ignored listing per whitelist
Feb  8 22:57:58.740: INFO: namespace e2e-tests-projected-7lx2q deletion completed in 6.083991678s

• [SLOW TEST:8.182 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:57:58.740: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  8 22:57:58.796: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fa99b50c-2bf4-11e9-a551-0a580a020303" in namespace "e2e-tests-projected-nfdp9" to be "success or failure"
Feb  8 22:57:58.799: INFO: Pod "downwardapi-volume-fa99b50c-2bf4-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.587666ms
Feb  8 22:58:00.802: INFO: Pod "downwardapi-volume-fa99b50c-2bf4-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006081621s
STEP: Saw pod success
Feb  8 22:58:00.802: INFO: Pod "downwardapi-volume-fa99b50c-2bf4-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:58:00.805: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod downwardapi-volume-fa99b50c-2bf4-11e9-a551-0a580a020303 container client-container: <nil>
STEP: delete the pod
Feb  8 22:58:00.836: INFO: Waiting for pod downwardapi-volume-fa99b50c-2bf4-11e9-a551-0a580a020303 to disappear
Feb  8 22:58:00.839: INFO: Pod downwardapi-volume-fa99b50c-2bf4-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:58:00.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nfdp9" for this suite.
Feb  8 22:58:06.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:58:06.885: INFO: namespace: e2e-tests-projected-nfdp9, resource: bindings, ignored listing per whitelist
Feb  8 22:58:06.927: INFO: namespace e2e-tests-projected-nfdp9 deletion completed in 6.085041817s

• [SLOW TEST:8.187 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:58:06.927: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  8 22:58:06.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-xmq7c'
Feb  8 22:58:07.067: INFO: stderr: ""
Feb  8 22:58:07.067: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Feb  8 22:58:07.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-xmq7c'
Feb  8 22:58:17.943: INFO: stderr: ""
Feb  8 22:58:17.943: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:58:17.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xmq7c" for this suite.
Feb  8 22:58:23.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:58:24.008: INFO: namespace: e2e-tests-kubectl-xmq7c, resource: bindings, ignored listing per whitelist
Feb  8 22:58:24.043: INFO: namespace e2e-tests-kubectl-xmq7c deletion completed in 6.097370656s

• [SLOW TEST:17.116 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:58:24.044: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb  8 22:58:26.621: INFO: Successfully updated pod "pod-update-activedeadlineseconds-09af18a9-2bf5-11e9-a551-0a580a020303"
Feb  8 22:58:26.621: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-09af18a9-2bf5-11e9-a551-0a580a020303" in namespace "e2e-tests-pods-q7h8g" to be "terminated due to deadline exceeded"
Feb  8 22:58:26.623: INFO: Pod "pod-update-activedeadlineseconds-09af18a9-2bf5-11e9-a551-0a580a020303": Phase="Running", Reason="", readiness=true. Elapsed: 2.272048ms
Feb  8 22:58:28.627: INFO: Pod "pod-update-activedeadlineseconds-09af18a9-2bf5-11e9-a551-0a580a020303": Phase="Running", Reason="", readiness=true. Elapsed: 2.005797219s
Feb  8 22:58:30.630: INFO: Pod "pod-update-activedeadlineseconds-09af18a9-2bf5-11e9-a551-0a580a020303": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.009301413s
Feb  8 22:58:30.630: INFO: Pod "pod-update-activedeadlineseconds-09af18a9-2bf5-11e9-a551-0a580a020303" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:58:30.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-q7h8g" for this suite.
Feb  8 22:58:36.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:58:36.703: INFO: namespace: e2e-tests-pods-q7h8g, resource: bindings, ignored listing per whitelist
Feb  8 22:58:36.722: INFO: namespace e2e-tests-pods-q7h8g deletion completed in 6.088387184s

• [SLOW TEST:12.678 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:58:36.722: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  8 22:58:36.780: INFO: Waiting up to 5m0s for pod "downwardapi-volume-113da5e4-2bf5-11e9-a551-0a580a020303" in namespace "e2e-tests-projected-4jd6m" to be "success or failure"
Feb  8 22:58:36.782: INFO: Pod "downwardapi-volume-113da5e4-2bf5-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.568457ms
Feb  8 22:58:38.786: INFO: Pod "downwardapi-volume-113da5e4-2bf5-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005962692s
STEP: Saw pod success
Feb  8 22:58:38.786: INFO: Pod "downwardapi-volume-113da5e4-2bf5-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:58:38.788: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod downwardapi-volume-113da5e4-2bf5-11e9-a551-0a580a020303 container client-container: <nil>
STEP: delete the pod
Feb  8 22:58:38.807: INFO: Waiting for pod downwardapi-volume-113da5e4-2bf5-11e9-a551-0a580a020303 to disappear
Feb  8 22:58:38.810: INFO: Pod downwardapi-volume-113da5e4-2bf5-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:58:38.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4jd6m" for this suite.
Feb  8 22:58:44.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:58:44.887: INFO: namespace: e2e-tests-projected-4jd6m, resource: bindings, ignored listing per whitelist
Feb  8 22:58:44.900: INFO: namespace e2e-tests-projected-4jd6m deletion completed in 6.087361189s

• [SLOW TEST:8.178 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:58:44.900: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Feb  8 22:58:44.955: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-821255472 proxy --unix-socket=/tmp/kubectl-proxy-unix756465359/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:58:45.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6d4d9" for this suite.
Feb  8 22:58:51.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:58:51.066: INFO: namespace: e2e-tests-kubectl-6d4d9, resource: bindings, ignored listing per whitelist
Feb  8 22:58:51.108: INFO: namespace e2e-tests-kubectl-6d4d9 deletion completed in 6.08705803s

• [SLOW TEST:6.208 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:58:51.108: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-vqc2
STEP: Creating a pod to test atomic-volume-subpath
Feb  8 22:58:51.173: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-vqc2" in namespace "e2e-tests-subpath-x6zmk" to be "success or failure"
Feb  8 22:58:51.178: INFO: Pod "pod-subpath-test-configmap-vqc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.071987ms
Feb  8 22:58:53.182: INFO: Pod "pod-subpath-test-configmap-vqc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008549593s
Feb  8 22:58:55.185: INFO: Pod "pod-subpath-test-configmap-vqc2": Phase="Running", Reason="", readiness=false. Elapsed: 4.012018223s
Feb  8 22:58:57.188: INFO: Pod "pod-subpath-test-configmap-vqc2": Phase="Running", Reason="", readiness=false. Elapsed: 6.015017254s
Feb  8 22:58:59.192: INFO: Pod "pod-subpath-test-configmap-vqc2": Phase="Running", Reason="", readiness=false. Elapsed: 8.018571407s
Feb  8 22:59:01.195: INFO: Pod "pod-subpath-test-configmap-vqc2": Phase="Running", Reason="", readiness=false. Elapsed: 10.022405354s
Feb  8 22:59:03.199: INFO: Pod "pod-subpath-test-configmap-vqc2": Phase="Running", Reason="", readiness=false. Elapsed: 12.025889733s
Feb  8 22:59:05.203: INFO: Pod "pod-subpath-test-configmap-vqc2": Phase="Running", Reason="", readiness=false. Elapsed: 14.029596858s
Feb  8 22:59:07.206: INFO: Pod "pod-subpath-test-configmap-vqc2": Phase="Running", Reason="", readiness=false. Elapsed: 16.033265627s
Feb  8 22:59:09.210: INFO: Pod "pod-subpath-test-configmap-vqc2": Phase="Running", Reason="", readiness=false. Elapsed: 18.036919444s
Feb  8 22:59:11.214: INFO: Pod "pod-subpath-test-configmap-vqc2": Phase="Running", Reason="", readiness=false. Elapsed: 20.040639844s
Feb  8 22:59:13.217: INFO: Pod "pod-subpath-test-configmap-vqc2": Phase="Running", Reason="", readiness=false. Elapsed: 22.044279563s
Feb  8 22:59:15.221: INFO: Pod "pod-subpath-test-configmap-vqc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.047824751s
STEP: Saw pod success
Feb  8 22:59:15.221: INFO: Pod "pod-subpath-test-configmap-vqc2" satisfied condition "success or failure"
Feb  8 22:59:15.223: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod pod-subpath-test-configmap-vqc2 container test-container-subpath-configmap-vqc2: <nil>
STEP: delete the pod
Feb  8 22:59:15.241: INFO: Waiting for pod pod-subpath-test-configmap-vqc2 to disappear
Feb  8 22:59:15.244: INFO: Pod pod-subpath-test-configmap-vqc2 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-vqc2
Feb  8 22:59:15.244: INFO: Deleting pod "pod-subpath-test-configmap-vqc2" in namespace "e2e-tests-subpath-x6zmk"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:59:15.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-x6zmk" for this suite.
Feb  8 22:59:21.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:59:21.280: INFO: namespace: e2e-tests-subpath-x6zmk, resource: bindings, ignored listing per whitelist
Feb  8 22:59:21.333: INFO: namespace e2e-tests-subpath-x6zmk deletion completed in 6.083843659s

• [SLOW TEST:30.225 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:59:21.333: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  8 22:59:21.393: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2bd4f9e0-2bf5-11e9-a551-0a580a020303" in namespace "e2e-tests-downward-api-swz4m" to be "success or failure"
Feb  8 22:59:21.396: INFO: Pod "downwardapi-volume-2bd4f9e0-2bf5-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.783176ms
Feb  8 22:59:23.399: INFO: Pod "downwardapi-volume-2bd4f9e0-2bf5-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005595942s
STEP: Saw pod success
Feb  8 22:59:23.399: INFO: Pod "downwardapi-volume-2bd4f9e0-2bf5-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 22:59:23.401: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod downwardapi-volume-2bd4f9e0-2bf5-11e9-a551-0a580a020303 container client-container: <nil>
STEP: delete the pod
Feb  8 22:59:23.418: INFO: Waiting for pod downwardapi-volume-2bd4f9e0-2bf5-11e9-a551-0a580a020303 to disappear
Feb  8 22:59:23.420: INFO: Pod downwardapi-volume-2bd4f9e0-2bf5-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 22:59:23.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-swz4m" for this suite.
Feb  8 22:59:29.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 22:59:29.453: INFO: namespace: e2e-tests-downward-api-swz4m, resource: bindings, ignored listing per whitelist
Feb  8 22:59:29.518: INFO: namespace e2e-tests-downward-api-swz4m deletion completed in 6.094322796s

• [SLOW TEST:8.185 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 22:59:29.518: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  8 22:59:29.577: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb  8 22:59:29.586: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:29.589: INFO: Number of nodes with available pods: 0
Feb  8 22:59:29.589: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:59:30.593: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:30.596: INFO: Number of nodes with available pods: 0
Feb  8 22:59:30.596: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 22:59:31.593: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:31.596: INFO: Number of nodes with available pods: 3
Feb  8 22:59:31.596: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb  8 22:59:31.614: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:31.614: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:31.614: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:31.619: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:32.623: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:32.623: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:32.623: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:32.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:33.623: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:33.623: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:33.623: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:33.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:34.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:34.622: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:34.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:34.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:35.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:35.622: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:35.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:35.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:36.623: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:36.623: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:36.623: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:36.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:37.623: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:37.623: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:37.623: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:37.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:38.623: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:38.623: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:38.623: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:38.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:39.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:39.622: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:39.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:39.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:40.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:40.622: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:40.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:40.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:41.623: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:41.623: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:41.623: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:41.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:42.623: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:42.623: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:42.623: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:42.638: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:43.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:43.622: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:43.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:43.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:44.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:44.622: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:44.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:44.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:45.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:45.622: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:45.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:45.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:46.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:46.622: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:46.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:46.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:47.623: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:47.623: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:47.623: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:47.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:48.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:48.622: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:48.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:48.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:49.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:49.622: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:49.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:49.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:50.623: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:50.623: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:50.623: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:50.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:51.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:51.622: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:51.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:51.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:52.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:52.622: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:52.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:52.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:53.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:53.622: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:53.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:53.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:54.623: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:54.623: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:54.623: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:54.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:55.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:55.622: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:55.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:55.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:56.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:56.622: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:56.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:56.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:57.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:57.622: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:57.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:57.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:58.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:58.622: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:58.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:58.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 22:59:59.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:59.622: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:59.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 22:59:59.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:00.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:00.622: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:00.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:00.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:01.623: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:01.623: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:01.623: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:01.627: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:02.623: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:02.623: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:02.623: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:02.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:03.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:03.622: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:03.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:03.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:04.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:04.622: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:04.622: INFO: Pod daemon-set-v57kz is not available
Feb  8 23:00:04.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:04.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:05.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:05.622: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:05.622: INFO: Pod daemon-set-v57kz is not available
Feb  8 23:00:05.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:05.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:06.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:06.622: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:06.622: INFO: Pod daemon-set-v57kz is not available
Feb  8 23:00:06.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:06.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:07.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:07.622: INFO: Wrong image for pod: daemon-set-v57kz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:07.622: INFO: Pod daemon-set-v57kz is not available
Feb  8 23:00:07.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:07.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:08.621: INFO: Pod daemon-set-8fmgm is not available
Feb  8 23:00:08.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:08.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:08.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:09.622: INFO: Pod daemon-set-8fmgm is not available
Feb  8 23:00:09.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:09.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:09.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:10.622: INFO: Pod daemon-set-8fmgm is not available
Feb  8 23:00:10.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:10.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:10.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:11.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:11.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:11.627: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:12.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:12.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:12.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:13.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:13.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:13.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:14.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:14.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:14.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:15.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:15.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:15.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:16.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:16.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:16.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:17.623: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:17.623: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:17.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:18.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:18.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:18.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:19.623: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:19.623: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:19.628: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:20.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:20.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:20.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:21.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:21.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:21.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:22.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:22.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:22.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:23.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:23.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:23.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:24.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:24.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:24.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:25.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:25.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:25.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:26.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:26.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:26.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:27.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:27.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:27.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:28.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:28.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:28.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:29.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:29.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:29.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:30.630: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:30.631: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:30.635: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:31.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:31.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:31.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:32.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:32.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:32.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:33.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:33.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:33.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:34.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:34.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:34.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:35.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:35.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:35.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:36.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:36.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:36.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:37.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:37.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:37.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:38.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:38.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:38.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:39.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:39.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:39.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:40.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:40.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:40.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:41.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:41.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:41.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:42.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:42.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:42.622: INFO: Pod daemon-set-w2qw8 is not available
Feb  8 23:00:42.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:43.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:43.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:43.622: INFO: Pod daemon-set-w2qw8 is not available
Feb  8 23:00:43.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:44.623: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:44.623: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:44.623: INFO: Pod daemon-set-w2qw8 is not available
Feb  8 23:00:44.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:45.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:45.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:45.622: INFO: Pod daemon-set-w2qw8 is not available
Feb  8 23:00:45.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:46.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:46.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:46.622: INFO: Pod daemon-set-w2qw8 is not available
Feb  8 23:00:46.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:47.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:47.622: INFO: Wrong image for pod: daemon-set-w2qw8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:47.622: INFO: Pod daemon-set-w2qw8 is not available
Feb  8 23:00:47.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:48.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:48.622: INFO: Pod daemon-set-974zh is not available
Feb  8 23:00:48.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:49.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:49.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:50.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:50.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:51.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:51.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:52.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:52.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:53.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:53.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:54.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:54.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:55.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:55.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:56.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:56.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:57.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:57.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:58.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:58.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:00:59.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:00:59.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:00.623: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:01:00.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:01.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:01:01.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:02.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:01:02.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:03.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:01:03.627: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:04.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:01:04.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:05.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:01:05.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:06.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:01:06.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:07.623: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:01:07.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:08.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:01:08.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:09.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:01:09.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:10.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:01:10.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:11.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:01:11.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:12.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:01:12.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:13.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:01:13.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:14.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:01:14.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:15.623: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:01:15.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:16.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:01:16.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:17.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:01:17.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:18.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:01:18.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:19.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:01:19.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:20.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:01:20.622: INFO: Pod daemon-set-8sk6w is not available
Feb  8 23:01:20.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:21.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:01:21.622: INFO: Pod daemon-set-8sk6w is not available
Feb  8 23:01:21.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:22.623: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:01:22.623: INFO: Pod daemon-set-8sk6w is not available
Feb  8 23:01:22.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:23.623: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:01:23.623: INFO: Pod daemon-set-8sk6w is not available
Feb  8 23:01:23.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:24.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:01:24.622: INFO: Pod daemon-set-8sk6w is not available
Feb  8 23:01:24.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:25.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:01:25.622: INFO: Pod daemon-set-8sk6w is not available
Feb  8 23:01:25.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:26.622: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:01:26.622: INFO: Pod daemon-set-8sk6w is not available
Feb  8 23:01:26.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:27.623: INFO: Wrong image for pod: daemon-set-8sk6w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  8 23:01:27.623: INFO: Pod daemon-set-8sk6w is not available
Feb  8 23:01:27.626: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:28.622: INFO: Pod daemon-set-d6pht is not available
Feb  8 23:01:28.625: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Feb  8 23:01:28.628: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:28.630: INFO: Number of nodes with available pods: 2
Feb  8 23:01:28.630: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:01:29.634: INFO: DaemonSet pods can't tolerate node ip-172-23-7-248.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  8 23:01:29.636: INFO: Number of nodes with available pods: 3
Feb  8 23:01:29.636: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-qxdvw, will wait for the garbage collector to delete the pods
Feb  8 23:01:29.706: INFO: Deleting {extensions DaemonSet} daemon-set took: 5.817254ms
Feb  8 23:01:29.806: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.163106ms
Feb  8 23:01:38.009: INFO: Number of nodes with available pods: 0
Feb  8 23:01:38.009: INFO: Number of running nodes: 0, number of available pods: 0
Feb  8 23:01:38.011: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-qxdvw/daemonsets","resourceVersion":"9493"},"items":null}

Feb  8 23:01:38.013: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-qxdvw/pods","resourceVersion":"9493"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:01:38.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-qxdvw" for this suite.
Feb  8 23:01:44.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:01:44.043: INFO: namespace: e2e-tests-daemonsets-qxdvw, resource: bindings, ignored listing per whitelist
Feb  8 23:01:44.109: INFO: namespace e2e-tests-daemonsets-qxdvw deletion completed in 6.082651483s

• [SLOW TEST:134.591 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:01:44.109: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:01:44.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-fr6b7" for this suite.
Feb  8 23:01:50.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:01:50.241: INFO: namespace: e2e-tests-services-fr6b7, resource: bindings, ignored listing per whitelist
Feb  8 23:01:50.253: INFO: namespace e2e-tests-services-fr6b7 deletion completed in 6.08025435s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.143 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:01:50.253: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  8 23:01:50.307: INFO: (0) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 4.302179ms)
Feb  8 23:01:50.311: INFO: (1) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.200287ms)
Feb  8 23:01:50.314: INFO: (2) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.012038ms)
Feb  8 23:01:50.317: INFO: (3) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.074081ms)
Feb  8 23:01:50.320: INFO: (4) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.914835ms)
Feb  8 23:01:50.323: INFO: (5) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.844031ms)
Feb  8 23:01:50.325: INFO: (6) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.913426ms)
Feb  8 23:01:50.328: INFO: (7) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.940257ms)
Feb  8 23:01:50.332: INFO: (8) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.029898ms)
Feb  8 23:01:50.334: INFO: (9) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.886846ms)
Feb  8 23:01:50.337: INFO: (10) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.871865ms)
Feb  8 23:01:50.340: INFO: (11) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.903311ms)
Feb  8 23:01:50.343: INFO: (12) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.925493ms)
Feb  8 23:01:50.346: INFO: (13) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.011423ms)
Feb  8 23:01:50.349: INFO: (14) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.803704ms)
Feb  8 23:01:50.352: INFO: (15) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.916855ms)
Feb  8 23:01:50.355: INFO: (16) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.913512ms)
Feb  8 23:01:50.358: INFO: (17) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.004053ms)
Feb  8 23:01:50.361: INFO: (18) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.017922ms)
Feb  8 23:01:50.364: INFO: (19) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.830069ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:01:50.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-j5j6t" for this suite.
Feb  8 23:01:56.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:01:56.426: INFO: namespace: e2e-tests-proxy-j5j6t, resource: bindings, ignored listing per whitelist
Feb  8 23:01:56.446: INFO: namespace e2e-tests-proxy-j5j6t deletion completed in 6.079071656s

• [SLOW TEST:6.193 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:01:56.446: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  8 23:01:56.508: INFO: Waiting up to 5m0s for pod "downwardapi-volume-88491fdf-2bf5-11e9-a551-0a580a020303" in namespace "e2e-tests-projected-kbn89" to be "success or failure"
Feb  8 23:01:56.511: INFO: Pod "downwardapi-volume-88491fdf-2bf5-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.676965ms
Feb  8 23:01:58.514: INFO: Pod "downwardapi-volume-88491fdf-2bf5-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005926572s
STEP: Saw pod success
Feb  8 23:01:58.514: INFO: Pod "downwardapi-volume-88491fdf-2bf5-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:01:58.516: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod downwardapi-volume-88491fdf-2bf5-11e9-a551-0a580a020303 container client-container: <nil>
STEP: delete the pod
Feb  8 23:01:58.534: INFO: Waiting for pod downwardapi-volume-88491fdf-2bf5-11e9-a551-0a580a020303 to disappear
Feb  8 23:01:58.537: INFO: Pod downwardapi-volume-88491fdf-2bf5-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:01:58.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kbn89" for this suite.
Feb  8 23:02:04.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:02:04.603: INFO: namespace: e2e-tests-projected-kbn89, resource: bindings, ignored listing per whitelist
Feb  8 23:02:04.635: INFO: namespace e2e-tests-projected-kbn89 deletion completed in 6.093138249s

• [SLOW TEST:8.189 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:02:04.635: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb  8 23:02:08.723: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  8 23:02:08.725: INFO: Pod pod-with-prestop-http-hook still exists
Feb  8 23:02:10.725: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  8 23:02:10.729: INFO: Pod pod-with-prestop-http-hook still exists
Feb  8 23:02:12.725: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  8 23:02:12.729: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:02:12.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-shrww" for this suite.
Feb  8 23:02:34.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:02:34.763: INFO: namespace: e2e-tests-container-lifecycle-hook-shrww, resource: bindings, ignored listing per whitelist
Feb  8 23:02:34.839: INFO: namespace e2e-tests-container-lifecycle-hook-shrww deletion completed in 22.098180454s

• [SLOW TEST:30.203 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:02:34.839: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-9f2be454-2bf5-11e9-a551-0a580a020303
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-9f2be454-2bf5-11e9-a551-0a580a020303
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:02:38.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nz49h" for this suite.
Feb  8 23:03:00.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:03:01.012: INFO: namespace: e2e-tests-projected-nz49h, resource: bindings, ignored listing per whitelist
Feb  8 23:03:01.032: INFO: namespace e2e-tests-projected-nz49h deletion completed in 22.086272187s

• [SLOW TEST:26.192 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:03:01.032: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-ghpw
STEP: Creating a pod to test atomic-volume-subpath
Feb  8 23:03:01.096: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-ghpw" in namespace "e2e-tests-subpath-l5ktx" to be "success or failure"
Feb  8 23:03:01.101: INFO: Pod "pod-subpath-test-projected-ghpw": Phase="Pending", Reason="", readiness=false. Elapsed: 5.34548ms
Feb  8 23:03:03.105: INFO: Pod "pod-subpath-test-projected-ghpw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008692437s
Feb  8 23:03:05.108: INFO: Pod "pod-subpath-test-projected-ghpw": Phase="Running", Reason="", readiness=false. Elapsed: 4.012137578s
Feb  8 23:03:07.112: INFO: Pod "pod-subpath-test-projected-ghpw": Phase="Running", Reason="", readiness=false. Elapsed: 6.01558521s
Feb  8 23:03:09.115: INFO: Pod "pod-subpath-test-projected-ghpw": Phase="Running", Reason="", readiness=false. Elapsed: 8.0192095s
Feb  8 23:03:11.119: INFO: Pod "pod-subpath-test-projected-ghpw": Phase="Running", Reason="", readiness=false. Elapsed: 10.022899124s
Feb  8 23:03:13.122: INFO: Pod "pod-subpath-test-projected-ghpw": Phase="Running", Reason="", readiness=false. Elapsed: 12.026423589s
Feb  8 23:03:15.126: INFO: Pod "pod-subpath-test-projected-ghpw": Phase="Running", Reason="", readiness=false. Elapsed: 14.030003663s
Feb  8 23:03:17.130: INFO: Pod "pod-subpath-test-projected-ghpw": Phase="Running", Reason="", readiness=false. Elapsed: 16.033582663s
Feb  8 23:03:19.133: INFO: Pod "pod-subpath-test-projected-ghpw": Phase="Running", Reason="", readiness=false. Elapsed: 18.037185149s
Feb  8 23:03:21.137: INFO: Pod "pod-subpath-test-projected-ghpw": Phase="Running", Reason="", readiness=false. Elapsed: 20.040906671s
Feb  8 23:03:23.141: INFO: Pod "pod-subpath-test-projected-ghpw": Phase="Running", Reason="", readiness=false. Elapsed: 22.044585312s
Feb  8 23:03:25.144: INFO: Pod "pod-subpath-test-projected-ghpw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.048194403s
STEP: Saw pod success
Feb  8 23:03:25.144: INFO: Pod "pod-subpath-test-projected-ghpw" satisfied condition "success or failure"
Feb  8 23:03:25.147: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod pod-subpath-test-projected-ghpw container test-container-subpath-projected-ghpw: <nil>
STEP: delete the pod
Feb  8 23:03:25.167: INFO: Waiting for pod pod-subpath-test-projected-ghpw to disappear
Feb  8 23:03:25.170: INFO: Pod pod-subpath-test-projected-ghpw no longer exists
STEP: Deleting pod pod-subpath-test-projected-ghpw
Feb  8 23:03:25.170: INFO: Deleting pod "pod-subpath-test-projected-ghpw" in namespace "e2e-tests-subpath-l5ktx"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:03:25.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-l5ktx" for this suite.
Feb  8 23:03:31.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:03:31.193: INFO: namespace: e2e-tests-subpath-l5ktx, resource: bindings, ignored listing per whitelist
Feb  8 23:03:31.262: INFO: namespace e2e-tests-subpath-l5ktx deletion completed in 6.087390733s

• [SLOW TEST:30.230 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:03:31.262: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  8 23:03:31.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 version'
Feb  8 23:03:31.405: INFO: stderr: ""
Feb  8 23:03:31.405: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.4\", GitCommit:\"f49fa022dbe63faafd0da106ef7e05a29721d3f1\", GitTreeState:\"clean\", BuildDate:\"2018-12-14T06:59:37Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:03:31.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wghpg" for this suite.
Feb  8 23:03:37.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:03:37.429: INFO: namespace: e2e-tests-kubectl-wghpg, resource: bindings, ignored listing per whitelist
Feb  8 23:03:37.495: INFO: namespace e2e-tests-kubectl-wghpg deletion completed in 6.08534913s

• [SLOW TEST:6.233 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:03:37.495: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  8 23:03:37.553: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Feb  8 23:03:37.558: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-ncd5d/daemonsets","resourceVersion":"9888"},"items":null}

Feb  8 23:03:37.560: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-ncd5d/pods","resourceVersion":"9888"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:03:37.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-ncd5d" for this suite.
Feb  8 23:03:43.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:03:43.612: INFO: namespace: e2e-tests-daemonsets-ncd5d, resource: bindings, ignored listing per whitelist
Feb  8 23:03:43.654: INFO: namespace e2e-tests-daemonsets-ncd5d deletion completed in 6.081425254s

S [SKIPPING] [6.159 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Feb  8 23:03:37.553: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:03:43.654: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb  8 23:03:43.711: INFO: Waiting up to 5m0s for pod "pod-c82f739e-2bf5-11e9-a551-0a580a020303" in namespace "e2e-tests-emptydir-4ktjj" to be "success or failure"
Feb  8 23:03:43.715: INFO: Pod "pod-c82f739e-2bf5-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 3.37137ms
Feb  8 23:03:45.718: INFO: Pod "pod-c82f739e-2bf5-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006886044s
STEP: Saw pod success
Feb  8 23:03:45.718: INFO: Pod "pod-c82f739e-2bf5-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:03:45.720: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod pod-c82f739e-2bf5-11e9-a551-0a580a020303 container test-container: <nil>
STEP: delete the pod
Feb  8 23:03:45.742: INFO: Waiting for pod pod-c82f739e-2bf5-11e9-a551-0a580a020303 to disappear
Feb  8 23:03:45.745: INFO: Pod pod-c82f739e-2bf5-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:03:45.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4ktjj" for this suite.
Feb  8 23:03:51.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:03:51.828: INFO: namespace: e2e-tests-emptydir-4ktjj, resource: bindings, ignored listing per whitelist
Feb  8 23:03:51.832: INFO: namespace e2e-tests-emptydir-4ktjj deletion completed in 6.084397277s

• [SLOW TEST:8.178 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:03:51.832: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-skztn
I0208 23:03:51.883560      14 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-skztn, replica count: 1
I0208 23:03:52.934006      14 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0208 23:03:53.934239      14 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb  8 23:03:54.043: INFO: Created: latency-svc-hhcpn
Feb  8 23:03:54.054: INFO: Got endpoints: latency-svc-hhcpn [20.41256ms]
Feb  8 23:03:54.068: INFO: Created: latency-svc-6xp4w
Feb  8 23:03:54.073: INFO: Got endpoints: latency-svc-6xp4w [18.776309ms]
Feb  8 23:03:54.080: INFO: Created: latency-svc-h25gz
Feb  8 23:03:54.087: INFO: Created: latency-svc-9b2tp
Feb  8 23:03:54.088: INFO: Got endpoints: latency-svc-h25gz [33.053244ms]
Feb  8 23:03:54.090: INFO: Got endpoints: latency-svc-9b2tp [35.057116ms]
Feb  8 23:03:54.095: INFO: Created: latency-svc-q49lw
Feb  8 23:03:54.097: INFO: Got endpoints: latency-svc-q49lw [41.755682ms]
Feb  8 23:03:54.101: INFO: Created: latency-svc-qqglg
Feb  8 23:03:54.105: INFO: Got endpoints: latency-svc-qqglg [49.234502ms]
Feb  8 23:03:54.109: INFO: Created: latency-svc-646wv
Feb  8 23:03:54.114: INFO: Got endpoints: latency-svc-646wv [59.14734ms]
Feb  8 23:03:54.129: INFO: Created: latency-svc-vxqqf
Feb  8 23:03:54.133: INFO: Got endpoints: latency-svc-vxqqf [78.319391ms]
Feb  8 23:03:54.136: INFO: Created: latency-svc-s8l6n
Feb  8 23:03:54.140: INFO: Got endpoints: latency-svc-s8l6n [84.615473ms]
Feb  8 23:03:54.142: INFO: Created: latency-svc-56rrv
Feb  8 23:03:54.147: INFO: Got endpoints: latency-svc-56rrv [91.013373ms]
Feb  8 23:03:54.149: INFO: Created: latency-svc-4vmcs
Feb  8 23:03:54.156: INFO: Got endpoints: latency-svc-4vmcs [100.216908ms]
Feb  8 23:03:54.159: INFO: Created: latency-svc-fjfkq
Feb  8 23:03:54.162: INFO: Got endpoints: latency-svc-fjfkq [106.400762ms]
Feb  8 23:03:54.166: INFO: Created: latency-svc-89cl4
Feb  8 23:03:54.172: INFO: Got endpoints: latency-svc-89cl4 [116.232198ms]
Feb  8 23:03:54.174: INFO: Created: latency-svc-nx4jn
Feb  8 23:03:54.178: INFO: Got endpoints: latency-svc-nx4jn [122.223734ms]
Feb  8 23:03:54.186: INFO: Created: latency-svc-xqzjg
Feb  8 23:03:54.186: INFO: Created: latency-svc-z6hdt
Feb  8 23:03:54.193: INFO: Got endpoints: latency-svc-z6hdt [136.896631ms]
Feb  8 23:03:54.193: INFO: Got endpoints: latency-svc-xqzjg [137.304154ms]
Feb  8 23:03:54.197: INFO: Created: latency-svc-28t4r
Feb  8 23:03:54.202: INFO: Got endpoints: latency-svc-28t4r [128.777866ms]
Feb  8 23:03:54.204: INFO: Created: latency-svc-qmw88
Feb  8 23:03:54.210: INFO: Got endpoints: latency-svc-qmw88 [121.899768ms]
Feb  8 23:03:54.211: INFO: Created: latency-svc-plgrr
Feb  8 23:03:54.216: INFO: Got endpoints: latency-svc-plgrr [126.043784ms]
Feb  8 23:03:54.218: INFO: Created: latency-svc-fhjcm
Feb  8 23:03:54.223: INFO: Got endpoints: latency-svc-fhjcm [125.199056ms]
Feb  8 23:03:54.227: INFO: Created: latency-svc-gs5ng
Feb  8 23:03:54.231: INFO: Got endpoints: latency-svc-gs5ng [126.525549ms]
Feb  8 23:03:54.233: INFO: Created: latency-svc-z54t8
Feb  8 23:03:54.239: INFO: Got endpoints: latency-svc-z54t8 [125.251891ms]
Feb  8 23:03:54.241: INFO: Created: latency-svc-5n5lj
Feb  8 23:03:54.245: INFO: Got endpoints: latency-svc-5n5lj [111.252976ms]
Feb  8 23:03:54.248: INFO: Created: latency-svc-82t4q
Feb  8 23:03:54.252: INFO: Got endpoints: latency-svc-82t4q [111.985349ms]
Feb  8 23:03:54.255: INFO: Created: latency-svc-jpv8v
Feb  8 23:03:54.260: INFO: Created: latency-svc-mztsj
Feb  8 23:03:54.261: INFO: Got endpoints: latency-svc-jpv8v [113.416986ms]
Feb  8 23:03:54.267: INFO: Got endpoints: latency-svc-mztsj [111.335243ms]
Feb  8 23:03:54.270: INFO: Created: latency-svc-vrk6f
Feb  8 23:03:54.275: INFO: Created: latency-svc-9nknx
Feb  8 23:03:54.278: INFO: Got endpoints: latency-svc-vrk6f [115.398559ms]
Feb  8 23:03:54.282: INFO: Got endpoints: latency-svc-9nknx [109.98179ms]
Feb  8 23:03:54.284: INFO: Created: latency-svc-g2p7d
Feb  8 23:03:54.293: INFO: Got endpoints: latency-svc-g2p7d [114.520049ms]
Feb  8 23:03:54.295: INFO: Created: latency-svc-4h6vm
Feb  8 23:03:54.301: INFO: Got endpoints: latency-svc-4h6vm [108.428649ms]
Feb  8 23:03:54.305: INFO: Created: latency-svc-qv97q
Feb  8 23:03:54.314: INFO: Got endpoints: latency-svc-qv97q [120.202928ms]
Feb  8 23:03:54.314: INFO: Created: latency-svc-pw88s
Feb  8 23:03:54.317: INFO: Got endpoints: latency-svc-pw88s [114.424311ms]
Feb  8 23:03:54.321: INFO: Created: latency-svc-2sjcv
Feb  8 23:03:54.331: INFO: Got endpoints: latency-svc-2sjcv [121.643018ms]
Feb  8 23:03:54.334: INFO: Created: latency-svc-gdsp8
Feb  8 23:03:54.339: INFO: Created: latency-svc-j6vcf
Feb  8 23:03:54.339: INFO: Got endpoints: latency-svc-gdsp8 [123.405712ms]
Feb  8 23:03:54.345: INFO: Got endpoints: latency-svc-j6vcf [122.529489ms]
Feb  8 23:03:54.346: INFO: Created: latency-svc-rbwdd
Feb  8 23:03:54.352: INFO: Created: latency-svc-2kgpk
Feb  8 23:03:54.353: INFO: Got endpoints: latency-svc-rbwdd [121.615309ms]
Feb  8 23:03:54.359: INFO: Created: latency-svc-vmwps
Feb  8 23:03:54.367: INFO: Created: latency-svc-p2v5l
Feb  8 23:03:54.371: INFO: Created: latency-svc-tjzdt
Feb  8 23:03:54.379: INFO: Created: latency-svc-dpxj8
Feb  8 23:03:54.386: INFO: Created: latency-svc-bbprd
Feb  8 23:03:54.392: INFO: Created: latency-svc-mrx7q
Feb  8 23:03:54.400: INFO: Created: latency-svc-jdf8f
Feb  8 23:03:54.401: INFO: Got endpoints: latency-svc-2kgpk [161.822537ms]
Feb  8 23:03:54.406: INFO: Created: latency-svc-qtdgl
Feb  8 23:03:54.413: INFO: Created: latency-svc-npdmf
Feb  8 23:03:54.419: INFO: Created: latency-svc-lhb4t
Feb  8 23:03:54.424: INFO: Created: latency-svc-rmcxt
Feb  8 23:03:54.428: INFO: Created: latency-svc-nxwrx
Feb  8 23:03:54.434: INFO: Created: latency-svc-h5pzw
Feb  8 23:03:54.441: INFO: Created: latency-svc-n5fb4
Feb  8 23:03:54.448: INFO: Created: latency-svc-sf64z
Feb  8 23:03:54.448: INFO: Got endpoints: latency-svc-vmwps [203.651319ms]
Feb  8 23:03:54.456: INFO: Created: latency-svc-zsl9k
Feb  8 23:03:54.499: INFO: Got endpoints: latency-svc-p2v5l [246.660541ms]
Feb  8 23:03:54.509: INFO: Created: latency-svc-6hbbj
Feb  8 23:03:54.549: INFO: Got endpoints: latency-svc-tjzdt [287.742388ms]
Feb  8 23:03:54.557: INFO: Created: latency-svc-j8b7g
Feb  8 23:03:54.598: INFO: Got endpoints: latency-svc-dpxj8 [330.771961ms]
Feb  8 23:03:54.606: INFO: Created: latency-svc-mplf9
Feb  8 23:03:54.647: INFO: Got endpoints: latency-svc-bbprd [369.848666ms]
Feb  8 23:03:54.658: INFO: Created: latency-svc-c2d48
Feb  8 23:03:54.699: INFO: Got endpoints: latency-svc-mrx7q [416.913019ms]
Feb  8 23:03:54.706: INFO: Created: latency-svc-zxrj2
Feb  8 23:03:54.748: INFO: Got endpoints: latency-svc-jdf8f [454.771851ms]
Feb  8 23:03:54.759: INFO: Created: latency-svc-nrfrv
Feb  8 23:03:54.798: INFO: Got endpoints: latency-svc-qtdgl [496.412505ms]
Feb  8 23:03:54.806: INFO: Created: latency-svc-fwjkn
Feb  8 23:03:54.848: INFO: Got endpoints: latency-svc-npdmf [534.725518ms]
Feb  8 23:03:54.857: INFO: Created: latency-svc-hlhxt
Feb  8 23:03:54.898: INFO: Got endpoints: latency-svc-lhb4t [580.851747ms]
Feb  8 23:03:54.906: INFO: Created: latency-svc-5rfl4
Feb  8 23:03:54.948: INFO: Got endpoints: latency-svc-rmcxt [616.962355ms]
Feb  8 23:03:54.956: INFO: Created: latency-svc-qvbq2
Feb  8 23:03:54.998: INFO: Got endpoints: latency-svc-nxwrx [658.830967ms]
Feb  8 23:03:55.008: INFO: Created: latency-svc-4xgvd
Feb  8 23:03:55.048: INFO: Got endpoints: latency-svc-h5pzw [703.031319ms]
Feb  8 23:03:55.059: INFO: Created: latency-svc-4gr9g
Feb  8 23:03:55.099: INFO: Got endpoints: latency-svc-n5fb4 [745.743521ms]
Feb  8 23:03:55.109: INFO: Created: latency-svc-czhlm
Feb  8 23:03:55.148: INFO: Got endpoints: latency-svc-sf64z [746.415354ms]
Feb  8 23:03:55.156: INFO: Created: latency-svc-54vng
Feb  8 23:03:55.199: INFO: Got endpoints: latency-svc-zsl9k [750.273658ms]
Feb  8 23:03:55.207: INFO: Created: latency-svc-v822h
Feb  8 23:03:55.248: INFO: Got endpoints: latency-svc-6hbbj [749.173824ms]
Feb  8 23:03:55.257: INFO: Created: latency-svc-b2bhp
Feb  8 23:03:55.302: INFO: Got endpoints: latency-svc-j8b7g [753.1319ms]
Feb  8 23:03:55.311: INFO: Created: latency-svc-gjb2c
Feb  8 23:03:55.349: INFO: Got endpoints: latency-svc-mplf9 [750.926904ms]
Feb  8 23:03:55.357: INFO: Created: latency-svc-bfm8w
Feb  8 23:03:55.399: INFO: Got endpoints: latency-svc-c2d48 [751.303158ms]
Feb  8 23:03:55.409: INFO: Created: latency-svc-r2chm
Feb  8 23:03:55.448: INFO: Got endpoints: latency-svc-zxrj2 [748.669983ms]
Feb  8 23:03:55.456: INFO: Created: latency-svc-4r72n
Feb  8 23:03:55.499: INFO: Got endpoints: latency-svc-nrfrv [751.071143ms]
Feb  8 23:03:55.508: INFO: Created: latency-svc-td5rc
Feb  8 23:03:55.548: INFO: Got endpoints: latency-svc-fwjkn [749.734677ms]
Feb  8 23:03:55.556: INFO: Created: latency-svc-jzfnv
Feb  8 23:03:55.599: INFO: Got endpoints: latency-svc-hlhxt [750.020767ms]
Feb  8 23:03:55.608: INFO: Created: latency-svc-smgbc
Feb  8 23:03:55.649: INFO: Got endpoints: latency-svc-5rfl4 [750.857227ms]
Feb  8 23:03:55.657: INFO: Created: latency-svc-j7f46
Feb  8 23:03:55.698: INFO: Got endpoints: latency-svc-qvbq2 [749.693152ms]
Feb  8 23:03:55.708: INFO: Created: latency-svc-pkv9s
Feb  8 23:03:55.753: INFO: Got endpoints: latency-svc-4xgvd [754.387585ms]
Feb  8 23:03:55.763: INFO: Created: latency-svc-6xmkp
Feb  8 23:03:55.797: INFO: Got endpoints: latency-svc-4gr9g [749.032919ms]
Feb  8 23:03:55.806: INFO: Created: latency-svc-58vpt
Feb  8 23:03:55.847: INFO: Got endpoints: latency-svc-czhlm [748.691573ms]
Feb  8 23:03:55.856: INFO: Created: latency-svc-cgxww
Feb  8 23:03:55.900: INFO: Got endpoints: latency-svc-54vng [751.955549ms]
Feb  8 23:03:55.909: INFO: Created: latency-svc-7h64q
Feb  8 23:03:55.948: INFO: Got endpoints: latency-svc-v822h [748.973851ms]
Feb  8 23:03:55.957: INFO: Created: latency-svc-7hpx4
Feb  8 23:03:55.998: INFO: Got endpoints: latency-svc-b2bhp [749.914186ms]
Feb  8 23:03:56.006: INFO: Created: latency-svc-cdfgs
Feb  8 23:03:56.049: INFO: Got endpoints: latency-svc-gjb2c [747.610245ms]
Feb  8 23:03:56.060: INFO: Created: latency-svc-w9bzz
Feb  8 23:03:56.099: INFO: Got endpoints: latency-svc-bfm8w [749.583853ms]
Feb  8 23:03:56.108: INFO: Created: latency-svc-svzhh
Feb  8 23:03:56.148: INFO: Got endpoints: latency-svc-r2chm [748.739516ms]
Feb  8 23:03:56.156: INFO: Created: latency-svc-42874
Feb  8 23:03:56.198: INFO: Got endpoints: latency-svc-4r72n [750.550169ms]
Feb  8 23:03:56.209: INFO: Created: latency-svc-78xfk
Feb  8 23:03:56.248: INFO: Got endpoints: latency-svc-td5rc [749.659934ms]
Feb  8 23:03:56.257: INFO: Created: latency-svc-flrkm
Feb  8 23:03:56.298: INFO: Got endpoints: latency-svc-jzfnv [749.977834ms]
Feb  8 23:03:56.314: INFO: Created: latency-svc-qbtpm
Feb  8 23:03:56.349: INFO: Got endpoints: latency-svc-smgbc [750.509664ms]
Feb  8 23:03:56.359: INFO: Created: latency-svc-2z6fm
Feb  8 23:03:56.397: INFO: Got endpoints: latency-svc-j7f46 [748.634229ms]
Feb  8 23:03:56.407: INFO: Created: latency-svc-xzgxj
Feb  8 23:03:56.448: INFO: Got endpoints: latency-svc-pkv9s [750.003356ms]
Feb  8 23:03:56.457: INFO: Created: latency-svc-zf8kn
Feb  8 23:03:56.500: INFO: Got endpoints: latency-svc-6xmkp [747.013047ms]
Feb  8 23:03:56.508: INFO: Created: latency-svc-57qq7
Feb  8 23:03:56.549: INFO: Got endpoints: latency-svc-58vpt [752.035829ms]
Feb  8 23:03:56.561: INFO: Created: latency-svc-46src
Feb  8 23:03:56.600: INFO: Got endpoints: latency-svc-cgxww [752.427913ms]
Feb  8 23:03:56.608: INFO: Created: latency-svc-w285z
Feb  8 23:03:56.648: INFO: Got endpoints: latency-svc-7h64q [748.597072ms]
Feb  8 23:03:56.658: INFO: Created: latency-svc-shv28
Feb  8 23:03:56.701: INFO: Got endpoints: latency-svc-7hpx4 [752.57983ms]
Feb  8 23:03:56.710: INFO: Created: latency-svc-x8tjt
Feb  8 23:03:56.750: INFO: Got endpoints: latency-svc-cdfgs [752.363369ms]
Feb  8 23:03:56.760: INFO: Created: latency-svc-qq68g
Feb  8 23:03:56.797: INFO: Got endpoints: latency-svc-w9bzz [747.735961ms]
Feb  8 23:03:56.806: INFO: Created: latency-svc-c4fjc
Feb  8 23:03:56.848: INFO: Got endpoints: latency-svc-svzhh [749.417015ms]
Feb  8 23:03:56.865: INFO: Created: latency-svc-6qsg4
Feb  8 23:03:56.901: INFO: Got endpoints: latency-svc-42874 [753.506948ms]
Feb  8 23:03:56.911: INFO: Created: latency-svc-jj4sf
Feb  8 23:03:56.947: INFO: Got endpoints: latency-svc-78xfk [748.889443ms]
Feb  8 23:03:56.956: INFO: Created: latency-svc-drjbx
Feb  8 23:03:56.999: INFO: Got endpoints: latency-svc-flrkm [750.838319ms]
Feb  8 23:03:57.009: INFO: Created: latency-svc-frqgz
Feb  8 23:03:57.051: INFO: Got endpoints: latency-svc-qbtpm [753.131926ms]
Feb  8 23:03:57.061: INFO: Created: latency-svc-crh2c
Feb  8 23:03:57.098: INFO: Got endpoints: latency-svc-2z6fm [748.749232ms]
Feb  8 23:03:57.106: INFO: Created: latency-svc-bnhrh
Feb  8 23:03:57.148: INFO: Got endpoints: latency-svc-xzgxj [751.024652ms]
Feb  8 23:03:57.159: INFO: Created: latency-svc-cng7h
Feb  8 23:03:57.199: INFO: Got endpoints: latency-svc-zf8kn [750.561035ms]
Feb  8 23:03:57.208: INFO: Created: latency-svc-zln64
Feb  8 23:03:57.249: INFO: Got endpoints: latency-svc-57qq7 [749.204753ms]
Feb  8 23:03:57.258: INFO: Created: latency-svc-8qcrm
Feb  8 23:03:57.298: INFO: Got endpoints: latency-svc-46src [749.017969ms]
Feb  8 23:03:57.310: INFO: Created: latency-svc-nlwc7
Feb  8 23:03:57.348: INFO: Got endpoints: latency-svc-w285z [748.475198ms]
Feb  8 23:03:57.358: INFO: Created: latency-svc-f7mhp
Feb  8 23:03:57.401: INFO: Got endpoints: latency-svc-shv28 [752.068805ms]
Feb  8 23:03:57.410: INFO: Created: latency-svc-t6j6f
Feb  8 23:03:57.450: INFO: Got endpoints: latency-svc-x8tjt [749.043158ms]
Feb  8 23:03:57.459: INFO: Created: latency-svc-jm7j9
Feb  8 23:03:57.499: INFO: Got endpoints: latency-svc-qq68g [748.60639ms]
Feb  8 23:03:57.508: INFO: Created: latency-svc-d5b87
Feb  8 23:03:57.549: INFO: Got endpoints: latency-svc-c4fjc [751.389705ms]
Feb  8 23:03:57.557: INFO: Created: latency-svc-ljcfr
Feb  8 23:03:57.601: INFO: Got endpoints: latency-svc-6qsg4 [752.855131ms]
Feb  8 23:03:57.626: INFO: Created: latency-svc-stjm9
Feb  8 23:03:57.649: INFO: Got endpoints: latency-svc-jj4sf [748.220607ms]
Feb  8 23:03:57.658: INFO: Created: latency-svc-sj4c9
Feb  8 23:03:57.699: INFO: Got endpoints: latency-svc-drjbx [752.009481ms]
Feb  8 23:03:57.710: INFO: Created: latency-svc-lpltw
Feb  8 23:03:57.748: INFO: Got endpoints: latency-svc-frqgz [748.556724ms]
Feb  8 23:03:57.760: INFO: Created: latency-svc-5v58c
Feb  8 23:03:57.799: INFO: Got endpoints: latency-svc-crh2c [748.109716ms]
Feb  8 23:03:57.807: INFO: Created: latency-svc-wvrgj
Feb  8 23:03:57.849: INFO: Got endpoints: latency-svc-bnhrh [750.843248ms]
Feb  8 23:03:57.860: INFO: Created: latency-svc-lg2nj
Feb  8 23:03:57.900: INFO: Got endpoints: latency-svc-cng7h [751.580931ms]
Feb  8 23:03:57.908: INFO: Created: latency-svc-jwz5h
Feb  8 23:03:57.948: INFO: Got endpoints: latency-svc-zln64 [749.596245ms]
Feb  8 23:03:57.957: INFO: Created: latency-svc-xszzt
Feb  8 23:03:57.999: INFO: Got endpoints: latency-svc-8qcrm [749.61272ms]
Feb  8 23:03:58.008: INFO: Created: latency-svc-zzdcf
Feb  8 23:03:58.053: INFO: Got endpoints: latency-svc-nlwc7 [754.223742ms]
Feb  8 23:03:58.062: INFO: Created: latency-svc-7thtj
Feb  8 23:03:58.099: INFO: Got endpoints: latency-svc-f7mhp [750.227181ms]
Feb  8 23:03:58.106: INFO: Created: latency-svc-d6xkc
Feb  8 23:03:58.148: INFO: Got endpoints: latency-svc-t6j6f [747.847977ms]
Feb  8 23:03:58.159: INFO: Created: latency-svc-pt2qr
Feb  8 23:03:58.199: INFO: Got endpoints: latency-svc-jm7j9 [749.45325ms]
Feb  8 23:03:58.209: INFO: Created: latency-svc-qbd2d
Feb  8 23:03:58.249: INFO: Got endpoints: latency-svc-d5b87 [749.683345ms]
Feb  8 23:03:58.258: INFO: Created: latency-svc-vt5wk
Feb  8 23:03:58.299: INFO: Got endpoints: latency-svc-ljcfr [750.166713ms]
Feb  8 23:03:58.307: INFO: Created: latency-svc-8smzs
Feb  8 23:03:58.350: INFO: Got endpoints: latency-svc-stjm9 [748.472207ms]
Feb  8 23:03:58.360: INFO: Created: latency-svc-mfvtc
Feb  8 23:03:58.399: INFO: Got endpoints: latency-svc-sj4c9 [749.280468ms]
Feb  8 23:03:58.408: INFO: Created: latency-svc-7wjk9
Feb  8 23:03:58.450: INFO: Got endpoints: latency-svc-lpltw [750.22451ms]
Feb  8 23:03:58.458: INFO: Created: latency-svc-pf6zl
Feb  8 23:03:58.498: INFO: Got endpoints: latency-svc-5v58c [750.057734ms]
Feb  8 23:03:58.507: INFO: Created: latency-svc-pgsv6
Feb  8 23:03:58.547: INFO: Got endpoints: latency-svc-wvrgj [748.447111ms]
Feb  8 23:03:58.558: INFO: Created: latency-svc-4tgm7
Feb  8 23:03:58.601: INFO: Got endpoints: latency-svc-lg2nj [751.545304ms]
Feb  8 23:03:58.610: INFO: Created: latency-svc-jjq8v
Feb  8 23:03:58.648: INFO: Got endpoints: latency-svc-jwz5h [747.777286ms]
Feb  8 23:03:58.658: INFO: Created: latency-svc-fjhxp
Feb  8 23:03:58.699: INFO: Got endpoints: latency-svc-xszzt [750.091028ms]
Feb  8 23:03:58.708: INFO: Created: latency-svc-hws4n
Feb  8 23:03:58.749: INFO: Got endpoints: latency-svc-zzdcf [750.248447ms]
Feb  8 23:03:58.758: INFO: Created: latency-svc-n8dqv
Feb  8 23:03:58.799: INFO: Got endpoints: latency-svc-7thtj [746.081553ms]
Feb  8 23:03:58.809: INFO: Created: latency-svc-46vhd
Feb  8 23:03:58.849: INFO: Got endpoints: latency-svc-d6xkc [750.179969ms]
Feb  8 23:03:58.858: INFO: Created: latency-svc-h6665
Feb  8 23:03:58.898: INFO: Got endpoints: latency-svc-pt2qr [750.019647ms]
Feb  8 23:03:58.907: INFO: Created: latency-svc-j6r49
Feb  8 23:03:58.948: INFO: Got endpoints: latency-svc-qbd2d [748.771744ms]
Feb  8 23:03:58.958: INFO: Created: latency-svc-6jkph
Feb  8 23:03:58.998: INFO: Got endpoints: latency-svc-vt5wk [749.0199ms]
Feb  8 23:03:59.011: INFO: Created: latency-svc-j4fkf
Feb  8 23:03:59.048: INFO: Got endpoints: latency-svc-8smzs [749.350666ms]
Feb  8 23:03:59.057: INFO: Created: latency-svc-8rcql
Feb  8 23:03:59.098: INFO: Got endpoints: latency-svc-mfvtc [748.444952ms]
Feb  8 23:03:59.108: INFO: Created: latency-svc-cjzlb
Feb  8 23:03:59.148: INFO: Got endpoints: latency-svc-7wjk9 [748.713697ms]
Feb  8 23:03:59.157: INFO: Created: latency-svc-6p7cc
Feb  8 23:03:59.199: INFO: Got endpoints: latency-svc-pf6zl [749.457336ms]
Feb  8 23:03:59.208: INFO: Created: latency-svc-zks9q
Feb  8 23:03:59.250: INFO: Got endpoints: latency-svc-pgsv6 [751.529648ms]
Feb  8 23:03:59.259: INFO: Created: latency-svc-47kz9
Feb  8 23:03:59.298: INFO: Got endpoints: latency-svc-4tgm7 [750.907542ms]
Feb  8 23:03:59.308: INFO: Created: latency-svc-8nzj7
Feb  8 23:03:59.351: INFO: Got endpoints: latency-svc-jjq8v [749.988502ms]
Feb  8 23:03:59.359: INFO: Created: latency-svc-5xbmw
Feb  8 23:03:59.400: INFO: Got endpoints: latency-svc-fjhxp [751.770689ms]
Feb  8 23:03:59.408: INFO: Created: latency-svc-cj7qx
Feb  8 23:03:59.448: INFO: Got endpoints: latency-svc-hws4n [749.667594ms]
Feb  8 23:03:59.457: INFO: Created: latency-svc-q6958
Feb  8 23:03:59.501: INFO: Got endpoints: latency-svc-n8dqv [752.364874ms]
Feb  8 23:03:59.511: INFO: Created: latency-svc-4b885
Feb  8 23:03:59.549: INFO: Got endpoints: latency-svc-46vhd [750.594241ms]
Feb  8 23:03:59.558: INFO: Created: latency-svc-tfd6n
Feb  8 23:03:59.599: INFO: Got endpoints: latency-svc-h6665 [749.784047ms]
Feb  8 23:03:59.607: INFO: Created: latency-svc-z8rg9
Feb  8 23:03:59.648: INFO: Got endpoints: latency-svc-j6r49 [749.812659ms]
Feb  8 23:03:59.657: INFO: Created: latency-svc-pd8w4
Feb  8 23:03:59.699: INFO: Got endpoints: latency-svc-6jkph [751.265154ms]
Feb  8 23:03:59.708: INFO: Created: latency-svc-m6zf4
Feb  8 23:03:59.749: INFO: Got endpoints: latency-svc-j4fkf [751.277739ms]
Feb  8 23:03:59.758: INFO: Created: latency-svc-6qgtq
Feb  8 23:03:59.801: INFO: Got endpoints: latency-svc-8rcql [752.806979ms]
Feb  8 23:03:59.811: INFO: Created: latency-svc-26tcv
Feb  8 23:03:59.849: INFO: Got endpoints: latency-svc-cjzlb [750.712919ms]
Feb  8 23:03:59.858: INFO: Created: latency-svc-mqfq9
Feb  8 23:03:59.901: INFO: Got endpoints: latency-svc-6p7cc [753.187331ms]
Feb  8 23:03:59.909: INFO: Created: latency-svc-9lr7z
Feb  8 23:03:59.948: INFO: Got endpoints: latency-svc-zks9q [749.226373ms]
Feb  8 23:03:59.959: INFO: Created: latency-svc-rj4h2
Feb  8 23:03:59.999: INFO: Got endpoints: latency-svc-47kz9 [748.987434ms]
Feb  8 23:04:00.010: INFO: Created: latency-svc-l7t6s
Feb  8 23:04:00.050: INFO: Got endpoints: latency-svc-8nzj7 [751.197541ms]
Feb  8 23:04:00.058: INFO: Created: latency-svc-z5nvk
Feb  8 23:04:00.101: INFO: Got endpoints: latency-svc-5xbmw [750.597839ms]
Feb  8 23:04:00.111: INFO: Created: latency-svc-cqkrw
Feb  8 23:04:00.149: INFO: Got endpoints: latency-svc-cj7qx [749.745457ms]
Feb  8 23:04:00.159: INFO: Created: latency-svc-rlmpt
Feb  8 23:04:00.198: INFO: Got endpoints: latency-svc-q6958 [749.708732ms]
Feb  8 23:04:00.207: INFO: Created: latency-svc-4r5x7
Feb  8 23:04:00.253: INFO: Got endpoints: latency-svc-4b885 [751.876955ms]
Feb  8 23:04:00.263: INFO: Created: latency-svc-th8jx
Feb  8 23:04:00.298: INFO: Got endpoints: latency-svc-tfd6n [748.528482ms]
Feb  8 23:04:00.305: INFO: Created: latency-svc-c42b5
Feb  8 23:04:00.351: INFO: Got endpoints: latency-svc-z8rg9 [752.380751ms]
Feb  8 23:04:00.361: INFO: Created: latency-svc-mc7vx
Feb  8 23:04:00.399: INFO: Got endpoints: latency-svc-pd8w4 [750.094155ms]
Feb  8 23:04:00.409: INFO: Created: latency-svc-b7gn2
Feb  8 23:04:00.449: INFO: Got endpoints: latency-svc-m6zf4 [749.338573ms]
Feb  8 23:04:00.473: INFO: Created: latency-svc-j5b29
Feb  8 23:04:00.500: INFO: Got endpoints: latency-svc-6qgtq [750.991546ms]
Feb  8 23:04:00.509: INFO: Created: latency-svc-tchwm
Feb  8 23:04:00.549: INFO: Got endpoints: latency-svc-26tcv [748.15861ms]
Feb  8 23:04:00.559: INFO: Created: latency-svc-ndfnz
Feb  8 23:04:00.598: INFO: Got endpoints: latency-svc-mqfq9 [749.463976ms]
Feb  8 23:04:00.607: INFO: Created: latency-svc-klzfq
Feb  8 23:04:00.650: INFO: Got endpoints: latency-svc-9lr7z [748.731135ms]
Feb  8 23:04:00.658: INFO: Created: latency-svc-n5fzb
Feb  8 23:04:00.699: INFO: Got endpoints: latency-svc-rj4h2 [750.372121ms]
Feb  8 23:04:00.707: INFO: Created: latency-svc-fjncl
Feb  8 23:04:00.753: INFO: Got endpoints: latency-svc-l7t6s [754.347509ms]
Feb  8 23:04:00.763: INFO: Created: latency-svc-fjh8f
Feb  8 23:04:00.799: INFO: Got endpoints: latency-svc-z5nvk [749.493304ms]
Feb  8 23:04:00.808: INFO: Created: latency-svc-scblx
Feb  8 23:04:00.848: INFO: Got endpoints: latency-svc-cqkrw [747.071234ms]
Feb  8 23:04:00.861: INFO: Created: latency-svc-s66fw
Feb  8 23:04:00.901: INFO: Got endpoints: latency-svc-rlmpt [751.847101ms]
Feb  8 23:04:00.911: INFO: Created: latency-svc-2bxl8
Feb  8 23:04:00.953: INFO: Got endpoints: latency-svc-4r5x7 [754.389135ms]
Feb  8 23:04:00.961: INFO: Created: latency-svc-xhb2v
Feb  8 23:04:00.999: INFO: Got endpoints: latency-svc-th8jx [745.3407ms]
Feb  8 23:04:01.008: INFO: Created: latency-svc-qng5x
Feb  8 23:04:01.050: INFO: Got endpoints: latency-svc-c42b5 [751.772752ms]
Feb  8 23:04:01.061: INFO: Created: latency-svc-wb5ht
Feb  8 23:04:01.101: INFO: Got endpoints: latency-svc-mc7vx [748.911917ms]
Feb  8 23:04:01.111: INFO: Created: latency-svc-6t4xh
Feb  8 23:04:01.150: INFO: Got endpoints: latency-svc-b7gn2 [750.792324ms]
Feb  8 23:04:01.159: INFO: Created: latency-svc-9bvmx
Feb  8 23:04:01.200: INFO: Got endpoints: latency-svc-j5b29 [750.729255ms]
Feb  8 23:04:01.210: INFO: Created: latency-svc-7gj9d
Feb  8 23:04:01.253: INFO: Got endpoints: latency-svc-tchwm [752.833041ms]
Feb  8 23:04:01.262: INFO: Created: latency-svc-cz6rw
Feb  8 23:04:01.301: INFO: Got endpoints: latency-svc-ndfnz [751.806486ms]
Feb  8 23:04:01.311: INFO: Created: latency-svc-l9flw
Feb  8 23:04:01.350: INFO: Got endpoints: latency-svc-klzfq [751.715447ms]
Feb  8 23:04:01.362: INFO: Created: latency-svc-cnk9t
Feb  8 23:04:01.399: INFO: Got endpoints: latency-svc-n5fzb [748.949006ms]
Feb  8 23:04:01.407: INFO: Created: latency-svc-w8nc9
Feb  8 23:04:01.453: INFO: Got endpoints: latency-svc-fjncl [754.419404ms]
Feb  8 23:04:01.462: INFO: Created: latency-svc-hnk8z
Feb  8 23:04:01.501: INFO: Got endpoints: latency-svc-fjh8f [747.715775ms]
Feb  8 23:04:01.512: INFO: Created: latency-svc-mw8w7
Feb  8 23:04:01.550: INFO: Got endpoints: latency-svc-scblx [750.232038ms]
Feb  8 23:04:01.559: INFO: Created: latency-svc-dzt5f
Feb  8 23:04:01.599: INFO: Got endpoints: latency-svc-s66fw [750.963253ms]
Feb  8 23:04:01.607: INFO: Created: latency-svc-cmq6k
Feb  8 23:04:01.649: INFO: Got endpoints: latency-svc-2bxl8 [747.573416ms]
Feb  8 23:04:01.659: INFO: Created: latency-svc-85n7r
Feb  8 23:04:01.699: INFO: Got endpoints: latency-svc-xhb2v [745.773552ms]
Feb  8 23:04:01.707: INFO: Created: latency-svc-8fgq4
Feb  8 23:04:01.749: INFO: Got endpoints: latency-svc-qng5x [750.09019ms]
Feb  8 23:04:01.759: INFO: Created: latency-svc-js8xs
Feb  8 23:04:01.798: INFO: Got endpoints: latency-svc-wb5ht [748.604987ms]
Feb  8 23:04:01.808: INFO: Created: latency-svc-q8gkr
Feb  8 23:04:01.849: INFO: Got endpoints: latency-svc-6t4xh [748.156753ms]
Feb  8 23:04:01.858: INFO: Created: latency-svc-bntct
Feb  8 23:04:01.899: INFO: Got endpoints: latency-svc-9bvmx [749.047864ms]
Feb  8 23:04:01.955: INFO: Got endpoints: latency-svc-7gj9d [755.837355ms]
Feb  8 23:04:02.001: INFO: Got endpoints: latency-svc-cz6rw [747.435221ms]
Feb  8 23:04:02.049: INFO: Got endpoints: latency-svc-l9flw [748.046838ms]
Feb  8 23:04:02.099: INFO: Got endpoints: latency-svc-cnk9t [748.989607ms]
Feb  8 23:04:02.148: INFO: Got endpoints: latency-svc-w8nc9 [749.53237ms]
Feb  8 23:04:02.198: INFO: Got endpoints: latency-svc-hnk8z [744.933025ms]
Feb  8 23:04:02.248: INFO: Got endpoints: latency-svc-mw8w7 [747.342567ms]
Feb  8 23:04:02.298: INFO: Got endpoints: latency-svc-dzt5f [748.138465ms]
Feb  8 23:04:02.349: INFO: Got endpoints: latency-svc-cmq6k [749.23871ms]
Feb  8 23:04:02.400: INFO: Got endpoints: latency-svc-85n7r [751.362846ms]
Feb  8 23:04:02.449: INFO: Got endpoints: latency-svc-8fgq4 [749.940537ms]
Feb  8 23:04:02.499: INFO: Got endpoints: latency-svc-js8xs [749.845088ms]
Feb  8 23:04:02.548: INFO: Got endpoints: latency-svc-q8gkr [749.323878ms]
Feb  8 23:04:02.599: INFO: Got endpoints: latency-svc-bntct [749.804893ms]
Feb  8 23:04:02.599: INFO: Latencies: [18.776309ms 33.053244ms 35.057116ms 41.755682ms 49.234502ms 59.14734ms 78.319391ms 84.615473ms 91.013373ms 100.216908ms 106.400762ms 108.428649ms 109.98179ms 111.252976ms 111.335243ms 111.985349ms 113.416986ms 114.424311ms 114.520049ms 115.398559ms 116.232198ms 120.202928ms 121.615309ms 121.643018ms 121.899768ms 122.223734ms 122.529489ms 123.405712ms 125.199056ms 125.251891ms 126.043784ms 126.525549ms 128.777866ms 136.896631ms 137.304154ms 161.822537ms 203.651319ms 246.660541ms 287.742388ms 330.771961ms 369.848666ms 416.913019ms 454.771851ms 496.412505ms 534.725518ms 580.851747ms 616.962355ms 658.830967ms 703.031319ms 744.933025ms 745.3407ms 745.743521ms 745.773552ms 746.081553ms 746.415354ms 747.013047ms 747.071234ms 747.342567ms 747.435221ms 747.573416ms 747.610245ms 747.715775ms 747.735961ms 747.777286ms 747.847977ms 748.046838ms 748.109716ms 748.138465ms 748.156753ms 748.15861ms 748.220607ms 748.444952ms 748.447111ms 748.472207ms 748.475198ms 748.528482ms 748.556724ms 748.597072ms 748.604987ms 748.60639ms 748.634229ms 748.669983ms 748.691573ms 748.713697ms 748.731135ms 748.739516ms 748.749232ms 748.771744ms 748.889443ms 748.911917ms 748.949006ms 748.973851ms 748.987434ms 748.989607ms 749.017969ms 749.0199ms 749.032919ms 749.043158ms 749.047864ms 749.173824ms 749.204753ms 749.226373ms 749.23871ms 749.280468ms 749.323878ms 749.338573ms 749.350666ms 749.417015ms 749.45325ms 749.457336ms 749.463976ms 749.493304ms 749.53237ms 749.583853ms 749.596245ms 749.61272ms 749.659934ms 749.667594ms 749.683345ms 749.693152ms 749.708732ms 749.734677ms 749.745457ms 749.784047ms 749.804893ms 749.812659ms 749.845088ms 749.914186ms 749.940537ms 749.977834ms 749.988502ms 750.003356ms 750.019647ms 750.020767ms 750.057734ms 750.09019ms 750.091028ms 750.094155ms 750.166713ms 750.179969ms 750.22451ms 750.227181ms 750.232038ms 750.248447ms 750.273658ms 750.372121ms 750.509664ms 750.550169ms 750.561035ms 750.594241ms 750.597839ms 750.712919ms 750.729255ms 750.792324ms 750.838319ms 750.843248ms 750.857227ms 750.907542ms 750.926904ms 750.963253ms 750.991546ms 751.024652ms 751.071143ms 751.197541ms 751.265154ms 751.277739ms 751.303158ms 751.362846ms 751.389705ms 751.529648ms 751.545304ms 751.580931ms 751.715447ms 751.770689ms 751.772752ms 751.806486ms 751.847101ms 751.876955ms 751.955549ms 752.009481ms 752.035829ms 752.068805ms 752.363369ms 752.364874ms 752.380751ms 752.427913ms 752.57983ms 752.806979ms 752.833041ms 752.855131ms 753.1319ms 753.131926ms 753.187331ms 753.506948ms 754.223742ms 754.347509ms 754.387585ms 754.389135ms 754.419404ms 755.837355ms]
Feb  8 23:04:02.599: INFO: 50 %ile: 749.204753ms
Feb  8 23:04:02.599: INFO: 90 %ile: 752.035829ms
Feb  8 23:04:02.599: INFO: 99 %ile: 754.419404ms
Feb  8 23:04:02.599: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:04:02.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-skztn" for this suite.
Feb  8 23:04:18.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:04:18.659: INFO: namespace: e2e-tests-svc-latency-skztn, resource: bindings, ignored listing per whitelist
Feb  8 23:04:18.689: INFO: namespace e2e-tests-svc-latency-skztn deletion completed in 16.086812184s

• [SLOW TEST:26.857 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:04:18.689: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-dd12eddd-2bf5-11e9-a551-0a580a020303
STEP: Creating a pod to test consume configMaps
Feb  8 23:04:18.759: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-dd13785d-2bf5-11e9-a551-0a580a020303" in namespace "e2e-tests-projected-8km2c" to be "success or failure"
Feb  8 23:04:18.764: INFO: Pod "pod-projected-configmaps-dd13785d-2bf5-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 5.35984ms
Feb  8 23:04:20.768: INFO: Pod "pod-projected-configmaps-dd13785d-2bf5-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008910404s
STEP: Saw pod success
Feb  8 23:04:20.768: INFO: Pod "pod-projected-configmaps-dd13785d-2bf5-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:04:20.770: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod pod-projected-configmaps-dd13785d-2bf5-11e9-a551-0a580a020303 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  8 23:04:20.789: INFO: Waiting for pod pod-projected-configmaps-dd13785d-2bf5-11e9-a551-0a580a020303 to disappear
Feb  8 23:04:20.792: INFO: Pod pod-projected-configmaps-dd13785d-2bf5-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:04:20.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8km2c" for this suite.
Feb  8 23:04:26.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:04:26.843: INFO: namespace: e2e-tests-projected-8km2c, resource: bindings, ignored listing per whitelist
Feb  8 23:04:26.879: INFO: namespace e2e-tests-projected-8km2c deletion completed in 6.084182157s

• [SLOW TEST:8.190 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:04:26.879: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb  8 23:04:26.937: INFO: Waiting up to 5m0s for pod "pod-e1f2e5f9-2bf5-11e9-a551-0a580a020303" in namespace "e2e-tests-emptydir-hxz9f" to be "success or failure"
Feb  8 23:04:26.949: INFO: Pod "pod-e1f2e5f9-2bf5-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 11.6155ms
Feb  8 23:04:28.953: INFO: Pod "pod-e1f2e5f9-2bf5-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015220214s
Feb  8 23:04:30.956: INFO: Pod "pod-e1f2e5f9-2bf5-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018752926s
STEP: Saw pod success
Feb  8 23:04:30.956: INFO: Pod "pod-e1f2e5f9-2bf5-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:04:30.958: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod pod-e1f2e5f9-2bf5-11e9-a551-0a580a020303 container test-container: <nil>
STEP: delete the pod
Feb  8 23:04:30.976: INFO: Waiting for pod pod-e1f2e5f9-2bf5-11e9-a551-0a580a020303 to disappear
Feb  8 23:04:30.979: INFO: Pod pod-e1f2e5f9-2bf5-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:04:30.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hxz9f" for this suite.
Feb  8 23:04:36.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:04:37.052: INFO: namespace: e2e-tests-emptydir-hxz9f, resource: bindings, ignored listing per whitelist
Feb  8 23:04:37.066: INFO: namespace e2e-tests-emptydir-hxz9f deletion completed in 6.084409418s

• [SLOW TEST:10.187 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:04:37.066: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-xdqdg
Feb  8 23:04:39.131: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-xdqdg
STEP: checking the pod's current state and verifying that restartCount is present
Feb  8 23:04:39.133: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:08:39.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-xdqdg" for this suite.
Feb  8 23:08:45.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:08:45.579: INFO: namespace: e2e-tests-container-probe-xdqdg, resource: bindings, ignored listing per whitelist
Feb  8 23:08:45.643: INFO: namespace e2e-tests-container-probe-xdqdg deletion completed in 6.086023399s

• [SLOW TEST:248.576 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:08:45.643: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-gwrzw A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-gwrzw;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-gwrzw A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-gwrzw;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-gwrzw.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-gwrzw.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-gwrzw.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-gwrzw.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-gwrzw.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-gwrzw.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-gwrzw.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gwrzw.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-gwrzw.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-gwrzw.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-gwrzw.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-gwrzw.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-gwrzw.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 237.0.3.10.in-addr.arpa. PTR)" && echo OK > /results/10.3.0.237_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 237.0.3.10.in-addr.arpa. PTR)" && echo OK > /results/10.3.0.237_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-gwrzw A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-gwrzw;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-gwrzw A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-gwrzw;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-gwrzw.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-gwrzw.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-gwrzw.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-gwrzw.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-gwrzw.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-gwrzw.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-gwrzw.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gwrzw.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-gwrzw.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-gwrzw.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-gwrzw.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-gwrzw.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-gwrzw.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 237.0.3.10.in-addr.arpa. PTR)" && echo OK > /results/10.3.0.237_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 237.0.3.10.in-addr.arpa. PTR)" && echo OK > /results/10.3.0.237_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb  8 23:08:57.735: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:08:57.738: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:08:57.741: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-gwrzw from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:08:57.745: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-gwrzw from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:08:57.748: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-gwrzw.svc from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:08:57.750: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-gwrzw.svc from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:08:57.753: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-gwrzw.svc from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:08:57.756: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gwrzw.svc from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:08:57.776: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:08:57.779: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:08:57.782: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-gwrzw from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:08:57.785: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-gwrzw from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:08:57.787: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-gwrzw.svc from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:08:57.790: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-gwrzw.svc from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:08:57.793: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-gwrzw.svc from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:08:57.795: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gwrzw.svc from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:08:57.811: INFO: Lookups using e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-gwrzw wheezy_tcp@dns-test-service.e2e-tests-dns-gwrzw wheezy_udp@dns-test-service.e2e-tests-dns-gwrzw.svc wheezy_tcp@dns-test-service.e2e-tests-dns-gwrzw.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-gwrzw.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gwrzw.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-gwrzw jessie_tcp@dns-test-service.e2e-tests-dns-gwrzw jessie_udp@dns-test-service.e2e-tests-dns-gwrzw.svc jessie_tcp@dns-test-service.e2e-tests-dns-gwrzw.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-gwrzw.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gwrzw.svc]

Feb  8 23:09:07.734: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:09:07.738: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:09:07.741: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-gwrzw from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:09:07.744: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-gwrzw from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:09:07.747: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-gwrzw.svc from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:09:07.749: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-gwrzw.svc from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:09:07.752: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-gwrzw.svc from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:09:07.755: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gwrzw.svc from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:09:07.774: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:09:07.777: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:09:07.780: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-gwrzw from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:09:07.782: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-gwrzw from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:09:07.785: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-gwrzw.svc from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:09:07.788: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-gwrzw.svc from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:09:07.790: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-gwrzw.svc from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:09:07.793: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gwrzw.svc from pod e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303: the server could not find the requested resource (get pods dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303)
Feb  8 23:09:07.810: INFO: Lookups using e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-gwrzw wheezy_tcp@dns-test-service.e2e-tests-dns-gwrzw wheezy_udp@dns-test-service.e2e-tests-dns-gwrzw.svc wheezy_tcp@dns-test-service.e2e-tests-dns-gwrzw.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-gwrzw.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gwrzw.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-gwrzw jessie_tcp@dns-test-service.e2e-tests-dns-gwrzw jessie_udp@dns-test-service.e2e-tests-dns-gwrzw.svc jessie_tcp@dns-test-service.e2e-tests-dns-gwrzw.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-gwrzw.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gwrzw.svc]

Feb  8 23:09:17.814: INFO: DNS probes using e2e-tests-dns-gwrzw/dns-test-7c315fb9-2bf6-11e9-a551-0a580a020303 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:09:17.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-gwrzw" for this suite.
Feb  8 23:09:23.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:09:23.931: INFO: namespace: e2e-tests-dns-gwrzw, resource: bindings, ignored listing per whitelist
Feb  8 23:09:23.960: INFO: namespace e2e-tests-dns-gwrzw deletion completed in 6.084282068s

• [SLOW TEST:38.317 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:09:23.960: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb  8 23:09:24.019: INFO: Waiting up to 5m0s for pod "pod-9306a3b2-2bf6-11e9-a551-0a580a020303" in namespace "e2e-tests-emptydir-gbz7n" to be "success or failure"
Feb  8 23:09:24.022: INFO: Pod "pod-9306a3b2-2bf6-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.334057ms
Feb  8 23:09:26.025: INFO: Pod "pod-9306a3b2-2bf6-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005924156s
STEP: Saw pod success
Feb  8 23:09:26.025: INFO: Pod "pod-9306a3b2-2bf6-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:09:26.028: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod pod-9306a3b2-2bf6-11e9-a551-0a580a020303 container test-container: <nil>
STEP: delete the pod
Feb  8 23:09:26.050: INFO: Waiting for pod pod-9306a3b2-2bf6-11e9-a551-0a580a020303 to disappear
Feb  8 23:09:26.053: INFO: Pod pod-9306a3b2-2bf6-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:09:26.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gbz7n" for this suite.
Feb  8 23:09:32.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:09:32.092: INFO: namespace: e2e-tests-emptydir-gbz7n, resource: bindings, ignored listing per whitelist
Feb  8 23:09:32.147: INFO: namespace e2e-tests-emptydir-gbz7n deletion completed in 6.090537935s

• [SLOW TEST:8.187 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:09:32.147: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-vbjph
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-vbjph
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-vbjph
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-vbjph
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-vbjph
Feb  8 23:09:34.224: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-vbjph, name: ss-0, uid: 97f5119d-2bf6-11e9-a760-02d2eeadbd48, status phase: Pending. Waiting for statefulset controller to delete.
Feb  8 23:09:37.888: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-vbjph, name: ss-0, uid: 97f5119d-2bf6-11e9-a760-02d2eeadbd48, status phase: Failed. Waiting for statefulset controller to delete.
Feb  8 23:09:37.896: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-vbjph, name: ss-0, uid: 97f5119d-2bf6-11e9-a760-02d2eeadbd48, status phase: Failed. Waiting for statefulset controller to delete.
Feb  8 23:09:37.900: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-vbjph
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-vbjph
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-vbjph and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  8 23:09:39.935: INFO: Deleting all statefulset in ns e2e-tests-statefulset-vbjph
Feb  8 23:09:39.939: INFO: Scaling statefulset ss to 0
Feb  8 23:09:49.954: INFO: Waiting for statefulset status.replicas updated to 0
Feb  8 23:09:49.957: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:09:49.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-vbjph" for this suite.
Feb  8 23:09:55.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:09:56.052: INFO: namespace: e2e-tests-statefulset-vbjph, resource: bindings, ignored listing per whitelist
Feb  8 23:09:56.063: INFO: namespace e2e-tests-statefulset-vbjph deletion completed in 6.086584465s

• [SLOW TEST:23.916 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:09:56.064: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  8 23:09:56.116: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb  8 23:09:56.122: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb  8 23:10:01.134: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb  8 23:10:01.134: INFO: Creating deployment "test-rolling-update-deployment"
Feb  8 23:10:01.140: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb  8 23:10:01.146: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Feb  8 23:10:03.151: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb  8 23:10:03.153: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  8 23:10:03.160: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-rvfcp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rvfcp/deployments/test-rolling-update-deployment,UID:a92723d2-2bf6-11e9-a760-02d2eeadbd48,ResourceVersion:12093,Generation:1,CreationTimestamp:2019-02-08 23:10:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-08 23:10:01 +0000 UTC 2019-02-08 23:10:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-08 23:10:03 +0000 UTC 2019-02-08 23:10:01 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb  8 23:10:03.163: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-rvfcp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rvfcp/replicasets/test-rolling-update-deployment-65b7695dcf,UID:a929c1cc-2bf6-11e9-a760-02d2eeadbd48,ResourceVersion:12084,Generation:1,CreationTimestamp:2019-02-08 23:10:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment a92723d2-2bf6-11e9-a760-02d2eeadbd48 0xc421dc51d7 0xc421dc51d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb  8 23:10:03.163: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb  8 23:10:03.163: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-rvfcp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rvfcp/replicasets/test-rolling-update-controller,UID:a629624c-2bf6-11e9-a760-02d2eeadbd48,ResourceVersion:12092,Generation:2,CreationTimestamp:2019-02-08 23:09:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment a92723d2-2bf6-11e9-a760-02d2eeadbd48 0xc421dc44be 0xc421dc44bf}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  8 23:10:03.166: INFO: Pod "test-rolling-update-deployment-65b7695dcf-4grl4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-4grl4,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-rvfcp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rvfcp/pods/test-rolling-update-deployment-65b7695dcf-4grl4,UID:a92a446e-2bf6-11e9-a760-02d2eeadbd48,ResourceVersion:12083,Generation:0,CreationTimestamp:2019-02-08 23:10:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf a929c1cc-2bf6-11e9-a760-02d2eeadbd48 0xc42260c427 0xc42260c428}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nv5kx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nv5kx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-nv5kx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-23-7-130.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42260c490} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42260c4b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:10:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:10:03 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:10:03 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:10:01 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.130,PodIP:10.2.2.83,StartTime:2019-02-08 23:10:01 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-08 23:10:02 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://a7bd16bbf87524054ee69e984c3289483b16d570de75c9b9c5d976efa58757fb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:10:03.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-rvfcp" for this suite.
Feb  8 23:10:09.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:10:09.224: INFO: namespace: e2e-tests-deployment-rvfcp, resource: bindings, ignored listing per whitelist
Feb  8 23:10:09.252: INFO: namespace e2e-tests-deployment-rvfcp deletion completed in 6.083480424s

• [SLOW TEST:13.189 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:10:09.252: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb  8 23:10:09.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 create -f - --namespace=e2e-tests-kubectl-8rvnv'
Feb  8 23:10:09.615: INFO: stderr: ""
Feb  8 23:10:09.615: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  8 23:10:09.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8rvnv'
Feb  8 23:10:09.700: INFO: stderr: ""
Feb  8 23:10:09.700: INFO: stdout: "update-demo-nautilus-5xg5r update-demo-nautilus-65gdx "
Feb  8 23:10:09.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods update-demo-nautilus-5xg5r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8rvnv'
Feb  8 23:10:09.776: INFO: stderr: ""
Feb  8 23:10:09.776: INFO: stdout: ""
Feb  8 23:10:09.776: INFO: update-demo-nautilus-5xg5r is created but not running
Feb  8 23:10:14.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8rvnv'
Feb  8 23:10:14.857: INFO: stderr: ""
Feb  8 23:10:14.857: INFO: stdout: "update-demo-nautilus-5xg5r update-demo-nautilus-65gdx "
Feb  8 23:10:14.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods update-demo-nautilus-5xg5r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8rvnv'
Feb  8 23:10:14.941: INFO: stderr: ""
Feb  8 23:10:14.941: INFO: stdout: "true"
Feb  8 23:10:14.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods update-demo-nautilus-5xg5r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8rvnv'
Feb  8 23:10:15.017: INFO: stderr: ""
Feb  8 23:10:15.018: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  8 23:10:15.018: INFO: validating pod update-demo-nautilus-5xg5r
Feb  8 23:10:15.022: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  8 23:10:15.022: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  8 23:10:15.022: INFO: update-demo-nautilus-5xg5r is verified up and running
Feb  8 23:10:15.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods update-demo-nautilus-65gdx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8rvnv'
Feb  8 23:10:15.098: INFO: stderr: ""
Feb  8 23:10:15.098: INFO: stdout: "true"
Feb  8 23:10:15.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods update-demo-nautilus-65gdx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8rvnv'
Feb  8 23:10:15.173: INFO: stderr: ""
Feb  8 23:10:15.173: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  8 23:10:15.173: INFO: validating pod update-demo-nautilus-65gdx
Feb  8 23:10:15.177: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  8 23:10:15.177: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  8 23:10:15.177: INFO: update-demo-nautilus-65gdx is verified up and running
STEP: using delete to clean up resources
Feb  8 23:10:15.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-8rvnv'
Feb  8 23:10:15.296: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  8 23:10:15.296: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb  8 23:10:15.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-8rvnv'
Feb  8 23:10:15.405: INFO: stderr: "No resources found.\n"
Feb  8 23:10:15.405: INFO: stdout: ""
Feb  8 23:10:15.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods -l name=update-demo --namespace=e2e-tests-kubectl-8rvnv -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  8 23:10:15.486: INFO: stderr: ""
Feb  8 23:10:15.486: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:10:15.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8rvnv" for this suite.
Feb  8 23:10:37.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:10:37.577: INFO: namespace: e2e-tests-kubectl-8rvnv, resource: bindings, ignored listing per whitelist
Feb  8 23:10:37.577: INFO: namespace e2e-tests-kubectl-8rvnv deletion completed in 22.086630003s

• [SLOW TEST:28.324 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:10:37.577: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Feb  8 23:10:37.630: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  8 23:10:37.637: INFO: Waiting for terminating namespaces to be deleted...
Feb  8 23:10:37.639: INFO: 
Logging pods the kubelet thinks is on node ip-172-23-7-110.us-west-2.compute.internal before test
Feb  8 23:10:37.644: INFO: kube-flannel-ds-5cwbb from kube-system started at 2019-02-08 22:14:48 +0000 UTC (1 container statuses recorded)
Feb  8 23:10:37.644: INFO: 	Container kube-flannel ready: true, restart count 0
Feb  8 23:10:37.644: INFO: kube-proxy-74ndc from kube-system started at 2019-02-08 22:14:48 +0000 UTC (1 container statuses recorded)
Feb  8 23:10:37.644: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  8 23:10:37.644: INFO: tiller-deploy-6fb6d4777d-pswxg from kube-system started at 2019-02-08 22:15:35 +0000 UTC (1 container statuses recorded)
Feb  8 23:10:37.644: INFO: 	Container tiller ready: true, restart count 0
Feb  8 23:10:37.644: INFO: sonobuoy-systemd-logs-daemon-set-97ae410a3d2d4a52-tsw98 from heptio-sonobuoy started at 2019-02-08 22:19:47 +0000 UTC (2 container statuses recorded)
Feb  8 23:10:37.644: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb  8 23:10:37.644: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  8 23:10:37.644: INFO: 
Logging pods the kubelet thinks is on node ip-172-23-7-130.us-west-2.compute.internal before test
Feb  8 23:10:37.649: INFO: kubernetes-dashboard-778d4ccc65-2mgbl from kube-system started at 2019-02-08 22:16:05 +0000 UTC (1 container statuses recorded)
Feb  8 23:10:37.649: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb  8 23:10:37.649: INFO: sonobuoy-systemd-logs-daemon-set-97ae410a3d2d4a52-rhwxj from heptio-sonobuoy started at 2019-02-08 22:19:47 +0000 UTC (2 container statuses recorded)
Feb  8 23:10:37.649: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb  8 23:10:37.649: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  8 23:10:37.649: INFO: kube-flannel-ds-hbllw from kube-system started at 2019-02-08 22:14:48 +0000 UTC (1 container statuses recorded)
Feb  8 23:10:37.649: INFO: 	Container kube-flannel ready: true, restart count 0
Feb  8 23:10:37.649: INFO: kube-proxy-4fjpj from kube-system started at 2019-02-08 22:14:48 +0000 UTC (1 container statuses recorded)
Feb  8 23:10:37.649: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  8 23:10:37.649: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-08 22:19:44 +0000 UTC (1 container statuses recorded)
Feb  8 23:10:37.649: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb  8 23:10:37.649: INFO: 
Logging pods the kubelet thinks is on node ip-172-23-7-34.us-west-2.compute.internal before test
Feb  8 23:10:37.654: INFO: kube-flannel-ds-n6skb from kube-system started at 2019-02-08 22:14:48 +0000 UTC (1 container statuses recorded)
Feb  8 23:10:37.654: INFO: 	Container kube-flannel ready: true, restart count 0
Feb  8 23:10:37.654: INFO: kube-proxy-c97zb from kube-system started at 2019-02-08 22:14:48 +0000 UTC (1 container statuses recorded)
Feb  8 23:10:37.654: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  8 23:10:37.654: INFO: heapster-5459947ccc-rlxzx from kube-system started at 2019-02-08 22:16:05 +0000 UTC (1 container statuses recorded)
Feb  8 23:10:37.654: INFO: 	Container heapster ready: true, restart count 0
Feb  8 23:10:37.654: INFO: sonobuoy-e2e-job-3bb448efb05f49ae from heptio-sonobuoy started at 2019-02-08 22:19:47 +0000 UTC (2 container statuses recorded)
Feb  8 23:10:37.654: INFO: 	Container e2e ready: true, restart count 0
Feb  8 23:10:37.654: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  8 23:10:37.654: INFO: sonobuoy-systemd-logs-daemon-set-97ae410a3d2d4a52-vzm9c from heptio-sonobuoy started at 2019-02-08 22:19:47 +0000 UTC (2 container statuses recorded)
Feb  8 23:10:37.654: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb  8 23:10:37.654: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-c020bca3-2bf6-11e9-a551-0a580a020303 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-c020bca3-2bf6-11e9-a551-0a580a020303 off the node ip-172-23-7-110.us-west-2.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-c020bca3-2bf6-11e9-a551-0a580a020303
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:10:41.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-cpdck" for this suite.
Feb  8 23:10:49.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:10:49.781: INFO: namespace: e2e-tests-sched-pred-cpdck, resource: bindings, ignored listing per whitelist
Feb  8 23:10:49.819: INFO: namespace e2e-tests-sched-pred-cpdck deletion completed in 8.095475352s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:12.242 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:10:49.819: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Feb  8 23:10:49.877: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-9bf8z" to be "success or failure"
Feb  8 23:10:49.881: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 3.884637ms
Feb  8 23:10:51.885: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007217437s
STEP: Saw pod success
Feb  8 23:10:51.885: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb  8 23:10:51.887: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb  8 23:10:51.907: INFO: Waiting for pod pod-host-path-test to disappear
Feb  8 23:10:51.909: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:10:51.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-9bf8z" for this suite.
Feb  8 23:10:57.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:10:57.993: INFO: namespace: e2e-tests-hostpath-9bf8z, resource: bindings, ignored listing per whitelist
Feb  8 23:10:57.998: INFO: namespace e2e-tests-hostpath-9bf8z deletion completed in 6.085607458s

• [SLOW TEST:8.179 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:10:57.998: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  8 23:10:58.055: INFO: (0) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 4.764715ms)
Feb  8 23:10:58.058: INFO: (1) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.237798ms)
Feb  8 23:10:58.061: INFO: (2) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.01047ms)
Feb  8 23:10:58.064: INFO: (3) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.023996ms)
Feb  8 23:10:58.067: INFO: (4) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.030642ms)
Feb  8 23:10:58.070: INFO: (5) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.031626ms)
Feb  8 23:10:58.073: INFO: (6) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.002356ms)
Feb  8 23:10:58.076: INFO: (7) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.877295ms)
Feb  8 23:10:58.079: INFO: (8) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.964218ms)
Feb  8 23:10:58.082: INFO: (9) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.193905ms)
Feb  8 23:10:58.088: INFO: (10) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 5.640572ms)
Feb  8 23:10:58.092: INFO: (11) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 4.291411ms)
Feb  8 23:10:58.095: INFO: (12) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.002563ms)
Feb  8 23:10:58.098: INFO: (13) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.985243ms)
Feb  8 23:10:58.101: INFO: (14) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.950701ms)
Feb  8 23:10:58.104: INFO: (15) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.994968ms)
Feb  8 23:10:58.107: INFO: (16) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.067017ms)
Feb  8 23:10:58.110: INFO: (17) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.119028ms)
Feb  8 23:10:58.113: INFO: (18) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.976583ms)
Feb  8 23:10:58.116: INFO: (19) /api/v1/nodes/ip-172-23-7-110.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.016738ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:10:58.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-pvps6" for this suite.
Feb  8 23:11:04.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:11:04.198: INFO: namespace: e2e-tests-proxy-pvps6, resource: bindings, ignored listing per whitelist
Feb  8 23:11:04.206: INFO: namespace e2e-tests-proxy-pvps6 deletion completed in 6.086737687s

• [SLOW TEST:6.208 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:11:04.206: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb  8 23:11:04.266: INFO: Waiting up to 5m0s for pod "pod-cec6fd45-2bf6-11e9-a551-0a580a020303" in namespace "e2e-tests-emptydir-8bqqp" to be "success or failure"
Feb  8 23:11:04.271: INFO: Pod "pod-cec6fd45-2bf6-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 4.575603ms
Feb  8 23:11:06.274: INFO: Pod "pod-cec6fd45-2bf6-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007791164s
STEP: Saw pod success
Feb  8 23:11:06.274: INFO: Pod "pod-cec6fd45-2bf6-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:11:06.277: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod pod-cec6fd45-2bf6-11e9-a551-0a580a020303 container test-container: <nil>
STEP: delete the pod
Feb  8 23:11:06.293: INFO: Waiting for pod pod-cec6fd45-2bf6-11e9-a551-0a580a020303 to disappear
Feb  8 23:11:06.295: INFO: Pod pod-cec6fd45-2bf6-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:11:06.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8bqqp" for this suite.
Feb  8 23:11:12.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:11:12.342: INFO: namespace: e2e-tests-emptydir-8bqqp, resource: bindings, ignored listing per whitelist
Feb  8 23:11:12.381: INFO: namespace e2e-tests-emptydir-8bqqp deletion completed in 6.082481611s

• [SLOW TEST:8.175 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:11:12.381: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-d3a56bd7-2bf6-11e9-a551-0a580a020303
STEP: Creating a pod to test consume secrets
Feb  8 23:11:12.438: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d3a5f27e-2bf6-11e9-a551-0a580a020303" in namespace "e2e-tests-projected-zp562" to be "success or failure"
Feb  8 23:11:12.442: INFO: Pod "pod-projected-secrets-d3a5f27e-2bf6-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 3.957472ms
Feb  8 23:11:14.446: INFO: Pod "pod-projected-secrets-d3a5f27e-2bf6-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007368433s
STEP: Saw pod success
Feb  8 23:11:14.446: INFO: Pod "pod-projected-secrets-d3a5f27e-2bf6-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:11:14.448: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod pod-projected-secrets-d3a5f27e-2bf6-11e9-a551-0a580a020303 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  8 23:11:14.466: INFO: Waiting for pod pod-projected-secrets-d3a5f27e-2bf6-11e9-a551-0a580a020303 to disappear
Feb  8 23:11:14.470: INFO: Pod pod-projected-secrets-d3a5f27e-2bf6-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:11:14.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zp562" for this suite.
Feb  8 23:11:20.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:11:20.540: INFO: namespace: e2e-tests-projected-zp562, resource: bindings, ignored listing per whitelist
Feb  8 23:11:20.569: INFO: namespace e2e-tests-projected-zp562 deletion completed in 6.087783672s

• [SLOW TEST:8.188 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:11:20.570: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Feb  8 23:11:20.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 create -f - --namespace=e2e-tests-kubectl-mhq25'
Feb  8 23:11:20.769: INFO: stderr: ""
Feb  8 23:11:20.769: INFO: stdout: "pod/pause created\n"
Feb  8 23:11:20.769: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb  8 23:11:20.769: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-mhq25" to be "running and ready"
Feb  8 23:11:20.772: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.615892ms
Feb  8 23:11:22.775: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.00586568s
Feb  8 23:11:22.775: INFO: Pod "pause" satisfied condition "running and ready"
Feb  8 23:11:22.775: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Feb  8 23:11:22.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-mhq25'
Feb  8 23:11:22.862: INFO: stderr: ""
Feb  8 23:11:22.862: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb  8 23:11:22.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pod pause -L testing-label --namespace=e2e-tests-kubectl-mhq25'
Feb  8 23:11:22.939: INFO: stderr: ""
Feb  8 23:11:22.939: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb  8 23:11:22.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 label pods pause testing-label- --namespace=e2e-tests-kubectl-mhq25'
Feb  8 23:11:23.027: INFO: stderr: ""
Feb  8 23:11:23.027: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb  8 23:11:23.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pod pause -L testing-label --namespace=e2e-tests-kubectl-mhq25'
Feb  8 23:11:23.107: INFO: stderr: ""
Feb  8 23:11:23.107: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Feb  8 23:11:23.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-mhq25'
Feb  8 23:11:23.188: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  8 23:11:23.188: INFO: stdout: "pod \"pause\" force deleted\n"
Feb  8 23:11:23.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-mhq25'
Feb  8 23:11:23.269: INFO: stderr: "No resources found.\n"
Feb  8 23:11:23.269: INFO: stdout: ""
Feb  8 23:11:23.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods -l name=pause --namespace=e2e-tests-kubectl-mhq25 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  8 23:11:23.344: INFO: stderr: ""
Feb  8 23:11:23.344: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:11:23.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mhq25" for this suite.
Feb  8 23:11:29.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:11:29.402: INFO: namespace: e2e-tests-kubectl-mhq25, resource: bindings, ignored listing per whitelist
Feb  8 23:11:29.433: INFO: namespace e2e-tests-kubectl-mhq25 deletion completed in 6.086233118s

• [SLOW TEST:8.864 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:11:29.433: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb  8 23:11:29.492: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-7cg8n,SelfLink:/api/v1/namespaces/e2e-tests-watch-7cg8n/configmaps/e2e-watch-test-watch-closed,UID:ddcfff4a-2bf6-11e9-a760-02d2eeadbd48,ResourceVersion:12476,Generation:0,CreationTimestamp:2019-02-08 23:11:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  8 23:11:29.492: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-7cg8n,SelfLink:/api/v1/namespaces/e2e-tests-watch-7cg8n/configmaps/e2e-watch-test-watch-closed,UID:ddcfff4a-2bf6-11e9-a760-02d2eeadbd48,ResourceVersion:12477,Generation:0,CreationTimestamp:2019-02-08 23:11:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb  8 23:11:29.508: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-7cg8n,SelfLink:/api/v1/namespaces/e2e-tests-watch-7cg8n/configmaps/e2e-watch-test-watch-closed,UID:ddcfff4a-2bf6-11e9-a760-02d2eeadbd48,ResourceVersion:12478,Generation:0,CreationTimestamp:2019-02-08 23:11:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  8 23:11:29.508: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-7cg8n,SelfLink:/api/v1/namespaces/e2e-tests-watch-7cg8n/configmaps/e2e-watch-test-watch-closed,UID:ddcfff4a-2bf6-11e9-a760-02d2eeadbd48,ResourceVersion:12479,Generation:0,CreationTimestamp:2019-02-08 23:11:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:11:29.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-7cg8n" for this suite.
Feb  8 23:11:35.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:11:35.534: INFO: namespace: e2e-tests-watch-7cg8n, resource: bindings, ignored listing per whitelist
Feb  8 23:11:35.599: INFO: namespace e2e-tests-watch-7cg8n deletion completed in 6.087653874s

• [SLOW TEST:6.165 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:11:35.599: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-e17da48e-2bf6-11e9-a551-0a580a020303
STEP: Creating secret with name s-test-opt-upd-e17da4d1-2bf6-11e9-a551-0a580a020303
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-e17da48e-2bf6-11e9-a551-0a580a020303
STEP: Updating secret s-test-opt-upd-e17da4d1-2bf6-11e9-a551-0a580a020303
STEP: Creating secret with name s-test-opt-create-e17da4ed-2bf6-11e9-a551-0a580a020303
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:11:39.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kmsmw" for this suite.
Feb  8 23:12:01.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:12:01.825: INFO: namespace: e2e-tests-projected-kmsmw, resource: bindings, ignored listing per whitelist
Feb  8 23:12:01.836: INFO: namespace e2e-tests-projected-kmsmw deletion completed in 22.093673958s

• [SLOW TEST:26.237 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:12:01.837: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-f121321e-2bf6-11e9-a551-0a580a020303
STEP: Creating a pod to test consume secrets
Feb  8 23:12:01.905: INFO: Waiting up to 5m0s for pod "pod-secrets-f121c0af-2bf6-11e9-a551-0a580a020303" in namespace "e2e-tests-secrets-7qrtt" to be "success or failure"
Feb  8 23:12:01.910: INFO: Pod "pod-secrets-f121c0af-2bf6-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 4.651449ms
Feb  8 23:12:03.913: INFO: Pod "pod-secrets-f121c0af-2bf6-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007705871s
STEP: Saw pod success
Feb  8 23:12:03.913: INFO: Pod "pod-secrets-f121c0af-2bf6-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:12:03.915: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod pod-secrets-f121c0af-2bf6-11e9-a551-0a580a020303 container secret-volume-test: <nil>
STEP: delete the pod
Feb  8 23:12:03.941: INFO: Waiting for pod pod-secrets-f121c0af-2bf6-11e9-a551-0a580a020303 to disappear
Feb  8 23:12:03.943: INFO: Pod pod-secrets-f121c0af-2bf6-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:12:03.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-7qrtt" for this suite.
Feb  8 23:12:09.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:12:10.018: INFO: namespace: e2e-tests-secrets-7qrtt, resource: bindings, ignored listing per whitelist
Feb  8 23:12:10.032: INFO: namespace e2e-tests-secrets-7qrtt deletion completed in 6.085614966s

• [SLOW TEST:8.195 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:12:10.032: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb  8 23:12:10.087: INFO: Waiting up to 5m0s for pod "pod-f6028daa-2bf6-11e9-a551-0a580a020303" in namespace "e2e-tests-emptydir-tjpxf" to be "success or failure"
Feb  8 23:12:10.090: INFO: Pod "pod-f6028daa-2bf6-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.384689ms
Feb  8 23:12:12.093: INFO: Pod "pod-f6028daa-2bf6-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005472345s
STEP: Saw pod success
Feb  8 23:12:12.093: INFO: Pod "pod-f6028daa-2bf6-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:12:12.095: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod pod-f6028daa-2bf6-11e9-a551-0a580a020303 container test-container: <nil>
STEP: delete the pod
Feb  8 23:12:12.112: INFO: Waiting for pod pod-f6028daa-2bf6-11e9-a551-0a580a020303 to disappear
Feb  8 23:12:12.114: INFO: Pod pod-f6028daa-2bf6-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:12:12.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-tjpxf" for this suite.
Feb  8 23:12:18.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:12:18.138: INFO: namespace: e2e-tests-emptydir-tjpxf, resource: bindings, ignored listing per whitelist
Feb  8 23:12:18.202: INFO: namespace e2e-tests-emptydir-tjpxf deletion completed in 6.084959419s

• [SLOW TEST:8.170 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:12:18.202: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  8 23:12:18.261: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:12:19.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-zz6mt" for this suite.
Feb  8 23:12:25.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:12:25.333: INFO: namespace: e2e-tests-custom-resource-definition-zz6mt, resource: bindings, ignored listing per whitelist
Feb  8 23:12:25.406: INFO: namespace e2e-tests-custom-resource-definition-zz6mt deletion completed in 6.09017469s

• [SLOW TEST:7.204 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:12:25.406: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  8 23:12:25.484: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb  8 23:12:25.490: INFO: Number of nodes with available pods: 0
Feb  8 23:12:25.490: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb  8 23:12:25.510: INFO: Number of nodes with available pods: 0
Feb  8 23:12:25.510: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:26.514: INFO: Number of nodes with available pods: 0
Feb  8 23:12:26.514: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:27.514: INFO: Number of nodes with available pods: 1
Feb  8 23:12:27.514: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb  8 23:12:27.529: INFO: Number of nodes with available pods: 1
Feb  8 23:12:27.529: INFO: Number of running nodes: 0, number of available pods: 1
Feb  8 23:12:28.532: INFO: Number of nodes with available pods: 0
Feb  8 23:12:28.532: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb  8 23:12:28.542: INFO: Number of nodes with available pods: 0
Feb  8 23:12:28.542: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:29.546: INFO: Number of nodes with available pods: 0
Feb  8 23:12:29.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:30.546: INFO: Number of nodes with available pods: 0
Feb  8 23:12:30.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:31.546: INFO: Number of nodes with available pods: 0
Feb  8 23:12:31.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:32.546: INFO: Number of nodes with available pods: 0
Feb  8 23:12:32.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:33.545: INFO: Number of nodes with available pods: 0
Feb  8 23:12:33.545: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:34.546: INFO: Number of nodes with available pods: 0
Feb  8 23:12:34.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:35.546: INFO: Number of nodes with available pods: 0
Feb  8 23:12:35.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:36.546: INFO: Number of nodes with available pods: 0
Feb  8 23:12:36.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:37.546: INFO: Number of nodes with available pods: 0
Feb  8 23:12:37.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:38.546: INFO: Number of nodes with available pods: 0
Feb  8 23:12:38.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:39.546: INFO: Number of nodes with available pods: 0
Feb  8 23:12:39.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:40.546: INFO: Number of nodes with available pods: 0
Feb  8 23:12:40.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:41.546: INFO: Number of nodes with available pods: 0
Feb  8 23:12:41.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:42.546: INFO: Number of nodes with available pods: 0
Feb  8 23:12:42.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:43.546: INFO: Number of nodes with available pods: 0
Feb  8 23:12:43.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:44.546: INFO: Number of nodes with available pods: 0
Feb  8 23:12:44.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:45.546: INFO: Number of nodes with available pods: 0
Feb  8 23:12:45.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:46.546: INFO: Number of nodes with available pods: 0
Feb  8 23:12:46.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:47.546: INFO: Number of nodes with available pods: 0
Feb  8 23:12:47.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:48.546: INFO: Number of nodes with available pods: 0
Feb  8 23:12:48.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:49.546: INFO: Number of nodes with available pods: 0
Feb  8 23:12:49.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:50.546: INFO: Number of nodes with available pods: 0
Feb  8 23:12:50.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:51.546: INFO: Number of nodes with available pods: 0
Feb  8 23:12:51.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:52.546: INFO: Number of nodes with available pods: 0
Feb  8 23:12:52.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:53.546: INFO: Number of nodes with available pods: 0
Feb  8 23:12:53.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:54.546: INFO: Number of nodes with available pods: 0
Feb  8 23:12:54.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:55.546: INFO: Number of nodes with available pods: 0
Feb  8 23:12:55.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:56.546: INFO: Number of nodes with available pods: 0
Feb  8 23:12:56.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:57.546: INFO: Number of nodes with available pods: 0
Feb  8 23:12:57.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:58.546: INFO: Number of nodes with available pods: 0
Feb  8 23:12:58.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:12:59.546: INFO: Number of nodes with available pods: 0
Feb  8 23:12:59.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:13:00.546: INFO: Number of nodes with available pods: 0
Feb  8 23:13:00.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:13:01.546: INFO: Number of nodes with available pods: 0
Feb  8 23:13:01.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:13:02.546: INFO: Number of nodes with available pods: 0
Feb  8 23:13:02.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:13:03.546: INFO: Number of nodes with available pods: 0
Feb  8 23:13:03.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:13:04.545: INFO: Number of nodes with available pods: 0
Feb  8 23:13:04.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:13:05.546: INFO: Number of nodes with available pods: 0
Feb  8 23:13:05.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:13:06.546: INFO: Number of nodes with available pods: 0
Feb  8 23:13:06.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:13:07.546: INFO: Number of nodes with available pods: 0
Feb  8 23:13:07.546: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:13:08.545: INFO: Number of nodes with available pods: 0
Feb  8 23:13:08.545: INFO: Node ip-172-23-7-110.us-west-2.compute.internal is running more than one daemon pod
Feb  8 23:13:09.546: INFO: Number of nodes with available pods: 1
Feb  8 23:13:09.546: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-9lz6d, will wait for the garbage collector to delete the pods
Feb  8 23:13:09.610: INFO: Deleting {extensions DaemonSet} daemon-set took: 6.801674ms
Feb  8 23:13:09.710: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.262979ms
Feb  8 23:13:47.913: INFO: Number of nodes with available pods: 0
Feb  8 23:13:47.913: INFO: Number of running nodes: 0, number of available pods: 0
Feb  8 23:13:47.915: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-9lz6d/daemonsets","resourceVersion":"12856"},"items":null}

Feb  8 23:13:47.917: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-9lz6d/pods","resourceVersion":"12856"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:13:47.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-9lz6d" for this suite.
Feb  8 23:13:53.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:13:53.981: INFO: namespace: e2e-tests-daemonsets-9lz6d, resource: bindings, ignored listing per whitelist
Feb  8 23:13:54.020: INFO: namespace e2e-tests-daemonsets-9lz6d deletion completed in 6.08336185s

• [SLOW TEST:88.614 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:13:54.020: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-srlkb
Feb  8 23:13:56.085: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-srlkb
STEP: checking the pod's current state and verifying that restartCount is present
Feb  8 23:13:56.087: INFO: Initial restart count of pod liveness-exec is 0
Feb  8 23:14:46.188: INFO: Restart count of pod e2e-tests-container-probe-srlkb/liveness-exec is now 1 (50.100711022s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:14:46.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-srlkb" for this suite.
Feb  8 23:14:52.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:14:52.240: INFO: namespace: e2e-tests-container-probe-srlkb, resource: bindings, ignored listing per whitelist
Feb  8 23:14:52.287: INFO: namespace e2e-tests-container-probe-srlkb deletion completed in 6.082875649s

• [SLOW TEST:58.267 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:14:52.288: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-56b90f20-2bf7-11e9-a551-0a580a020303
STEP: Creating a pod to test consume configMaps
Feb  8 23:14:52.349: INFO: Waiting up to 5m0s for pod "pod-configmaps-56b99043-2bf7-11e9-a551-0a580a020303" in namespace "e2e-tests-configmap-99s72" to be "success or failure"
Feb  8 23:14:52.352: INFO: Pod "pod-configmaps-56b99043-2bf7-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.382004ms
Feb  8 23:14:54.355: INFO: Pod "pod-configmaps-56b99043-2bf7-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00599628s
STEP: Saw pod success
Feb  8 23:14:54.355: INFO: Pod "pod-configmaps-56b99043-2bf7-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:14:54.358: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod pod-configmaps-56b99043-2bf7-11e9-a551-0a580a020303 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  8 23:14:54.377: INFO: Waiting for pod pod-configmaps-56b99043-2bf7-11e9-a551-0a580a020303 to disappear
Feb  8 23:14:54.380: INFO: Pod pod-configmaps-56b99043-2bf7-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:14:54.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-99s72" for this suite.
Feb  8 23:15:00.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:15:00.410: INFO: namespace: e2e-tests-configmap-99s72, resource: bindings, ignored listing per whitelist
Feb  8 23:15:00.472: INFO: namespace e2e-tests-configmap-99s72 deletion completed in 6.088298776s

• [SLOW TEST:8.184 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:15:00.472: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  8 23:15:00.553: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"5b9c568e-2bf7-11e9-a760-02d2eeadbd48", Controller:(*bool)(0xc422052a7e), BlockOwnerDeletion:(*bool)(0xc422052a7f)}}
Feb  8 23:15:00.561: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"5b9a78b7-2bf7-11e9-a760-02d2eeadbd48", Controller:(*bool)(0xc42260d49e), BlockOwnerDeletion:(*bool)(0xc42260d49f)}}
Feb  8 23:15:00.568: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"5b9b0722-2bf7-11e9-a760-02d2eeadbd48", Controller:(*bool)(0xc422052ce6), BlockOwnerDeletion:(*bool)(0xc422052ce7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:15:05.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-nflb5" for this suite.
Feb  8 23:15:11.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:15:11.602: INFO: namespace: e2e-tests-gc-nflb5, resource: bindings, ignored listing per whitelist
Feb  8 23:15:11.667: INFO: namespace e2e-tests-gc-nflb5 deletion completed in 6.086614109s

• [SLOW TEST:11.195 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:15:11.667: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-6246510e-2bf7-11e9-a551-0a580a020303
STEP: Creating a pod to test consume configMaps
Feb  8 23:15:11.731: INFO: Waiting up to 5m0s for pod "pod-configmaps-6246eefb-2bf7-11e9-a551-0a580a020303" in namespace "e2e-tests-configmap-hnhvk" to be "success or failure"
Feb  8 23:15:11.734: INFO: Pod "pod-configmaps-6246eefb-2bf7-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.741179ms
Feb  8 23:15:13.737: INFO: Pod "pod-configmaps-6246eefb-2bf7-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006425827s
STEP: Saw pod success
Feb  8 23:15:13.737: INFO: Pod "pod-configmaps-6246eefb-2bf7-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:15:13.740: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod pod-configmaps-6246eefb-2bf7-11e9-a551-0a580a020303 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  8 23:15:13.759: INFO: Waiting for pod pod-configmaps-6246eefb-2bf7-11e9-a551-0a580a020303 to disappear
Feb  8 23:15:13.761: INFO: Pod pod-configmaps-6246eefb-2bf7-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:15:13.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-hnhvk" for this suite.
Feb  8 23:15:19.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:15:19.789: INFO: namespace: e2e-tests-configmap-hnhvk, resource: bindings, ignored listing per whitelist
Feb  8 23:15:19.859: INFO: namespace e2e-tests-configmap-hnhvk deletion completed in 6.09417875s

• [SLOW TEST:8.192 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:15:19.859: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Feb  8 23:15:19.907: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 --namespace=e2e-tests-kubectl-ww58h run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb  8 23:15:21.961: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb  8 23:15:21.961: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:15:23.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ww58h" for this suite.
Feb  8 23:15:29.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:15:30.031: INFO: namespace: e2e-tests-kubectl-ww58h, resource: bindings, ignored listing per whitelist
Feb  8 23:15:30.061: INFO: namespace e2e-tests-kubectl-ww58h deletion completed in 6.086525828s

• [SLOW TEST:10.202 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:15:30.061: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb  8 23:15:34.158: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  8 23:15:34.161: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  8 23:15:36.161: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  8 23:15:36.165: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  8 23:15:38.161: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  8 23:15:38.164: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  8 23:15:40.161: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  8 23:15:40.165: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  8 23:15:42.161: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  8 23:15:42.165: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  8 23:15:44.161: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  8 23:15:44.164: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  8 23:15:46.161: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  8 23:15:46.165: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  8 23:15:48.161: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  8 23:15:48.164: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  8 23:15:50.161: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  8 23:15:50.164: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  8 23:15:52.161: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  8 23:15:52.165: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  8 23:15:54.161: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  8 23:15:54.164: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  8 23:15:56.161: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  8 23:15:56.164: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  8 23:15:58.161: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  8 23:15:58.164: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:15:58.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-2g6m4" for this suite.
Feb  8 23:16:20.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:16:20.225: INFO: namespace: e2e-tests-container-lifecycle-hook-2g6m4, resource: bindings, ignored listing per whitelist
Feb  8 23:16:20.253: INFO: namespace e2e-tests-container-lifecycle-hook-2g6m4 deletion completed in 22.085988479s

• [SLOW TEST:50.192 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:16:20.253: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-8b279f66-2bf7-11e9-a551-0a580a020303
STEP: Creating a pod to test consume configMaps
Feb  8 23:16:20.316: INFO: Waiting up to 5m0s for pod "pod-configmaps-8b283125-2bf7-11e9-a551-0a580a020303" in namespace "e2e-tests-configmap-s5hnv" to be "success or failure"
Feb  8 23:16:20.320: INFO: Pod "pod-configmaps-8b283125-2bf7-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 3.738224ms
Feb  8 23:16:22.323: INFO: Pod "pod-configmaps-8b283125-2bf7-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007173326s
STEP: Saw pod success
Feb  8 23:16:22.323: INFO: Pod "pod-configmaps-8b283125-2bf7-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:16:22.325: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod pod-configmaps-8b283125-2bf7-11e9-a551-0a580a020303 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  8 23:16:22.344: INFO: Waiting for pod pod-configmaps-8b283125-2bf7-11e9-a551-0a580a020303 to disappear
Feb  8 23:16:22.346: INFO: Pod pod-configmaps-8b283125-2bf7-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:16:22.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-s5hnv" for this suite.
Feb  8 23:16:28.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:16:28.430: INFO: namespace: e2e-tests-configmap-s5hnv, resource: bindings, ignored listing per whitelist
Feb  8 23:16:28.445: INFO: namespace e2e-tests-configmap-s5hnv deletion completed in 6.096100903s

• [SLOW TEST:8.192 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:16:28.445: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb  8 23:16:31.031: INFO: Successfully updated pod "annotationupdate900955ca-2bf7-11e9-a551-0a580a020303"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:16:33.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xk64w" for this suite.
Feb  8 23:16:55.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:16:55.075: INFO: namespace: e2e-tests-downward-api-xk64w, resource: bindings, ignored listing per whitelist
Feb  8 23:16:55.135: INFO: namespace e2e-tests-downward-api-xk64w deletion completed in 22.085925455s

• [SLOW TEST:26.689 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:16:55.135: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-zvkfk
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Feb  8 23:16:55.200: INFO: Found 0 stateful pods, waiting for 3
Feb  8 23:17:05.204: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  8 23:17:05.204: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  8 23:17:05.204: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb  8 23:17:05.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 exec --namespace=e2e-tests-statefulset-zvkfk ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  8 23:17:05.408: INFO: stderr: ""
Feb  8 23:17:05.408: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  8 23:17:05.408: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb  8 23:17:15.438: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb  8 23:17:25.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 exec --namespace=e2e-tests-statefulset-zvkfk ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  8 23:17:25.653: INFO: stderr: ""
Feb  8 23:17:25.653: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  8 23:17:25.653: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  8 23:17:35.671: INFO: Waiting for StatefulSet e2e-tests-statefulset-zvkfk/ss2 to complete update
Feb  8 23:17:35.671: INFO: Waiting for Pod e2e-tests-statefulset-zvkfk/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb  8 23:17:35.671: INFO: Waiting for Pod e2e-tests-statefulset-zvkfk/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb  8 23:17:35.671: INFO: Waiting for Pod e2e-tests-statefulset-zvkfk/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb  8 23:17:45.677: INFO: Waiting for StatefulSet e2e-tests-statefulset-zvkfk/ss2 to complete update
Feb  8 23:17:45.677: INFO: Waiting for Pod e2e-tests-statefulset-zvkfk/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb  8 23:17:45.677: INFO: Waiting for Pod e2e-tests-statefulset-zvkfk/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb  8 23:17:55.677: INFO: Waiting for StatefulSet e2e-tests-statefulset-zvkfk/ss2 to complete update
STEP: Rolling back to a previous revision
Feb  8 23:18:05.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 exec --namespace=e2e-tests-statefulset-zvkfk ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  8 23:18:05.862: INFO: stderr: ""
Feb  8 23:18:05.862: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  8 23:18:05.862: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  8 23:18:15.891: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb  8 23:18:25.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 exec --namespace=e2e-tests-statefulset-zvkfk ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  8 23:18:26.114: INFO: stderr: ""
Feb  8 23:18:26.114: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  8 23:18:26.114: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  8 23:18:46.131: INFO: Waiting for StatefulSet e2e-tests-statefulset-zvkfk/ss2 to complete update
Feb  8 23:18:46.131: INFO: Waiting for Pod e2e-tests-statefulset-zvkfk/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  8 23:18:56.137: INFO: Deleting all statefulset in ns e2e-tests-statefulset-zvkfk
Feb  8 23:18:56.140: INFO: Scaling statefulset ss2 to 0
Feb  8 23:19:06.152: INFO: Waiting for statefulset status.replicas updated to 0
Feb  8 23:19:06.155: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:19:06.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-zvkfk" for this suite.
Feb  8 23:19:12.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:19:12.217: INFO: namespace: e2e-tests-statefulset-zvkfk, resource: bindings, ignored listing per whitelist
Feb  8 23:19:12.255: INFO: namespace e2e-tests-statefulset-zvkfk deletion completed in 6.082915252s

• [SLOW TEST:137.120 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:19:12.255: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  8 23:19:12.317: INFO: Waiting up to 5m0s for pod "downward-api-f1ad339c-2bf7-11e9-a551-0a580a020303" in namespace "e2e-tests-downward-api-2rcnk" to be "success or failure"
Feb  8 23:19:12.321: INFO: Pod "downward-api-f1ad339c-2bf7-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 3.89439ms
Feb  8 23:19:14.324: INFO: Pod "downward-api-f1ad339c-2bf7-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007275663s
STEP: Saw pod success
Feb  8 23:19:14.324: INFO: Pod "downward-api-f1ad339c-2bf7-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:19:14.328: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod downward-api-f1ad339c-2bf7-11e9-a551-0a580a020303 container dapi-container: <nil>
STEP: delete the pod
Feb  8 23:19:14.362: INFO: Waiting for pod downward-api-f1ad339c-2bf7-11e9-a551-0a580a020303 to disappear
Feb  8 23:19:14.364: INFO: Pod downward-api-f1ad339c-2bf7-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:19:14.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2rcnk" for this suite.
Feb  8 23:19:20.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:19:20.426: INFO: namespace: e2e-tests-downward-api-2rcnk, resource: bindings, ignored listing per whitelist
Feb  8 23:19:20.454: INFO: namespace e2e-tests-downward-api-2rcnk deletion completed in 6.086350126s

• [SLOW TEST:8.199 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:19:20.454: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Feb  8 23:19:20.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 cluster-info'
Feb  8 23:19:20.580: INFO: stderr: ""
Feb  8 23:19:20.580: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.3.0.1:443\x1b[0m\n\x1b[0;32mHeapster\x1b[0m is running at \x1b[0;33mhttps://10.3.0.1:443/api/v1/namespaces/kube-system/services/heapster/proxy\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.3.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:19:20.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-k9nnl" for this suite.
Feb  8 23:19:26.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:19:26.617: INFO: namespace: e2e-tests-kubectl-k9nnl, resource: bindings, ignored listing per whitelist
Feb  8 23:19:26.670: INFO: namespace e2e-tests-kubectl-k9nnl deletion completed in 6.086602366s

• [SLOW TEST:6.216 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:19:26.670: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-fa449c46-2bf7-11e9-a551-0a580a020303
STEP: Creating a pod to test consume configMaps
Feb  8 23:19:26.732: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fa454f45-2bf7-11e9-a551-0a580a020303" in namespace "e2e-tests-projected-z86ch" to be "success or failure"
Feb  8 23:19:26.735: INFO: Pod "pod-projected-configmaps-fa454f45-2bf7-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.434248ms
Feb  8 23:19:28.738: INFO: Pod "pod-projected-configmaps-fa454f45-2bf7-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005532028s
STEP: Saw pod success
Feb  8 23:19:28.738: INFO: Pod "pod-projected-configmaps-fa454f45-2bf7-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:19:28.740: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod pod-projected-configmaps-fa454f45-2bf7-11e9-a551-0a580a020303 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  8 23:19:28.759: INFO: Waiting for pod pod-projected-configmaps-fa454f45-2bf7-11e9-a551-0a580a020303 to disappear
Feb  8 23:19:28.763: INFO: Pod pod-projected-configmaps-fa454f45-2bf7-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:19:28.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-z86ch" for this suite.
Feb  8 23:19:34.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:19:34.843: INFO: namespace: e2e-tests-projected-z86ch, resource: bindings, ignored listing per whitelist
Feb  8 23:19:34.850: INFO: namespace e2e-tests-projected-z86ch deletion completed in 6.083635079s

• [SLOW TEST:8.179 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:19:34.850: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  8 23:19:34.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-kh2jj'
Feb  8 23:19:34.983: INFO: stderr: ""
Feb  8 23:19:34.983: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Feb  8 23:19:40.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-kh2jj -o json'
Feb  8 23:19:40.110: INFO: stderr: ""
Feb  8 23:19:40.110: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-02-08T23:19:34Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-kh2jj\",\n        \"resourceVersion\": \"14058\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-kh2jj/pods/e2e-test-nginx-pod\",\n        \"uid\": \"ff2fc16f-2bf7-11e9-a760-02d2eeadbd48\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-xxn7s\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"ip-172-23-7-110.us-west-2.compute.internal\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-xxn7s\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-xxn7s\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-08T23:19:34Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-08T23:19:36Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-08T23:19:36Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-08T23:19:34Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://4f8fe72d68a92217c97b182979629d16c104337aac259404344584a6aad06806\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-02-08T23:19:35Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.23.7.110\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.2.1.135\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-02-08T23:19:34Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb  8 23:19:40.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 replace -f - --namespace=e2e-tests-kubectl-kh2jj'
Feb  8 23:19:40.263: INFO: stderr: ""
Feb  8 23:19:40.263: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Feb  8 23:19:40.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-kh2jj'
Feb  8 23:19:42.723: INFO: stderr: ""
Feb  8 23:19:42.723: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:19:42.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kh2jj" for this suite.
Feb  8 23:19:48.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:19:48.748: INFO: namespace: e2e-tests-kubectl-kh2jj, resource: bindings, ignored listing per whitelist
Feb  8 23:19:48.816: INFO: namespace e2e-tests-kubectl-kh2jj deletion completed in 6.089057016s

• [SLOW TEST:13.967 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:19:48.816: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-bvg94
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-bvg94
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-bvg94
Feb  8 23:19:48.885: INFO: Found 0 stateful pods, waiting for 1
Feb  8 23:19:58.888: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb  8 23:19:58.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 exec --namespace=e2e-tests-statefulset-bvg94 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  8 23:19:59.093: INFO: stderr: ""
Feb  8 23:19:59.093: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  8 23:19:59.093: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  8 23:19:59.096: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb  8 23:20:09.099: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  8 23:20:09.099: INFO: Waiting for statefulset status.replicas updated to 0
Feb  8 23:20:09.111: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Feb  8 23:20:09.111: INFO: ss-0  ip-172-23-7-130.us-west-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:19:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:19:48 +0000 UTC  }]
Feb  8 23:20:09.111: INFO: 
Feb  8 23:20:09.111: INFO: StatefulSet ss has not reached scale 3, at 1
Feb  8 23:20:10.114: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996988439s
Feb  8 23:20:11.118: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993789246s
Feb  8 23:20:12.122: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.990231519s
Feb  8 23:20:13.125: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.986534592s
Feb  8 23:20:14.129: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.982711026s
Feb  8 23:20:15.133: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.978678496s
Feb  8 23:20:16.137: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.974977085s
Feb  8 23:20:17.141: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.971428823s
Feb  8 23:20:18.144: INFO: Verifying statefulset ss doesn't scale past 3 for another 967.633703ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-bvg94
Feb  8 23:20:19.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 exec --namespace=e2e-tests-statefulset-bvg94 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  8 23:20:19.346: INFO: stderr: ""
Feb  8 23:20:19.346: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  8 23:20:19.346: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  8 23:20:19.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 exec --namespace=e2e-tests-statefulset-bvg94 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  8 23:20:19.526: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb  8 23:20:19.526: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  8 23:20:19.526: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  8 23:20:19.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 exec --namespace=e2e-tests-statefulset-bvg94 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  8 23:20:19.714: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb  8 23:20:19.714: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  8 23:20:19.714: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  8 23:20:19.717: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Feb  8 23:20:29.721: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  8 23:20:29.721: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  8 23:20:29.721: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb  8 23:20:29.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 exec --namespace=e2e-tests-statefulset-bvg94 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  8 23:20:29.923: INFO: stderr: ""
Feb  8 23:20:29.923: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  8 23:20:29.923: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  8 23:20:29.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 exec --namespace=e2e-tests-statefulset-bvg94 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  8 23:20:30.125: INFO: stderr: ""
Feb  8 23:20:30.125: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  8 23:20:30.125: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  8 23:20:30.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 exec --namespace=e2e-tests-statefulset-bvg94 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  8 23:20:30.315: INFO: stderr: ""
Feb  8 23:20:30.315: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  8 23:20:30.315: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  8 23:20:30.315: INFO: Waiting for statefulset status.replicas updated to 0
Feb  8 23:20:30.318: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb  8 23:20:40.324: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  8 23:20:40.324: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb  8 23:20:40.324: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb  8 23:20:40.334: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Feb  8 23:20:40.334: INFO: ss-0  ip-172-23-7-130.us-west-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:19:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:20:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:20:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:19:48 +0000 UTC  }]
Feb  8 23:20:40.334: INFO: ss-1  ip-172-23-7-110.us-west-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:20:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:20:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:20:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:20:09 +0000 UTC  }]
Feb  8 23:20:40.334: INFO: ss-2  ip-172-23-7-34.us-west-2.compute.internal   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:20:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:20:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:20:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:20:09 +0000 UTC  }]
Feb  8 23:20:40.334: INFO: 
Feb  8 23:20:40.334: INFO: StatefulSet ss has not reached scale 0, at 3
Feb  8 23:20:41.338: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Feb  8 23:20:41.338: INFO: ss-0  ip-172-23-7-130.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:19:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:20:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:20:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:19:48 +0000 UTC  }]
Feb  8 23:20:41.338: INFO: ss-1  ip-172-23-7-110.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:20:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:20:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:20:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:20:09 +0000 UTC  }]
Feb  8 23:20:41.338: INFO: ss-2  ip-172-23-7-34.us-west-2.compute.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:20:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:20:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:20:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:20:09 +0000 UTC  }]
Feb  8 23:20:41.338: INFO: 
Feb  8 23:20:41.338: INFO: StatefulSet ss has not reached scale 0, at 3
Feb  8 23:20:42.341: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.993450771s
Feb  8 23:20:43.345: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.989762962s
Feb  8 23:20:44.349: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.986170083s
Feb  8 23:20:45.352: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.982403747s
Feb  8 23:20:46.356: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.978955108s
Feb  8 23:20:47.360: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.975211878s
Feb  8 23:20:48.363: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.971582428s
Feb  8 23:20:49.367: INFO: Verifying statefulset ss doesn't scale past 0 for another 967.9979ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-bvg94
Feb  8 23:20:50.370: INFO: Scaling statefulset ss to 0
Feb  8 23:20:50.378: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  8 23:20:50.380: INFO: Deleting all statefulset in ns e2e-tests-statefulset-bvg94
Feb  8 23:20:50.382: INFO: Scaling statefulset ss to 0
Feb  8 23:20:50.390: INFO: Waiting for statefulset status.replicas updated to 0
Feb  8 23:20:50.392: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:20:50.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-bvg94" for this suite.
Feb  8 23:20:56.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:20:56.471: INFO: namespace: e2e-tests-statefulset-bvg94, resource: bindings, ignored listing per whitelist
Feb  8 23:20:56.492: INFO: namespace e2e-tests-statefulset-bvg94 deletion completed in 6.084494627s

• [SLOW TEST:67.675 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:20:56.492: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-2fcf2c4b-2bf8-11e9-a551-0a580a020303
STEP: Creating a pod to test consume secrets
Feb  8 23:20:56.566: INFO: Waiting up to 5m0s for pod "pod-secrets-2fd05a99-2bf8-11e9-a551-0a580a020303" in namespace "e2e-tests-secrets-57qnx" to be "success or failure"
Feb  8 23:20:56.571: INFO: Pod "pod-secrets-2fd05a99-2bf8-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 5.022641ms
Feb  8 23:20:58.574: INFO: Pod "pod-secrets-2fd05a99-2bf8-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008364267s
STEP: Saw pod success
Feb  8 23:20:58.574: INFO: Pod "pod-secrets-2fd05a99-2bf8-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:20:58.577: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod pod-secrets-2fd05a99-2bf8-11e9-a551-0a580a020303 container secret-volume-test: <nil>
STEP: delete the pod
Feb  8 23:20:58.599: INFO: Waiting for pod pod-secrets-2fd05a99-2bf8-11e9-a551-0a580a020303 to disappear
Feb  8 23:20:58.601: INFO: Pod pod-secrets-2fd05a99-2bf8-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:20:58.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-57qnx" for this suite.
Feb  8 23:21:04.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:21:04.629: INFO: namespace: e2e-tests-secrets-57qnx, resource: bindings, ignored listing per whitelist
Feb  8 23:21:04.690: INFO: namespace e2e-tests-secrets-57qnx deletion completed in 6.085506165s

• [SLOW TEST:8.198 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:21:04.690: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-34b074f2-2bf8-11e9-a551-0a580a020303
STEP: Creating a pod to test consume secrets
Feb  8 23:21:04.747: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-34b0f5b5-2bf8-11e9-a551-0a580a020303" in namespace "e2e-tests-projected-2zttg" to be "success or failure"
Feb  8 23:21:04.750: INFO: Pod "pod-projected-secrets-34b0f5b5-2bf8-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.599185ms
Feb  8 23:21:06.753: INFO: Pod "pod-projected-secrets-34b0f5b5-2bf8-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006288384s
STEP: Saw pod success
Feb  8 23:21:06.753: INFO: Pod "pod-projected-secrets-34b0f5b5-2bf8-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:21:06.756: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod pod-projected-secrets-34b0f5b5-2bf8-11e9-a551-0a580a020303 container secret-volume-test: <nil>
STEP: delete the pod
Feb  8 23:21:06.776: INFO: Waiting for pod pod-projected-secrets-34b0f5b5-2bf8-11e9-a551-0a580a020303 to disappear
Feb  8 23:21:06.778: INFO: Pod pod-projected-secrets-34b0f5b5-2bf8-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:21:06.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2zttg" for this suite.
Feb  8 23:21:12.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:21:12.858: INFO: namespace: e2e-tests-projected-2zttg, resource: bindings, ignored listing per whitelist
Feb  8 23:21:12.871: INFO: namespace e2e-tests-projected-2zttg deletion completed in 6.089711325s

• [SLOW TEST:8.181 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:21:12.871: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:22:12.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-cbjnd" for this suite.
Feb  8 23:22:34.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:22:34.990: INFO: namespace: e2e-tests-container-probe-cbjnd, resource: bindings, ignored listing per whitelist
Feb  8 23:22:35.024: INFO: namespace e2e-tests-container-probe-cbjnd deletion completed in 22.086737952s

• [SLOW TEST:82.152 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:22:35.024: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb  8 23:22:35.083: INFO: Waiting up to 5m0s for pod "pod-6a893d35-2bf8-11e9-a551-0a580a020303" in namespace "e2e-tests-emptydir-9s44h" to be "success or failure"
Feb  8 23:22:35.085: INFO: Pod "pod-6a893d35-2bf8-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.192793ms
Feb  8 23:22:37.089: INFO: Pod "pod-6a893d35-2bf8-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005599786s
STEP: Saw pod success
Feb  8 23:22:37.089: INFO: Pod "pod-6a893d35-2bf8-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:22:37.091: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod pod-6a893d35-2bf8-11e9-a551-0a580a020303 container test-container: <nil>
STEP: delete the pod
Feb  8 23:22:37.109: INFO: Waiting for pod pod-6a893d35-2bf8-11e9-a551-0a580a020303 to disappear
Feb  8 23:22:37.111: INFO: Pod pod-6a893d35-2bf8-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:22:37.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-9s44h" for this suite.
Feb  8 23:22:43.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:22:43.133: INFO: namespace: e2e-tests-emptydir-9s44h, resource: bindings, ignored listing per whitelist
Feb  8 23:22:43.200: INFO: namespace e2e-tests-emptydir-9s44h deletion completed in 6.08596808s

• [SLOW TEST:8.176 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:22:43.200: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-6f67f6b2-2bf8-11e9-a551-0a580a020303
STEP: Creating a pod to test consume configMaps
Feb  8 23:22:43.257: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6f68713c-2bf8-11e9-a551-0a580a020303" in namespace "e2e-tests-projected-q6stt" to be "success or failure"
Feb  8 23:22:43.263: INFO: Pod "pod-projected-configmaps-6f68713c-2bf8-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 5.338242ms
Feb  8 23:22:45.266: INFO: Pod "pod-projected-configmaps-6f68713c-2bf8-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008855259s
STEP: Saw pod success
Feb  8 23:22:45.266: INFO: Pod "pod-projected-configmaps-6f68713c-2bf8-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:22:45.268: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod pod-projected-configmaps-6f68713c-2bf8-11e9-a551-0a580a020303 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  8 23:22:45.296: INFO: Waiting for pod pod-projected-configmaps-6f68713c-2bf8-11e9-a551-0a580a020303 to disappear
Feb  8 23:22:45.299: INFO: Pod pod-projected-configmaps-6f68713c-2bf8-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:22:45.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-q6stt" for this suite.
Feb  8 23:22:51.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:22:51.367: INFO: namespace: e2e-tests-projected-q6stt, resource: bindings, ignored listing per whitelist
Feb  8 23:22:51.388: INFO: namespace e2e-tests-projected-q6stt deletion completed in 6.086092486s

• [SLOW TEST:8.188 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:22:51.388: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-744a2f80-2bf8-11e9-a551-0a580a020303
STEP: Creating a pod to test consume configMaps
Feb  8 23:22:51.451: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-744ab42e-2bf8-11e9-a551-0a580a020303" in namespace "e2e-tests-projected-zjj6x" to be "success or failure"
Feb  8 23:22:51.455: INFO: Pod "pod-projected-configmaps-744ab42e-2bf8-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 4.429305ms
Feb  8 23:22:53.459: INFO: Pod "pod-projected-configmaps-744ab42e-2bf8-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008225327s
STEP: Saw pod success
Feb  8 23:22:53.459: INFO: Pod "pod-projected-configmaps-744ab42e-2bf8-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:22:53.462: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod pod-projected-configmaps-744ab42e-2bf8-11e9-a551-0a580a020303 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  8 23:22:53.481: INFO: Waiting for pod pod-projected-configmaps-744ab42e-2bf8-11e9-a551-0a580a020303 to disappear
Feb  8 23:22:53.484: INFO: Pod pod-projected-configmaps-744ab42e-2bf8-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:22:53.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zjj6x" for this suite.
Feb  8 23:22:59.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:22:59.521: INFO: namespace: e2e-tests-projected-zjj6x, resource: bindings, ignored listing per whitelist
Feb  8 23:22:59.574: INFO: namespace e2e-tests-projected-zjj6x deletion completed in 6.086748047s

• [SLOW TEST:8.186 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:22:59.574: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb  8 23:23:02.151: INFO: Successfully updated pod "labelsupdate792a725c-2bf8-11e9-a551-0a580a020303"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:23:04.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7tnv8" for this suite.
Feb  8 23:23:26.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:23:26.245: INFO: namespace: e2e-tests-downward-api-7tnv8, resource: bindings, ignored listing per whitelist
Feb  8 23:23:26.256: INFO: namespace e2e-tests-downward-api-7tnv8 deletion completed in 22.086065497s

• [SLOW TEST:26.682 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:23:26.256: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-8912add0-2bf8-11e9-a551-0a580a020303
STEP: Creating a pod to test consume secrets
Feb  8 23:23:26.319: INFO: Waiting up to 5m0s for pod "pod-secrets-89133139-2bf8-11e9-a551-0a580a020303" in namespace "e2e-tests-secrets-lg4gd" to be "success or failure"
Feb  8 23:23:26.325: INFO: Pod "pod-secrets-89133139-2bf8-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 5.389363ms
Feb  8 23:23:28.328: INFO: Pod "pod-secrets-89133139-2bf8-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008720753s
STEP: Saw pod success
Feb  8 23:23:28.328: INFO: Pod "pod-secrets-89133139-2bf8-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:23:28.330: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod pod-secrets-89133139-2bf8-11e9-a551-0a580a020303 container secret-volume-test: <nil>
STEP: delete the pod
Feb  8 23:23:28.348: INFO: Waiting for pod pod-secrets-89133139-2bf8-11e9-a551-0a580a020303 to disappear
Feb  8 23:23:28.351: INFO: Pod pod-secrets-89133139-2bf8-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:23:28.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-lg4gd" for this suite.
Feb  8 23:23:34.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:23:34.396: INFO: namespace: e2e-tests-secrets-lg4gd, resource: bindings, ignored listing per whitelist
Feb  8 23:23:34.441: INFO: namespace e2e-tests-secrets-lg4gd deletion completed in 6.086716117s

• [SLOW TEST:8.185 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:23:34.441: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-rgfjn
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  8 23:23:34.490: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  8 23:23:52.571: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.1.142:8080/dial?request=hostName&protocol=http&host=10.2.2.108&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-rgfjn PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  8 23:23:52.571: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
Feb  8 23:23:52.701: INFO: Waiting for endpoints: map[]
Feb  8 23:23:52.704: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.1.142:8080/dial?request=hostName&protocol=http&host=10.2.3.28&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-rgfjn PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  8 23:23:52.704: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
Feb  8 23:23:52.840: INFO: Waiting for endpoints: map[]
Feb  8 23:23:52.843: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.1.142:8080/dial?request=hostName&protocol=http&host=10.2.1.141&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-rgfjn PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  8 23:23:52.843: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
Feb  8 23:23:52.986: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:23:52.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-rgfjn" for this suite.
Feb  8 23:24:15.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:24:15.069: INFO: namespace: e2e-tests-pod-network-test-rgfjn, resource: bindings, ignored listing per whitelist
Feb  8 23:24:15.077: INFO: namespace e2e-tests-pod-network-test-rgfjn deletion completed in 22.087010082s

• [SLOW TEST:40.636 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:24:15.077: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:24:21.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-kcntt" for this suite.
Feb  8 23:24:27.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:24:27.254: INFO: namespace: e2e-tests-namespaces-kcntt, resource: bindings, ignored listing per whitelist
Feb  8 23:24:27.293: INFO: namespace e2e-tests-namespaces-kcntt deletion completed in 6.088976276s
STEP: Destroying namespace "e2e-tests-nsdeletetest-jgbtk" for this suite.
Feb  8 23:24:27.295: INFO: Namespace e2e-tests-nsdeletetest-jgbtk was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-v6q2j" for this suite.
Feb  8 23:24:33.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:24:33.356: INFO: namespace: e2e-tests-nsdeletetest-v6q2j, resource: bindings, ignored listing per whitelist
Feb  8 23:24:33.383: INFO: namespace e2e-tests-nsdeletetest-v6q2j deletion completed in 6.08796333s

• [SLOW TEST:18.306 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:24:33.383: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  8 23:24:33.444: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b1156659-2bf8-11e9-a551-0a580a020303" in namespace "e2e-tests-downward-api-kclcn" to be "success or failure"
Feb  8 23:24:33.448: INFO: Pod "downwardapi-volume-b1156659-2bf8-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 4.388301ms
Feb  8 23:24:35.452: INFO: Pod "downwardapi-volume-b1156659-2bf8-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008130682s
STEP: Saw pod success
Feb  8 23:24:35.452: INFO: Pod "downwardapi-volume-b1156659-2bf8-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:24:35.454: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod downwardapi-volume-b1156659-2bf8-11e9-a551-0a580a020303 container client-container: <nil>
STEP: delete the pod
Feb  8 23:24:35.473: INFO: Waiting for pod downwardapi-volume-b1156659-2bf8-11e9-a551-0a580a020303 to disappear
Feb  8 23:24:35.477: INFO: Pod downwardapi-volume-b1156659-2bf8-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:24:35.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kclcn" for this suite.
Feb  8 23:24:41.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:24:41.535: INFO: namespace: e2e-tests-downward-api-kclcn, resource: bindings, ignored listing per whitelist
Feb  8 23:24:41.568: INFO: namespace e2e-tests-downward-api-kclcn deletion completed in 6.088235622s

• [SLOW TEST:8.185 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:24:41.568: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Feb  8 23:24:43.659: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:25:07.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-mn5rj" for this suite.
Feb  8 23:25:13.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:25:13.758: INFO: namespace: e2e-tests-namespaces-mn5rj, resource: bindings, ignored listing per whitelist
Feb  8 23:25:13.794: INFO: namespace e2e-tests-namespaces-mn5rj deletion completed in 6.086549038s
STEP: Destroying namespace "e2e-tests-nsdeletetest-c8vsf" for this suite.
Feb  8 23:25:13.796: INFO: Namespace e2e-tests-nsdeletetest-c8vsf was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-flhvn" for this suite.
Feb  8 23:25:19.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:25:19.874: INFO: namespace: e2e-tests-nsdeletetest-flhvn, resource: bindings, ignored listing per whitelist
Feb  8 23:25:19.883: INFO: namespace e2e-tests-nsdeletetest-flhvn deletion completed in 6.087363084s

• [SLOW TEST:38.315 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:25:19.883: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  8 23:25:19.943: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ccccd7ba-2bf8-11e9-a551-0a580a020303" in namespace "e2e-tests-projected-fch5q" to be "success or failure"
Feb  8 23:25:19.949: INFO: Pod "downwardapi-volume-ccccd7ba-2bf8-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 5.888537ms
Feb  8 23:25:21.953: INFO: Pod "downwardapi-volume-ccccd7ba-2bf8-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009674401s
STEP: Saw pod success
Feb  8 23:25:21.953: INFO: Pod "downwardapi-volume-ccccd7ba-2bf8-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:25:21.955: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod downwardapi-volume-ccccd7ba-2bf8-11e9-a551-0a580a020303 container client-container: <nil>
STEP: delete the pod
Feb  8 23:25:21.974: INFO: Waiting for pod downwardapi-volume-ccccd7ba-2bf8-11e9-a551-0a580a020303 to disappear
Feb  8 23:25:21.977: INFO: Pod downwardapi-volume-ccccd7ba-2bf8-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:25:21.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fch5q" for this suite.
Feb  8 23:25:27.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:25:28.053: INFO: namespace: e2e-tests-projected-fch5q, resource: bindings, ignored listing per whitelist
Feb  8 23:25:28.067: INFO: namespace e2e-tests-projected-fch5q deletion completed in 6.08574357s

• [SLOW TEST:8.183 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:25:28.067: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Feb  8 23:25:28.123: INFO: Waiting up to 5m0s for pod "client-containers-d1ad058b-2bf8-11e9-a551-0a580a020303" in namespace "e2e-tests-containers-gfxfv" to be "success or failure"
Feb  8 23:25:28.128: INFO: Pod "client-containers-d1ad058b-2bf8-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 4.408149ms
Feb  8 23:25:30.131: INFO: Pod "client-containers-d1ad058b-2bf8-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007957311s
STEP: Saw pod success
Feb  8 23:25:30.131: INFO: Pod "client-containers-d1ad058b-2bf8-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:25:30.134: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod client-containers-d1ad058b-2bf8-11e9-a551-0a580a020303 container test-container: <nil>
STEP: delete the pod
Feb  8 23:25:30.157: INFO: Waiting for pod client-containers-d1ad058b-2bf8-11e9-a551-0a580a020303 to disappear
Feb  8 23:25:30.160: INFO: Pod client-containers-d1ad058b-2bf8-11e9-a551-0a580a020303 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:25:30.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-gfxfv" for this suite.
Feb  8 23:25:36.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:25:36.182: INFO: namespace: e2e-tests-containers-gfxfv, resource: bindings, ignored listing per whitelist
Feb  8 23:25:36.253: INFO: namespace e2e-tests-containers-gfxfv deletion completed in 6.089033387s

• [SLOW TEST:8.186 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:25:36.253: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-fwhx
STEP: Creating a pod to test atomic-volume-subpath
Feb  8 23:25:36.336: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-fwhx" in namespace "e2e-tests-subpath-qb65m" to be "success or failure"
Feb  8 23:25:36.339: INFO: Pod "pod-subpath-test-secret-fwhx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.432394ms
Feb  8 23:25:38.342: INFO: Pod "pod-subpath-test-secret-fwhx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005941472s
Feb  8 23:25:40.346: INFO: Pod "pod-subpath-test-secret-fwhx": Phase="Running", Reason="", readiness=false. Elapsed: 4.009325741s
Feb  8 23:25:42.350: INFO: Pod "pod-subpath-test-secret-fwhx": Phase="Running", Reason="", readiness=false. Elapsed: 6.013251979s
Feb  8 23:25:44.353: INFO: Pod "pod-subpath-test-secret-fwhx": Phase="Running", Reason="", readiness=false. Elapsed: 8.016928666s
Feb  8 23:25:46.357: INFO: Pod "pod-subpath-test-secret-fwhx": Phase="Running", Reason="", readiness=false. Elapsed: 10.020408047s
Feb  8 23:25:48.362: INFO: Pod "pod-subpath-test-secret-fwhx": Phase="Running", Reason="", readiness=false. Elapsed: 12.025543134s
Feb  8 23:25:50.365: INFO: Pod "pod-subpath-test-secret-fwhx": Phase="Running", Reason="", readiness=false. Elapsed: 14.028689883s
Feb  8 23:25:52.368: INFO: Pod "pod-subpath-test-secret-fwhx": Phase="Running", Reason="", readiness=false. Elapsed: 16.032171625s
Feb  8 23:25:54.372: INFO: Pod "pod-subpath-test-secret-fwhx": Phase="Running", Reason="", readiness=false. Elapsed: 18.035513822s
Feb  8 23:25:56.375: INFO: Pod "pod-subpath-test-secret-fwhx": Phase="Running", Reason="", readiness=false. Elapsed: 20.039031541s
Feb  8 23:25:58.379: INFO: Pod "pod-subpath-test-secret-fwhx": Phase="Running", Reason="", readiness=false. Elapsed: 22.042758219s
Feb  8 23:26:00.382: INFO: Pod "pod-subpath-test-secret-fwhx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.04595143s
STEP: Saw pod success
Feb  8 23:26:00.382: INFO: Pod "pod-subpath-test-secret-fwhx" satisfied condition "success or failure"
Feb  8 23:26:00.385: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod pod-subpath-test-secret-fwhx container test-container-subpath-secret-fwhx: <nil>
STEP: delete the pod
Feb  8 23:26:00.405: INFO: Waiting for pod pod-subpath-test-secret-fwhx to disappear
Feb  8 23:26:00.407: INFO: Pod pod-subpath-test-secret-fwhx no longer exists
STEP: Deleting pod pod-subpath-test-secret-fwhx
Feb  8 23:26:00.407: INFO: Deleting pod "pod-subpath-test-secret-fwhx" in namespace "e2e-tests-subpath-qb65m"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:26:00.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-qb65m" for this suite.
Feb  8 23:26:06.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:26:06.429: INFO: namespace: e2e-tests-subpath-qb65m, resource: bindings, ignored listing per whitelist
Feb  8 23:26:06.498: INFO: namespace e2e-tests-subpath-qb65m deletion completed in 6.085349369s

• [SLOW TEST:30.245 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:26:06.498: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  8 23:26:06.551: INFO: Creating ReplicaSet my-hostname-basic-e8959077-2bf8-11e9-a551-0a580a020303
Feb  8 23:26:06.558: INFO: Pod name my-hostname-basic-e8959077-2bf8-11e9-a551-0a580a020303: Found 0 pods out of 1
Feb  8 23:26:11.561: INFO: Pod name my-hostname-basic-e8959077-2bf8-11e9-a551-0a580a020303: Found 1 pods out of 1
Feb  8 23:26:11.561: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-e8959077-2bf8-11e9-a551-0a580a020303" is running
Feb  8 23:26:11.564: INFO: Pod "my-hostname-basic-e8959077-2bf8-11e9-a551-0a580a020303-rssjr" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-08 23:26:06 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-08 23:26:08 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-08 23:26:08 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-08 23:26:06 +0000 UTC Reason: Message:}])
Feb  8 23:26:11.564: INFO: Trying to dial the pod
Feb  8 23:26:16.575: INFO: Controller my-hostname-basic-e8959077-2bf8-11e9-a551-0a580a020303: Got expected result from replica 1 [my-hostname-basic-e8959077-2bf8-11e9-a551-0a580a020303-rssjr]: "my-hostname-basic-e8959077-2bf8-11e9-a551-0a580a020303-rssjr", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:26:16.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-ddnnf" for this suite.
Feb  8 23:26:22.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:26:22.610: INFO: namespace: e2e-tests-replicaset-ddnnf, resource: bindings, ignored listing per whitelist
Feb  8 23:26:22.674: INFO: namespace e2e-tests-replicaset-ddnnf deletion completed in 6.095985523s

• [SLOW TEST:16.176 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:26:22.674: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  8 23:26:22.728: INFO: Creating deployment "nginx-deployment"
Feb  8 23:26:22.731: INFO: Waiting for observed generation 1
Feb  8 23:26:24.738: INFO: Waiting for all required pods to come up
Feb  8 23:26:24.741: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb  8 23:26:26.751: INFO: Waiting for deployment "nginx-deployment" to complete
Feb  8 23:26:26.757: INFO: Updating deployment "nginx-deployment" with a non-existent image
Feb  8 23:26:26.763: INFO: Updating deployment nginx-deployment
Feb  8 23:26:26.763: INFO: Waiting for observed generation 2
Feb  8 23:26:28.769: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb  8 23:26:28.771: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb  8 23:26:28.773: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb  8 23:26:28.779: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb  8 23:26:28.779: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb  8 23:26:28.781: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb  8 23:26:28.785: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Feb  8 23:26:28.785: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Feb  8 23:26:28.793: INFO: Updating deployment nginx-deployment
Feb  8 23:26:28.793: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Feb  8 23:26:28.799: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb  8 23:26:28.804: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  8 23:26:28.823: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-xg2p6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xg2p6/deployments/nginx-deployment,UID:f23a6f69-2bf8-11e9-a760-02d2eeadbd48,ResourceVersion:15663,Generation:3,CreationTimestamp:2019-02-08 23:26:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Progressing True 2019-02-08 23:26:26 +0000 UTC 2019-02-08 23:26:22 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.} {Available False 2019-02-08 23:26:28 +0000 UTC 2019-02-08 23:26:28 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Feb  8 23:26:28.827: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-xg2p6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xg2p6/replicasets/nginx-deployment-7dc8f79789,UID:f4a24bdb-2bf8-11e9-a760-02d2eeadbd48,ResourceVersion:15658,Generation:3,CreationTimestamp:2019-02-08 23:26:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment f23a6f69-2bf8-11e9-a760-02d2eeadbd48 0xc421b23da7 0xc421b23da8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  8 23:26:28.827: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Feb  8 23:26:28.827: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-xg2p6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xg2p6/replicasets/nginx-deployment-7f9675fb8b,UID:f23bb9dd-2bf8-11e9-a760-02d2eeadbd48,ResourceVersion:15655,Generation:3,CreationTimestamp:2019-02-08 23:26:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment f23a6f69-2bf8-11e9-a760-02d2eeadbd48 0xc420b40277 0xc420b40278}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Feb  8 23:26:28.846: INFO: Pod "nginx-deployment-7dc8f79789-4f9nr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-4f9nr,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-xg2p6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xg2p6/pods/nginx-deployment-7dc8f79789-4f9nr,UID:f4a43637-2bf8-11e9-a760-02d2eeadbd48,ResourceVersion:15648,Generation:0,CreationTimestamp:2019-02-08 23:26:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f4a24bdb-2bf8-11e9-a760-02d2eeadbd48 0xc420b415c7 0xc420b415c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-d6thh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d6thh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d6thh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-23-7-34.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420b41640} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420b41660}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:26 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.34,PodIP:10.2.3.32,StartTime:2019-02-08 23:26:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  8 23:26:28.846: INFO: Pod "nginx-deployment-7dc8f79789-69nd9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-69nd9,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-xg2p6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xg2p6/pods/nginx-deployment-7dc8f79789-69nd9,UID:f4aac4a2-2bf8-11e9-a760-02d2eeadbd48,ResourceVersion:15632,Generation:0,CreationTimestamp:2019-02-08 23:26:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f4a24bdb-2bf8-11e9-a760-02d2eeadbd48 0xc420b41760 0xc420b41761}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-d6thh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d6thh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d6thh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-23-7-130.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420b417d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420b417f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:26 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.130,PodIP:,StartTime:2019-02-08 23:26:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  8 23:26:28.846: INFO: Pod "nginx-deployment-7dc8f79789-7cb5d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-7cb5d,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-xg2p6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xg2p6/pods/nginx-deployment-7dc8f79789-7cb5d,UID:f4a41fbe-2bf8-11e9-a760-02d2eeadbd48,ResourceVersion:15615,Generation:0,CreationTimestamp:2019-02-08 23:26:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f4a24bdb-2bf8-11e9-a760-02d2eeadbd48 0xc420b418b0 0xc420b418b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-d6thh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d6thh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d6thh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-23-7-110.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420b41920} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420b41940}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:26 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.110,PodIP:,StartTime:2019-02-08 23:26:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  8 23:26:28.846: INFO: Pod "nginx-deployment-7dc8f79789-b5wc7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-b5wc7,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-xg2p6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xg2p6/pods/nginx-deployment-7dc8f79789-b5wc7,UID:f5dc6970-2bf8-11e9-a760-02d2eeadbd48,ResourceVersion:15675,Generation:0,CreationTimestamp:2019-02-08 23:26:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f4a24bdb-2bf8-11e9-a760-02d2eeadbd48 0xc420b41a00 0xc420b41a01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-d6thh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d6thh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d6thh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420b41a70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420b41a90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  8 23:26:28.846: INFO: Pod "nginx-deployment-7dc8f79789-bxgq4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-bxgq4,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-xg2p6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xg2p6/pods/nginx-deployment-7dc8f79789-bxgq4,UID:f4a2e41b-2bf8-11e9-a760-02d2eeadbd48,ResourceVersion:15609,Generation:0,CreationTimestamp:2019-02-08 23:26:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f4a24bdb-2bf8-11e9-a760-02d2eeadbd48 0xc420b41ae7 0xc420b41ae8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-d6thh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d6thh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d6thh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-23-7-130.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420b41c50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420b41c80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:26 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.130,PodIP:,StartTime:2019-02-08 23:26:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  8 23:26:28.846: INFO: Pod "nginx-deployment-7dc8f79789-jrjn7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-jrjn7,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-xg2p6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xg2p6/pods/nginx-deployment-7dc8f79789-jrjn7,UID:f4ad50b2-2bf8-11e9-a760-02d2eeadbd48,ResourceVersion:15634,Generation:0,CreationTimestamp:2019-02-08 23:26:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f4a24bdb-2bf8-11e9-a760-02d2eeadbd48 0xc420b41d50 0xc420b41d51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-d6thh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d6thh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d6thh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-23-7-110.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420b41dc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420b41de0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:26 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.110,PodIP:,StartTime:2019-02-08 23:26:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  8 23:26:28.847: INFO: Pod "nginx-deployment-7dc8f79789-mx56q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-mx56q,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-xg2p6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xg2p6/pods/nginx-deployment-7dc8f79789-mx56q,UID:f5dc61af-2bf8-11e9-a760-02d2eeadbd48,ResourceVersion:15672,Generation:0,CreationTimestamp:2019-02-08 23:26:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f4a24bdb-2bf8-11e9-a760-02d2eeadbd48 0xc420b41ea0 0xc420b41ea1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-d6thh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d6thh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d6thh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420b41f10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420b41f30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  8 23:26:28.847: INFO: Pod "nginx-deployment-7dc8f79789-r8nv5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-r8nv5,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-xg2p6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xg2p6/pods/nginx-deployment-7dc8f79789-r8nv5,UID:f5da3007-2bf8-11e9-a760-02d2eeadbd48,ResourceVersion:15670,Generation:0,CreationTimestamp:2019-02-08 23:26:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f4a24bdb-2bf8-11e9-a760-02d2eeadbd48 0xc420b41f97 0xc420b41f98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-d6thh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d6thh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-d6thh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-23-7-34.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4210220f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421022110}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:28 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  8 23:26:28.847: INFO: Pod "nginx-deployment-7f9675fb8b-2sqs6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-2sqs6,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-xg2p6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xg2p6/pods/nginx-deployment-7f9675fb8b-2sqs6,UID:f2422828-2bf8-11e9-a760-02d2eeadbd48,ResourceVersion:15567,Generation:0,CreationTimestamp:2019-02-08 23:26:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f23bb9dd-2bf8-11e9-a760-02d2eeadbd48 0xc421022210 0xc421022211}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-d6thh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d6thh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d6thh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-23-7-110.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4210222f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421022310}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:22 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.110,PodIP:10.2.1.150,StartTime:2019-02-08 23:26:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-08 23:26:24 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://0a9f1af608cd3a1315c7d00fcf0d2e3759f38b74ab8bf923a5cc958abec77c22}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  8 23:26:28.847: INFO: Pod "nginx-deployment-7f9675fb8b-5b6fm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-5b6fm,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-xg2p6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xg2p6/pods/nginx-deployment-7f9675fb8b-5b6fm,UID:f5dc3d32-2bf8-11e9-a760-02d2eeadbd48,ResourceVersion:15673,Generation:0,CreationTimestamp:2019-02-08 23:26:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f23bb9dd-2bf8-11e9-a760-02d2eeadbd48 0xc421022460 0xc421022461}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-d6thh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d6thh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d6thh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421022600} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421022650}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  8 23:26:28.847: INFO: Pod "nginx-deployment-7f9675fb8b-5tkl8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-5tkl8,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-xg2p6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xg2p6/pods/nginx-deployment-7f9675fb8b-5tkl8,UID:f5db5dcf-2bf8-11e9-a760-02d2eeadbd48,ResourceVersion:15668,Generation:0,CreationTimestamp:2019-02-08 23:26:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f23bb9dd-2bf8-11e9-a760-02d2eeadbd48 0xc4210226b7 0xc4210226b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-d6thh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d6thh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d6thh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421022780} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421022870}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  8 23:26:28.847: INFO: Pod "nginx-deployment-7f9675fb8b-6zfrp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-6zfrp,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-xg2p6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xg2p6/pods/nginx-deployment-7f9675fb8b-6zfrp,UID:f23cccb5-2bf8-11e9-a760-02d2eeadbd48,ResourceVersion:15537,Generation:0,CreationTimestamp:2019-02-08 23:26:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f23bb9dd-2bf8-11e9-a760-02d2eeadbd48 0xc4210228e7 0xc4210228e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-d6thh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d6thh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d6thh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-23-7-130.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421022990} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421022a00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:22 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.130,PodIP:10.2.2.112,StartTime:2019-02-08 23:26:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-08 23:26:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://21351910fb1ac6f1eef8803b324e56079143a7c78175bb37c11ce15deeae337c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  8 23:26:28.847: INFO: Pod "nginx-deployment-7f9675fb8b-8vv25" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-8vv25,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-xg2p6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xg2p6/pods/nginx-deployment-7f9675fb8b-8vv25,UID:f2420fcf-2bf8-11e9-a760-02d2eeadbd48,ResourceVersion:15574,Generation:0,CreationTimestamp:2019-02-08 23:26:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f23bb9dd-2bf8-11e9-a760-02d2eeadbd48 0xc421022c20 0xc421022c21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-d6thh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d6thh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d6thh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-23-7-34.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421022cd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421022cf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:22 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.34,PodIP:10.2.3.30,StartTime:2019-02-08 23:26:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-08 23:26:24 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://268bf88aa37c2cdb7666a31c709574a7f45dcaa03a7c7668e3f3b88ac76783f4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  8 23:26:28.847: INFO: Pod "nginx-deployment-7f9675fb8b-cv8s2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-cv8s2,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-xg2p6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xg2p6/pods/nginx-deployment-7f9675fb8b-cv8s2,UID:f5da0b9e-2bf8-11e9-a760-02d2eeadbd48,ResourceVersion:15667,Generation:0,CreationTimestamp:2019-02-08 23:26:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f23bb9dd-2bf8-11e9-a760-02d2eeadbd48 0xc421022f40 0xc421022f41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-d6thh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d6thh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d6thh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-23-7-110.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421022fa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421023010}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:28 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  8 23:26:28.847: INFO: Pod "nginx-deployment-7f9675fb8b-dw29r" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-dw29r,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-xg2p6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xg2p6/pods/nginx-deployment-7f9675fb8b-dw29r,UID:f23f7bd1-2bf8-11e9-a760-02d2eeadbd48,ResourceVersion:15576,Generation:0,CreationTimestamp:2019-02-08 23:26:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f23bb9dd-2bf8-11e9-a760-02d2eeadbd48 0xc421023080 0xc421023081}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-d6thh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d6thh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d6thh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-23-7-34.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421023160} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421023180}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:22 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.34,PodIP:10.2.3.31,StartTime:2019-02-08 23:26:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-08 23:26:24 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://8cdb7fc2c58be59be2a2e10916126cef4d6987c048d112e0731e7dda8769033f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  8 23:26:28.847: INFO: Pod "nginx-deployment-7f9675fb8b-g4pp9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-g4pp9,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-xg2p6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xg2p6/pods/nginx-deployment-7f9675fb8b-g4pp9,UID:f5dc5182-2bf8-11e9-a760-02d2eeadbd48,ResourceVersion:15674,Generation:0,CreationTimestamp:2019-02-08 23:26:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f23bb9dd-2bf8-11e9-a760-02d2eeadbd48 0xc421023240 0xc421023241}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-d6thh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d6thh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d6thh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4210233d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421023400}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  8 23:26:28.847: INFO: Pod "nginx-deployment-7f9675fb8b-gcdx9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-gcdx9,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-xg2p6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xg2p6/pods/nginx-deployment-7f9675fb8b-gcdx9,UID:f23f540d-2bf8-11e9-a760-02d2eeadbd48,ResourceVersion:15571,Generation:0,CreationTimestamp:2019-02-08 23:26:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f23bb9dd-2bf8-11e9-a760-02d2eeadbd48 0xc421023457 0xc421023458}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-d6thh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d6thh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d6thh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-23-7-110.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4210234c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4210234e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:22 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.110,PodIP:10.2.1.149,StartTime:2019-02-08 23:26:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-08 23:26:24 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://8df295a3cf80453c721cb2465b7d603a3317340c1f41a30aa79054b2d8f3faf8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  8 23:26:28.848: INFO: Pod "nginx-deployment-7f9675fb8b-lgd77" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-lgd77,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-xg2p6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xg2p6/pods/nginx-deployment-7f9675fb8b-lgd77,UID:f23dc076-2bf8-11e9-a760-02d2eeadbd48,ResourceVersion:15564,Generation:0,CreationTimestamp:2019-02-08 23:26:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f23bb9dd-2bf8-11e9-a760-02d2eeadbd48 0xc421023620 0xc421023621}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-d6thh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d6thh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d6thh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-23-7-110.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421023680} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4210236a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:22 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.110,PodIP:10.2.1.151,StartTime:2019-02-08 23:26:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-08 23:26:24 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://6e013b7dbd4658f352330fe4ae1cde9c10b576e8e9c4940d0704b4740f0231e2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  8 23:26:28.848: INFO: Pod "nginx-deployment-7f9675fb8b-plr5w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-plr5w,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-xg2p6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xg2p6/pods/nginx-deployment-7f9675fb8b-plr5w,UID:f5da407f-2bf8-11e9-a760-02d2eeadbd48,ResourceVersion:15669,Generation:0,CreationTimestamp:2019-02-08 23:26:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f23bb9dd-2bf8-11e9-a760-02d2eeadbd48 0xc421023900 0xc421023901}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-d6thh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d6thh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d6thh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-23-7-130.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421023990} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4210239b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:28 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  8 23:26:28.848: INFO: Pod "nginx-deployment-7f9675fb8b-qk95d" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-qk95d,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-xg2p6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xg2p6/pods/nginx-deployment-7f9675fb8b-qk95d,UID:f241ef94-2bf8-11e9-a760-02d2eeadbd48,ResourceVersion:15539,Generation:0,CreationTimestamp:2019-02-08 23:26:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f23bb9dd-2bf8-11e9-a760-02d2eeadbd48 0xc421023ab0 0xc421023ab1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-d6thh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d6thh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d6thh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-23-7-130.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421023b60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421023bf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:22 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.130,PodIP:10.2.2.113,StartTime:2019-02-08 23:26:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-08 23:26:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://3498e08d6bafedc7c96c3a8dc266539a0d71abb619e99cd51aa933be3c3f78fe}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  8 23:26:28.848: INFO: Pod "nginx-deployment-7f9675fb8b-r4mgx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-r4mgx,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-xg2p6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xg2p6/pods/nginx-deployment-7f9675fb8b-r4mgx,UID:f23dabef-2bf8-11e9-a760-02d2eeadbd48,ResourceVersion:15580,Generation:0,CreationTimestamp:2019-02-08 23:26:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f23bb9dd-2bf8-11e9-a760-02d2eeadbd48 0xc421023d40 0xc421023d41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-d6thh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d6thh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d6thh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-23-7-34.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421023e70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421023e90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:22 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.34,PodIP:10.2.3.29,StartTime:2019-02-08 23:26:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-08 23:26:24 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://6e95cf01dce3de103bf9f6a446f686a69d0c092abe42f6d06ea8b31d221e52d8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  8 23:26:28.848: INFO: Pod "nginx-deployment-7f9675fb8b-vsdwv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-vsdwv,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-xg2p6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xg2p6/pods/nginx-deployment-7f9675fb8b-vsdwv,UID:f5d8ca05-2bf8-11e9-a760-02d2eeadbd48,ResourceVersion:15659,Generation:0,CreationTimestamp:2019-02-08 23:26:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f23bb9dd-2bf8-11e9-a760-02d2eeadbd48 0xc421023fd0 0xc421023fd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-d6thh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d6thh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d6thh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-23-7-130.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420fc6030} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420fc6050}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:26:28 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  8 23:26:28.848: INFO: Pod "nginx-deployment-7f9675fb8b-zqzk5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-zqzk5,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-xg2p6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xg2p6/pods/nginx-deployment-7f9675fb8b-zqzk5,UID:f5dc30b4-2bf8-11e9-a760-02d2eeadbd48,ResourceVersion:15671,Generation:0,CreationTimestamp:2019-02-08 23:26:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f23bb9dd-2bf8-11e9-a760-02d2eeadbd48 0xc420fc60c0 0xc420fc60c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-d6thh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d6thh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d6thh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420fc6120} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420fc6140}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:26:28.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-xg2p6" for this suite.
Feb  8 23:26:36.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:26:36.922: INFO: namespace: e2e-tests-deployment-xg2p6, resource: bindings, ignored listing per whitelist
Feb  8 23:26:36.978: INFO: namespace e2e-tests-deployment-xg2p6 deletion completed in 8.113002426s

• [SLOW TEST:14.304 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:26:36.978: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-fac067d7-2bf8-11e9-a551-0a580a020303
STEP: Creating a pod to test consume configMaps
Feb  8 23:26:37.040: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fac1026a-2bf8-11e9-a551-0a580a020303" in namespace "e2e-tests-projected-jhfdx" to be "success or failure"
Feb  8 23:26:37.042: INFO: Pod "pod-projected-configmaps-fac1026a-2bf8-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.226014ms
Feb  8 23:26:39.046: INFO: Pod "pod-projected-configmaps-fac1026a-2bf8-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005775532s
STEP: Saw pod success
Feb  8 23:26:39.046: INFO: Pod "pod-projected-configmaps-fac1026a-2bf8-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:26:39.048: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod pod-projected-configmaps-fac1026a-2bf8-11e9-a551-0a580a020303 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  8 23:26:39.069: INFO: Waiting for pod pod-projected-configmaps-fac1026a-2bf8-11e9-a551-0a580a020303 to disappear
Feb  8 23:26:39.071: INFO: Pod pod-projected-configmaps-fac1026a-2bf8-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:26:39.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jhfdx" for this suite.
Feb  8 23:26:45.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:26:45.147: INFO: namespace: e2e-tests-projected-jhfdx, resource: bindings, ignored listing per whitelist
Feb  8 23:26:45.160: INFO: namespace e2e-tests-projected-jhfdx deletion completed in 6.085442058s

• [SLOW TEST:8.182 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:26:45.160: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  8 23:26:45.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-84fvm'
Feb  8 23:26:45.456: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb  8 23:26:45.456: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Feb  8 23:26:47.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-84fvm'
Feb  8 23:26:47.548: INFO: stderr: ""
Feb  8 23:26:47.548: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:26:47.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-84fvm" for this suite.
Feb  8 23:27:09.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:27:09.579: INFO: namespace: e2e-tests-kubectl-84fvm, resource: bindings, ignored listing per whitelist
Feb  8 23:27:09.638: INFO: namespace e2e-tests-kubectl-84fvm deletion completed in 22.085494447s

• [SLOW TEST:24.478 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:27:09.638: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0208 23:27:15.715498      14 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  8 23:27:15.715: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:27:15.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-lmxr9" for this suite.
Feb  8 23:27:21.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:27:21.791: INFO: namespace: e2e-tests-gc-lmxr9, resource: bindings, ignored listing per whitelist
Feb  8 23:27:21.803: INFO: namespace e2e-tests-gc-lmxr9 deletion completed in 6.084055502s

• [SLOW TEST:12.165 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:27:21.803: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb  8 23:27:21.854: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:27:25.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-bsznx" for this suite.
Feb  8 23:27:47.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:27:47.864: INFO: namespace: e2e-tests-init-container-bsznx, resource: bindings, ignored listing per whitelist
Feb  8 23:27:47.869: INFO: namespace e2e-tests-init-container-bsznx deletion completed in 22.084875187s

• [SLOW TEST:26.066 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:27:47.870: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb  8 23:27:47.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 create -f - --namespace=e2e-tests-kubectl-bxs8m'
Feb  8 23:27:48.089: INFO: stderr: ""
Feb  8 23:27:48.089: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  8 23:27:48.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bxs8m'
Feb  8 23:27:48.190: INFO: stderr: ""
Feb  8 23:27:48.190: INFO: stdout: "update-demo-nautilus-b8925 update-demo-nautilus-ggbtz "
Feb  8 23:27:48.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods update-demo-nautilus-b8925 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bxs8m'
Feb  8 23:27:48.271: INFO: stderr: ""
Feb  8 23:27:48.271: INFO: stdout: ""
Feb  8 23:27:48.271: INFO: update-demo-nautilus-b8925 is created but not running
Feb  8 23:27:53.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bxs8m'
Feb  8 23:27:53.351: INFO: stderr: ""
Feb  8 23:27:53.351: INFO: stdout: "update-demo-nautilus-b8925 update-demo-nautilus-ggbtz "
Feb  8 23:27:53.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods update-demo-nautilus-b8925 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bxs8m'
Feb  8 23:27:53.434: INFO: stderr: ""
Feb  8 23:27:53.434: INFO: stdout: "true"
Feb  8 23:27:53.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods update-demo-nautilus-b8925 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bxs8m'
Feb  8 23:27:53.510: INFO: stderr: ""
Feb  8 23:27:53.510: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  8 23:27:53.510: INFO: validating pod update-demo-nautilus-b8925
Feb  8 23:27:53.515: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  8 23:27:53.515: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  8 23:27:53.515: INFO: update-demo-nautilus-b8925 is verified up and running
Feb  8 23:27:53.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods update-demo-nautilus-ggbtz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bxs8m'
Feb  8 23:27:53.590: INFO: stderr: ""
Feb  8 23:27:53.590: INFO: stdout: "true"
Feb  8 23:27:53.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods update-demo-nautilus-ggbtz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bxs8m'
Feb  8 23:27:53.666: INFO: stderr: ""
Feb  8 23:27:53.666: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  8 23:27:53.666: INFO: validating pod update-demo-nautilus-ggbtz
Feb  8 23:27:53.670: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  8 23:27:53.671: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  8 23:27:53.671: INFO: update-demo-nautilus-ggbtz is verified up and running
STEP: scaling down the replication controller
Feb  8 23:27:53.671: INFO: scanned /root for discovery docs: <nil>
Feb  8 23:27:53.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-bxs8m'
Feb  8 23:27:54.774: INFO: stderr: ""
Feb  8 23:27:54.774: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  8 23:27:54.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bxs8m'
Feb  8 23:27:54.852: INFO: stderr: ""
Feb  8 23:27:54.852: INFO: stdout: "update-demo-nautilus-b8925 update-demo-nautilus-ggbtz "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb  8 23:27:59.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bxs8m'
Feb  8 23:27:59.930: INFO: stderr: ""
Feb  8 23:27:59.930: INFO: stdout: "update-demo-nautilus-b8925 "
Feb  8 23:27:59.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods update-demo-nautilus-b8925 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bxs8m'
Feb  8 23:28:00.019: INFO: stderr: ""
Feb  8 23:28:00.019: INFO: stdout: "true"
Feb  8 23:28:00.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods update-demo-nautilus-b8925 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bxs8m'
Feb  8 23:28:00.095: INFO: stderr: ""
Feb  8 23:28:00.095: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  8 23:28:00.095: INFO: validating pod update-demo-nautilus-b8925
Feb  8 23:28:00.100: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  8 23:28:00.100: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  8 23:28:00.100: INFO: update-demo-nautilus-b8925 is verified up and running
STEP: scaling up the replication controller
Feb  8 23:28:00.101: INFO: scanned /root for discovery docs: <nil>
Feb  8 23:28:00.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-bxs8m'
Feb  8 23:28:01.206: INFO: stderr: ""
Feb  8 23:28:01.206: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  8 23:28:01.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bxs8m'
Feb  8 23:28:01.285: INFO: stderr: ""
Feb  8 23:28:01.285: INFO: stdout: "update-demo-nautilus-b8925 update-demo-nautilus-hhpzf "
Feb  8 23:28:01.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods update-demo-nautilus-b8925 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bxs8m'
Feb  8 23:28:01.362: INFO: stderr: ""
Feb  8 23:28:01.362: INFO: stdout: "true"
Feb  8 23:28:01.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods update-demo-nautilus-b8925 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bxs8m'
Feb  8 23:28:01.440: INFO: stderr: ""
Feb  8 23:28:01.440: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  8 23:28:01.440: INFO: validating pod update-demo-nautilus-b8925
Feb  8 23:28:01.444: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  8 23:28:01.444: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  8 23:28:01.444: INFO: update-demo-nautilus-b8925 is verified up and running
Feb  8 23:28:01.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods update-demo-nautilus-hhpzf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bxs8m'
Feb  8 23:28:01.528: INFO: stderr: ""
Feb  8 23:28:01.528: INFO: stdout: ""
Feb  8 23:28:01.528: INFO: update-demo-nautilus-hhpzf is created but not running
Feb  8 23:28:06.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bxs8m'
Feb  8 23:28:06.607: INFO: stderr: ""
Feb  8 23:28:06.608: INFO: stdout: "update-demo-nautilus-b8925 update-demo-nautilus-hhpzf "
Feb  8 23:28:06.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods update-demo-nautilus-b8925 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bxs8m'
Feb  8 23:28:06.684: INFO: stderr: ""
Feb  8 23:28:06.684: INFO: stdout: "true"
Feb  8 23:28:06.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods update-demo-nautilus-b8925 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bxs8m'
Feb  8 23:28:06.763: INFO: stderr: ""
Feb  8 23:28:06.763: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  8 23:28:06.763: INFO: validating pod update-demo-nautilus-b8925
Feb  8 23:28:06.767: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  8 23:28:06.767: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  8 23:28:06.767: INFO: update-demo-nautilus-b8925 is verified up and running
Feb  8 23:28:06.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods update-demo-nautilus-hhpzf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bxs8m'
Feb  8 23:28:06.844: INFO: stderr: ""
Feb  8 23:28:06.844: INFO: stdout: "true"
Feb  8 23:28:06.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods update-demo-nautilus-hhpzf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bxs8m'
Feb  8 23:28:06.922: INFO: stderr: ""
Feb  8 23:28:06.922: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  8 23:28:06.922: INFO: validating pod update-demo-nautilus-hhpzf
Feb  8 23:28:06.927: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  8 23:28:06.927: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  8 23:28:06.927: INFO: update-demo-nautilus-hhpzf is verified up and running
STEP: using delete to clean up resources
Feb  8 23:28:06.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bxs8m'
Feb  8 23:28:07.011: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  8 23:28:07.011: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb  8 23:28:07.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-bxs8m'
Feb  8 23:28:07.093: INFO: stderr: "No resources found.\n"
Feb  8 23:28:07.093: INFO: stdout: ""
Feb  8 23:28:07.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 get pods -l name=update-demo --namespace=e2e-tests-kubectl-bxs8m -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  8 23:28:07.171: INFO: stderr: ""
Feb  8 23:28:07.171: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:28:07.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bxs8m" for this suite.
Feb  8 23:28:29.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:28:29.197: INFO: namespace: e2e-tests-kubectl-bxs8m, resource: bindings, ignored listing per whitelist
Feb  8 23:28:29.260: INFO: namespace e2e-tests-kubectl-bxs8m deletion completed in 22.084136742s

• [SLOW TEST:41.390 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:28:29.260: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0208 23:28:39.337284      14 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  8 23:28:39.337: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:28:39.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-9bpcj" for this suite.
Feb  8 23:28:45.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:28:45.391: INFO: namespace: e2e-tests-gc-9bpcj, resource: bindings, ignored listing per whitelist
Feb  8 23:28:45.424: INFO: namespace e2e-tests-gc-9bpcj deletion completed in 6.084477479s

• [SLOW TEST:16.165 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:28:45.425: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb  8 23:28:45.486: INFO: Waiting up to 5m0s for pod "pod-47501d73-2bf9-11e9-a551-0a580a020303" in namespace "e2e-tests-emptydir-4d9z7" to be "success or failure"
Feb  8 23:28:45.491: INFO: Pod "pod-47501d73-2bf9-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 4.784479ms
Feb  8 23:28:47.494: INFO: Pod "pod-47501d73-2bf9-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008176683s
STEP: Saw pod success
Feb  8 23:28:47.494: INFO: Pod "pod-47501d73-2bf9-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:28:47.496: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod pod-47501d73-2bf9-11e9-a551-0a580a020303 container test-container: <nil>
STEP: delete the pod
Feb  8 23:28:47.516: INFO: Waiting for pod pod-47501d73-2bf9-11e9-a551-0a580a020303 to disappear
Feb  8 23:28:47.518: INFO: Pod pod-47501d73-2bf9-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:28:47.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4d9z7" for this suite.
Feb  8 23:28:53.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:28:53.554: INFO: namespace: e2e-tests-emptydir-4d9z7, resource: bindings, ignored listing per whitelist
Feb  8 23:28:53.610: INFO: namespace e2e-tests-emptydir-4d9z7 deletion completed in 6.088796026s

• [SLOW TEST:8.186 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:28:53.610: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-gxnss
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Feb  8 23:28:53.675: INFO: Found 0 stateful pods, waiting for 3
Feb  8 23:29:03.679: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  8 23:29:03.679: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  8 23:29:03.679: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb  8 23:29:03.704: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb  8 23:29:13.735: INFO: Updating stateful set ss2
Feb  8 23:29:13.743: INFO: Waiting for Pod e2e-tests-statefulset-gxnss/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Feb  8 23:29:23.798: INFO: Found 2 stateful pods, waiting for 3
Feb  8 23:29:33.801: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  8 23:29:33.801: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  8 23:29:33.801: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb  8 23:29:33.826: INFO: Updating stateful set ss2
Feb  8 23:29:33.833: INFO: Waiting for Pod e2e-tests-statefulset-gxnss/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb  8 23:29:43.858: INFO: Updating stateful set ss2
Feb  8 23:29:43.863: INFO: Waiting for StatefulSet e2e-tests-statefulset-gxnss/ss2 to complete update
Feb  8 23:29:43.863: INFO: Waiting for Pod e2e-tests-statefulset-gxnss/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  8 23:29:53.870: INFO: Deleting all statefulset in ns e2e-tests-statefulset-gxnss
Feb  8 23:29:53.872: INFO: Scaling statefulset ss2 to 0
Feb  8 23:30:03.885: INFO: Waiting for statefulset status.replicas updated to 0
Feb  8 23:30:03.888: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:30:03.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-gxnss" for this suite.
Feb  8 23:30:09.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:30:09.995: INFO: namespace: e2e-tests-statefulset-gxnss, resource: bindings, ignored listing per whitelist
Feb  8 23:30:10.010: INFO: namespace e2e-tests-statefulset-gxnss deletion completed in 6.089527954s

• [SLOW TEST:76.400 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:30:10.010: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb  8 23:30:10.064: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:30:13.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-6d469" for this suite.
Feb  8 23:30:19.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:30:19.146: INFO: namespace: e2e-tests-init-container-6d469, resource: bindings, ignored listing per whitelist
Feb  8 23:30:19.202: INFO: namespace e2e-tests-init-container-6d469 deletion completed in 6.088457856s

• [SLOW TEST:9.191 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:30:19.202: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  8 23:30:19.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-g9zfv'
Feb  8 23:30:19.334: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb  8 23:30:19.334: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Feb  8 23:30:19.341: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-85kvq]
Feb  8 23:30:19.341: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-85kvq" in namespace "e2e-tests-kubectl-g9zfv" to be "running and ready"
Feb  8 23:30:19.346: INFO: Pod "e2e-test-nginx-rc-85kvq": Phase="Pending", Reason="", readiness=false. Elapsed: 5.189176ms
Feb  8 23:30:21.350: INFO: Pod "e2e-test-nginx-rc-85kvq": Phase="Running", Reason="", readiness=true. Elapsed: 2.008676149s
Feb  8 23:30:21.350: INFO: Pod "e2e-test-nginx-rc-85kvq" satisfied condition "running and ready"
Feb  8 23:30:21.350: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-85kvq]
Feb  8 23:30:21.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-g9zfv'
Feb  8 23:30:21.443: INFO: stderr: ""
Feb  8 23:30:21.443: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Feb  8 23:30:21.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-g9zfv'
Feb  8 23:30:21.527: INFO: stderr: ""
Feb  8 23:30:21.527: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:30:21.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-g9zfv" for this suite.
Feb  8 23:30:43.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:30:43.608: INFO: namespace: e2e-tests-kubectl-g9zfv, resource: bindings, ignored listing per whitelist
Feb  8 23:30:43.618: INFO: namespace e2e-tests-kubectl-g9zfv deletion completed in 22.087552207s

• [SLOW TEST:24.416 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:30:43.619: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Feb  8 23:30:43.676: INFO: Waiting up to 5m0s for pod "client-containers-8dc296b3-2bf9-11e9-a551-0a580a020303" in namespace "e2e-tests-containers-bgkl8" to be "success or failure"
Feb  8 23:30:43.679: INFO: Pod "client-containers-8dc296b3-2bf9-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.433472ms
Feb  8 23:30:45.682: INFO: Pod "client-containers-8dc296b3-2bf9-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005750453s
STEP: Saw pod success
Feb  8 23:30:45.682: INFO: Pod "client-containers-8dc296b3-2bf9-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:30:45.685: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod client-containers-8dc296b3-2bf9-11e9-a551-0a580a020303 container test-container: <nil>
STEP: delete the pod
Feb  8 23:30:45.705: INFO: Waiting for pod client-containers-8dc296b3-2bf9-11e9-a551-0a580a020303 to disappear
Feb  8 23:30:45.708: INFO: Pod client-containers-8dc296b3-2bf9-11e9-a551-0a580a020303 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:30:45.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-bgkl8" for this suite.
Feb  8 23:30:51.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:30:51.789: INFO: namespace: e2e-tests-containers-bgkl8, resource: bindings, ignored listing per whitelist
Feb  8 23:30:51.802: INFO: namespace e2e-tests-containers-bgkl8 deletion completed in 6.090918261s

• [SLOW TEST:8.184 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:30:51.802: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  8 23:30:51.858: INFO: Waiting up to 5m0s for pod "downward-api-92a302f0-2bf9-11e9-a551-0a580a020303" in namespace "e2e-tests-downward-api-tlm5c" to be "success or failure"
Feb  8 23:30:51.860: INFO: Pod "downward-api-92a302f0-2bf9-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.767091ms
Feb  8 23:30:53.863: INFO: Pod "downward-api-92a302f0-2bf9-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00589884s
STEP: Saw pod success
Feb  8 23:30:53.863: INFO: Pod "downward-api-92a302f0-2bf9-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:30:53.866: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod downward-api-92a302f0-2bf9-11e9-a551-0a580a020303 container dapi-container: <nil>
STEP: delete the pod
Feb  8 23:30:53.882: INFO: Waiting for pod downward-api-92a302f0-2bf9-11e9-a551-0a580a020303 to disappear
Feb  8 23:30:53.884: INFO: Pod downward-api-92a302f0-2bf9-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:30:53.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-tlm5c" for this suite.
Feb  8 23:30:59.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:30:59.917: INFO: namespace: e2e-tests-downward-api-tlm5c, resource: bindings, ignored listing per whitelist
Feb  8 23:30:59.975: INFO: namespace e2e-tests-downward-api-tlm5c deletion completed in 6.087422591s

• [SLOW TEST:8.172 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:30:59.975: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-k22nr
Feb  8 23:31:02.046: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-k22nr
STEP: checking the pod's current state and verifying that restartCount is present
Feb  8 23:31:02.048: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:35:02.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-k22nr" for this suite.
Feb  8 23:35:08.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:35:08.539: INFO: namespace: e2e-tests-container-probe-k22nr, resource: bindings, ignored listing per whitelist
Feb  8 23:35:08.581: INFO: namespace e2e-tests-container-probe-k22nr deletion completed in 6.087587056s

• [SLOW TEST:248.606 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:35:08.581: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-2bb2efe0-2bfa-11e9-a551-0a580a020303
STEP: Creating configMap with name cm-test-opt-upd-2bb2f01a-2bfa-11e9-a551-0a580a020303
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-2bb2efe0-2bfa-11e9-a551-0a580a020303
STEP: Updating configmap cm-test-opt-upd-2bb2f01a-2bfa-11e9-a551-0a580a020303
STEP: Creating configMap with name cm-test-opt-create-2bb2f03b-2bfa-11e9-a551-0a580a020303
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:35:14.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-m97m9" for this suite.
Feb  8 23:35:36.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:35:36.781: INFO: namespace: e2e-tests-configmap-m97m9, resource: bindings, ignored listing per whitelist
Feb  8 23:35:36.830: INFO: namespace e2e-tests-configmap-m97m9 deletion completed in 22.086548556s

• [SLOW TEST:28.249 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:35:36.830: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-3c8733a2-2bfa-11e9-a551-0a580a020303
STEP: Creating a pod to test consume secrets
Feb  8 23:35:36.919: INFO: Waiting up to 5m0s for pod "pod-secrets-3c8bd548-2bfa-11e9-a551-0a580a020303" in namespace "e2e-tests-secrets-znnq7" to be "success or failure"
Feb  8 23:35:36.922: INFO: Pod "pod-secrets-3c8bd548-2bfa-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.834004ms
Feb  8 23:35:38.925: INFO: Pod "pod-secrets-3c8bd548-2bfa-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006312556s
STEP: Saw pod success
Feb  8 23:35:38.925: INFO: Pod "pod-secrets-3c8bd548-2bfa-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:35:38.928: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod pod-secrets-3c8bd548-2bfa-11e9-a551-0a580a020303 container secret-volume-test: <nil>
STEP: delete the pod
Feb  8 23:35:38.946: INFO: Waiting for pod pod-secrets-3c8bd548-2bfa-11e9-a551-0a580a020303 to disappear
Feb  8 23:35:38.948: INFO: Pod pod-secrets-3c8bd548-2bfa-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:35:38.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-znnq7" for this suite.
Feb  8 23:35:44.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:35:44.981: INFO: namespace: e2e-tests-secrets-znnq7, resource: bindings, ignored listing per whitelist
Feb  8 23:35:45.037: INFO: namespace e2e-tests-secrets-znnq7 deletion completed in 6.086296762s
STEP: Destroying namespace "e2e-tests-secret-namespace-dpzdt" for this suite.
Feb  8 23:35:51.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:35:51.109: INFO: namespace: e2e-tests-secret-namespace-dpzdt, resource: bindings, ignored listing per whitelist
Feb  8 23:35:51.129: INFO: namespace e2e-tests-secret-namespace-dpzdt deletion completed in 6.091068016s

• [SLOW TEST:14.299 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:35:51.129: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  8 23:35:51.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-2gxkn'
Feb  8 23:35:51.271: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb  8 23:35:51.271: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Feb  8 23:35:51.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-2gxkn'
Feb  8 23:35:51.361: INFO: stderr: ""
Feb  8 23:35:51.361: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:35:51.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2gxkn" for this suite.
Feb  8 23:36:13.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:36:13.401: INFO: namespace: e2e-tests-kubectl-2gxkn, resource: bindings, ignored listing per whitelist
Feb  8 23:36:13.455: INFO: namespace e2e-tests-kubectl-2gxkn deletion completed in 22.090472524s

• [SLOW TEST:22.327 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:36:13.456: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-525beff4-2bfa-11e9-a551-0a580a020303
STEP: Creating a pod to test consume secrets
Feb  8 23:36:13.518: INFO: Waiting up to 5m0s for pod "pod-secrets-525c8923-2bfa-11e9-a551-0a580a020303" in namespace "e2e-tests-secrets-lxqt5" to be "success or failure"
Feb  8 23:36:13.521: INFO: Pod "pod-secrets-525c8923-2bfa-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.283048ms
Feb  8 23:36:15.524: INFO: Pod "pod-secrets-525c8923-2bfa-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005981941s
STEP: Saw pod success
Feb  8 23:36:15.524: INFO: Pod "pod-secrets-525c8923-2bfa-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:36:15.527: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod pod-secrets-525c8923-2bfa-11e9-a551-0a580a020303 container secret-volume-test: <nil>
STEP: delete the pod
Feb  8 23:36:15.546: INFO: Waiting for pod pod-secrets-525c8923-2bfa-11e9-a551-0a580a020303 to disappear
Feb  8 23:36:15.549: INFO: Pod pod-secrets-525c8923-2bfa-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:36:15.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-lxqt5" for this suite.
Feb  8 23:36:21.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:36:21.579: INFO: namespace: e2e-tests-secrets-lxqt5, resource: bindings, ignored listing per whitelist
Feb  8 23:36:21.639: INFO: namespace e2e-tests-secrets-lxqt5 deletion completed in 6.086254986s

• [SLOW TEST:8.183 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:36:21.639: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  8 23:36:21.696: INFO: Pod name rollover-pod: Found 0 pods out of 1
Feb  8 23:36:26.700: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb  8 23:36:26.700: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb  8 23:36:28.703: INFO: Creating deployment "test-rollover-deployment"
Feb  8 23:36:28.711: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb  8 23:36:30.717: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb  8 23:36:30.721: INFO: Ensure that both replica sets have 1 created replica
Feb  8 23:36:30.726: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb  8 23:36:30.732: INFO: Updating deployment test-rollover-deployment
Feb  8 23:36:30.732: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb  8 23:36:32.740: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb  8 23:36:32.745: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb  8 23:36:32.749: INFO: all replica sets need to contain the pod-template-hash label
Feb  8 23:36:32.749: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685265788, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685265788, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685265792, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685265788, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  8 23:36:34.756: INFO: all replica sets need to contain the pod-template-hash label
Feb  8 23:36:34.756: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685265788, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685265788, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685265792, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685265788, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  8 23:36:36.755: INFO: all replica sets need to contain the pod-template-hash label
Feb  8 23:36:36.756: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685265788, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685265788, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685265792, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685265788, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  8 23:36:38.756: INFO: all replica sets need to contain the pod-template-hash label
Feb  8 23:36:38.756: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685265788, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685265788, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685265792, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685265788, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  8 23:36:40.755: INFO: all replica sets need to contain the pod-template-hash label
Feb  8 23:36:40.755: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685265788, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685265788, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685265792, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685265788, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  8 23:36:42.756: INFO: 
Feb  8 23:36:42.756: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  8 23:36:42.762: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-7hwdq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7hwdq/deployments/test-rollover-deployment,UID:5b6b01a6-2bfa-11e9-a760-02d2eeadbd48,ResourceVersion:17948,Generation:2,CreationTimestamp:2019-02-08 23:36:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-08 23:36:28 +0000 UTC 2019-02-08 23:36:28 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-08 23:36:42 +0000 UTC 2019-02-08 23:36:28 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb  8 23:36:42.764: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-7hwdq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7hwdq/replicasets/test-rollover-deployment-5b76ff8c4,UID:5ca095f6-2bfa-11e9-a760-02d2eeadbd48,ResourceVersion:17939,Generation:2,CreationTimestamp:2019-02-08 23:36:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 5b6b01a6-2bfa-11e9-a760-02d2eeadbd48 0xc421e3bcd7 0xc421e3bcd8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb  8 23:36:42.764: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb  8 23:36:42.764: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-7hwdq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7hwdq/replicasets/test-rollover-controller,UID:573cd1c3-2bfa-11e9-a760-02d2eeadbd48,ResourceVersion:17947,Generation:2,CreationTimestamp:2019-02-08 23:36:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 5b6b01a6-2bfa-11e9-a760-02d2eeadbd48 0xc421e3b8ce 0xc421e3b8cf}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  8 23:36:42.764: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-7hwdq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7hwdq/replicasets/test-rollover-deployment-6975f4fb87,UID:5b6dc79c-2bfa-11e9-a760-02d2eeadbd48,ResourceVersion:17911,Generation:2,CreationTimestamp:2019-02-08 23:36:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 5b6b01a6-2bfa-11e9-a760-02d2eeadbd48 0xc421e3bf47 0xc421e3bf48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  8 23:36:42.767: INFO: Pod "test-rollover-deployment-5b76ff8c4-vvfvp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-vvfvp,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-7hwdq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7hwdq/pods/test-rollover-deployment-5b76ff8c4-vvfvp,UID:5ca41ea1-2bfa-11e9-a760-02d2eeadbd48,ResourceVersion:17921,Generation:0,CreationTimestamp:2019-02-08 23:36:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 5ca095f6-2bfa-11e9-a760-02d2eeadbd48 0xc421e81d00 0xc421e81d01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-pxszv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pxszv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-pxszv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-23-7-110.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421e81df0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421e81e10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:36:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:36:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:36:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-08 23:36:30 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.110,PodIP:10.2.1.173,StartTime:2019-02-08 23:36:30 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-08 23:36:31 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://e47c56d3e63f335df1da96bb7da684e7a9a64fa515240151a7f26076d3b21714}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:36:42.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-7hwdq" for this suite.
Feb  8 23:36:48.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:36:48.800: INFO: namespace: e2e-tests-deployment-7hwdq, resource: bindings, ignored listing per whitelist
Feb  8 23:36:48.854: INFO: namespace e2e-tests-deployment-7hwdq deletion completed in 6.083571673s

• [SLOW TEST:27.215 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:36:48.854: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Feb  8 23:36:48.912: INFO: Waiting up to 5m0s for pod "var-expansion-67752854-2bfa-11e9-a551-0a580a020303" in namespace "e2e-tests-var-expansion-qfqps" to be "success or failure"
Feb  8 23:36:48.914: INFO: Pod "var-expansion-67752854-2bfa-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.20312ms
Feb  8 23:36:50.917: INFO: Pod "var-expansion-67752854-2bfa-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005624269s
STEP: Saw pod success
Feb  8 23:36:50.917: INFO: Pod "var-expansion-67752854-2bfa-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:36:50.919: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod var-expansion-67752854-2bfa-11e9-a551-0a580a020303 container dapi-container: <nil>
STEP: delete the pod
Feb  8 23:36:50.954: INFO: Waiting for pod var-expansion-67752854-2bfa-11e9-a551-0a580a020303 to disappear
Feb  8 23:36:50.956: INFO: Pod var-expansion-67752854-2bfa-11e9-a551-0a580a020303 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:36:50.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-qfqps" for this suite.
Feb  8 23:36:56.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:36:57.044: INFO: namespace: e2e-tests-var-expansion-qfqps, resource: bindings, ignored listing per whitelist
Feb  8 23:36:57.052: INFO: namespace e2e-tests-var-expansion-qfqps deletion completed in 6.092788167s

• [SLOW TEST:8.198 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:36:57.052: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-x9zkj
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-x9zkj
STEP: Deleting pre-stop pod
Feb  8 23:37:08.142: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:37:08.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-x9zkj" for this suite.
Feb  8 23:37:46.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:37:46.201: INFO: namespace: e2e-tests-prestop-x9zkj, resource: bindings, ignored listing per whitelist
Feb  8 23:37:46.238: INFO: namespace e2e-tests-prestop-x9zkj deletion completed in 38.087511201s

• [SLOW TEST:49.186 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:37:46.238: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb  8 23:37:46.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 create -f - --namespace=e2e-tests-kubectl-fh9sh'
Feb  8 23:37:46.592: INFO: stderr: ""
Feb  8 23:37:46.592: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb  8 23:37:47.596: INFO: Selector matched 1 pods for map[app:redis]
Feb  8 23:37:47.596: INFO: Found 1 / 1
Feb  8 23:37:47.596: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb  8 23:37:47.598: INFO: Selector matched 1 pods for map[app:redis]
Feb  8 23:37:47.598: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb  8 23:37:47.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-821255472 patch pod redis-master-94nvs --namespace=e2e-tests-kubectl-fh9sh -p {"metadata":{"annotations":{"x":"y"}}}'
Feb  8 23:37:47.678: INFO: stderr: ""
Feb  8 23:37:47.678: INFO: stdout: "pod/redis-master-94nvs patched\n"
STEP: checking annotations
Feb  8 23:37:47.681: INFO: Selector matched 1 pods for map[app:redis]
Feb  8 23:37:47.681: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:37:47.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fh9sh" for this suite.
Feb  8 23:38:09.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:38:09.710: INFO: namespace: e2e-tests-kubectl-fh9sh, resource: bindings, ignored listing per whitelist
Feb  8 23:38:09.770: INFO: namespace e2e-tests-kubectl-fh9sh deletion completed in 22.085844168s

• [SLOW TEST:23.532 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:38:09.770: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-97aff62a-2bfa-11e9-a551-0a580a020303
STEP: Creating a pod to test consume secrets
Feb  8 23:38:09.831: INFO: Waiting up to 5m0s for pod "pod-secrets-97b073b3-2bfa-11e9-a551-0a580a020303" in namespace "e2e-tests-secrets-swkvh" to be "success or failure"
Feb  8 23:38:09.834: INFO: Pod "pod-secrets-97b073b3-2bfa-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.735142ms
Feb  8 23:38:11.838: INFO: Pod "pod-secrets-97b073b3-2bfa-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00635079s
STEP: Saw pod success
Feb  8 23:38:11.838: INFO: Pod "pod-secrets-97b073b3-2bfa-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:38:11.840: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod pod-secrets-97b073b3-2bfa-11e9-a551-0a580a020303 container secret-env-test: <nil>
STEP: delete the pod
Feb  8 23:38:11.859: INFO: Waiting for pod pod-secrets-97b073b3-2bfa-11e9-a551-0a580a020303 to disappear
Feb  8 23:38:11.861: INFO: Pod pod-secrets-97b073b3-2bfa-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:38:11.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-swkvh" for this suite.
Feb  8 23:38:17.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:38:17.899: INFO: namespace: e2e-tests-secrets-swkvh, resource: bindings, ignored listing per whitelist
Feb  8 23:38:17.951: INFO: namespace e2e-tests-secrets-swkvh deletion completed in 6.087323082s

• [SLOW TEST:8.181 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:38:17.952: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Feb  8 23:38:20.023: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-9c904ca9-2bfa-11e9-a551-0a580a020303", GenerateName:"", Namespace:"e2e-tests-pods-6l9hd", SelfLink:"/api/v1/namespaces/e2e-tests-pods-6l9hd/pods/pod-submit-remove-9c904ca9-2bfa-11e9-a551-0a580a020303", UID:"9c9187e1-2bfa-11e9-a760-02d2eeadbd48", ResourceVersion:"18270", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63685265898, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"3170305"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-qwlxr", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc421adec80), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-qwlxr", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc421166ea8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-23-7-110.us-west-2.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc4222a2900), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421166f60)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421166f80)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc421166f88), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685265898, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685265899, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685265899, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685265898, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.23.7.110", PodIP:"10.2.1.176", StartTime:(*v1.Time)(0xc420f88860), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc420f888a0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632", ContainerID:"docker://6f39a0ec1f7b5fc4e59e9269324852c97a34825461f5eead89206c94d09de8dc"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:38:27.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-6l9hd" for this suite.
Feb  8 23:38:33.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:38:33.952: INFO: namespace: e2e-tests-pods-6l9hd, resource: bindings, ignored listing per whitelist
Feb  8 23:38:33.995: INFO: namespace e2e-tests-pods-6l9hd deletion completed in 6.091915642s

• [SLOW TEST:16.043 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:38:33.995: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-6mn27/configmap-test-a6209beb-2bfa-11e9-a551-0a580a020303
STEP: Creating a pod to test consume configMaps
Feb  8 23:38:34.058: INFO: Waiting up to 5m0s for pod "pod-configmaps-a6211fe3-2bfa-11e9-a551-0a580a020303" in namespace "e2e-tests-configmap-6mn27" to be "success or failure"
Feb  8 23:38:34.063: INFO: Pod "pod-configmaps-a6211fe3-2bfa-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 4.311ms
Feb  8 23:38:36.066: INFO: Pod "pod-configmaps-a6211fe3-2bfa-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00781307s
STEP: Saw pod success
Feb  8 23:38:36.066: INFO: Pod "pod-configmaps-a6211fe3-2bfa-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:38:36.069: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod pod-configmaps-a6211fe3-2bfa-11e9-a551-0a580a020303 container env-test: <nil>
STEP: delete the pod
Feb  8 23:38:36.086: INFO: Waiting for pod pod-configmaps-a6211fe3-2bfa-11e9-a551-0a580a020303 to disappear
Feb  8 23:38:36.088: INFO: Pod pod-configmaps-a6211fe3-2bfa-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:38:36.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-6mn27" for this suite.
Feb  8 23:38:42.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:38:42.116: INFO: namespace: e2e-tests-configmap-6mn27, resource: bindings, ignored listing per whitelist
Feb  8 23:38:42.175: INFO: namespace e2e-tests-configmap-6mn27 deletion completed in 6.081955769s

• [SLOW TEST:8.179 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:38:42.175: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb  8 23:38:42.229: INFO: Waiting up to 5m0s for pod "pod-ab000d39-2bfa-11e9-a551-0a580a020303" in namespace "e2e-tests-emptydir-67hdk" to be "success or failure"
Feb  8 23:38:42.231: INFO: Pod "pod-ab000d39-2bfa-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.502524ms
Feb  8 23:38:44.235: INFO: Pod "pod-ab000d39-2bfa-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006035051s
STEP: Saw pod success
Feb  8 23:38:44.235: INFO: Pod "pod-ab000d39-2bfa-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:38:44.237: INFO: Trying to get logs from node ip-172-23-7-110.us-west-2.compute.internal pod pod-ab000d39-2bfa-11e9-a551-0a580a020303 container test-container: <nil>
STEP: delete the pod
Feb  8 23:38:44.255: INFO: Waiting for pod pod-ab000d39-2bfa-11e9-a551-0a580a020303 to disappear
Feb  8 23:38:44.257: INFO: Pod pod-ab000d39-2bfa-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:38:44.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-67hdk" for this suite.
Feb  8 23:38:50.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:38:50.309: INFO: namespace: e2e-tests-emptydir-67hdk, resource: bindings, ignored listing per whitelist
Feb  8 23:38:50.343: INFO: namespace e2e-tests-emptydir-67hdk deletion completed in 6.082180974s

• [SLOW TEST:8.168 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:38:50.343: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-7rv29
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7rv29 to expose endpoints map[]
Feb  8 23:38:50.409: INFO: Get endpoints failed (2.79233ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Feb  8 23:38:51.413: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7rv29 exposes endpoints map[] (1.0064152s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-7rv29
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7rv29 to expose endpoints map[pod1:[80]]
Feb  8 23:38:53.448: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7rv29 exposes endpoints map[pod1:[80]] (2.027149956s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-7rv29
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7rv29 to expose endpoints map[pod1:[80] pod2:[80]]
Feb  8 23:38:55.482: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7rv29 exposes endpoints map[pod1:[80] pod2:[80]] (2.028302023s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-7rv29
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7rv29 to expose endpoints map[pod2:[80]]
Feb  8 23:38:56.503: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7rv29 exposes endpoints map[pod2:[80]] (1.0149116s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-7rv29
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7rv29 to expose endpoints map[]
Feb  8 23:38:57.515: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7rv29 exposes endpoints map[] (1.005776141s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:38:57.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-7rv29" for this suite.
Feb  8 23:39:19.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:39:19.633: INFO: namespace: e2e-tests-services-7rv29, resource: bindings, ignored listing per whitelist
Feb  8 23:39:19.639: INFO: namespace e2e-tests-services-7rv29 deletion completed in 22.090880855s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:29.297 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:39:19.640: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb  8 23:39:19.715: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-bjbv5,SelfLink:/api/v1/namespaces/e2e-tests-watch-bjbv5/configmaps/e2e-watch-test-resource-version,UID:c155c73f-2bfa-11e9-a760-02d2eeadbd48,ResourceVersion:18488,Generation:0,CreationTimestamp:2019-02-08 23:39:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  8 23:39:19.715: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-bjbv5,SelfLink:/api/v1/namespaces/e2e-tests-watch-bjbv5/configmaps/e2e-watch-test-resource-version,UID:c155c73f-2bfa-11e9-a760-02d2eeadbd48,ResourceVersion:18489,Generation:0,CreationTimestamp:2019-02-08 23:39:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:39:19.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-bjbv5" for this suite.
Feb  8 23:39:25.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:39:25.775: INFO: namespace: e2e-tests-watch-bjbv5, resource: bindings, ignored listing per whitelist
Feb  8 23:39:25.814: INFO: namespace e2e-tests-watch-bjbv5 deletion completed in 6.096003223s

• [SLOW TEST:6.175 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  8 23:39:25.814: INFO: >>> kubeConfig: /tmp/kubeconfig-821255472
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  8 23:39:25.869: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c502dbd2-2bfa-11e9-a551-0a580a020303" in namespace "e2e-tests-downward-api-2cqgw" to be "success or failure"
Feb  8 23:39:25.873: INFO: Pod "downwardapi-volume-c502dbd2-2bfa-11e9-a551-0a580a020303": Phase="Pending", Reason="", readiness=false. Elapsed: 4.366503ms
Feb  8 23:39:27.877: INFO: Pod "downwardapi-volume-c502dbd2-2bfa-11e9-a551-0a580a020303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007706612s
STEP: Saw pod success
Feb  8 23:39:27.877: INFO: Pod "downwardapi-volume-c502dbd2-2bfa-11e9-a551-0a580a020303" satisfied condition "success or failure"
Feb  8 23:39:27.879: INFO: Trying to get logs from node ip-172-23-7-130.us-west-2.compute.internal pod downwardapi-volume-c502dbd2-2bfa-11e9-a551-0a580a020303 container client-container: <nil>
STEP: delete the pod
Feb  8 23:39:27.897: INFO: Waiting for pod downwardapi-volume-c502dbd2-2bfa-11e9-a551-0a580a020303 to disappear
Feb  8 23:39:27.900: INFO: Pod downwardapi-volume-c502dbd2-2bfa-11e9-a551-0a580a020303 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  8 23:39:27.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2cqgw" for this suite.
Feb  8 23:39:33.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  8 23:39:33.963: INFO: namespace: e2e-tests-downward-api-2cqgw, resource: bindings, ignored listing per whitelist
Feb  8 23:39:33.993: INFO: namespace e2e-tests-downward-api-2cqgw deletion completed in 6.089622201s

• [SLOW TEST:8.179 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSFeb  8 23:39:33.993: INFO: Running AfterSuite actions on all node
Feb  8 23:39:33.993: INFO: Running AfterSuite actions on node 1
Feb  8 23:39:33.993: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 4775.594 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 1h19m36.333377704s
Test Suite Passed
